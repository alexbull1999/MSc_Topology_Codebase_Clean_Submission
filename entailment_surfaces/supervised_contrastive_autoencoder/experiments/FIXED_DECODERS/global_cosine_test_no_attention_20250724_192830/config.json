{
  "data": {
    "train_path": "data/processed/snli_full_standard_SBERT.pt",
    "val_path": "data/processed/snli_full_standard_SBERT_validation.pt",
    "test_path": "data/processed/snli_full_standard_SBERT_test.pt",
    "embedding_type": "cosine_concat",
    "batch_size": 1020,
    "sample_size": null,
    "balanced_sampling": true,
    "random_state": 42
  },
  "model": {
    "input_dim": 1537,
    "latent_dim": 75,
    "hidden_dims": [
      1024,
      768,
      512,
      256,
      128
    ],
    "dropout_rate": 0.2
  },
  "loss": {
    "contrastive_weight": 1.0,
    "reconstruction_weight": 100.0,
    "margin": 2.0,
    "update_frequency": 3,
    "max_global_samples": 5000,
    "schedule_reconstruction": false,
    "warmup_epochs": 0,
    "max_reconstruction_weight": 100.0,
    "schedule_type": "linear"
  },
  "optimizer": {
    "optimizer_type": "Adam",
    "lr": 0.0001,
    "weight_decay": 1e-05
  },
  "training": {
    "num_epochs": 200,
    "patience": 8,
    "save_every": 20,
    "debug_frequency": 25
  },
  "output": {
    "save_results": true,
    "save_plots": true,
    "experiment_name": "global_cosine_test_no_attention"
  }
}