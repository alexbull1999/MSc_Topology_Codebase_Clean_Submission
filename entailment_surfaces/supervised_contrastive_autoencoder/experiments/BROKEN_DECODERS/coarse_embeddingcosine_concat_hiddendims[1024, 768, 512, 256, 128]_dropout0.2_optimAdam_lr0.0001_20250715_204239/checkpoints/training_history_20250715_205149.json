{
  "epoch": [
    1,
    2,
    3,
    4,
    5,
    6,
    7,
    8,
    9,
    10,
    11,
    12,
    13,
    14,
    15,
    16,
    17,
    18,
    19
  ],
  "train_loss": [
    1.9189313175069997,
    1.8866181868636631,
    1.8779990786280711,
    1.2148706278099473,
    1.1985503947934626,
    1.1901282973351648,
    1.1410358207407831,
    1.1327630250369591,
    1.1288615116637957,
    1.1044838131029069,
    1.1019465756815905,
    1.0980487664540608,
    1.0835454401801197,
    1.0805290946303354,
    1.0775711576365892,
    1.0357658707673767,
    1.032871301169724,
    1.029207053242227,
    1.0010823788367613
  ],
  "train_contrastive_loss": [
    1.9189313175069997,
    1.8866181868636631,
    1.8779990786280711,
    1.2148706278099473,
    1.1985503947934626,
    1.1901282973351648,
    1.1410358207407831,
    1.1327630250369591,
    1.1288615116637957,
    1.1044838131029069,
    1.1019465756815905,
    1.0980487664540608,
    1.0835454401801197,
    1.0805290946303354,
    1.0775711576365892,
    1.0357658707673767,
    1.032871301169724,
    1.029207053242227,
    1.0010823788367613
  ],
  "train_reconstruction_loss": [
    0.010805975238218543,
    0.01071135377861712,
    0.010711069007228983,
    0.010711146100620206,
    0.010711058504268999,
    0.010711161069419353,
    0.010711089692302255,
    0.010711058020397493,
    0.010711062326680459,
    0.01071103999401604,
    0.010711050581957041,
    0.010711075817850493,
    0.0107111357259989,
    0.010711126452662202,
    0.010710984501411907,
    0.010711064791129954,
    0.01071112138848731,
    0.010711011749100862,
    0.010710983667210494
  ],
  "val_loss": [
    1.8797509007983737,
    1.8764233854081895,
    1.869088305367364,
    1.1996454662746854,
    1.1991156604554918,
    1.1791806485917833,
    1.1257627805074055,
    1.1284715334574382,
    1.1367971102396648,
    1.1184825632307265,
    1.107123335202535,
    1.109512792693244,
    1.1016299062305026,
    1.0963340997695923,
    1.079852859179179,
    1.0570837126837835,
    1.0471892886691623,
    1.044222844971551,
    1.0265486637751262
  ],
  "val_contrastive_loss": [
    1.8797509007983737,
    1.8764233854081895,
    1.869088305367364,
    1.1996454662746854,
    1.1991156604554918,
    1.1791806485917833,
    1.1257627805074055,
    1.1284715334574382,
    1.1367971102396648,
    1.1184825632307265,
    1.107123335202535,
    1.109512792693244,
    1.1016299062305026,
    1.0963340997695923,
    1.079852859179179,
    1.0570837126837835,
    1.0471892886691623,
    1.044222844971551,
    1.0265486637751262
  ],
  "val_reconstruction_loss": [
    0.010632446242703332,
    0.010626820743911795,
    0.010629767448537879,
    0.010628368912471665,
    0.010628343559801579,
    0.010629227488405175,
    0.010633109033935599,
    0.01063016222582923,
    0.010633035666412778,
    0.01063092208156983,
    0.01062895336912738,
    0.010630281124677923,
    0.010630551415185133,
    0.010631179126600424,
    0.010631036737726795,
    0.010628807668884596,
    0.010631637958188852,
    0.010630042499138249,
    0.010632069470981756
  ],
  "learning_rate": [
    0.0001,
    0.0001,
    0.0001,
    0.0001,
    0.0001,
    0.0001,
    0.0001,
    0.0001,
    0.0001,
    0.0001,
    0.0001,
    0.0001,
    0.0001,
    0.0001,
    0.0001,
    0.0001,
    0.0001,
    0.0001,
    0.0001
  ],
  "train_separation_ratio": [
    1.7842067019505934,
    2.270026206970215,
    2.4478914087468926,
    2.5249147306789053,
    2.70672438361428,
    2.728538231416182,
    2.837680773301558,
    3.008207852190191,
    2.977254965088584,
    3.065799344669689,
    3.0860792940313164,
    3.1527709744193335,
    3.240079944783991,
    3.1946633729067715,
    3.361771746115251,
    3.341780510815707,
    3.4990520152178677,
    3.460304368625988,
    3.578889640894803
  ],
  "val_separation_ratio": [
    2.441513670815362,
    2.5900762610965304,
    2.7842123243543835,
    2.772641314400567,
    2.823524740007189,
    2.947530428568522,
    3.038327217102051,
    3.009361081653171,
    2.9919011063045926,
    3.0611271063486734,
    3.1542494032118054,
    3.1475992997487388,
    3.1901749769846597,
    3.1756109396616616,
    3.266943719651964,
    3.2487654156155057,
    3.231318235397339,
    3.3292206128438315,
    3.293278005388048
  ]
}