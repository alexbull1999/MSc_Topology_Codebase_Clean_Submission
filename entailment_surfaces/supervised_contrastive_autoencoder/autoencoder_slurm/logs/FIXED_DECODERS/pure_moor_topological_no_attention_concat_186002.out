Starting Surface Distance Metric Analysis job...
Job ID: 186002
Node: gpuvm17
Time: Thu 24 Jul 22:42:09 BST 2025
Loading CUDA...
Activating conda environment...
Activated conda environment: /vol/bitbucket/ahb24/tda_entailment_new
Python location: /vol/bitbucket/ahb24/tda_entailment_new/bin/python
Checking GPU availability...
Thu Jul 24 22:42:11 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.133.07             Driver Version: 570.133.07     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla T4                       Off |   00000000:00:06.0 Off |                    0 |
| N/A   34C    P8             13W /   70W |       0MiB /  15360MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+

Testing PyTorch and CUDA...
PyTorch version: 2.4.1
CUDA available: True
CUDA device: Tesla T4
GPU memory: 15.6 GB
PyTorch setup verified!

Starting Topological Training...

============================================================
TOPOLOGICAL AUTOENCODER TRAINING WITH TORCHPH
============================================================
Experiment setup completed:
  Experiment directory: entailment_surfaces/supervised_contrastive_autoencoder/experiments/pure_moor_topological_autoencoder_no_attention_20250724_224242
  Config saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/pure_moor_topological_autoencoder_no_attention_20250724_224242/config.json
Loading data...
========================================
FlexibleEmbedder initialized with type: 'concat'
Output dimension will be: 1536
GlobalDataLoader initialized:
  Embedding type: concat
  Output dimension: 1536
  Sample size: All
Starting data loading pipeline...
============================================================
Loading training data from data/processed/snli_full_standard_SBERT.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 549367 training samples
Loading validation data from data/processed/snli_full_standard_SBERT_validation.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9842 validation samples
Loading test data from data/processed/snli_full_standard_SBERT_test.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9824 test samples
Generating embeddings for training...
Generating concat embeddings on cuda
Processing 549367 samples in batches of 1000
  Processing batch 1/550
  Processing batch 6/550
  Processing batch 11/550
  Processing batch 16/550
  Processing batch 21/550
  Processing batch 26/550
  Processing batch 31/550
  Processing batch 36/550
  Processing batch 41/550
  Processing batch 46/550
  Processing batch 51/550
  Processing batch 56/550
  Processing batch 61/550
  Processing batch 66/550
  Processing batch 71/550
  Processing batch 76/550
  Processing batch 81/550
  Processing batch 86/550
  Processing batch 91/550
  Processing batch 96/550
  Processing batch 101/550
  Processing batch 106/550
  Processing batch 111/550
  Processing batch 116/550
  Processing batch 121/550
  Processing batch 126/550
  Processing batch 131/550
  Processing batch 136/550
  Processing batch 141/550
  Processing batch 146/550
  Processing batch 151/550
  Processing batch 156/550
  Processing batch 161/550
  Processing batch 166/550
  Processing batch 171/550
  Processing batch 176/550
  Processing batch 181/550
  Processing batch 186/550
  Processing batch 191/550
  Processing batch 196/550
  Processing batch 201/550
  Processing batch 206/550
  Processing batch 211/550
  Processing batch 216/550
  Processing batch 221/550
  Processing batch 226/550
  Processing batch 231/550
  Processing batch 236/550
  Processing batch 241/550
  Processing batch 246/550
  Processing batch 251/550
  Processing batch 256/550
  Processing batch 261/550
  Processing batch 266/550
  Processing batch 271/550
  Processing batch 276/550
  Processing batch 281/550
  Processing batch 286/550
  Processing batch 291/550
  Processing batch 296/550
  Processing batch 301/550
  Processing batch 306/550
  Processing batch 311/550
  Processing batch 316/550
  Processing batch 321/550
  Processing batch 326/550
  Processing batch 331/550
  Processing batch 336/550
  Processing batch 341/550
  Processing batch 346/550
  Processing batch 351/550
  Processing batch 356/550
  Processing batch 361/550
  Processing batch 366/550
  Processing batch 371/550
  Processing batch 376/550
  Processing batch 381/550
  Processing batch 386/550
  Processing batch 391/550
  Processing batch 396/550
  Processing batch 401/550
  Processing batch 406/550
  Processing batch 411/550
  Processing batch 416/550
  Processing batch 421/550
  Processing batch 426/550
  Processing batch 431/550
  Processing batch 436/550
  Processing batch 441/550
  Processing batch 446/550
  Processing batch 451/550
  Processing batch 456/550
  Processing batch 461/550
  Processing batch 466/550
  Processing batch 471/550
  Processing batch 476/550
  Processing batch 481/550
  Processing batch 486/550
  Processing batch 491/550
  Processing batch 496/550
  Processing batch 501/550
  Processing batch 506/550
  Processing batch 511/550
  Processing batch 516/550
  Processing batch 521/550
  Processing batch 526/550
  Processing batch 531/550
  Processing batch 536/550
  Processing batch 541/550
  Processing batch 546/550
Generated concat embeddings: torch.Size([549367, 1536])
Generating embeddings for validation...
Generating concat embeddings on cuda
Processing 9842 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9842, 1536])
Generating embeddings for test...
Generating concat embeddings on cuda
Processing 9824 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9824, 1536])
EntailmentDataset created: 549367 samples
  Embedding shape: torch.Size([549367, 1536])
  Class distribution: {'entailment': 183416, 'neutral': 182764, 'contradiction': 183187}
EntailmentDataset created: 9842 samples
  Embedding shape: torch.Size([9842, 1536])
  Class distribution: {'entailment': 3329, 'neutral': 3235, 'contradiction': 3278}
EntailmentDataset created: 9824 samples
  Embedding shape: torch.Size([9824, 1536])
  Class distribution: {'entailment': 3368, 'neutral': 3219, 'contradiction': 3237}

Data loading pipeline completed!
Output embedding dimension: 1536
Updated model input_dim to: 1536
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 537
  Class 2: 183187 samples
  Class 0: 183416 samples
  Class 1: 182764 samples
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 9
  Class 2: 3278 samples
  Class 0: 3329 samples
  Class 1: 3235 samples
DataLoaders created:
  Batch size: 1020
  Balanced sampling: True
  Train batches: 537
  Val batches: 9
  Test batches: 10
Data loading completed!
  Train: 549367 samples, 537 batches
  Val: 9842 samples, 9 batches
  Test: 9824 samples, 10 batches
ContrastiveAutoencoder initialized:
  Input dim: 1536
  Latent dim: 75
  Hidden dims: [1024, 768, 512, 256, 128]
  Dropout rate: 0.2
  Total parameters: 3,045,451
FullDatasetContrastiveLoss initialized:
  Margin: 2.0
  Update frequency: 3 epochs
  Max global samples: 5000
FullDatasetCombinedLoss initialized:
  Contrastive weight: 0.0
  Base reconstruction weight: 100.0
MoorTopologicalLoss Initialized: Using 0-dimensional persistence pairings (MST edges).
No prototypes being used for topological loss - whole dataset instead.
TopologicalTrainer initialized on device: cuda
Model parameters: 3,045,451
Enhanced with topological loss monitoring
Starting Phase 1: Pure Topological Training
  Contrastive weight: 0.0
  Topological weight: 1.0
  Reconstruction weight: 100.0

======================================================================
ğŸ§  TOPOLOGICAL AUTOENCODER TRAINING STARTED
======================================================================

============================================================
EPOCH 1 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=49.2619 (C:2.0000, R:0.0160, T:47.6593(w:1.000)âš ï¸)
Batch  25/537: Loss=12.2429 (C:5.2108, R:0.0682, T:5.4192(w:1.000)ğŸš€)
Batch  50/537: Loss=8.9490 (C:5.1170, R:0.0441, T:4.5414(w:1.000)ğŸš€)
Batch  75/537: Loss=7.1433 (C:5.0855, R:0.0321, T:3.9321(w:1.000)ğŸš€)
Batch 100/537: Loss=6.4554 (C:5.2116, R:0.0257, T:3.8830(w:1.000)ğŸš€)
Batch 125/537: Loss=5.8485 (C:5.2033, R:0.0211, T:3.7413(w:1.000)ğŸš€)
Batch 150/537: Loss=5.5859 (C:5.3133, R:0.0184, T:3.7498(w:1.000)ğŸš€)
Batch 175/537: Loss=5.0685 (C:5.3719, R:0.0164, T:3.4330(w:1.000)ğŸš€)
Batch 200/537: Loss=4.8365 (C:5.4259, R:0.0150, T:3.3347(w:1.000)ğŸš€)
Batch 225/537: Loss=4.7524 (C:5.3913, R:0.0140, T:3.3562(w:1.000)ğŸš€)
Batch 250/537: Loss=4.4954 (C:5.4155, R:0.0132, T:3.1724(w:1.000)ğŸš€)
Batch 275/537: Loss=4.4418 (C:5.4021, R:0.0125, T:3.1883(w:1.000)ğŸš€)
Batch 300/537: Loss=4.3651 (C:5.3838, R:0.0121, T:3.1517(w:1.000)ğŸš€)
Batch 325/537: Loss=4.2664 (C:5.2821, R:0.0116, T:3.1030(w:1.000)ğŸš€)
Batch 350/537: Loss=4.3419 (C:5.2087, R:0.0114, T:3.2051(w:1.000)ğŸš€)
Batch 375/537: Loss=4.3289 (C:5.3825, R:0.0113, T:3.1983(w:1.000)ğŸš€)
Batch 400/537: Loss=4.2504 (C:5.4111, R:0.0110, T:3.1456(w:1.000)ğŸš€)
Batch 425/537: Loss=4.1571 (C:5.4152, R:0.0109, T:3.0649(w:1.000)ğŸš€)
Batch 450/537: Loss=4.0839 (C:5.3400, R:0.0108, T:3.0047(w:1.000)ğŸš€)
Batch 475/537: Loss=4.0536 (C:5.2264, R:0.0107, T:2.9879(w:1.000)ğŸš€)
Batch 500/537: Loss=4.0594 (C:5.2701, R:0.0106, T:3.0029(w:1.000)ğŸš€)
Batch 525/537: Loss=3.8875 (C:5.3964, R:0.0105, T:2.8348(w:1.000)ğŸš€)
ğŸ‰ MILESTONE: First topological learning detected at epoch 1!
   Initial topological loss: 3.9845
ğŸ“ˆ New best topological loss: 3.9845

ğŸ“Š EPOCH 1 TRAINING SUMMARY:
  Total Loss: 5.9036
  Contrastive: 5.2369
  Reconstruction: 0.0192
  Topological: 3.9845 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 43.2409
  Contrastive: 1.9858
  Reconstruction: 0.0099
  Topological: 42.2542 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 1/300 COMPLETE (38.6s)
Train Loss: 5.9036 (C:5.2369, R:0.0192, T:3.9845)
Val Loss:   43.2409 (C:1.9858, R:0.0099, T:42.2542)
ğŸš€ Good topological learning progress
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 2 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=3.9443 (C:5.4501, R:0.0105, T:2.8897(w:1.000)ğŸš€)
Batch  25/537: Loss=3.9209 (C:5.4220, R:0.0104, T:2.8835(w:1.000)ğŸš€)
Batch  50/537: Loss=3.6690 (C:5.3810, R:0.0100, T:2.6698(w:1.000)ğŸš€)
Batch  75/537: Loss=3.5339 (C:5.5076, R:0.0100, T:2.5362(w:1.000)ğŸš€)
Batch 100/537: Loss=3.5319 (C:5.3838, R:0.0099, T:2.5467(w:1.000)ğŸš€)
Batch 125/537: Loss=3.4086 (C:5.5021, R:0.0098, T:2.4305(w:1.000)ğŸš€)
Batch 150/537: Loss=3.3757 (C:5.3849, R:0.0097, T:2.4028(w:1.000)ğŸš€)
Batch 175/537: Loss=3.2425 (C:5.3532, R:0.0095, T:2.2951(w:1.000)ğŸš€)
Batch 200/537: Loss=3.1572 (C:5.4892, R:0.0095, T:2.2118(w:1.000)ğŸš€)
Batch 225/537: Loss=3.3195 (C:5.7970, R:0.0095, T:2.3684(w:1.000)ğŸš€)
Batch 250/537: Loss=3.1494 (C:5.4196, R:0.0095, T:2.2026(w:1.000)ğŸš€)
Batch 275/537: Loss=3.0997 (C:5.3731, R:0.0094, T:2.1624(w:1.000)ğŸš€)
Batch 300/537: Loss=3.0870 (C:5.5745, R:0.0094, T:2.1428(w:1.000)ğŸš€)
Batch 325/537: Loss=3.0190 (C:5.4520, R:0.0094, T:2.0784(w:1.000)ğŸš€)
Batch 350/537: Loss=3.0923 (C:5.6445, R:0.0095, T:2.1465(w:1.000)ğŸš€)
Batch 375/537: Loss=3.0487 (C:5.4685, R:0.0094, T:2.1130(w:1.000)ğŸš€)
Batch 400/537: Loss=3.0826 (C:5.7528, R:0.0093, T:2.1485(w:1.000)ğŸš€)
Batch 425/537: Loss=2.9730 (C:5.6599, R:0.0093, T:2.0382(w:1.000)ğŸš€)
Batch 450/537: Loss=2.9490 (C:5.3723, R:0.0093, T:2.0212(w:1.000)ğŸš€)
Batch 475/537: Loss=2.8882 (C:5.5396, R:0.0093, T:1.9631(w:1.000)ğŸš€)
Batch 500/537: Loss=2.9579 (C:5.4097, R:0.0093, T:2.0284(w:1.000)ğŸš€)
Batch 525/537: Loss=2.8523 (C:5.6326, R:0.0093, T:1.9254(w:1.000)ğŸš€)
ğŸ“ˆ New best topological loss: 2.2534

ğŸ“Š EPOCH 2 TRAINING SUMMARY:
  Total Loss: 3.2105
  Contrastive: 5.4946
  Reconstruction: 0.0096
  Topological: 2.2534 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 35.0978
  Contrastive: 2.4834
  Reconstruction: 0.0090
  Topological: 34.2025 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 2/300 COMPLETE (40.2s)
Train Loss: 3.2105 (C:5.4946, R:0.0096, T:2.2534)
Val Loss:   35.0978 (C:2.4834, R:0.0090, T:34.2025)
ğŸš€ Good topological learning progress
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 3 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=2.8695 (C:5.5406, R:0.0093, T:1.9411(w:1.000)ğŸš€)
Batch  25/537: Loss=2.8856 (C:5.5505, R:0.0092, T:1.9643(w:1.000)ğŸš€)
Batch  50/537: Loss=2.8821 (C:5.5067, R:0.0092, T:1.9628(w:1.000)ğŸš€)
Batch  75/537: Loss=2.7749 (C:5.6330, R:0.0092, T:1.8596(w:1.000)ğŸš€)
Batch 100/537: Loss=2.8257 (C:5.7989, R:0.0091, T:1.9180(w:1.000)ğŸš€)
Batch 125/537: Loss=2.6907 (C:5.5109, R:0.0090, T:1.7896(w:1.000)ğŸš€)
Batch 150/537: Loss=2.7092 (C:5.6912, R:0.0090, T:1.8102(w:1.000)ğŸš€)
Batch 175/537: Loss=2.7825 (C:5.5978, R:0.0091, T:1.8738(w:1.000)ğŸš€)
Batch 200/537: Loss=2.5699 (C:5.6771, R:0.0090, T:1.6740(w:1.000)ğŸš€)
Batch 225/537: Loss=2.5577 (C:5.6134, R:0.0089, T:1.6715(w:1.000)ğŸš€)
Batch 250/537: Loss=2.5844 (C:5.5406, R:0.0089, T:1.6953(w:1.000)ğŸš€)
Batch 275/537: Loss=2.5862 (C:5.7205, R:0.0089, T:1.6965(w:1.000)ğŸš€)
Batch 300/537: Loss=2.5937 (C:5.4535, R:0.0089, T:1.7086(w:1.000)ğŸš€)
Batch 325/537: Loss=2.5364 (C:5.6049, R:0.0089, T:1.6500(w:1.000)ğŸš€)
Batch 350/537: Loss=2.5317 (C:5.6928, R:0.0088, T:1.6501(w:1.000)ğŸš€)
Batch 375/537: Loss=2.3964 (C:5.6364, R:0.0088, T:1.5177(w:1.000)ğŸš€)
Batch 400/537: Loss=2.4036 (C:5.5492, R:0.0088, T:1.5268(w:1.000)ğŸš€)
Batch 425/537: Loss=2.4611 (C:5.6908, R:0.0088, T:1.5838(w:1.000)ğŸš€)
Batch 450/537: Loss=2.4384 (C:5.4878, R:0.0087, T:1.5669(w:1.000)ğŸš€)
Batch 475/537: Loss=2.3893 (C:5.5578, R:0.0087, T:1.5193(w:1.000)ğŸš€)
Batch 500/537: Loss=2.2824 (C:5.6699, R:0.0087, T:1.4117(w:1.000)ğŸš€)
Batch 525/537: Loss=2.3889 (C:5.6175, R:0.0087, T:1.5153(w:1.000)ğŸš€)
ğŸ“ˆ New best topological loss: 1.6941

ğŸ“Š EPOCH 3 TRAINING SUMMARY:
  Total Loss: 2.5844
  Contrastive: 5.6076
  Reconstruction: 0.0089
  Topological: 1.6941 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 25.6701
  Contrastive: 3.0487
  Reconstruction: 0.0083
  Topological: 24.8383 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 3/300 COMPLETE (39.0s)
Train Loss: 2.5844 (C:5.6076, R:0.0089, T:1.6941)
Val Loss:   25.6701 (C:3.0487, R:0.0083, T:24.8383)
ğŸš€ Good topological learning progress
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 4 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=2.2750 (C:5.6996, R:0.0086, T:1.4130(w:1.000)ğŸš€)
Batch  25/537: Loss=2.3564 (C:5.7169, R:0.0086, T:1.4941(w:1.000)ğŸš€)
Batch  50/537: Loss=2.3615 (C:5.6384, R:0.0087, T:1.4964(w:1.000)ğŸš€)
Batch  75/537: Loss=2.2069 (C:5.7539, R:0.0086, T:1.3476(w:1.000)ğŸš€)
Batch 100/537: Loss=2.2653 (C:5.6098, R:0.0086, T:1.4035(w:1.000)ğŸš€)
Batch 125/537: Loss=2.3411 (C:5.6595, R:0.0086, T:1.4783(w:1.000)ğŸš€)
Batch 150/537: Loss=2.2676 (C:5.7650, R:0.0086, T:1.4052(w:1.000)ğŸš€)
Batch 175/537: Loss=2.2438 (C:5.6505, R:0.0086, T:1.3878(w:1.000)ğŸš€)
Batch 200/537: Loss=2.2587 (C:5.5325, R:0.0086, T:1.3995(w:1.000)ğŸš€)
Batch 225/537: Loss=2.2902 (C:5.7729, R:0.0086, T:1.4324(w:1.000)ğŸš€)
Batch 250/537: Loss=2.1861 (C:5.7080, R:0.0085, T:1.3328(w:1.000)ğŸš€)
Batch 275/537: Loss=2.1741 (C:5.7693, R:0.0084, T:1.3293(w:1.000)ğŸš€)
Batch 300/537: Loss=2.1486 (C:5.7821, R:0.0085, T:1.2986(w:1.000)ğŸš€)
Batch 325/537: Loss=2.2048 (C:5.7192, R:0.0085, T:1.3540(w:1.000)ğŸš€)
Batch 350/537: Loss=2.2368 (C:5.9164, R:0.0084, T:1.3924(w:1.000)ğŸš€)
Batch 375/537: Loss=2.1476 (C:5.7170, R:0.0085, T:1.3012(w:1.000)ğŸš€)
Batch 400/537: Loss=2.0898 (C:5.7444, R:0.0084, T:1.2508(w:1.000)ğŸš€)
Batch 425/537: Loss=2.1132 (C:5.7443, R:0.0083, T:1.2784(w:1.000)ğŸš€)
Batch 450/537: Loss=2.0594 (C:5.8451, R:0.0084, T:1.2218(w:1.000)ğŸš€)
Batch 475/537: Loss=2.0523 (C:5.6769, R:0.0084, T:1.2157(w:1.000)ğŸš€)
Batch 500/537: Loss=2.0950 (C:5.6684, R:0.0084, T:1.2542(w:1.000)ğŸš€)
Batch 525/537: Loss=2.0780 (C:5.7224, R:0.0084, T:1.2402(w:1.000)ğŸš€)
ğŸ“ˆ New best topological loss: 1.3481

ğŸ“Š EPOCH 4 TRAINING SUMMARY:
  Total Loss: 2.1991
  Contrastive: 5.6953
  Reconstruction: 0.0085
  Topological: 1.3481 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 21.0479
  Contrastive: 3.3509
  Reconstruction: 0.0079
  Topological: 20.2536 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 4/300 COMPLETE (39.4s)
Train Loss: 2.1991 (C:5.6953, R:0.0085, T:1.3481)
Val Loss:   21.0479 (C:3.3509, R:0.0079, T:20.2536)
ğŸš€ Good topological learning progress
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 5 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=2.0190 (C:5.7181, R:0.0084, T:1.1792(w:1.000)ğŸš€)
Batch  25/537: Loss=1.9924 (C:5.7573, R:0.0083, T:1.1649(w:1.000)ğŸš€)
Batch  50/537: Loss=2.0458 (C:5.6430, R:0.0084, T:1.2100(w:1.000)ğŸš€)
Batch  75/537: Loss=2.1486 (C:5.8133, R:0.0084, T:1.3134(w:1.000)ğŸš€)
Batch 100/537: Loss=2.0653 (C:5.5364, R:0.0083, T:1.2371(w:1.000)ğŸš€)
Batch 125/537: Loss=1.9847 (C:5.7865, R:0.0084, T:1.1484(w:1.000)ğŸš€)
Batch 150/537: Loss=2.0300 (C:5.6889, R:0.0083, T:1.2017(w:1.000)ğŸš€)
Batch 175/537: Loss=1.9947 (C:5.5946, R:0.0082, T:1.1730(w:1.000)ğŸš€)
Batch 200/537: Loss=1.9410 (C:5.7514, R:0.0082, T:1.1197(w:1.000)ğŸš€)
Batch 225/537: Loss=2.0164 (C:5.6698, R:0.0082, T:1.1936(w:1.000)ğŸš€)
Batch 250/537: Loss=2.0052 (C:5.7219, R:0.0082, T:1.1859(w:1.000)ğŸš€)
Batch 275/537: Loss=1.9763 (C:5.7523, R:0.0082, T:1.1544(w:1.000)ğŸš€)
Batch 300/537: Loss=1.9559 (C:5.7264, R:0.0082, T:1.1366(w:1.000)ğŸš€)
Batch 325/537: Loss=1.9079 (C:5.6440, R:0.0082, T:1.0905(w:1.000)ğŸš€)
Batch 350/537: Loss=1.9789 (C:5.7312, R:0.0082, T:1.1607(w:1.000)ğŸš€)
Batch 375/537: Loss=1.9020 (C:5.7917, R:0.0081, T:1.0887(w:1.000)ğŸš€)
Batch 400/537: Loss=1.9303 (C:5.8843, R:0.0081, T:1.1161(w:1.000)ğŸš€)
Batch 425/537: Loss=1.8363 (C:5.7683, R:0.0080, T:1.0331(w:1.000)ğŸš€)
Batch 450/537: Loss=1.8822 (C:5.7330, R:0.0081, T:1.0697(w:1.000)ğŸš€)
Batch 475/537: Loss=1.9281 (C:5.7972, R:0.0082, T:1.1121(w:1.000)ğŸš€)
Batch 500/537: Loss=1.8323 (C:5.7280, R:0.0080, T:1.0301(w:1.000)ğŸš€)
Batch 525/537: Loss=1.8950 (C:5.7819, R:0.0081, T:1.0875(w:1.000)ğŸš€)
ğŸ“ˆ New best topological loss: 1.1424

ğŸ“Š EPOCH 5 TRAINING SUMMARY:
  Total Loss: 1.9628
  Contrastive: 5.7359
  Reconstruction: 0.0082
  Topological: 1.1424 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 16.3839
  Contrastive: 3.6890
  Reconstruction: 0.0076
  Topological: 15.6262 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 5/300 COMPLETE (38.9s)
Train Loss: 1.9628 (C:5.7359, R:0.0082, T:1.1424)
Val Loss:   16.3839 (C:3.6890, R:0.0076, T:15.6262)
ğŸš€ Good topological learning progress
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 6 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.8834 (C:5.7893, R:0.0081, T:1.0727(w:1.000)ğŸš€)
Batch  25/537: Loss=1.9093 (C:5.7750, R:0.0081, T:1.1013(w:1.000)ğŸš€)
Batch  50/537: Loss=1.8480 (C:5.7200, R:0.0080, T:1.0443(w:1.000)ğŸš€)
Batch  75/537: Loss=1.8330 (C:5.8323, R:0.0081, T:1.0252(w:1.000)ğŸš€)
Batch 100/537: Loss=1.8082 (C:5.7859, R:0.0080, T:1.0042(w:1.000)ğŸš€)
Batch 125/537: Loss=1.8629 (C:5.7633, R:0.0081, T:1.0517(w:1.000)ğŸš€)
Batch 150/537: Loss=1.8125 (C:5.7956, R:0.0080, T:1.0146(w:1.000)ğŸš€)
Batch 175/537: Loss=1.8094 (C:5.7774, R:0.0080, T:1.0099(w:1.000)ğŸš€)
Batch 200/537: Loss=1.8559 (C:5.6851, R:0.0080, T:1.0556(w:1.000)ğŸš€)
Batch 225/537: Loss=1.8412 (C:5.6784, R:0.0079, T:1.0472(w:1.000)ğŸš€)
Batch 250/537: Loss=1.8055 (C:5.8066, R:0.0080, T:1.0089(w:1.000)ğŸš€)
Batch 275/537: Loss=1.8404 (C:5.9068, R:0.0079, T:1.0459(w:1.000)ğŸš€)
Batch 300/537: Loss=1.7593 (C:5.7716, R:0.0079, T:0.9645(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.7848 (C:5.8326, R:0.0079, T:0.9910(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.7647 (C:5.8249, R:0.0081, T:0.9558(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.7741 (C:5.7284, R:0.0079, T:0.9803(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.7305 (C:5.7939, R:0.0079, T:0.9400(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.7400 (C:5.7449, R:0.0079, T:0.9481(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.7231 (C:5.8432, R:0.0079, T:0.9295(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.7528 (C:5.7710, R:0.0078, T:0.9705(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.7165 (C:5.7296, R:0.0080, T:0.9195(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.7421 (C:5.7709, R:0.0079, T:0.9489(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.9954

ğŸ“Š EPOCH 6 TRAINING SUMMARY:
  Total Loss: 1.7931
  Contrastive: 5.7672
  Reconstruction: 0.0080
  Topological: 0.9954 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 14.0553
  Contrastive: 3.8997
  Reconstruction: 0.0074
  Topological: 13.3159 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 6/300 COMPLETE (38.0s)
Train Loss: 1.7931 (C:5.7672, R:0.0080, T:0.9954)
Val Loss:   14.0553 (C:3.8997, R:0.0074, T:13.3159)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 7 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.7091 (C:5.8459, R:0.0080, T:0.9130(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.7106 (C:5.7465, R:0.0079, T:0.9187(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.7064 (C:5.7674, R:0.0078, T:0.9241(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.7745 (C:5.9323, R:0.0079, T:0.9841(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.7080 (C:5.8327, R:0.0079, T:0.9144(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.7587 (C:5.7648, R:0.0079, T:0.9697(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.6981 (C:5.7674, R:0.0078, T:0.9132(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.6687 (C:5.8059, R:0.0078, T:0.8864(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.6867 (C:5.8204, R:0.0079, T:0.8943(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.7392 (C:5.8901, R:0.0079, T:0.9515(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.6880 (C:5.7301, R:0.0079, T:0.9008(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.7137 (C:5.7860, R:0.0078, T:0.9320(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.6781 (C:5.6998, R:0.0079, T:0.8931(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.6911 (C:5.7360, R:0.0079, T:0.9038(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.6315 (C:5.8112, R:0.0078, T:0.8505(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.7092 (C:5.7071, R:0.0079, T:0.9226(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.6475 (C:5.8522, R:0.0078, T:0.8671(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.6706 (C:5.7843, R:0.0079, T:0.8838(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.6701 (C:5.7180, R:0.0078, T:0.8873(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.6514 (C:5.8383, R:0.0077, T:0.8769(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.6287 (C:5.7262, R:0.0078, T:0.8527(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.6251 (C:5.7437, R:0.0078, T:0.8453(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.9026

ğŸ“Š EPOCH 7 TRAINING SUMMARY:
  Total Loss: 1.6873
  Contrastive: 5.7838
  Reconstruction: 0.0078
  Topological: 0.9026 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 12.5232
  Contrastive: 4.0105
  Reconstruction: 0.0072
  Topological: 11.7993 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 7/300 COMPLETE (37.8s)
Train Loss: 1.6873 (C:5.7838, R:0.0078, T:0.9026)
Val Loss:   12.5232 (C:4.0105, R:0.0072, T:11.7993)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 8 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.6279 (C:5.8110, R:0.0078, T:0.8527(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.6362 (C:5.8277, R:0.0078, T:0.8611(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.6629 (C:5.8034, R:0.0078, T:0.8816(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.6208 (C:5.8201, R:0.0078, T:0.8407(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.6103 (C:5.8436, R:0.0077, T:0.8386(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.6929 (C:5.7095, R:0.0078, T:0.9146(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.6048 (C:5.7561, R:0.0077, T:0.8319(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.5920 (C:5.7585, R:0.0077, T:0.8212(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.6190 (C:5.8415, R:0.0077, T:0.8489(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.6125 (C:5.7912, R:0.0077, T:0.8412(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.6646 (C:5.7640, R:0.0077, T:0.8910(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.6793 (C:5.7580, R:0.0078, T:0.9018(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.6134 (C:5.8120, R:0.0077, T:0.8400(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.6260 (C:5.8549, R:0.0077, T:0.8569(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.6073 (C:5.7558, R:0.0077, T:0.8363(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.6115 (C:5.8434, R:0.0077, T:0.8416(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.6229 (C:5.8064, R:0.0077, T:0.8494(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.6025 (C:5.7966, R:0.0077, T:0.8288(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.5800 (C:5.8381, R:0.0077, T:0.8064(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.5929 (C:5.7463, R:0.0077, T:0.8245(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.5749 (C:5.8566, R:0.0076, T:0.8105(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.5155 (C:5.7904, R:0.0077, T:0.7479(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.8350

ğŸ“Š EPOCH 8 TRAINING SUMMARY:
  Total Loss: 1.6071
  Contrastive: 5.7962
  Reconstruction: 0.0077
  Topological: 0.8350 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 11.3247
  Contrastive: 4.0915
  Reconstruction: 0.0071
  Topological: 10.6142 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 8/300 COMPLETE (37.8s)
Train Loss: 1.6071 (C:5.7962, R:0.0077, T:0.8350)
Val Loss:   11.3247 (C:4.0915, R:0.0071, T:10.6142)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 9 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.5653 (C:5.8237, R:0.0076, T:0.8073(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.5530 (C:5.8200, R:0.0077, T:0.7871(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.5353 (C:5.7890, R:0.0077, T:0.7695(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.5635 (C:5.7485, R:0.0076, T:0.7991(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.5405 (C:5.7444, R:0.0076, T:0.7791(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.5931 (C:5.8033, R:0.0077, T:0.8279(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.5981 (C:5.7914, R:0.0077, T:0.8317(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.6048 (C:5.8351, R:0.0077, T:0.8331(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.5486 (C:5.8492, R:0.0076, T:0.7846(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.5368 (C:5.7691, R:0.0076, T:0.7738(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.5200 (C:5.7989, R:0.0076, T:0.7594(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.5198 (C:5.7826, R:0.0076, T:0.7619(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.5065 (C:5.7838, R:0.0076, T:0.7435(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.5335 (C:5.8368, R:0.0076, T:0.7711(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.5577 (C:5.7455, R:0.0076, T:0.7954(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.5377 (C:5.7663, R:0.0076, T:0.7793(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.5140 (C:5.8091, R:0.0076, T:0.7519(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.5099 (C:5.8548, R:0.0075, T:0.7570(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.5320 (C:5.8137, R:0.0075, T:0.7790(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.5456 (C:5.8524, R:0.0076, T:0.7852(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.5563 (C:5.8525, R:0.0076, T:0.7980(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.5088 (C:5.8465, R:0.0076, T:0.7517(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.7868

ğŸ“Š EPOCH 9 TRAINING SUMMARY:
  Total Loss: 1.5489
  Contrastive: 5.7951
  Reconstruction: 0.0076
  Topological: 0.7868 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 10.4666
  Contrastive: 4.1617
  Reconstruction: 0.0070
  Topological: 9.7686 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 9/300 COMPLETE (38.4s)
Train Loss: 1.5489 (C:5.7951, R:0.0076, T:0.7868)
Val Loss:   10.4666 (C:4.1617, R:0.0070, T:9.7686)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 10 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.5489 (C:5.8822, R:0.0076, T:0.7903(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.5657 (C:5.8190, R:0.0076, T:0.8013(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.5135 (C:5.8029, R:0.0076, T:0.7572(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.5072 (C:5.8021, R:0.0076, T:0.7521(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.4988 (C:5.7899, R:0.0076, T:0.7415(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.5241 (C:5.7631, R:0.0076, T:0.7654(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.5254 (C:5.7575, R:0.0076, T:0.7656(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.5083 (C:5.7794, R:0.0075, T:0.7585(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.5487 (C:5.8345, R:0.0076, T:0.7921(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.4870 (C:5.7814, R:0.0075, T:0.7356(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.5210 (C:5.8222, R:0.0076, T:0.7655(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.5112 (C:5.8343, R:0.0075, T:0.7612(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.5144 (C:5.7899, R:0.0075, T:0.7638(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.5206 (C:5.8102, R:0.0076, T:0.7620(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.5047 (C:5.8453, R:0.0076, T:0.7430(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.4857 (C:5.7903, R:0.0075, T:0.7342(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.4505 (C:5.7856, R:0.0075, T:0.7033(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.4903 (C:5.7855, R:0.0075, T:0.7382(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.4798 (C:5.8292, R:0.0075, T:0.7297(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.5037 (C:5.7959, R:0.0075, T:0.7514(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.4725 (C:5.7830, R:0.0075, T:0.7210(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.5624 (C:5.7766, R:0.0075, T:0.8101(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.7476

ğŸ“Š EPOCH 10 TRAINING SUMMARY:
  Total Loss: 1.5013
  Contrastive: 5.7980
  Reconstruction: 0.0075
  Topological: 0.7476 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 9.8473
  Contrastive: 4.1979
  Reconstruction: 0.0069
  Topological: 9.1582 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 10/300 COMPLETE (38.5s)
Train Loss: 1.5013 (C:5.7980, R:0.0075, T:0.7476)
Val Loss:   9.8473 (C:4.1979, R:0.0069, T:9.1582)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 11 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.5268 (C:5.7832, R:0.0075, T:0.7737(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.5135 (C:5.7936, R:0.0075, T:0.7664(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.4468 (C:5.7881, R:0.0074, T:0.7027(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.4839 (C:5.7830, R:0.0075, T:0.7351(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.4203 (C:5.7885, R:0.0075, T:0.6699(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.4755 (C:5.8128, R:0.0075, T:0.7286(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.4900 (C:5.8408, R:0.0075, T:0.7424(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.4397 (C:5.8214, R:0.0074, T:0.6957(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.4787 (C:5.7681, R:0.0075, T:0.7327(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.4393 (C:5.8464, R:0.0075, T:0.6932(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.4660 (C:5.7982, R:0.0075, T:0.7138(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.5191 (C:5.8273, R:0.0075, T:0.7693(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.4899 (C:5.7710, R:0.0075, T:0.7404(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.4587 (C:5.7681, R:0.0074, T:0.7167(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.4937 (C:5.7924, R:0.0074, T:0.7493(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.5197 (C:5.7750, R:0.0076, T:0.7635(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.4080 (C:5.7759, R:0.0074, T:0.6694(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.4368 (C:5.8158, R:0.0074, T:0.6967(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.4770 (C:5.8023, R:0.0075, T:0.7285(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.4713 (C:5.8253, R:0.0075, T:0.7241(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.4726 (C:5.8051, R:0.0075, T:0.7267(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.4773 (C:5.8228, R:0.0075, T:0.7245(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.7224

ğŸ“Š EPOCH 11 TRAINING SUMMARY:
  Total Loss: 1.4696
  Contrastive: 5.7975
  Reconstruction: 0.0075
  Topological: 0.7224 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 8.8279
  Contrastive: 4.3276
  Reconstruction: 0.0068
  Topological: 8.1478 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 11/300 COMPLETE (37.7s)
Train Loss: 1.4696 (C:5.7975, R:0.0075, T:0.7224)
Val Loss:   8.8279 (C:4.3276, R:0.0068, T:8.1478)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 12 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.4391 (C:5.8530, R:0.0074, T:0.6952(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.4647 (C:5.7748, R:0.0074, T:0.7206(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.4821 (C:5.8161, R:0.0074, T:0.7408(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.4677 (C:5.7957, R:0.0074, T:0.7244(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.4452 (C:5.7724, R:0.0074, T:0.7040(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.4449 (C:5.7532, R:0.0074, T:0.7024(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.4725 (C:5.8050, R:0.0074, T:0.7345(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.4630 (C:5.8310, R:0.0075, T:0.7168(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.4165 (C:5.7915, R:0.0074, T:0.6734(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.4667 (C:5.7639, R:0.0074, T:0.7274(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.4715 (C:5.7797, R:0.0074, T:0.7286(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.4679 (C:5.8039, R:0.0074, T:0.7259(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.4315 (C:5.7925, R:0.0074, T:0.6938(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.4679 (C:5.8597, R:0.0074, T:0.7248(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.4118 (C:5.7814, R:0.0074, T:0.6749(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.4841 (C:5.7895, R:0.0074, T:0.7439(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.4326 (C:5.7978, R:0.0075, T:0.6872(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.4527 (C:5.8231, R:0.0075, T:0.7061(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.4444 (C:5.7935, R:0.0074, T:0.7038(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.4436 (C:5.8153, R:0.0074, T:0.7036(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.4267 (C:5.8097, R:0.0074, T:0.6897(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.3966 (C:5.8159, R:0.0074, T:0.6582(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.7065

ğŸ“Š EPOCH 12 TRAINING SUMMARY:
  Total Loss: 1.4481
  Contrastive: 5.7973
  Reconstruction: 0.0074
  Topological: 0.7065 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 8.4170
  Contrastive: 4.3489
  Reconstruction: 0.0067
  Topological: 7.7451 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 12/300 COMPLETE (39.2s)
Train Loss: 1.4481 (C:5.7973, R:0.0074, T:0.7065)
Val Loss:   8.4170 (C:4.3489, R:0.0067, T:7.7451)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 13 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.4160 (C:5.8231, R:0.0073, T:0.6811(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.4230 (C:5.8258, R:0.0073, T:0.6883(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.4303 (C:5.8211, R:0.0074, T:0.6946(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.4400 (C:5.7552, R:0.0074, T:0.7028(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.4031 (C:5.8510, R:0.0073, T:0.6714(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.4227 (C:5.7693, R:0.0074, T:0.6872(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.4262 (C:5.7967, R:0.0074, T:0.6865(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.4233 (C:5.8093, R:0.0074, T:0.6859(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.4499 (C:5.8031, R:0.0074, T:0.7090(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.4385 (C:5.7673, R:0.0074, T:0.7025(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.4472 (C:5.7481, R:0.0074, T:0.7086(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.4303 (C:5.8432, R:0.0074, T:0.6952(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.3996 (C:5.7490, R:0.0074, T:0.6638(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.4105 (C:5.8030, R:0.0074, T:0.6684(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.4299 (C:5.7869, R:0.0074, T:0.6910(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.4105 (C:5.7877, R:0.0074, T:0.6716(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.4177 (C:5.7496, R:0.0074, T:0.6825(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.4322 (C:5.8456, R:0.0074, T:0.6946(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.4323 (C:5.7690, R:0.0073, T:0.6983(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.4238 (C:5.7741, R:0.0074, T:0.6875(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.4122 (C:5.8383, R:0.0073, T:0.6802(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.4320 (C:5.7544, R:0.0073, T:0.7001(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6896

ğŸ“Š EPOCH 13 TRAINING SUMMARY:
  Total Loss: 1.4264
  Contrastive: 5.7944
  Reconstruction: 0.0074
  Topological: 0.6896 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 8.0726
  Contrastive: 4.3508
  Reconstruction: 0.0067
  Topological: 7.4058 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 13/300 COMPLETE (39.7s)
Train Loss: 1.4264 (C:5.7944, R:0.0074, T:0.6896)
Val Loss:   8.0726 (C:4.3508, R:0.0067, T:7.4058)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 14 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.3800 (C:5.7645, R:0.0073, T:0.6490(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.4434 (C:5.7869, R:0.0074, T:0.7062(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.4291 (C:5.7961, R:0.0073, T:0.6941(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.4088 (C:5.7439, R:0.0074, T:0.6715(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.4091 (C:5.8211, R:0.0073, T:0.6789(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.4031 (C:5.7764, R:0.0074, T:0.6674(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.3765 (C:5.7953, R:0.0073, T:0.6470(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.3903 (C:5.7729, R:0.0074, T:0.6550(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.3968 (C:5.7734, R:0.0073, T:0.6628(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.3945 (C:5.7690, R:0.0073, T:0.6602(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.4149 (C:5.7644, R:0.0073, T:0.6819(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.4327 (C:5.7840, R:0.0073, T:0.7006(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.4144 (C:5.7660, R:0.0073, T:0.6830(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.4685 (C:5.8006, R:0.0074, T:0.7282(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.4471 (C:5.7803, R:0.0074, T:0.7102(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.3813 (C:5.7833, R:0.0073, T:0.6486(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.4032 (C:5.7878, R:0.0074, T:0.6673(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.4142 (C:5.7528, R:0.0074, T:0.6783(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.4184 (C:5.7950, R:0.0074, T:0.6811(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.3872 (C:5.7461, R:0.0073, T:0.6559(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.3790 (C:5.7829, R:0.0073, T:0.6516(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.4271 (C:5.8186, R:0.0073, T:0.6923(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6778

ğŸ“Š EPOCH 14 TRAINING SUMMARY:
  Total Loss: 1.4113
  Contrastive: 5.7923
  Reconstruction: 0.0073
  Topological: 0.6778 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 7.7588
  Contrastive: 4.4042
  Reconstruction: 0.0066
  Topological: 7.0957 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 14/300 COMPLETE (37.9s)
Train Loss: 1.4113 (C:5.7923, R:0.0073, T:0.6778)
Val Loss:   7.7588 (C:4.4042, R:0.0066, T:7.0957)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 15 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.4008 (C:5.7776, R:0.0073, T:0.6678(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.4475 (C:5.8441, R:0.0074, T:0.7094(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.4164 (C:5.8109, R:0.0073, T:0.6874(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.4165 (C:5.7975, R:0.0073, T:0.6858(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.3883 (C:5.8297, R:0.0073, T:0.6550(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.3785 (C:5.7879, R:0.0073, T:0.6513(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.3863 (C:5.7768, R:0.0074, T:0.6493(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.4137 (C:5.7809, R:0.0074, T:0.6767(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.3605 (C:5.7677, R:0.0073, T:0.6310(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.3741 (C:5.8084, R:0.0073, T:0.6420(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.4194 (C:5.7389, R:0.0073, T:0.6895(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.4281 (C:5.8327, R:0.0073, T:0.6974(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.4046 (C:5.8301, R:0.0074, T:0.6681(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.4211 (C:5.8302, R:0.0074, T:0.6849(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.3832 (C:5.7781, R:0.0073, T:0.6564(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.4000 (C:5.7383, R:0.0073, T:0.6662(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.3895 (C:5.7713, R:0.0073, T:0.6620(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.3786 (C:5.8044, R:0.0073, T:0.6467(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.4659 (C:5.7931, R:0.0074, T:0.7302(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.4261 (C:5.7857, R:0.0073, T:0.6921(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.3892 (C:5.7741, R:0.0073, T:0.6575(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.3641 (C:5.7932, R:0.0073, T:0.6385(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6684

ğŸ“Š EPOCH 15 TRAINING SUMMARY:
  Total Loss: 1.3993
  Contrastive: 5.7881
  Reconstruction: 0.0073
  Topological: 0.6684 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 7.4057
  Contrastive: 4.4593
  Reconstruction: 0.0066
  Topological: 6.7466 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 15/300 COMPLETE (39.0s)
Train Loss: 1.3993 (C:5.7881, R:0.0073, T:0.6684)
Val Loss:   7.4057 (C:4.4593, R:0.0066, T:6.7466)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 16 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.3865 (C:5.7865, R:0.0073, T:0.6540(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.3961 (C:5.7882, R:0.0073, T:0.6657(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.3834 (C:5.7973, R:0.0073, T:0.6532(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.3769 (C:5.7700, R:0.0073, T:0.6498(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.3625 (C:5.8138, R:0.0073, T:0.6327(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.3649 (C:5.7558, R:0.0073, T:0.6315(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.3755 (C:5.7726, R:0.0073, T:0.6473(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.3788 (C:5.7970, R:0.0073, T:0.6461(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.3837 (C:5.7461, R:0.0073, T:0.6579(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.3706 (C:5.8471, R:0.0073, T:0.6376(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.3635 (C:5.8198, R:0.0073, T:0.6309(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.3798 (C:5.7891, R:0.0073, T:0.6483(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.3578 (C:5.7643, R:0.0072, T:0.6347(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.3754 (C:5.7874, R:0.0073, T:0.6504(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.3836 (C:5.7835, R:0.0073, T:0.6544(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.4234 (C:5.8194, R:0.0073, T:0.6932(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.3744 (C:5.7823, R:0.0072, T:0.6510(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.3339 (C:5.7718, R:0.0073, T:0.6042(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.4143 (C:5.7906, R:0.0073, T:0.6815(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.4072 (C:5.7898, R:0.0073, T:0.6791(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.4120 (C:5.7761, R:0.0073, T:0.6795(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.4015 (C:5.7882, R:0.0073, T:0.6682(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6599

ğŸ“Š EPOCH 16 TRAINING SUMMARY:
  Total Loss: 1.3888
  Contrastive: 5.7864
  Reconstruction: 0.0073
  Topological: 0.6599 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 7.2968
  Contrastive: 4.4350
  Reconstruction: 0.0066
  Topological: 6.6402 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 16/300 COMPLETE (39.7s)
Train Loss: 1.3888 (C:5.7864, R:0.0073, T:0.6599)
Val Loss:   7.2968 (C:4.4350, R:0.0066, T:6.6402)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 17 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.4151 (C:5.7354, R:0.0073, T:0.6857(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.4166 (C:5.8053, R:0.0073, T:0.6878(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.3548 (C:5.7682, R:0.0072, T:0.6299(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.4061 (C:5.7747, R:0.0073, T:0.6735(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.3640 (C:5.7767, R:0.0072, T:0.6392(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.4076 (C:5.8256, R:0.0073, T:0.6809(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.3550 (C:5.7716, R:0.0072, T:0.6305(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.3962 (C:5.7885, R:0.0073, T:0.6657(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.3858 (C:5.7875, R:0.0073, T:0.6568(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.3880 (C:5.8211, R:0.0072, T:0.6648(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.3968 (C:5.7788, R:0.0073, T:0.6650(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.4304 (C:5.8188, R:0.0073, T:0.6977(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.3925 (C:5.7957, R:0.0073, T:0.6638(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.3813 (C:5.7697, R:0.0072, T:0.6574(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.3648 (C:5.7667, R:0.0072, T:0.6471(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.3770 (C:5.7821, R:0.0072, T:0.6533(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.3655 (C:5.7611, R:0.0072, T:0.6431(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.3847 (C:5.8668, R:0.0073, T:0.6530(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.3825 (C:5.7378, R:0.0072, T:0.6618(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.3983 (C:5.8289, R:0.0073, T:0.6705(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.3980 (C:5.7392, R:0.0072, T:0.6783(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.3694 (C:5.7869, R:0.0073, T:0.6436(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6549

ğŸ“Š EPOCH 17 TRAINING SUMMARY:
  Total Loss: 1.3820
  Contrastive: 5.7823
  Reconstruction: 0.0073
  Topological: 0.6549 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 7.1726
  Contrastive: 4.4448
  Reconstruction: 0.0065
  Topological: 6.5178 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 17/300 COMPLETE (40.0s)
Train Loss: 1.3820 (C:5.7823, R:0.0073, T:0.6549)
Val Loss:   7.1726 (C:4.4448, R:0.0065, T:6.5178)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 18 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.3846 (C:5.7446, R:0.0072, T:0.6609(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.3895 (C:5.7966, R:0.0073, T:0.6630(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.3540 (C:5.7562, R:0.0073, T:0.6266(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.3631 (C:5.7275, R:0.0072, T:0.6396(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.3488 (C:5.7297, R:0.0073, T:0.6233(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.3542 (C:5.8016, R:0.0073, T:0.6250(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.4006 (C:5.7473, R:0.0073, T:0.6720(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.4005 (C:5.7729, R:0.0073, T:0.6686(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.3608 (C:5.7667, R:0.0073, T:0.6357(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.3805 (C:5.7944, R:0.0073, T:0.6484(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.3916 (C:5.7885, R:0.0072, T:0.6695(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.3634 (C:5.7593, R:0.0073, T:0.6371(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.3355 (C:5.7191, R:0.0072, T:0.6141(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.3539 (C:5.7892, R:0.0072, T:0.6305(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.3804 (C:5.8061, R:0.0073, T:0.6537(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.3701 (C:5.7431, R:0.0072, T:0.6484(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.3769 (C:5.7811, R:0.0073, T:0.6512(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.3885 (C:5.7355, R:0.0073, T:0.6608(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.3689 (C:5.7755, R:0.0073, T:0.6396(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.3634 (C:5.7526, R:0.0072, T:0.6394(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.3734 (C:5.7542, R:0.0072, T:0.6497(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.3649 (C:5.8390, R:0.0073, T:0.6356(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6465

ğŸ“Š EPOCH 18 TRAINING SUMMARY:
  Total Loss: 1.3721
  Contrastive: 5.7790
  Reconstruction: 0.0073
  Topological: 0.6465 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 7.1768
  Contrastive: 4.4231
  Reconstruction: 0.0065
  Topological: 6.5225 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 18/300 COMPLETE (39.0s)
Train Loss: 1.3721 (C:5.7790, R:0.0073, T:0.6465)
Val Loss:   7.1768 (C:4.4231, R:0.0065, T:6.5225)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 19 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.3386 (C:5.7182, R:0.0072, T:0.6163(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.3662 (C:5.8172, R:0.0072, T:0.6418(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.3350 (C:5.7659, R:0.0072, T:0.6123(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.3360 (C:5.8051, R:0.0072, T:0.6125(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.3559 (C:5.7419, R:0.0072, T:0.6355(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.3754 (C:5.7211, R:0.0073, T:0.6471(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.3480 (C:5.7309, R:0.0072, T:0.6260(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.3653 (C:5.7736, R:0.0072, T:0.6436(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.3507 (C:5.7585, R:0.0072, T:0.6262(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.3502 (C:5.7765, R:0.0072, T:0.6259(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.3435 (C:5.8334, R:0.0073, T:0.6163(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.3581 (C:5.7593, R:0.0072, T:0.6333(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.3216 (C:5.7449, R:0.0073, T:0.5958(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.3377 (C:5.7719, R:0.0072, T:0.6184(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.3505 (C:5.7604, R:0.0072, T:0.6314(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.3846 (C:5.7813, R:0.0073, T:0.6552(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.3680 (C:5.7547, R:0.0073, T:0.6388(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.3342 (C:5.8340, R:0.0072, T:0.6126(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.3693 (C:5.7631, R:0.0072, T:0.6465(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.3522 (C:5.7494, R:0.0072, T:0.6303(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.3866 (C:5.7195, R:0.0072, T:0.6618(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.3913 (C:5.7944, R:0.0073, T:0.6577(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6394

ğŸ“Š EPOCH 19 TRAINING SUMMARY:
  Total Loss: 1.3637
  Contrastive: 5.7788
  Reconstruction: 0.0072
  Topological: 0.6394 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.9397
  Contrastive: 4.4592
  Reconstruction: 0.0065
  Topological: 6.2869 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 19/300 COMPLETE (41.0s)
Train Loss: 1.3637 (C:5.7788, R:0.0072, T:0.6394)
Val Loss:   6.9397 (C:4.4592, R:0.0065, T:6.2869)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 20 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.3805 (C:5.7440, R:0.0073, T:0.6553(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.3511 (C:5.7508, R:0.0072, T:0.6275(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.3379 (C:5.8172, R:0.0073, T:0.6125(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.3591 (C:5.7683, R:0.0073, T:0.6322(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.3744 (C:5.7916, R:0.0073, T:0.6448(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.3129 (C:5.7549, R:0.0072, T:0.5923(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.3822 (C:5.8178, R:0.0072, T:0.6630(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.3712 (C:5.8177, R:0.0073, T:0.6391(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.3178 (C:5.7797, R:0.0072, T:0.5945(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.3170 (C:5.7382, R:0.0072, T:0.5993(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.3623 (C:5.7505, R:0.0072, T:0.6412(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.4014 (C:5.7682, R:0.0073, T:0.6749(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.3447 (C:5.8050, R:0.0072, T:0.6205(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.3619 (C:5.7638, R:0.0072, T:0.6378(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.3263 (C:5.8000, R:0.0072, T:0.6021(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.3233 (C:5.8236, R:0.0072, T:0.6069(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.3599 (C:5.8269, R:0.0073, T:0.6317(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.3864 (C:5.7350, R:0.0073, T:0.6601(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.3485 (C:5.7749, R:0.0072, T:0.6286(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.3558 (C:5.7853, R:0.0073, T:0.6266(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.3503 (C:5.8062, R:0.0072, T:0.6313(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.3469 (C:5.7721, R:0.0072, T:0.6230(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6325

ğŸ“Š EPOCH 20 TRAINING SUMMARY:
  Total Loss: 1.3554
  Contrastive: 5.7783
  Reconstruction: 0.0072
  Topological: 0.6325 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.7288
  Contrastive: 4.4830
  Reconstruction: 0.0065
  Topological: 6.0781 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 20/300 COMPLETE (39.7s)
Train Loss: 1.3554 (C:5.7783, R:0.0072, T:0.6325)
Val Loss:   6.7288 (C:4.4830, R:0.0065, T:6.0781)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 21 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.3245 (C:5.8146, R:0.0072, T:0.6001(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.3314 (C:5.7684, R:0.0072, T:0.6146(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.3513 (C:5.7955, R:0.0072, T:0.6318(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.3818 (C:5.7873, R:0.0072, T:0.6601(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.3216 (C:5.7728, R:0.0072, T:0.5985(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.3441 (C:5.7811, R:0.0072, T:0.6255(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.3349 (C:5.7847, R:0.0072, T:0.6112(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.3052 (C:5.7794, R:0.0072, T:0.5868(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.3607 (C:5.7509, R:0.0072, T:0.6375(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.3724 (C:5.8025, R:0.0072, T:0.6500(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.3671 (C:5.7752, R:0.0072, T:0.6480(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.3062 (C:5.7470, R:0.0072, T:0.5906(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.3679 (C:5.7825, R:0.0072, T:0.6442(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.3514 (C:5.7898, R:0.0072, T:0.6270(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.3410 (C:5.7583, R:0.0072, T:0.6182(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.3922 (C:5.7539, R:0.0072, T:0.6722(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.3735 (C:5.7814, R:0.0072, T:0.6524(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.3226 (C:5.7994, R:0.0072, T:0.6026(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.3332 (C:5.7559, R:0.0072, T:0.6141(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.3352 (C:5.8578, R:0.0073, T:0.6080(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.3225 (C:5.7319, R:0.0072, T:0.6064(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.3415 (C:5.8051, R:0.0072, T:0.6196(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6292

ğŸ“Š EPOCH 21 TRAINING SUMMARY:
  Total Loss: 1.3508
  Contrastive: 5.7749
  Reconstruction: 0.0072
  Topological: 0.6292 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.5300
  Contrastive: 4.5075
  Reconstruction: 0.0065
  Topological: 5.8814 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 21/300 COMPLETE (41.0s)
Train Loss: 1.3508 (C:5.7749, R:0.0072, T:0.6292)
Val Loss:   6.5300 (C:4.5075, R:0.0065, T:5.8814)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 22 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.3187 (C:5.7846, R:0.0072, T:0.5950(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.3823 (C:5.7657, R:0.0072, T:0.6589(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.3536 (C:5.7660, R:0.0072, T:0.6337(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.3535 (C:5.7467, R:0.0072, T:0.6319(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.3645 (C:5.7851, R:0.0072, T:0.6480(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.3379 (C:5.7684, R:0.0072, T:0.6158(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.3904 (C:5.7671, R:0.0072, T:0.6712(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.3437 (C:5.6985, R:0.0072, T:0.6258(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.3132 (C:5.8022, R:0.0072, T:0.5941(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.3540 (C:5.7921, R:0.0072, T:0.6315(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.3406 (C:5.7941, R:0.0072, T:0.6234(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.3270 (C:5.8062, R:0.0072, T:0.6083(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.3502 (C:5.7893, R:0.0073, T:0.6227(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.3822 (C:5.7892, R:0.0072, T:0.6577(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.3317 (C:5.7540, R:0.0073, T:0.6058(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.3269 (C:5.8133, R:0.0072, T:0.6056(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.3299 (C:5.7093, R:0.0072, T:0.6080(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.3528 (C:5.7931, R:0.0072, T:0.6328(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.3443 (C:5.7580, R:0.0072, T:0.6230(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.3593 (C:5.7471, R:0.0072, T:0.6406(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.3456 (C:5.8293, R:0.0072, T:0.6222(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.3534 (C:5.7700, R:0.0072, T:0.6344(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6253

ğŸ“Š EPOCH 22 TRAINING SUMMARY:
  Total Loss: 1.3457
  Contrastive: 5.7748
  Reconstruction: 0.0072
  Topological: 0.6253 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.3949
  Contrastive: 4.5247
  Reconstruction: 0.0065
  Topological: 5.7479 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 22/300 COMPLETE (39.5s)
Train Loss: 1.3457 (C:5.7748, R:0.0072, T:0.6253)
Val Loss:   6.3949 (C:4.5247, R:0.0065, T:5.7479)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 23 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.3175 (C:5.7677, R:0.0072, T:0.6014(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.3636 (C:5.7258, R:0.0072, T:0.6405(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.3424 (C:5.7860, R:0.0072, T:0.6231(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.3390 (C:5.7723, R:0.0072, T:0.6185(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.3371 (C:5.7599, R:0.0071, T:0.6222(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.3469 (C:5.8082, R:0.0072, T:0.6295(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.3376 (C:5.6989, R:0.0071, T:0.6264(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.3519 (C:5.7403, R:0.0072, T:0.6306(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.3278 (C:5.7751, R:0.0071, T:0.6144(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.3446 (C:5.7607, R:0.0072, T:0.6206(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.3417 (C:5.8229, R:0.0072, T:0.6212(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.3104 (C:5.7627, R:0.0072, T:0.5913(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.3332 (C:5.7434, R:0.0072, T:0.6134(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.3174 (C:5.7700, R:0.0072, T:0.5987(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.3646 (C:5.7904, R:0.0072, T:0.6449(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.3182 (C:5.7501, R:0.0071, T:0.6043(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.3343 (C:5.7721, R:0.0072, T:0.6174(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.3251 (C:5.7663, R:0.0072, T:0.6058(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.3087 (C:5.7710, R:0.0071, T:0.5955(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.3536 (C:5.7886, R:0.0072, T:0.6337(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.3733 (C:5.7536, R:0.0072, T:0.6529(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.3267 (C:5.7859, R:0.0072, T:0.6057(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6213

ğŸ“Š EPOCH 23 TRAINING SUMMARY:
  Total Loss: 1.3408
  Contrastive: 5.7740
  Reconstruction: 0.0072
  Topological: 0.6213 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.1148
  Contrastive: 4.5922
  Reconstruction: 0.0064
  Topological: 5.4703 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 23/300 COMPLETE (39.2s)
Train Loss: 1.3408 (C:5.7740, R:0.0072, T:0.6213)
Val Loss:   6.1148 (C:4.5922, R:0.0064, T:5.4703)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 24 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.3199 (C:5.7943, R:0.0071, T:0.6089(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.3675 (C:5.7673, R:0.0072, T:0.6437(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.3168 (C:5.7742, R:0.0072, T:0.5999(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.3494 (C:5.7649, R:0.0072, T:0.6298(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.3273 (C:5.8166, R:0.0072, T:0.6054(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.3140 (C:5.8224, R:0.0072, T:0.5952(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.3544 (C:5.7739, R:0.0072, T:0.6345(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.3536 (C:5.8270, R:0.0073, T:0.6281(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.3290 (C:5.8061, R:0.0072, T:0.6087(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.3118 (C:5.7672, R:0.0072, T:0.5926(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.3310 (C:5.7674, R:0.0072, T:0.6089(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.3316 (C:5.7776, R:0.0072, T:0.6112(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.3329 (C:5.7787, R:0.0072, T:0.6108(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.3021 (C:5.8037, R:0.0071, T:0.5896(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.3707 (C:5.7672, R:0.0072, T:0.6491(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2832 (C:5.7746, R:0.0071, T:0.5706(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.3432 (C:5.7825, R:0.0073, T:0.6168(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.3280 (C:5.7353, R:0.0072, T:0.6093(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.3109 (C:5.7477, R:0.0072, T:0.5937(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.3019 (C:5.7541, R:0.0071, T:0.5902(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.3560 (C:5.7704, R:0.0072, T:0.6335(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.3309 (C:5.7530, R:0.0072, T:0.6131(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6170

ğŸ“Š EPOCH 24 TRAINING SUMMARY:
  Total Loss: 1.3357
  Contrastive: 5.7743
  Reconstruction: 0.0072
  Topological: 0.6170 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.2981
  Contrastive: 4.5341
  Reconstruction: 0.0065
  Topological: 5.6528 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 24/300 COMPLETE (38.9s)
Train Loss: 1.3357 (C:5.7743, R:0.0072, T:0.6170)
Val Loss:   6.2981 (C:4.5341, R:0.0065, T:5.6528)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 25 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.3716 (C:5.7647, R:0.0072, T:0.6501(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.3598 (C:5.7199, R:0.0072, T:0.6422(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.3135 (C:5.7918, R:0.0072, T:0.5921(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.3361 (C:5.7935, R:0.0072, T:0.6197(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.3332 (C:5.7796, R:0.0072, T:0.6093(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.3280 (C:5.7638, R:0.0072, T:0.6088(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2946 (C:5.8378, R:0.0071, T:0.5810(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.3387 (C:5.7563, R:0.0072, T:0.6203(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.3130 (C:5.7937, R:0.0072, T:0.5949(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.3410 (C:5.8141, R:0.0072, T:0.6252(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.3194 (C:5.7689, R:0.0072, T:0.5996(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.3271 (C:5.8155, R:0.0072, T:0.6072(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.3304 (C:5.8084, R:0.0072, T:0.6140(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2998 (C:5.7457, R:0.0071, T:0.5898(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.3383 (C:5.7542, R:0.0072, T:0.6226(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.3317 (C:5.7504, R:0.0072, T:0.6150(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.3737 (C:5.7670, R:0.0072, T:0.6550(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.3257 (C:5.8352, R:0.0072, T:0.6036(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.3112 (C:5.7150, R:0.0072, T:0.5927(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.3133 (C:5.7405, R:0.0072, T:0.5982(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.3342 (C:5.7986, R:0.0072, T:0.6187(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.3127 (C:5.7740, R:0.0072, T:0.5973(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6130

ğŸ“Š EPOCH 25 TRAINING SUMMARY:
  Total Loss: 1.3308
  Contrastive: 5.7740
  Reconstruction: 0.0072
  Topological: 0.6130 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.8755
  Contrastive: 4.5988
  Reconstruction: 0.0064
  Topological: 5.2321 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 25/300 COMPLETE (38.6s)
Train Loss: 1.3308 (C:5.7740, R:0.0072, T:0.6130)
Val Loss:   5.8755 (C:4.5988, R:0.0064, T:5.2321)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 26 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.3280 (C:5.8144, R:0.0071, T:0.6133(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.3613 (C:5.7739, R:0.0072, T:0.6429(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.3393 (C:5.7181, R:0.0072, T:0.6179(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2749 (C:5.7334, R:0.0071, T:0.5614(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.3363 (C:5.7442, R:0.0072, T:0.6212(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.3178 (C:5.7470, R:0.0072, T:0.5997(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.3212 (C:5.7505, R:0.0072, T:0.6041(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2803 (C:5.7863, R:0.0072, T:0.5648(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.3493 (C:5.7761, R:0.0073, T:0.6240(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.3086 (C:5.7558, R:0.0072, T:0.5891(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.3396 (C:5.7763, R:0.0072, T:0.6236(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2998 (C:5.7209, R:0.0072, T:0.5797(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.3239 (C:5.8179, R:0.0072, T:0.6075(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.3124 (C:5.7515, R:0.0072, T:0.5961(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.3352 (C:5.7649, R:0.0071, T:0.6215(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.3250 (C:5.7524, R:0.0071, T:0.6147(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.3119 (C:5.7315, R:0.0072, T:0.5939(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.3216 (C:5.8434, R:0.0072, T:0.6029(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.3255 (C:5.8006, R:0.0072, T:0.6061(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.3584 (C:5.7233, R:0.0072, T:0.6432(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.3782 (C:5.7404, R:0.0072, T:0.6548(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.3051 (C:5.7496, R:0.0071, T:0.5910(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6111

ğŸ“Š EPOCH 26 TRAINING SUMMARY:
  Total Loss: 1.3283
  Contrastive: 5.7708
  Reconstruction: 0.0072
  Topological: 0.6111 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.9191
  Contrastive: 4.5708
  Reconstruction: 0.0064
  Topological: 5.2764 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 26/300 COMPLETE (37.3s)
Train Loss: 1.3283 (C:5.7708, R:0.0072, T:0.6111)
Val Loss:   5.9191 (C:4.5708, R:0.0064, T:5.2764)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 27 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.3129 (C:5.7396, R:0.0071, T:0.5993(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.3237 (C:5.7688, R:0.0071, T:0.6121(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.3453 (C:5.7633, R:0.0072, T:0.6293(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2915 (C:5.7957, R:0.0071, T:0.5827(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.3074 (C:5.7948, R:0.0071, T:0.5976(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.3074 (C:5.7255, R:0.0072, T:0.5913(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.3270 (C:5.7489, R:0.0072, T:0.6110(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.3474 (C:5.7656, R:0.0072, T:0.6277(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.3216 (C:5.7745, R:0.0072, T:0.6065(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.3102 (C:5.7767, R:0.0072, T:0.5948(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.3343 (C:5.7601, R:0.0071, T:0.6196(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.3172 (C:5.7985, R:0.0072, T:0.6013(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2963 (C:5.7877, R:0.0072, T:0.5787(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2945 (C:5.7463, R:0.0072, T:0.5787(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.3241 (C:5.7418, R:0.0072, T:0.6077(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.3444 (C:5.8000, R:0.0072, T:0.6231(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.3505 (C:5.7479, R:0.0072, T:0.6330(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.3528 (C:5.7962, R:0.0072, T:0.6329(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.3316 (C:5.7783, R:0.0072, T:0.6158(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.3233 (C:5.7857, R:0.0072, T:0.6005(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2916 (C:5.7630, R:0.0071, T:0.5776(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.3431 (C:5.7632, R:0.0072, T:0.6278(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6082

ğŸ“Š EPOCH 27 TRAINING SUMMARY:
  Total Loss: 1.3247
  Contrastive: 5.7710
  Reconstruction: 0.0072
  Topological: 0.6082 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.9661
  Contrastive: 4.5766
  Reconstruction: 0.0064
  Topological: 5.3234 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 27/300 COMPLETE (38.4s)
Train Loss: 1.3247 (C:5.7710, R:0.0072, T:0.6082)
Val Loss:   5.9661 (C:4.5766, R:0.0064, T:5.3234)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 28 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.3398 (C:5.7654, R:0.0072, T:0.6222(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.3284 (C:5.7653, R:0.0071, T:0.6176(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2742 (C:5.7526, R:0.0071, T:0.5637(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.3011 (C:5.7361, R:0.0072, T:0.5844(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.3341 (C:5.8155, R:0.0072, T:0.6186(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.3130 (C:5.7644, R:0.0071, T:0.5998(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2981 (C:5.7599, R:0.0072, T:0.5829(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.3244 (C:5.7960, R:0.0072, T:0.6018(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.3255 (C:5.7886, R:0.0071, T:0.6126(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.3543 (C:5.7445, R:0.0071, T:0.6401(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.3185 (C:5.7888, R:0.0071, T:0.6038(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.3152 (C:5.7808, R:0.0072, T:0.5953(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2958 (C:5.7653, R:0.0071, T:0.5836(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.3864 (C:5.7925, R:0.0072, T:0.6647(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.3365 (C:5.7458, R:0.0072, T:0.6200(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.3454 (C:5.7904, R:0.0071, T:0.6311(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2918 (C:5.7523, R:0.0071, T:0.5799(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.3227 (C:5.7431, R:0.0071, T:0.6083(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.3080 (C:5.7051, R:0.0072, T:0.5907(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.3382 (C:5.8076, R:0.0071, T:0.6234(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.3097 (C:5.7931, R:0.0071, T:0.5952(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.3248 (C:5.7581, R:0.0072, T:0.6077(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6061

ğŸ“Š EPOCH 28 TRAINING SUMMARY:
  Total Loss: 1.3221
  Contrastive: 5.7718
  Reconstruction: 0.0072
  Topological: 0.6061 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.9310
  Contrastive: 4.5782
  Reconstruction: 0.0064
  Topological: 5.2891 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 28/300 COMPLETE (39.5s)
Train Loss: 1.3221 (C:5.7718, R:0.0072, T:0.6061)
Val Loss:   5.9310 (C:4.5782, R:0.0064, T:5.2891)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 29 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.3290 (C:5.7457, R:0.0072, T:0.6124(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.3256 (C:5.7500, R:0.0072, T:0.6093(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.3182 (C:5.7901, R:0.0071, T:0.6052(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.3617 (C:5.7734, R:0.0071, T:0.6506(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.3038 (C:5.7328, R:0.0071, T:0.5895(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2872 (C:5.8113, R:0.0071, T:0.5741(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.3257 (C:5.8417, R:0.0072, T:0.6043(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.3226 (C:5.7614, R:0.0072, T:0.6018(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.3253 (C:5.7555, R:0.0072, T:0.6101(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.3380 (C:5.7609, R:0.0071, T:0.6242(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.3049 (C:5.7806, R:0.0072, T:0.5866(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2990 (C:5.7198, R:0.0071, T:0.5842(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2913 (C:5.7742, R:0.0071, T:0.5820(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.3761 (C:5.7305, R:0.0072, T:0.6608(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.3150 (C:5.8202, R:0.0072, T:0.5961(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.3031 (C:5.7459, R:0.0071, T:0.5913(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.3227 (C:5.7677, R:0.0072, T:0.6037(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2914 (C:5.7822, R:0.0072, T:0.5755(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.3164 (C:5.7446, R:0.0072, T:0.6006(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.3097 (C:5.7657, R:0.0072, T:0.5919(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.3452 (C:5.7273, R:0.0072, T:0.6296(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.3134 (C:5.7527, R:0.0071, T:0.6022(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6029

ğŸ“Š EPOCH 29 TRAINING SUMMARY:
  Total Loss: 1.3183
  Contrastive: 5.7695
  Reconstruction: 0.0072
  Topological: 0.6029 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.7940
  Contrastive: 4.6050
  Reconstruction: 0.0064
  Topological: 5.1539 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 29/300 COMPLETE (39.8s)
Train Loss: 1.3183 (C:5.7695, R:0.0072, T:0.6029)
Val Loss:   5.7940 (C:4.6050, R:0.0064, T:5.1539)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 30 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.3242 (C:5.7939, R:0.0072, T:0.6051(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2996 (C:5.7704, R:0.0071, T:0.5864(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.3333 (C:5.7255, R:0.0072, T:0.6117(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2926 (C:5.7574, R:0.0071, T:0.5844(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.3074 (C:5.7797, R:0.0071, T:0.5955(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2752 (C:5.7595, R:0.0071, T:0.5639(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.3026 (C:5.7379, R:0.0071, T:0.5913(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.3208 (C:5.7624, R:0.0072, T:0.6027(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.3256 (C:5.7584, R:0.0072, T:0.6085(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.3386 (C:5.8135, R:0.0071, T:0.6260(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2749 (C:5.7484, R:0.0071, T:0.5645(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.3247 (C:5.7553, R:0.0071, T:0.6154(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.3252 (C:5.8022, R:0.0072, T:0.6087(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.3406 (C:5.7806, R:0.0071, T:0.6259(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.3040 (C:5.7355, R:0.0072, T:0.5846(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2911 (C:5.7531, R:0.0072, T:0.5754(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2821 (C:5.7730, R:0.0071, T:0.5704(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2895 (C:5.7340, R:0.0071, T:0.5780(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2899 (C:5.8219, R:0.0071, T:0.5790(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.3059 (C:5.7687, R:0.0071, T:0.5975(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.3391 (C:5.7535, R:0.0072, T:0.6210(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2827 (C:5.7442, R:0.0071, T:0.5712(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6012

ğŸ“Š EPOCH 30 TRAINING SUMMARY:
  Total Loss: 1.3158
  Contrastive: 5.7684
  Reconstruction: 0.0071
  Topological: 0.6012 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.8256
  Contrastive: 4.5660
  Reconstruction: 0.0064
  Topological: 5.1845 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 30/300 COMPLETE (39.1s)
Train Loss: 1.3158 (C:5.7684, R:0.0071, T:0.6012)
Val Loss:   5.8256 (C:4.5660, R:0.0064, T:5.1845)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 31 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.3004 (C:5.7022, R:0.0071, T:0.5915(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.3383 (C:5.7443, R:0.0072, T:0.6226(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2806 (C:5.7960, R:0.0071, T:0.5670(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.3450 (C:5.7741, R:0.0072, T:0.6257(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2810 (C:5.7555, R:0.0071, T:0.5717(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.3026 (C:5.8124, R:0.0071, T:0.5910(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.3074 (C:5.7679, R:0.0072, T:0.5904(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2979 (C:5.7176, R:0.0071, T:0.5841(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.3192 (C:5.7994, R:0.0072, T:0.6018(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.3315 (C:5.8188, R:0.0072, T:0.6141(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.3234 (C:5.7148, R:0.0072, T:0.6073(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2777 (C:5.8077, R:0.0071, T:0.5688(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2723 (C:5.7237, R:0.0071, T:0.5617(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2817 (C:5.8262, R:0.0071, T:0.5735(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2617 (C:5.7719, R:0.0071, T:0.5537(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.3056 (C:5.8085, R:0.0071, T:0.5919(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.3183 (C:5.7635, R:0.0072, T:0.5977(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.3251 (C:5.7358, R:0.0072, T:0.6091(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2848 (C:5.7584, R:0.0071, T:0.5720(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.3409 (C:5.7831, R:0.0072, T:0.6226(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.3209 (C:5.7058, R:0.0071, T:0.6088(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.3333 (C:5.7978, R:0.0072, T:0.6148(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5984

ğŸ“Š EPOCH 31 TRAINING SUMMARY:
  Total Loss: 1.3126
  Contrastive: 5.7688
  Reconstruction: 0.0071
  Topological: 0.5984 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.6922
  Contrastive: 4.5933
  Reconstruction: 0.0064
  Topological: 5.0533 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 31/300 COMPLETE (37.9s)
Train Loss: 1.3126 (C:5.7688, R:0.0071, T:0.5984)
Val Loss:   5.6922 (C:4.5933, R:0.0064, T:5.0533)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 32 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2839 (C:5.7312, R:0.0072, T:0.5678(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.3491 (C:5.7386, R:0.0072, T:0.6336(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.3210 (C:5.7857, R:0.0071, T:0.6104(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.3020 (C:5.7110, R:0.0071, T:0.5893(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.3221 (C:5.7818, R:0.0072, T:0.6042(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.3057 (C:5.7306, R:0.0072, T:0.5900(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.3237 (C:5.7937, R:0.0072, T:0.6062(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2798 (C:5.7680, R:0.0071, T:0.5650(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.3196 (C:5.7646, R:0.0072, T:0.6025(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.3473 (C:5.7694, R:0.0072, T:0.6266(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.3081 (C:5.7910, R:0.0072, T:0.5926(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2884 (C:5.7355, R:0.0071, T:0.5739(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.3217 (C:5.8225, R:0.0072, T:0.6054(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.3478 (C:5.7771, R:0.0071, T:0.6358(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2641 (C:5.7806, R:0.0071, T:0.5563(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.3146 (C:5.7823, R:0.0071, T:0.6020(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.3097 (C:5.7627, R:0.0071, T:0.5963(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2841 (C:5.7706, R:0.0071, T:0.5716(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.3063 (C:5.7704, R:0.0071, T:0.5922(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2832 (C:5.7849, R:0.0072, T:0.5640(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.3418 (C:5.7647, R:0.0072, T:0.6264(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2798 (C:5.7659, R:0.0071, T:0.5718(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5961

ğŸ“Š EPOCH 32 TRAINING SUMMARY:
  Total Loss: 1.3098
  Contrastive: 5.7687
  Reconstruction: 0.0071
  Topological: 0.5961 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.4765
  Contrastive: 4.6261
  Reconstruction: 0.0064
  Topological: 4.8379 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 32/300 COMPLETE (39.9s)
Train Loss: 1.3098 (C:5.7687, R:0.0071, T:0.5961)
Val Loss:   5.4765 (C:4.6261, R:0.0064, T:4.8379)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 33 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.3327 (C:5.7812, R:0.0072, T:0.6096(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2840 (C:5.7307, R:0.0071, T:0.5704(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.3218 (C:5.7404, R:0.0072, T:0.6057(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.3232 (C:5.7423, R:0.0071, T:0.6143(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2993 (C:5.7963, R:0.0071, T:0.5848(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.3176 (C:5.7508, R:0.0072, T:0.6009(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.3003 (C:5.7823, R:0.0071, T:0.5870(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2751 (C:5.7190, R:0.0072, T:0.5586(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2810 (C:5.7615, R:0.0071, T:0.5665(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.3079 (C:5.8031, R:0.0071, T:0.5937(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.3002 (C:5.7308, R:0.0071, T:0.5870(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.3129 (C:5.7687, R:0.0071, T:0.6009(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.3088 (C:5.7466, R:0.0071, T:0.5977(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.3269 (C:5.7574, R:0.0071, T:0.6136(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.3109 (C:5.7937, R:0.0072, T:0.5951(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2319 (C:5.7500, R:0.0071, T:0.5198(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.3000 (C:5.7702, R:0.0071, T:0.5868(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.3135 (C:5.7828, R:0.0071, T:0.6021(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2674 (C:5.7255, R:0.0071, T:0.5611(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2992 (C:5.7672, R:0.0071, T:0.5847(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.3216 (C:5.6997, R:0.0071, T:0.6070(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.3003 (C:5.7271, R:0.0071, T:0.5865(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5937

ğŸ“Š EPOCH 33 TRAINING SUMMARY:
  Total Loss: 1.3070
  Contrastive: 5.7674
  Reconstruction: 0.0071
  Topological: 0.5937 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.5713
  Contrastive: 4.6052
  Reconstruction: 0.0064
  Topological: 4.9318 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 33/300 COMPLETE (38.9s)
Train Loss: 1.3070 (C:5.7674, R:0.0071, T:0.5937)
Val Loss:   5.5713 (C:4.6052, R:0.0064, T:4.9318)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 34 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.3025 (C:5.7549, R:0.0072, T:0.5861(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.3662 (C:5.7834, R:0.0071, T:0.6520(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.3377 (C:5.7990, R:0.0072, T:0.6211(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.3220 (C:5.8061, R:0.0072, T:0.6041(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.3358 (C:5.7326, R:0.0072, T:0.6185(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.3191 (C:5.7494, R:0.0072, T:0.6039(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.3237 (C:5.7824, R:0.0072, T:0.6038(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.3116 (C:5.7816, R:0.0072, T:0.5965(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.3159 (C:5.7205, R:0.0072, T:0.5991(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.3052 (C:5.7925, R:0.0071, T:0.5928(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2945 (C:5.7865, R:0.0071, T:0.5841(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2924 (C:5.7533, R:0.0071, T:0.5851(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2818 (C:5.7717, R:0.0071, T:0.5750(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.3033 (C:5.7017, R:0.0071, T:0.5952(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.3001 (C:5.8221, R:0.0071, T:0.5869(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.3077 (C:5.7543, R:0.0071, T:0.5950(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2943 (C:5.7539, R:0.0071, T:0.5855(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.3114 (C:5.7787, R:0.0071, T:0.5980(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2755 (C:5.7836, R:0.0071, T:0.5627(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.3022 (C:5.7736, R:0.0072, T:0.5857(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2967 (C:5.8230, R:0.0072, T:0.5807(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.3090 (C:5.7794, R:0.0071, T:0.5974(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 34 TRAINING SUMMARY:
  Total Loss: 1.3067
  Contrastive: 5.7683
  Reconstruction: 0.0071
  Topological: 0.5938 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.5348
  Contrastive: 4.6072
  Reconstruction: 0.0064
  Topological: 4.8969 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 34/300 COMPLETE (38.6s)
Train Loss: 1.3067 (C:5.7683, R:0.0071, T:0.5938)
Val Loss:   5.5348 (C:4.6072, R:0.0064, T:4.8969)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 35 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.3077 (C:5.7561, R:0.0071, T:0.5956(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2707 (C:5.7650, R:0.0071, T:0.5604(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.3155 (C:5.8045, R:0.0071, T:0.6041(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.3372 (C:5.7697, R:0.0072, T:0.6180(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.3134 (C:5.7715, R:0.0072, T:0.5978(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2948 (C:5.7706, R:0.0071, T:0.5816(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2917 (C:5.7613, R:0.0071, T:0.5794(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2997 (C:5.7740, R:0.0071, T:0.5888(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.3155 (C:5.7775, R:0.0071, T:0.6027(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.3233 (C:5.8002, R:0.0072, T:0.6018(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2595 (C:5.7897, R:0.0071, T:0.5476(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2836 (C:5.8130, R:0.0071, T:0.5711(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.3169 (C:5.7155, R:0.0071, T:0.6091(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2920 (C:5.7959, R:0.0071, T:0.5811(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2687 (C:5.7498, R:0.0071, T:0.5624(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.3093 (C:5.7885, R:0.0071, T:0.5954(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.3083 (C:5.7999, R:0.0071, T:0.5939(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.3258 (C:5.7566, R:0.0071, T:0.6156(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.3298 (C:5.7972, R:0.0072, T:0.6098(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2974 (C:5.7170, R:0.0071, T:0.5870(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2851 (C:5.7675, R:0.0071, T:0.5724(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.3286 (C:5.7961, R:0.0072, T:0.6077(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5929

ğŸ“Š EPOCH 35 TRAINING SUMMARY:
  Total Loss: 1.3052
  Contrastive: 5.7647
  Reconstruction: 0.0071
  Topological: 0.5929 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.4463
  Contrastive: 4.6369
  Reconstruction: 0.0064
  Topological: 4.8091 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 35/300 COMPLETE (39.4s)
Train Loss: 1.3052 (C:5.7647, R:0.0071, T:0.5929)
Val Loss:   5.4463 (C:4.6369, R:0.0064, T:4.8091)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 36 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2901 (C:5.7882, R:0.0071, T:0.5760(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.3312 (C:5.7664, R:0.0071, T:0.6166(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.3240 (C:5.7114, R:0.0071, T:0.6096(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2512 (C:5.7903, R:0.0070, T:0.5480(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.3023 (C:5.8003, R:0.0072, T:0.5856(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.3151 (C:5.7737, R:0.0072, T:0.5967(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.3121 (C:5.7251, R:0.0071, T:0.6020(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.3010 (C:5.7906, R:0.0071, T:0.5929(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2723 (C:5.8073, R:0.0071, T:0.5595(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.3025 (C:5.7758, R:0.0071, T:0.5969(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2803 (C:5.7747, R:0.0071, T:0.5731(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.3115 (C:5.7897, R:0.0071, T:0.5971(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2871 (C:5.7771, R:0.0071, T:0.5770(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2782 (C:5.7760, R:0.0071, T:0.5654(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2666 (C:5.7520, R:0.0071, T:0.5575(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2982 (C:5.7299, R:0.0071, T:0.5859(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.3035 (C:5.7465, R:0.0071, T:0.5950(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.3004 (C:5.7867, R:0.0071, T:0.5952(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.3044 (C:5.7285, R:0.0071, T:0.5904(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.3054 (C:5.7878, R:0.0071, T:0.5940(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.3384 (C:5.8035, R:0.0071, T:0.6268(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2619 (C:5.7531, R:0.0071, T:0.5524(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5889

ğŸ“Š EPOCH 36 TRAINING SUMMARY:
  Total Loss: 1.3007
  Contrastive: 5.7678
  Reconstruction: 0.0071
  Topological: 0.5889 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.3124
  Contrastive: 4.6612
  Reconstruction: 0.0064
  Topological: 4.6767 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 36/300 COMPLETE (38.6s)
Train Loss: 1.3007 (C:5.7678, R:0.0071, T:0.5889)
Val Loss:   5.3124 (C:4.6612, R:0.0064, T:4.6767)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 37 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2975 (C:5.8013, R:0.0071, T:0.5829(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.3062 (C:5.7589, R:0.0071, T:0.5945(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.3136 (C:5.7332, R:0.0072, T:0.5968(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.3316 (C:5.8012, R:0.0071, T:0.6184(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.3345 (C:5.7611, R:0.0072, T:0.6164(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2723 (C:5.7920, R:0.0071, T:0.5621(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.3188 (C:5.7772, R:0.0071, T:0.6092(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.3007 (C:5.7855, R:0.0071, T:0.5880(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.3515 (C:5.7473, R:0.0071, T:0.6383(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2894 (C:5.7340, R:0.0071, T:0.5777(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2962 (C:5.7908, R:0.0071, T:0.5814(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2977 (C:5.7528, R:0.0071, T:0.5828(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.3281 (C:5.8057, R:0.0071, T:0.6136(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.3019 (C:5.7152, R:0.0071, T:0.5920(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2457 (C:5.7634, R:0.0071, T:0.5393(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2691 (C:5.7417, R:0.0071, T:0.5592(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.3413 (C:5.7792, R:0.0071, T:0.6295(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2719 (C:5.7021, R:0.0071, T:0.5620(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2989 (C:5.7847, R:0.0071, T:0.5936(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.3181 (C:5.7652, R:0.0071, T:0.6090(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2959 (C:5.7433, R:0.0071, T:0.5897(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2681 (C:5.8048, R:0.0072, T:0.5517(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 37 TRAINING SUMMARY:
  Total Loss: 1.3008
  Contrastive: 5.7666
  Reconstruction: 0.0071
  Topological: 0.5892 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.2920
  Contrastive: 4.6427
  Reconstruction: 0.0064
  Topological: 4.6549 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 37/300 COMPLETE (38.9s)
Train Loss: 1.3008 (C:5.7666, R:0.0071, T:0.5892)
Val Loss:   5.2920 (C:4.6427, R:0.0064, T:4.6549)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 38 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2896 (C:5.7711, R:0.0071, T:0.5829(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2457 (C:5.7862, R:0.0071, T:0.5350(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.3362 (C:5.7849, R:0.0072, T:0.6196(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2748 (C:5.7465, R:0.0071, T:0.5638(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2986 (C:5.7593, R:0.0071, T:0.5914(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.3180 (C:5.7781, R:0.0071, T:0.6072(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2798 (C:5.7888, R:0.0071, T:0.5703(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2781 (C:5.7435, R:0.0071, T:0.5693(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2784 (C:5.7518, R:0.0071, T:0.5645(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2806 (C:5.7564, R:0.0071, T:0.5672(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2726 (C:5.7697, R:0.0071, T:0.5647(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2972 (C:5.7615, R:0.0071, T:0.5854(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2967 (C:5.7962, R:0.0071, T:0.5856(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.3064 (C:5.7599, R:0.0071, T:0.5990(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.3279 (C:5.7849, R:0.0071, T:0.6139(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2822 (C:5.7650, R:0.0071, T:0.5745(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.3067 (C:5.8073, R:0.0071, T:0.5920(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2928 (C:5.8274, R:0.0071, T:0.5827(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.3066 (C:5.7194, R:0.0071, T:0.5966(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2949 (C:5.8157, R:0.0071, T:0.5848(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.3286 (C:5.7923, R:0.0071, T:0.6148(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2970 (C:5.7858, R:0.0072, T:0.5817(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5868

ğŸ“Š EPOCH 38 TRAINING SUMMARY:
  Total Loss: 1.2981
  Contrastive: 5.7670
  Reconstruction: 0.0071
  Topological: 0.5868 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.3053
  Contrastive: 4.6458
  Reconstruction: 0.0064
  Topological: 4.6686 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 38/300 COMPLETE (37.8s)
Train Loss: 1.2981 (C:5.7670, R:0.0071, T:0.5868)
Val Loss:   5.3053 (C:4.6458, R:0.0064, T:4.6686)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 39 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.3056 (C:5.7504, R:0.0072, T:0.5888(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.3214 (C:5.7827, R:0.0071, T:0.6099(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2993 (C:5.7860, R:0.0071, T:0.5900(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2899 (C:5.7469, R:0.0071, T:0.5791(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2663 (C:5.7773, R:0.0071, T:0.5587(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2615 (C:5.7880, R:0.0071, T:0.5539(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.3100 (C:5.8156, R:0.0071, T:0.5985(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2863 (C:5.7024, R:0.0071, T:0.5798(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2806 (C:5.8402, R:0.0071, T:0.5699(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2973 (C:5.7847, R:0.0071, T:0.5848(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2553 (C:5.7650, R:0.0071, T:0.5483(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2871 (C:5.7367, R:0.0071, T:0.5764(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2744 (C:5.7396, R:0.0071, T:0.5640(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2938 (C:5.7581, R:0.0072, T:0.5784(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2914 (C:5.7819, R:0.0071, T:0.5827(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2957 (C:5.8029, R:0.0072, T:0.5789(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2667 (C:5.7692, R:0.0071, T:0.5572(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.3122 (C:5.7226, R:0.0071, T:0.6051(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.3261 (C:5.7709, R:0.0072, T:0.6098(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.3343 (C:5.7827, R:0.0072, T:0.6179(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2868 (C:5.7697, R:0.0071, T:0.5801(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2945 (C:5.7146, R:0.0071, T:0.5874(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5868

ğŸ“Š EPOCH 39 TRAINING SUMMARY:
  Total Loss: 1.2976
  Contrastive: 5.7670
  Reconstruction: 0.0071
  Topological: 0.5868 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0545
  Contrastive: 4.6837
  Reconstruction: 0.0064
  Topological: 4.4193 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 39/300 COMPLETE (38.5s)
Train Loss: 1.2976 (C:5.7670, R:0.0071, T:0.5868)
Val Loss:   5.0545 (C:4.6837, R:0.0064, T:4.4193)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 40 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.3338 (C:5.8248, R:0.0071, T:0.6213(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2955 (C:5.7369, R:0.0071, T:0.5862(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2661 (C:5.7899, R:0.0071, T:0.5550(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2771 (C:5.8171, R:0.0071, T:0.5643(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2851 (C:5.7331, R:0.0071, T:0.5762(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.3430 (C:5.8072, R:0.0072, T:0.6212(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2894 (C:5.7950, R:0.0071, T:0.5758(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2700 (C:5.7317, R:0.0071, T:0.5613(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.3074 (C:5.7639, R:0.0072, T:0.5924(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.3056 (C:5.7543, R:0.0071, T:0.5961(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.3002 (C:5.7406, R:0.0071, T:0.5934(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2770 (C:5.7187, R:0.0071, T:0.5690(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2864 (C:5.7480, R:0.0071, T:0.5748(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.3009 (C:5.7867, R:0.0071, T:0.5884(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.3037 (C:5.7708, R:0.0071, T:0.5954(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2725 (C:5.7960, R:0.0071, T:0.5651(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.3206 (C:5.7727, R:0.0071, T:0.6071(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2870 (C:5.7637, R:0.0071, T:0.5804(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.3084 (C:5.7373, R:0.0071, T:0.5986(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.3069 (C:5.7736, R:0.0072, T:0.5904(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2854 (C:5.7837, R:0.0071, T:0.5755(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2701 (C:5.7414, R:0.0071, T:0.5587(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5830

ğŸ“Š EPOCH 40 TRAINING SUMMARY:
  Total Loss: 1.2936
  Contrastive: 5.7660
  Reconstruction: 0.0071
  Topological: 0.5830 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.2134
  Contrastive: 4.6683
  Reconstruction: 0.0064
  Topological: 4.5777 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 40/300 COMPLETE (38.4s)
Train Loss: 1.2936 (C:5.7660, R:0.0071, T:0.5830)
Val Loss:   5.2134 (C:4.6683, R:0.0064, T:4.5777)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 41 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2973 (C:5.7928, R:0.0071, T:0.5824(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2744 (C:5.8043, R:0.0071, T:0.5630(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2880 (C:5.7237, R:0.0071, T:0.5768(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.3178 (C:5.8111, R:0.0071, T:0.6039(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.3098 (C:5.7729, R:0.0072, T:0.5897(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2691 (C:5.7516, R:0.0071, T:0.5610(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2813 (C:5.7308, R:0.0071, T:0.5719(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2644 (C:5.7562, R:0.0071, T:0.5565(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2950 (C:5.7858, R:0.0071, T:0.5801(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2884 (C:5.7592, R:0.0071, T:0.5774(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2729 (C:5.7187, R:0.0071, T:0.5642(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.3379 (C:5.7900, R:0.0072, T:0.6220(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2786 (C:5.7997, R:0.0071, T:0.5677(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2710 (C:5.7797, R:0.0071, T:0.5561(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2908 (C:5.7854, R:0.0071, T:0.5808(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2808 (C:5.8042, R:0.0071, T:0.5684(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.3188 (C:5.7968, R:0.0071, T:0.6057(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2930 (C:5.7569, R:0.0071, T:0.5864(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2763 (C:5.7218, R:0.0071, T:0.5651(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2592 (C:5.7808, R:0.0071, T:0.5522(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2707 (C:5.7240, R:0.0070, T:0.5660(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2777 (C:5.7619, R:0.0071, T:0.5727(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5827

ğŸ“Š EPOCH 41 TRAINING SUMMARY:
  Total Loss: 1.2928
  Contrastive: 5.7668
  Reconstruction: 0.0071
  Topological: 0.5827 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.2107
  Contrastive: 4.6332
  Reconstruction: 0.0064
  Topological: 4.5754 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 41/300 COMPLETE (38.7s)
Train Loss: 1.2928 (C:5.7668, R:0.0071, T:0.5827)
Val Loss:   5.2107 (C:4.6332, R:0.0064, T:4.5754)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 42 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2945 (C:5.7248, R:0.0071, T:0.5832(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.3035 (C:5.7688, R:0.0071, T:0.5956(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2850 (C:5.7666, R:0.0071, T:0.5767(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2876 (C:5.8064, R:0.0071, T:0.5816(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2752 (C:5.7608, R:0.0071, T:0.5698(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.3053 (C:5.7665, R:0.0071, T:0.5932(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.3106 (C:5.7635, R:0.0071, T:0.6015(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.3008 (C:5.7592, R:0.0071, T:0.5911(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2798 (C:5.7968, R:0.0071, T:0.5669(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2695 (C:5.7268, R:0.0071, T:0.5631(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2821 (C:5.8166, R:0.0071, T:0.5737(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.3090 (C:5.7456, R:0.0071, T:0.6008(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2653 (C:5.7463, R:0.0071, T:0.5560(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.3152 (C:5.7507, R:0.0071, T:0.6072(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2751 (C:5.7489, R:0.0071, T:0.5681(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2739 (C:5.7706, R:0.0071, T:0.5635(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.3009 (C:5.7662, R:0.0071, T:0.5896(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2497 (C:5.8074, R:0.0071, T:0.5414(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2525 (C:5.7368, R:0.0071, T:0.5464(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2728 (C:5.7841, R:0.0071, T:0.5622(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2769 (C:5.7679, R:0.0070, T:0.5724(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2977 (C:5.7322, R:0.0071, T:0.5921(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5798

ğŸ“Š EPOCH 42 TRAINING SUMMARY:
  Total Loss: 1.2895
  Contrastive: 5.7649
  Reconstruction: 0.0071
  Topological: 0.5798 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.1700
  Contrastive: 4.6685
  Reconstruction: 0.0063
  Topological: 4.5357 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 42/300 COMPLETE (38.1s)
Train Loss: 1.2895 (C:5.7649, R:0.0071, T:0.5798)
Val Loss:   5.1700 (C:4.6685, R:0.0063, T:4.5357)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 43 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2862 (C:5.7481, R:0.0071, T:0.5785(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.3089 (C:5.7562, R:0.0072, T:0.5927(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.3166 (C:5.8323, R:0.0071, T:0.6056(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2972 (C:5.7638, R:0.0071, T:0.5889(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.3115 (C:5.7537, R:0.0070, T:0.6070(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.3000 (C:5.7968, R:0.0071, T:0.5906(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.3252 (C:5.7816, R:0.0072, T:0.6096(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2947 (C:5.7679, R:0.0071, T:0.5870(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2848 (C:5.7672, R:0.0070, T:0.5830(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.3394 (C:5.8113, R:0.0071, T:0.6285(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2982 (C:5.7629, R:0.0071, T:0.5856(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.3133 (C:5.7874, R:0.0071, T:0.6024(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.3166 (C:5.8366, R:0.0071, T:0.6082(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2977 (C:5.7754, R:0.0071, T:0.5851(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2788 (C:5.7789, R:0.0071, T:0.5689(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2996 (C:5.7449, R:0.0071, T:0.5901(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2345 (C:5.7426, R:0.0071, T:0.5287(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2996 (C:5.7429, R:0.0071, T:0.5930(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.3020 (C:5.8103, R:0.0071, T:0.5915(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2845 (C:5.7648, R:0.0071, T:0.5760(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2921 (C:5.8011, R:0.0071, T:0.5824(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2888 (C:5.7290, R:0.0071, T:0.5833(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 43 TRAINING SUMMARY:
  Total Loss: 1.2901
  Contrastive: 5.7652
  Reconstruction: 0.0071
  Topological: 0.5807 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0849
  Contrastive: 4.6731
  Reconstruction: 0.0063
  Topological: 4.4513 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 43/300 COMPLETE (39.6s)
Train Loss: 1.2901 (C:5.7652, R:0.0071, T:0.5807)
Val Loss:   5.0849 (C:4.6731, R:0.0063, T:4.4513)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 44 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2519 (C:5.7657, R:0.0071, T:0.5454(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2883 (C:5.7365, R:0.0071, T:0.5800(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2807 (C:5.7404, R:0.0071, T:0.5744(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2681 (C:5.7702, R:0.0071, T:0.5591(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2788 (C:5.7689, R:0.0071, T:0.5727(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2794 (C:5.7952, R:0.0071, T:0.5688(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2848 (C:5.7421, R:0.0071, T:0.5745(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2737 (C:5.7681, R:0.0071, T:0.5649(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2839 (C:5.7798, R:0.0072, T:0.5687(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2877 (C:5.7441, R:0.0071, T:0.5754(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.3076 (C:5.7512, R:0.0071, T:0.5996(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.3022 (C:5.7824, R:0.0071, T:0.5915(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2785 (C:5.7709, R:0.0071, T:0.5706(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2792 (C:5.7828, R:0.0071, T:0.5736(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2875 (C:5.7527, R:0.0071, T:0.5759(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2873 (C:5.7645, R:0.0071, T:0.5782(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2855 (C:5.7807, R:0.0071, T:0.5759(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2930 (C:5.7307, R:0.0071, T:0.5870(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2918 (C:5.7839, R:0.0071, T:0.5837(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2965 (C:5.7461, R:0.0071, T:0.5817(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2870 (C:5.7693, R:0.0071, T:0.5772(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2883 (C:5.7776, R:0.0071, T:0.5800(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5794

ğŸ“Š EPOCH 44 TRAINING SUMMARY:
  Total Loss: 1.2886
  Contrastive: 5.7643
  Reconstruction: 0.0071
  Topological: 0.5794 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0511
  Contrastive: 4.6860
  Reconstruction: 0.0063
  Topological: 4.4171 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 44/300 COMPLETE (39.2s)
Train Loss: 1.2886 (C:5.7643, R:0.0071, T:0.5794)
Val Loss:   5.0511 (C:4.6860, R:0.0063, T:4.4171)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 45 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2831 (C:5.7904, R:0.0070, T:0.5793(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.3110 (C:5.7554, R:0.0071, T:0.6003(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2816 (C:5.8127, R:0.0071, T:0.5695(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2848 (C:5.7610, R:0.0071, T:0.5775(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.3261 (C:5.7711, R:0.0071, T:0.6172(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.3079 (C:5.7623, R:0.0071, T:0.5941(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.3209 (C:5.6996, R:0.0071, T:0.6130(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2706 (C:5.7912, R:0.0071, T:0.5646(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2721 (C:5.7798, R:0.0071, T:0.5652(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2861 (C:5.7972, R:0.0071, T:0.5771(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2997 (C:5.8018, R:0.0071, T:0.5869(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2718 (C:5.8217, R:0.0071, T:0.5638(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2690 (C:5.7709, R:0.0071, T:0.5630(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2647 (C:5.7198, R:0.0071, T:0.5594(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2814 (C:5.7207, R:0.0071, T:0.5708(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.3057 (C:5.7687, R:0.0072, T:0.5897(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2793 (C:5.7646, R:0.0070, T:0.5760(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2716 (C:5.7366, R:0.0071, T:0.5636(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.3205 (C:5.7890, R:0.0071, T:0.6064(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.3302 (C:5.7415, R:0.0071, T:0.6165(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2949 (C:5.7697, R:0.0071, T:0.5815(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2506 (C:5.7549, R:0.0071, T:0.5413(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5794

ğŸ“Š EPOCH 45 TRAINING SUMMARY:
  Total Loss: 1.2884
  Contrastive: 5.7646
  Reconstruction: 0.0071
  Topological: 0.5794 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0237
  Contrastive: 4.6919
  Reconstruction: 0.0063
  Topological: 4.3895 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 45/300 COMPLETE (38.8s)
Train Loss: 1.2884 (C:5.7646, R:0.0071, T:0.5794)
Val Loss:   5.0237 (C:4.6919, R:0.0063, T:4.3895)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 46 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.3131 (C:5.7719, R:0.0071, T:0.6004(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2831 (C:5.7773, R:0.0071, T:0.5734(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2771 (C:5.7851, R:0.0071, T:0.5698(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2681 (C:5.7540, R:0.0071, T:0.5614(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2935 (C:5.7203, R:0.0071, T:0.5831(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2499 (C:5.7277, R:0.0071, T:0.5443(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2756 (C:5.7413, R:0.0071, T:0.5703(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.3240 (C:5.7933, R:0.0071, T:0.6106(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2956 (C:5.7671, R:0.0071, T:0.5835(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.3292 (C:5.7111, R:0.0071, T:0.6147(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2622 (C:5.7615, R:0.0071, T:0.5566(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2849 (C:5.7437, R:0.0071, T:0.5747(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2493 (C:5.7749, R:0.0071, T:0.5410(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2879 (C:5.7484, R:0.0071, T:0.5738(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.3054 (C:5.8119, R:0.0071, T:0.5933(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2785 (C:5.7355, R:0.0071, T:0.5722(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.3041 (C:5.8032, R:0.0071, T:0.5949(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2843 (C:5.7647, R:0.0071, T:0.5743(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2789 (C:5.7658, R:0.0070, T:0.5792(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2784 (C:5.7834, R:0.0071, T:0.5708(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2877 (C:5.7425, R:0.0071, T:0.5804(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2607 (C:5.8017, R:0.0071, T:0.5514(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5780

ğŸ“Š EPOCH 46 TRAINING SUMMARY:
  Total Loss: 1.2867
  Contrastive: 5.7650
  Reconstruction: 0.0071
  Topological: 0.5780 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9699
  Contrastive: 4.6847
  Reconstruction: 0.0063
  Topological: 4.3363 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 46/300 COMPLETE (39.6s)
Train Loss: 1.2867 (C:5.7650, R:0.0071, T:0.5780)
Val Loss:   4.9699 (C:4.6847, R:0.0063, T:4.3363)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 47 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2826 (C:5.8006, R:0.0071, T:0.5714(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.3049 (C:5.7408, R:0.0071, T:0.5959(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2955 (C:5.7955, R:0.0071, T:0.5898(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2628 (C:5.7648, R:0.0071, T:0.5533(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2445 (C:5.7373, R:0.0070, T:0.5399(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2990 (C:5.7805, R:0.0071, T:0.5891(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2965 (C:5.7358, R:0.0071, T:0.5824(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2822 (C:5.7637, R:0.0071, T:0.5717(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2570 (C:5.7992, R:0.0071, T:0.5478(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2552 (C:5.7937, R:0.0071, T:0.5430(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.3022 (C:5.8162, R:0.0071, T:0.5913(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2960 (C:5.7783, R:0.0071, T:0.5820(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2824 (C:5.7775, R:0.0071, T:0.5700(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2507 (C:5.7465, R:0.0070, T:0.5502(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2733 (C:5.7504, R:0.0071, T:0.5638(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2342 (C:5.7244, R:0.0070, T:0.5324(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2804 (C:5.8255, R:0.0071, T:0.5693(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2831 (C:5.7625, R:0.0071, T:0.5750(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2645 (C:5.7356, R:0.0071, T:0.5551(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2650 (C:5.7956, R:0.0072, T:0.5476(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.3167 (C:5.7909, R:0.0071, T:0.6028(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2788 (C:5.7562, R:0.0071, T:0.5724(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5751

ğŸ“Š EPOCH 47 TRAINING SUMMARY:
  Total Loss: 1.2834
  Contrastive: 5.7648
  Reconstruction: 0.0071
  Topological: 0.5751 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9836
  Contrastive: 4.6701
  Reconstruction: 0.0063
  Topological: 4.3500 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 47/300 COMPLETE (38.1s)
Train Loss: 1.2834 (C:5.7648, R:0.0071, T:0.5751)
Val Loss:   4.9836 (C:4.6701, R:0.0063, T:4.3500)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 48 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.3216 (C:5.7674, R:0.0071, T:0.6086(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.3031 (C:5.7673, R:0.0071, T:0.5926(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2540 (C:5.7862, R:0.0071, T:0.5485(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2368 (C:5.7883, R:0.0070, T:0.5356(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2662 (C:5.7054, R:0.0070, T:0.5656(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.3073 (C:5.7691, R:0.0071, T:0.5963(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2840 (C:5.7527, R:0.0071, T:0.5760(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.3282 (C:5.7848, R:0.0071, T:0.6138(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2624 (C:5.7970, R:0.0071, T:0.5551(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2893 (C:5.7601, R:0.0071, T:0.5812(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2638 (C:5.7315, R:0.0070, T:0.5640(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2931 (C:5.7833, R:0.0071, T:0.5803(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2654 (C:5.7448, R:0.0071, T:0.5562(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2941 (C:5.7764, R:0.0071, T:0.5799(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2497 (C:5.7538, R:0.0070, T:0.5466(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2916 (C:5.7759, R:0.0071, T:0.5823(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2772 (C:5.7844, R:0.0071, T:0.5671(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.3058 (C:5.7253, R:0.0071, T:0.5974(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2732 (C:5.8062, R:0.0071, T:0.5632(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2944 (C:5.7074, R:0.0071, T:0.5857(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2758 (C:5.7916, R:0.0070, T:0.5720(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2827 (C:5.7344, R:0.0071, T:0.5756(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 48 TRAINING SUMMARY:
  Total Loss: 1.2830
  Contrastive: 5.7641
  Reconstruction: 0.0071
  Topological: 0.5751 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0713
  Contrastive: 4.6796
  Reconstruction: 0.0063
  Topological: 4.4385 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 48/300 COMPLETE (38.6s)
Train Loss: 1.2830 (C:5.7641, R:0.0071, T:0.5751)
Val Loss:   5.0713 (C:4.6796, R:0.0063, T:4.4385)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 49 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.3086 (C:5.7463, R:0.0071, T:0.6029(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2810 (C:5.7783, R:0.0071, T:0.5698(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2980 (C:5.7396, R:0.0071, T:0.5870(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2536 (C:5.7269, R:0.0070, T:0.5525(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2909 (C:5.7616, R:0.0071, T:0.5834(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2572 (C:5.8119, R:0.0071, T:0.5501(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2983 (C:5.8012, R:0.0071, T:0.5887(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2769 (C:5.8179, R:0.0071, T:0.5695(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2613 (C:5.7043, R:0.0071, T:0.5540(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2924 (C:5.7817, R:0.0071, T:0.5848(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2783 (C:5.7483, R:0.0071, T:0.5718(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.3103 (C:5.7458, R:0.0070, T:0.6055(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2849 (C:5.7394, R:0.0070, T:0.5808(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.3063 (C:5.7343, R:0.0071, T:0.5960(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.3020 (C:5.7608, R:0.0071, T:0.5966(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2783 (C:5.7438, R:0.0071, T:0.5692(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.3051 (C:5.8060, R:0.0072, T:0.5891(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2933 (C:5.7602, R:0.0071, T:0.5834(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2607 (C:5.7319, R:0.0071, T:0.5557(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2761 (C:5.7485, R:0.0071, T:0.5680(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2643 (C:5.7924, R:0.0071, T:0.5512(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2942 (C:5.7405, R:0.0071, T:0.5865(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5728

ğŸ“Š EPOCH 49 TRAINING SUMMARY:
  Total Loss: 1.2805
  Contrastive: 5.7653
  Reconstruction: 0.0071
  Topological: 0.5728 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9571
  Contrastive: 4.6601
  Reconstruction: 0.0063
  Topological: 4.3242 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 49/300 COMPLETE (39.0s)
Train Loss: 1.2805 (C:5.7653, R:0.0071, T:0.5728)
Val Loss:   4.9571 (C:4.6601, R:0.0063, T:4.3242)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 50 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.3271 (C:5.7731, R:0.0071, T:0.6138(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2725 (C:5.7166, R:0.0071, T:0.5618(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2766 (C:5.7850, R:0.0071, T:0.5685(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.3045 (C:5.7459, R:0.0071, T:0.5920(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.3041 (C:5.7653, R:0.0071, T:0.5896(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2910 (C:5.7579, R:0.0071, T:0.5809(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.3026 (C:5.7502, R:0.0071, T:0.5906(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.3072 (C:5.7676, R:0.0071, T:0.5975(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2842 (C:5.7274, R:0.0070, T:0.5826(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2780 (C:5.7447, R:0.0071, T:0.5685(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2864 (C:5.7525, R:0.0071, T:0.5756(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2809 (C:5.7935, R:0.0071, T:0.5704(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2791 (C:5.7488, R:0.0071, T:0.5648(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2661 (C:5.7353, R:0.0071, T:0.5570(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2801 (C:5.7978, R:0.0071, T:0.5654(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2812 (C:5.8090, R:0.0071, T:0.5759(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2949 (C:5.8120, R:0.0071, T:0.5875(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2738 (C:5.7707, R:0.0071, T:0.5664(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2611 (C:5.7260, R:0.0071, T:0.5540(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2561 (C:5.7950, R:0.0071, T:0.5496(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.3013 (C:5.7817, R:0.0071, T:0.5938(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2952 (C:5.7220, R:0.0071, T:0.5840(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5715

ğŸ“Š EPOCH 50 TRAINING SUMMARY:
  Total Loss: 1.2789
  Contrastive: 5.7658
  Reconstruction: 0.0071
  Topological: 0.5715 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9605
  Contrastive: 4.6937
  Reconstruction: 0.0063
  Topological: 4.3283 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 50/300 COMPLETE (39.0s)
Train Loss: 1.2789 (C:5.7658, R:0.0071, T:0.5715)
Val Loss:   4.9605 (C:4.6937, R:0.0063, T:4.3283)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 51 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2657 (C:5.7568, R:0.0070, T:0.5651(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2733 (C:5.7843, R:0.0071, T:0.5652(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2638 (C:5.8108, R:0.0071, T:0.5541(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2691 (C:5.7347, R:0.0071, T:0.5585(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2703 (C:5.7710, R:0.0071, T:0.5621(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2953 (C:5.7920, R:0.0071, T:0.5897(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2540 (C:5.8296, R:0.0071, T:0.5463(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2746 (C:5.7612, R:0.0071, T:0.5657(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.3131 (C:5.7907, R:0.0071, T:0.6021(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2643 (C:5.7464, R:0.0071, T:0.5550(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2573 (C:5.7804, R:0.0070, T:0.5556(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2986 (C:5.7165, R:0.0071, T:0.5932(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.3075 (C:5.7787, R:0.0071, T:0.5971(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2635 (C:5.8082, R:0.0071, T:0.5548(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2751 (C:5.7439, R:0.0071, T:0.5638(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2669 (C:5.7505, R:0.0070, T:0.5645(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2576 (C:5.7663, R:0.0071, T:0.5511(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2792 (C:5.7767, R:0.0071, T:0.5703(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.3012 (C:5.7834, R:0.0071, T:0.5905(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2573 (C:5.7549, R:0.0071, T:0.5512(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2737 (C:5.7418, R:0.0070, T:0.5703(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2969 (C:5.7949, R:0.0071, T:0.5886(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 51 TRAINING SUMMARY:
  Total Loss: 1.2788
  Contrastive: 5.7666
  Reconstruction: 0.0071
  Topological: 0.5717 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9707
  Contrastive: 4.6506
  Reconstruction: 0.0063
  Topological: 4.3379 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 51/300 COMPLETE (38.8s)
Train Loss: 1.2788 (C:5.7666, R:0.0071, T:0.5717)
Val Loss:   4.9707 (C:4.6506, R:0.0063, T:4.3379)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 52 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2756 (C:5.7141, R:0.0070, T:0.5721(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2813 (C:5.7711, R:0.0071, T:0.5686(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2938 (C:5.7264, R:0.0071, T:0.5812(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2661 (C:5.7554, R:0.0071, T:0.5593(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2602 (C:5.8196, R:0.0071, T:0.5505(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2995 (C:5.7125, R:0.0070, T:0.5963(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2602 (C:5.7876, R:0.0071, T:0.5540(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2671 (C:5.7582, R:0.0070, T:0.5622(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2819 (C:5.7324, R:0.0071, T:0.5745(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2494 (C:5.7785, R:0.0071, T:0.5399(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2772 (C:5.7698, R:0.0070, T:0.5725(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2883 (C:5.8048, R:0.0071, T:0.5747(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2498 (C:5.7675, R:0.0070, T:0.5451(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2681 (C:5.7528, R:0.0071, T:0.5608(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2587 (C:5.7553, R:0.0070, T:0.5614(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2951 (C:5.7246, R:0.0071, T:0.5867(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2862 (C:5.7559, R:0.0070, T:0.5814(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2218 (C:5.7474, R:0.0070, T:0.5181(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2790 (C:5.7907, R:0.0071, T:0.5694(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2588 (C:5.7650, R:0.0071, T:0.5515(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2603 (C:5.7779, R:0.0071, T:0.5505(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2898 (C:5.7716, R:0.0071, T:0.5800(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5701

ğŸ“Š EPOCH 52 TRAINING SUMMARY:
  Total Loss: 1.2765
  Contrastive: 5.7644
  Reconstruction: 0.0071
  Topological: 0.5701 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9167
  Contrastive: 4.6845
  Reconstruction: 0.0063
  Topological: 4.2856 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 52/300 COMPLETE (40.0s)
Train Loss: 1.2765 (C:5.7644, R:0.0071, T:0.5701)
Val Loss:   4.9167 (C:4.6845, R:0.0063, T:4.2856)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 53 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2705 (C:5.7249, R:0.0070, T:0.5663(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2891 (C:5.7339, R:0.0071, T:0.5796(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2363 (C:5.7579, R:0.0071, T:0.5248(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2580 (C:5.7102, R:0.0071, T:0.5529(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2976 (C:5.7728, R:0.0071, T:0.5877(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2721 (C:5.7909, R:0.0071, T:0.5666(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2996 (C:5.7818, R:0.0071, T:0.5914(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2622 (C:5.7228, R:0.0071, T:0.5558(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2729 (C:5.7688, R:0.0071, T:0.5641(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2774 (C:5.7803, R:0.0071, T:0.5703(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2807 (C:5.7945, R:0.0071, T:0.5730(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2829 (C:5.7744, R:0.0071, T:0.5724(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2409 (C:5.7364, R:0.0071, T:0.5353(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2744 (C:5.7623, R:0.0071, T:0.5688(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2530 (C:5.7560, R:0.0070, T:0.5512(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2869 (C:5.7502, R:0.0070, T:0.5820(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2760 (C:5.7774, R:0.0071, T:0.5665(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2646 (C:5.7742, R:0.0071, T:0.5574(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2882 (C:5.7803, R:0.0071, T:0.5771(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2653 (C:5.7737, R:0.0071, T:0.5571(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2786 (C:5.7919, R:0.0071, T:0.5708(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2537 (C:5.7773, R:0.0070, T:0.5520(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5700

ğŸ“Š EPOCH 53 TRAINING SUMMARY:
  Total Loss: 1.2765
  Contrastive: 5.7649
  Reconstruction: 0.0071
  Topological: 0.5700 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8505
  Contrastive: 4.6945
  Reconstruction: 0.0063
  Topological: 4.2194 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 53/300 COMPLETE (38.6s)
Train Loss: 1.2765 (C:5.7649, R:0.0071, T:0.5700)
Val Loss:   4.8505 (C:4.6945, R:0.0063, T:4.2194)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 54 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2664 (C:5.7617, R:0.0071, T:0.5598(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.3105 (C:5.8222, R:0.0071, T:0.6036(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2713 (C:5.7699, R:0.0071, T:0.5640(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2606 (C:5.7826, R:0.0070, T:0.5586(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2945 (C:5.7408, R:0.0071, T:0.5853(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2786 (C:5.7825, R:0.0071, T:0.5675(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2636 (C:5.7241, R:0.0070, T:0.5608(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2855 (C:5.7474, R:0.0071, T:0.5745(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2656 (C:5.7760, R:0.0071, T:0.5590(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2452 (C:5.7714, R:0.0071, T:0.5372(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2579 (C:5.7275, R:0.0071, T:0.5497(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2675 (C:5.8091, R:0.0070, T:0.5658(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2622 (C:5.7888, R:0.0070, T:0.5619(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2942 (C:5.7236, R:0.0070, T:0.5906(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2801 (C:5.7487, R:0.0071, T:0.5749(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2824 (C:5.7708, R:0.0071, T:0.5717(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2955 (C:5.7211, R:0.0070, T:0.5910(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.3016 (C:5.7285, R:0.0071, T:0.5895(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2703 (C:5.7662, R:0.0070, T:0.5678(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2942 (C:5.7810, R:0.0071, T:0.5866(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2788 (C:5.8021, R:0.0071, T:0.5726(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2683 (C:5.7634, R:0.0070, T:0.5658(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5687

ğŸ“Š EPOCH 54 TRAINING SUMMARY:
  Total Loss: 1.2747
  Contrastive: 5.7650
  Reconstruction: 0.0071
  Topological: 0.5687 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0585
  Contrastive: 4.6425
  Reconstruction: 0.0063
  Topological: 4.4259 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 54/300 COMPLETE (38.7s)
Train Loss: 1.2747 (C:5.7650, R:0.0071, T:0.5687)
Val Loss:   5.0585 (C:4.6425, R:0.0063, T:4.4259)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 55 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2874 (C:5.6837, R:0.0070, T:0.5856(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2595 (C:5.8404, R:0.0071, T:0.5518(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2624 (C:5.7593, R:0.0070, T:0.5655(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2748 (C:5.7259, R:0.0070, T:0.5700(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.3049 (C:5.7717, R:0.0071, T:0.5968(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.3260 (C:5.7463, R:0.0071, T:0.6207(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2811 (C:5.7795, R:0.0070, T:0.5780(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.3195 (C:5.7713, R:0.0071, T:0.6073(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2713 (C:5.7593, R:0.0070, T:0.5681(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2802 (C:5.7425, R:0.0071, T:0.5732(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2697 (C:5.8106, R:0.0071, T:0.5610(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2728 (C:5.7200, R:0.0071, T:0.5674(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.3182 (C:5.7916, R:0.0071, T:0.6079(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2567 (C:5.7900, R:0.0070, T:0.5519(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2723 (C:5.7445, R:0.0070, T:0.5683(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2498 (C:5.7250, R:0.0070, T:0.5481(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2970 (C:5.7971, R:0.0071, T:0.5902(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2324 (C:5.7423, R:0.0070, T:0.5300(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.3017 (C:5.7760, R:0.0071, T:0.5929(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2515 (C:5.7808, R:0.0070, T:0.5497(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2580 (C:5.7734, R:0.0070, T:0.5556(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2478 (C:5.7465, R:0.0070, T:0.5457(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5679

ğŸ“Š EPOCH 55 TRAINING SUMMARY:
  Total Loss: 1.2735
  Contrastive: 5.7644
  Reconstruction: 0.0071
  Topological: 0.5679 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9039
  Contrastive: 4.6947
  Reconstruction: 0.0063
  Topological: 4.2741 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 55/300 COMPLETE (39.2s)
Train Loss: 1.2735 (C:5.7644, R:0.0071, T:0.5679)
Val Loss:   4.9039 (C:4.6947, R:0.0063, T:4.2741)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 56 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2705 (C:5.7605, R:0.0070, T:0.5664(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2443 (C:5.8265, R:0.0070, T:0.5413(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2372 (C:5.7636, R:0.0070, T:0.5390(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2297 (C:5.7827, R:0.0070, T:0.5320(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2698 (C:5.7685, R:0.0070, T:0.5655(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2552 (C:5.8205, R:0.0070, T:0.5524(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2648 (C:5.7443, R:0.0070, T:0.5604(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2451 (C:5.8138, R:0.0070, T:0.5411(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2768 (C:5.8105, R:0.0071, T:0.5693(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2734 (C:5.7792, R:0.0071, T:0.5626(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2745 (C:5.7353, R:0.0071, T:0.5689(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2649 (C:5.8182, R:0.0071, T:0.5541(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2979 (C:5.7872, R:0.0071, T:0.5849(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2496 (C:5.7724, R:0.0071, T:0.5398(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2604 (C:5.7630, R:0.0070, T:0.5599(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2614 (C:5.7674, R:0.0071, T:0.5545(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2580 (C:5.8031, R:0.0071, T:0.5519(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2541 (C:5.7567, R:0.0071, T:0.5474(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2563 (C:5.7707, R:0.0070, T:0.5550(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2737 (C:5.8177, R:0.0070, T:0.5727(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2515 (C:5.7904, R:0.0071, T:0.5426(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2846 (C:5.7613, R:0.0070, T:0.5801(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 56 TRAINING SUMMARY:
  Total Loss: 1.2739
  Contrastive: 5.7656
  Reconstruction: 0.0071
  Topological: 0.5682 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8766
  Contrastive: 4.6891
  Reconstruction: 0.0063
  Topological: 4.2458 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 56/300 COMPLETE (38.4s)
Train Loss: 1.2739 (C:5.7656, R:0.0071, T:0.5682)
Val Loss:   4.8766 (C:4.6891, R:0.0063, T:4.2458)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 57 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2584 (C:5.7187, R:0.0070, T:0.5565(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2521 (C:5.7883, R:0.0071, T:0.5445(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2424 (C:5.7728, R:0.0070, T:0.5419(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2643 (C:5.7577, R:0.0071, T:0.5554(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2827 (C:5.7832, R:0.0071, T:0.5774(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2614 (C:5.7823, R:0.0070, T:0.5577(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2585 (C:5.6977, R:0.0070, T:0.5570(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2671 (C:5.7465, R:0.0071, T:0.5593(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2738 (C:5.7543, R:0.0071, T:0.5665(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2561 (C:5.8094, R:0.0071, T:0.5491(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2966 (C:5.8152, R:0.0070, T:0.5951(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2672 (C:5.7775, R:0.0071, T:0.5589(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2678 (C:5.7966, R:0.0070, T:0.5651(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2697 (C:5.7428, R:0.0070, T:0.5648(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2983 (C:5.7289, R:0.0070, T:0.5941(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2661 (C:5.7573, R:0.0071, T:0.5605(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2787 (C:5.7899, R:0.0071, T:0.5722(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2702 (C:5.7354, R:0.0071, T:0.5631(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2677 (C:5.8049, R:0.0070, T:0.5627(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2780 (C:5.7558, R:0.0071, T:0.5694(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2423 (C:5.7911, R:0.0071, T:0.5358(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2208 (C:5.7924, R:0.0070, T:0.5183(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5664

ğŸ“Š EPOCH 57 TRAINING SUMMARY:
  Total Loss: 1.2718
  Contrastive: 5.7654
  Reconstruction: 0.0071
  Topological: 0.5664 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.7898
  Contrastive: 4.7140
  Reconstruction: 0.0063
  Topological: 4.1595 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 57/300 COMPLETE (39.0s)
Train Loss: 1.2718 (C:5.7654, R:0.0071, T:0.5664)
Val Loss:   4.7898 (C:4.7140, R:0.0063, T:4.1595)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 58 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2665 (C:5.7775, R:0.0071, T:0.5573(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2494 (C:5.7416, R:0.0070, T:0.5481(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2739 (C:5.7446, R:0.0070, T:0.5714(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2705 (C:5.8022, R:0.0070, T:0.5749(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2635 (C:5.7025, R:0.0070, T:0.5619(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2742 (C:5.7842, R:0.0070, T:0.5702(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2865 (C:5.7543, R:0.0071, T:0.5744(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2910 (C:5.7792, R:0.0070, T:0.5893(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.3034 (C:5.7982, R:0.0071, T:0.5977(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.3003 (C:5.7765, R:0.0071, T:0.5910(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2648 (C:5.7166, R:0.0070, T:0.5627(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2634 (C:5.7342, R:0.0071, T:0.5565(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2601 (C:5.7524, R:0.0070, T:0.5613(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2536 (C:5.7868, R:0.0071, T:0.5451(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2752 (C:5.7600, R:0.0071, T:0.5692(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2864 (C:5.7774, R:0.0071, T:0.5776(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2633 (C:5.7500, R:0.0071, T:0.5564(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2668 (C:5.7265, R:0.0071, T:0.5600(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2735 (C:5.7746, R:0.0070, T:0.5712(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2634 (C:5.7619, R:0.0071, T:0.5574(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2536 (C:5.7343, R:0.0070, T:0.5488(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2546 (C:5.7773, R:0.0071, T:0.5491(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5654

ğŸ“Š EPOCH 58 TRAINING SUMMARY:
  Total Loss: 1.2706
  Contrastive: 5.7632
  Reconstruction: 0.0071
  Topological: 0.5654 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8570
  Contrastive: 4.6888
  Reconstruction: 0.0063
  Topological: 4.2269 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 58/300 COMPLETE (38.6s)
Train Loss: 1.2706 (C:5.7632, R:0.0071, T:0.5654)
Val Loss:   4.8570 (C:4.6888, R:0.0063, T:4.2269)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 59 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.3000 (C:5.7633, R:0.0071, T:0.5938(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2777 (C:5.7466, R:0.0071, T:0.5686(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2973 (C:5.7987, R:0.0070, T:0.5950(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2639 (C:5.8070, R:0.0070, T:0.5619(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2890 (C:5.7377, R:0.0071, T:0.5789(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.3009 (C:5.7929, R:0.0071, T:0.5904(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2574 (C:5.8114, R:0.0071, T:0.5467(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2753 (C:5.7943, R:0.0071, T:0.5655(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2436 (C:5.7774, R:0.0070, T:0.5398(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2633 (C:5.7866, R:0.0070, T:0.5603(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2589 (C:5.7491, R:0.0070, T:0.5553(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2920 (C:5.8334, R:0.0071, T:0.5850(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2862 (C:5.7107, R:0.0071, T:0.5793(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.3017 (C:5.7922, R:0.0071, T:0.5915(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2715 (C:5.6981, R:0.0070, T:0.5695(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2876 (C:5.7424, R:0.0070, T:0.5879(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2708 (C:5.7700, R:0.0070, T:0.5669(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2864 (C:5.7913, R:0.0071, T:0.5814(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2633 (C:5.7610, R:0.0071, T:0.5573(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2418 (C:5.7748, R:0.0070, T:0.5371(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2676 (C:5.7653, R:0.0070, T:0.5658(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2377 (C:5.7497, R:0.0070, T:0.5339(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5637

ğŸ“Š EPOCH 59 TRAINING SUMMARY:
  Total Loss: 1.2687
  Contrastive: 5.7658
  Reconstruction: 0.0070
  Topological: 0.5637 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8435
  Contrastive: 4.7040
  Reconstruction: 0.0063
  Topological: 4.2128 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 59/300 COMPLETE (40.0s)
Train Loss: 1.2687 (C:5.7658, R:0.0070, T:0.5637)
Val Loss:   4.8435 (C:4.7040, R:0.0063, T:4.2128)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 60 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2370 (C:5.7597, R:0.0070, T:0.5338(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2918 (C:5.7441, R:0.0071, T:0.5837(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2865 (C:5.7963, R:0.0071, T:0.5722(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2822 (C:5.7816, R:0.0070, T:0.5784(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2399 (C:5.7464, R:0.0071, T:0.5316(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2860 (C:5.7338, R:0.0070, T:0.5858(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2384 (C:5.7651, R:0.0070, T:0.5364(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2341 (C:5.7794, R:0.0070, T:0.5316(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2553 (C:5.7560, R:0.0071, T:0.5490(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2694 (C:5.7827, R:0.0070, T:0.5700(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2565 (C:5.7335, R:0.0070, T:0.5544(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2892 (C:5.7177, R:0.0071, T:0.5824(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2906 (C:5.7830, R:0.0071, T:0.5848(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2581 (C:5.7862, R:0.0071, T:0.5502(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2580 (C:5.8165, R:0.0071, T:0.5527(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2469 (C:5.7488, R:0.0071, T:0.5417(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2671 (C:5.7712, R:0.0071, T:0.5600(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2582 (C:5.8156, R:0.0071, T:0.5502(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2499 (C:5.7443, R:0.0071, T:0.5428(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2351 (C:5.8089, R:0.0070, T:0.5318(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2614 (C:5.7656, R:0.0071, T:0.5538(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2688 (C:5.6906, R:0.0070, T:0.5689(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 60 TRAINING SUMMARY:
  Total Loss: 1.2684
  Contrastive: 5.7666
  Reconstruction: 0.0070
  Topological: 0.5638 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.7612
  Contrastive: 4.7205
  Reconstruction: 0.0063
  Topological: 4.1328 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 60/300 COMPLETE (38.7s)
Train Loss: 1.2684 (C:5.7666, R:0.0070, T:0.5638)
Val Loss:   4.7612 (C:4.7205, R:0.0063, T:4.1328)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 61 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2668 (C:5.7576, R:0.0070, T:0.5697(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.3067 (C:5.7815, R:0.0071, T:0.5994(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2381 (C:5.7946, R:0.0071, T:0.5316(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2866 (C:5.7248, R:0.0071, T:0.5808(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2336 (C:5.8212, R:0.0070, T:0.5314(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2525 (C:5.8273, R:0.0070, T:0.5539(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2739 (C:5.8115, R:0.0070, T:0.5701(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2806 (C:5.7287, R:0.0070, T:0.5761(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2707 (C:5.7805, R:0.0070, T:0.5675(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2285 (C:5.7304, R:0.0070, T:0.5268(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2599 (C:5.7638, R:0.0071, T:0.5486(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2424 (C:5.7483, R:0.0070, T:0.5377(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2478 (C:5.7779, R:0.0070, T:0.5433(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2842 (C:5.7518, R:0.0070, T:0.5831(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2734 (C:5.7624, R:0.0070, T:0.5703(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2884 (C:5.8071, R:0.0070, T:0.5849(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2875 (C:5.7761, R:0.0071, T:0.5782(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2974 (C:5.7442, R:0.0070, T:0.5944(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2433 (C:5.7299, R:0.0071, T:0.5351(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2343 (C:5.7821, R:0.0070, T:0.5328(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.3161 (C:5.7009, R:0.0071, T:0.6109(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2900 (C:5.7628, R:0.0071, T:0.5843(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5635

ğŸ“Š EPOCH 61 TRAINING SUMMARY:
  Total Loss: 1.2682
  Contrastive: 5.7652
  Reconstruction: 0.0070
  Topological: 0.5635 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.7952
  Contrastive: 4.7158
  Reconstruction: 0.0063
  Topological: 4.1655 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 61/300 COMPLETE (39.1s)
Train Loss: 1.2682 (C:5.7652, R:0.0070, T:0.5635)
Val Loss:   4.7952 (C:4.7158, R:0.0063, T:4.1655)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 62 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2584 (C:5.7527, R:0.0070, T:0.5541(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2552 (C:5.7493, R:0.0070, T:0.5532(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2711 (C:5.7609, R:0.0070, T:0.5681(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2401 (C:5.7737, R:0.0070, T:0.5372(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2530 (C:5.7749, R:0.0071, T:0.5477(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2635 (C:5.7884, R:0.0071, T:0.5542(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2945 (C:5.7927, R:0.0071, T:0.5825(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2743 (C:5.8035, R:0.0070, T:0.5696(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2770 (C:5.7643, R:0.0071, T:0.5716(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2459 (C:5.7510, R:0.0070, T:0.5434(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2442 (C:5.7937, R:0.0071, T:0.5376(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2521 (C:5.8027, R:0.0071, T:0.5430(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2558 (C:5.8069, R:0.0070, T:0.5517(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2328 (C:5.7599, R:0.0070, T:0.5299(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2696 (C:5.7667, R:0.0070, T:0.5677(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2806 (C:5.7534, R:0.0070, T:0.5802(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2601 (C:5.8037, R:0.0070, T:0.5564(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2460 (C:5.7887, R:0.0070, T:0.5419(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2467 (C:5.7836, R:0.0070, T:0.5452(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2562 (C:5.7313, R:0.0070, T:0.5535(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2574 (C:5.6643, R:0.0070, T:0.5621(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2622 (C:5.7678, R:0.0070, T:0.5579(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5606

ğŸ“Š EPOCH 62 TRAINING SUMMARY:
  Total Loss: 1.2648
  Contrastive: 5.7653
  Reconstruction: 0.0070
  Topological: 0.5606 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.6285
  Contrastive: 4.7460
  Reconstruction: 0.0063
  Topological: 4.0006 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 62/300 COMPLETE (40.0s)
Train Loss: 1.2648 (C:5.7653, R:0.0070, T:0.5606)
Val Loss:   4.6285 (C:4.7460, R:0.0063, T:4.0006)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 63 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2689 (C:5.8086, R:0.0070, T:0.5677(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.3153 (C:5.7257, R:0.0071, T:0.6050(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2387 (C:5.8225, R:0.0070, T:0.5366(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2447 (C:5.7348, R:0.0070, T:0.5453(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2641 (C:5.7920, R:0.0070, T:0.5613(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2311 (C:5.7454, R:0.0070, T:0.5310(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2655 (C:5.7445, R:0.0070, T:0.5627(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2567 (C:5.7609, R:0.0070, T:0.5559(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2678 (C:5.8097, R:0.0070, T:0.5642(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2970 (C:5.7516, R:0.0071, T:0.5858(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2526 (C:5.7965, R:0.0070, T:0.5527(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.3107 (C:5.7300, R:0.0071, T:0.6050(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2634 (C:5.7486, R:0.0070, T:0.5611(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2433 (C:5.7869, R:0.0070, T:0.5434(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2428 (C:5.7836, R:0.0071, T:0.5369(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2430 (C:5.7747, R:0.0071, T:0.5348(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2482 (C:5.8045, R:0.0070, T:0.5468(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.3080 (C:5.7389, R:0.0070, T:0.6039(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2501 (C:5.7701, R:0.0070, T:0.5457(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2487 (C:5.7987, R:0.0071, T:0.5414(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2792 (C:5.7026, R:0.0071, T:0.5694(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.3088 (C:5.7767, R:0.0071, T:0.6035(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5600

ğŸ“Š EPOCH 63 TRAINING SUMMARY:
  Total Loss: 1.2641
  Contrastive: 5.7665
  Reconstruction: 0.0070
  Topological: 0.5600 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.6877
  Contrastive: 4.7009
  Reconstruction: 0.0063
  Topological: 4.0576 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 63/300 COMPLETE (38.0s)
Train Loss: 1.2641 (C:5.7665, R:0.0070, T:0.5600)
Val Loss:   4.6877 (C:4.7009, R:0.0063, T:4.0576)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 64 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2851 (C:5.7512, R:0.0070, T:0.5807(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2589 (C:5.8068, R:0.0070, T:0.5583(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2409 (C:5.7893, R:0.0070, T:0.5389(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2494 (C:5.8098, R:0.0070, T:0.5509(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2637 (C:5.8025, R:0.0070, T:0.5654(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2872 (C:5.7884, R:0.0070, T:0.5884(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2808 (C:5.7380, R:0.0071, T:0.5743(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2528 (C:5.7122, R:0.0071, T:0.5434(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2536 (C:5.7735, R:0.0070, T:0.5522(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2520 (C:5.7875, R:0.0071, T:0.5455(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2466 (C:5.7552, R:0.0070, T:0.5481(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2792 (C:5.7363, R:0.0070, T:0.5764(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2598 (C:5.7628, R:0.0070, T:0.5574(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2384 (C:5.7381, R:0.0070, T:0.5367(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2573 (C:5.8113, R:0.0071, T:0.5473(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2594 (C:5.7951, R:0.0070, T:0.5569(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2532 (C:5.7437, R:0.0070, T:0.5524(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2738 (C:5.7667, R:0.0070, T:0.5733(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2600 (C:5.7846, R:0.0070, T:0.5551(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2393 (C:5.7454, R:0.0071, T:0.5336(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2687 (C:5.7565, R:0.0070, T:0.5659(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.3131 (C:5.7572, R:0.0070, T:0.6113(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 64 TRAINING SUMMARY:
  Total Loss: 1.2657
  Contrastive: 5.7665
  Reconstruction: 0.0070
  Topological: 0.5618 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.7610
  Contrastive: 4.7092
  Reconstruction: 0.0063
  Topological: 4.1319 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 64/300 COMPLETE (39.5s)
Train Loss: 1.2657 (C:5.7665, R:0.0070, T:0.5618)
Val Loss:   4.7610 (C:4.7092, R:0.0063, T:4.1319)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 65 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2907 (C:5.7298, R:0.0070, T:0.5875(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2635 (C:5.7533, R:0.0070, T:0.5607(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2406 (C:5.7479, R:0.0070, T:0.5436(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2502 (C:5.7422, R:0.0070, T:0.5501(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2362 (C:5.7588, R:0.0070, T:0.5391(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2676 (C:5.8238, R:0.0070, T:0.5636(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2448 (C:5.7342, R:0.0071, T:0.5395(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2840 (C:5.7613, R:0.0070, T:0.5793(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2535 (C:5.7622, R:0.0070, T:0.5530(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2525 (C:5.7503, R:0.0070, T:0.5505(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2560 (C:5.8000, R:0.0070, T:0.5522(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2506 (C:5.7656, R:0.0070, T:0.5464(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2624 (C:5.7847, R:0.0070, T:0.5609(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2494 (C:5.7550, R:0.0071, T:0.5418(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2405 (C:5.7560, R:0.0070, T:0.5408(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2775 (C:5.7562, R:0.0070, T:0.5740(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2476 (C:5.7159, R:0.0070, T:0.5468(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2398 (C:5.7778, R:0.0070, T:0.5361(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2546 (C:5.7556, R:0.0070, T:0.5504(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2683 (C:5.7453, R:0.0070, T:0.5676(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2901 (C:5.7416, R:0.0071, T:0.5832(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2438 (C:5.7709, R:0.0070, T:0.5421(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5586

ğŸ“Š EPOCH 65 TRAINING SUMMARY:
  Total Loss: 1.2619
  Contrastive: 5.7673
  Reconstruction: 0.0070
  Topological: 0.5586 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.6450
  Contrastive: 4.7346
  Reconstruction: 0.0063
  Topological: 4.0164 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 65/300 COMPLETE (39.3s)
Train Loss: 1.2619 (C:5.7673, R:0.0070, T:0.5586)
Val Loss:   4.6450 (C:4.7346, R:0.0063, T:4.0164)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 66 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2831 (C:5.7786, R:0.0071, T:0.5723(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2607 (C:5.8165, R:0.0070, T:0.5601(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2341 (C:5.8118, R:0.0070, T:0.5333(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2765 (C:5.6960, R:0.0070, T:0.5800(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2599 (C:5.7672, R:0.0070, T:0.5550(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2476 (C:5.7344, R:0.0070, T:0.5465(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2439 (C:5.7866, R:0.0070, T:0.5396(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2588 (C:5.7956, R:0.0070, T:0.5629(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2861 (C:5.7156, R:0.0071, T:0.5770(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2617 (C:5.7941, R:0.0070, T:0.5584(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2406 (C:5.7328, R:0.0070, T:0.5374(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2546 (C:5.7630, R:0.0071, T:0.5468(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2773 (C:5.8002, R:0.0071, T:0.5715(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2771 (C:5.7959, R:0.0070, T:0.5773(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2632 (C:5.7426, R:0.0070, T:0.5641(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2497 (C:5.7691, R:0.0070, T:0.5494(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2667 (C:5.7526, R:0.0071, T:0.5610(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2726 (C:5.7617, R:0.0070, T:0.5703(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2731 (C:5.7158, R:0.0071, T:0.5677(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2318 (C:5.8128, R:0.0070, T:0.5346(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2309 (C:5.7260, R:0.0070, T:0.5286(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2525 (C:5.7866, R:0.0071, T:0.5456(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 66 TRAINING SUMMARY:
  Total Loss: 1.2632
  Contrastive: 5.7666
  Reconstruction: 0.0070
  Topological: 0.5599 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.7243
  Contrastive: 4.6922
  Reconstruction: 0.0063
  Topological: 4.0957 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 66/300 COMPLETE (38.9s)
Train Loss: 1.2632 (C:5.7666, R:0.0070, T:0.5599)
Val Loss:   4.7243 (C:4.6922, R:0.0063, T:4.0957)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 67 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2669 (C:5.7107, R:0.0070, T:0.5630(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2818 (C:5.7779, R:0.0071, T:0.5768(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2482 (C:5.7644, R:0.0070, T:0.5457(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2572 (C:5.7608, R:0.0070, T:0.5543(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2975 (C:5.7539, R:0.0070, T:0.5940(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2768 (C:5.7713, R:0.0071, T:0.5717(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2542 (C:5.7595, R:0.0071, T:0.5455(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2469 (C:5.7498, R:0.0070, T:0.5449(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2797 (C:5.7424, R:0.0071, T:0.5743(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2916 (C:5.7378, R:0.0070, T:0.5886(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2659 (C:5.7161, R:0.0070, T:0.5652(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2788 (C:5.7323, R:0.0071, T:0.5728(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2625 (C:5.7411, R:0.0071, T:0.5524(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2550 (C:5.7626, R:0.0070, T:0.5521(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2782 (C:5.7482, R:0.0070, T:0.5754(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2541 (C:5.7981, R:0.0070, T:0.5504(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2680 (C:5.7858, R:0.0070, T:0.5630(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2671 (C:5.7142, R:0.0070, T:0.5643(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2909 (C:5.7724, R:0.0071, T:0.5854(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2715 (C:5.7554, R:0.0070, T:0.5700(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2802 (C:5.7105, R:0.0071, T:0.5718(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2559 (C:5.7795, R:0.0070, T:0.5559(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 67 TRAINING SUMMARY:
  Total Loss: 1.2621
  Contrastive: 5.7667
  Reconstruction: 0.0070
  Topological: 0.5587 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.5550
  Contrastive: 4.7587
  Reconstruction: 0.0063
  Topological: 3.9284 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 67/300 COMPLETE (39.0s)
Train Loss: 1.2621 (C:5.7667, R:0.0070, T:0.5587)
Val Loss:   4.5550 (C:4.7587, R:0.0063, T:3.9284)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 68 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2431 (C:5.7881, R:0.0070, T:0.5435(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2399 (C:5.8342, R:0.0070, T:0.5395(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2439 (C:5.7670, R:0.0070, T:0.5400(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2515 (C:5.7718, R:0.0070, T:0.5470(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2710 (C:5.7410, R:0.0070, T:0.5699(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2282 (C:5.7295, R:0.0070, T:0.5298(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2567 (C:5.7300, R:0.0070, T:0.5567(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2570 (C:5.7204, R:0.0070, T:0.5540(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2290 (C:5.7762, R:0.0070, T:0.5305(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2442 (C:5.7170, R:0.0070, T:0.5470(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2712 (C:5.7699, R:0.0070, T:0.5677(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2269 (C:5.7342, R:0.0070, T:0.5251(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2979 (C:5.8616, R:0.0071, T:0.5910(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2432 (C:5.7692, R:0.0070, T:0.5443(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2227 (C:5.7370, R:0.0070, T:0.5258(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2381 (C:5.7304, R:0.0070, T:0.5358(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2825 (C:5.7643, R:0.0070, T:0.5814(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2919 (C:5.8163, R:0.0071, T:0.5857(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2831 (C:5.8235, R:0.0071, T:0.5748(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2731 (C:5.7852, R:0.0070, T:0.5709(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2557 (C:5.7671, R:0.0070, T:0.5528(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2878 (C:5.7344, R:0.0071, T:0.5815(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5574

ğŸ“Š EPOCH 68 TRAINING SUMMARY:
  Total Loss: 1.2601
  Contrastive: 5.7657
  Reconstruction: 0.0070
  Topological: 0.5574 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.5314
  Contrastive: 4.7649
  Reconstruction: 0.0063
  Topological: 3.9053 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 68/300 COMPLETE (39.5s)
Train Loss: 1.2601 (C:5.7657, R:0.0070, T:0.5574)
Val Loss:   4.5314 (C:4.7649, R:0.0063, T:3.9053)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 69 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2713 (C:5.8003, R:0.0070, T:0.5697(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2813 (C:5.7097, R:0.0071, T:0.5723(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2822 (C:5.8016, R:0.0071, T:0.5740(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2764 (C:5.7569, R:0.0070, T:0.5725(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2694 (C:5.8057, R:0.0070, T:0.5679(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2657 (C:5.7329, R:0.0070, T:0.5661(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2385 (C:5.7934, R:0.0070, T:0.5380(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2465 (C:5.7941, R:0.0070, T:0.5480(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2726 (C:5.7389, R:0.0071, T:0.5669(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2492 (C:5.7761, R:0.0070, T:0.5455(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2773 (C:5.7767, R:0.0070, T:0.5726(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2699 (C:5.7642, R:0.0070, T:0.5684(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2610 (C:5.7953, R:0.0070, T:0.5642(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2566 (C:5.7686, R:0.0070, T:0.5554(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2552 (C:5.7974, R:0.0070, T:0.5589(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2790 (C:5.7585, R:0.0070, T:0.5768(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2328 (C:5.7385, R:0.0070, T:0.5351(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2750 (C:5.8039, R:0.0070, T:0.5719(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2401 (C:5.7805, R:0.0071, T:0.5351(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2902 (C:5.7448, R:0.0070, T:0.5862(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2461 (C:5.7527, R:0.0069, T:0.5514(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2624 (C:5.7784, R:0.0071, T:0.5551(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5567

ğŸ“Š EPOCH 69 TRAINING SUMMARY:
  Total Loss: 1.2593
  Contrastive: 5.7672
  Reconstruction: 0.0070
  Topological: 0.5567 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.6890
  Contrastive: 4.7117
  Reconstruction: 0.0063
  Topological: 4.0609 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 69/300 COMPLETE (38.7s)
Train Loss: 1.2593 (C:5.7672, R:0.0070, T:0.5567)
Val Loss:   4.6890 (C:4.7117, R:0.0063, T:4.0609)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 70 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2911 (C:5.7426, R:0.0071, T:0.5825(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2546 (C:5.7403, R:0.0071, T:0.5464(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2543 (C:5.7232, R:0.0070, T:0.5521(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2375 (C:5.7729, R:0.0070, T:0.5329(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2432 (C:5.7501, R:0.0070, T:0.5442(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2430 (C:5.7523, R:0.0071, T:0.5356(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2845 (C:5.7839, R:0.0071, T:0.5793(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2827 (C:5.7399, R:0.0070, T:0.5803(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2735 (C:5.7741, R:0.0070, T:0.5691(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2706 (C:5.7201, R:0.0071, T:0.5656(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2533 (C:5.7791, R:0.0070, T:0.5502(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2764 (C:5.7463, R:0.0071, T:0.5687(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2853 (C:5.7686, R:0.0070, T:0.5868(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2374 (C:5.7389, R:0.0070, T:0.5406(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2825 (C:5.7923, R:0.0070, T:0.5805(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2465 (C:5.7974, R:0.0070, T:0.5446(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2673 (C:5.7570, R:0.0070, T:0.5640(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2718 (C:5.8293, R:0.0071, T:0.5655(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2180 (C:5.7977, R:0.0070, T:0.5189(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2470 (C:5.7463, R:0.0070, T:0.5465(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2313 (C:5.7658, R:0.0070, T:0.5282(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2700 (C:5.7842, R:0.0070, T:0.5672(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5554

ğŸ“Š EPOCH 70 TRAINING SUMMARY:
  Total Loss: 1.2579
  Contrastive: 5.7682
  Reconstruction: 0.0070
  Topological: 0.5554 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8124
  Contrastive: 4.6810
  Reconstruction: 0.0063
  Topological: 4.1838 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 70/300 COMPLETE (38.2s)
Train Loss: 1.2579 (C:5.7682, R:0.0070, T:0.5554)
Val Loss:   4.8124 (C:4.6810, R:0.0063, T:4.1838)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 71 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2891 (C:5.7139, R:0.0070, T:0.5908(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2691 (C:5.7775, R:0.0070, T:0.5697(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2384 (C:5.7866, R:0.0070, T:0.5339(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2645 (C:5.7736, R:0.0070, T:0.5629(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2669 (C:5.7602, R:0.0070, T:0.5656(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2850 (C:5.7732, R:0.0070, T:0.5801(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2748 (C:5.7629, R:0.0070, T:0.5731(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2452 (C:5.7902, R:0.0071, T:0.5397(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2560 (C:5.8008, R:0.0070, T:0.5526(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2695 (C:5.7700, R:0.0070, T:0.5675(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2590 (C:5.7560, R:0.0071, T:0.5538(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2963 (C:5.7381, R:0.0071, T:0.5904(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2346 (C:5.7843, R:0.0070, T:0.5310(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2468 (C:5.7017, R:0.0070, T:0.5477(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2524 (C:5.7273, R:0.0070, T:0.5496(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2311 (C:5.7396, R:0.0070, T:0.5313(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2657 (C:5.7304, R:0.0070, T:0.5631(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2550 (C:5.7487, R:0.0070, T:0.5540(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2788 (C:5.7614, R:0.0070, T:0.5774(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2752 (C:5.7910, R:0.0071, T:0.5686(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2601 (C:5.7793, R:0.0071, T:0.5523(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2442 (C:5.7780, R:0.0070, T:0.5442(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5550

ğŸ“Š EPOCH 71 TRAINING SUMMARY:
  Total Loss: 1.2571
  Contrastive: 5.7644
  Reconstruction: 0.0070
  Topological: 0.5550 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.6157
  Contrastive: 4.7289
  Reconstruction: 0.0063
  Topological: 3.9899 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 71/300 COMPLETE (39.0s)
Train Loss: 1.2571 (C:5.7644, R:0.0070, T:0.5550)
Val Loss:   4.6157 (C:4.7289, R:0.0063, T:3.9899)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 72 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2604 (C:5.7524, R:0.0070, T:0.5586(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2638 (C:5.7920, R:0.0071, T:0.5575(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2485 (C:5.8260, R:0.0070, T:0.5471(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2487 (C:5.7629, R:0.0070, T:0.5505(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2651 (C:5.7516, R:0.0071, T:0.5547(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2524 (C:5.7097, R:0.0070, T:0.5556(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2558 (C:5.7781, R:0.0071, T:0.5481(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2689 (C:5.7637, R:0.0071, T:0.5625(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2598 (C:5.7897, R:0.0070, T:0.5607(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2473 (C:5.8218, R:0.0070, T:0.5461(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2843 (C:5.7698, R:0.0071, T:0.5783(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2794 (C:5.8434, R:0.0071, T:0.5718(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2709 (C:5.7792, R:0.0071, T:0.5635(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2349 (C:5.7299, R:0.0070, T:0.5363(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2803 (C:5.7822, R:0.0071, T:0.5748(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2750 (C:5.7900, R:0.0071, T:0.5694(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2759 (C:5.7174, R:0.0070, T:0.5757(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2628 (C:5.7365, R:0.0070, T:0.5649(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2819 (C:5.7809, R:0.0070, T:0.5780(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2235 (C:5.8052, R:0.0070, T:0.5250(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2597 (C:5.7965, R:0.0070, T:0.5568(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2718 (C:5.7924, R:0.0070, T:0.5671(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 72 TRAINING SUMMARY:
  Total Loss: 1.2571
  Contrastive: 5.7675
  Reconstruction: 0.0070
  Topological: 0.5552 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.6219
  Contrastive: 4.7379
  Reconstruction: 0.0063
  Topological: 3.9955 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 72/300 COMPLETE (38.4s)
Train Loss: 1.2571 (C:5.7675, R:0.0070, T:0.5552)
Val Loss:   4.6219 (C:4.7379, R:0.0063, T:3.9955)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 73 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2474 (C:5.7879, R:0.0070, T:0.5471(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2540 (C:5.7678, R:0.0070, T:0.5552(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2955 (C:5.7998, R:0.0070, T:0.5908(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2586 (C:5.7546, R:0.0070, T:0.5590(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2594 (C:5.7498, R:0.0070, T:0.5613(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2263 (C:5.7932, R:0.0070, T:0.5297(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.3044 (C:5.7369, R:0.0071, T:0.5984(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2603 (C:5.7409, R:0.0070, T:0.5556(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2638 (C:5.7369, R:0.0070, T:0.5594(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2427 (C:5.7214, R:0.0070, T:0.5390(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2866 (C:5.7822, R:0.0071, T:0.5746(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2777 (C:5.7244, R:0.0070, T:0.5810(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2597 (C:5.7377, R:0.0070, T:0.5619(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2655 (C:5.7926, R:0.0070, T:0.5607(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2275 (C:5.7479, R:0.0069, T:0.5341(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2623 (C:5.7558, R:0.0071, T:0.5568(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2437 (C:5.7937, R:0.0070, T:0.5426(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2493 (C:5.7872, R:0.0070, T:0.5492(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2301 (C:5.7320, R:0.0070, T:0.5332(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2567 (C:5.8160, R:0.0070, T:0.5598(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2513 (C:5.7264, R:0.0070, T:0.5472(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2307 (C:5.7499, R:0.0070, T:0.5292(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5548

ğŸ“Š EPOCH 73 TRAINING SUMMARY:
  Total Loss: 1.2562
  Contrastive: 5.7676
  Reconstruction: 0.0070
  Topological: 0.5548 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.5662
  Contrastive: 4.7479
  Reconstruction: 0.0063
  Topological: 3.9408 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 73/300 COMPLETE (39.7s)
Train Loss: 1.2562 (C:5.7676, R:0.0070, T:0.5548)
Val Loss:   4.5662 (C:4.7479, R:0.0063, T:3.9408)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 74 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2700 (C:5.7785, R:0.0070, T:0.5718(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2447 (C:5.8256, R:0.0070, T:0.5416(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2752 (C:5.7476, R:0.0070, T:0.5719(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2463 (C:5.7475, R:0.0070, T:0.5432(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2339 (C:5.7478, R:0.0070, T:0.5348(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2777 (C:5.7004, R:0.0071, T:0.5699(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2457 (C:5.7687, R:0.0071, T:0.5397(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2608 (C:5.7960, R:0.0070, T:0.5640(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2538 (C:5.7782, R:0.0070, T:0.5568(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2344 (C:5.7589, R:0.0070, T:0.5333(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2524 (C:5.8086, R:0.0070, T:0.5520(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2388 (C:5.7914, R:0.0070, T:0.5414(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2315 (C:5.7795, R:0.0070, T:0.5359(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2477 (C:5.7675, R:0.0070, T:0.5432(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2667 (C:5.7844, R:0.0070, T:0.5676(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2574 (C:5.7483, R:0.0070, T:0.5557(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2784 (C:5.7854, R:0.0071, T:0.5732(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2387 (C:5.7604, R:0.0070, T:0.5389(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2622 (C:5.7749, R:0.0070, T:0.5620(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2709 (C:5.8204, R:0.0070, T:0.5718(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2999 (C:5.7571, R:0.0070, T:0.5968(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2490 (C:5.7448, R:0.0070, T:0.5451(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 74 TRAINING SUMMARY:
  Total Loss: 1.2566
  Contrastive: 5.7673
  Reconstruction: 0.0070
  Topological: 0.5555 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.7172
  Contrastive: 4.7101
  Reconstruction: 0.0063
  Topological: 4.0910 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 74/300 COMPLETE (38.3s)
Train Loss: 1.2566 (C:5.7673, R:0.0070, T:0.5555)
Val Loss:   4.7172 (C:4.7101, R:0.0063, T:4.0910)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 75 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2589 (C:5.7258, R:0.0070, T:0.5567(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2484 (C:5.7982, R:0.0070, T:0.5473(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2490 (C:5.7633, R:0.0070, T:0.5482(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2468 (C:5.7659, R:0.0070, T:0.5482(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2731 (C:5.7739, R:0.0070, T:0.5724(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2577 (C:5.7447, R:0.0070, T:0.5567(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2588 (C:5.7743, R:0.0071, T:0.5529(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2478 (C:5.7764, R:0.0070, T:0.5455(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2395 (C:5.8067, R:0.0070, T:0.5392(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2803 (C:5.7553, R:0.0070, T:0.5754(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2455 (C:5.7521, R:0.0070, T:0.5492(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2490 (C:5.7271, R:0.0070, T:0.5444(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2539 (C:5.7809, R:0.0070, T:0.5562(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2370 (C:5.7475, R:0.0070, T:0.5359(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2594 (C:5.8035, R:0.0071, T:0.5528(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2171 (C:5.7479, R:0.0070, T:0.5180(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2530 (C:5.7842, R:0.0070, T:0.5494(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2880 (C:5.7855, R:0.0070, T:0.5880(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2395 (C:5.7148, R:0.0070, T:0.5399(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2898 (C:5.8258, R:0.0071, T:0.5806(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2391 (C:5.8172, R:0.0069, T:0.5456(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2474 (C:5.6830, R:0.0070, T:0.5509(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5535

ğŸ“Š EPOCH 75 TRAINING SUMMARY:
  Total Loss: 1.2548
  Contrastive: 5.7681
  Reconstruction: 0.0070
  Topological: 0.5535 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.5823
  Contrastive: 4.7330
  Reconstruction: 0.0063
  Topological: 3.9567 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 75/300 COMPLETE (39.5s)
Train Loss: 1.2548 (C:5.7681, R:0.0070, T:0.5535)
Val Loss:   4.5823 (C:4.7330, R:0.0063, T:3.9567)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 76 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2491 (C:5.7590, R:0.0070, T:0.5520(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2715 (C:5.8121, R:0.0070, T:0.5746(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2732 (C:5.7502, R:0.0070, T:0.5707(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2346 (C:5.7540, R:0.0070, T:0.5317(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2714 (C:5.7736, R:0.0070, T:0.5682(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2471 (C:5.7134, R:0.0070, T:0.5486(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2665 (C:5.7656, R:0.0070, T:0.5655(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2407 (C:5.7741, R:0.0070, T:0.5406(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2200 (C:5.7748, R:0.0070, T:0.5218(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2467 (C:5.7599, R:0.0070, T:0.5428(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2619 (C:5.7621, R:0.0070, T:0.5641(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1975 (C:5.7315, R:0.0070, T:0.5001(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2742 (C:5.8066, R:0.0070, T:0.5775(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2806 (C:5.7916, R:0.0071, T:0.5744(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2516 (C:5.7299, R:0.0070, T:0.5472(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2609 (C:5.8118, R:0.0070, T:0.5593(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2849 (C:5.7640, R:0.0070, T:0.5811(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2629 (C:5.8052, R:0.0070, T:0.5618(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2144 (C:5.7719, R:0.0069, T:0.5198(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2675 (C:5.7879, R:0.0070, T:0.5644(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2621 (C:5.7373, R:0.0070, T:0.5627(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2486 (C:5.8266, R:0.0070, T:0.5486(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5517

ğŸ“Š EPOCH 76 TRAINING SUMMARY:
  Total Loss: 1.2522
  Contrastive: 5.7686
  Reconstruction: 0.0070
  Topological: 0.5517 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.5254
  Contrastive: 4.7691
  Reconstruction: 0.0062
  Topological: 3.9016 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 76/300 COMPLETE (38.4s)
Train Loss: 1.2522 (C:5.7686, R:0.0070, T:0.5517)
Val Loss:   4.5254 (C:4.7691, R:0.0062, T:3.9016)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 77 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2340 (C:5.7964, R:0.0070, T:0.5323(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2805 (C:5.7490, R:0.0070, T:0.5827(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2388 (C:5.7443, R:0.0070, T:0.5397(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2289 (C:5.7922, R:0.0070, T:0.5246(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2455 (C:5.7950, R:0.0070, T:0.5421(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2425 (C:5.7363, R:0.0070, T:0.5461(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2291 (C:5.7928, R:0.0070, T:0.5315(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2292 (C:5.7381, R:0.0070, T:0.5340(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2713 (C:5.7090, R:0.0070, T:0.5734(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2381 (C:5.7752, R:0.0070, T:0.5356(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2438 (C:5.7621, R:0.0070, T:0.5446(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2606 (C:5.7642, R:0.0070, T:0.5600(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2718 (C:5.7611, R:0.0070, T:0.5677(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2678 (C:5.7721, R:0.0070, T:0.5662(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2642 (C:5.7824, R:0.0070, T:0.5612(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2704 (C:5.7445, R:0.0070, T:0.5722(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2643 (C:5.8221, R:0.0070, T:0.5650(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2749 (C:5.8003, R:0.0070, T:0.5739(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2715 (C:5.7547, R:0.0070, T:0.5699(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2159 (C:5.7694, R:0.0069, T:0.5223(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2524 (C:5.7438, R:0.0070, T:0.5512(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2853 (C:5.7935, R:0.0071, T:0.5799(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5505

ğŸ“Š EPOCH 77 TRAINING SUMMARY:
  Total Loss: 1.2511
  Contrastive: 5.7684
  Reconstruction: 0.0070
  Topological: 0.5505 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.4496
  Contrastive: 4.7610
  Reconstruction: 0.0062
  Topological: 3.8253 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 77/300 COMPLETE (38.2s)
Train Loss: 1.2511 (C:5.7684, R:0.0070, T:0.5505)
Val Loss:   4.4496 (C:4.7610, R:0.0062, T:3.8253)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 78 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2499 (C:5.7823, R:0.0070, T:0.5510(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2312 (C:5.7782, R:0.0070, T:0.5307(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2746 (C:5.7430, R:0.0070, T:0.5762(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2711 (C:5.7524, R:0.0070, T:0.5710(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2519 (C:5.7594, R:0.0070, T:0.5482(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2251 (C:5.7541, R:0.0070, T:0.5282(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2378 (C:5.8074, R:0.0070, T:0.5352(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2368 (C:5.7885, R:0.0071, T:0.5300(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2502 (C:5.7827, R:0.0070, T:0.5501(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2731 (C:5.7203, R:0.0070, T:0.5707(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2311 (C:5.7482, R:0.0070, T:0.5275(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2226 (C:5.7319, R:0.0069, T:0.5298(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2379 (C:5.7285, R:0.0070, T:0.5388(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2659 (C:5.7559, R:0.0070, T:0.5636(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2661 (C:5.7935, R:0.0070, T:0.5622(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2633 (C:5.7080, R:0.0070, T:0.5634(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2190 (C:5.7498, R:0.0069, T:0.5241(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2391 (C:5.7878, R:0.0070, T:0.5375(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2298 (C:5.7804, R:0.0069, T:0.5372(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2281 (C:5.7762, R:0.0069, T:0.5348(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2519 (C:5.7952, R:0.0070, T:0.5538(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2773 (C:5.7301, R:0.0070, T:0.5759(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5494

ğŸ“Š EPOCH 78 TRAINING SUMMARY:
  Total Loss: 1.2499
  Contrastive: 5.7663
  Reconstruction: 0.0070
  Topological: 0.5494 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.5302
  Contrastive: 4.7542
  Reconstruction: 0.0062
  Topological: 3.9053 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 78/300 COMPLETE (39.0s)
Train Loss: 1.2499 (C:5.7663, R:0.0070, T:0.5494)
Val Loss:   4.5302 (C:4.7542, R:0.0062, T:3.9053)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 79 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2533 (C:5.7801, R:0.0070, T:0.5509(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2467 (C:5.7520, R:0.0070, T:0.5512(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2370 (C:5.7384, R:0.0070, T:0.5403(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2472 (C:5.7461, R:0.0070, T:0.5466(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2462 (C:5.7802, R:0.0070, T:0.5446(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2567 (C:5.7878, R:0.0070, T:0.5583(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2264 (C:5.8188, R:0.0070, T:0.5313(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2239 (C:5.7351, R:0.0070, T:0.5289(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2443 (C:5.8158, R:0.0070, T:0.5415(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2418 (C:5.7444, R:0.0070, T:0.5454(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2606 (C:5.7491, R:0.0069, T:0.5660(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2370 (C:5.7748, R:0.0069, T:0.5422(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2551 (C:5.7185, R:0.0071, T:0.5499(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2805 (C:5.7723, R:0.0070, T:0.5802(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2493 (C:5.7857, R:0.0070, T:0.5504(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2401 (C:5.7547, R:0.0069, T:0.5455(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2603 (C:5.8073, R:0.0070, T:0.5562(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2422 (C:5.7769, R:0.0070, T:0.5400(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2507 (C:5.7551, R:0.0070, T:0.5475(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2410 (C:5.7992, R:0.0070, T:0.5416(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2461 (C:5.7271, R:0.0070, T:0.5468(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2634 (C:5.7247, R:0.0070, T:0.5647(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5484

ğŸ“Š EPOCH 79 TRAINING SUMMARY:
  Total Loss: 1.2487
  Contrastive: 5.7683
  Reconstruction: 0.0070
  Topological: 0.5484 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.4455
  Contrastive: 4.7620
  Reconstruction: 0.0062
  Topological: 3.8212 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 79/300 COMPLETE (39.5s)
Train Loss: 1.2487 (C:5.7683, R:0.0070, T:0.5484)
Val Loss:   4.4455 (C:4.7620, R:0.0062, T:3.8212)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 80 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2546 (C:5.8006, R:0.0070, T:0.5558(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2573 (C:5.8359, R:0.0070, T:0.5578(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2301 (C:5.7613, R:0.0070, T:0.5338(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2386 (C:5.7824, R:0.0070, T:0.5381(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2546 (C:5.7721, R:0.0070, T:0.5592(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2150 (C:5.7585, R:0.0070, T:0.5187(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2218 (C:5.7700, R:0.0070, T:0.5243(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2249 (C:5.7575, R:0.0069, T:0.5341(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2590 (C:5.7493, R:0.0070, T:0.5578(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2520 (C:5.7531, R:0.0070, T:0.5532(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2635 (C:5.8136, R:0.0070, T:0.5604(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2499 (C:5.7416, R:0.0070, T:0.5462(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2599 (C:5.8157, R:0.0069, T:0.5654(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2672 (C:5.7952, R:0.0071, T:0.5605(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2573 (C:5.7783, R:0.0070, T:0.5588(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2906 (C:5.7942, R:0.0070, T:0.5860(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2658 (C:5.7891, R:0.0070, T:0.5665(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2427 (C:5.7347, R:0.0070, T:0.5429(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2851 (C:5.7214, R:0.0071, T:0.5795(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2662 (C:5.7839, R:0.0070, T:0.5686(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2683 (C:5.7965, R:0.0071, T:0.5632(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2708 (C:5.7545, R:0.0070, T:0.5735(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 80 TRAINING SUMMARY:
  Total Loss: 1.2497
  Contrastive: 5.7691
  Reconstruction: 0.0070
  Topological: 0.5497 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.5893
  Contrastive: 4.7368
  Reconstruction: 0.0062
  Topological: 3.9644 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 80/300 COMPLETE (38.0s)
Train Loss: 1.2497 (C:5.7691, R:0.0070, T:0.5497)
Val Loss:   4.5893 (C:4.7368, R:0.0062, T:3.9644)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 81 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2216 (C:5.7743, R:0.0070, T:0.5226(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2519 (C:5.7632, R:0.0070, T:0.5514(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2463 (C:5.7382, R:0.0070, T:0.5506(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2415 (C:5.8369, R:0.0070, T:0.5414(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2396 (C:5.8049, R:0.0070, T:0.5353(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2508 (C:5.7660, R:0.0070, T:0.5553(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2507 (C:5.7421, R:0.0070, T:0.5493(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2733 (C:5.7975, R:0.0071, T:0.5646(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2542 (C:5.7422, R:0.0069, T:0.5625(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2130 (C:5.8096, R:0.0069, T:0.5186(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2360 (C:5.7807, R:0.0070, T:0.5357(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2330 (C:5.7876, R:0.0070, T:0.5305(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2564 (C:5.8024, R:0.0070, T:0.5557(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2337 (C:5.7292, R:0.0070, T:0.5318(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2720 (C:5.8218, R:0.0071, T:0.5659(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2478 (C:5.7732, R:0.0070, T:0.5468(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2711 (C:5.8014, R:0.0070, T:0.5694(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2370 (C:5.7714, R:0.0070, T:0.5384(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2354 (C:5.7490, R:0.0069, T:0.5412(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2307 (C:5.7693, R:0.0070, T:0.5351(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2572 (C:5.7716, R:0.0070, T:0.5612(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2476 (C:5.7885, R:0.0070, T:0.5486(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 81 TRAINING SUMMARY:
  Total Loss: 1.2495
  Contrastive: 5.7673
  Reconstruction: 0.0070
  Topological: 0.5497 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.6556
  Contrastive: 4.6966
  Reconstruction: 0.0063
  Topological: 4.0305 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 81/300 COMPLETE (40.1s)
Train Loss: 1.2495 (C:5.7673, R:0.0070, T:0.5497)
Val Loss:   4.6556 (C:4.6966, R:0.0063, T:4.0305)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 82 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2345 (C:5.6918, R:0.0069, T:0.5441(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2461 (C:5.7509, R:0.0070, T:0.5460(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2882 (C:5.7946, R:0.0070, T:0.5863(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2290 (C:5.7984, R:0.0069, T:0.5344(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2543 (C:5.8260, R:0.0071, T:0.5472(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2243 (C:5.7594, R:0.0069, T:0.5324(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2363 (C:5.7946, R:0.0070, T:0.5388(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2227 (C:5.7822, R:0.0070, T:0.5251(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2664 (C:5.8369, R:0.0070, T:0.5623(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2888 (C:5.7815, R:0.0070, T:0.5844(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2647 (C:5.7500, R:0.0071, T:0.5595(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2639 (C:5.7783, R:0.0070, T:0.5625(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2959 (C:5.7628, R:0.0071, T:0.5856(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2723 (C:5.7778, R:0.0069, T:0.5776(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2305 (C:5.8387, R:0.0070, T:0.5351(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2349 (C:5.7922, R:0.0070, T:0.5328(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2372 (C:5.7291, R:0.0070, T:0.5390(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2336 (C:5.7465, R:0.0070, T:0.5327(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2544 (C:5.6934, R:0.0070, T:0.5523(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2408 (C:5.7939, R:0.0069, T:0.5469(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2494 (C:5.7657, R:0.0069, T:0.5557(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2882 (C:5.8022, R:0.0071, T:0.5819(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 82 TRAINING SUMMARY:
  Total Loss: 1.2487
  Contrastive: 5.7692
  Reconstruction: 0.0070
  Topological: 0.5491 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.5020
  Contrastive: 4.7416
  Reconstruction: 0.0062
  Topological: 3.8777 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 82/300 COMPLETE (38.5s)
Train Loss: 1.2487 (C:5.7692, R:0.0070, T:0.5491)
Val Loss:   4.5020 (C:4.7416, R:0.0062, T:3.8777)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 83 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2374 (C:5.7646, R:0.0070, T:0.5385(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2569 (C:5.8131, R:0.0070, T:0.5556(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2320 (C:5.7308, R:0.0070, T:0.5308(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2074 (C:5.7634, R:0.0070, T:0.5096(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2139 (C:5.7629, R:0.0069, T:0.5202(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2337 (C:5.7312, R:0.0070, T:0.5336(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2398 (C:5.7702, R:0.0070, T:0.5379(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2559 (C:5.7534, R:0.0070, T:0.5545(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2450 (C:5.8259, R:0.0070, T:0.5445(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2616 (C:5.7667, R:0.0070, T:0.5626(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2534 (C:5.7900, R:0.0071, T:0.5462(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2257 (C:5.7843, R:0.0070, T:0.5301(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2225 (C:5.7726, R:0.0069, T:0.5295(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2714 (C:5.7603, R:0.0070, T:0.5689(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2045 (C:5.8100, R:0.0070, T:0.5080(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2627 (C:5.7908, R:0.0070, T:0.5641(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2316 (C:5.7992, R:0.0070, T:0.5346(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2509 (C:5.7394, R:0.0070, T:0.5504(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2541 (C:5.7816, R:0.0070, T:0.5509(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2206 (C:5.7963, R:0.0070, T:0.5250(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2708 (C:5.7965, R:0.0070, T:0.5711(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2228 (C:5.7869, R:0.0070, T:0.5201(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5469

ğŸ“Š EPOCH 83 TRAINING SUMMARY:
  Total Loss: 1.2460
  Contrastive: 5.7710
  Reconstruction: 0.0070
  Topological: 0.5469 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.5683
  Contrastive: 4.7295
  Reconstruction: 0.0062
  Topological: 3.9444 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 83/300 COMPLETE (38.4s)
Train Loss: 1.2460 (C:5.7710, R:0.0070, T:0.5469)
Val Loss:   4.5683 (C:4.7295, R:0.0062, T:3.9444)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 84 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1997 (C:5.7517, R:0.0069, T:0.5053(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2410 (C:5.8067, R:0.0070, T:0.5407(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2658 (C:5.7677, R:0.0070, T:0.5638(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2213 (C:5.7822, R:0.0070, T:0.5257(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2506 (C:5.7674, R:0.0070, T:0.5503(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2186 (C:5.7495, R:0.0070, T:0.5227(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2444 (C:5.8198, R:0.0070, T:0.5446(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2232 (C:5.7573, R:0.0070, T:0.5223(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2615 (C:5.8021, R:0.0070, T:0.5596(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2655 (C:5.7396, R:0.0070, T:0.5695(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2450 (C:5.8024, R:0.0070, T:0.5451(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2417 (C:5.7504, R:0.0071, T:0.5355(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2572 (C:5.7827, R:0.0070, T:0.5559(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2627 (C:5.7654, R:0.0070, T:0.5644(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2323 (C:5.8274, R:0.0070, T:0.5344(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2204 (C:5.7534, R:0.0069, T:0.5258(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2475 (C:5.8221, R:0.0070, T:0.5468(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2473 (C:5.7879, R:0.0070, T:0.5517(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2453 (C:5.7558, R:0.0070, T:0.5498(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2718 (C:5.7688, R:0.0070, T:0.5703(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2278 (C:5.7878, R:0.0069, T:0.5362(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2585 (C:5.7843, R:0.0070, T:0.5564(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 84 TRAINING SUMMARY:
  Total Loss: 1.2463
  Contrastive: 5.7697
  Reconstruction: 0.0070
  Topological: 0.5472 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.4445
  Contrastive: 4.7563
  Reconstruction: 0.0062
  Topological: 3.8224 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 84/300 COMPLETE (38.4s)
Train Loss: 1.2463 (C:5.7697, R:0.0070, T:0.5472)
Val Loss:   4.4445 (C:4.7563, R:0.0062, T:3.8224)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 85 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2360 (C:5.7809, R:0.0070, T:0.5381(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2568 (C:5.7824, R:0.0070, T:0.5588(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2500 (C:5.7712, R:0.0069, T:0.5555(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2175 (C:5.8019, R:0.0070, T:0.5203(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2585 (C:5.7640, R:0.0070, T:0.5578(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2527 (C:5.8131, R:0.0070, T:0.5502(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2468 (C:5.7708, R:0.0070, T:0.5471(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2420 (C:5.7655, R:0.0070, T:0.5459(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2281 (C:5.7790, R:0.0070, T:0.5284(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2350 (C:5.7099, R:0.0069, T:0.5408(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2500 (C:5.8136, R:0.0070, T:0.5512(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1987 (C:5.7751, R:0.0070, T:0.5017(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2594 (C:5.7746, R:0.0070, T:0.5589(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2343 (C:5.7244, R:0.0070, T:0.5386(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2709 (C:5.8096, R:0.0071, T:0.5638(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2399 (C:5.7844, R:0.0070, T:0.5383(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2259 (C:5.7606, R:0.0070, T:0.5301(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2423 (C:5.7075, R:0.0070, T:0.5461(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2908 (C:5.8028, R:0.0071, T:0.5847(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2687 (C:5.7484, R:0.0070, T:0.5685(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2558 (C:5.7392, R:0.0070, T:0.5602(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2677 (C:5.7882, R:0.0070, T:0.5666(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 85 TRAINING SUMMARY:
  Total Loss: 1.2460
  Contrastive: 5.7693
  Reconstruction: 0.0070
  Topological: 0.5472 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.4513
  Contrastive: 4.7649
  Reconstruction: 0.0062
  Topological: 3.8279 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 85/300 COMPLETE (38.4s)
Train Loss: 1.2460 (C:5.7693, R:0.0070, T:0.5472)
Val Loss:   4.4513 (C:4.7649, R:0.0062, T:3.8279)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 86 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2344 (C:5.7754, R:0.0070, T:0.5345(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2328 (C:5.8103, R:0.0069, T:0.5389(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2182 (C:5.7405, R:0.0070, T:0.5208(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2730 (C:5.7420, R:0.0070, T:0.5747(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2292 (C:5.7480, R:0.0070, T:0.5326(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2502 (C:5.7567, R:0.0070, T:0.5469(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2262 (C:5.7628, R:0.0069, T:0.5320(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2257 (C:5.7718, R:0.0069, T:0.5313(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2456 (C:5.7368, R:0.0069, T:0.5527(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2593 (C:5.8475, R:0.0070, T:0.5617(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2664 (C:5.7835, R:0.0070, T:0.5645(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2573 (C:5.7444, R:0.0070, T:0.5585(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2117 (C:5.8065, R:0.0070, T:0.5136(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2971 (C:5.7823, R:0.0070, T:0.5972(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2195 (C:5.7284, R:0.0070, T:0.5232(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2294 (C:5.7435, R:0.0070, T:0.5288(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2313 (C:5.7710, R:0.0070, T:0.5328(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2448 (C:5.7610, R:0.0070, T:0.5469(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2246 (C:5.7881, R:0.0069, T:0.5342(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2490 (C:5.7693, R:0.0070, T:0.5467(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2288 (C:5.7544, R:0.0070, T:0.5277(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2653 (C:5.7584, R:0.0070, T:0.5670(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5463

ğŸ“Š EPOCH 86 TRAINING SUMMARY:
  Total Loss: 1.2449
  Contrastive: 5.7687
  Reconstruction: 0.0070
  Topological: 0.5463 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.5415
  Contrastive: 4.7371
  Reconstruction: 0.0062
  Topological: 3.9180 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 86/300 COMPLETE (37.6s)
Train Loss: 1.2449 (C:5.7687, R:0.0070, T:0.5463)
Val Loss:   4.5415 (C:4.7371, R:0.0062, T:3.9180)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 87 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2270 (C:5.7527, R:0.0069, T:0.5345(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2431 (C:5.8025, R:0.0070, T:0.5411(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2712 (C:5.7319, R:0.0070, T:0.5696(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2426 (C:5.7564, R:0.0070, T:0.5459(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2279 (C:5.7645, R:0.0070, T:0.5298(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2389 (C:5.7555, R:0.0070, T:0.5388(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2544 (C:5.7770, R:0.0070, T:0.5578(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2258 (C:5.7901, R:0.0070, T:0.5209(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2537 (C:5.7413, R:0.0070, T:0.5563(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2458 (C:5.7547, R:0.0069, T:0.5516(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2557 (C:5.7835, R:0.0070, T:0.5525(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2700 (C:5.7742, R:0.0070, T:0.5716(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2382 (C:5.7845, R:0.0070, T:0.5425(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2719 (C:5.7964, R:0.0070, T:0.5675(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2159 (C:5.7529, R:0.0070, T:0.5178(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2486 (C:5.7647, R:0.0070, T:0.5476(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2764 (C:5.7657, R:0.0071, T:0.5697(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2077 (C:5.7465, R:0.0069, T:0.5158(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2190 (C:5.7793, R:0.0069, T:0.5249(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2465 (C:5.7909, R:0.0070, T:0.5441(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2376 (C:5.7653, R:0.0069, T:0.5427(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2504 (C:5.6902, R:0.0070, T:0.5486(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5455

ğŸ“Š EPOCH 87 TRAINING SUMMARY:
  Total Loss: 1.2436
  Contrastive: 5.7688
  Reconstruction: 0.0070
  Topological: 0.5455 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.5079
  Contrastive: 4.7262
  Reconstruction: 0.0062
  Topological: 3.8849 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 87/300 COMPLETE (45.2s)
Train Loss: 1.2436 (C:5.7688, R:0.0070, T:0.5455)
Val Loss:   4.5079 (C:4.7262, R:0.0062, T:3.8849)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 88 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2519 (C:5.7259, R:0.0070, T:0.5551(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2317 (C:5.7668, R:0.0070, T:0.5363(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2340 (C:5.7618, R:0.0070, T:0.5366(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2387 (C:5.8027, R:0.0070, T:0.5393(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2569 (C:5.7549, R:0.0069, T:0.5630(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2432 (C:5.7584, R:0.0070, T:0.5440(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2260 (C:5.7626, R:0.0070, T:0.5285(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2282 (C:5.8073, R:0.0069, T:0.5336(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2528 (C:5.8162, R:0.0070, T:0.5547(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2434 (C:5.7846, R:0.0070, T:0.5420(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2556 (C:5.7825, R:0.0070, T:0.5590(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2367 (C:5.7635, R:0.0069, T:0.5434(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2410 (C:5.8249, R:0.0070, T:0.5380(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2227 (C:5.7452, R:0.0069, T:0.5290(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2557 (C:5.7980, R:0.0070, T:0.5575(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2522 (C:5.7743, R:0.0070, T:0.5535(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2378 (C:5.7798, R:0.0070, T:0.5391(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2439 (C:5.7347, R:0.0070, T:0.5468(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2787 (C:5.8072, R:0.0070, T:0.5794(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2562 (C:5.7981, R:0.0069, T:0.5623(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2371 (C:5.8239, R:0.0070, T:0.5369(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2415 (C:5.7826, R:0.0069, T:0.5495(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 88 TRAINING SUMMARY:
  Total Loss: 1.2437
  Contrastive: 5.7683
  Reconstruction: 0.0070
  Topological: 0.5457 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.4376
  Contrastive: 4.7664
  Reconstruction: 0.0062
  Topological: 3.8152 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 88/300 COMPLETE (48.2s)
Train Loss: 1.2437 (C:5.7683, R:0.0070, T:0.5457)
Val Loss:   4.4376 (C:4.7664, R:0.0062, T:3.8152)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 89 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2315 (C:5.7589, R:0.0069, T:0.5387(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2719 (C:5.7048, R:0.0070, T:0.5767(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2391 (C:5.8029, R:0.0070, T:0.5433(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2578 (C:5.7203, R:0.0070, T:0.5598(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2505 (C:5.7667, R:0.0070, T:0.5512(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1816 (C:5.7555, R:0.0069, T:0.4895(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2388 (C:5.7921, R:0.0070, T:0.5399(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2563 (C:5.7329, R:0.0070, T:0.5557(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2831 (C:5.8344, R:0.0070, T:0.5839(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2588 (C:5.8083, R:0.0070, T:0.5631(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2198 (C:5.8003, R:0.0069, T:0.5260(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2649 (C:5.7110, R:0.0069, T:0.5715(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2463 (C:5.7526, R:0.0070, T:0.5488(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2090 (C:5.7737, R:0.0069, T:0.5164(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2390 (C:5.7914, R:0.0069, T:0.5450(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2643 (C:5.7111, R:0.0070, T:0.5594(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2485 (C:5.7795, R:0.0070, T:0.5498(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2558 (C:5.7992, R:0.0070, T:0.5558(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2662 (C:5.7727, R:0.0070, T:0.5649(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2250 (C:5.7383, R:0.0070, T:0.5247(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2350 (C:5.7782, R:0.0070, T:0.5392(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2326 (C:5.7903, R:0.0070, T:0.5368(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5447

ğŸ“Š EPOCH 89 TRAINING SUMMARY:
  Total Loss: 1.2425
  Contrastive: 5.7698
  Reconstruction: 0.0070
  Topological: 0.5447 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.2739
  Contrastive: 4.7859
  Reconstruction: 0.0062
  Topological: 3.6530 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 89/300 COMPLETE (48.6s)
Train Loss: 1.2425 (C:5.7698, R:0.0070, T:0.5447)
Val Loss:   4.2739 (C:4.7859, R:0.0062, T:3.6530)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 90 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2533 (C:5.8345, R:0.0070, T:0.5532(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2455 (C:5.7862, R:0.0070, T:0.5446(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2354 (C:5.7289, R:0.0069, T:0.5410(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2403 (C:5.7577, R:0.0070, T:0.5440(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2359 (C:5.7158, R:0.0070, T:0.5397(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2277 (C:5.7180, R:0.0069, T:0.5335(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2323 (C:5.7581, R:0.0070, T:0.5361(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2393 (C:5.7320, R:0.0070, T:0.5377(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2605 (C:5.7709, R:0.0070, T:0.5595(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2201 (C:5.7852, R:0.0069, T:0.5253(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2439 (C:5.7180, R:0.0069, T:0.5553(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2334 (C:5.7851, R:0.0070, T:0.5358(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2412 (C:5.7957, R:0.0070, T:0.5440(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2561 (C:5.7660, R:0.0069, T:0.5628(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2402 (C:5.7736, R:0.0070, T:0.5431(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2563 (C:5.7472, R:0.0070, T:0.5561(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2601 (C:5.7966, R:0.0070, T:0.5574(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2335 (C:5.8223, R:0.0070, T:0.5344(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2379 (C:5.8092, R:0.0070, T:0.5383(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2725 (C:5.7537, R:0.0070, T:0.5744(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2227 (C:5.6962, R:0.0070, T:0.5268(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2281 (C:5.7745, R:0.0070, T:0.5294(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 90 TRAINING SUMMARY:
  Total Loss: 1.2429
  Contrastive: 5.7701
  Reconstruction: 0.0070
  Topological: 0.5453 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.1715
  Contrastive: 4.8171
  Reconstruction: 0.0062
  Topological: 3.5508 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 90/300 COMPLETE (50.3s)
Train Loss: 1.2429 (C:5.7701, R:0.0070, T:0.5453)
Val Loss:   4.1715 (C:4.8171, R:0.0062, T:3.5508)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 91 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2605 (C:5.8735, R:0.0070, T:0.5559(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2077 (C:5.7317, R:0.0069, T:0.5161(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2516 (C:5.7164, R:0.0070, T:0.5554(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2295 (C:5.8330, R:0.0070, T:0.5307(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2475 (C:5.7852, R:0.0069, T:0.5535(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2404 (C:5.7886, R:0.0070, T:0.5452(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2313 (C:5.8021, R:0.0070, T:0.5356(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2416 (C:5.8132, R:0.0070, T:0.5370(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2317 (C:5.7663, R:0.0070, T:0.5346(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2301 (C:5.7518, R:0.0070, T:0.5337(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2179 (C:5.7473, R:0.0069, T:0.5238(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2271 (C:5.8162, R:0.0069, T:0.5330(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2286 (C:5.7684, R:0.0070, T:0.5271(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2047 (C:5.7355, R:0.0069, T:0.5127(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2470 (C:5.7506, R:0.0070, T:0.5484(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2164 (C:5.8400, R:0.0070, T:0.5193(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2383 (C:5.8184, R:0.0070, T:0.5401(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2375 (C:5.7829, R:0.0069, T:0.5456(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2606 (C:5.7636, R:0.0070, T:0.5647(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2640 (C:5.7530, R:0.0070, T:0.5593(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2368 (C:5.7696, R:0.0069, T:0.5421(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2391 (C:5.7624, R:0.0070, T:0.5436(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5416

ğŸ“Š EPOCH 91 TRAINING SUMMARY:
  Total Loss: 1.2390
  Contrastive: 5.7713
  Reconstruction: 0.0070
  Topological: 0.5416 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.4726
  Contrastive: 4.7624
  Reconstruction: 0.0062
  Topological: 3.8516 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 91/300 COMPLETE (49.1s)
Train Loss: 1.2390 (C:5.7713, R:0.0070, T:0.5416)
Val Loss:   4.4726 (C:4.7624, R:0.0062, T:3.8516)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 92 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2521 (C:5.7462, R:0.0070, T:0.5513(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2926 (C:5.8150, R:0.0070, T:0.5935(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2443 (C:5.7252, R:0.0070, T:0.5453(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2406 (C:5.7829, R:0.0069, T:0.5457(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2313 (C:5.7365, R:0.0069, T:0.5381(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2066 (C:5.7689, R:0.0070, T:0.5116(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2345 (C:5.7266, R:0.0070, T:0.5391(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2284 (C:5.7975, R:0.0070, T:0.5271(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2316 (C:5.7488, R:0.0070, T:0.5327(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2559 (C:5.7678, R:0.0070, T:0.5547(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2252 (C:5.7729, R:0.0069, T:0.5315(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2248 (C:5.7620, R:0.0070, T:0.5252(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2559 (C:5.7967, R:0.0070, T:0.5581(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2293 (C:5.7632, R:0.0070, T:0.5304(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2350 (C:5.7926, R:0.0070, T:0.5397(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2177 (C:5.7422, R:0.0069, T:0.5235(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2526 (C:5.7892, R:0.0070, T:0.5566(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2282 (C:5.7760, R:0.0070, T:0.5281(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2928 (C:5.8117, R:0.0070, T:0.5916(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2558 (C:5.7834, R:0.0070, T:0.5605(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2316 (C:5.7612, R:0.0070, T:0.5365(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2318 (C:5.7556, R:0.0069, T:0.5395(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 92 TRAINING SUMMARY:
  Total Loss: 1.2389
  Contrastive: 5.7700
  Reconstruction: 0.0070
  Topological: 0.5416 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.3351
  Contrastive: 4.7966
  Reconstruction: 0.0062
  Topological: 3.7144 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 92/300 COMPLETE (51.4s)
Train Loss: 1.2389 (C:5.7700, R:0.0070, T:0.5416)
Val Loss:   4.3351 (C:4.7966, R:0.0062, T:3.7144)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 93 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2164 (C:5.8345, R:0.0070, T:0.5173(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2170 (C:5.7854, R:0.0069, T:0.5303(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2329 (C:5.7705, R:0.0070, T:0.5368(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2594 (C:5.6876, R:0.0070, T:0.5615(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2250 (C:5.7758, R:0.0070, T:0.5288(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2392 (C:5.8275, R:0.0070, T:0.5431(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2185 (C:5.7651, R:0.0069, T:0.5251(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2491 (C:5.7490, R:0.0070, T:0.5517(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2427 (C:5.7539, R:0.0070, T:0.5437(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2362 (C:5.7969, R:0.0070, T:0.5380(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2214 (C:5.7522, R:0.0070, T:0.5200(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2204 (C:5.7546, R:0.0069, T:0.5287(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2204 (C:5.8071, R:0.0069, T:0.5261(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2711 (C:5.8309, R:0.0070, T:0.5720(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2362 (C:5.7738, R:0.0069, T:0.5415(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2441 (C:5.7818, R:0.0070, T:0.5461(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2086 (C:5.7670, R:0.0069, T:0.5185(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2062 (C:5.7693, R:0.0069, T:0.5147(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2737 (C:5.7960, R:0.0070, T:0.5755(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2633 (C:5.8005, R:0.0070, T:0.5679(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2366 (C:5.7631, R:0.0070, T:0.5399(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2261 (C:5.7749, R:0.0069, T:0.5321(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5404

ğŸ“Š EPOCH 93 TRAINING SUMMARY:
  Total Loss: 1.2373
  Contrastive: 5.7721
  Reconstruction: 0.0070
  Topological: 0.5404 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.4203
  Contrastive: 4.7820
  Reconstruction: 0.0062
  Topological: 3.8003 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 93/300 COMPLETE (50.8s)
Train Loss: 1.2373 (C:5.7721, R:0.0070, T:0.5404)
Val Loss:   4.4203 (C:4.7820, R:0.0062, T:3.8003)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 94 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2323 (C:5.7977, R:0.0070, T:0.5341(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2292 (C:5.7680, R:0.0070, T:0.5282(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2494 (C:5.7976, R:0.0070, T:0.5497(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2467 (C:5.7827, R:0.0070, T:0.5447(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2590 (C:5.7805, R:0.0070, T:0.5584(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2243 (C:5.7741, R:0.0070, T:0.5272(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2326 (C:5.7992, R:0.0070, T:0.5360(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2392 (C:5.7807, R:0.0069, T:0.5486(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2219 (C:5.7824, R:0.0069, T:0.5302(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2574 (C:5.8252, R:0.0070, T:0.5548(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2163 (C:5.7672, R:0.0070, T:0.5186(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2375 (C:5.7041, R:0.0069, T:0.5427(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2356 (C:5.7898, R:0.0070, T:0.5389(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2182 (C:5.7273, R:0.0069, T:0.5290(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2099 (C:5.7796, R:0.0070, T:0.5131(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2248 (C:5.8123, R:0.0070, T:0.5256(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2205 (C:5.7488, R:0.0070, T:0.5223(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1954 (C:5.7384, R:0.0069, T:0.5046(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2627 (C:5.8040, R:0.0070, T:0.5610(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2616 (C:5.7107, R:0.0070, T:0.5656(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2699 (C:5.8138, R:0.0070, T:0.5690(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2191 (C:5.7317, R:0.0070, T:0.5189(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 94 TRAINING SUMMARY:
  Total Loss: 1.2380
  Contrastive: 5.7712
  Reconstruction: 0.0070
  Topological: 0.5412 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.4216
  Contrastive: 4.7818
  Reconstruction: 0.0062
  Topological: 3.8010 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 94/300 COMPLETE (50.2s)
Train Loss: 1.2380 (C:5.7712, R:0.0070, T:0.5412)
Val Loss:   4.4216 (C:4.7818, R:0.0062, T:3.8010)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 95 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2048 (C:5.8208, R:0.0069, T:0.5102(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2523 (C:5.7845, R:0.0070, T:0.5525(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2221 (C:5.7575, R:0.0069, T:0.5271(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2314 (C:5.8174, R:0.0070, T:0.5331(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2149 (C:5.7792, R:0.0070, T:0.5190(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2545 (C:5.8281, R:0.0070, T:0.5543(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2437 (C:5.7881, R:0.0069, T:0.5500(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2406 (C:5.7159, R:0.0070, T:0.5413(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2286 (C:5.8052, R:0.0070, T:0.5278(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2520 (C:5.7552, R:0.0069, T:0.5581(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2464 (C:5.7764, R:0.0069, T:0.5532(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2517 (C:5.7873, R:0.0070, T:0.5516(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2464 (C:5.7322, R:0.0070, T:0.5474(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2440 (C:5.7817, R:0.0070, T:0.5456(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2444 (C:5.8441, R:0.0069, T:0.5533(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2469 (C:5.7663, R:0.0070, T:0.5449(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2545 (C:5.8015, R:0.0070, T:0.5547(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2253 (C:5.7862, R:0.0069, T:0.5344(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2609 (C:5.7162, R:0.0069, T:0.5664(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2457 (C:5.7413, R:0.0070, T:0.5501(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2561 (C:5.7332, R:0.0070, T:0.5597(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2707 (C:5.7829, R:0.0070, T:0.5687(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 95 TRAINING SUMMARY:
  Total Loss: 1.2377
  Contrastive: 5.7725
  Reconstruction: 0.0070
  Topological: 0.5413 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.3401
  Contrastive: 4.7939
  Reconstruction: 0.0062
  Topological: 3.7199 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 95/300 COMPLETE (50.7s)
Train Loss: 1.2377 (C:5.7725, R:0.0070, T:0.5413)
Val Loss:   4.3401 (C:4.7939, R:0.0062, T:3.7199)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 96 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2165 (C:5.8011, R:0.0069, T:0.5256(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2389 (C:5.7916, R:0.0070, T:0.5414(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2321 (C:5.7633, R:0.0069, T:0.5389(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2610 (C:5.7876, R:0.0070, T:0.5604(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2300 (C:5.7863, R:0.0070, T:0.5322(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2394 (C:5.8447, R:0.0070, T:0.5368(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2868 (C:5.7468, R:0.0070, T:0.5845(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2269 (C:5.7785, R:0.0070, T:0.5306(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2240 (C:5.7911, R:0.0070, T:0.5254(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2430 (C:5.7211, R:0.0069, T:0.5519(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2404 (C:5.7124, R:0.0070, T:0.5426(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2573 (C:5.7653, R:0.0070, T:0.5596(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2287 (C:5.7705, R:0.0069, T:0.5347(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2208 (C:5.8194, R:0.0070, T:0.5215(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2559 (C:5.7804, R:0.0070, T:0.5546(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2510 (C:5.7925, R:0.0069, T:0.5570(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2344 (C:5.7927, R:0.0069, T:0.5425(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2031 (C:5.7635, R:0.0069, T:0.5119(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2152 (C:5.7032, R:0.0069, T:0.5226(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2453 (C:5.8042, R:0.0070, T:0.5476(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2685 (C:5.7621, R:0.0070, T:0.5671(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2519 (C:5.7621, R:0.0070, T:0.5492(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 96 TRAINING SUMMARY:
  Total Loss: 1.2377
  Contrastive: 5.7717
  Reconstruction: 0.0070
  Topological: 0.5412 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.3234
  Contrastive: 4.7954
  Reconstruction: 0.0062
  Topological: 3.7033 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 96/300 COMPLETE (46.6s)
Train Loss: 1.2377 (C:5.7717, R:0.0070, T:0.5412)
Val Loss:   4.3234 (C:4.7954, R:0.0062, T:3.7033)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 97 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2398 (C:5.8146, R:0.0070, T:0.5386(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2250 (C:5.7770, R:0.0069, T:0.5315(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2071 (C:5.7527, R:0.0069, T:0.5151(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2147 (C:5.7936, R:0.0070, T:0.5192(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2672 (C:5.7571, R:0.0070, T:0.5652(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2515 (C:5.7638, R:0.0069, T:0.5603(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2160 (C:5.7337, R:0.0069, T:0.5248(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2230 (C:5.7820, R:0.0070, T:0.5252(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2256 (C:5.7882, R:0.0070, T:0.5287(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2613 (C:5.7657, R:0.0069, T:0.5687(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2369 (C:5.7612, R:0.0069, T:0.5441(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2376 (C:5.8035, R:0.0069, T:0.5467(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2433 (C:5.8127, R:0.0070, T:0.5416(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2484 (C:5.7871, R:0.0070, T:0.5528(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2202 (C:5.7758, R:0.0070, T:0.5229(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2099 (C:5.7185, R:0.0069, T:0.5156(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2502 (C:5.7717, R:0.0070, T:0.5494(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2564 (C:5.7435, R:0.0069, T:0.5639(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2242 (C:5.7077, R:0.0070, T:0.5248(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2506 (C:5.7702, R:0.0069, T:0.5566(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2351 (C:5.8030, R:0.0069, T:0.5438(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2484 (C:5.7832, R:0.0070, T:0.5521(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5377

ğŸ“Š EPOCH 97 TRAINING SUMMARY:
  Total Loss: 1.2340
  Contrastive: 5.7723
  Reconstruction: 0.0070
  Topological: 0.5377 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.5499
  Contrastive: 4.7240
  Reconstruction: 0.0062
  Topological: 3.9285 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 97/300 COMPLETE (45.6s)
Train Loss: 1.2340 (C:5.7723, R:0.0070, T:0.5377)
Val Loss:   4.5499 (C:4.7240, R:0.0062, T:3.9285)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 98 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2473 (C:5.7313, R:0.0069, T:0.5526(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2339 (C:5.7320, R:0.0069, T:0.5404(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2426 (C:5.8289, R:0.0070, T:0.5416(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2609 (C:5.7917, R:0.0070, T:0.5649(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2189 (C:5.7734, R:0.0070, T:0.5217(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2456 (C:5.7258, R:0.0070, T:0.5475(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2369 (C:5.8110, R:0.0070, T:0.5373(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2192 (C:5.7310, R:0.0069, T:0.5302(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2369 (C:5.7854, R:0.0070, T:0.5376(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2286 (C:5.7786, R:0.0070, T:0.5293(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2126 (C:5.7596, R:0.0069, T:0.5205(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2562 (C:5.8136, R:0.0070, T:0.5581(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2262 (C:5.7960, R:0.0069, T:0.5341(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2555 (C:5.7568, R:0.0070, T:0.5539(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2510 (C:5.6714, R:0.0069, T:0.5577(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2435 (C:5.7905, R:0.0070, T:0.5482(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2138 (C:5.7755, R:0.0069, T:0.5247(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2232 (C:5.7751, R:0.0070, T:0.5248(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2687 (C:5.7647, R:0.0069, T:0.5741(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2591 (C:5.7864, R:0.0070, T:0.5610(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2223 (C:5.8113, R:0.0069, T:0.5277(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2269 (C:5.8044, R:0.0070, T:0.5315(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 98 TRAINING SUMMARY:
  Total Loss: 1.2365
  Contrastive: 5.7736
  Reconstruction: 0.0070
  Topological: 0.5404 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.3660
  Contrastive: 4.7785
  Reconstruction: 0.0062
  Topological: 3.7464 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 98/300 COMPLETE (46.0s)
Train Loss: 1.2365 (C:5.7736, R:0.0070, T:0.5404)
Val Loss:   4.3660 (C:4.7785, R:0.0062, T:3.7464)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 99 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2304 (C:5.7855, R:0.0070, T:0.5299(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2274 (C:5.7838, R:0.0070, T:0.5297(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2073 (C:5.7689, R:0.0069, T:0.5147(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2648 (C:5.7917, R:0.0070, T:0.5696(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1998 (C:5.7836, R:0.0069, T:0.5085(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2429 (C:5.7556, R:0.0069, T:0.5526(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2090 (C:5.7900, R:0.0069, T:0.5203(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2252 (C:5.7857, R:0.0069, T:0.5314(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2005 (C:5.7222, R:0.0069, T:0.5081(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2388 (C:5.7207, R:0.0069, T:0.5469(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2554 (C:5.7692, R:0.0070, T:0.5559(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2433 (C:5.7665, R:0.0070, T:0.5453(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2321 (C:5.7758, R:0.0070, T:0.5357(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2468 (C:5.8815, R:0.0069, T:0.5547(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1975 (C:5.7429, R:0.0069, T:0.5091(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2303 (C:5.7779, R:0.0069, T:0.5415(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2443 (C:5.8253, R:0.0069, T:0.5502(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2258 (C:5.7420, R:0.0069, T:0.5342(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2412 (C:5.7646, R:0.0069, T:0.5496(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2463 (C:5.8255, R:0.0070, T:0.5492(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2367 (C:5.7515, R:0.0069, T:0.5443(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2243 (C:5.8407, R:0.0070, T:0.5269(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 99 TRAINING SUMMARY:
  Total Loss: 1.2354
  Contrastive: 5.7727
  Reconstruction: 0.0070
  Topological: 0.5396 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.4784
  Contrastive: 4.7323
  Reconstruction: 0.0062
  Topological: 3.8571 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 99/300 COMPLETE (45.6s)
Train Loss: 1.2354 (C:5.7727, R:0.0070, T:0.5396)
Val Loss:   4.4784 (C:4.7323, R:0.0062, T:3.8571)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 100 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2293 (C:5.7178, R:0.0069, T:0.5354(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2716 (C:5.7557, R:0.0070, T:0.5679(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2302 (C:5.8365, R:0.0070, T:0.5351(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2525 (C:5.7718, R:0.0069, T:0.5585(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2415 (C:5.7917, R:0.0070, T:0.5440(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2499 (C:5.7426, R:0.0070, T:0.5536(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2310 (C:5.7750, R:0.0069, T:0.5403(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2346 (C:5.8021, R:0.0069, T:0.5411(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2515 (C:5.7691, R:0.0070, T:0.5559(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2532 (C:5.7986, R:0.0069, T:0.5607(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2233 (C:5.7867, R:0.0069, T:0.5302(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2220 (C:5.7669, R:0.0070, T:0.5240(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2476 (C:5.7537, R:0.0070, T:0.5473(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2570 (C:5.7184, R:0.0069, T:0.5659(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2194 (C:5.8414, R:0.0070, T:0.5203(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2349 (C:5.7313, R:0.0069, T:0.5424(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2428 (C:5.7458, R:0.0070, T:0.5467(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2209 (C:5.8104, R:0.0069, T:0.5292(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2493 (C:5.7451, R:0.0069, T:0.5572(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2461 (C:5.7828, R:0.0070, T:0.5504(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2439 (C:5.7545, R:0.0070, T:0.5475(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2224 (C:5.7251, R:0.0070, T:0.5266(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 100 TRAINING SUMMARY:
  Total Loss: 1.2349
  Contrastive: 5.7724
  Reconstruction: 0.0070
  Topological: 0.5392 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.3587
  Contrastive: 4.7659
  Reconstruction: 0.0062
  Topological: 3.7391 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 100/300 COMPLETE (45.2s)
Train Loss: 1.2349 (C:5.7724, R:0.0070, T:0.5392)
Val Loss:   4.3587 (C:4.7659, R:0.0062, T:3.7391)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 101 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2383 (C:5.7826, R:0.0070, T:0.5381(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2272 (C:5.7368, R:0.0069, T:0.5350(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1844 (C:5.7921, R:0.0069, T:0.4912(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2500 (C:5.7518, R:0.0070, T:0.5534(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2266 (C:5.7546, R:0.0070, T:0.5310(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2147 (C:5.7968, R:0.0069, T:0.5243(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2243 (C:5.7808, R:0.0070, T:0.5293(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2384 (C:5.7282, R:0.0069, T:0.5458(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2609 (C:5.7841, R:0.0069, T:0.5702(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2380 (C:5.8160, R:0.0070, T:0.5416(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2299 (C:5.8064, R:0.0069, T:0.5350(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2259 (C:5.7394, R:0.0069, T:0.5313(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2164 (C:5.7468, R:0.0069, T:0.5221(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2065 (C:5.7556, R:0.0070, T:0.5097(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2247 (C:5.8016, R:0.0070, T:0.5270(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2183 (C:5.7515, R:0.0069, T:0.5267(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2254 (C:5.7281, R:0.0070, T:0.5216(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2498 (C:5.7756, R:0.0070, T:0.5531(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2368 (C:5.7280, R:0.0069, T:0.5437(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2478 (C:5.7727, R:0.0070, T:0.5486(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2464 (C:5.8196, R:0.0070, T:0.5448(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2393 (C:5.7478, R:0.0070, T:0.5422(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5365

ğŸ“Š EPOCH 101 TRAINING SUMMARY:
  Total Loss: 1.2318
  Contrastive: 5.7741
  Reconstruction: 0.0070
  Topological: 0.5365 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.6544
  Contrastive: 4.6895
  Reconstruction: 0.0062
  Topological: 4.0338 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 101/300 COMPLETE (45.0s)
Train Loss: 1.2318 (C:5.7741, R:0.0070, T:0.5365)
Val Loss:   4.6544 (C:4.6895, R:0.0062, T:4.0338)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 102 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2652 (C:5.7077, R:0.0070, T:0.5616(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2289 (C:5.7539, R:0.0070, T:0.5324(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2288 (C:5.8123, R:0.0070, T:0.5318(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2318 (C:5.8028, R:0.0070, T:0.5336(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2401 (C:5.7894, R:0.0069, T:0.5462(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2222 (C:5.7471, R:0.0070, T:0.5263(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2604 (C:5.7547, R:0.0070, T:0.5644(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2245 (C:5.7443, R:0.0070, T:0.5291(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2256 (C:5.7329, R:0.0069, T:0.5361(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2602 (C:5.7372, R:0.0070, T:0.5634(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2222 (C:5.7853, R:0.0070, T:0.5263(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2330 (C:5.7769, R:0.0070, T:0.5358(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2615 (C:5.7398, R:0.0069, T:0.5686(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2643 (C:5.7757, R:0.0070, T:0.5656(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2134 (C:5.7631, R:0.0069, T:0.5196(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2260 (C:5.7688, R:0.0069, T:0.5310(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2354 (C:5.8222, R:0.0070, T:0.5386(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2326 (C:5.7740, R:0.0069, T:0.5398(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2089 (C:5.7673, R:0.0069, T:0.5177(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2387 (C:5.7527, R:0.0070, T:0.5428(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2498 (C:5.7935, R:0.0070, T:0.5488(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2347 (C:5.7180, R:0.0070, T:0.5368(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5362

ğŸ“Š EPOCH 102 TRAINING SUMMARY:
  Total Loss: 1.2315
  Contrastive: 5.7744
  Reconstruction: 0.0070
  Topological: 0.5362 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.4145
  Contrastive: 4.7494
  Reconstruction: 0.0062
  Topological: 3.7948 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 102/300 COMPLETE (46.2s)
Train Loss: 1.2315 (C:5.7744, R:0.0070, T:0.5362)
Val Loss:   4.4145 (C:4.7494, R:0.0062, T:3.7948)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 103 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2150 (C:5.7477, R:0.0069, T:0.5221(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2081 (C:5.7837, R:0.0070, T:0.5124(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1967 (C:5.7354, R:0.0069, T:0.5068(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2495 (C:5.7806, R:0.0069, T:0.5598(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2202 (C:5.7396, R:0.0069, T:0.5253(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2266 (C:5.6892, R:0.0069, T:0.5352(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2461 (C:5.7677, R:0.0070, T:0.5490(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2400 (C:5.7776, R:0.0070, T:0.5427(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2232 (C:5.7835, R:0.0070, T:0.5230(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2370 (C:5.7977, R:0.0070, T:0.5349(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2199 (C:5.7781, R:0.0069, T:0.5255(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2607 (C:5.7432, R:0.0070, T:0.5614(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2215 (C:5.7639, R:0.0070, T:0.5250(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2578 (C:5.8063, R:0.0069, T:0.5668(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2381 (C:5.7759, R:0.0070, T:0.5425(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2469 (C:5.7278, R:0.0069, T:0.5528(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1967 (C:5.7786, R:0.0069, T:0.5029(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2350 (C:5.7850, R:0.0070, T:0.5369(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2452 (C:5.7946, R:0.0069, T:0.5530(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2317 (C:5.8231, R:0.0069, T:0.5406(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2403 (C:5.8061, R:0.0070, T:0.5445(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2142 (C:5.7519, R:0.0069, T:0.5226(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5357

ğŸ“Š EPOCH 103 TRAINING SUMMARY:
  Total Loss: 1.2307
  Contrastive: 5.7731
  Reconstruction: 0.0069
  Topological: 0.5357 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.3019
  Contrastive: 4.7955
  Reconstruction: 0.0062
  Topological: 3.6830 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 103/300 COMPLETE (46.0s)
Train Loss: 1.2307 (C:5.7731, R:0.0069, T:0.5357)
Val Loss:   4.3019 (C:4.7955, R:0.0062, T:3.6830)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 104 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2428 (C:5.7826, R:0.0069, T:0.5496(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2220 (C:5.8313, R:0.0069, T:0.5282(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2343 (C:5.7530, R:0.0070, T:0.5389(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1963 (C:5.8333, R:0.0070, T:0.5003(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2387 (C:5.6981, R:0.0069, T:0.5453(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2277 (C:5.7971, R:0.0070, T:0.5298(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1945 (C:5.7830, R:0.0069, T:0.5006(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2313 (C:5.7307, R:0.0069, T:0.5378(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2178 (C:5.7798, R:0.0069, T:0.5249(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2488 (C:5.8198, R:0.0070, T:0.5525(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2445 (C:5.8135, R:0.0069, T:0.5538(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2298 (C:5.8091, R:0.0070, T:0.5310(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2329 (C:5.7539, R:0.0069, T:0.5403(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2224 (C:5.7629, R:0.0070, T:0.5212(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2335 (C:5.7798, R:0.0070, T:0.5384(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2718 (C:5.7810, R:0.0070, T:0.5750(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2189 (C:5.7813, R:0.0070, T:0.5208(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2260 (C:5.8142, R:0.0069, T:0.5332(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2398 (C:5.7338, R:0.0070, T:0.5437(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2316 (C:5.7350, R:0.0070, T:0.5351(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2430 (C:5.7965, R:0.0070, T:0.5428(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2644 (C:5.7502, R:0.0069, T:0.5697(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 104 TRAINING SUMMARY:
  Total Loss: 1.2307
  Contrastive: 5.7744
  Reconstruction: 0.0069
  Topological: 0.5359 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.3929
  Contrastive: 4.7637
  Reconstruction: 0.0062
  Topological: 3.7731 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 104/300 COMPLETE (45.0s)
Train Loss: 1.2307 (C:5.7744, R:0.0069, T:0.5359)
Val Loss:   4.3929 (C:4.7637, R:0.0062, T:3.7731)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 105 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2010 (C:5.7807, R:0.0069, T:0.5085(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1954 (C:5.7481, R:0.0069, T:0.5054(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2579 (C:5.7597, R:0.0070, T:0.5554(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2335 (C:5.7410, R:0.0070, T:0.5377(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2292 (C:5.7448, R:0.0069, T:0.5345(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2182 (C:5.8011, R:0.0069, T:0.5245(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2307 (C:5.7663, R:0.0070, T:0.5329(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2404 (C:5.8145, R:0.0070, T:0.5410(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2952 (C:5.8228, R:0.0070, T:0.5977(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2345 (C:5.7416, R:0.0069, T:0.5399(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2425 (C:5.7976, R:0.0070, T:0.5405(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2320 (C:5.7386, R:0.0069, T:0.5410(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2519 (C:5.7326, R:0.0069, T:0.5627(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2535 (C:5.8125, R:0.0070, T:0.5538(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2505 (C:5.7703, R:0.0070, T:0.5519(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1960 (C:5.7471, R:0.0069, T:0.5029(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2512 (C:5.8017, R:0.0070, T:0.5510(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2309 (C:5.7857, R:0.0070, T:0.5319(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2239 (C:5.8161, R:0.0069, T:0.5351(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1994 (C:5.7688, R:0.0069, T:0.5051(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2456 (C:5.8063, R:0.0070, T:0.5474(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2082 (C:5.7490, R:0.0069, T:0.5190(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5351

ğŸ“Š EPOCH 105 TRAINING SUMMARY:
  Total Loss: 1.2297
  Contrastive: 5.7740
  Reconstruction: 0.0069
  Topological: 0.5351 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.3267
  Contrastive: 4.7896
  Reconstruction: 0.0062
  Topological: 3.7089 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 105/300 COMPLETE (45.3s)
Train Loss: 1.2297 (C:5.7740, R:0.0069, T:0.5351)
Val Loss:   4.3267 (C:4.7896, R:0.0062, T:3.7089)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 106 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2382 (C:5.7755, R:0.0069, T:0.5445(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1944 (C:5.7729, R:0.0069, T:0.5000(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2591 (C:5.7461, R:0.0069, T:0.5706(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2058 (C:5.7876, R:0.0069, T:0.5133(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2377 (C:5.7427, R:0.0069, T:0.5436(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2119 (C:5.7755, R:0.0069, T:0.5185(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2209 (C:5.8050, R:0.0070, T:0.5229(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2511 (C:5.8412, R:0.0070, T:0.5533(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2100 (C:5.7313, R:0.0069, T:0.5178(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2282 (C:5.7639, R:0.0069, T:0.5348(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2217 (C:5.7758, R:0.0070, T:0.5266(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2087 (C:5.7963, R:0.0069, T:0.5172(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2444 (C:5.7574, R:0.0070, T:0.5493(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2505 (C:5.7357, R:0.0070, T:0.5523(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2201 (C:5.7730, R:0.0069, T:0.5270(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2131 (C:5.7585, R:0.0069, T:0.5190(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2306 (C:5.7275, R:0.0070, T:0.5355(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2119 (C:5.7433, R:0.0069, T:0.5226(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2525 (C:5.7514, R:0.0070, T:0.5548(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2295 (C:5.7637, R:0.0069, T:0.5358(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2336 (C:5.7126, R:0.0069, T:0.5391(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2254 (C:5.7875, R:0.0069, T:0.5330(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 106 TRAINING SUMMARY:
  Total Loss: 1.2299
  Contrastive: 5.7730
  Reconstruction: 0.0069
  Topological: 0.5353 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.3016
  Contrastive: 4.7960
  Reconstruction: 0.0062
  Topological: 3.6839 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 106/300 COMPLETE (45.3s)
Train Loss: 1.2299 (C:5.7730, R:0.0069, T:0.5353)
Val Loss:   4.3016 (C:4.7960, R:0.0062, T:3.6839)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 107 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2327 (C:5.7817, R:0.0069, T:0.5442(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2501 (C:5.7235, R:0.0069, T:0.5557(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2453 (C:5.7047, R:0.0069, T:0.5516(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2233 (C:5.8023, R:0.0069, T:0.5328(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2084 (C:5.8199, R:0.0069, T:0.5160(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2302 (C:5.7581, R:0.0069, T:0.5364(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2151 (C:5.7654, R:0.0069, T:0.5214(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2099 (C:5.7672, R:0.0070, T:0.5139(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2332 (C:5.7557, R:0.0070, T:0.5380(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2228 (C:5.7695, R:0.0069, T:0.5300(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2533 (C:5.7284, R:0.0069, T:0.5632(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2417 (C:5.7368, R:0.0069, T:0.5482(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2471 (C:5.7242, R:0.0070, T:0.5518(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2381 (C:5.7524, R:0.0069, T:0.5491(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2178 (C:5.7473, R:0.0069, T:0.5245(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2042 (C:5.7588, R:0.0069, T:0.5119(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2622 (C:5.7674, R:0.0070, T:0.5607(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2421 (C:5.7542, R:0.0070, T:0.5431(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2570 (C:5.7868, R:0.0070, T:0.5582(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2399 (C:5.7463, R:0.0069, T:0.5451(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2392 (C:5.7555, R:0.0069, T:0.5471(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2461 (C:5.8154, R:0.0070, T:0.5483(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 107 TRAINING SUMMARY:
  Total Loss: 1.2302
  Contrastive: 5.7733
  Reconstruction: 0.0069
  Topological: 0.5358 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.2272
  Contrastive: 4.8073
  Reconstruction: 0.0062
  Topological: 3.6091 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 107/300 COMPLETE (46.4s)
Train Loss: 1.2302 (C:5.7733, R:0.0069, T:0.5358)
Val Loss:   4.2272 (C:4.8073, R:0.0062, T:3.6091)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 108 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2404 (C:5.7863, R:0.0070, T:0.5393(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2070 (C:5.7501, R:0.0069, T:0.5159(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2152 (C:5.7627, R:0.0069, T:0.5232(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2624 (C:5.7665, R:0.0070, T:0.5609(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2632 (C:5.7697, R:0.0070, T:0.5638(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2105 (C:5.7563, R:0.0069, T:0.5188(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2110 (C:5.7680, R:0.0070, T:0.5156(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2179 (C:5.7643, R:0.0069, T:0.5233(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2366 (C:5.7790, R:0.0070, T:0.5380(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2344 (C:5.7301, R:0.0069, T:0.5424(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2391 (C:5.7603, R:0.0070, T:0.5402(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2164 (C:5.7761, R:0.0069, T:0.5293(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1916 (C:5.7756, R:0.0070, T:0.4958(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2149 (C:5.7873, R:0.0069, T:0.5266(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2412 (C:5.7751, R:0.0069, T:0.5480(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2159 (C:5.8020, R:0.0069, T:0.5243(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2145 (C:5.7769, R:0.0069, T:0.5206(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2177 (C:5.7964, R:0.0069, T:0.5293(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2488 (C:5.7452, R:0.0070, T:0.5498(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2363 (C:5.7736, R:0.0069, T:0.5415(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2430 (C:5.8320, R:0.0070, T:0.5427(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2218 (C:5.7503, R:0.0069, T:0.5292(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5338

ğŸ“Š EPOCH 108 TRAINING SUMMARY:
  Total Loss: 1.2278
  Contrastive: 5.7741
  Reconstruction: 0.0069
  Topological: 0.5338 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.2879
  Contrastive: 4.7799
  Reconstruction: 0.0062
  Topological: 3.6699 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 108/300 COMPLETE (44.6s)
Train Loss: 1.2278 (C:5.7741, R:0.0069, T:0.5338)
Val Loss:   4.2879 (C:4.7799, R:0.0062, T:3.6699)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 109 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2423 (C:5.7870, R:0.0070, T:0.5413(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1855 (C:5.7771, R:0.0069, T:0.4948(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1843 (C:5.7950, R:0.0069, T:0.4923(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2384 (C:5.8350, R:0.0069, T:0.5446(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2245 (C:5.7817, R:0.0069, T:0.5316(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2038 (C:5.7490, R:0.0070, T:0.5085(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2180 (C:5.7362, R:0.0069, T:0.5269(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2267 (C:5.7221, R:0.0070, T:0.5310(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2355 (C:5.8015, R:0.0069, T:0.5438(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2366 (C:5.7483, R:0.0069, T:0.5444(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2412 (C:5.7986, R:0.0070, T:0.5454(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2202 (C:5.7834, R:0.0069, T:0.5259(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2322 (C:5.7755, R:0.0069, T:0.5414(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1937 (C:5.7928, R:0.0069, T:0.5034(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2051 (C:5.7770, R:0.0069, T:0.5167(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1936 (C:5.8036, R:0.0069, T:0.5021(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1975 (C:5.7449, R:0.0069, T:0.5071(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2100 (C:5.7789, R:0.0069, T:0.5225(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2346 (C:5.7829, R:0.0069, T:0.5411(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2328 (C:5.7721, R:0.0069, T:0.5385(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2305 (C:5.7760, R:0.0070, T:0.5328(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2366 (C:5.7092, R:0.0069, T:0.5439(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5319

ğŸ“Š EPOCH 109 TRAINING SUMMARY:
  Total Loss: 1.2255
  Contrastive: 5.7741
  Reconstruction: 0.0069
  Topological: 0.5319 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.4721
  Contrastive: 4.7573
  Reconstruction: 0.0062
  Topological: 3.8533 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 109/300 COMPLETE (45.2s)
Train Loss: 1.2255 (C:5.7741, R:0.0069, T:0.5319)
Val Loss:   4.4721 (C:4.7573, R:0.0062, T:3.8533)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 110 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2946 (C:5.7192, R:0.0070, T:0.5971(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2264 (C:5.7374, R:0.0069, T:0.5326(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2353 (C:5.7508, R:0.0069, T:0.5424(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2321 (C:5.7407, R:0.0070, T:0.5365(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2116 (C:5.7632, R:0.0069, T:0.5222(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2304 (C:5.7553, R:0.0069, T:0.5396(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1998 (C:5.7864, R:0.0069, T:0.5050(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2183 (C:5.7281, R:0.0069, T:0.5246(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2230 (C:5.6924, R:0.0069, T:0.5281(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2556 (C:5.7576, R:0.0069, T:0.5610(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2373 (C:5.7389, R:0.0069, T:0.5442(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2268 (C:5.7658, R:0.0069, T:0.5355(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2169 (C:5.7456, R:0.0069, T:0.5221(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2307 (C:5.7718, R:0.0069, T:0.5405(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2157 (C:5.7617, R:0.0070, T:0.5207(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2381 (C:5.7348, R:0.0069, T:0.5445(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2401 (C:5.7928, R:0.0069, T:0.5451(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2381 (C:5.7483, R:0.0069, T:0.5437(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2432 (C:5.7902, R:0.0070, T:0.5462(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2288 (C:5.8001, R:0.0070, T:0.5288(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2208 (C:5.7910, R:0.0069, T:0.5297(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2105 (C:5.8198, R:0.0069, T:0.5188(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 110 TRAINING SUMMARY:
  Total Loss: 1.2275
  Contrastive: 5.7738
  Reconstruction: 0.0069
  Topological: 0.5337 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.4347
  Contrastive: 4.7621
  Reconstruction: 0.0062
  Topological: 3.8163 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 110/300 COMPLETE (46.4s)
Train Loss: 1.2275 (C:5.7738, R:0.0069, T:0.5337)
Val Loss:   4.4347 (C:4.7621, R:0.0062, T:3.8163)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

ğŸ›‘ Early stopping triggered after 110 epochs
Best model was at epoch 90 with Val Loss: 4.1715

======================================================================
ğŸ“ˆ FINAL TOPOLOGICAL LEARNING ANALYSIS
======================================================================
First topological learning: Epoch 1
Epochs with topology: 110/110
Max consecutive topology epochs: 110
Best topological loss: 0.5319
Final topological loss: 0.5337
âœ… SUCCESS: Topological learning achieved!
ğŸš€ EXCELLENT: Very consistent topological learning (>80%)
ğŸ“ˆ Topological learning appears stable

======================================================================
ğŸ¯ TOPOLOGICAL AUTOENCODER TRAINING COMPLETED
======================================================================
âœ… Topological training completed successfully!
Creating topological loss plots...

ContrastiveAutoencoder initialized:
  Input dim: 1536
  Latent dim: 75
  Hidden dims: [1024, 768, 512, 256, 128]
  Dropout rate: 0.2
  Total parameters: 3,045,451
FullDatasetContrastiveLoss initialized:
  Margin: 2.0
  Update frequency: 3 epochs
  Max global samples: 5000
FullDatasetCombinedLoss initialized:
  Contrastive weight: 0.0
  Base reconstruction weight: 100.0
MoorTopologicalLoss Initialized: Using 0-dimensional persistence pairings (MST edges).
No prototypes being used for topological loss - whole dataset instead.
TopologicalTrainer initialized on device: cpu
Model parameters: 3,045,451
Enhanced with topological loss monitoring
âœ… Model and trainer loaded successfully
Creating topological loss plots...
Topological loss plots saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/pure_moor_topological_autoencoder_no_attention_20250724_224242/plots/pure_moor_topological_autoencoder_no_attention_20250724_224242_topological_training_losses.png
Curriculum learning analysis saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/pure_moor_topological_autoencoder_no_attention_20250724_224242/plots/pure_moor_topological_autoencoder_no_attention_20250724_224242_curriculum_analysis.png
Main training plots saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/pure_moor_topological_autoencoder_no_attention_20250724_224242/plots/pure_moor_topological_autoencoder_no_attention_20250724_224242_topological_training_losses.png
Curriculum analysis saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/pure_moor_topological_autoencoder_no_attention_20250724_224242/plots/pure_moor_topological_autoencoder_no_attention_20250724_224242_curriculum_analysis.png
Training summary saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/pure_moor_topological_autoencoder_no_attention_20250724_224242/pure_moor_topological_autoencoder_no_attention_20250724_224242_training_summary.txt
âœ… Plots and summary created successfully
FlexibleEmbedder initialized with type: 'concat'
Output dimension will be: 1536
GlobalDataLoader initialized:
  Embedding type: concat
  Output dimension: 1536
  Sample size: All
Starting data loading pipeline...
============================================================
Loading training data from data/processed/snli_full_standard_SBERT.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 549367 training samples
Loading validation data from data/processed/snli_full_standard_SBERT_validation.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9842 validation samples
Loading test data from data/processed/snli_full_standard_SBERT_test.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9824 test samples
Generating embeddings for training...
Generating concat embeddings on cpu
Processing 549367 samples in batches of 1000
  Processing batch 1/550
  Processing batch 6/550
  Processing batch 11/550
  Processing batch 16/550
  Processing batch 21/550
  Processing batch 26/550
  Processing batch 31/550
  Processing batch 36/550
  Processing batch 41/550
  Processing batch 46/550
  Processing batch 51/550
  Processing batch 56/550
  Processing batch 61/550
  Processing batch 66/550
  Processing batch 71/550
  Processing batch 76/550
  Processing batch 81/550
  Processing batch 86/550
  Processing batch 91/550
  Processing batch 96/550
  Processing batch 101/550
  Processing batch 106/550
  Processing batch 111/550
  Processing batch 116/550
  Processing batch 121/550
  Processing batch 126/550
  Processing batch 131/550
  Processing batch 136/550
  Processing batch 141/550
  Processing batch 146/550
  Processing batch 151/550
  Processing batch 156/550
  Processing batch 161/550
  Processing batch 166/550
  Processing batch 171/550
  Processing batch 176/550
  Processing batch 181/550
  Processing batch 186/550
  Processing batch 191/550
  Processing batch 196/550
  Processing batch 201/550
  Processing batch 206/550
  Processing batch 211/550
  Processing batch 216/550
  Processing batch 221/550
  Processing batch 226/550
  Processing batch 231/550
  Processing batch 236/550
  Processing batch 241/550
  Processing batch 246/550
  Processing batch 251/550
  Processing batch 256/550
  Processing batch 261/550
  Processing batch 266/550
  Processing batch 271/550
  Processing batch 276/550
  Processing batch 281/550
  Processing batch 286/550
  Processing batch 291/550
  Processing batch 296/550
  Processing batch 301/550
  Processing batch 306/550
  Processing batch 311/550
  Processing batch 316/550
  Processing batch 321/550
  Processing batch 326/550
  Processing batch 331/550
  Processing batch 336/550
  Processing batch 341/550
  Processing batch 346/550
  Processing batch 351/550
  Processing batch 356/550
  Processing batch 361/550
  Processing batch 366/550
  Processing batch 371/550
  Processing batch 376/550
  Processing batch 381/550
  Processing batch 386/550
  Processing batch 391/550
  Processing batch 396/550
  Processing batch 401/550
  Processing batch 406/550
  Processing batch 411/550
  Processing batch 416/550
  Processing batch 421/550
  Processing batch 426/550
  Processing batch 431/550
  Processing batch 436/550
  Processing batch 441/550
  Processing batch 446/550
  Processing batch 451/550
  Processing batch 456/550
  Processing batch 461/550
  Processing batch 466/550
  Processing batch 471/550
  Processing batch 476/550
  Processing batch 481/550
  Processing batch 486/550
  Processing batch 491/550
  Processing batch 496/550
  Processing batch 501/550
  Processing batch 506/550
  Processing batch 511/550
  Processing batch 516/550
  Processing batch 521/550
  Processing batch 526/550
  Processing batch 531/550
  Processing batch 536/550
  Processing batch 541/550
  Processing batch 546/550
Generated concat embeddings: torch.Size([549367, 1536])
Generating embeddings for validation...
Generating concat embeddings on cpu
Processing 9842 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9842, 1536])
Generating embeddings for test...
Generating concat embeddings on cpu
Processing 9824 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9824, 1536])
EntailmentDataset created: 549367 samples
  Embedding shape: torch.Size([549367, 1536])
  Class distribution: {'entailment': 183416, 'neutral': 182764, 'contradiction': 183187}
EntailmentDataset created: 9842 samples
  Embedding shape: torch.Size([9842, 1536])
  Class distribution: {'entailment': 3329, 'neutral': 3235, 'contradiction': 3278}
EntailmentDataset created: 9824 samples
  Embedding shape: torch.Size([9824, 1536])
  Class distribution: {'entailment': 3368, 'neutral': 3219, 'contradiction': 3237}

Data loading pipeline completed!
Output embedding dimension: 1536
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 537
  Class 2: 183187 samples
  Class 0: 183416 samples
  Class 1: 182764 samples
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 9
  Class 2: 3278 samples
  Class 0: 3329 samples
  Class 1: 3235 samples
DataLoaders created:
  Batch size: 1020
  Balanced sampling: True
  Train batches: 537
  Val batches: 9
  Test batches: 10
âœ… Data loaded successfully
Starting model evaluation...
GlobalContrastiveEvaluator initialized on cpu
Starting comprehensive evaluation...
============================================================
Extracting latent representations...
  Processed 1/10 batches
Extracted representations: torch.Size([9824, 75])
Evaluating clustering performance...
Clustering Results:
  Silhouette Score: 0.0013
  Adjusted Rand Score: -0.0001
  Clustering Accuracy: 0.3371
Evaluating classification performance...
  Extracting training representations...
Extracting latent representations...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
Extracted representations: torch.Size([547740, 75])
  Extracting validation representations...
Extracting latent representations...
  Processed 1/9 batches
Extracted representations: torch.Size([9180, 75])
Subsampled training to 50000 samples
  Training on 50000 samples, evaluating on 9180 samples
Classification Results:
  Accuracy: 0.5076
  Per-class F1: [0.5563984579032458, 0.414484092107576, 0.537365010799136]
Evaluating reconstruction quality...
Reconstruction Results:
  Average MSE: 0.006173
Evaluating separation quality...
Separation Results:
  Positive distances: 4.811 Â± 0.469
  Negative distances: 4.836 Â± 0.457
  Separation ratio: 1.01x
  Gap: -6.236
  Perfect separation: No

Comprehensive evaluation completed!

============================================================
EVALUATION SUMMARY
============================================================
Clustering Performance:
  Silhouette Score: 0.0013
  Clustering Accuracy: 0.3371
  Adjusted Rand Score: -0.0001

Classification Performance:
  Accuracy: 0.5076

Separation Quality:
  Separation Ratio: 1.01x
  Gap: -6.236
  Perfect Separation: False

Reconstruction Quality:
  Average MSE: 0.006173
============================================================
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/pure_moor_topological_autoencoder_no_attention_20250724_224242/results/evaluation_results_20250725_100721.json
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/pure_moor_topological_autoencoder_no_attention_20250724_224242/results/evaluation_results_20250725_100721.json
âœ… Model evaluation completed successfully

Key Results:
  Separation ratio: 1.01x
  Perfect separation: False
  Classification accuracy: 0.5076

============================================================
TOPOLOGICAL TRAINING ANALYSIS
============================================================

ğŸ“ˆ TOPOLOGICAL LEARNING DIAGNOSIS:
  Total epochs: 90
  Epochs with topological learning: 90
  Current topological loss: 0.5453
  Current topological weight: 1.0000
  âœ… Topological loss is decreasing (good progress)
ğŸš€ EXCELLENT: Consistent topological learning achieved!
Final topological loss: 0.5453
Epochs with topology: 90/90
âš ï¸  Poor clustering accuracy: 0.337

Final analysis saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/pure_moor_topological_autoencoder_no_attention_20250724_224242/results/final_analysis.json
âœ… Analysis completed for: entailment_surfaces/supervised_contrastive_autoencoder/experiments/pure_moor_topological_autoencoder_no_attention_20250724_224242

============================================================
ğŸ‰ ANALYSIS COMPLETED SUCCESSFULLY!
============================================================
Results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/pure_moor_topological_autoencoder_no_attention_20250724_224242

Experiment saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/pure_moor_topological_autoencoder_no_attention_20250724_224242

Analysis completed with exit code: 0
Time: Thu 24 Jul 23:57:37 BST 2025

=== ANALYSIS SUCCESSFUL ===
Regularization successful!


Job finished.
