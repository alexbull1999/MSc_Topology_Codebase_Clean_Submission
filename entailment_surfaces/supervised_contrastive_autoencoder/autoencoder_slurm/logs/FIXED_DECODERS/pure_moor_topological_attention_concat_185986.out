Starting Surface Distance Metric Analysis job...
Job ID: 185986
Node: gpuvm16
Time: Thu 24 Jul 22:19:49 BST 2025
Loading CUDA...
Activating conda environment...
Activated conda environment: /vol/bitbucket/ahb24/tda_entailment_new
Python location: /vol/bitbucket/ahb24/tda_entailment_new/bin/python
Checking GPU availability...
Thu Jul 24 22:19:51 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.133.07             Driver Version: 570.133.07     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla T4                       Off |   00000000:00:06.0 Off |                    0 |
| N/A   36C    P8             13W /   70W |       0MiB /  15360MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+

Testing PyTorch and CUDA...
PyTorch version: 2.4.1
CUDA available: True
CUDA device: Tesla T4
GPU memory: 15.6 GB
PyTorch setup verified!

Starting Topological Training...

============================================================
TOPOLOGICAL AUTOENCODER TRAINING WITH TORCHPH
============================================================
Experiment setup completed:
  Experiment directory: entailment_surfaces/supervised_contrastive_autoencoder/experiments/pure_moor_topological_autoencoder_attention_20250724_222029
  Config saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/pure_moor_topological_autoencoder_attention_20250724_222029/config.json
Loading data...
========================================
FlexibleEmbedder initialized with type: 'concat'
Output dimension will be: 1536
GlobalDataLoader initialized:
  Embedding type: concat
  Output dimension: 1536
  Sample size: All
Starting data loading pipeline...
============================================================
Loading training data from data/processed/snli_full_standard_SBERT.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 549367 training samples
Loading validation data from data/processed/snli_full_standard_SBERT_validation.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9842 validation samples
Loading test data from data/processed/snli_full_standard_SBERT_test.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9824 test samples
Generating embeddings for training...
Generating concat embeddings on cuda
Processing 549367 samples in batches of 1000
  Processing batch 1/550
  Processing batch 6/550
  Processing batch 11/550
  Processing batch 16/550
  Processing batch 21/550
  Processing batch 26/550
  Processing batch 31/550
  Processing batch 36/550
  Processing batch 41/550
  Processing batch 46/550
  Processing batch 51/550
  Processing batch 56/550
  Processing batch 61/550
  Processing batch 66/550
  Processing batch 71/550
  Processing batch 76/550
  Processing batch 81/550
  Processing batch 86/550
  Processing batch 91/550
  Processing batch 96/550
  Processing batch 101/550
  Processing batch 106/550
  Processing batch 111/550
  Processing batch 116/550
  Processing batch 121/550
  Processing batch 126/550
  Processing batch 131/550
  Processing batch 136/550
  Processing batch 141/550
  Processing batch 146/550
  Processing batch 151/550
  Processing batch 156/550
  Processing batch 161/550
  Processing batch 166/550
  Processing batch 171/550
  Processing batch 176/550
  Processing batch 181/550
  Processing batch 186/550
  Processing batch 191/550
  Processing batch 196/550
  Processing batch 201/550
  Processing batch 206/550
  Processing batch 211/550
  Processing batch 216/550
  Processing batch 221/550
  Processing batch 226/550
  Processing batch 231/550
  Processing batch 236/550
  Processing batch 241/550
  Processing batch 246/550
  Processing batch 251/550
  Processing batch 256/550
  Processing batch 261/550
  Processing batch 266/550
  Processing batch 271/550
  Processing batch 276/550
  Processing batch 281/550
  Processing batch 286/550
  Processing batch 291/550
  Processing batch 296/550
  Processing batch 301/550
  Processing batch 306/550
  Processing batch 311/550
  Processing batch 316/550
  Processing batch 321/550
  Processing batch 326/550
  Processing batch 331/550
  Processing batch 336/550
  Processing batch 341/550
  Processing batch 346/550
  Processing batch 351/550
  Processing batch 356/550
  Processing batch 361/550
  Processing batch 366/550
  Processing batch 371/550
  Processing batch 376/550
  Processing batch 381/550
  Processing batch 386/550
  Processing batch 391/550
  Processing batch 396/550
  Processing batch 401/550
  Processing batch 406/550
  Processing batch 411/550
  Processing batch 416/550
  Processing batch 421/550
  Processing batch 426/550
  Processing batch 431/550
  Processing batch 436/550
  Processing batch 441/550
  Processing batch 446/550
  Processing batch 451/550
  Processing batch 456/550
  Processing batch 461/550
  Processing batch 466/550
  Processing batch 471/550
  Processing batch 476/550
  Processing batch 481/550
  Processing batch 486/550
  Processing batch 491/550
  Processing batch 496/550
  Processing batch 501/550
  Processing batch 506/550
  Processing batch 511/550
  Processing batch 516/550
  Processing batch 521/550
  Processing batch 526/550
  Processing batch 531/550
  Processing batch 536/550
  Processing batch 541/550
  Processing batch 546/550
Generated concat embeddings: torch.Size([549367, 1536])
Generating embeddings for validation...
Generating concat embeddings on cuda
Processing 9842 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9842, 1536])
Generating embeddings for test...
Generating concat embeddings on cuda
Processing 9824 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9824, 1536])
EntailmentDataset created: 549367 samples
  Embedding shape: torch.Size([549367, 1536])
  Class distribution: {'entailment': 183416, 'neutral': 182764, 'contradiction': 183187}
EntailmentDataset created: 9842 samples
  Embedding shape: torch.Size([9842, 1536])
  Class distribution: {'entailment': 3329, 'neutral': 3235, 'contradiction': 3278}
EntailmentDataset created: 9824 samples
  Embedding shape: torch.Size([9824, 1536])
  Class distribution: {'entailment': 3368, 'neutral': 3219, 'contradiction': 3237}

Data loading pipeline completed!
Output embedding dimension: 1536
Updated model input_dim to: 1536
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 537
  Class 2: 183187 samples
  Class 0: 183416 samples
  Class 1: 182764 samples
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 9
  Class 2: 3278 samples
  Class 0: 3329 samples
  Class 1: 3235 samples
DataLoaders created:
  Batch size: 1020
  Balanced sampling: True
  Train batches: 537
  Val batches: 9
  Test batches: 10
Data loading completed!
  Train: 549367 samples, 537 batches
  Val: 9842 samples, 9 batches
  Test: 9824 samples, 10 batches
AttentionAutoencoder initialized:
  Input dim: 1536
  Latent dim: 75
  Hidden dims: [1024, 768, 512, 256, 128]
  Attention Heads: 5
  Total parameters: 3,068,401
FullDatasetContrastiveLoss initialized:
  Margin: 2.0
  Update frequency: 3 epochs
  Max global samples: 5000
FullDatasetCombinedLoss initialized:
  Contrastive weight: 0.0
  Base reconstruction weight: 100.0
MoorTopologicalLoss Initialized: Using 0-dimensional persistence pairings (MST edges).
No prototypes being used for topological loss - whole dataset instead.
TopologicalTrainer initialized on device: cuda
Model parameters: 3,068,401
Enhanced with topological loss monitoring
Starting Phase 1: Pure Topological Training
  Contrastive weight: 0.0
  Topological weight: 1.0
  Reconstruction weight: 100.0

======================================================================
ğŸ§  TOPOLOGICAL AUTOENCODER TRAINING STARTED
======================================================================

============================================================
EPOCH 1 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=53.3113 (C:2.5798, R:0.3316, T:20.1502(w:1.000)âš ï¸)
Batch  25/537: Loss=10.8874 (C:4.8211, R:0.0627, T:4.6172(w:1.000)ğŸš€)
Batch  50/537: Loss=9.2493 (C:4.9061, R:0.0520, T:4.0533(w:1.000)ğŸš€)
Batch  75/537: Loss=8.0111 (C:4.9694, R:0.0454, T:3.4744(w:1.000)ğŸš€)
Batch 100/537: Loss=6.8226 (C:5.1223, R:0.0393, T:2.8934(w:1.000)ğŸš€)
Batch 125/537: Loss=6.0249 (C:5.4658, R:0.0342, T:2.6015(w:1.000)ğŸš€)
Batch 150/537: Loss=5.2537 (C:5.4973, R:0.0286, T:2.3962(w:1.000)ğŸš€)
Batch 175/537: Loss=4.5579 (C:5.7585, R:0.0252, T:2.0337(w:1.000)ğŸš€)
Batch 200/537: Loss=4.1371 (C:5.7894, R:0.0213, T:2.0026(w:1.000)ğŸš€)
Batch 225/537: Loss=3.8943 (C:5.9481, R:0.0195, T:1.9457(w:1.000)ğŸš€)
Batch 250/537: Loss=3.4537 (C:5.9643, R:0.0171, T:1.7449(w:1.000)ğŸš€)
Batch 275/537: Loss=3.2315 (C:6.1355, R:0.0156, T:1.6691(w:1.000)ğŸš€)
Batch 300/537: Loss=3.1084 (C:6.0139, R:0.0145, T:1.6544(w:1.000)ğŸš€)
Batch 325/537: Loss=2.8818 (C:6.0662, R:0.0135, T:1.5367(w:1.000)ğŸš€)
Batch 350/537: Loss=2.8603 (C:6.0961, R:0.0127, T:1.5917(w:1.000)ğŸš€)
Batch 375/537: Loss=2.7267 (C:6.1296, R:0.0121, T:1.5165(w:1.000)ğŸš€)
Batch 400/537: Loss=2.6614 (C:6.0681, R:0.0115, T:1.5108(w:1.000)ğŸš€)
Batch 425/537: Loss=2.5659 (C:5.9833, R:0.0110, T:1.4705(w:1.000)ğŸš€)
Batch 450/537: Loss=2.4807 (C:6.0448, R:0.0107, T:1.4135(w:1.000)ğŸš€)
Batch 475/537: Loss=2.5034 (C:6.1667, R:0.0104, T:1.4605(w:1.000)ğŸš€)
Batch 500/537: Loss=2.3309 (C:6.1705, R:0.0101, T:1.3164(w:1.000)ğŸš€)
Batch 525/537: Loss=2.2631 (C:6.1248, R:0.0098, T:1.2786(w:1.000)ğŸš€)
ğŸ‰ MILESTONE: First topological learning detected at epoch 1!
   Initial topological loss: 2.2239
ğŸ“ˆ New best topological loss: 2.2239

ğŸ“Š EPOCH 1 TRAINING SUMMARY:
  Total Loss: 4.8496
  Contrastive: 5.7318
  Reconstruction: 0.0263
  Topological: 2.2239 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 9.1832
  Contrastive: 4.8950
  Reconstruction: 0.0079
  Topological: 8.3950 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 1/300 COMPLETE (41.4s)
Train Loss: 4.8496 (C:5.7318, R:0.0263, T:2.2239)
Val Loss:   9.1832 (C:4.8950, R:0.0079, T:8.3950)
ğŸš€ Good topological learning progress
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 2 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=2.2658 (C:6.1054, R:0.0098, T:1.2874(w:1.000)ğŸš€)
Batch  25/537: Loss=2.2047 (C:6.1111, R:0.0096, T:1.2478(w:1.000)ğŸš€)
Batch  50/537: Loss=2.2727 (C:6.0566, R:0.0094, T:1.3318(w:1.000)ğŸš€)
Batch  75/537: Loss=2.1529 (C:6.0458, R:0.0092, T:1.2307(w:1.000)ğŸš€)
Batch 100/537: Loss=2.1615 (C:6.0762, R:0.0092, T:1.2440(w:1.000)ğŸš€)
Batch 125/537: Loss=2.2126 (C:6.1421, R:0.0091, T:1.2989(w:1.000)ğŸš€)
Batch 150/537: Loss=2.0984 (C:5.9866, R:0.0089, T:1.2090(w:1.000)ğŸš€)
Batch 175/537: Loss=2.0769 (C:6.0911, R:0.0088, T:1.1936(w:1.000)ğŸš€)
Batch 200/537: Loss=2.1387 (C:6.0692, R:0.0089, T:1.2528(w:1.000)ğŸš€)
Batch 225/537: Loss=2.0448 (C:6.0786, R:0.0087, T:1.1763(w:1.000)ğŸš€)
Batch 250/537: Loss=2.0939 (C:6.0834, R:0.0086, T:1.2354(w:1.000)ğŸš€)
Batch 275/537: Loss=2.0502 (C:6.1055, R:0.0086, T:1.1939(w:1.000)ğŸš€)
Batch 300/537: Loss=2.0293 (C:6.1164, R:0.0085, T:1.1789(w:1.000)ğŸš€)
Batch 325/537: Loss=2.0242 (C:6.0626, R:0.0085, T:1.1777(w:1.000)ğŸš€)
Batch 350/537: Loss=2.0163 (C:6.1722, R:0.0085, T:1.1696(w:1.000)ğŸš€)
Batch 375/537: Loss=1.9320 (C:6.0418, R:0.0084, T:1.0955(w:1.000)ğŸš€)
Batch 400/537: Loss=1.9846 (C:6.0414, R:0.0083, T:1.1504(w:1.000)ğŸš€)
Batch 425/537: Loss=1.9267 (C:6.0394, R:0.0082, T:1.1038(w:1.000)ğŸš€)
Batch 450/537: Loss=1.9313 (C:6.1167, R:0.0083, T:1.1048(w:1.000)ğŸš€)
Batch 475/537: Loss=1.8920 (C:6.0616, R:0.0082, T:1.0730(w:1.000)ğŸš€)
Batch 500/537: Loss=1.8902 (C:6.0478, R:0.0082, T:1.0727(w:1.000)ğŸš€)
Batch 525/537: Loss=1.8832 (C:6.0894, R:0.0081, T:1.0707(w:1.000)ğŸš€)
ğŸ“ˆ New best topological loss: 1.1864

ğŸ“Š EPOCH 2 TRAINING SUMMARY:
  Total Loss: 2.0560
  Contrastive: 6.0752
  Reconstruction: 0.0087
  Topological: 1.1864 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 7.5664
  Contrastive: 4.9464
  Reconstruction: 0.0074
  Topological: 6.8259 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 2/300 COMPLETE (39.0s)
Train Loss: 2.0560 (C:6.0752, R:0.0087, T:1.1864)
Val Loss:   7.5664 (C:4.9464, R:0.0074, T:6.8259)
ğŸš€ Good topological learning progress
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 3 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.8794 (C:6.0842, R:0.0082, T:1.0596(w:1.000)ğŸš€)
Batch  25/537: Loss=1.8729 (C:6.0567, R:0.0081, T:1.0613(w:1.000)ğŸš€)
Batch  50/537: Loss=1.9568 (C:6.1269, R:0.0081, T:1.1453(w:1.000)ğŸš€)
Batch  75/537: Loss=1.8844 (C:6.0788, R:0.0081, T:1.0768(w:1.000)ğŸš€)
Batch 100/537: Loss=1.8627 (C:6.0913, R:0.0081, T:1.0552(w:1.000)ğŸš€)
Batch 125/537: Loss=1.8274 (C:6.0578, R:0.0080, T:1.0262(w:1.000)ğŸš€)
Batch 150/537: Loss=1.8350 (C:6.2061, R:0.0080, T:1.0334(w:1.000)ğŸš€)
Batch 175/537: Loss=1.7965 (C:6.0723, R:0.0079, T:1.0058(w:1.000)ğŸš€)
Batch 200/537: Loss=1.8169 (C:6.0014, R:0.0079, T:1.0252(w:1.000)ğŸš€)
Batch 225/537: Loss=1.7726 (C:6.1274, R:0.0080, T:0.9761(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.8369 (C:5.9935, R:0.0080, T:1.0418(w:1.000)ğŸš€)
Batch 275/537: Loss=1.8299 (C:6.0551, R:0.0079, T:1.0360(w:1.000)ğŸš€)
Batch 300/537: Loss=1.8033 (C:6.1074, R:0.0079, T:1.0104(w:1.000)ğŸš€)
Batch 325/537: Loss=1.7942 (C:6.0447, R:0.0079, T:1.0049(w:1.000)ğŸš€)
Batch 350/537: Loss=1.7814 (C:6.0090, R:0.0079, T:0.9915(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.7947 (C:6.0868, R:0.0079, T:1.0014(w:1.000)ğŸš€)
Batch 400/537: Loss=1.7867 (C:6.0489, R:0.0079, T:0.9968(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.7843 (C:6.0590, R:0.0079, T:0.9923(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.7831 (C:6.0406, R:0.0078, T:0.9998(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.7824 (C:6.0551, R:0.0078, T:0.9988(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.8237 (C:5.9434, R:0.0078, T:1.0434(w:1.000)ğŸš€)
Batch 525/537: Loss=1.7478 (C:6.0501, R:0.0078, T:0.9690(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 1.0103

ğŸ“Š EPOCH 3 TRAINING SUMMARY:
  Total Loss: 1.8042
  Contrastive: 6.0559
  Reconstruction: 0.0079
  Topological: 1.0103 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.6340
  Contrastive: 5.0072
  Reconstruction: 0.0072
  Topological: 5.9160 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 3/300 COMPLETE (38.3s)
Train Loss: 1.8042 (C:6.0559, R:0.0079, T:1.0103)
Val Loss:   6.6340 (C:5.0072, R:0.0072, T:5.9160)
ğŸš€ Good topological learning progress
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 4 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.7442 (C:6.0175, R:0.0078, T:0.9666(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.7031 (C:6.0763, R:0.0077, T:0.9291(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.7635 (C:6.0289, R:0.0078, T:0.9845(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.7563 (C:6.0758, R:0.0079, T:0.9711(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.6915 (C:6.0246, R:0.0077, T:0.9205(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.7672 (C:6.0145, R:0.0078, T:0.9910(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.7279 (C:5.9891, R:0.0078, T:0.9502(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.6666 (C:6.0749, R:0.0077, T:0.8940(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.6802 (C:6.0902, R:0.0077, T:0.9073(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.7210 (C:5.9784, R:0.0077, T:0.9494(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.7384 (C:6.0835, R:0.0077, T:0.9682(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.7051 (C:6.1048, R:0.0077, T:0.9396(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.7042 (C:6.0343, R:0.0077, T:0.9337(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.6718 (C:6.0686, R:0.0077, T:0.9031(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.6802 (C:6.0695, R:0.0077, T:0.9133(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.6848 (C:6.0110, R:0.0077, T:0.9118(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.6977 (C:6.0312, R:0.0077, T:0.9310(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.6682 (C:6.0174, R:0.0076, T:0.9073(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.6660 (C:6.0202, R:0.0076, T:0.9028(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.6523 (C:6.0398, R:0.0077, T:0.8850(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.6772 (C:6.0148, R:0.0076, T:0.9209(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.5853 (C:5.9712, R:0.0076, T:0.8239(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.9226

ğŸ“Š EPOCH 4 TRAINING SUMMARY:
  Total Loss: 1.6920
  Contrastive: 6.0364
  Reconstruction: 0.0077
  Topological: 0.9226 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.7678
  Contrastive: 5.1442
  Reconstruction: 0.0070
  Topological: 5.0688 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 4/300 COMPLETE (38.1s)
Train Loss: 1.6920 (C:6.0364, R:0.0077, T:0.9226)
Val Loss:   5.7678 (C:5.1442, R:0.0070, T:5.0688)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 5 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.6211 (C:6.0215, R:0.0076, T:0.8637(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.6086 (C:6.0147, R:0.0076, T:0.8478(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.6076 (C:5.9372, R:0.0075, T:0.8527(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.6698 (C:6.0686, R:0.0076, T:0.9127(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.6345 (C:6.0494, R:0.0076, T:0.8700(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.6181 (C:6.0885, R:0.0076, T:0.8619(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.6362 (C:6.0389, R:0.0076, T:0.8763(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.6060 (C:6.0096, R:0.0076, T:0.8436(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.6357 (C:6.0448, R:0.0076, T:0.8798(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.6235 (C:6.0565, R:0.0076, T:0.8657(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.6300 (C:5.9358, R:0.0076, T:0.8739(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.6105 (C:5.9826, R:0.0076, T:0.8517(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.5879 (C:6.0253, R:0.0075, T:0.8374(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.5921 (C:6.0528, R:0.0075, T:0.8396(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.5385 (C:6.0613, R:0.0075, T:0.7846(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.6196 (C:5.9595, R:0.0076, T:0.8624(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.5668 (C:6.0257, R:0.0075, T:0.8175(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.6383 (C:5.9995, R:0.0075, T:0.8894(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.5742 (C:5.9631, R:0.0075, T:0.8241(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.5811 (C:5.9537, R:0.0075, T:0.8356(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.5985 (C:6.0119, R:0.0075, T:0.8471(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.5328 (C:5.9958, R:0.0075, T:0.7841(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.8535

ğŸ“Š EPOCH 5 TRAINING SUMMARY:
  Total Loss: 1.6089
  Contrastive: 6.0255
  Reconstruction: 0.0076
  Topological: 0.8535 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.1564
  Contrastive: 5.1960
  Reconstruction: 0.0069
  Topological: 4.4690 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 5/300 COMPLETE (38.6s)
Train Loss: 1.6089 (C:6.0255, R:0.0076, T:0.8535)
Val Loss:   5.1564 (C:5.1960, R:0.0069, T:4.4690)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 6 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.5921 (C:6.0193, R:0.0075, T:0.8418(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.5884 (C:6.0228, R:0.0075, T:0.8364(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.5651 (C:6.0012, R:0.0075, T:0.8158(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.5697 (C:6.0666, R:0.0075, T:0.8156(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.5341 (C:6.0428, R:0.0074, T:0.7893(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.5649 (C:6.0015, R:0.0075, T:0.8198(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.5614 (C:5.9823, R:0.0074, T:0.8167(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.5902 (C:5.9806, R:0.0075, T:0.8425(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.5709 (C:6.0538, R:0.0074, T:0.8289(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.5489 (C:6.0138, R:0.0075, T:0.8014(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.5263 (C:5.9884, R:0.0074, T:0.7818(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.5920 (C:6.0427, R:0.0075, T:0.8434(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.5473 (C:5.9929, R:0.0074, T:0.8079(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.5897 (C:6.0051, R:0.0075, T:0.8419(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.5566 (C:6.0145, R:0.0075, T:0.8105(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.5560 (C:6.0104, R:0.0075, T:0.8014(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.5169 (C:5.9966, R:0.0074, T:0.7762(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.5309 (C:5.9791, R:0.0074, T:0.7914(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.5534 (C:6.0023, R:0.0075, T:0.8081(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.4939 (C:5.9908, R:0.0074, T:0.7550(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.5339 (C:5.9878, R:0.0074, T:0.7916(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.5101 (C:5.9953, R:0.0074, T:0.7652(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.8086

ğŸ“Š EPOCH 6 TRAINING SUMMARY:
  Total Loss: 1.5539
  Contrastive: 6.0088
  Reconstruction: 0.0075
  Topological: 0.8086 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.7626
  Contrastive: 5.2333
  Reconstruction: 0.0068
  Topological: 4.0852 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 6/300 COMPLETE (37.7s)
Train Loss: 1.5539 (C:6.0088, R:0.0075, T:0.8086)
Val Loss:   4.7626 (C:5.2333, R:0.0068, T:4.0852)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 7 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.5068 (C:6.0205, R:0.0074, T:0.7671(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.5103 (C:5.9726, R:0.0074, T:0.7679(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.5402 (C:5.9941, R:0.0074, T:0.7971(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.5055 (C:6.0824, R:0.0074, T:0.7656(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.4936 (C:6.0387, R:0.0074, T:0.7527(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.5342 (C:5.9843, R:0.0075, T:0.7883(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.5020 (C:6.0115, R:0.0074, T:0.7638(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.4989 (C:5.9776, R:0.0074, T:0.7616(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.4863 (C:6.0341, R:0.0074, T:0.7498(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.5423 (C:5.9669, R:0.0074, T:0.8010(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.5416 (C:5.9256, R:0.0074, T:0.8029(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.4820 (C:5.9789, R:0.0074, T:0.7440(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.5204 (C:5.9806, R:0.0073, T:0.7856(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.5128 (C:6.0308, R:0.0074, T:0.7744(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.5134 (C:6.0097, R:0.0074, T:0.7724(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.5054 (C:6.0537, R:0.0073, T:0.7705(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.5236 (C:6.0048, R:0.0074, T:0.7837(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.5251 (C:6.0611, R:0.0074, T:0.7877(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.5061 (C:5.9753, R:0.0074, T:0.7682(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.5168 (C:5.9798, R:0.0073, T:0.7825(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.4891 (C:6.0395, R:0.0074, T:0.7516(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.4569 (C:6.0214, R:0.0074, T:0.7199(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.7708

ğŸ“Š EPOCH 7 TRAINING SUMMARY:
  Total Loss: 1.5094
  Contrastive: 6.0026
  Reconstruction: 0.0074
  Topological: 0.7708 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.3702
  Contrastive: 5.3067
  Reconstruction: 0.0067
  Topological: 3.6981 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 7/300 COMPLETE (38.5s)
Train Loss: 1.5094 (C:6.0026, R:0.0074, T:0.7708)
Val Loss:   4.3702 (C:5.3067, R:0.0067, T:3.6981)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 8 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.4974 (C:5.9755, R:0.0074, T:0.7606(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.4995 (C:6.0196, R:0.0074, T:0.7613(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.4886 (C:6.0123, R:0.0074, T:0.7520(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.4742 (C:6.0160, R:0.0073, T:0.7432(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.4802 (C:5.9964, R:0.0073, T:0.7494(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.4928 (C:5.9797, R:0.0074, T:0.7572(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.4959 (C:5.9936, R:0.0073, T:0.7609(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.4426 (C:5.9748, R:0.0073, T:0.7119(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.4892 (C:5.9511, R:0.0073, T:0.7583(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.4870 (C:5.9597, R:0.0074, T:0.7496(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.4738 (C:6.0151, R:0.0073, T:0.7434(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.4517 (C:6.0413, R:0.0074, T:0.7164(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.4896 (C:5.9952, R:0.0073, T:0.7598(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.4446 (C:6.0234, R:0.0073, T:0.7106(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.4391 (C:5.9991, R:0.0073, T:0.7071(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.4412 (C:5.9541, R:0.0073, T:0.7099(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.4606 (C:5.9562, R:0.0073, T:0.7340(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.4748 (C:6.0181, R:0.0073, T:0.7446(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.4653 (C:5.9834, R:0.0073, T:0.7356(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.4501 (C:5.9811, R:0.0073, T:0.7223(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.4713 (C:5.9733, R:0.0073, T:0.7440(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.4875 (C:5.9932, R:0.0073, T:0.7597(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.7401

ğŸ“Š EPOCH 8 TRAINING SUMMARY:
  Total Loss: 1.4726
  Contrastive: 5.9951
  Reconstruction: 0.0073
  Topological: 0.7401 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.0271
  Contrastive: 5.3499
  Reconstruction: 0.0066
  Topological: 3.3645 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 8/300 COMPLETE (39.1s)
Train Loss: 1.4726 (C:5.9951, R:0.0073, T:0.7401)
Val Loss:   4.0271 (C:5.3499, R:0.0066, T:3.3645)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 9 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.4417 (C:5.9666, R:0.0073, T:0.7105(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.4282 (C:5.9724, R:0.0073, T:0.6971(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.4627 (C:5.9865, R:0.0073, T:0.7332(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.4322 (C:5.9495, R:0.0073, T:0.7036(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.4299 (C:5.9785, R:0.0073, T:0.7026(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.4413 (C:5.9623, R:0.0073, T:0.7152(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.4201 (C:5.9792, R:0.0073, T:0.6940(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.4563 (C:5.9795, R:0.0073, T:0.7284(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.4419 (C:5.9954, R:0.0072, T:0.7187(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.4407 (C:5.9376, R:0.0073, T:0.7122(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.4583 (C:6.0376, R:0.0073, T:0.7260(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.4579 (C:6.0121, R:0.0073, T:0.7284(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.4491 (C:5.9945, R:0.0073, T:0.7220(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.4387 (C:5.9753, R:0.0073, T:0.7123(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.4167 (C:5.9794, R:0.0073, T:0.6901(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.4486 (C:5.9363, R:0.0072, T:0.7244(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.3985 (C:5.9669, R:0.0072, T:0.6749(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.4392 (C:5.9976, R:0.0072, T:0.7150(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.3904 (C:5.9815, R:0.0073, T:0.6599(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.4229 (C:5.9964, R:0.0072, T:0.7019(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.4116 (C:5.8830, R:0.0073, T:0.6852(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.4391 (C:6.0399, R:0.0073, T:0.7118(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.7104

ğŸ“Š EPOCH 9 TRAINING SUMMARY:
  Total Loss: 1.4371
  Contrastive: 5.9788
  Reconstruction: 0.0073
  Topological: 0.7104 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 3.5799
  Contrastive: 5.4732
  Reconstruction: 0.0066
  Topological: 2.9217 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 9/300 COMPLETE (38.1s)
Train Loss: 1.4371 (C:5.9788, R:0.0073, T:0.7104)
Val Loss:   3.5799 (C:5.4732, R:0.0066, T:2.9217)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 10 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.4260 (C:5.9835, R:0.0073, T:0.7000(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.4201 (C:5.9159, R:0.0072, T:0.6973(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.3927 (C:5.9107, R:0.0072, T:0.6695(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.4501 (C:6.0085, R:0.0072, T:0.7263(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.4080 (C:5.9716, R:0.0073, T:0.6806(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.4398 (C:5.9653, R:0.0073, T:0.7104(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.4234 (C:5.9898, R:0.0073, T:0.6954(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.4259 (C:5.9529, R:0.0072, T:0.7013(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.3716 (C:5.9680, R:0.0072, T:0.6486(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.4249 (C:5.9393, R:0.0073, T:0.6991(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.4110 (C:5.9973, R:0.0072, T:0.6912(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.4089 (C:5.9819, R:0.0072, T:0.6901(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.4297 (C:5.9887, R:0.0072, T:0.7067(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.4094 (C:5.9425, R:0.0072, T:0.6881(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.3790 (C:5.9475, R:0.0072, T:0.6594(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.4166 (C:5.8984, R:0.0073, T:0.6887(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.3869 (C:5.9729, R:0.0072, T:0.6668(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.3983 (C:5.9191, R:0.0072, T:0.6804(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.4377 (C:5.9606, R:0.0072, T:0.7160(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.3835 (C:5.8819, R:0.0072, T:0.6658(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.3622 (C:5.9229, R:0.0071, T:0.6490(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.4425 (C:5.8621, R:0.0072, T:0.7179(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6835

ğŸ“Š EPOCH 10 TRAINING SUMMARY:
  Total Loss: 1.4062
  Contrastive: 5.9608
  Reconstruction: 0.0072
  Topological: 0.6835 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 3.5457
  Contrastive: 5.4219
  Reconstruction: 0.0066
  Topological: 2.8881 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 10/300 COMPLETE (38.3s)
Train Loss: 1.4062 (C:5.9608, R:0.0072, T:0.6835)
Val Loss:   3.5457 (C:5.4219, R:0.0066, T:2.8881)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 11 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.4262 (C:5.8359, R:0.0072, T:0.7066(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.3744 (C:5.9338, R:0.0072, T:0.6568(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.4220 (C:5.9763, R:0.0072, T:0.7014(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.3608 (C:5.9287, R:0.0072, T:0.6408(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.3510 (C:5.9348, R:0.0072, T:0.6354(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.4015 (C:5.9304, R:0.0072, T:0.6808(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.3859 (C:5.8742, R:0.0072, T:0.6674(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.3730 (C:5.9102, R:0.0072, T:0.6546(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.3427 (C:5.9330, R:0.0071, T:0.6294(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.3668 (C:5.8837, R:0.0071, T:0.6537(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.3676 (C:5.9549, R:0.0072, T:0.6509(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.3651 (C:5.9476, R:0.0072, T:0.6476(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.3976 (C:5.9755, R:0.0072, T:0.6727(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.3735 (C:5.9082, R:0.0071, T:0.6590(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.3870 (C:5.9708, R:0.0073, T:0.6584(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.4030 (C:5.9585, R:0.0072, T:0.6780(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.3496 (C:5.9973, R:0.0072, T:0.6321(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.3932 (C:5.9396, R:0.0072, T:0.6749(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.3468 (C:5.9085, R:0.0072, T:0.6286(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.3623 (C:5.9331, R:0.0072, T:0.6466(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.3995 (C:5.9760, R:0.0072, T:0.6800(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.3880 (C:5.9300, R:0.0072, T:0.6694(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6614

ğŸ“Š EPOCH 11 TRAINING SUMMARY:
  Total Loss: 1.3809
  Contrastive: 5.9457
  Reconstruction: 0.0072
  Topological: 0.6614 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.9149
  Contrastive: 5.7024
  Reconstruction: 0.0065
  Topological: 2.2650 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 11/300 COMPLETE (38.8s)
Train Loss: 1.3809 (C:5.9457, R:0.0072, T:0.6614)
Val Loss:   2.9149 (C:5.7024, R:0.0065, T:2.2650)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 12 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.3780 (C:5.9587, R:0.0072, T:0.6585(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.3993 (C:5.8479, R:0.0072, T:0.6788(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.3542 (C:5.9358, R:0.0072, T:0.6337(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.3825 (C:5.9346, R:0.0072, T:0.6628(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.3070 (C:5.9463, R:0.0072, T:0.5914(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.3558 (C:5.9131, R:0.0071, T:0.6453(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.3978 (C:5.9155, R:0.0072, T:0.6805(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.3758 (C:5.8864, R:0.0072, T:0.6570(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.3695 (C:5.9607, R:0.0072, T:0.6489(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.3827 (C:5.9389, R:0.0073, T:0.6576(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.3083 (C:5.9021, R:0.0071, T:0.5957(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.3234 (C:5.9116, R:0.0071, T:0.6102(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.3537 (C:5.9445, R:0.0072, T:0.6378(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.3614 (C:5.9212, R:0.0072, T:0.6454(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.3409 (C:5.9051, R:0.0071, T:0.6295(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.3656 (C:5.9257, R:0.0072, T:0.6488(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.3694 (C:5.9436, R:0.0071, T:0.6548(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.3646 (C:5.9245, R:0.0072, T:0.6483(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.3434 (C:5.8994, R:0.0072, T:0.6280(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.3556 (C:5.9015, R:0.0071, T:0.6456(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.3995 (C:5.9313, R:0.0071, T:0.6863(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.3236 (C:5.8855, R:0.0071, T:0.6158(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6432

ğŸ“Š EPOCH 12 TRAINING SUMMARY:
  Total Loss: 1.3597
  Contrastive: 5.9293
  Reconstruction: 0.0072
  Topological: 0.6432 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.7122
  Contrastive: 5.7752
  Reconstruction: 0.0065
  Topological: 2.0654 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 12/300 COMPLETE (39.0s)
Train Loss: 1.3597 (C:5.9293, R:0.0072, T:0.6432)
Val Loss:   2.7122 (C:5.7752, R:0.0065, T:2.0654)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 13 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.3497 (C:5.9332, R:0.0072, T:0.6329(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.3737 (C:5.9467, R:0.0071, T:0.6593(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.3449 (C:5.9037, R:0.0071, T:0.6329(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.3170 (C:5.9116, R:0.0071, T:0.6039(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.3131 (C:5.9015, R:0.0071, T:0.6032(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.3480 (C:5.9497, R:0.0072, T:0.6298(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.3316 (C:5.9282, R:0.0071, T:0.6238(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.3482 (C:5.9174, R:0.0071, T:0.6338(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.3378 (C:5.8611, R:0.0071, T:0.6241(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.3037 (C:5.9079, R:0.0071, T:0.5915(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.3480 (C:5.9369, R:0.0071, T:0.6362(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.3500 (C:5.9361, R:0.0071, T:0.6363(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.3374 (C:5.9172, R:0.0071, T:0.6243(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.3073 (C:5.9016, R:0.0072, T:0.5875(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.3325 (C:5.9250, R:0.0072, T:0.6152(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.3454 (C:5.8942, R:0.0072, T:0.6278(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.3477 (C:5.8924, R:0.0072, T:0.6305(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.3232 (C:5.9218, R:0.0071, T:0.6122(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.3395 (C:5.8575, R:0.0072, T:0.6243(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.3250 (C:5.8924, R:0.0071, T:0.6136(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.3567 (C:5.9214, R:0.0072, T:0.6401(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.3190 (C:5.8699, R:0.0071, T:0.6093(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6294

ğŸ“Š EPOCH 13 TRAINING SUMMARY:
  Total Loss: 1.3430
  Contrastive: 5.9119
  Reconstruction: 0.0071
  Topological: 0.6294 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.6135
  Contrastive: 5.8070
  Reconstruction: 0.0064
  Topological: 1.9725 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 13/300 COMPLETE (38.4s)
Train Loss: 1.3430 (C:5.9119, R:0.0071, T:0.6294)
Val Loss:   2.6135 (C:5.8070, R:0.0064, T:1.9725)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 14 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.3288 (C:5.9118, R:0.0071, T:0.6185(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.3421 (C:5.9285, R:0.0071, T:0.6312(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.3145 (C:5.9193, R:0.0072, T:0.5957(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.3354 (C:5.9258, R:0.0071, T:0.6237(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.3200 (C:5.8582, R:0.0071, T:0.6103(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.3346 (C:5.8870, R:0.0071, T:0.6199(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.3544 (C:5.8715, R:0.0072, T:0.6392(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.3100 (C:5.8911, R:0.0071, T:0.5970(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.3404 (C:5.9499, R:0.0072, T:0.6245(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.3287 (C:5.8756, R:0.0072, T:0.6122(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.3409 (C:5.9477, R:0.0071, T:0.6349(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.3178 (C:5.9447, R:0.0071, T:0.6085(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.3380 (C:5.8864, R:0.0071, T:0.6264(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.3502 (C:5.9128, R:0.0071, T:0.6390(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.3553 (C:5.9021, R:0.0071, T:0.6479(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.3234 (C:5.8677, R:0.0072, T:0.6074(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2759 (C:5.8860, R:0.0071, T:0.5685(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.3082 (C:5.9044, R:0.0071, T:0.6030(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.3574 (C:5.8918, R:0.0071, T:0.6491(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.3431 (C:5.9355, R:0.0071, T:0.6337(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.3166 (C:5.8981, R:0.0071, T:0.6056(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.3348 (C:5.8631, R:0.0070, T:0.6301(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6172

ğŸ“Š EPOCH 14 TRAINING SUMMARY:
  Total Loss: 1.3282
  Contrastive: 5.9031
  Reconstruction: 0.0071
  Topological: 0.6172 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.6727
  Contrastive: 5.7768
  Reconstruction: 0.0064
  Topological: 2.0356 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 14/300 COMPLETE (39.5s)
Train Loss: 1.3282 (C:5.9031, R:0.0071, T:0.6172)
Val Loss:   2.6727 (C:5.7768, R:0.0064, T:2.0356)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 15 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.3115 (C:5.8661, R:0.0071, T:0.5988(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.3053 (C:5.8835, R:0.0071, T:0.5970(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.3193 (C:5.8883, R:0.0071, T:0.6086(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2794 (C:5.8907, R:0.0071, T:0.5718(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.3012 (C:5.8915, R:0.0071, T:0.5951(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.3117 (C:5.8823, R:0.0070, T:0.6084(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.3089 (C:5.9070, R:0.0070, T:0.6057(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.3163 (C:5.8596, R:0.0071, T:0.6110(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.3260 (C:5.9322, R:0.0070, T:0.6232(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.3146 (C:5.9409, R:0.0071, T:0.6008(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2862 (C:5.9023, R:0.0070, T:0.5817(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2696 (C:5.9346, R:0.0071, T:0.5638(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2689 (C:5.9397, R:0.0071, T:0.5624(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.3512 (C:5.8564, R:0.0071, T:0.6382(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.3130 (C:5.8851, R:0.0071, T:0.6016(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2625 (C:5.9001, R:0.0070, T:0.5590(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.3169 (C:5.8708, R:0.0071, T:0.6085(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.3088 (C:5.9223, R:0.0071, T:0.6010(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.3199 (C:5.8912, R:0.0071, T:0.6066(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.3170 (C:5.8811, R:0.0071, T:0.6119(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2829 (C:5.9092, R:0.0070, T:0.5781(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2864 (C:5.8720, R:0.0070, T:0.5823(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6041

ğŸ“Š EPOCH 15 TRAINING SUMMARY:
  Total Loss: 1.3125
  Contrastive: 5.8911
  Reconstruction: 0.0071
  Topological: 0.6041 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.6042
  Contrastive: 5.8003
  Reconstruction: 0.0064
  Topological: 1.9683 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 15/300 COMPLETE (39.3s)
Train Loss: 1.3125 (C:5.8911, R:0.0071, T:0.6041)
Val Loss:   2.6042 (C:5.8003, R:0.0064, T:1.9683)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 16 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.3001 (C:5.8673, R:0.0070, T:0.5986(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2772 (C:5.8595, R:0.0071, T:0.5714(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.3014 (C:5.8783, R:0.0071, T:0.5905(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.3170 (C:5.9158, R:0.0071, T:0.6030(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.3181 (C:5.8878, R:0.0070, T:0.6153(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.3197 (C:5.8590, R:0.0071, T:0.6134(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2899 (C:5.8948, R:0.0070, T:0.5867(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.3017 (C:5.9159, R:0.0071, T:0.5960(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2944 (C:5.9394, R:0.0071, T:0.5847(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.3224 (C:5.8676, R:0.0071, T:0.6171(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.3440 (C:5.8523, R:0.0071, T:0.6329(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2990 (C:5.9366, R:0.0070, T:0.5945(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2804 (C:5.8548, R:0.0071, T:0.5708(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2989 (C:5.8376, R:0.0070, T:0.5946(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2881 (C:5.8694, R:0.0071, T:0.5814(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.3221 (C:5.8809, R:0.0071, T:0.6135(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2995 (C:5.8851, R:0.0071, T:0.5933(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2651 (C:5.9061, R:0.0070, T:0.5643(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2884 (C:5.8700, R:0.0070, T:0.5838(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.3149 (C:5.8465, R:0.0071, T:0.6063(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2839 (C:5.8453, R:0.0071, T:0.5783(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2957 (C:5.8895, R:0.0071, T:0.5900(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5953

ğŸ“Š EPOCH 16 TRAINING SUMMARY:
  Total Loss: 1.3018
  Contrastive: 5.8804
  Reconstruction: 0.0071
  Topological: 0.5953 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.5051
  Contrastive: 5.7949
  Reconstruction: 0.0063
  Topological: 1.8740 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 16/300 COMPLETE (38.1s)
Train Loss: 1.3018 (C:5.8804, R:0.0071, T:0.5953)
Val Loss:   2.5051 (C:5.7949, R:0.0063, T:1.8740)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 17 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2916 (C:5.8424, R:0.0071, T:0.5862(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.3031 (C:5.8773, R:0.0071, T:0.5977(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2815 (C:5.8766, R:0.0071, T:0.5760(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2707 (C:5.8530, R:0.0071, T:0.5636(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2617 (C:5.8742, R:0.0070, T:0.5617(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2821 (C:5.8969, R:0.0071, T:0.5743(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2917 (C:5.8624, R:0.0070, T:0.5896(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2893 (C:5.8528, R:0.0070, T:0.5858(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.3027 (C:5.8258, R:0.0070, T:0.6006(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2946 (C:5.9082, R:0.0070, T:0.5923(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2820 (C:5.8686, R:0.0070, T:0.5771(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2998 (C:5.8827, R:0.0070, T:0.5960(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2800 (C:5.8326, R:0.0071, T:0.5745(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2656 (C:5.8465, R:0.0070, T:0.5611(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2803 (C:5.8615, R:0.0070, T:0.5763(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2760 (C:5.8741, R:0.0070, T:0.5728(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2554 (C:5.8575, R:0.0070, T:0.5555(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2735 (C:5.8715, R:0.0070, T:0.5711(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2972 (C:5.8881, R:0.0070, T:0.5926(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2555 (C:5.8236, R:0.0070, T:0.5531(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2824 (C:5.8609, R:0.0070, T:0.5816(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.3178 (C:5.8070, R:0.0070, T:0.6183(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5822

ğŸ“Š EPOCH 17 TRAINING SUMMARY:
  Total Loss: 1.2865
  Contrastive: 5.8716
  Reconstruction: 0.0070
  Topological: 0.5822 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.4640
  Contrastive: 5.8006
  Reconstruction: 0.0063
  Topological: 1.8335 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 17/300 COMPLETE (38.4s)
Train Loss: 1.2865 (C:5.8716, R:0.0070, T:0.5822)
Val Loss:   2.4640 (C:5.8006, R:0.0063, T:1.8335)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 18 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2863 (C:5.8499, R:0.0070, T:0.5881(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.3031 (C:5.8822, R:0.0070, T:0.6028(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2915 (C:5.8293, R:0.0070, T:0.5901(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2605 (C:5.8454, R:0.0070, T:0.5615(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.3086 (C:5.8384, R:0.0071, T:0.5995(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2879 (C:5.8093, R:0.0070, T:0.5859(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2710 (C:5.8405, R:0.0071, T:0.5628(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2610 (C:5.8528, R:0.0070, T:0.5606(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2520 (C:5.8661, R:0.0070, T:0.5485(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2633 (C:5.8484, R:0.0071, T:0.5571(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2885 (C:5.8997, R:0.0070, T:0.5873(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2848 (C:5.8887, R:0.0070, T:0.5861(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2639 (C:5.8344, R:0.0069, T:0.5696(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2662 (C:5.8547, R:0.0070, T:0.5655(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2768 (C:5.8241, R:0.0070, T:0.5756(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2836 (C:5.8325, R:0.0071, T:0.5782(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2702 (C:5.8396, R:0.0071, T:0.5649(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2654 (C:5.8695, R:0.0071, T:0.5585(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2563 (C:5.8527, R:0.0070, T:0.5522(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2710 (C:5.8698, R:0.0070, T:0.5688(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2719 (C:5.8181, R:0.0070, T:0.5693(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2490 (C:5.8234, R:0.0070, T:0.5497(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5727

ğŸ“Š EPOCH 18 TRAINING SUMMARY:
  Total Loss: 1.2746
  Contrastive: 5.8588
  Reconstruction: 0.0070
  Topological: 0.5727 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.4402
  Contrastive: 5.8020
  Reconstruction: 0.0063
  Topological: 1.8125 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 18/300 COMPLETE (38.5s)
Train Loss: 1.2746 (C:5.8588, R:0.0070, T:0.5727)
Val Loss:   2.4402 (C:5.8020, R:0.0063, T:1.8125)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 19 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2681 (C:5.8525, R:0.0070, T:0.5657(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2430 (C:5.8753, R:0.0070, T:0.5466(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2714 (C:5.8716, R:0.0071, T:0.5649(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2394 (C:5.8407, R:0.0070, T:0.5433(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2472 (C:5.8391, R:0.0070, T:0.5466(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2855 (C:5.8677, R:0.0070, T:0.5878(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2767 (C:5.8425, R:0.0070, T:0.5812(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2570 (C:5.8253, R:0.0070, T:0.5556(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2689 (C:5.8331, R:0.0070, T:0.5690(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2371 (C:5.7841, R:0.0070, T:0.5421(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2685 (C:5.8106, R:0.0070, T:0.5643(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2788 (C:5.8459, R:0.0070, T:0.5743(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2459 (C:5.7962, R:0.0070, T:0.5467(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2752 (C:5.7922, R:0.0070, T:0.5747(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2570 (C:5.8817, R:0.0071, T:0.5515(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2356 (C:5.8157, R:0.0069, T:0.5452(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2180 (C:5.8404, R:0.0069, T:0.5260(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2594 (C:5.8539, R:0.0070, T:0.5561(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2802 (C:5.8234, R:0.0070, T:0.5771(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2377 (C:5.8471, R:0.0070, T:0.5410(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2558 (C:5.8131, R:0.0070, T:0.5533(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2259 (C:5.7938, R:0.0070, T:0.5304(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5602

ğŸ“Š EPOCH 19 TRAINING SUMMARY:
  Total Loss: 1.2608
  Contrastive: 5.8402
  Reconstruction: 0.0070
  Topological: 0.5602 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.4064
  Contrastive: 5.8111
  Reconstruction: 0.0063
  Topological: 1.7775 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 19/300 COMPLETE (38.5s)
Train Loss: 1.2608 (C:5.8402, R:0.0070, T:0.5602)
Val Loss:   2.4064 (C:5.8111, R:0.0063, T:1.7775)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 20 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2714 (C:5.8452, R:0.0070, T:0.5700(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2478 (C:5.8039, R:0.0070, T:0.5502(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2724 (C:5.8198, R:0.0070, T:0.5763(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2199 (C:5.8407, R:0.0070, T:0.5203(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2301 (C:5.8345, R:0.0070, T:0.5330(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2667 (C:5.8489, R:0.0070, T:0.5684(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2040 (C:5.8407, R:0.0070, T:0.5020(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2528 (C:5.8100, R:0.0069, T:0.5610(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2562 (C:5.8510, R:0.0070, T:0.5535(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2548 (C:5.8347, R:0.0070, T:0.5530(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2654 (C:5.8240, R:0.0070, T:0.5634(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2905 (C:5.8415, R:0.0070, T:0.5925(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2340 (C:5.8383, R:0.0070, T:0.5363(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2382 (C:5.8230, R:0.0070, T:0.5388(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2765 (C:5.8177, R:0.0070, T:0.5787(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2769 (C:5.8296, R:0.0070, T:0.5790(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2305 (C:5.8238, R:0.0070, T:0.5308(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2691 (C:5.8256, R:0.0070, T:0.5692(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2112 (C:5.8242, R:0.0070, T:0.5143(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2456 (C:5.8292, R:0.0070, T:0.5505(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2841 (C:5.8584, R:0.0071, T:0.5766(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2269 (C:5.8690, R:0.0070, T:0.5283(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5510

ğŸ“Š EPOCH 20 TRAINING SUMMARY:
  Total Loss: 1.2503
  Contrastive: 5.8266
  Reconstruction: 0.0070
  Topological: 0.5510 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.4765
  Contrastive: 5.7743
  Reconstruction: 0.0063
  Topological: 1.8509 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 20/300 COMPLETE (37.8s)
Train Loss: 1.2503 (C:5.8266, R:0.0070, T:0.5510)
Val Loss:   2.4765 (C:5.7743, R:0.0063, T:1.8509)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 21 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2104 (C:5.8190, R:0.0070, T:0.5112(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2742 (C:5.8319, R:0.0070, T:0.5706(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2316 (C:5.8245, R:0.0070, T:0.5350(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2511 (C:5.8655, R:0.0070, T:0.5539(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2283 (C:5.7748, R:0.0070, T:0.5331(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2310 (C:5.8067, R:0.0070, T:0.5345(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2511 (C:5.8088, R:0.0070, T:0.5468(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2203 (C:5.8032, R:0.0069, T:0.5325(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2212 (C:5.7804, R:0.0070, T:0.5233(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2382 (C:5.7993, R:0.0070, T:0.5408(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2622 (C:5.8080, R:0.0070, T:0.5626(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2638 (C:5.8259, R:0.0071, T:0.5550(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2298 (C:5.8308, R:0.0070, T:0.5279(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2219 (C:5.7713, R:0.0069, T:0.5271(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2371 (C:5.7705, R:0.0070, T:0.5375(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2399 (C:5.8572, R:0.0070, T:0.5405(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2125 (C:5.8165, R:0.0069, T:0.5242(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2234 (C:5.7944, R:0.0069, T:0.5304(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2291 (C:5.8136, R:0.0069, T:0.5364(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2538 (C:5.8050, R:0.0070, T:0.5544(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2324 (C:5.7801, R:0.0070, T:0.5295(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2137 (C:5.8297, R:0.0070, T:0.5177(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5426

ğŸ“Š EPOCH 21 TRAINING SUMMARY:
  Total Loss: 1.2407
  Contrastive: 5.8150
  Reconstruction: 0.0070
  Topological: 0.5426 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.4696
  Contrastive: 5.7536
  Reconstruction: 0.0063
  Topological: 1.8433 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 21/300 COMPLETE (39.3s)
Train Loss: 1.2407 (C:5.8150, R:0.0070, T:0.5426)
Val Loss:   2.4696 (C:5.7536, R:0.0063, T:1.8433)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 22 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2298 (C:5.7900, R:0.0070, T:0.5343(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2400 (C:5.7866, R:0.0070, T:0.5430(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2460 (C:5.8157, R:0.0070, T:0.5481(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2179 (C:5.8308, R:0.0069, T:0.5246(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2138 (C:5.8248, R:0.0069, T:0.5203(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2440 (C:5.8408, R:0.0070, T:0.5429(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2310 (C:5.8104, R:0.0069, T:0.5360(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2182 (C:5.8437, R:0.0070, T:0.5207(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2090 (C:5.8044, R:0.0070, T:0.5131(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2298 (C:5.7779, R:0.0069, T:0.5362(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2311 (C:5.8363, R:0.0070, T:0.5309(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2352 (C:5.8285, R:0.0070, T:0.5354(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2253 (C:5.8334, R:0.0069, T:0.5310(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2078 (C:5.7950, R:0.0069, T:0.5130(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1993 (C:5.8164, R:0.0070, T:0.5011(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2416 (C:5.8466, R:0.0071, T:0.5360(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2383 (C:5.8356, R:0.0070, T:0.5430(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2334 (C:5.7915, R:0.0069, T:0.5389(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2516 (C:5.8300, R:0.0070, T:0.5533(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2513 (C:5.8121, R:0.0070, T:0.5544(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2040 (C:5.8183, R:0.0069, T:0.5092(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2180 (C:5.8253, R:0.0070, T:0.5189(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5359

ğŸ“Š EPOCH 22 TRAINING SUMMARY:
  Total Loss: 1.2324
  Contrastive: 5.8072
  Reconstruction: 0.0070
  Topological: 0.5359 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.3948
  Contrastive: 5.7732
  Reconstruction: 0.0062
  Topological: 1.7752 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 22/300 COMPLETE (38.0s)
Train Loss: 1.2324 (C:5.8072, R:0.0070, T:0.5359)
Val Loss:   2.3948 (C:5.7732, R:0.0062, T:1.7752)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 23 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2372 (C:5.7937, R:0.0070, T:0.5400(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2108 (C:5.8092, R:0.0069, T:0.5176(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2198 (C:5.8098, R:0.0070, T:0.5235(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2312 (C:5.7981, R:0.0069, T:0.5384(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2091 (C:5.7916, R:0.0070, T:0.5116(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2454 (C:5.7935, R:0.0070, T:0.5469(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2351 (C:5.7917, R:0.0070, T:0.5339(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2384 (C:5.7954, R:0.0069, T:0.5439(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2461 (C:5.8358, R:0.0070, T:0.5489(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1868 (C:5.8037, R:0.0069, T:0.4933(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2191 (C:5.7961, R:0.0070, T:0.5211(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2304 (C:5.7837, R:0.0069, T:0.5367(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2244 (C:5.7849, R:0.0070, T:0.5263(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2336 (C:5.7989, R:0.0070, T:0.5351(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2304 (C:5.8518, R:0.0070, T:0.5299(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2789 (C:5.8191, R:0.0070, T:0.5839(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2272 (C:5.7573, R:0.0070, T:0.5310(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2167 (C:5.7789, R:0.0070, T:0.5212(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2148 (C:5.7629, R:0.0069, T:0.5226(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2402 (C:5.7775, R:0.0069, T:0.5454(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2128 (C:5.8169, R:0.0069, T:0.5229(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1977 (C:5.8266, R:0.0069, T:0.5076(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5307

ğŸ“Š EPOCH 23 TRAINING SUMMARY:
  Total Loss: 1.2263
  Contrastive: 5.7971
  Reconstruction: 0.0070
  Topological: 0.5307 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.4821
  Contrastive: 5.7439
  Reconstruction: 0.0062
  Topological: 1.8613 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 23/300 COMPLETE (38.4s)
Train Loss: 1.2263 (C:5.7971, R:0.0070, T:0.5307)
Val Loss:   2.4821 (C:5.7439, R:0.0062, T:1.8613)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 24 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2535 (C:5.7830, R:0.0070, T:0.5551(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1847 (C:5.7818, R:0.0069, T:0.4928(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2135 (C:5.7922, R:0.0069, T:0.5225(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2153 (C:5.8024, R:0.0069, T:0.5241(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1973 (C:5.8390, R:0.0069, T:0.5044(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2338 (C:5.8155, R:0.0070, T:0.5385(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2557 (C:5.7799, R:0.0070, T:0.5605(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2329 (C:5.8264, R:0.0070, T:0.5360(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2457 (C:5.7880, R:0.0070, T:0.5447(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2433 (C:5.7778, R:0.0070, T:0.5468(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2339 (C:5.7599, R:0.0070, T:0.5345(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1944 (C:5.7917, R:0.0069, T:0.5036(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2288 (C:5.8054, R:0.0070, T:0.5324(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1975 (C:5.7462, R:0.0069, T:0.5078(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1764 (C:5.7770, R:0.0069, T:0.4897(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1972 (C:5.7920, R:0.0070, T:0.5018(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1891 (C:5.8301, R:0.0069, T:0.4959(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1993 (C:5.7867, R:0.0070, T:0.5040(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2172 (C:5.7838, R:0.0069, T:0.5253(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2126 (C:5.7956, R:0.0070, T:0.5150(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2241 (C:5.8636, R:0.0070, T:0.5227(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2120 (C:5.7678, R:0.0069, T:0.5185(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5244

ğŸ“Š EPOCH 24 TRAINING SUMMARY:
  Total Loss: 1.2190
  Contrastive: 5.7905
  Reconstruction: 0.0069
  Topological: 0.5244 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.4173
  Contrastive: 5.7337
  Reconstruction: 0.0062
  Topological: 1.7992 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 24/300 COMPLETE (38.0s)
Train Loss: 1.2190 (C:5.7905, R:0.0069, T:0.5244)
Val Loss:   2.4173 (C:5.7337, R:0.0062, T:1.7992)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 25 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2136 (C:5.7753, R:0.0069, T:0.5187(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2131 (C:5.7803, R:0.0069, T:0.5212(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.2114 (C:5.8204, R:0.0069, T:0.5186(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1957 (C:5.7862, R:0.0069, T:0.5027(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2263 (C:5.7911, R:0.0070, T:0.5297(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2317 (C:5.7805, R:0.0070, T:0.5364(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2133 (C:5.8182, R:0.0069, T:0.5265(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2135 (C:5.7642, R:0.0069, T:0.5236(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2420 (C:5.7804, R:0.0069, T:0.5520(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2154 (C:5.8075, R:0.0069, T:0.5226(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2274 (C:5.7945, R:0.0069, T:0.5329(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.2407 (C:5.7808, R:0.0069, T:0.5487(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2133 (C:5.7756, R:0.0069, T:0.5207(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1971 (C:5.7898, R:0.0069, T:0.5029(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1620 (C:5.7967, R:0.0069, T:0.4756(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2461 (C:5.8353, R:0.0070, T:0.5485(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1964 (C:5.8126, R:0.0070, T:0.4974(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2294 (C:5.7955, R:0.0070, T:0.5321(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2015 (C:5.7787, R:0.0069, T:0.5101(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2082 (C:5.7854, R:0.0069, T:0.5153(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2360 (C:5.7863, R:0.0069, T:0.5462(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2183 (C:5.8081, R:0.0070, T:0.5233(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5197

ğŸ“Š EPOCH 25 TRAINING SUMMARY:
  Total Loss: 1.2132
  Contrastive: 5.7823
  Reconstruction: 0.0069
  Topological: 0.5197 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.3130
  Contrastive: 5.7894
  Reconstruction: 0.0062
  Topological: 1.6951 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 25/300 COMPLETE (38.8s)
Train Loss: 1.2132 (C:5.7823, R:0.0069, T:0.5197)
Val Loss:   2.3130 (C:5.7894, R:0.0062, T:1.6951)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 26 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2047 (C:5.8070, R:0.0069, T:0.5110(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2367 (C:5.7768, R:0.0070, T:0.5370(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1643 (C:5.7529, R:0.0069, T:0.4756(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1843 (C:5.7569, R:0.0070, T:0.4874(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2125 (C:5.7904, R:0.0070, T:0.5170(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2006 (C:5.7821, R:0.0069, T:0.5119(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1885 (C:5.7863, R:0.0069, T:0.4999(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1896 (C:5.7512, R:0.0069, T:0.4995(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2211 (C:5.7685, R:0.0069, T:0.5297(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.2287 (C:5.7995, R:0.0069, T:0.5369(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2122 (C:5.7678, R:0.0069, T:0.5186(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1988 (C:5.7945, R:0.0069, T:0.5070(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2141 (C:5.7513, R:0.0070, T:0.5176(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2143 (C:5.7359, R:0.0069, T:0.5259(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2045 (C:5.7296, R:0.0069, T:0.5111(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2355 (C:5.7770, R:0.0070, T:0.5400(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.2119 (C:5.7593, R:0.0069, T:0.5198(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2305 (C:5.8137, R:0.0069, T:0.5399(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2009 (C:5.7636, R:0.0069, T:0.5082(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1903 (C:5.8071, R:0.0069, T:0.5010(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2370 (C:5.7775, R:0.0069, T:0.5439(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2065 (C:5.7954, R:0.0069, T:0.5166(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5143

ğŸ“Š EPOCH 26 TRAINING SUMMARY:
  Total Loss: 1.2070
  Contrastive: 5.7783
  Reconstruction: 0.0069
  Topological: 0.5143 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.3579
  Contrastive: 5.7637
  Reconstruction: 0.0062
  Topological: 1.7419 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 26/300 COMPLETE (37.4s)
Train Loss: 1.2070 (C:5.7783, R:0.0069, T:0.5143)
Val Loss:   2.3579 (C:5.7637, R:0.0062, T:1.7419)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 27 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2145 (C:5.7858, R:0.0069, T:0.5234(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2079 (C:5.7328, R:0.0069, T:0.5184(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1801 (C:5.7759, R:0.0069, T:0.4886(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.2044 (C:5.7807, R:0.0069, T:0.5104(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2220 (C:5.8163, R:0.0069, T:0.5276(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2158 (C:5.8018, R:0.0069, T:0.5210(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2002 (C:5.7739, R:0.0069, T:0.5053(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1934 (C:5.7803, R:0.0069, T:0.5031(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1836 (C:5.7833, R:0.0068, T:0.5003(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1857 (C:5.7762, R:0.0069, T:0.4954(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2314 (C:5.8073, R:0.0069, T:0.5395(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1716 (C:5.7657, R:0.0069, T:0.4860(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1738 (C:5.7780, R:0.0069, T:0.4843(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2181 (C:5.7611, R:0.0069, T:0.5249(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1744 (C:5.7579, R:0.0069, T:0.4879(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2111 (C:5.7883, R:0.0069, T:0.5205(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1985 (C:5.7963, R:0.0069, T:0.5041(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2079 (C:5.7661, R:0.0069, T:0.5195(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2131 (C:5.7973, R:0.0069, T:0.5199(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1985 (C:5.7159, R:0.0069, T:0.5132(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1904 (C:5.7731, R:0.0069, T:0.5012(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1900 (C:5.7805, R:0.0069, T:0.4988(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5107

ğŸ“Š EPOCH 27 TRAINING SUMMARY:
  Total Loss: 1.2027
  Contrastive: 5.7728
  Reconstruction: 0.0069
  Topological: 0.5107 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.3090
  Contrastive: 5.7697
  Reconstruction: 0.0061
  Topological: 1.6942 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 27/300 COMPLETE (38.9s)
Train Loss: 1.2027 (C:5.7728, R:0.0069, T:0.5107)
Val Loss:   2.3090 (C:5.7697, R:0.0061, T:1.6942)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 28 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1855 (C:5.7636, R:0.0069, T:0.4987(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2196 (C:5.7836, R:0.0069, T:0.5296(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1772 (C:5.7815, R:0.0070, T:0.4809(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1932 (C:5.7401, R:0.0069, T:0.5007(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2273 (C:5.7905, R:0.0070, T:0.5310(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1912 (C:5.7519, R:0.0069, T:0.5047(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1902 (C:5.7773, R:0.0069, T:0.5030(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2148 (C:5.7629, R:0.0069, T:0.5274(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2015 (C:5.7740, R:0.0069, T:0.5106(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1840 (C:5.7290, R:0.0069, T:0.4929(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1947 (C:5.7946, R:0.0069, T:0.5010(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1816 (C:5.7812, R:0.0069, T:0.4896(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1671 (C:5.7713, R:0.0069, T:0.4761(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2169 (C:5.7454, R:0.0069, T:0.5244(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.2114 (C:5.7479, R:0.0069, T:0.5233(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2090 (C:5.7500, R:0.0069, T:0.5179(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1957 (C:5.7644, R:0.0069, T:0.5042(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2026 (C:5.7514, R:0.0070, T:0.5074(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.2238 (C:5.7406, R:0.0070, T:0.5280(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1906 (C:5.7491, R:0.0069, T:0.5023(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1854 (C:5.7926, R:0.0069, T:0.4963(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2035 (C:5.7190, R:0.0069, T:0.5108(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5060

ğŸ“Š EPOCH 28 TRAINING SUMMARY:
  Total Loss: 1.1969
  Contrastive: 5.7696
  Reconstruction: 0.0069
  Topological: 0.5060 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.4100
  Contrastive: 5.7096
  Reconstruction: 0.0062
  Topological: 1.7941 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 28/300 COMPLETE (38.3s)
Train Loss: 1.1969 (C:5.7696, R:0.0069, T:0.5060)
Val Loss:   2.4100 (C:5.7096, R:0.0062, T:1.7941)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 29 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1846 (C:5.7398, R:0.0069, T:0.4966(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2059 (C:5.7617, R:0.0069, T:0.5155(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1912 (C:5.8228, R:0.0069, T:0.5014(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1933 (C:5.7575, R:0.0069, T:0.5030(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1941 (C:5.7575, R:0.0069, T:0.5004(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1869 (C:5.7545, R:0.0069, T:0.4993(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.2147 (C:5.7548, R:0.0069, T:0.5255(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1988 (C:5.7601, R:0.0069, T:0.5120(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1703 (C:5.7786, R:0.0069, T:0.4773(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1826 (C:5.7802, R:0.0069, T:0.4921(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2166 (C:5.7716, R:0.0070, T:0.5187(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1878 (C:5.7301, R:0.0069, T:0.4995(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1442 (C:5.7627, R:0.0069, T:0.4546(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.2188 (C:5.7718, R:0.0069, T:0.5249(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1506 (C:5.7557, R:0.0069, T:0.4640(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1688 (C:5.7740, R:0.0068, T:0.4839(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1710 (C:5.7895, R:0.0068, T:0.4867(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1810 (C:5.7845, R:0.0069, T:0.4902(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1859 (C:5.7362, R:0.0069, T:0.4911(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2195 (C:5.7409, R:0.0069, T:0.5288(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1959 (C:5.7678, R:0.0069, T:0.5062(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1775 (C:5.7776, R:0.0069, T:0.4866(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5011

ğŸ“Š EPOCH 29 TRAINING SUMMARY:
  Total Loss: 1.1914
  Contrastive: 5.7670
  Reconstruction: 0.0069
  Topological: 0.5011 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.3724
  Contrastive: 5.7360
  Reconstruction: 0.0061
  Topological: 1.7580 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 29/300 COMPLETE (38.1s)
Train Loss: 1.1914 (C:5.7670, R:0.0069, T:0.5011)
Val Loss:   2.3724 (C:5.7360, R:0.0061, T:1.7580)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 30 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1909 (C:5.7491, R:0.0069, T:0.5027(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1783 (C:5.7903, R:0.0069, T:0.4904(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1739 (C:5.8027, R:0.0069, T:0.4820(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1755 (C:5.7445, R:0.0069, T:0.4859(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.2181 (C:5.7443, R:0.0069, T:0.5297(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2032 (C:5.7132, R:0.0069, T:0.5160(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1967 (C:5.7177, R:0.0069, T:0.5083(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.2371 (C:5.7660, R:0.0069, T:0.5454(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.2180 (C:5.7422, R:0.0069, T:0.5271(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1676 (C:5.7752, R:0.0069, T:0.4772(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1942 (C:5.7739, R:0.0069, T:0.5005(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1924 (C:5.7991, R:0.0070, T:0.4957(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1792 (C:5.7813, R:0.0069, T:0.4900(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1892 (C:5.7857, R:0.0069, T:0.5039(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1792 (C:5.7770, R:0.0069, T:0.4890(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1982 (C:5.7741, R:0.0069, T:0.5083(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1845 (C:5.8114, R:0.0069, T:0.4932(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.2085 (C:5.7818, R:0.0069, T:0.5159(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1632 (C:5.7597, R:0.0068, T:0.4792(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2197 (C:5.8021, R:0.0069, T:0.5256(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1603 (C:5.8000, R:0.0069, T:0.4729(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.2376 (C:5.7730, R:0.0069, T:0.5438(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4977

ğŸ“Š EPOCH 30 TRAINING SUMMARY:
  Total Loss: 1.1872
  Contrastive: 5.7639
  Reconstruction: 0.0069
  Topological: 0.4977 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.2888
  Contrastive: 5.7699
  Reconstruction: 0.0061
  Topological: 1.6768 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 30/300 COMPLETE (38.4s)
Train Loss: 1.1872 (C:5.7639, R:0.0069, T:0.4977)
Val Loss:   2.2888 (C:5.7699, R:0.0061, T:1.6768)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 31 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1853 (C:5.7775, R:0.0069, T:0.4983(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1896 (C:5.7409, R:0.0069, T:0.5017(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1886 (C:5.7724, R:0.0069, T:0.4992(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1932 (C:5.7714, R:0.0070, T:0.4975(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1988 (C:5.7670, R:0.0069, T:0.5057(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2043 (C:5.7446, R:0.0069, T:0.5142(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1664 (C:5.7773, R:0.0069, T:0.4783(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1730 (C:5.7233, R:0.0069, T:0.4844(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1916 (C:5.7554, R:0.0069, T:0.4998(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1760 (C:5.7886, R:0.0069, T:0.4863(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1626 (C:5.7609, R:0.0068, T:0.4777(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1956 (C:5.7849, R:0.0069, T:0.5019(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1800 (C:5.7683, R:0.0068, T:0.4972(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1649 (C:5.7827, R:0.0069, T:0.4762(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1819 (C:5.8031, R:0.0069, T:0.4949(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1975 (C:5.7743, R:0.0069, T:0.5071(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1940 (C:5.7269, R:0.0069, T:0.5068(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1780 (C:5.7219, R:0.0069, T:0.4914(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1820 (C:5.7938, R:0.0069, T:0.4926(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2069 (C:5.7230, R:0.0069, T:0.5179(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1801 (C:5.7683, R:0.0069, T:0.4887(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1812 (C:5.7693, R:0.0069, T:0.4960(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4939

ğŸ“Š EPOCH 31 TRAINING SUMMARY:
  Total Loss: 1.1826
  Contrastive: 5.7612
  Reconstruction: 0.0069
  Topological: 0.4939 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.3838
  Contrastive: 5.7276
  Reconstruction: 0.0061
  Topological: 1.7706 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 31/300 COMPLETE (40.4s)
Train Loss: 1.1826 (C:5.7612, R:0.0069, T:0.4939)
Val Loss:   2.3838 (C:5.7276, R:0.0061, T:1.7706)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 32 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1588 (C:5.7467, R:0.0069, T:0.4713(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.2034 (C:5.7466, R:0.0069, T:0.5164(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1841 (C:5.7412, R:0.0069, T:0.4952(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1680 (C:5.7566, R:0.0069, T:0.4806(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1696 (C:5.7781, R:0.0069, T:0.4815(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1697 (C:5.7480, R:0.0068, T:0.4853(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1784 (C:5.7505, R:0.0069, T:0.4896(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1710 (C:5.7669, R:0.0069, T:0.4810(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1523 (C:5.7614, R:0.0068, T:0.4685(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1926 (C:5.7518, R:0.0069, T:0.5065(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1840 (C:5.7700, R:0.0069, T:0.4914(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1727 (C:5.7374, R:0.0069, T:0.4869(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1460 (C:5.7353, R:0.0069, T:0.4578(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1936 (C:5.7290, R:0.0069, T:0.5057(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1672 (C:5.7271, R:0.0069, T:0.4816(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.2054 (C:5.7570, R:0.0069, T:0.5162(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1985 (C:5.7438, R:0.0069, T:0.5085(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1631 (C:5.7537, R:0.0068, T:0.4809(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1639 (C:5.7860, R:0.0069, T:0.4776(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1921 (C:5.7995, R:0.0069, T:0.5000(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1861 (C:5.7619, R:0.0069, T:0.4967(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1773 (C:5.7414, R:0.0069, T:0.4851(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4913

ğŸ“Š EPOCH 32 TRAINING SUMMARY:
  Total Loss: 1.1792
  Contrastive: 5.7610
  Reconstruction: 0.0069
  Topological: 0.4913 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.2049
  Contrastive: 5.7873
  Reconstruction: 0.0061
  Topological: 1.5984 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 32/300 COMPLETE (38.7s)
Train Loss: 1.1792 (C:5.7610, R:0.0069, T:0.4913)
Val Loss:   2.2049 (C:5.7873, R:0.0061, T:1.5984)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 33 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1578 (C:5.7766, R:0.0069, T:0.4673(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1956 (C:5.7519, R:0.0069, T:0.5047(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1761 (C:5.7646, R:0.0069, T:0.4879(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1925 (C:5.7248, R:0.0069, T:0.5057(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1769 (C:5.7253, R:0.0069, T:0.4915(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.2171 (C:5.7497, R:0.0069, T:0.5269(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1629 (C:5.7401, R:0.0069, T:0.4775(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1502 (C:5.7644, R:0.0068, T:0.4685(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1887 (C:5.7600, R:0.0069, T:0.4982(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1800 (C:5.7823, R:0.0069, T:0.4932(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.2033 (C:5.7592, R:0.0068, T:0.5199(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1734 (C:5.7278, R:0.0069, T:0.4870(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.2001 (C:5.7770, R:0.0069, T:0.5109(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1696 (C:5.7407, R:0.0068, T:0.4855(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1897 (C:5.7985, R:0.0069, T:0.5020(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1603 (C:5.8130, R:0.0069, T:0.4736(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1847 (C:5.7616, R:0.0069, T:0.4960(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1940 (C:5.8003, R:0.0069, T:0.5050(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1532 (C:5.7564, R:0.0069, T:0.4674(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1626 (C:5.7538, R:0.0069, T:0.4754(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1792 (C:5.7373, R:0.0068, T:0.4964(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1687 (C:5.7607, R:0.0069, T:0.4835(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4899

ğŸ“Š EPOCH 33 TRAINING SUMMARY:
  Total Loss: 1.1772
  Contrastive: 5.7603
  Reconstruction: 0.0069
  Topological: 0.4899 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.2896
  Contrastive: 5.7598
  Reconstruction: 0.0061
  Topological: 1.6808 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 33/300 COMPLETE (39.8s)
Train Loss: 1.1772 (C:5.7603, R:0.0069, T:0.4899)
Val Loss:   2.2896 (C:5.7598, R:0.0061, T:1.6808)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 34 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1853 (C:5.7611, R:0.0069, T:0.4930(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1688 (C:5.7903, R:0.0069, T:0.4792(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1347 (C:5.7797, R:0.0068, T:0.4533(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1771 (C:5.7802, R:0.0068, T:0.4929(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1727 (C:5.7284, R:0.0068, T:0.4899(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1873 (C:5.8213, R:0.0069, T:0.4977(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1848 (C:5.7901, R:0.0069, T:0.4937(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1674 (C:5.7679, R:0.0069, T:0.4762(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1735 (C:5.7676, R:0.0069, T:0.4819(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1553 (C:5.7182, R:0.0068, T:0.4734(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1754 (C:5.7622, R:0.0069, T:0.4880(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1836 (C:5.7575, R:0.0068, T:0.5008(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1935 (C:5.7362, R:0.0069, T:0.5046(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1778 (C:5.7381, R:0.0069, T:0.4882(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1481 (C:5.7186, R:0.0068, T:0.4644(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1464 (C:5.7694, R:0.0068, T:0.4658(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1479 (C:5.7473, R:0.0069, T:0.4619(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1839 (C:5.7091, R:0.0069, T:0.4971(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1651 (C:5.7561, R:0.0068, T:0.4817(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1856 (C:5.7334, R:0.0069, T:0.4995(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1719 (C:5.8027, R:0.0069, T:0.4807(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1633 (C:5.7691, R:0.0068, T:0.4791(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4867

ğŸ“Š EPOCH 34 TRAINING SUMMARY:
  Total Loss: 1.1735
  Contrastive: 5.7599
  Reconstruction: 0.0069
  Topological: 0.4867 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.2543
  Contrastive: 5.7671
  Reconstruction: 0.0061
  Topological: 1.6483 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 34/300 COMPLETE (39.5s)
Train Loss: 1.1735 (C:5.7599, R:0.0069, T:0.4867)
Val Loss:   2.2543 (C:5.7671, R:0.0061, T:1.6483)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 35 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1531 (C:5.7468, R:0.0068, T:0.4719(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1867 (C:5.7582, R:0.0069, T:0.4948(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1604 (C:5.8102, R:0.0069, T:0.4749(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1679 (C:5.7781, R:0.0069, T:0.4763(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1661 (C:5.7714, R:0.0069, T:0.4761(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1596 (C:5.7540, R:0.0069, T:0.4725(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1625 (C:5.7225, R:0.0068, T:0.4782(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1910 (C:5.7387, R:0.0068, T:0.5071(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1472 (C:5.7671, R:0.0068, T:0.4645(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1740 (C:5.7664, R:0.0068, T:0.4917(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1632 (C:5.7528, R:0.0068, T:0.4784(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1599 (C:5.7345, R:0.0068, T:0.4759(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1800 (C:5.7528, R:0.0068, T:0.4993(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1836 (C:5.7581, R:0.0069, T:0.4942(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1625 (C:5.7526, R:0.0068, T:0.4820(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1581 (C:5.7227, R:0.0069, T:0.4704(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1583 (C:5.7414, R:0.0069, T:0.4731(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1739 (C:5.8084, R:0.0069, T:0.4883(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1534 (C:5.7687, R:0.0068, T:0.4687(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1550 (C:5.7636, R:0.0068, T:0.4743(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1882 (C:5.7719, R:0.0068, T:0.5040(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1622 (C:5.7993, R:0.0069, T:0.4765(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4852

ğŸ“Š EPOCH 35 TRAINING SUMMARY:
  Total Loss: 1.1714
  Contrastive: 5.7593
  Reconstruction: 0.0069
  Topological: 0.4852 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.1987
  Contrastive: 5.7895
  Reconstruction: 0.0060
  Topological: 1.5940 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 35/300 COMPLETE (40.3s)
Train Loss: 1.1714 (C:5.7593, R:0.0069, T:0.4852)
Val Loss:   2.1987 (C:5.7895, R:0.0060, T:1.5940)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 36 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1857 (C:5.7844, R:0.0069, T:0.4950(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1977 (C:5.7727, R:0.0069, T:0.5091(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1613 (C:5.7284, R:0.0069, T:0.4760(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1731 (C:5.7355, R:0.0069, T:0.4873(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1744 (C:5.7787, R:0.0069, T:0.4865(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1943 (C:5.7443, R:0.0069, T:0.5072(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1579 (C:5.7619, R:0.0068, T:0.4757(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1622 (C:5.7274, R:0.0069, T:0.4769(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1693 (C:5.7678, R:0.0069, T:0.4797(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1833 (C:5.7669, R:0.0068, T:0.4985(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1858 (C:5.7704, R:0.0069, T:0.4939(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1548 (C:5.7630, R:0.0069, T:0.4667(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1850 (C:5.7675, R:0.0069, T:0.4978(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1889 (C:5.7582, R:0.0069, T:0.5009(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1532 (C:5.7560, R:0.0068, T:0.4701(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1750 (C:5.7518, R:0.0069, T:0.4866(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1464 (C:5.7437, R:0.0068, T:0.4646(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1572 (C:5.7647, R:0.0069, T:0.4688(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1735 (C:5.7591, R:0.0068, T:0.4925(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.2128 (C:5.7462, R:0.0069, T:0.5229(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.2036 (C:5.7586, R:0.0069, T:0.5118(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1742 (C:5.7636, R:0.0069, T:0.4882(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4840

ğŸ“Š EPOCH 36 TRAINING SUMMARY:
  Total Loss: 1.1697
  Contrastive: 5.7571
  Reconstruction: 0.0069
  Topological: 0.4840 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.2896
  Contrastive: 5.7236
  Reconstruction: 0.0061
  Topological: 1.6806 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 36/300 COMPLETE (40.4s)
Train Loss: 1.1697 (C:5.7571, R:0.0069, T:0.4840)
Val Loss:   2.2896 (C:5.7236, R:0.0061, T:1.6806)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 37 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1513 (C:5.7305, R:0.0068, T:0.4709(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1815 (C:5.7320, R:0.0068, T:0.4981(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1697 (C:5.7687, R:0.0069, T:0.4832(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1761 (C:5.7682, R:0.0068, T:0.4929(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1537 (C:5.7759, R:0.0069, T:0.4684(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1583 (C:5.7754, R:0.0069, T:0.4705(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1582 (C:5.7542, R:0.0068, T:0.4815(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1769 (C:5.7690, R:0.0068, T:0.4927(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1579 (C:5.7458, R:0.0069, T:0.4698(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1854 (C:5.7477, R:0.0068, T:0.5013(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1699 (C:5.7607, R:0.0069, T:0.4820(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1788 (C:5.7697, R:0.0069, T:0.4932(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1504 (C:5.7761, R:0.0069, T:0.4598(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1676 (C:5.7463, R:0.0068, T:0.4843(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1795 (C:5.7561, R:0.0069, T:0.4896(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1688 (C:5.7529, R:0.0069, T:0.4801(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1796 (C:5.7526, R:0.0069, T:0.4907(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1522 (C:5.7826, R:0.0069, T:0.4659(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1369 (C:5.7981, R:0.0068, T:0.4550(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1314 (C:5.7783, R:0.0068, T:0.4503(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1791 (C:5.7520, R:0.0068, T:0.4955(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1786 (C:5.7547, R:0.0069, T:0.4908(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4802

ğŸ“Š EPOCH 37 TRAINING SUMMARY:
  Total Loss: 1.1651
  Contrastive: 5.7581
  Reconstruction: 0.0068
  Topological: 0.4802 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.1256
  Contrastive: 5.8127
  Reconstruction: 0.0060
  Topological: 1.5233 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 37/300 COMPLETE (41.3s)
Train Loss: 1.1651 (C:5.7581, R:0.0068, T:0.4802)
Val Loss:   2.1256 (C:5.8127, R:0.0060, T:1.5233)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 38 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2093 (C:5.7947, R:0.0069, T:0.5224(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1765 (C:5.7967, R:0.0069, T:0.4903(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1807 (C:5.7328, R:0.0068, T:0.4962(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1885 (C:5.7601, R:0.0069, T:0.5002(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1625 (C:5.7834, R:0.0069, T:0.4755(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1526 (C:5.7325, R:0.0068, T:0.4679(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1538 (C:5.7486, R:0.0068, T:0.4691(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1422 (C:5.7599, R:0.0068, T:0.4575(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1731 (C:5.7872, R:0.0068, T:0.4903(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1938 (C:5.7757, R:0.0069, T:0.5068(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1603 (C:5.7908, R:0.0069, T:0.4741(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1532 (C:5.7906, R:0.0068, T:0.4715(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1693 (C:5.7557, R:0.0068, T:0.4856(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1521 (C:5.7153, R:0.0068, T:0.4686(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1575 (C:5.7407, R:0.0068, T:0.4737(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1950 (C:5.7201, R:0.0068, T:0.5128(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1148 (C:5.7847, R:0.0068, T:0.4356(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1844 (C:5.7713, R:0.0068, T:0.5021(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1640 (C:5.7197, R:0.0068, T:0.4837(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1778 (C:5.7480, R:0.0068, T:0.4950(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1818 (C:5.7785, R:0.0069, T:0.4940(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1555 (C:5.7937, R:0.0069, T:0.4704(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 38 TRAINING SUMMARY:
  Total Loss: 1.1652
  Contrastive: 5.7573
  Reconstruction: 0.0068
  Topological: 0.4807 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.2196
  Contrastive: 5.7716
  Reconstruction: 0.0060
  Topological: 1.6167 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 38/300 COMPLETE (40.9s)
Train Loss: 1.1652 (C:5.7573, R:0.0068, T:0.4807)
Val Loss:   2.2196 (C:5.7716, R:0.0060, T:1.6167)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 39 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1575 (C:5.7685, R:0.0068, T:0.4733(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1767 (C:5.7733, R:0.0069, T:0.4882(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1961 (C:5.7306, R:0.0068, T:0.5143(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1392 (C:5.7520, R:0.0069, T:0.4524(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1531 (C:5.7777, R:0.0069, T:0.4664(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1485 (C:5.7451, R:0.0068, T:0.4654(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1765 (C:5.7478, R:0.0069, T:0.4893(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1523 (C:5.7504, R:0.0068, T:0.4705(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1755 (C:5.7289, R:0.0069, T:0.4899(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1531 (C:5.7208, R:0.0068, T:0.4705(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1276 (C:5.7407, R:0.0068, T:0.4454(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1674 (C:5.7466, R:0.0068, T:0.4872(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1923 (C:5.7419, R:0.0068, T:0.5112(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1683 (C:5.7476, R:0.0068, T:0.4859(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1654 (C:5.7672, R:0.0068, T:0.4846(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1799 (C:5.7710, R:0.0068, T:0.4959(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1574 (C:5.7421, R:0.0068, T:0.4729(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1962 (C:5.7951, R:0.0069, T:0.5074(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1789 (C:5.7226, R:0.0069, T:0.4939(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1521 (C:5.7128, R:0.0068, T:0.4721(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1852 (C:5.7514, R:0.0069, T:0.4975(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1765 (C:5.7297, R:0.0068, T:0.4918(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4791

ğŸ“Š EPOCH 39 TRAINING SUMMARY:
  Total Loss: 1.1630
  Contrastive: 5.7550
  Reconstruction: 0.0068
  Topological: 0.4791 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.1844
  Contrastive: 5.7670
  Reconstruction: 0.0060
  Topological: 1.5822 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 39/300 COMPLETE (40.4s)
Train Loss: 1.1630 (C:5.7550, R:0.0068, T:0.4791)
Val Loss:   2.1844 (C:5.7670, R:0.0060, T:1.5822)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 40 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1696 (C:5.7583, R:0.0068, T:0.4854(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1610 (C:5.7339, R:0.0068, T:0.4786(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1527 (C:5.7583, R:0.0068, T:0.4698(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1348 (C:5.7614, R:0.0068, T:0.4528(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1761 (C:5.7533, R:0.0068, T:0.4928(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1717 (C:5.7526, R:0.0068, T:0.4869(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1677 (C:5.7701, R:0.0068, T:0.4847(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1520 (C:5.7911, R:0.0068, T:0.4689(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1658 (C:5.7628, R:0.0068, T:0.4830(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1654 (C:5.7314, R:0.0069, T:0.4790(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1674 (C:5.7569, R:0.0068, T:0.4828(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1686 (C:5.7596, R:0.0069, T:0.4816(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1863 (C:5.7612, R:0.0069, T:0.5002(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1606 (C:5.7420, R:0.0068, T:0.4756(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1684 (C:5.7490, R:0.0069, T:0.4822(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1506 (C:5.7897, R:0.0069, T:0.4584(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1789 (C:5.7661, R:0.0068, T:0.4971(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1777 (C:5.7444, R:0.0068, T:0.4950(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1580 (C:5.7650, R:0.0068, T:0.4749(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1480 (C:5.7530, R:0.0068, T:0.4661(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1840 (C:5.7606, R:0.0068, T:0.4990(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1475 (C:5.7309, R:0.0068, T:0.4645(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4768

ğŸ“Š EPOCH 40 TRAINING SUMMARY:
  Total Loss: 1.1603
  Contrastive: 5.7582
  Reconstruction: 0.0068
  Topological: 0.4768 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.3148
  Contrastive: 5.7244
  Reconstruction: 0.0060
  Topological: 1.7105 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 40/300 COMPLETE (40.0s)
Train Loss: 1.1603 (C:5.7582, R:0.0068, T:0.4768)
Val Loss:   2.3148 (C:5.7244, R:0.0060, T:1.7105)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 41 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1663 (C:5.7518, R:0.0069, T:0.4812(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1769 (C:5.7233, R:0.0069, T:0.4908(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1426 (C:5.7947, R:0.0069, T:0.4555(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1707 (C:5.7612, R:0.0069, T:0.4848(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1482 (C:5.7461, R:0.0068, T:0.4702(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1664 (C:5.7618, R:0.0068, T:0.4850(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1703 (C:5.7471, R:0.0068, T:0.4866(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1646 (C:5.7513, R:0.0068, T:0.4854(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1780 (C:5.7903, R:0.0069, T:0.4882(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1788 (C:5.7847, R:0.0069, T:0.4919(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1611 (C:5.7838, R:0.0068, T:0.4812(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1578 (C:5.7670, R:0.0068, T:0.4763(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1666 (C:5.7359, R:0.0069, T:0.4799(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1690 (C:5.7656, R:0.0068, T:0.4872(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1581 (C:5.7232, R:0.0068, T:0.4735(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1740 (C:5.7765, R:0.0068, T:0.4923(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1348 (C:5.7669, R:0.0068, T:0.4557(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1744 (C:5.7538, R:0.0068, T:0.4903(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1584 (C:5.7931, R:0.0068, T:0.4738(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1256 (C:5.7274, R:0.0068, T:0.4493(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1444 (C:5.7332, R:0.0069, T:0.4556(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1857 (C:5.7379, R:0.0069, T:0.4981(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4767

ğŸ“Š EPOCH 41 TRAINING SUMMARY:
  Total Loss: 1.1597
  Contrastive: 5.7553
  Reconstruction: 0.0068
  Topological: 0.4767 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.1775
  Contrastive: 5.7683
  Reconstruction: 0.0060
  Topological: 1.5767 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 41/300 COMPLETE (39.5s)
Train Loss: 1.1597 (C:5.7553, R:0.0068, T:0.4767)
Val Loss:   2.1775 (C:5.7683, R:0.0060, T:1.5767)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 42 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1610 (C:5.7589, R:0.0069, T:0.4751(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1697 (C:5.7667, R:0.0069, T:0.4836(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1399 (C:5.7480, R:0.0068, T:0.4615(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1486 (C:5.7533, R:0.0068, T:0.4706(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1476 (C:5.7589, R:0.0068, T:0.4652(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1414 (C:5.7667, R:0.0068, T:0.4574(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1653 (C:5.7451, R:0.0068, T:0.4833(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1473 (C:5.7178, R:0.0068, T:0.4717(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1694 (C:5.7401, R:0.0068, T:0.4893(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1637 (C:5.7316, R:0.0068, T:0.4798(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1704 (C:5.7610, R:0.0068, T:0.4867(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1323 (C:5.7369, R:0.0068, T:0.4504(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1608 (C:5.7475, R:0.0068, T:0.4768(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1528 (C:5.7373, R:0.0068, T:0.4680(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1798 (C:5.7298, R:0.0069, T:0.4936(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1663 (C:5.7519, R:0.0068, T:0.4831(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1597 (C:5.7305, R:0.0068, T:0.4762(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1694 (C:5.7108, R:0.0068, T:0.4873(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1797 (C:5.7678, R:0.0068, T:0.4996(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1727 (C:5.7568, R:0.0069, T:0.4876(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1850 (C:5.7304, R:0.0069, T:0.4959(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1930 (C:5.7449, R:0.0068, T:0.5104(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4748

ğŸ“Š EPOCH 42 TRAINING SUMMARY:
  Total Loss: 1.1573
  Contrastive: 5.7550
  Reconstruction: 0.0068
  Topological: 0.4748 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.1749
  Contrastive: 5.7598
  Reconstruction: 0.0060
  Topological: 1.5755 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 42/300 COMPLETE (39.1s)
Train Loss: 1.1573 (C:5.7550, R:0.0068, T:0.4748)
Val Loss:   2.1749 (C:5.7598, R:0.0060, T:1.5755)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 43 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1664 (C:5.7634, R:0.0068, T:0.4830(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1643 (C:5.7959, R:0.0068, T:0.4804(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1523 (C:5.7422, R:0.0068, T:0.4721(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1443 (C:5.7516, R:0.0068, T:0.4606(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1537 (C:5.7490, R:0.0068, T:0.4705(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1238 (C:5.7361, R:0.0068, T:0.4429(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1496 (C:5.7017, R:0.0068, T:0.4662(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1526 (C:5.7520, R:0.0069, T:0.4635(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1221 (C:5.7784, R:0.0067, T:0.4500(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1712 (C:5.7421, R:0.0068, T:0.4903(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1502 (C:5.7241, R:0.0067, T:0.4768(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1489 (C:5.7759, R:0.0068, T:0.4668(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1559 (C:5.7392, R:0.0068, T:0.4758(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1386 (C:5.7364, R:0.0068, T:0.4601(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1589 (C:5.7483, R:0.0068, T:0.4762(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1426 (C:5.7106, R:0.0068, T:0.4611(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1752 (C:5.7410, R:0.0068, T:0.4941(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1514 (C:5.7694, R:0.0068, T:0.4723(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1398 (C:5.7349, R:0.0069, T:0.4521(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1631 (C:5.7351, R:0.0068, T:0.4815(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1761 (C:5.7765, R:0.0068, T:0.4913(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1649 (C:5.7442, R:0.0068, T:0.4822(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4733

ğŸ“Š EPOCH 43 TRAINING SUMMARY:
  Total Loss: 1.1552
  Contrastive: 5.7558
  Reconstruction: 0.0068
  Topological: 0.4733 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.2175
  Contrastive: 5.7258
  Reconstruction: 0.0060
  Topological: 1.6163 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 43/300 COMPLETE (39.8s)
Train Loss: 1.1552 (C:5.7558, R:0.0068, T:0.4733)
Val Loss:   2.2175 (C:5.7258, R:0.0060, T:1.6163)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 44 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1506 (C:5.7244, R:0.0068, T:0.4712(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1378 (C:5.7955, R:0.0068, T:0.4551(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1446 (C:5.7790, R:0.0068, T:0.4644(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1459 (C:5.7690, R:0.0068, T:0.4651(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1487 (C:5.7296, R:0.0068, T:0.4683(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1373 (C:5.7679, R:0.0068, T:0.4539(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1500 (C:5.7698, R:0.0068, T:0.4701(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1455 (C:5.7605, R:0.0068, T:0.4691(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1938 (C:5.7422, R:0.0069, T:0.5064(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1576 (C:5.7318, R:0.0068, T:0.4776(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1360 (C:5.7240, R:0.0068, T:0.4574(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1440 (C:5.7736, R:0.0068, T:0.4594(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1664 (C:5.7377, R:0.0068, T:0.4857(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1724 (C:5.7668, R:0.0069, T:0.4861(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1788 (C:5.7799, R:0.0068, T:0.4971(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1458 (C:5.7708, R:0.0068, T:0.4639(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1240 (C:5.7553, R:0.0068, T:0.4488(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1454 (C:5.7450, R:0.0069, T:0.4594(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1545 (C:5.7832, R:0.0068, T:0.4701(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1571 (C:5.7344, R:0.0068, T:0.4756(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1689 (C:5.7458, R:0.0069, T:0.4817(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1252 (C:5.7265, R:0.0068, T:0.4488(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4712

ğŸ“Š EPOCH 44 TRAINING SUMMARY:
  Total Loss: 1.1529
  Contrastive: 5.7544
  Reconstruction: 0.0068
  Topological: 0.4712 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.1551
  Contrastive: 5.7869
  Reconstruction: 0.0060
  Topological: 1.5550 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 44/300 COMPLETE (39.3s)
Train Loss: 1.1529 (C:5.7544, R:0.0068, T:0.4712)
Val Loss:   2.1551 (C:5.7869, R:0.0060, T:1.5550)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 45 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1798 (C:5.7776, R:0.0068, T:0.4954(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1389 (C:5.7446, R:0.0068, T:0.4598(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1518 (C:5.7348, R:0.0068, T:0.4712(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1483 (C:5.7418, R:0.0068, T:0.4656(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1677 (C:5.7793, R:0.0069, T:0.4825(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1279 (C:5.7806, R:0.0068, T:0.4487(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1320 (C:5.7301, R:0.0067, T:0.4600(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1647 (C:5.7506, R:0.0069, T:0.4793(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1656 (C:5.7628, R:0.0068, T:0.4860(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1640 (C:5.7458, R:0.0068, T:0.4800(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1437 (C:5.7767, R:0.0068, T:0.4620(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1551 (C:5.7642, R:0.0068, T:0.4753(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1432 (C:5.7202, R:0.0068, T:0.4662(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1456 (C:5.7463, R:0.0068, T:0.4625(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1440 (C:5.7675, R:0.0068, T:0.4620(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1716 (C:5.7653, R:0.0068, T:0.4913(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1531 (C:5.7538, R:0.0068, T:0.4726(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1286 (C:5.7161, R:0.0068, T:0.4489(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1768 (C:5.7475, R:0.0068, T:0.4941(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1305 (C:5.7481, R:0.0068, T:0.4478(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1504 (C:5.7564, R:0.0069, T:0.4620(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1350 (C:5.7722, R:0.0068, T:0.4538(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4708

ğŸ“Š EPOCH 45 TRAINING SUMMARY:
  Total Loss: 1.1521
  Contrastive: 5.7553
  Reconstruction: 0.0068
  Topological: 0.4708 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.1050
  Contrastive: 5.7746
  Reconstruction: 0.0060
  Topological: 1.5072 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 45/300 COMPLETE (39.8s)
Train Loss: 1.1521 (C:5.7553, R:0.0068, T:0.4708)
Val Loss:   2.1050 (C:5.7746, R:0.0060, T:1.5072)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 46 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1444 (C:5.7683, R:0.0068, T:0.4653(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1596 (C:5.7686, R:0.0068, T:0.4789(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1376 (C:5.7608, R:0.0068, T:0.4601(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1340 (C:5.7918, R:0.0068, T:0.4533(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1295 (C:5.7763, R:0.0068, T:0.4475(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1733 (C:5.7740, R:0.0069, T:0.4860(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1554 (C:5.7752, R:0.0068, T:0.4728(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1354 (C:5.7535, R:0.0067, T:0.4609(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1385 (C:5.7431, R:0.0068, T:0.4592(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1316 (C:5.7991, R:0.0068, T:0.4523(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1522 (C:5.7697, R:0.0068, T:0.4719(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1485 (C:5.7799, R:0.0068, T:0.4691(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1619 (C:5.7434, R:0.0068, T:0.4780(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1546 (C:5.7301, R:0.0068, T:0.4731(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1351 (C:5.7869, R:0.0068, T:0.4570(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1839 (C:5.7776, R:0.0069, T:0.4988(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1461 (C:5.7854, R:0.0068, T:0.4614(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1349 (C:5.7549, R:0.0068, T:0.4583(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1511 (C:5.7638, R:0.0069, T:0.4633(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1503 (C:5.7678, R:0.0068, T:0.4730(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1557 (C:5.7742, R:0.0068, T:0.4765(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1573 (C:5.7406, R:0.0068, T:0.4782(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4696

ğŸ“Š EPOCH 46 TRAINING SUMMARY:
  Total Loss: 1.1503
  Contrastive: 5.7542
  Reconstruction: 0.0068
  Topological: 0.4696 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.0834
  Contrastive: 5.7957
  Reconstruction: 0.0060
  Topological: 1.4862 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 46/300 COMPLETE (41.1s)
Train Loss: 1.1503 (C:5.7542, R:0.0068, T:0.4696)
Val Loss:   2.0834 (C:5.7957, R:0.0060, T:1.4862)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 47 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1731 (C:5.7815, R:0.0069, T:0.4874(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1266 (C:5.7813, R:0.0068, T:0.4493(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1309 (C:5.7796, R:0.0068, T:0.4493(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1495 (C:5.7286, R:0.0068, T:0.4704(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1354 (C:5.7376, R:0.0068, T:0.4574(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1622 (C:5.7410, R:0.0068, T:0.4838(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1596 (C:5.7749, R:0.0068, T:0.4763(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1511 (C:5.7493, R:0.0068, T:0.4722(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1547 (C:5.7569, R:0.0068, T:0.4758(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1441 (C:5.7708, R:0.0069, T:0.4587(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1465 (C:5.7737, R:0.0068, T:0.4639(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1250 (C:5.7899, R:0.0068, T:0.4449(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1567 (C:5.7369, R:0.0068, T:0.4769(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1409 (C:5.7462, R:0.0068, T:0.4620(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1146 (C:5.7645, R:0.0067, T:0.4454(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1487 (C:5.7409, R:0.0068, T:0.4706(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1595 (C:5.8059, R:0.0068, T:0.4776(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1429 (C:5.7260, R:0.0068, T:0.4676(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1438 (C:5.7458, R:0.0068, T:0.4610(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1443 (C:5.7692, R:0.0068, T:0.4630(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1597 (C:5.6873, R:0.0068, T:0.4757(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1329 (C:5.7533, R:0.0068, T:0.4480(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4668

ğŸ“Š EPOCH 47 TRAINING SUMMARY:
  Total Loss: 1.1469
  Contrastive: 5.7539
  Reconstruction: 0.0068
  Topological: 0.4668 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.0963
  Contrastive: 5.7710
  Reconstruction: 0.0060
  Topological: 1.4994 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 47/300 COMPLETE (39.8s)
Train Loss: 1.1469 (C:5.7539, R:0.0068, T:0.4668)
Val Loss:   2.0963 (C:5.7710, R:0.0060, T:1.4994)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 48 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1356 (C:5.7642, R:0.0068, T:0.4555(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1340 (C:5.7064, R:0.0068, T:0.4543(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1157 (C:5.7405, R:0.0068, T:0.4356(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1587 (C:5.7738, R:0.0068, T:0.4748(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1650 (C:5.7553, R:0.0068, T:0.4844(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1114 (C:5.7420, R:0.0067, T:0.4370(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1557 (C:5.7491, R:0.0067, T:0.4826(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1336 (C:5.7404, R:0.0067, T:0.4593(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1100 (C:5.7829, R:0.0068, T:0.4329(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1315 (C:5.7632, R:0.0068, T:0.4503(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1352 (C:5.7558, R:0.0068, T:0.4566(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1228 (C:5.7449, R:0.0068, T:0.4439(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1448 (C:5.7442, R:0.0068, T:0.4638(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1218 (C:5.7800, R:0.0067, T:0.4479(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1789 (C:5.7323, R:0.0068, T:0.4982(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1111 (C:5.7400, R:0.0068, T:0.4316(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1200 (C:5.7590, R:0.0068, T:0.4379(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1676 (C:5.7458, R:0.0068, T:0.4835(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1462 (C:5.7360, R:0.0067, T:0.4718(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1326 (C:5.7639, R:0.0068, T:0.4501(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1351 (C:5.7864, R:0.0068, T:0.4547(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1829 (C:5.7727, R:0.0068, T:0.5008(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 48 TRAINING SUMMARY:
  Total Loss: 1.1464
  Contrastive: 5.7544
  Reconstruction: 0.0068
  Topological: 0.4669 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.1520
  Contrastive: 5.7370
  Reconstruction: 0.0060
  Topological: 1.5538 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 48/300 COMPLETE (38.4s)
Train Loss: 1.1464 (C:5.7544, R:0.0068, T:0.4669)
Val Loss:   2.1520 (C:5.7370, R:0.0060, T:1.5538)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 49 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1447 (C:5.7482, R:0.0068, T:0.4647(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1390 (C:5.7749, R:0.0068, T:0.4562(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1425 (C:5.7775, R:0.0068, T:0.4628(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1064 (C:5.7536, R:0.0068, T:0.4302(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1205 (C:5.7561, R:0.0068, T:0.4434(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1655 (C:5.7776, R:0.0068, T:0.4829(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1761 (C:5.7553, R:0.0068, T:0.4935(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1161 (C:5.7597, R:0.0067, T:0.4414(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1445 (C:5.7384, R:0.0068, T:0.4659(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1601 (C:5.7848, R:0.0068, T:0.4806(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1477 (C:5.7673, R:0.0068, T:0.4697(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1872 (C:5.7928, R:0.0069, T:0.5011(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1325 (C:5.7491, R:0.0068, T:0.4557(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1517 (C:5.7618, R:0.0068, T:0.4687(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1756 (C:5.7622, R:0.0068, T:0.4935(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1585 (C:5.7731, R:0.0068, T:0.4791(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1793 (C:5.8308, R:0.0068, T:0.4964(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1533 (C:5.7648, R:0.0068, T:0.4737(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1734 (C:5.7337, R:0.0068, T:0.4933(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1570 (C:5.7594, R:0.0068, T:0.4769(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1333 (C:5.7539, R:0.0068, T:0.4559(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1381 (C:5.7488, R:0.0068, T:0.4590(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4658

ğŸ“Š EPOCH 49 TRAINING SUMMARY:
  Total Loss: 1.1450
  Contrastive: 5.7549
  Reconstruction: 0.0068
  Topological: 0.4658 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.1258
  Contrastive: 5.7422
  Reconstruction: 0.0060
  Topological: 1.5304 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 49/300 COMPLETE (38.7s)
Train Loss: 1.1450 (C:5.7549, R:0.0068, T:0.4658)
Val Loss:   2.1258 (C:5.7422, R:0.0060, T:1.5304)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 50 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1698 (C:5.7510, R:0.0068, T:0.4853(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1398 (C:5.7706, R:0.0069, T:0.4541(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1255 (C:5.7622, R:0.0068, T:0.4484(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1385 (C:5.7533, R:0.0068, T:0.4574(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1537 (C:5.7579, R:0.0068, T:0.4701(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1171 (C:5.7455, R:0.0068, T:0.4402(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1381 (C:5.7400, R:0.0068, T:0.4566(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1460 (C:5.7676, R:0.0068, T:0.4687(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1602 (C:5.7619, R:0.0068, T:0.4788(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1601 (C:5.7470, R:0.0068, T:0.4810(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1355 (C:5.7473, R:0.0068, T:0.4600(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1021 (C:5.7239, R:0.0068, T:0.4227(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1378 (C:5.7679, R:0.0067, T:0.4640(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1676 (C:5.7898, R:0.0068, T:0.4888(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1390 (C:5.7824, R:0.0068, T:0.4574(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1311 (C:5.7331, R:0.0067, T:0.4576(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1304 (C:5.7483, R:0.0068, T:0.4550(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1091 (C:5.7317, R:0.0067, T:0.4359(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1423 (C:5.7319, R:0.0068, T:0.4645(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1440 (C:5.7545, R:0.0068, T:0.4689(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1513 (C:5.7380, R:0.0068, T:0.4746(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1520 (C:5.7630, R:0.0068, T:0.4731(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4641

ğŸ“Š EPOCH 50 TRAINING SUMMARY:
  Total Loss: 1.1430
  Contrastive: 5.7536
  Reconstruction: 0.0068
  Topological: 0.4641 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.0572
  Contrastive: 5.7711
  Reconstruction: 0.0059
  Topological: 1.4625 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 50/300 COMPLETE (39.2s)
Train Loss: 1.1430 (C:5.7536, R:0.0068, T:0.4641)
Val Loss:   2.0572 (C:5.7711, R:0.0059, T:1.4625)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 51 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1530 (C:5.7674, R:0.0068, T:0.4768(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1565 (C:5.7799, R:0.0068, T:0.4739(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1321 (C:5.7345, R:0.0068, T:0.4516(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1443 (C:5.7530, R:0.0068, T:0.4684(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1523 (C:5.7422, R:0.0068, T:0.4721(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1362 (C:5.7427, R:0.0068, T:0.4549(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1856 (C:5.7681, R:0.0068, T:0.5021(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1509 (C:5.7719, R:0.0068, T:0.4663(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1473 (C:5.7542, R:0.0068, T:0.4645(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1346 (C:5.7748, R:0.0068, T:0.4517(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1512 (C:5.7615, R:0.0068, T:0.4685(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1426 (C:5.7394, R:0.0068, T:0.4635(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1706 (C:5.7794, R:0.0068, T:0.4945(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1732 (C:5.7650, R:0.0068, T:0.4926(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1433 (C:5.7272, R:0.0068, T:0.4603(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1722 (C:5.7235, R:0.0068, T:0.4931(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1267 (C:5.7400, R:0.0067, T:0.4518(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1407 (C:5.7526, R:0.0068, T:0.4610(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1485 (C:5.7499, R:0.0068, T:0.4716(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1371 (C:5.7503, R:0.0067, T:0.4646(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1467 (C:5.7437, R:0.0068, T:0.4710(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1664 (C:5.7522, R:0.0068, T:0.4885(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4637

ğŸ“Š EPOCH 51 TRAINING SUMMARY:
  Total Loss: 1.1419
  Contrastive: 5.7542
  Reconstruction: 0.0068
  Topological: 0.4637 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.1912
  Contrastive: 5.7243
  Reconstruction: 0.0060
  Topological: 1.5949 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 51/300 COMPLETE (38.4s)
Train Loss: 1.1419 (C:5.7542, R:0.0068, T:0.4637)
Val Loss:   2.1912 (C:5.7243, R:0.0060, T:1.5949)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 52 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1392 (C:5.7417, R:0.0068, T:0.4639(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1440 (C:5.7341, R:0.0067, T:0.4715(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1409 (C:5.7841, R:0.0068, T:0.4636(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1615 (C:5.7621, R:0.0068, T:0.4796(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1574 (C:5.7384, R:0.0068, T:0.4772(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1547 (C:5.7122, R:0.0068, T:0.4718(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1177 (C:5.7465, R:0.0068, T:0.4408(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1146 (C:5.7439, R:0.0068, T:0.4386(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1337 (C:5.7333, R:0.0068, T:0.4564(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1472 (C:5.7818, R:0.0068, T:0.4709(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1305 (C:5.7418, R:0.0068, T:0.4472(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1471 (C:5.7184, R:0.0067, T:0.4734(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1733 (C:5.7567, R:0.0068, T:0.4927(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1730 (C:5.7263, R:0.0067, T:0.4981(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1412 (C:5.7540, R:0.0068, T:0.4601(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1528 (C:5.8024, R:0.0069, T:0.4633(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1146 (C:5.7351, R:0.0067, T:0.4406(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1374 (C:5.7460, R:0.0068, T:0.4598(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1646 (C:5.7712, R:0.0068, T:0.4876(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1418 (C:5.7616, R:0.0068, T:0.4630(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1546 (C:5.7224, R:0.0068, T:0.4729(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1268 (C:5.7829, R:0.0068, T:0.4464(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 52 TRAINING SUMMARY:
  Total Loss: 1.1419
  Contrastive: 5.7556
  Reconstruction: 0.0068
  Topological: 0.4639 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.1730
  Contrastive: 5.7317
  Reconstruction: 0.0059
  Topological: 1.5795 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 52/300 COMPLETE (38.9s)
Train Loss: 1.1419 (C:5.7556, R:0.0068, T:0.4639)
Val Loss:   2.1730 (C:5.7317, R:0.0059, T:1.5795)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 53 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1582 (C:5.7516, R:0.0068, T:0.4823(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1605 (C:5.7491, R:0.0069, T:0.4749(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1306 (C:5.7271, R:0.0067, T:0.4559(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1401 (C:5.7384, R:0.0068, T:0.4603(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1199 (C:5.7506, R:0.0068, T:0.4443(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1227 (C:5.7561, R:0.0068, T:0.4461(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1406 (C:5.7682, R:0.0068, T:0.4581(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1694 (C:5.7858, R:0.0068, T:0.4918(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1247 (C:5.7844, R:0.0068, T:0.4456(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1312 (C:5.7466, R:0.0067, T:0.4583(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1650 (C:5.8100, R:0.0068, T:0.4825(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1256 (C:5.7617, R:0.0068, T:0.4466(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1483 (C:5.7517, R:0.0067, T:0.4747(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1406 (C:5.7875, R:0.0068, T:0.4622(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1884 (C:5.7833, R:0.0068, T:0.5091(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1620 (C:5.7587, R:0.0068, T:0.4830(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1319 (C:5.7506, R:0.0067, T:0.4607(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1364 (C:5.7494, R:0.0068, T:0.4575(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1738 (C:5.7506, R:0.0068, T:0.4900(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1563 (C:5.7571, R:0.0068, T:0.4796(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1276 (C:5.7489, R:0.0068, T:0.4498(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1435 (C:5.7013, R:0.0068, T:0.4677(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4625

ğŸ“Š EPOCH 53 TRAINING SUMMARY:
  Total Loss: 1.1402
  Contrastive: 5.7530
  Reconstruction: 0.0068
  Topological: 0.4625 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.0128
  Contrastive: 5.7830
  Reconstruction: 0.0059
  Topological: 1.4208 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 53/300 COMPLETE (39.0s)
Train Loss: 1.1402 (C:5.7530, R:0.0068, T:0.4625)
Val Loss:   2.0128 (C:5.7830, R:0.0059, T:1.4208)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 54 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1451 (C:5.7857, R:0.0068, T:0.4629(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1249 (C:5.7473, R:0.0067, T:0.4501(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1304 (C:5.7504, R:0.0068, T:0.4527(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1248 (C:5.7311, R:0.0068, T:0.4488(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1007 (C:5.7597, R:0.0068, T:0.4222(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1527 (C:5.7259, R:0.0068, T:0.4725(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1319 (C:5.7415, R:0.0068, T:0.4510(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1456 (C:5.7166, R:0.0068, T:0.4670(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1325 (C:5.7341, R:0.0068, T:0.4553(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1411 (C:5.7756, R:0.0068, T:0.4645(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1445 (C:5.7372, R:0.0068, T:0.4688(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1511 (C:5.6968, R:0.0068, T:0.4669(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1304 (C:5.7214, R:0.0068, T:0.4536(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1288 (C:5.7485, R:0.0067, T:0.4546(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1166 (C:5.7471, R:0.0068, T:0.4372(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1318 (C:5.7225, R:0.0068, T:0.4549(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1384 (C:5.7446, R:0.0068, T:0.4623(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1493 (C:5.7531, R:0.0068, T:0.4682(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1465 (C:5.7603, R:0.0068, T:0.4662(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1501 (C:5.7242, R:0.0068, T:0.4733(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1346 (C:5.7291, R:0.0068, T:0.4593(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1399 (C:5.7298, R:0.0068, T:0.4639(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4609

ğŸ“Š EPOCH 54 TRAINING SUMMARY:
  Total Loss: 1.1380
  Contrastive: 5.7520
  Reconstruction: 0.0068
  Topological: 0.4609 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.1276
  Contrastive: 5.7595
  Reconstruction: 0.0059
  Topological: 1.5342 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 54/300 COMPLETE (38.6s)
Train Loss: 1.1380 (C:5.7520, R:0.0068, T:0.4609)
Val Loss:   2.1276 (C:5.7595, R:0.0059, T:1.5342)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 55 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1373 (C:5.7593, R:0.0068, T:0.4567(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1186 (C:5.7495, R:0.0067, T:0.4445(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1219 (C:5.7458, R:0.0067, T:0.4491(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1387 (C:5.7622, R:0.0068, T:0.4602(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1116 (C:5.7648, R:0.0068, T:0.4337(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1224 (C:5.7445, R:0.0068, T:0.4432(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1422 (C:5.7496, R:0.0067, T:0.4710(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1301 (C:5.7630, R:0.0068, T:0.4525(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1524 (C:5.7319, R:0.0068, T:0.4754(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1272 (C:5.7566, R:0.0068, T:0.4482(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1366 (C:5.7201, R:0.0068, T:0.4610(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1409 (C:5.7283, R:0.0068, T:0.4607(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1496 (C:5.7464, R:0.0068, T:0.4736(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1131 (C:5.7524, R:0.0067, T:0.4397(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1335 (C:5.7240, R:0.0067, T:0.4598(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1396 (C:5.7728, R:0.0068, T:0.4583(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1369 (C:5.7796, R:0.0068, T:0.4599(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1526 (C:5.7298, R:0.0068, T:0.4705(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1195 (C:5.7375, R:0.0067, T:0.4500(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1462 (C:5.7301, R:0.0068, T:0.4698(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1348 (C:5.7385, R:0.0067, T:0.4608(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1292 (C:5.7712, R:0.0067, T:0.4560(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4588

ğŸ“Š EPOCH 55 TRAINING SUMMARY:
  Total Loss: 1.1355
  Contrastive: 5.7536
  Reconstruction: 0.0068
  Topological: 0.4588 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.0652
  Contrastive: 5.7583
  Reconstruction: 0.0059
  Topological: 1.4734 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 55/300 COMPLETE (40.7s)
Train Loss: 1.1355 (C:5.7536, R:0.0068, T:0.4588)
Val Loss:   2.0652 (C:5.7583, R:0.0059, T:1.4734)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 56 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1300 (C:5.7575, R:0.0068, T:0.4544(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1420 (C:5.7413, R:0.0067, T:0.4677(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1384 (C:5.7309, R:0.0068, T:0.4572(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1296 (C:5.7286, R:0.0067, T:0.4596(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1355 (C:5.7925, R:0.0068, T:0.4579(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1513 (C:5.7809, R:0.0068, T:0.4732(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1217 (C:5.7196, R:0.0068, T:0.4438(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1616 (C:5.7944, R:0.0068, T:0.4797(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1314 (C:5.7490, R:0.0067, T:0.4565(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1218 (C:5.7794, R:0.0068, T:0.4457(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1077 (C:5.7498, R:0.0067, T:0.4363(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1138 (C:5.7289, R:0.0067, T:0.4410(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1255 (C:5.7435, R:0.0068, T:0.4489(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1578 (C:5.7613, R:0.0068, T:0.4807(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1173 (C:5.7582, R:0.0067, T:0.4452(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1163 (C:5.7803, R:0.0067, T:0.4426(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1330 (C:5.7519, R:0.0068, T:0.4556(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1358 (C:5.7301, R:0.0068, T:0.4586(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1218 (C:5.7467, R:0.0068, T:0.4464(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1422 (C:5.7992, R:0.0068, T:0.4624(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1420 (C:5.7639, R:0.0068, T:0.4667(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1615 (C:5.7552, R:0.0068, T:0.4807(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4577

ğŸ“Š EPOCH 56 TRAINING SUMMARY:
  Total Loss: 1.1339
  Contrastive: 5.7542
  Reconstruction: 0.0068
  Topological: 0.4577 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.0813
  Contrastive: 5.7507
  Reconstruction: 0.0059
  Topological: 1.4893 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 56/300 COMPLETE (39.2s)
Train Loss: 1.1339 (C:5.7542, R:0.0068, T:0.4577)
Val Loss:   2.0813 (C:5.7507, R:0.0059, T:1.4893)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 57 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1023 (C:5.7545, R:0.0067, T:0.4304(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1233 (C:5.7130, R:0.0068, T:0.4410(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1084 (C:5.7156, R:0.0067, T:0.4348(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1548 (C:5.7190, R:0.0068, T:0.4789(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1475 (C:5.7756, R:0.0067, T:0.4744(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1373 (C:5.7717, R:0.0068, T:0.4621(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1415 (C:5.7409, R:0.0067, T:0.4692(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1336 (C:5.7406, R:0.0067, T:0.4605(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1450 (C:5.7680, R:0.0067, T:0.4718(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1494 (C:5.7644, R:0.0068, T:0.4683(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1189 (C:5.7559, R:0.0067, T:0.4520(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1274 (C:5.7692, R:0.0067, T:0.4548(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1227 (C:5.7379, R:0.0067, T:0.4530(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1001 (C:5.7399, R:0.0067, T:0.4277(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1100 (C:5.7324, R:0.0068, T:0.4308(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1189 (C:5.7427, R:0.0068, T:0.4427(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1409 (C:5.7677, R:0.0068, T:0.4652(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1424 (C:5.7529, R:0.0067, T:0.4688(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1358 (C:5.7528, R:0.0068, T:0.4568(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1374 (C:5.7536, R:0.0068, T:0.4599(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1297 (C:5.7299, R:0.0068, T:0.4545(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1181 (C:5.7242, R:0.0067, T:0.4456(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4563

ğŸ“Š EPOCH 57 TRAINING SUMMARY:
  Total Loss: 1.1319
  Contrastive: 5.7525
  Reconstruction: 0.0068
  Topological: 0.4563 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.1379
  Contrastive: 5.7180
  Reconstruction: 0.0059
  Topological: 1.5484 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 57/300 COMPLETE (39.5s)
Train Loss: 1.1319 (C:5.7525, R:0.0068, T:0.4563)
Val Loss:   2.1379 (C:5.7180, R:0.0059, T:1.5484)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 58 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1080 (C:5.7275, R:0.0067, T:0.4331(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1665 (C:5.7117, R:0.0068, T:0.4858(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1448 (C:5.7135, R:0.0068, T:0.4665(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1410 (C:5.7590, R:0.0067, T:0.4677(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1691 (C:5.7581, R:0.0067, T:0.4953(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1012 (C:5.7520, R:0.0067, T:0.4275(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1317 (C:5.7372, R:0.0067, T:0.4598(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1297 (C:5.7838, R:0.0068, T:0.4524(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1473 (C:5.7723, R:0.0068, T:0.4671(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1388 (C:5.7986, R:0.0068, T:0.4590(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1012 (C:5.7641, R:0.0067, T:0.4331(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1137 (C:5.7943, R:0.0068, T:0.4315(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1226 (C:5.7645, R:0.0068, T:0.4447(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1183 (C:5.7793, R:0.0067, T:0.4457(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1093 (C:5.7596, R:0.0068, T:0.4301(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1348 (C:5.7186, R:0.0067, T:0.4599(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1191 (C:5.7395, R:0.0068, T:0.4440(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1289 (C:5.7412, R:0.0068, T:0.4533(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1128 (C:5.7885, R:0.0068, T:0.4335(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1542 (C:5.7489, R:0.0068, T:0.4780(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1332 (C:5.7404, R:0.0068, T:0.4566(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1426 (C:5.8033, R:0.0068, T:0.4659(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4550

ğŸ“Š EPOCH 58 TRAINING SUMMARY:
  Total Loss: 1.1301
  Contrastive: 5.7515
  Reconstruction: 0.0068
  Topological: 0.4550 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.1345
  Contrastive: 5.7301
  Reconstruction: 0.0059
  Topological: 1.5419 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 58/300 COMPLETE (39.5s)
Train Loss: 1.1301 (C:5.7515, R:0.0068, T:0.4550)
Val Loss:   2.1345 (C:5.7301, R:0.0059, T:1.5419)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 59 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1133 (C:5.7592, R:0.0068, T:0.4377(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1544 (C:5.7572, R:0.0068, T:0.4750(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1040 (C:5.7650, R:0.0067, T:0.4302(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1251 (C:5.7436, R:0.0067, T:0.4546(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1127 (C:5.7326, R:0.0067, T:0.4403(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1493 (C:5.7214, R:0.0068, T:0.4732(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1436 (C:5.7558, R:0.0068, T:0.4604(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1293 (C:5.7727, R:0.0068, T:0.4486(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1209 (C:5.7582, R:0.0068, T:0.4455(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1341 (C:5.7213, R:0.0067, T:0.4606(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1061 (C:5.7334, R:0.0067, T:0.4321(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1328 (C:5.7718, R:0.0068, T:0.4577(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1137 (C:5.7892, R:0.0067, T:0.4446(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1300 (C:5.7896, R:0.0068, T:0.4537(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1382 (C:5.7105, R:0.0068, T:0.4596(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1455 (C:5.7429, R:0.0068, T:0.4686(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1237 (C:5.7723, R:0.0067, T:0.4492(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1463 (C:5.7373, R:0.0068, T:0.4669(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1265 (C:5.7229, R:0.0068, T:0.4486(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1182 (C:5.7199, R:0.0067, T:0.4473(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1178 (C:5.7573, R:0.0068, T:0.4395(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1421 (C:5.7350, R:0.0068, T:0.4669(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4549

ğŸ“Š EPOCH 59 TRAINING SUMMARY:
  Total Loss: 1.1299
  Contrastive: 5.7539
  Reconstruction: 0.0067
  Topological: 0.4549 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.0726
  Contrastive: 5.7456
  Reconstruction: 0.0059
  Topological: 1.4818 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 59/300 COMPLETE (39.1s)
Train Loss: 1.1299 (C:5.7539, R:0.0067, T:0.4549)
Val Loss:   2.0726 (C:5.7456, R:0.0059, T:1.4818)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 60 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1339 (C:5.7668, R:0.0068, T:0.4547(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1243 (C:5.7447, R:0.0068, T:0.4473(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1281 (C:5.7758, R:0.0067, T:0.4553(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1365 (C:5.7429, R:0.0067, T:0.4659(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1483 (C:5.7213, R:0.0067, T:0.4747(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1430 (C:5.7451, R:0.0068, T:0.4668(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1315 (C:5.7133, R:0.0067, T:0.4597(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1461 (C:5.7922, R:0.0068, T:0.4681(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1217 (C:5.7929, R:0.0067, T:0.4485(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1274 (C:5.7042, R:0.0066, T:0.4640(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1231 (C:5.7796, R:0.0068, T:0.4461(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1333 (C:5.7557, R:0.0067, T:0.4632(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1124 (C:5.7263, R:0.0067, T:0.4403(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1361 (C:5.7592, R:0.0068, T:0.4606(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1378 (C:5.7329, R:0.0067, T:0.4639(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1461 (C:5.7739, R:0.0068, T:0.4703(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1164 (C:5.7759, R:0.0067, T:0.4443(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1183 (C:5.7584, R:0.0067, T:0.4461(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1317 (C:5.7380, R:0.0067, T:0.4579(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1163 (C:5.7610, R:0.0067, T:0.4434(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1480 (C:5.7486, R:0.0068, T:0.4711(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1282 (C:5.7632, R:0.0068, T:0.4501(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4527

ğŸ“Š EPOCH 60 TRAINING SUMMARY:
  Total Loss: 1.1272
  Contrastive: 5.7532
  Reconstruction: 0.0067
  Topological: 0.4527 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.1195
  Contrastive: 5.7250
  Reconstruction: 0.0059
  Topological: 1.5291 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 60/300 COMPLETE (37.6s)
Train Loss: 1.1272 (C:5.7532, R:0.0067, T:0.4527)
Val Loss:   2.1195 (C:5.7250, R:0.0059, T:1.5291)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 61 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1319 (C:5.7518, R:0.0068, T:0.4562(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1221 (C:5.7357, R:0.0068, T:0.4458(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1558 (C:5.7524, R:0.0068, T:0.4789(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1267 (C:5.7795, R:0.0067, T:0.4524(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1375 (C:5.7896, R:0.0068, T:0.4611(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1740 (C:5.7806, R:0.0067, T:0.5001(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1183 (C:5.7428, R:0.0068, T:0.4430(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1132 (C:5.7427, R:0.0067, T:0.4399(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1230 (C:5.7545, R:0.0067, T:0.4522(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1099 (C:5.7376, R:0.0067, T:0.4392(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1170 (C:5.7767, R:0.0068, T:0.4406(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1218 (C:5.7114, R:0.0067, T:0.4540(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1372 (C:5.7766, R:0.0068, T:0.4609(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.0772 (C:5.7645, R:0.0067, T:0.4045(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1523 (C:5.7379, R:0.0067, T:0.4786(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1271 (C:5.7530, R:0.0068, T:0.4481(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1381 (C:5.7258, R:0.0067, T:0.4671(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1174 (C:5.7557, R:0.0067, T:0.4496(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1405 (C:5.7342, R:0.0067, T:0.4673(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1289 (C:5.7730, R:0.0068, T:0.4519(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1252 (C:5.7438, R:0.0067, T:0.4528(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1392 (C:5.7464, R:0.0068, T:0.4590(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 61 TRAINING SUMMARY:
  Total Loss: 1.1274
  Contrastive: 5.7507
  Reconstruction: 0.0067
  Topological: 0.4533 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.0849
  Contrastive: 5.7158
  Reconstruction: 0.0059
  Topological: 1.4956 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 61/300 COMPLETE (38.9s)
Train Loss: 1.1274 (C:5.7507, R:0.0067, T:0.4533)
Val Loss:   2.0849 (C:5.7158, R:0.0059, T:1.4956)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 62 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1050 (C:5.7368, R:0.0067, T:0.4355(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1198 (C:5.7427, R:0.0067, T:0.4455(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1217 (C:5.7167, R:0.0067, T:0.4506(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1348 (C:5.7545, R:0.0068, T:0.4595(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1270 (C:5.7789, R:0.0068, T:0.4520(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1213 (C:5.8198, R:0.0067, T:0.4487(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1232 (C:5.7348, R:0.0068, T:0.4474(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1307 (C:5.7120, R:0.0068, T:0.4555(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1384 (C:5.7615, R:0.0067, T:0.4705(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1280 (C:5.7457, R:0.0067, T:0.4555(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0980 (C:5.7686, R:0.0068, T:0.4179(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1227 (C:5.7454, R:0.0068, T:0.4425(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1355 (C:5.7297, R:0.0067, T:0.4626(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1120 (C:5.7376, R:0.0067, T:0.4424(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1384 (C:5.7416, R:0.0068, T:0.4626(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1345 (C:5.7216, R:0.0068, T:0.4559(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1242 (C:5.7722, R:0.0067, T:0.4534(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1308 (C:5.7873, R:0.0068, T:0.4545(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1442 (C:5.7685, R:0.0068, T:0.4661(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1241 (C:5.7745, R:0.0067, T:0.4512(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1201 (C:5.7634, R:0.0067, T:0.4460(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1205 (C:5.7575, R:0.0068, T:0.4444(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4525

ğŸ“Š EPOCH 62 TRAINING SUMMARY:
  Total Loss: 1.1265
  Contrastive: 5.7505
  Reconstruction: 0.0067
  Topological: 0.4525 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.0631
  Contrastive: 5.7410
  Reconstruction: 0.0059
  Topological: 1.4742 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 62/300 COMPLETE (40.2s)
Train Loss: 1.1265 (C:5.7505, R:0.0067, T:0.4525)
Val Loss:   2.0631 (C:5.7410, R:0.0059, T:1.4742)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 63 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1438 (C:5.7551, R:0.0068, T:0.4671(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1314 (C:5.7648, R:0.0068, T:0.4493(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1278 (C:5.7663, R:0.0068, T:0.4504(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1506 (C:5.7598, R:0.0068, T:0.4727(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1364 (C:5.7808, R:0.0068, T:0.4613(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1166 (C:5.7206, R:0.0067, T:0.4459(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1172 (C:5.7540, R:0.0068, T:0.4401(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1307 (C:5.7504, R:0.0067, T:0.4570(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1321 (C:5.7737, R:0.0068, T:0.4567(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1572 (C:5.7407, R:0.0068, T:0.4782(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1256 (C:5.7198, R:0.0067, T:0.4569(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1288 (C:5.7510, R:0.0067, T:0.4541(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1187 (C:5.7261, R:0.0067, T:0.4493(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1338 (C:5.7116, R:0.0067, T:0.4635(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0996 (C:5.6934, R:0.0067, T:0.4291(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1433 (C:5.7694, R:0.0068, T:0.4644(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1190 (C:5.7477, R:0.0067, T:0.4479(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1479 (C:5.7678, R:0.0067, T:0.4756(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0903 (C:5.7476, R:0.0067, T:0.4205(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1059 (C:5.7439, R:0.0067, T:0.4327(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1122 (C:5.7646, R:0.0067, T:0.4441(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1245 (C:5.7734, R:0.0067, T:0.4514(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 63 TRAINING SUMMARY:
  Total Loss: 1.1270
  Contrastive: 5.7516
  Reconstruction: 0.0067
  Topological: 0.4534 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.0420
  Contrastive: 5.7523
  Reconstruction: 0.0059
  Topological: 1.4542 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 63/300 COMPLETE (40.8s)
Train Loss: 1.1270 (C:5.7516, R:0.0067, T:0.4534)
Val Loss:   2.0420 (C:5.7523, R:0.0059, T:1.4542)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 64 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1484 (C:5.7656, R:0.0068, T:0.4709(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1349 (C:5.7466, R:0.0067, T:0.4631(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1369 (C:5.8046, R:0.0067, T:0.4669(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1378 (C:5.7823, R:0.0067, T:0.4631(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1159 (C:5.7401, R:0.0067, T:0.4448(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1208 (C:5.7299, R:0.0067, T:0.4481(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1346 (C:5.7494, R:0.0067, T:0.4628(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1194 (C:5.7230, R:0.0067, T:0.4523(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1105 (C:5.7712, R:0.0067, T:0.4388(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1419 (C:5.7848, R:0.0067, T:0.4703(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1028 (C:5.7326, R:0.0067, T:0.4282(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1022 (C:5.7363, R:0.0068, T:0.4269(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1357 (C:5.7809, R:0.0068, T:0.4592(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1225 (C:5.7502, R:0.0067, T:0.4481(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1169 (C:5.7472, R:0.0067, T:0.4457(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1472 (C:5.7606, R:0.0068, T:0.4692(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1282 (C:5.7430, R:0.0068, T:0.4527(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1024 (C:5.7672, R:0.0067, T:0.4336(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1124 (C:5.7231, R:0.0067, T:0.4382(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1210 (C:5.7754, R:0.0067, T:0.4501(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1257 (C:5.7538, R:0.0067, T:0.4533(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1231 (C:5.7649, R:0.0068, T:0.4471(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4507

ğŸ“Š EPOCH 64 TRAINING SUMMARY:
  Total Loss: 1.1241
  Contrastive: 5.7506
  Reconstruction: 0.0067
  Topological: 0.4507 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.0363
  Contrastive: 5.7277
  Reconstruction: 0.0059
  Topological: 1.4490 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 64/300 COMPLETE (39.6s)
Train Loss: 1.1241 (C:5.7506, R:0.0067, T:0.4507)
Val Loss:   2.0363 (C:5.7277, R:0.0059, T:1.4490)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 65 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1124 (C:5.7437, R:0.0067, T:0.4393(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1249 (C:5.7316, R:0.0067, T:0.4588(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1079 (C:5.7374, R:0.0067, T:0.4378(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1459 (C:5.7849, R:0.0068, T:0.4669(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0907 (C:5.7579, R:0.0067, T:0.4180(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1120 (C:5.7533, R:0.0067, T:0.4389(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1252 (C:5.7630, R:0.0067, T:0.4524(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1288 (C:5.7587, R:0.0067, T:0.4571(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1380 (C:5.7464, R:0.0067, T:0.4631(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1699 (C:5.7204, R:0.0068, T:0.4929(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1292 (C:5.7766, R:0.0067, T:0.4569(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1098 (C:5.7588, R:0.0068, T:0.4333(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1279 (C:5.7663, R:0.0067, T:0.4561(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1196 (C:5.7447, R:0.0067, T:0.4494(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0973 (C:5.7349, R:0.0067, T:0.4305(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1215 (C:5.7624, R:0.0068, T:0.4419(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1261 (C:5.7706, R:0.0068, T:0.4507(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1671 (C:5.7301, R:0.0068, T:0.4883(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1179 (C:5.7303, R:0.0067, T:0.4463(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1163 (C:5.7555, R:0.0067, T:0.4442(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1323 (C:5.7536, R:0.0067, T:0.4590(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0886 (C:5.7437, R:0.0067, T:0.4198(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4498

ğŸ“Š EPOCH 65 TRAINING SUMMARY:
  Total Loss: 1.1227
  Contrastive: 5.7508
  Reconstruction: 0.0067
  Topological: 0.4498 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.0956
  Contrastive: 5.7156
  Reconstruction: 0.0059
  Topological: 1.5084 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 65/300 COMPLETE (39.2s)
Train Loss: 1.1227 (C:5.7508, R:0.0067, T:0.4498)
Val Loss:   2.0956 (C:5.7156, R:0.0059, T:1.5084)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 66 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1404 (C:5.7415, R:0.0068, T:0.4647(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1132 (C:5.7821, R:0.0067, T:0.4388(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1014 (C:5.7536, R:0.0067, T:0.4308(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1256 (C:5.7644, R:0.0067, T:0.4564(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1195 (C:5.7629, R:0.0068, T:0.4404(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1194 (C:5.7524, R:0.0067, T:0.4463(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1151 (C:5.7179, R:0.0067, T:0.4446(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1187 (C:5.7993, R:0.0067, T:0.4438(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1050 (C:5.7599, R:0.0067, T:0.4349(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1172 (C:5.7448, R:0.0068, T:0.4419(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1149 (C:5.7418, R:0.0067, T:0.4454(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1111 (C:5.7479, R:0.0067, T:0.4380(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1145 (C:5.7550, R:0.0068, T:0.4351(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1130 (C:5.7405, R:0.0067, T:0.4393(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0972 (C:5.7642, R:0.0067, T:0.4271(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1036 (C:5.7893, R:0.0067, T:0.4345(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1375 (C:5.7181, R:0.0068, T:0.4592(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1183 (C:5.7534, R:0.0067, T:0.4487(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1210 (C:5.7851, R:0.0067, T:0.4505(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1523 (C:5.7503, R:0.0067, T:0.4784(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1101 (C:5.7446, R:0.0067, T:0.4415(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0987 (C:5.7415, R:0.0067, T:0.4273(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4490

ğŸ“Š EPOCH 66 TRAINING SUMMARY:
  Total Loss: 1.1216
  Contrastive: 5.7502
  Reconstruction: 0.0067
  Topological: 0.4490 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.9692
  Contrastive: 5.7542
  Reconstruction: 0.0058
  Topological: 1.3844 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 66/300 COMPLETE (40.2s)
Train Loss: 1.1216 (C:5.7502, R:0.0067, T:0.4490)
Val Loss:   1.9692 (C:5.7542, R:0.0058, T:1.3844)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 67 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1378 (C:5.7734, R:0.0067, T:0.4647(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1344 (C:5.7512, R:0.0067, T:0.4623(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1261 (C:5.7089, R:0.0067, T:0.4522(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1268 (C:5.7629, R:0.0067, T:0.4538(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1152 (C:5.7641, R:0.0067, T:0.4428(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1104 (C:5.7736, R:0.0067, T:0.4399(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1134 (C:5.7749, R:0.0067, T:0.4434(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1013 (C:5.7620, R:0.0067, T:0.4288(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1394 (C:5.7285, R:0.0067, T:0.4663(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1184 (C:5.7307, R:0.0067, T:0.4437(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0984 (C:5.7491, R:0.0067, T:0.4290(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1093 (C:5.7515, R:0.0067, T:0.4383(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1071 (C:5.7135, R:0.0067, T:0.4389(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1115 (C:5.7273, R:0.0067, T:0.4414(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1232 (C:5.7163, R:0.0067, T:0.4491(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1383 (C:5.7231, R:0.0067, T:0.4637(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1291 (C:5.7468, R:0.0068, T:0.4507(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0956 (C:5.7536, R:0.0068, T:0.4201(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1226 (C:5.7910, R:0.0068, T:0.4455(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1415 (C:5.7601, R:0.0067, T:0.4686(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1063 (C:5.7559, R:0.0067, T:0.4374(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0983 (C:5.7534, R:0.0068, T:0.4200(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4484

ğŸ“Š EPOCH 67 TRAINING SUMMARY:
  Total Loss: 1.1206
  Contrastive: 5.7503
  Reconstruction: 0.0067
  Topological: 0.4484 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.0611
  Contrastive: 5.7222
  Reconstruction: 0.0059
  Topological: 1.4751 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 67/300 COMPLETE (39.4s)
Train Loss: 1.1206 (C:5.7503, R:0.0067, T:0.4484)
Val Loss:   2.0611 (C:5.7222, R:0.0059, T:1.4751)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 68 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1145 (C:5.7425, R:0.0066, T:0.4501(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1003 (C:5.7540, R:0.0068, T:0.4241(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1287 (C:5.7209, R:0.0067, T:0.4563(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1183 (C:5.7339, R:0.0067, T:0.4488(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0938 (C:5.7850, R:0.0067, T:0.4238(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1266 (C:5.7727, R:0.0067, T:0.4551(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.0887 (C:5.7429, R:0.0067, T:0.4157(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.0997 (C:5.7370, R:0.0067, T:0.4284(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1263 (C:5.7077, R:0.0067, T:0.4590(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1335 (C:5.7630, R:0.0068, T:0.4574(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1290 (C:5.7722, R:0.0067, T:0.4580(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1238 (C:5.7497, R:0.0067, T:0.4488(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1076 (C:5.7609, R:0.0067, T:0.4357(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1218 (C:5.7954, R:0.0067, T:0.4525(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1198 (C:5.7676, R:0.0067, T:0.4497(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0928 (C:5.7466, R:0.0067, T:0.4229(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1228 (C:5.7653, R:0.0067, T:0.4485(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1184 (C:5.7218, R:0.0067, T:0.4457(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1156 (C:5.7548, R:0.0067, T:0.4457(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1347 (C:5.7372, R:0.0067, T:0.4634(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.0973 (C:5.7655, R:0.0068, T:0.4208(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1108 (C:5.7740, R:0.0067, T:0.4392(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4483

ğŸ“Š EPOCH 68 TRAINING SUMMARY:
  Total Loss: 1.1204
  Contrastive: 5.7503
  Reconstruction: 0.0067
  Topological: 0.4483 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.0743
  Contrastive: 5.6982
  Reconstruction: 0.0058
  Topological: 1.4894 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 68/300 COMPLETE (39.4s)
Train Loss: 1.1204 (C:5.7503, R:0.0067, T:0.4483)
Val Loss:   2.0743 (C:5.6982, R:0.0058, T:1.4894)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 69 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1242 (C:5.7156, R:0.0067, T:0.4494(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1472 (C:5.7273, R:0.0068, T:0.4681(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1462 (C:5.7683, R:0.0068, T:0.4689(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1089 (C:5.7565, R:0.0067, T:0.4382(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1304 (C:5.7589, R:0.0067, T:0.4555(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1600 (C:5.7672, R:0.0068, T:0.4808(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1021 (C:5.7314, R:0.0067, T:0.4356(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1244 (C:5.7095, R:0.0067, T:0.4534(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1130 (C:5.7323, R:0.0067, T:0.4399(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1411 (C:5.7376, R:0.0068, T:0.4652(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1368 (C:5.7656, R:0.0067, T:0.4629(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1255 (C:5.7694, R:0.0068, T:0.4464(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1067 (C:5.7532, R:0.0067, T:0.4350(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1195 (C:5.7482, R:0.0067, T:0.4544(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1260 (C:5.7884, R:0.0067, T:0.4520(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1040 (C:5.7731, R:0.0067, T:0.4361(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1432 (C:5.7414, R:0.0068, T:0.4662(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1418 (C:5.7455, R:0.0067, T:0.4729(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1102 (C:5.7549, R:0.0067, T:0.4390(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1072 (C:5.7762, R:0.0067, T:0.4403(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1218 (C:5.7913, R:0.0067, T:0.4520(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0779 (C:5.7646, R:0.0067, T:0.4074(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4476

ğŸ“Š EPOCH 69 TRAINING SUMMARY:
  Total Loss: 1.1193
  Contrastive: 5.7499
  Reconstruction: 0.0067
  Topological: 0.4476 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.0536
  Contrastive: 5.7530
  Reconstruction: 0.0059
  Topological: 1.4680 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 69/300 COMPLETE (39.6s)
Train Loss: 1.1193 (C:5.7499, R:0.0067, T:0.4476)
Val Loss:   2.0536 (C:5.7530, R:0.0059, T:1.4680)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 70 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1088 (C:5.7433, R:0.0067, T:0.4411(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1251 (C:5.7924, R:0.0067, T:0.4527(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0872 (C:5.7408, R:0.0067, T:0.4222(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1306 (C:5.7545, R:0.0067, T:0.4558(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1050 (C:5.6918, R:0.0067, T:0.4387(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1125 (C:5.7789, R:0.0067, T:0.4440(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1202 (C:5.7256, R:0.0067, T:0.4470(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1154 (C:5.7596, R:0.0067, T:0.4465(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1373 (C:5.7725, R:0.0068, T:0.4582(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1281 (C:5.7733, R:0.0068, T:0.4520(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1462 (C:5.7708, R:0.0068, T:0.4698(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1359 (C:5.7424, R:0.0068, T:0.4604(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1093 (C:5.7419, R:0.0068, T:0.4324(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1224 (C:5.7411, R:0.0067, T:0.4499(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1250 (C:5.7473, R:0.0067, T:0.4533(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1219 (C:5.7591, R:0.0067, T:0.4477(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.0941 (C:5.7480, R:0.0067, T:0.4261(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1368 (C:5.7494, R:0.0067, T:0.4654(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1301 (C:5.7619, R:0.0068, T:0.4544(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0989 (C:5.7842, R:0.0067, T:0.4287(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.0929 (C:5.7239, R:0.0066, T:0.4283(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1105 (C:5.7622, R:0.0067, T:0.4372(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4472

ğŸ“Š EPOCH 70 TRAINING SUMMARY:
  Total Loss: 1.1187
  Contrastive: 5.7496
  Reconstruction: 0.0067
  Topological: 0.4472 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.9961
  Contrastive: 5.7445
  Reconstruction: 0.0058
  Topological: 1.4117 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 70/300 COMPLETE (39.3s)
Train Loss: 1.1187 (C:5.7496, R:0.0067, T:0.4472)
Val Loss:   1.9961 (C:5.7445, R:0.0058, T:1.4117)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 71 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1101 (C:5.7533, R:0.0067, T:0.4422(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1079 (C:5.7393, R:0.0067, T:0.4339(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1411 (C:5.7411, R:0.0067, T:0.4695(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1136 (C:5.7311, R:0.0067, T:0.4424(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1128 (C:5.7308, R:0.0067, T:0.4378(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0995 (C:5.7907, R:0.0067, T:0.4309(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1012 (C:5.7458, R:0.0067, T:0.4326(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1297 (C:5.7825, R:0.0067, T:0.4574(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1277 (C:5.7742, R:0.0067, T:0.4552(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1405 (C:5.7074, R:0.0067, T:0.4699(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1190 (C:5.7191, R:0.0067, T:0.4494(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1063 (C:5.6998, R:0.0067, T:0.4371(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1069 (C:5.6996, R:0.0067, T:0.4360(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1253 (C:5.7773, R:0.0068, T:0.4500(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1018 (C:5.7049, R:0.0067, T:0.4330(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1094 (C:5.7636, R:0.0067, T:0.4392(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1225 (C:5.7633, R:0.0067, T:0.4539(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1099 (C:5.7264, R:0.0067, T:0.4406(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0982 (C:5.7611, R:0.0067, T:0.4296(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1228 (C:5.7374, R:0.0067, T:0.4534(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1340 (C:5.7036, R:0.0068, T:0.4567(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0915 (C:5.7429, R:0.0067, T:0.4208(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4469

ğŸ“Š EPOCH 71 TRAINING SUMMARY:
  Total Loss: 1.1182
  Contrastive: 5.7490
  Reconstruction: 0.0067
  Topological: 0.4469 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.9591
  Contrastive: 5.7418
  Reconstruction: 0.0058
  Topological: 1.3760 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 71/300 COMPLETE (39.4s)
Train Loss: 1.1182 (C:5.7490, R:0.0067, T:0.4469)
Val Loss:   1.9591 (C:5.7418, R:0.0058, T:1.3760)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 72 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1238 (C:5.7398, R:0.0067, T:0.4507(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1168 (C:5.7506, R:0.0067, T:0.4458(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1126 (C:5.7972, R:0.0067, T:0.4430(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1413 (C:5.7520, R:0.0067, T:0.4669(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1332 (C:5.7884, R:0.0067, T:0.4598(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0754 (C:5.7619, R:0.0066, T:0.4109(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1364 (C:5.7615, R:0.0067, T:0.4694(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1076 (C:5.7612, R:0.0067, T:0.4349(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1210 (C:5.7315, R:0.0067, T:0.4483(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0794 (C:5.7440, R:0.0067, T:0.4097(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0918 (C:5.7313, R:0.0067, T:0.4246(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1470 (C:5.7050, R:0.0068, T:0.4715(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1148 (C:5.7810, R:0.0067, T:0.4419(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1241 (C:5.7567, R:0.0067, T:0.4516(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1058 (C:5.7192, R:0.0067, T:0.4368(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1385 (C:5.7495, R:0.0068, T:0.4626(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1288 (C:5.7580, R:0.0068, T:0.4533(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1128 (C:5.7225, R:0.0067, T:0.4406(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1140 (C:5.7322, R:0.0067, T:0.4443(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1130 (C:5.7397, R:0.0067, T:0.4455(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1254 (C:5.7272, R:0.0067, T:0.4579(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1098 (C:5.7952, R:0.0067, T:0.4378(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 72 TRAINING SUMMARY:
  Total Loss: 1.1183
  Contrastive: 5.7481
  Reconstruction: 0.0067
  Topological: 0.4470 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.0220
  Contrastive: 5.7322
  Reconstruction: 0.0058
  Topological: 1.4379 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 72/300 COMPLETE (38.6s)
Train Loss: 1.1183 (C:5.7481, R:0.0067, T:0.4470)
Val Loss:   2.0220 (C:5.7322, R:0.0058, T:1.4379)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 73 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1101 (C:5.7356, R:0.0066, T:0.4454(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1110 (C:5.7458, R:0.0067, T:0.4408(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1027 (C:5.7399, R:0.0067, T:0.4294(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0918 (C:5.7335, R:0.0068, T:0.4153(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1158 (C:5.7762, R:0.0068, T:0.4408(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1299 (C:5.7359, R:0.0067, T:0.4593(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.0875 (C:5.7172, R:0.0066, T:0.4233(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1153 (C:5.7277, R:0.0067, T:0.4464(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1218 (C:5.7414, R:0.0067, T:0.4532(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0853 (C:5.7474, R:0.0067, T:0.4138(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1267 (C:5.7602, R:0.0067, T:0.4552(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1262 (C:5.7256, R:0.0067, T:0.4556(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1289 (C:5.7203, R:0.0067, T:0.4588(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1293 (C:5.7149, R:0.0067, T:0.4585(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0998 (C:5.7692, R:0.0067, T:0.4291(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1216 (C:5.7733, R:0.0067, T:0.4496(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1316 (C:5.7777, R:0.0067, T:0.4580(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1136 (C:5.7538, R:0.0067, T:0.4458(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1068 (C:5.7465, R:0.0066, T:0.4420(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1151 (C:5.7665, R:0.0067, T:0.4424(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.0982 (C:5.7528, R:0.0067, T:0.4302(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1109 (C:5.7430, R:0.0067, T:0.4440(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4459

ğŸ“Š EPOCH 73 TRAINING SUMMARY:
  Total Loss: 1.1167
  Contrastive: 5.7482
  Reconstruction: 0.0067
  Topological: 0.4459 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.9011
  Contrastive: 5.7800
  Reconstruction: 0.0058
  Topological: 1.3211 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 73/300 COMPLETE (39.1s)
Train Loss: 1.1167 (C:5.7482, R:0.0067, T:0.4459)
Val Loss:   1.9011 (C:5.7800, R:0.0058, T:1.3211)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 74 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1146 (C:5.7849, R:0.0067, T:0.4467(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1234 (C:5.7252, R:0.0067, T:0.4540(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1106 (C:5.7250, R:0.0067, T:0.4410(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1393 (C:5.7584, R:0.0067, T:0.4665(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1191 (C:5.7410, R:0.0067, T:0.4523(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1271 (C:5.7726, R:0.0067, T:0.4533(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1177 (C:5.7140, R:0.0067, T:0.4447(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1109 (C:5.7568, R:0.0067, T:0.4403(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.0859 (C:5.7335, R:0.0067, T:0.4186(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1432 (C:5.7364, R:0.0067, T:0.4724(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1348 (C:5.7750, R:0.0067, T:0.4606(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1071 (C:5.7863, R:0.0067, T:0.4388(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1293 (C:5.7699, R:0.0067, T:0.4552(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1354 (C:5.7349, R:0.0067, T:0.4606(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1128 (C:5.7255, R:0.0066, T:0.4492(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0856 (C:5.7954, R:0.0067, T:0.4184(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1369 (C:5.7421, R:0.0067, T:0.4648(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1000 (C:5.7170, R:0.0067, T:0.4332(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1296 (C:5.7788, R:0.0067, T:0.4599(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1366 (C:5.7223, R:0.0067, T:0.4696(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1104 (C:5.7575, R:0.0067, T:0.4376(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1049 (C:5.7291, R:0.0067, T:0.4336(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4442

ğŸ“Š EPOCH 74 TRAINING SUMMARY:
  Total Loss: 1.1147
  Contrastive: 5.7484
  Reconstruction: 0.0067
  Topological: 0.4442 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.9993
  Contrastive: 5.7393
  Reconstruction: 0.0058
  Topological: 1.4152 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 74/300 COMPLETE (39.5s)
Train Loss: 1.1147 (C:5.7484, R:0.0067, T:0.4442)
Val Loss:   1.9993 (C:5.7393, R:0.0058, T:1.4152)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 75 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1078 (C:5.7599, R:0.0067, T:0.4340(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1011 (C:5.7697, R:0.0067, T:0.4306(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1152 (C:5.7692, R:0.0067, T:0.4485(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1096 (C:5.7535, R:0.0066, T:0.4466(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1071 (C:5.7937, R:0.0067, T:0.4371(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1273 (C:5.7736, R:0.0068, T:0.4504(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1115 (C:5.7140, R:0.0067, T:0.4398(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1107 (C:5.7729, R:0.0067, T:0.4398(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1327 (C:5.7401, R:0.0067, T:0.4597(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1218 (C:5.7483, R:0.0068, T:0.4463(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1018 (C:5.7321, R:0.0067, T:0.4303(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.0995 (C:5.7434, R:0.0066, T:0.4349(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.0886 (C:5.7402, R:0.0067, T:0.4230(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1122 (C:5.7494, R:0.0067, T:0.4426(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0953 (C:5.7608, R:0.0067, T:0.4268(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0918 (C:5.7430, R:0.0067, T:0.4208(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1285 (C:5.7520, R:0.0067, T:0.4589(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0742 (C:5.7338, R:0.0067, T:0.4040(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1200 (C:5.7658, R:0.0067, T:0.4480(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1083 (C:5.7416, R:0.0066, T:0.4457(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1333 (C:5.7269, R:0.0067, T:0.4607(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0966 (C:5.7534, R:0.0067, T:0.4279(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4430

ğŸ“Š EPOCH 75 TRAINING SUMMARY:
  Total Loss: 1.1131
  Contrastive: 5.7498
  Reconstruction: 0.0067
  Topological: 0.4430 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.9885
  Contrastive: 5.7476
  Reconstruction: 0.0058
  Topological: 1.4060 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 75/300 COMPLETE (39.6s)
Train Loss: 1.1131 (C:5.7498, R:0.0067, T:0.4430)
Val Loss:   1.9885 (C:5.7476, R:0.0058, T:1.4060)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 76 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1132 (C:5.7612, R:0.0067, T:0.4437(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1328 (C:5.7202, R:0.0067, T:0.4644(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1044 (C:5.7473, R:0.0067, T:0.4380(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1203 (C:5.7826, R:0.0067, T:0.4508(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1105 (C:5.7779, R:0.0066, T:0.4483(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1367 (C:5.7438, R:0.0068, T:0.4601(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.0983 (C:5.7089, R:0.0067, T:0.4297(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1080 (C:5.7652, R:0.0067, T:0.4371(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1063 (C:5.7362, R:0.0067, T:0.4366(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1220 (C:5.7310, R:0.0067, T:0.4495(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1156 (C:5.7628, R:0.0067, T:0.4454(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1242 (C:5.7832, R:0.0067, T:0.4535(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1267 (C:5.7556, R:0.0067, T:0.4563(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1231 (C:5.7504, R:0.0067, T:0.4522(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1452 (C:5.6925, R:0.0067, T:0.4709(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1343 (C:5.7609, R:0.0067, T:0.4615(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1418 (C:5.7711, R:0.0068, T:0.4650(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1110 (C:5.7650, R:0.0067, T:0.4377(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0928 (C:5.7258, R:0.0067, T:0.4271(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0897 (C:5.7399, R:0.0067, T:0.4188(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1042 (C:5.7582, R:0.0067, T:0.4368(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1198 (C:5.7473, R:0.0067, T:0.4484(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 76 TRAINING SUMMARY:
  Total Loss: 1.1136
  Contrastive: 5.7505
  Reconstruction: 0.0067
  Topological: 0.4436 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.0451
  Contrastive: 5.7158
  Reconstruction: 0.0058
  Topological: 1.4616 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 76/300 COMPLETE (39.1s)
Train Loss: 1.1136 (C:5.7505, R:0.0067, T:0.4436)
Val Loss:   2.0451 (C:5.7158, R:0.0058, T:1.4616)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 77 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1105 (C:5.7387, R:0.0067, T:0.4400(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1111 (C:5.7255, R:0.0067, T:0.4428(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1106 (C:5.7616, R:0.0067, T:0.4395(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1227 (C:5.7405, R:0.0067, T:0.4576(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1014 (C:5.7335, R:0.0067, T:0.4354(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1091 (C:5.7570, R:0.0067, T:0.4385(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1023 (C:5.7741, R:0.0067, T:0.4327(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1095 (C:5.7430, R:0.0067, T:0.4413(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1010 (C:5.7267, R:0.0067, T:0.4352(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1062 (C:5.7123, R:0.0066, T:0.4421(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0887 (C:5.7716, R:0.0067, T:0.4177(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1299 (C:5.7673, R:0.0067, T:0.4570(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1124 (C:5.7662, R:0.0067, T:0.4389(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1406 (C:5.7410, R:0.0067, T:0.4667(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1456 (C:5.7467, R:0.0067, T:0.4731(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0792 (C:5.7511, R:0.0067, T:0.4130(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1387 (C:5.7092, R:0.0067, T:0.4661(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1260 (C:5.7517, R:0.0067, T:0.4541(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1228 (C:5.7625, R:0.0067, T:0.4527(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1099 (C:5.7014, R:0.0067, T:0.4442(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1061 (C:5.7583, R:0.0067, T:0.4350(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1318 (C:5.7342, R:0.0067, T:0.4662(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4427

ğŸ“Š EPOCH 77 TRAINING SUMMARY:
  Total Loss: 1.1126
  Contrastive: 5.7491
  Reconstruction: 0.0067
  Topological: 0.4427 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.0247
  Contrastive: 5.7215
  Reconstruction: 0.0058
  Topological: 1.4431 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 77/300 COMPLETE (40.6s)
Train Loss: 1.1126 (C:5.7491, R:0.0067, T:0.4427)
Val Loss:   2.0247 (C:5.7215, R:0.0058, T:1.4431)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 78 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.0984 (C:5.7405, R:0.0067, T:0.4308(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1186 (C:5.7470, R:0.0067, T:0.4479(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0993 (C:5.7718, R:0.0067, T:0.4273(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0942 (C:5.7505, R:0.0067, T:0.4238(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1049 (C:5.7257, R:0.0066, T:0.4415(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1067 (C:5.7294, R:0.0067, T:0.4387(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.0968 (C:5.7050, R:0.0066, T:0.4328(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1050 (C:5.7561, R:0.0067, T:0.4356(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1024 (C:5.7663, R:0.0067, T:0.4313(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1048 (C:5.7177, R:0.0067, T:0.4379(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0913 (C:5.7369, R:0.0067, T:0.4212(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1135 (C:5.7218, R:0.0067, T:0.4466(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1411 (C:5.7400, R:0.0067, T:0.4690(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.0907 (C:5.7324, R:0.0067, T:0.4235(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1139 (C:5.7926, R:0.0068, T:0.4376(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0979 (C:5.7505, R:0.0067, T:0.4307(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1014 (C:5.7498, R:0.0067, T:0.4304(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0951 (C:5.7667, R:0.0067, T:0.4243(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1022 (C:5.7441, R:0.0067, T:0.4319(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0890 (C:5.7263, R:0.0067, T:0.4235(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1423 (C:5.7484, R:0.0067, T:0.4734(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1013 (C:5.7510, R:0.0067, T:0.4336(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4410

ğŸ“Š EPOCH 78 TRAINING SUMMARY:
  Total Loss: 1.1106
  Contrastive: 5.7491
  Reconstruction: 0.0067
  Topological: 0.4410 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.8845
  Contrastive: 5.7681
  Reconstruction: 0.0058
  Topological: 1.3049 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 78/300 COMPLETE (39.4s)
Train Loss: 1.1106 (C:5.7491, R:0.0067, T:0.4410)
Val Loss:   1.8845 (C:5.7681, R:0.0058, T:1.3049)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 79 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1020 (C:5.7836, R:0.0067, T:0.4279(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0886 (C:5.7526, R:0.0067, T:0.4183(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1092 (C:5.7359, R:0.0067, T:0.4400(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1188 (C:5.7337, R:0.0067, T:0.4478(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1350 (C:5.7144, R:0.0067, T:0.4607(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1275 (C:5.7237, R:0.0067, T:0.4588(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1246 (C:5.7755, R:0.0067, T:0.4540(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1140 (C:5.7678, R:0.0067, T:0.4466(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1105 (C:5.7452, R:0.0067, T:0.4400(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0988 (C:5.7394, R:0.0067, T:0.4294(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1283 (C:5.7305, R:0.0067, T:0.4607(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1080 (C:5.7484, R:0.0067, T:0.4422(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1225 (C:5.7799, R:0.0067, T:0.4528(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1089 (C:5.7481, R:0.0067, T:0.4346(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0982 (C:5.7374, R:0.0066, T:0.4390(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1447 (C:5.7417, R:0.0067, T:0.4739(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1478 (C:5.7320, R:0.0067, T:0.4794(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0902 (C:5.7522, R:0.0067, T:0.4214(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0885 (C:5.7548, R:0.0067, T:0.4180(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1072 (C:5.7695, R:0.0067, T:0.4390(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1080 (C:5.7164, R:0.0067, T:0.4375(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0848 (C:5.7601, R:0.0067, T:0.4162(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4409

ğŸ“Š EPOCH 79 TRAINING SUMMARY:
  Total Loss: 1.1102
  Contrastive: 5.7493
  Reconstruction: 0.0067
  Topological: 0.4409 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.9247
  Contrastive: 5.7895
  Reconstruction: 0.0058
  Topological: 1.3458 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 79/300 COMPLETE (39.8s)
Train Loss: 1.1102 (C:5.7493, R:0.0067, T:0.4409)
Val Loss:   1.9247 (C:5.7895, R:0.0058, T:1.3458)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 80 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.0885 (C:5.8013, R:0.0067, T:0.4220(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1051 (C:5.7533, R:0.0067, T:0.4330(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1164 (C:5.7274, R:0.0067, T:0.4441(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0986 (C:5.7489, R:0.0066, T:0.4358(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0975 (C:5.7664, R:0.0067, T:0.4313(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1297 (C:5.7841, R:0.0067, T:0.4568(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1054 (C:5.7736, R:0.0067, T:0.4368(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.0984 (C:5.7582, R:0.0067, T:0.4295(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1014 (C:5.7396, R:0.0067, T:0.4363(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1300 (C:5.7418, R:0.0067, T:0.4601(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1110 (C:5.7581, R:0.0067, T:0.4415(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1129 (C:5.7324, R:0.0067, T:0.4447(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1035 (C:5.7960, R:0.0067, T:0.4364(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1203 (C:5.7677, R:0.0067, T:0.4496(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1080 (C:5.7479, R:0.0067, T:0.4365(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0922 (C:5.7368, R:0.0067, T:0.4259(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1003 (C:5.7147, R:0.0067, T:0.4350(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0910 (C:5.7828, R:0.0067, T:0.4247(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1315 (C:5.7566, R:0.0067, T:0.4596(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1020 (C:5.7676, R:0.0067, T:0.4302(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1145 (C:5.7406, R:0.0067, T:0.4489(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1051 (C:5.7213, R:0.0067, T:0.4399(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4403

ğŸ“Š EPOCH 80 TRAINING SUMMARY:
  Total Loss: 1.1091
  Contrastive: 5.7511
  Reconstruction: 0.0067
  Topological: 0.4403 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.0275
  Contrastive: 5.7037
  Reconstruction: 0.0058
  Topological: 1.4458 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 80/300 COMPLETE (40.0s)
Train Loss: 1.1091 (C:5.7511, R:0.0067, T:0.4403)
Val Loss:   2.0275 (C:5.7037, R:0.0058, T:1.4458)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 81 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1225 (C:5.7321, R:0.0067, T:0.4495(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1331 (C:5.7426, R:0.0067, T:0.4653(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1169 (C:5.7852, R:0.0067, T:0.4447(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0985 (C:5.7583, R:0.0067, T:0.4269(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1136 (C:5.7236, R:0.0067, T:0.4431(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0958 (C:5.7464, R:0.0067, T:0.4258(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1163 (C:5.7540, R:0.0067, T:0.4473(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1040 (C:5.7296, R:0.0068, T:0.4269(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1105 (C:5.7592, R:0.0067, T:0.4450(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1084 (C:5.7720, R:0.0067, T:0.4355(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1116 (C:5.6912, R:0.0066, T:0.4488(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1095 (C:5.7389, R:0.0067, T:0.4407(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.0993 (C:5.7745, R:0.0067, T:0.4327(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1024 (C:5.7477, R:0.0066, T:0.4376(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1144 (C:5.7122, R:0.0066, T:0.4507(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1267 (C:5.7667, R:0.0067, T:0.4582(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1364 (C:5.7365, R:0.0067, T:0.4627(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1091 (C:5.7539, R:0.0067, T:0.4372(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0923 (C:5.7360, R:0.0067, T:0.4206(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0929 (C:5.7330, R:0.0067, T:0.4224(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1120 (C:5.7273, R:0.0067, T:0.4437(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0928 (C:5.7590, R:0.0067, T:0.4246(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4399

ğŸ“Š EPOCH 81 TRAINING SUMMARY:
  Total Loss: 1.1086
  Contrastive: 5.7497
  Reconstruction: 0.0067
  Topological: 0.4399 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.0496
  Contrastive: 5.6863
  Reconstruction: 0.0058
  Topological: 1.4673 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 81/300 COMPLETE (39.2s)
Train Loss: 1.1086 (C:5.7497, R:0.0067, T:0.4399)
Val Loss:   2.0496 (C:5.6863, R:0.0058, T:1.4673)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 82 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1191 (C:5.7229, R:0.0067, T:0.4487(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1110 (C:5.7388, R:0.0067, T:0.4429(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1089 (C:5.7218, R:0.0067, T:0.4419(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0935 (C:5.7258, R:0.0067, T:0.4275(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1215 (C:5.7338, R:0.0067, T:0.4527(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1240 (C:5.7277, R:0.0067, T:0.4559(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1120 (C:5.7443, R:0.0067, T:0.4423(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.0779 (C:5.7099, R:0.0067, T:0.4098(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1071 (C:5.7428, R:0.0067, T:0.4415(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1084 (C:5.7373, R:0.0067, T:0.4408(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0991 (C:5.7530, R:0.0067, T:0.4315(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.0929 (C:5.7641, R:0.0067, T:0.4224(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1431 (C:5.7542, R:0.0067, T:0.4725(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1151 (C:5.7689, R:0.0067, T:0.4411(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1155 (C:5.7518, R:0.0067, T:0.4457(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1052 (C:5.7520, R:0.0067, T:0.4322(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.0995 (C:5.7372, R:0.0066, T:0.4347(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1015 (C:5.7922, R:0.0067, T:0.4313(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1038 (C:5.7539, R:0.0066, T:0.4399(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1019 (C:5.7646, R:0.0067, T:0.4314(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1220 (C:5.7722, R:0.0067, T:0.4503(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0939 (C:5.7548, R:0.0067, T:0.4285(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4385

ğŸ“Š EPOCH 82 TRAINING SUMMARY:
  Total Loss: 1.1067
  Contrastive: 5.7513
  Reconstruction: 0.0067
  Topological: 0.4385 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.8888
  Contrastive: 5.7865
  Reconstruction: 0.0058
  Topological: 1.3086 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 82/300 COMPLETE (39.6s)
Train Loss: 1.1067 (C:5.7513, R:0.0067, T:0.4385)
Val Loss:   1.8888 (C:5.7865, R:0.0058, T:1.3086)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 83 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1132 (C:5.8017, R:0.0067, T:0.4423(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0935 (C:5.7570, R:0.0066, T:0.4328(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1142 (C:5.7619, R:0.0068, T:0.4391(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1133 (C:5.7577, R:0.0067, T:0.4470(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0939 (C:5.6950, R:0.0066, T:0.4293(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1250 (C:5.7090, R:0.0067, T:0.4566(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.0850 (C:5.7635, R:0.0067, T:0.4192(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1429 (C:5.7294, R:0.0067, T:0.4723(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1048 (C:5.7436, R:0.0067, T:0.4392(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1150 (C:5.7865, R:0.0067, T:0.4449(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1286 (C:5.7503, R:0.0068, T:0.4500(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.0859 (C:5.7667, R:0.0066, T:0.4214(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1117 (C:5.7286, R:0.0066, T:0.4473(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1122 (C:5.7643, R:0.0067, T:0.4404(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1034 (C:5.7580, R:0.0067, T:0.4364(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1047 (C:5.7875, R:0.0067, T:0.4344(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1080 (C:5.7664, R:0.0067, T:0.4364(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1160 (C:5.7573, R:0.0067, T:0.4460(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0773 (C:5.7325, R:0.0066, T:0.4167(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1293 (C:5.7644, R:0.0067, T:0.4635(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1318 (C:5.7720, R:0.0067, T:0.4584(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1345 (C:5.7656, R:0.0067, T:0.4641(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 83 TRAINING SUMMARY:
  Total Loss: 1.1072
  Contrastive: 5.7505
  Reconstruction: 0.0067
  Topological: 0.4390 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.9030
  Contrastive: 5.7539
  Reconstruction: 0.0058
  Topological: 1.3225 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 83/300 COMPLETE (39.5s)
Train Loss: 1.1072 (C:5.7505, R:0.0067, T:0.4390)
Val Loss:   1.9030 (C:5.7539, R:0.0058, T:1.3225)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 84 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.0933 (C:5.7741, R:0.0067, T:0.4260(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1104 (C:5.7149, R:0.0067, T:0.4435(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0815 (C:5.7518, R:0.0066, T:0.4167(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0821 (C:5.7380, R:0.0067, T:0.4103(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0978 (C:5.7558, R:0.0067, T:0.4301(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1121 (C:5.7164, R:0.0067, T:0.4414(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1205 (C:5.7030, R:0.0067, T:0.4511(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1210 (C:5.7112, R:0.0067, T:0.4510(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.0990 (C:5.7472, R:0.0067, T:0.4285(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1145 (C:5.6963, R:0.0067, T:0.4465(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0885 (C:5.7498, R:0.0066, T:0.4277(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1375 (C:5.7665, R:0.0067, T:0.4659(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1178 (C:5.7548, R:0.0067, T:0.4522(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.0834 (C:5.7471, R:0.0067, T:0.4116(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1242 (C:5.7857, R:0.0067, T:0.4527(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0921 (C:5.7712, R:0.0067, T:0.4244(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1002 (C:5.7483, R:0.0066, T:0.4364(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1175 (C:5.7665, R:0.0067, T:0.4459(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1211 (C:5.7607, R:0.0067, T:0.4497(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0934 (C:5.7319, R:0.0067, T:0.4235(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1133 (C:5.7378, R:0.0067, T:0.4444(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1261 (C:5.7711, R:0.0067, T:0.4593(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4382

ğŸ“Š EPOCH 84 TRAINING SUMMARY:
  Total Loss: 1.1061
  Contrastive: 5.7501
  Reconstruction: 0.0067
  Topological: 0.4382 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.9013
  Contrastive: 5.7585
  Reconstruction: 0.0058
  Topological: 1.3240 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 84/300 COMPLETE (39.4s)
Train Loss: 1.1061 (C:5.7501, R:0.0067, T:0.4382)
Val Loss:   1.9013 (C:5.7585, R:0.0058, T:1.3240)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 85 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1218 (C:5.7775, R:0.0067, T:0.4549(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1239 (C:5.7631, R:0.0067, T:0.4522(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0914 (C:5.7369, R:0.0066, T:0.4274(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1118 (C:5.7518, R:0.0067, T:0.4444(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1021 (C:5.7344, R:0.0067, T:0.4360(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0925 (C:5.7621, R:0.0067, T:0.4235(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1203 (C:5.7594, R:0.0067, T:0.4487(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.0997 (C:5.7705, R:0.0067, T:0.4286(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1331 (C:5.7474, R:0.0067, T:0.4623(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1177 (C:5.7426, R:0.0067, T:0.4502(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1139 (C:5.7449, R:0.0067, T:0.4428(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1087 (C:5.7264, R:0.0067, T:0.4408(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1321 (C:5.7975, R:0.0067, T:0.4611(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1148 (C:5.7785, R:0.0067, T:0.4475(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0821 (C:5.7256, R:0.0066, T:0.4189(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1015 (C:5.7213, R:0.0067, T:0.4351(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1104 (C:5.7244, R:0.0067, T:0.4364(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1100 (C:5.7675, R:0.0067, T:0.4438(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1084 (C:5.7365, R:0.0067, T:0.4428(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1139 (C:5.7636, R:0.0067, T:0.4466(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1212 (C:5.7431, R:0.0067, T:0.4522(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0844 (C:5.7295, R:0.0067, T:0.4157(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4374

ğŸ“Š EPOCH 85 TRAINING SUMMARY:
  Total Loss: 1.1052
  Contrastive: 5.7497
  Reconstruction: 0.0067
  Topological: 0.4374 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.9161
  Contrastive: 5.7439
  Reconstruction: 0.0058
  Topological: 1.3362 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 85/300 COMPLETE (40.6s)
Train Loss: 1.1052 (C:5.7497, R:0.0067, T:0.4374)
Val Loss:   1.9161 (C:5.7439, R:0.0058, T:1.3362)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 86 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.0942 (C:5.7649, R:0.0067, T:0.4277(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0958 (C:5.8106, R:0.0067, T:0.4292(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0881 (C:5.7510, R:0.0067, T:0.4186(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0979 (C:5.7502, R:0.0067, T:0.4324(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1110 (C:5.7831, R:0.0067, T:0.4399(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1155 (C:5.7308, R:0.0067, T:0.4495(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1283 (C:5.7664, R:0.0067, T:0.4597(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1185 (C:5.7078, R:0.0067, T:0.4472(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.0989 (C:5.7447, R:0.0067, T:0.4322(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1058 (C:5.7476, R:0.0067, T:0.4396(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0805 (C:5.7401, R:0.0067, T:0.4148(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.0900 (C:5.7343, R:0.0067, T:0.4231(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.0950 (C:5.7545, R:0.0067, T:0.4248(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1064 (C:5.7094, R:0.0067, T:0.4362(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1075 (C:5.7446, R:0.0067, T:0.4368(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1093 (C:5.7565, R:0.0067, T:0.4411(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.0985 (C:5.7535, R:0.0067, T:0.4330(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0985 (C:5.7440, R:0.0067, T:0.4319(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0885 (C:5.7478, R:0.0067, T:0.4195(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0876 (C:5.7753, R:0.0067, T:0.4220(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.0929 (C:5.7425, R:0.0066, T:0.4288(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1028 (C:5.7510, R:0.0066, T:0.4394(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4366

ğŸ“Š EPOCH 86 TRAINING SUMMARY:
  Total Loss: 1.1041
  Contrastive: 5.7510
  Reconstruction: 0.0067
  Topological: 0.4366 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.9456
  Contrastive: 5.7572
  Reconstruction: 0.0058
  Topological: 1.3671 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 86/300 COMPLETE (39.6s)
Train Loss: 1.1041 (C:5.7510, R:0.0067, T:0.4366)
Val Loss:   1.9456 (C:5.7572, R:0.0058, T:1.3671)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 87 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.0956 (C:5.7649, R:0.0067, T:0.4255(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1165 (C:5.7339, R:0.0067, T:0.4498(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0980 (C:5.7484, R:0.0066, T:0.4355(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0984 (C:5.7817, R:0.0066, T:0.4343(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1238 (C:5.7817, R:0.0067, T:0.4499(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0983 (C:5.7499, R:0.0066, T:0.4393(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1020 (C:5.7423, R:0.0067, T:0.4351(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1283 (C:5.7602, R:0.0067, T:0.4563(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.0996 (C:5.7541, R:0.0066, T:0.4367(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0964 (C:5.7960, R:0.0067, T:0.4300(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1247 (C:5.7507, R:0.0067, T:0.4534(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1123 (C:5.7596, R:0.0067, T:0.4396(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1122 (C:5.7591, R:0.0067, T:0.4426(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1286 (C:5.7640, R:0.0067, T:0.4587(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1103 (C:5.7528, R:0.0067, T:0.4390(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0955 (C:5.7697, R:0.0066, T:0.4375(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1025 (C:5.7337, R:0.0066, T:0.4381(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1083 (C:5.7451, R:0.0067, T:0.4412(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1125 (C:5.7855, R:0.0067, T:0.4438(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0827 (C:5.7578, R:0.0067, T:0.4156(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1070 (C:5.7530, R:0.0067, T:0.4408(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1222 (C:5.7705, R:0.0066, T:0.4576(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 87 TRAINING SUMMARY:
  Total Loss: 1.1041
  Contrastive: 5.7520
  Reconstruction: 0.0067
  Topological: 0.4367 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.9161
  Contrastive: 5.7431
  Reconstruction: 0.0058
  Topological: 1.3382 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 87/300 COMPLETE (39.7s)
Train Loss: 1.1041 (C:5.7520, R:0.0067, T:0.4367)
Val Loss:   1.9161 (C:5.7431, R:0.0058, T:1.3382)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 88 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.0995 (C:5.7509, R:0.0067, T:0.4344(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0918 (C:5.7475, R:0.0067, T:0.4173(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1121 (C:5.7395, R:0.0067, T:0.4426(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1042 (C:5.7256, R:0.0067, T:0.4377(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1005 (C:5.7176, R:0.0067, T:0.4318(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0672 (C:5.7544, R:0.0066, T:0.4026(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1013 (C:5.7685, R:0.0067, T:0.4343(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1044 (C:5.7933, R:0.0067, T:0.4380(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1042 (C:5.7803, R:0.0067, T:0.4391(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0998 (C:5.6945, R:0.0067, T:0.4319(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1271 (C:5.7472, R:0.0067, T:0.4591(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.0976 (C:5.7299, R:0.0067, T:0.4282(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1132 (C:5.7445, R:0.0067, T:0.4479(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1055 (C:5.7511, R:0.0066, T:0.4433(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1064 (C:5.7595, R:0.0067, T:0.4411(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1199 (C:5.7696, R:0.0067, T:0.4544(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.0950 (C:5.7909, R:0.0067, T:0.4289(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0765 (C:5.7490, R:0.0067, T:0.4093(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0722 (C:5.7343, R:0.0066, T:0.4106(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1145 (C:5.7782, R:0.0067, T:0.4433(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1038 (C:5.7398, R:0.0067, T:0.4339(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0904 (C:5.7274, R:0.0067, T:0.4244(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 88 TRAINING SUMMARY:
  Total Loss: 1.1042
  Contrastive: 5.7485
  Reconstruction: 0.0067
  Topological: 0.4368 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.9824
  Contrastive: 5.7179
  Reconstruction: 0.0058
  Topological: 1.4015 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 88/300 COMPLETE (39.0s)
Train Loss: 1.1042 (C:5.7485, R:0.0067, T:0.4368)
Val Loss:   1.9824 (C:5.7179, R:0.0058, T:1.4015)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 89 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1008 (C:5.7381, R:0.0066, T:0.4368(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0884 (C:5.7845, R:0.0067, T:0.4198(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1114 (C:5.7450, R:0.0067, T:0.4445(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1109 (C:5.7362, R:0.0067, T:0.4397(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0852 (C:5.6940, R:0.0066, T:0.4227(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0914 (C:5.7510, R:0.0067, T:0.4249(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.0933 (C:5.7638, R:0.0067, T:0.4269(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1339 (C:5.7402, R:0.0067, T:0.4657(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1008 (C:5.7179, R:0.0066, T:0.4362(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0938 (C:5.7473, R:0.0067, T:0.4267(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1070 (C:5.7450, R:0.0067, T:0.4416(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.0831 (C:5.7340, R:0.0067, T:0.4161(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.0689 (C:5.7603, R:0.0066, T:0.4067(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.0946 (C:5.7737, R:0.0066, T:0.4316(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1085 (C:5.7559, R:0.0067, T:0.4406(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0843 (C:5.7479, R:0.0066, T:0.4222(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1074 (C:5.7047, R:0.0068, T:0.4321(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0858 (C:5.7577, R:0.0066, T:0.4214(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0887 (C:5.7436, R:0.0067, T:0.4222(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0951 (C:5.7560, R:0.0067, T:0.4299(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.0785 (C:5.7728, R:0.0066, T:0.4152(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0899 (C:5.7241, R:0.0067, T:0.4239(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4360

ğŸ“Š EPOCH 89 TRAINING SUMMARY:
  Total Loss: 1.1032
  Contrastive: 5.7496
  Reconstruction: 0.0067
  Topological: 0.4360 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.9387
  Contrastive: 5.7287
  Reconstruction: 0.0058
  Topological: 1.3568 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 89/300 COMPLETE (39.7s)
Train Loss: 1.1032 (C:5.7496, R:0.0067, T:0.4360)
Val Loss:   1.9387 (C:5.7287, R:0.0058, T:1.3568)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 90 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1092 (C:5.7604, R:0.0067, T:0.4427(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1101 (C:5.7483, R:0.0067, T:0.4412(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0835 (C:5.7394, R:0.0066, T:0.4209(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1180 (C:5.7735, R:0.0067, T:0.4473(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0929 (C:5.7362, R:0.0066, T:0.4286(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0957 (C:5.7447, R:0.0067, T:0.4247(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.0802 (C:5.7534, R:0.0067, T:0.4142(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.0928 (C:5.7419, R:0.0067, T:0.4271(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1078 (C:5.7741, R:0.0067, T:0.4374(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0966 (C:5.7589, R:0.0067, T:0.4294(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1139 (C:5.7299, R:0.0067, T:0.4414(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1144 (C:5.7696, R:0.0067, T:0.4452(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1096 (C:5.7971, R:0.0067, T:0.4388(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1234 (C:5.7620, R:0.0067, T:0.4548(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0941 (C:5.7455, R:0.0067, T:0.4276(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1061 (C:5.7413, R:0.0066, T:0.4426(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1045 (C:5.7595, R:0.0067, T:0.4349(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1006 (C:5.7522, R:0.0067, T:0.4325(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1135 (C:5.7973, R:0.0066, T:0.4494(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0966 (C:5.7527, R:0.0067, T:0.4270(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.0748 (C:5.7478, R:0.0066, T:0.4113(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0901 (C:5.7580, R:0.0067, T:0.4233(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 90 TRAINING SUMMARY:
  Total Loss: 1.1034
  Contrastive: 5.7486
  Reconstruction: 0.0067
  Topological: 0.4363 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.9162
  Contrastive: 5.7467
  Reconstruction: 0.0058
  Topological: 1.3365 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 90/300 COMPLETE (38.9s)
Train Loss: 1.1034 (C:5.7486, R:0.0067, T:0.4363)
Val Loss:   1.9162 (C:5.7467, R:0.0058, T:1.3365)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 91 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1219 (C:5.7565, R:0.0067, T:0.4562(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0899 (C:5.7461, R:0.0067, T:0.4243(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0930 (C:5.7664, R:0.0066, T:0.4301(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1120 (C:5.7511, R:0.0067, T:0.4427(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0823 (C:5.7170, R:0.0066, T:0.4191(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1019 (C:5.7577, R:0.0067, T:0.4337(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1075 (C:5.7482, R:0.0067, T:0.4387(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.0954 (C:5.7744, R:0.0067, T:0.4296(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1103 (C:5.7336, R:0.0066, T:0.4464(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1275 (C:5.7387, R:0.0067, T:0.4599(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1065 (C:5.7547, R:0.0067, T:0.4407(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.0825 (C:5.7735, R:0.0066, T:0.4187(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1212 (C:5.7532, R:0.0067, T:0.4496(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.0977 (C:5.7476, R:0.0067, T:0.4308(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1118 (C:5.7607, R:0.0067, T:0.4427(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0980 (C:5.7263, R:0.0067, T:0.4325(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.0844 (C:5.7522, R:0.0066, T:0.4227(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0733 (C:5.7110, R:0.0067, T:0.4065(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0852 (C:5.7131, R:0.0066, T:0.4226(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0911 (C:5.7606, R:0.0066, T:0.4266(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1095 (C:5.7675, R:0.0067, T:0.4424(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1127 (C:5.7587, R:0.0066, T:0.4498(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4354

ğŸ“Š EPOCH 91 TRAINING SUMMARY:
  Total Loss: 1.1022
  Contrastive: 5.7505
  Reconstruction: 0.0067
  Topological: 0.4354 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.9439
  Contrastive: 5.7327
  Reconstruction: 0.0058
  Topological: 1.3659 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 91/300 COMPLETE (39.5s)
Train Loss: 1.1022 (C:5.7505, R:0.0067, T:0.4354)
Val Loss:   1.9439 (C:5.7327, R:0.0058, T:1.3659)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 92 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.0953 (C:5.7572, R:0.0067, T:0.4296(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1071 (C:5.7402, R:0.0066, T:0.4448(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1221 (C:5.7455, R:0.0067, T:0.4536(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0998 (C:5.7637, R:0.0067, T:0.4308(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0893 (C:5.7453, R:0.0067, T:0.4206(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0937 (C:5.7788, R:0.0067, T:0.4221(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1034 (C:5.7514, R:0.0066, T:0.4391(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.0883 (C:5.7501, R:0.0067, T:0.4220(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1016 (C:5.7523, R:0.0067, T:0.4344(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1129 (C:5.8304, R:0.0066, T:0.4505(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0848 (C:5.7163, R:0.0066, T:0.4247(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1061 (C:5.7304, R:0.0066, T:0.4415(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1018 (C:5.7704, R:0.0067, T:0.4348(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1238 (C:5.7728, R:0.0067, T:0.4522(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1136 (C:5.7541, R:0.0067, T:0.4447(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1022 (C:5.7485, R:0.0067, T:0.4361(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1037 (C:5.7417, R:0.0067, T:0.4378(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0935 (C:5.7511, R:0.0067, T:0.4271(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0913 (C:5.7230, R:0.0067, T:0.4241(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0887 (C:5.7412, R:0.0066, T:0.4244(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1053 (C:5.7642, R:0.0067, T:0.4359(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1046 (C:5.7279, R:0.0067, T:0.4343(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4347

ğŸ“Š EPOCH 92 TRAINING SUMMARY:
  Total Loss: 1.1013
  Contrastive: 5.7497
  Reconstruction: 0.0067
  Topological: 0.4347 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.0201
  Contrastive: 5.6856
  Reconstruction: 0.0058
  Topological: 1.4403 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 92/300 COMPLETE (40.2s)
Train Loss: 1.1013 (C:5.7497, R:0.0067, T:0.4347)
Val Loss:   2.0201 (C:5.6856, R:0.0058, T:1.4403)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 93 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1081 (C:5.7339, R:0.0067, T:0.4403(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0848 (C:5.7352, R:0.0066, T:0.4230(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1173 (C:5.7629, R:0.0066, T:0.4534(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0974 (C:5.7553, R:0.0066, T:0.4346(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0948 (C:5.7514, R:0.0066, T:0.4307(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0916 (C:5.7533, R:0.0067, T:0.4263(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.0970 (C:5.7664, R:0.0067, T:0.4319(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1039 (C:5.7447, R:0.0066, T:0.4419(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1350 (C:5.7449, R:0.0067, T:0.4678(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1071 (C:5.7442, R:0.0067, T:0.4375(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0836 (C:5.7445, R:0.0067, T:0.4158(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1352 (C:5.7494, R:0.0067, T:0.4661(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1290 (C:5.7345, R:0.0067, T:0.4622(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1024 (C:5.7521, R:0.0067, T:0.4297(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0828 (C:5.7814, R:0.0066, T:0.4185(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0798 (C:5.7157, R:0.0067, T:0.4147(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1086 (C:5.7554, R:0.0067, T:0.4395(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0826 (C:5.7593, R:0.0067, T:0.4111(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1280 (C:5.8101, R:0.0067, T:0.4583(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0737 (C:5.7892, R:0.0066, T:0.4124(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1050 (C:5.7146, R:0.0067, T:0.4365(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1024 (C:5.7611, R:0.0066, T:0.4388(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4345

ğŸ“Š EPOCH 93 TRAINING SUMMARY:
  Total Loss: 1.1009
  Contrastive: 5.7492
  Reconstruction: 0.0067
  Topological: 0.4345 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.8504
  Contrastive: 5.7739
  Reconstruction: 0.0058
  Topological: 1.2742 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 93/300 COMPLETE (39.6s)
Train Loss: 1.1009 (C:5.7492, R:0.0067, T:0.4345)
Val Loss:   1.8504 (C:5.7739, R:0.0058, T:1.2742)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 94 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.0956 (C:5.7863, R:0.0067, T:0.4295(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0913 (C:5.7227, R:0.0067, T:0.4262(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0953 (C:5.7448, R:0.0067, T:0.4275(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1090 (C:5.7407, R:0.0066, T:0.4460(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1253 (C:5.7573, R:0.0066, T:0.4603(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1034 (C:5.7763, R:0.0067, T:0.4364(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1026 (C:5.7512, R:0.0067, T:0.4373(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.0927 (C:5.7441, R:0.0066, T:0.4309(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.0864 (C:5.7395, R:0.0067, T:0.4164(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0913 (C:5.7189, R:0.0067, T:0.4221(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0923 (C:5.7172, R:0.0066, T:0.4293(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1041 (C:5.7685, R:0.0067, T:0.4371(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1065 (C:5.7247, R:0.0066, T:0.4432(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.0976 (C:5.7411, R:0.0066, T:0.4340(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1196 (C:5.7164, R:0.0067, T:0.4493(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1224 (C:5.7231, R:0.0067, T:0.4530(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.0846 (C:5.7178, R:0.0066, T:0.4222(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1020 (C:5.7339, R:0.0066, T:0.4393(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1188 (C:5.7488, R:0.0067, T:0.4480(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1120 (C:5.7767, R:0.0067, T:0.4460(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1197 (C:5.7904, R:0.0067, T:0.4507(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1113 (C:5.7209, R:0.0066, T:0.4494(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4335

ğŸ“Š EPOCH 94 TRAINING SUMMARY:
  Total Loss: 1.0998
  Contrastive: 5.7475
  Reconstruction: 0.0067
  Topological: 0.4335 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.8557
  Contrastive: 5.7540
  Reconstruction: 0.0058
  Topological: 1.2786 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 94/300 COMPLETE (39.5s)
Train Loss: 1.0998 (C:5.7475, R:0.0067, T:0.4335)
Val Loss:   1.8557 (C:5.7540, R:0.0058, T:1.2786)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 95 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1051 (C:5.7808, R:0.0067, T:0.4337(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1154 (C:5.7501, R:0.0067, T:0.4461(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0958 (C:5.7322, R:0.0066, T:0.4322(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0945 (C:5.7272, R:0.0066, T:0.4320(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1094 (C:5.7269, R:0.0067, T:0.4358(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0972 (C:5.7335, R:0.0067, T:0.4318(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.0829 (C:5.7647, R:0.0066, T:0.4191(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1084 (C:5.7297, R:0.0066, T:0.4449(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1046 (C:5.7718, R:0.0067, T:0.4362(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0989 (C:5.7739, R:0.0066, T:0.4345(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0801 (C:5.7471, R:0.0066, T:0.4181(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1053 (C:5.8050, R:0.0066, T:0.4449(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.0986 (C:5.7512, R:0.0066, T:0.4342(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.0997 (C:5.7154, R:0.0066, T:0.4347(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1051 (C:5.7593, R:0.0067, T:0.4335(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0654 (C:5.7214, R:0.0065, T:0.4115(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1021 (C:5.7592, R:0.0066, T:0.4382(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0948 (C:5.7877, R:0.0066, T:0.4318(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0931 (C:5.7316, R:0.0066, T:0.4304(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1114 (C:5.7327, R:0.0067, T:0.4425(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1267 (C:5.7021, R:0.0067, T:0.4595(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0913 (C:5.7417, R:0.0066, T:0.4293(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4328

ğŸ“Š EPOCH 95 TRAINING SUMMARY:
  Total Loss: 1.0988
  Contrastive: 5.7481
  Reconstruction: 0.0067
  Topological: 0.4328 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.8806
  Contrastive: 5.7642
  Reconstruction: 0.0058
  Topological: 1.3044 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 95/300 COMPLETE (40.5s)
Train Loss: 1.0988 (C:5.7481, R:0.0067, T:0.4328)
Val Loss:   1.8806 (C:5.7642, R:0.0058, T:1.3044)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 96 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.0945 (C:5.7759, R:0.0067, T:0.4248(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0945 (C:5.7528, R:0.0067, T:0.4255(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0935 (C:5.7425, R:0.0067, T:0.4251(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1052 (C:5.7298, R:0.0067, T:0.4311(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1065 (C:5.7358, R:0.0067, T:0.4369(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0838 (C:5.7573, R:0.0066, T:0.4212(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.0955 (C:5.6847, R:0.0066, T:0.4311(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1157 (C:5.7274, R:0.0067, T:0.4453(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.0850 (C:5.7267, R:0.0066, T:0.4227(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1064 (C:5.7752, R:0.0067, T:0.4399(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0937 (C:5.7294, R:0.0067, T:0.4278(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.0881 (C:5.7491, R:0.0066, T:0.4242(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.0969 (C:5.7541, R:0.0067, T:0.4277(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.0991 (C:5.7704, R:0.0067, T:0.4316(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0935 (C:5.7387, R:0.0066, T:0.4326(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1173 (C:5.7143, R:0.0067, T:0.4519(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.0723 (C:5.7403, R:0.0066, T:0.4075(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0979 (C:5.7251, R:0.0066, T:0.4356(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1226 (C:5.7112, R:0.0067, T:0.4519(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1012 (C:5.7765, R:0.0066, T:0.4382(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.0920 (C:5.7366, R:0.0067, T:0.4259(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1030 (C:5.6780, R:0.0067, T:0.4369(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 96 TRAINING SUMMARY:
  Total Loss: 1.0989
  Contrastive: 5.7488
  Reconstruction: 0.0067
  Topological: 0.4328 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.9422
  Contrastive: 5.7154
  Reconstruction: 0.0058
  Topological: 1.3647 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 96/300 COMPLETE (39.3s)
Train Loss: 1.0989 (C:5.7488, R:0.0067, T:0.4328)
Val Loss:   1.9422 (C:5.7154, R:0.0058, T:1.3647)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 97 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.0840 (C:5.7217, R:0.0067, T:0.4167(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0750 (C:5.7287, R:0.0066, T:0.4116(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0969 (C:5.7426, R:0.0066, T:0.4342(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1044 (C:5.7676, R:0.0066, T:0.4419(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0847 (C:5.7192, R:0.0067, T:0.4175(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0732 (C:5.7291, R:0.0066, T:0.4085(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1200 (C:5.7688, R:0.0066, T:0.4568(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1056 (C:5.7159, R:0.0066, T:0.4415(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1130 (C:5.7436, R:0.0067, T:0.4463(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0955 (C:5.7556, R:0.0067, T:0.4293(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1171 (C:5.7333, R:0.0067, T:0.4481(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.0908 (C:5.7789, R:0.0067, T:0.4231(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.0806 (C:5.7405, R:0.0066, T:0.4186(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.0730 (C:5.7230, R:0.0066, T:0.4102(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0990 (C:5.7563, R:0.0067, T:0.4319(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0857 (C:5.7281, R:0.0067, T:0.4205(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.0780 (C:5.7360, R:0.0067, T:0.4114(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1060 (C:5.7984, R:0.0067, T:0.4408(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0946 (C:5.7525, R:0.0067, T:0.4240(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1062 (C:5.7935, R:0.0067, T:0.4394(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1365 (C:5.7475, R:0.0067, T:0.4669(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1129 (C:5.7456, R:0.0066, T:0.4493(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 97 TRAINING SUMMARY:
  Total Loss: 1.0990
  Contrastive: 5.7488
  Reconstruction: 0.0067
  Topological: 0.4333 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.9165
  Contrastive: 5.7205
  Reconstruction: 0.0058
  Topological: 1.3404 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 97/300 COMPLETE (38.6s)
Train Loss: 1.0990 (C:5.7488, R:0.0067, T:0.4333)
Val Loss:   1.9165 (C:5.7205, R:0.0058, T:1.3404)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 98 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.0543 (C:5.7407, R:0.0066, T:0.3896(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1080 (C:5.7134, R:0.0066, T:0.4432(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1050 (C:5.7533, R:0.0067, T:0.4376(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0996 (C:5.7566, R:0.0067, T:0.4292(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0760 (C:5.7286, R:0.0066, T:0.4175(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1009 (C:5.7706, R:0.0067, T:0.4348(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.0944 (C:5.7101, R:0.0066, T:0.4319(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.0684 (C:5.7501, R:0.0066, T:0.4086(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.0991 (C:5.7649, R:0.0066, T:0.4347(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1004 (C:5.7783, R:0.0067, T:0.4323(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1133 (C:5.7788, R:0.0067, T:0.4463(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1221 (C:5.7591, R:0.0067, T:0.4504(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.0936 (C:5.7674, R:0.0067, T:0.4283(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1126 (C:5.7816, R:0.0067, T:0.4454(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0845 (C:5.7727, R:0.0066, T:0.4201(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1146 (C:5.7404, R:0.0067, T:0.4481(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.0844 (C:5.7459, R:0.0066, T:0.4219(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1360 (C:5.7417, R:0.0067, T:0.4646(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0918 (C:5.7607, R:0.0067, T:0.4236(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1116 (C:5.7227, R:0.0066, T:0.4490(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1059 (C:5.7609, R:0.0067, T:0.4375(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1087 (C:5.7191, R:0.0067, T:0.4384(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4320

ğŸ“Š EPOCH 98 TRAINING SUMMARY:
  Total Loss: 1.0977
  Contrastive: 5.7483
  Reconstruction: 0.0067
  Topological: 0.4320 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.9114
  Contrastive: 5.7207
  Reconstruction: 0.0058
  Topological: 1.3361 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 98/300 COMPLETE (39.7s)
Train Loss: 1.0977 (C:5.7483, R:0.0067, T:0.4320)
Val Loss:   1.9114 (C:5.7207, R:0.0058, T:1.3361)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 99 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1338 (C:5.7621, R:0.0067, T:0.4608(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1126 (C:5.7470, R:0.0067, T:0.4431(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0807 (C:5.7950, R:0.0066, T:0.4203(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0745 (C:5.7445, R:0.0067, T:0.4055(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0836 (C:5.7252, R:0.0067, T:0.4122(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0955 (C:5.7382, R:0.0067, T:0.4296(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.0899 (C:5.7627, R:0.0066, T:0.4269(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1066 (C:5.7991, R:0.0068, T:0.4303(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.0989 (C:5.7889, R:0.0066, T:0.4366(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0914 (C:5.7526, R:0.0066, T:0.4270(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0912 (C:5.7424, R:0.0067, T:0.4233(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.0871 (C:5.7242, R:0.0067, T:0.4203(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.0951 (C:5.7657, R:0.0067, T:0.4289(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1144 (C:5.7610, R:0.0067, T:0.4492(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0931 (C:5.7506, R:0.0067, T:0.4254(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1036 (C:5.7473, R:0.0066, T:0.4387(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.0923 (C:5.7774, R:0.0067, T:0.4246(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1025 (C:5.7447, R:0.0067, T:0.4316(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1108 (C:5.7471, R:0.0066, T:0.4471(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1206 (C:5.7350, R:0.0067, T:0.4538(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1129 (C:5.7366, R:0.0066, T:0.4485(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0877 (C:5.7612, R:0.0067, T:0.4158(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 99 TRAINING SUMMARY:
  Total Loss: 1.0985
  Contrastive: 5.7484
  Reconstruction: 0.0067
  Topological: 0.4329 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.8793
  Contrastive: 5.7527
  Reconstruction: 0.0058
  Topological: 1.3032 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 99/300 COMPLETE (38.2s)
Train Loss: 1.0985 (C:5.7484, R:0.0067, T:0.4329)
Val Loss:   1.8793 (C:5.7527, R:0.0058, T:1.3032)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 100 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.0763 (C:5.7669, R:0.0066, T:0.4137(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1337 (C:5.7565, R:0.0066, T:0.4690(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1061 (C:5.7665, R:0.0067, T:0.4369(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0930 (C:5.7004, R:0.0066, T:0.4288(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0809 (C:5.7395, R:0.0066, T:0.4205(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1040 (C:5.7295, R:0.0067, T:0.4355(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.0912 (C:5.7942, R:0.0067, T:0.4260(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.0976 (C:5.7287, R:0.0066, T:0.4341(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1057 (C:5.7276, R:0.0067, T:0.4373(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0925 (C:5.7390, R:0.0066, T:0.4292(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1177 (C:5.7570, R:0.0067, T:0.4483(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1118 (C:5.7521, R:0.0067, T:0.4433(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.0864 (C:5.7436, R:0.0066, T:0.4221(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.0928 (C:5.7584, R:0.0067, T:0.4250(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1049 (C:5.7490, R:0.0067, T:0.4349(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1061 (C:5.7258, R:0.0067, T:0.4358(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.0915 (C:5.7733, R:0.0066, T:0.4286(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0770 (C:5.7538, R:0.0066, T:0.4147(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1028 (C:5.7383, R:0.0067, T:0.4368(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0854 (C:5.7283, R:0.0067, T:0.4194(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.0906 (C:5.7534, R:0.0067, T:0.4233(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1331 (C:5.7620, R:0.0067, T:0.4644(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4315

ğŸ“Š EPOCH 100 TRAINING SUMMARY:
  Total Loss: 1.0967
  Contrastive: 5.7493
  Reconstruction: 0.0067
  Topological: 0.4315 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.8702
  Contrastive: 5.7506
  Reconstruction: 0.0058
  Topological: 1.2951 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 100/300 COMPLETE (38.7s)
Train Loss: 1.0967 (C:5.7493, R:0.0067, T:0.4315)
Val Loss:   1.8702 (C:5.7506, R:0.0058, T:1.2951)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 101 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.0884 (C:5.7602, R:0.0066, T:0.4256(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0935 (C:5.7156, R:0.0067, T:0.4283(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0957 (C:5.7645, R:0.0066, T:0.4332(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0934 (C:5.7033, R:0.0066, T:0.4334(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0921 (C:5.7407, R:0.0067, T:0.4264(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0971 (C:5.7435, R:0.0067, T:0.4287(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.0828 (C:5.7376, R:0.0067, T:0.4177(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.0629 (C:5.7774, R:0.0066, T:0.4031(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.0995 (C:5.7624, R:0.0066, T:0.4376(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0986 (C:5.7632, R:0.0066, T:0.4348(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1210 (C:5.7450, R:0.0067, T:0.4476(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.0832 (C:5.7382, R:0.0067, T:0.4158(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.0927 (C:5.7441, R:0.0066, T:0.4295(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1207 (C:5.7729, R:0.0067, T:0.4523(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0895 (C:5.7622, R:0.0066, T:0.4258(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0994 (C:5.7625, R:0.0066, T:0.4347(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1040 (C:5.7329, R:0.0067, T:0.4382(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1027 (C:5.7169, R:0.0067, T:0.4353(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1173 (C:5.7445, R:0.0066, T:0.4552(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0955 (C:5.7506, R:0.0066, T:0.4307(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1261 (C:5.7432, R:0.0067, T:0.4610(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0843 (C:5.7295, R:0.0066, T:0.4263(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 101 TRAINING SUMMARY:
  Total Loss: 1.0967
  Contrastive: 5.7491
  Reconstruction: 0.0067
  Topological: 0.4316 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.8693
  Contrastive: 5.7478
  Reconstruction: 0.0057
  Topological: 1.2945 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 101/300 COMPLETE (41.0s)
Train Loss: 1.0967 (C:5.7491, R:0.0067, T:0.4316)
Val Loss:   1.8693 (C:5.7478, R:0.0057, T:1.2945)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 102 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1104 (C:5.7648, R:0.0066, T:0.4465(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1192 (C:5.7377, R:0.0067, T:0.4492(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0864 (C:5.7505, R:0.0066, T:0.4233(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0809 (C:5.7476, R:0.0066, T:0.4180(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0979 (C:5.7455, R:0.0066, T:0.4339(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1016 (C:5.7673, R:0.0067, T:0.4307(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.0892 (C:5.7316, R:0.0066, T:0.4245(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.0866 (C:5.7592, R:0.0067, T:0.4176(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1231 (C:5.7562, R:0.0067, T:0.4539(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0836 (C:5.7607, R:0.0066, T:0.4233(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0861 (C:5.7590, R:0.0066, T:0.4253(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1154 (C:5.7511, R:0.0066, T:0.4519(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.0867 (C:5.7686, R:0.0066, T:0.4230(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1159 (C:5.7142, R:0.0066, T:0.4517(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0675 (C:5.7457, R:0.0066, T:0.4027(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1110 (C:5.7422, R:0.0067, T:0.4453(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1066 (C:5.7811, R:0.0066, T:0.4421(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0826 (C:5.7693, R:0.0067, T:0.4143(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0988 (C:5.7322, R:0.0067, T:0.4329(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0792 (C:5.7374, R:0.0067, T:0.4139(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1009 (C:5.7412, R:0.0066, T:0.4368(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1117 (C:5.8036, R:0.0067, T:0.4401(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4301

ğŸ“Š EPOCH 102 TRAINING SUMMARY:
  Total Loss: 1.0949
  Contrastive: 5.7499
  Reconstruction: 0.0066
  Topological: 0.4301 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.8101
  Contrastive: 5.7808
  Reconstruction: 0.0058
  Topological: 1.2351 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 102/300 COMPLETE (39.7s)
Train Loss: 1.0949 (C:5.7499, R:0.0066, T:0.4301)
Val Loss:   1.8101 (C:5.7808, R:0.0058, T:1.2351)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 103 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1125 (C:5.7981, R:0.0067, T:0.4457(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0834 (C:5.7368, R:0.0066, T:0.4223(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0882 (C:5.7980, R:0.0067, T:0.4179(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1008 (C:5.7460, R:0.0067, T:0.4336(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0858 (C:5.7272, R:0.0067, T:0.4179(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1071 (C:5.7808, R:0.0067, T:0.4363(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1071 (C:5.7939, R:0.0067, T:0.4379(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1198 (C:5.7382, R:0.0066, T:0.4575(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.0935 (C:5.7458, R:0.0066, T:0.4294(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0877 (C:5.7705, R:0.0067, T:0.4210(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1084 (C:5.7545, R:0.0066, T:0.4450(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.0756 (C:5.7847, R:0.0067, T:0.4097(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.0967 (C:5.7786, R:0.0067, T:0.4306(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.0678 (C:5.7645, R:0.0067, T:0.4013(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1004 (C:5.7691, R:0.0066, T:0.4385(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0908 (C:5.7553, R:0.0067, T:0.4241(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1004 (C:5.7392, R:0.0066, T:0.4355(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0911 (C:5.7760, R:0.0066, T:0.4263(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0886 (C:5.7456, R:0.0066, T:0.4251(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1199 (C:5.7576, R:0.0067, T:0.4479(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.0829 (C:5.7651, R:0.0067, T:0.4167(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0896 (C:5.7674, R:0.0067, T:0.4243(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4291

ğŸ“Š EPOCH 103 TRAINING SUMMARY:
  Total Loss: 1.0939
  Contrastive: 5.7503
  Reconstruction: 0.0066
  Topological: 0.4291 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.8321
  Contrastive: 5.7664
  Reconstruction: 0.0057
  Topological: 1.2581 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 103/300 COMPLETE (39.5s)
Train Loss: 1.0939 (C:5.7503, R:0.0066, T:0.4291)
Val Loss:   1.8321 (C:5.7664, R:0.0057, T:1.2581)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 104 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.0902 (C:5.7926, R:0.0066, T:0.4278(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0873 (C:5.7512, R:0.0066, T:0.4260(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0713 (C:5.7640, R:0.0067, T:0.4055(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0898 (C:5.7962, R:0.0067, T:0.4227(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0821 (C:5.7178, R:0.0066, T:0.4224(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0893 (C:5.7697, R:0.0066, T:0.4254(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.0790 (C:5.7458, R:0.0067, T:0.4102(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.0916 (C:5.7476, R:0.0066, T:0.4271(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.0875 (C:5.7474, R:0.0066, T:0.4231(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0841 (C:5.7541, R:0.0067, T:0.4187(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0889 (C:5.7384, R:0.0066, T:0.4273(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1131 (C:5.7140, R:0.0066, T:0.4501(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.0886 (C:5.7184, R:0.0067, T:0.4231(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.0931 (C:5.7756, R:0.0067, T:0.4251(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0870 (C:5.7445, R:0.0067, T:0.4179(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0759 (C:5.7030, R:0.0066, T:0.4153(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1115 (C:5.7392, R:0.0067, T:0.4452(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1007 (C:5.7429, R:0.0066, T:0.4404(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0825 (C:5.7626, R:0.0067, T:0.4145(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0722 (C:5.7549, R:0.0066, T:0.4092(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.0883 (C:5.7696, R:0.0066, T:0.4249(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0716 (C:5.7288, R:0.0067, T:0.4063(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4285

ğŸ“Š EPOCH 104 TRAINING SUMMARY:
  Total Loss: 1.0931
  Contrastive: 5.7501
  Reconstruction: 0.0066
  Topological: 0.4285 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.9082
  Contrastive: 5.7315
  Reconstruction: 0.0058
  Topological: 1.3311 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 104/300 COMPLETE (40.0s)
Train Loss: 1.0931 (C:5.7501, R:0.0066, T:0.4285)
Val Loss:   1.9082 (C:5.7315, R:0.0058, T:1.3311)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 105 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1023 (C:5.7575, R:0.0066, T:0.4386(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0867 (C:5.7654, R:0.0066, T:0.4258(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1066 (C:5.7314, R:0.0068, T:0.4285(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0964 (C:5.7317, R:0.0066, T:0.4319(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1068 (C:5.7668, R:0.0067, T:0.4377(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0844 (C:5.7767, R:0.0066, T:0.4207(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1095 (C:5.7492, R:0.0067, T:0.4375(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1078 (C:5.7307, R:0.0066, T:0.4440(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.0544 (C:5.7660, R:0.0066, T:0.3958(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1057 (C:5.7066, R:0.0067, T:0.4387(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0871 (C:5.7041, R:0.0066, T:0.4269(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.0827 (C:5.7405, R:0.0066, T:0.4202(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.0985 (C:5.7512, R:0.0066, T:0.4346(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1290 (C:5.7442, R:0.0067, T:0.4602(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0797 (C:5.7616, R:0.0066, T:0.4174(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0986 (C:5.7391, R:0.0066, T:0.4375(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1344 (C:5.7848, R:0.0067, T:0.4676(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0891 (C:5.7425, R:0.0066, T:0.4276(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1140 (C:5.7416, R:0.0066, T:0.4499(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1020 (C:5.7838, R:0.0067, T:0.4362(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.0830 (C:5.7520, R:0.0066, T:0.4228(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1454 (C:5.7625, R:0.0067, T:0.4765(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4282

ğŸ“Š EPOCH 105 TRAINING SUMMARY:
  Total Loss: 1.0927
  Contrastive: 5.7506
  Reconstruction: 0.0066
  Topological: 0.4282 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.8562
  Contrastive: 5.7549
  Reconstruction: 0.0057
  Topological: 1.2826 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 105/300 COMPLETE (41.2s)
Train Loss: 1.0927 (C:5.7506, R:0.0066, T:0.4282)
Val Loss:   1.8562 (C:5.7549, R:0.0057, T:1.2826)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 106 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1153 (C:5.7738, R:0.0067, T:0.4425(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1083 (C:5.7665, R:0.0067, T:0.4394(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1177 (C:5.7136, R:0.0066, T:0.4541(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1178 (C:5.7289, R:0.0066, T:0.4528(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1252 (C:5.7647, R:0.0067, T:0.4568(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0834 (C:5.7443, R:0.0066, T:0.4201(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.0974 (C:5.7705, R:0.0066, T:0.4342(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.0725 (C:5.7269, R:0.0066, T:0.4094(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.0749 (C:5.7422, R:0.0066, T:0.4141(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0943 (C:5.7599, R:0.0066, T:0.4354(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0799 (C:5.7778, R:0.0067, T:0.4127(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1212 (C:5.7231, R:0.0067, T:0.4543(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.0943 (C:5.7028, R:0.0066, T:0.4332(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.0973 (C:5.7991, R:0.0067, T:0.4291(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0723 (C:5.7118, R:0.0066, T:0.4118(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1100 (C:5.7454, R:0.0067, T:0.4411(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1110 (C:5.7720, R:0.0067, T:0.4434(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0850 (C:5.7470, R:0.0067, T:0.4176(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0914 (C:5.7805, R:0.0066, T:0.4277(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0956 (C:5.7707, R:0.0067, T:0.4284(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.0750 (C:5.7811, R:0.0067, T:0.4085(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0753 (C:5.7626, R:0.0066, T:0.4161(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 106 TRAINING SUMMARY:
  Total Loss: 1.0943
  Contrastive: 5.7488
  Reconstruction: 0.0066
  Topological: 0.4297 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.8727
  Contrastive: 5.7194
  Reconstruction: 0.0057
  Topological: 1.2983 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 106/300 COMPLETE (42.0s)
Train Loss: 1.0943 (C:5.7488, R:0.0066, T:0.4297)
Val Loss:   1.8727 (C:5.7194, R:0.0057, T:1.2983)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 107 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.0930 (C:5.7480, R:0.0067, T:0.4234(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0888 (C:5.7326, R:0.0066, T:0.4268(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0983 (C:5.7598, R:0.0067, T:0.4292(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0928 (C:5.7388, R:0.0066, T:0.4299(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0989 (C:5.7986, R:0.0067, T:0.4309(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0901 (C:5.7531, R:0.0067, T:0.4208(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1049 (C:5.6834, R:0.0067, T:0.4375(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1242 (C:5.7720, R:0.0067, T:0.4532(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.0810 (C:5.7420, R:0.0067, T:0.4144(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0847 (C:5.7137, R:0.0065, T:0.4325(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0757 (C:5.6982, R:0.0066, T:0.4142(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.0977 (C:5.7478, R:0.0066, T:0.4376(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.0854 (C:5.7608, R:0.0066, T:0.4216(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.0785 (C:5.7495, R:0.0066, T:0.4148(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0720 (C:5.7298, R:0.0067, T:0.4053(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0745 (C:5.7484, R:0.0066, T:0.4157(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.0957 (C:5.7425, R:0.0066, T:0.4312(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0899 (C:5.7702, R:0.0066, T:0.4278(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0847 (C:5.7440, R:0.0067, T:0.4184(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0867 (C:5.7653, R:0.0066, T:0.4263(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1003 (C:5.7451, R:0.0066, T:0.4380(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0844 (C:5.7658, R:0.0066, T:0.4243(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 107 TRAINING SUMMARY:
  Total Loss: 1.0929
  Contrastive: 5.7487
  Reconstruction: 0.0066
  Topological: 0.4285 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.9286
  Contrastive: 5.7066
  Reconstruction: 0.0058
  Topological: 1.3532 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 107/300 COMPLETE (41.9s)
Train Loss: 1.0929 (C:5.7487, R:0.0066, T:0.4285)
Val Loss:   1.9286 (C:5.7066, R:0.0058, T:1.3532)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 108 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.0836 (C:5.7413, R:0.0066, T:0.4202(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0871 (C:5.7526, R:0.0067, T:0.4211(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1279 (C:5.7469, R:0.0067, T:0.4575(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0909 (C:5.7464, R:0.0066, T:0.4289(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0972 (C:5.7020, R:0.0066, T:0.4347(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0996 (C:5.7365, R:0.0066, T:0.4370(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1449 (C:5.7626, R:0.0067, T:0.4767(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.0967 (C:5.7222, R:0.0066, T:0.4327(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.0863 (C:5.7294, R:0.0067, T:0.4199(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1112 (C:5.7186, R:0.0066, T:0.4462(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0888 (C:5.7578, R:0.0066, T:0.4277(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.0720 (C:5.7461, R:0.0066, T:0.4084(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1006 (C:5.7551, R:0.0067, T:0.4338(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.0925 (C:5.7797, R:0.0066, T:0.4308(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1230 (C:5.7513, R:0.0066, T:0.4596(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1061 (C:5.7739, R:0.0067, T:0.4376(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1178 (C:5.7256, R:0.0066, T:0.4570(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1231 (C:5.7571, R:0.0067, T:0.4538(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0738 (C:5.7667, R:0.0066, T:0.4092(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0836 (C:5.7456, R:0.0066, T:0.4234(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.0923 (C:5.7834, R:0.0067, T:0.4261(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1197 (C:5.7234, R:0.0067, T:0.4527(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 108 TRAINING SUMMARY:
  Total Loss: 1.0931
  Contrastive: 5.7494
  Reconstruction: 0.0066
  Topological: 0.4289 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.9401
  Contrastive: 5.6727
  Reconstruction: 0.0057
  Topological: 1.3655 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 108/300 COMPLETE (43.5s)
Train Loss: 1.0931 (C:5.7494, R:0.0066, T:0.4289)
Val Loss:   1.9401 (C:5.6727, R:0.0057, T:1.3655)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 109 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1066 (C:5.7131, R:0.0067, T:0.4413(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0808 (C:5.7552, R:0.0066, T:0.4179(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1022 (C:5.7509, R:0.0067, T:0.4333(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1011 (C:5.7768, R:0.0067, T:0.4345(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1093 (C:5.7687, R:0.0067, T:0.4422(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0992 (C:5.7477, R:0.0066, T:0.4372(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.0775 (C:5.7877, R:0.0067, T:0.4100(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.0908 (C:5.7608, R:0.0067, T:0.4248(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1351 (C:5.7704, R:0.0067, T:0.4655(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0986 (C:5.7521, R:0.0066, T:0.4398(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0516 (C:5.7652, R:0.0066, T:0.3915(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.0897 (C:5.7377, R:0.0067, T:0.4191(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1081 (C:5.7432, R:0.0066, T:0.4447(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.0657 (C:5.7767, R:0.0066, T:0.4061(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0739 (C:5.7815, R:0.0066, T:0.4095(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0834 (C:5.7671, R:0.0066, T:0.4202(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.0846 (C:5.7224, R:0.0066, T:0.4204(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0834 (C:5.7245, R:0.0066, T:0.4212(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0920 (C:5.7663, R:0.0066, T:0.4283(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0956 (C:5.7441, R:0.0066, T:0.4334(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.0970 (C:5.7758, R:0.0066, T:0.4383(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0865 (C:5.7637, R:0.0066, T:0.4240(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4270

ğŸ“Š EPOCH 109 TRAINING SUMMARY:
  Total Loss: 1.0909
  Contrastive: 5.7495
  Reconstruction: 0.0066
  Topological: 0.4270 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.9101
  Contrastive: 5.7053
  Reconstruction: 0.0058
  Topological: 1.3349 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 109/300 COMPLETE (41.5s)
Train Loss: 1.0909 (C:5.7495, R:0.0066, T:0.4270)
Val Loss:   1.9101 (C:5.7053, R:0.0058, T:1.3349)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 110 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.0825 (C:5.7326, R:0.0066, T:0.4195(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0888 (C:5.7555, R:0.0066, T:0.4248(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0854 (C:5.7591, R:0.0066, T:0.4217(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0857 (C:5.7267, R:0.0066, T:0.4256(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0989 (C:5.7261, R:0.0067, T:0.4308(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0847 (C:5.7714, R:0.0067, T:0.4169(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1108 (C:5.7731, R:0.0066, T:0.4491(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.0930 (C:5.7787, R:0.0067, T:0.4255(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1028 (C:5.7768, R:0.0066, T:0.4414(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0939 (C:5.7732, R:0.0066, T:0.4316(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0897 (C:5.7151, R:0.0066, T:0.4272(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.0915 (C:5.7396, R:0.0066, T:0.4328(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.0909 (C:5.7326, R:0.0066, T:0.4261(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.0985 (C:5.7494, R:0.0067, T:0.4318(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0815 (C:5.7835, R:0.0067, T:0.4133(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0757 (C:5.7599, R:0.0066, T:0.4108(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.0862 (C:5.7496, R:0.0066, T:0.4237(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0994 (C:5.7424, R:0.0066, T:0.4411(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1097 (C:5.7493, R:0.0066, T:0.4460(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0780 (C:5.7540, R:0.0066, T:0.4212(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.0775 (C:5.7712, R:0.0066, T:0.4133(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1386 (C:5.7418, R:0.0067, T:0.4730(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 110 TRAINING SUMMARY:
  Total Loss: 1.0915
  Contrastive: 5.7481
  Reconstruction: 0.0066
  Topological: 0.4276 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.9031
  Contrastive: 5.7042
  Reconstruction: 0.0058
  Topological: 1.3274 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 110/300 COMPLETE (38.9s)
Train Loss: 1.0915 (C:5.7481, R:0.0066, T:0.4276)
Val Loss:   1.9031 (C:5.7042, R:0.0058, T:1.3274)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 111 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1111 (C:5.7362, R:0.0067, T:0.4446(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0982 (C:5.7297, R:0.0067, T:0.4324(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0937 (C:5.7524, R:0.0067, T:0.4259(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0838 (C:5.7612, R:0.0066, T:0.4225(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1051 (C:5.7443, R:0.0066, T:0.4403(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0880 (C:5.7780, R:0.0067, T:0.4223(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.0787 (C:5.7614, R:0.0067, T:0.4134(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.0923 (C:5.7566, R:0.0066, T:0.4315(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.0934 (C:5.7602, R:0.0066, T:0.4290(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1029 (C:5.7649, R:0.0067, T:0.4347(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0759 (C:5.7261, R:0.0066, T:0.4174(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.0897 (C:5.7518, R:0.0067, T:0.4187(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1020 (C:5.7362, R:0.0067, T:0.4346(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1144 (C:5.7410, R:0.0067, T:0.4481(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0768 (C:5.7139, R:0.0066, T:0.4179(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0975 (C:5.7565, R:0.0066, T:0.4361(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.0852 (C:5.7498, R:0.0066, T:0.4237(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0806 (C:5.7688, R:0.0066, T:0.4206(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0637 (C:5.7603, R:0.0066, T:0.4070(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0856 (C:5.7818, R:0.0066, T:0.4269(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.0954 (C:5.7544, R:0.0066, T:0.4319(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0958 (C:5.7309, R:0.0067, T:0.4284(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4266

ğŸ“Š EPOCH 111 TRAINING SUMMARY:
  Total Loss: 1.0904
  Contrastive: 5.7493
  Reconstruction: 0.0066
  Topological: 0.4266 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.8878
  Contrastive: 5.7230
  Reconstruction: 0.0057
  Topological: 1.3137 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 111/300 COMPLETE (40.1s)
Train Loss: 1.0904 (C:5.7493, R:0.0066, T:0.4266)
Val Loss:   1.8878 (C:5.7230, R:0.0057, T:1.3137)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 112 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.0772 (C:5.7451, R:0.0067, T:0.4102(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0862 (C:5.7637, R:0.0066, T:0.4278(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0896 (C:5.7237, R:0.0067, T:0.4245(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0900 (C:5.7600, R:0.0066, T:0.4251(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0878 (C:5.7602, R:0.0066, T:0.4273(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0824 (C:5.7677, R:0.0066, T:0.4178(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1054 (C:5.7950, R:0.0066, T:0.4436(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1032 (C:5.7422, R:0.0066, T:0.4389(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.0933 (C:5.7303, R:0.0066, T:0.4317(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0686 (C:5.7370, R:0.0067, T:0.4029(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0866 (C:5.7323, R:0.0066, T:0.4225(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.0786 (C:5.7698, R:0.0066, T:0.4144(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.0646 (C:5.7309, R:0.0066, T:0.4018(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1041 (C:5.7739, R:0.0066, T:0.4411(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0766 (C:5.7555, R:0.0066, T:0.4147(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0965 (C:5.7652, R:0.0067, T:0.4312(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.0898 (C:5.7269, R:0.0066, T:0.4286(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0794 (C:5.7642, R:0.0066, T:0.4190(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0958 (C:5.7756, R:0.0066, T:0.4348(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1013 (C:5.7639, R:0.0067, T:0.4332(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1061 (C:5.7273, R:0.0067, T:0.4396(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1272 (C:5.7726, R:0.0067, T:0.4585(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 112 TRAINING SUMMARY:
  Total Loss: 1.0910
  Contrastive: 5.7480
  Reconstruction: 0.0066
  Topological: 0.4271 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.7712
  Contrastive: 5.7813
  Reconstruction: 0.0057
  Topological: 1.2016 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 112/300 COMPLETE (39.7s)
Train Loss: 1.0910 (C:5.7480, R:0.0066, T:0.4271)
Val Loss:   1.7712 (C:5.7813, R:0.0057, T:1.2016)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 113 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.0900 (C:5.7799, R:0.0066, T:0.4298(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0663 (C:5.7071, R:0.0065, T:0.4134(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1036 (C:5.7543, R:0.0066, T:0.4419(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0964 (C:5.7884, R:0.0066, T:0.4314(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0706 (C:5.7411, R:0.0067, T:0.4050(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0792 (C:5.7549, R:0.0067, T:0.4137(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.0771 (C:5.7607, R:0.0066, T:0.4174(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.0935 (C:5.7488, R:0.0066, T:0.4318(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.0894 (C:5.7473, R:0.0067, T:0.4238(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1069 (C:5.7453, R:0.0067, T:0.4396(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1159 (C:5.7798, R:0.0067, T:0.4488(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.0634 (C:5.7596, R:0.0066, T:0.4021(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1019 (C:5.7648, R:0.0067, T:0.4319(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.0922 (C:5.7232, R:0.0066, T:0.4292(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0838 (C:5.7625, R:0.0066, T:0.4216(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0826 (C:5.7728, R:0.0066, T:0.4185(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1083 (C:5.7739, R:0.0067, T:0.4401(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0805 (C:5.7218, R:0.0066, T:0.4186(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0873 (C:5.7190, R:0.0066, T:0.4234(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0712 (C:5.7594, R:0.0066, T:0.4102(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1083 (C:5.7593, R:0.0067, T:0.4421(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0937 (C:5.7359, R:0.0067, T:0.4285(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4257

ğŸ“Š EPOCH 113 TRAINING SUMMARY:
  Total Loss: 1.0895
  Contrastive: 5.7484
  Reconstruction: 0.0066
  Topological: 0.4257 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.8645
  Contrastive: 5.7408
  Reconstruction: 0.0057
  Topological: 1.2926 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 113/300 COMPLETE (38.9s)
Train Loss: 1.0895 (C:5.7484, R:0.0066, T:0.4257)
Val Loss:   1.8645 (C:5.7408, R:0.0057, T:1.2926)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 114 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.0842 (C:5.7650, R:0.0066, T:0.4202(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1312 (C:5.7586, R:0.0066, T:0.4664(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1099 (C:5.7776, R:0.0067, T:0.4441(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1132 (C:5.6930, R:0.0067, T:0.4475(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0645 (C:5.7311, R:0.0066, T:0.4072(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1032 (C:5.7276, R:0.0066, T:0.4397(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.0752 (C:5.7571, R:0.0066, T:0.4168(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.0809 (C:5.7645, R:0.0066, T:0.4183(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.0712 (C:5.7841, R:0.0066, T:0.4078(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0757 (C:5.7285, R:0.0066, T:0.4125(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0770 (C:5.7281, R:0.0066, T:0.4176(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.0831 (C:5.7731, R:0.0066, T:0.4241(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.0949 (C:5.7417, R:0.0066, T:0.4374(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.0859 (C:5.7174, R:0.0066, T:0.4265(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0869 (C:5.7100, R:0.0066, T:0.4222(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0857 (C:5.6960, R:0.0066, T:0.4238(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.0855 (C:5.7524, R:0.0067, T:0.4164(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0903 (C:5.7654, R:0.0066, T:0.4294(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0842 (C:5.7833, R:0.0067, T:0.4156(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0855 (C:5.7060, R:0.0066, T:0.4232(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.0965 (C:5.7468, R:0.0067, T:0.4268(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0904 (C:5.7444, R:0.0066, T:0.4310(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 114 TRAINING SUMMARY:
  Total Loss: 1.0908
  Contrastive: 5.7492
  Reconstruction: 0.0066
  Topological: 0.4271 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.8937
  Contrastive: 5.7154
  Reconstruction: 0.0057
  Topological: 1.3204 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 114/300 COMPLETE (40.1s)
Train Loss: 1.0908 (C:5.7492, R:0.0066, T:0.4271)
Val Loss:   1.8937 (C:5.7154, R:0.0057, T:1.3204)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 115 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.0843 (C:5.7406, R:0.0067, T:0.4166(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1019 (C:5.7314, R:0.0066, T:0.4380(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1163 (C:5.7305, R:0.0066, T:0.4517(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0895 (C:5.7765, R:0.0066, T:0.4269(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1142 (C:5.7496, R:0.0066, T:0.4570(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1022 (C:5.7211, R:0.0067, T:0.4335(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.0843 (C:5.7840, R:0.0066, T:0.4225(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.0831 (C:5.7380, R:0.0066, T:0.4212(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1030 (C:5.7702, R:0.0067, T:0.4349(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0944 (C:5.7658, R:0.0066, T:0.4327(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1036 (C:5.7536, R:0.0066, T:0.4436(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1187 (C:5.7642, R:0.0066, T:0.4554(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.0669 (C:5.7483, R:0.0066, T:0.4049(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.0945 (C:5.7633, R:0.0066, T:0.4340(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0866 (C:5.7647, R:0.0067, T:0.4152(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0676 (C:5.7599, R:0.0066, T:0.4026(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.0855 (C:5.7148, R:0.0067, T:0.4197(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0629 (C:5.7180, R:0.0066, T:0.4034(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0966 (C:5.7475, R:0.0066, T:0.4393(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1056 (C:5.7440, R:0.0066, T:0.4426(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.0915 (C:5.7525, R:0.0066, T:0.4297(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0723 (C:5.6936, R:0.0067, T:0.4050(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 115 TRAINING SUMMARY:
  Total Loss: 1.0913
  Contrastive: 5.7479
  Reconstruction: 0.0066
  Topological: 0.4277 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.7803
  Contrastive: 5.7671
  Reconstruction: 0.0057
  Topological: 1.2076 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 115/300 COMPLETE (39.7s)
Train Loss: 1.0913 (C:5.7479, R:0.0066, T:0.4277)
Val Loss:   1.7803 (C:5.7671, R:0.0057, T:1.2076)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 116 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.0908 (C:5.7883, R:0.0066, T:0.4258(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.1027 (C:5.7764, R:0.0066, T:0.4430(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.1008 (C:5.7567, R:0.0066, T:0.4391(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0698 (C:5.7284, R:0.0066, T:0.4092(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0947 (C:5.7462, R:0.0066, T:0.4303(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0866 (C:5.7418, R:0.0066, T:0.4236(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.0897 (C:5.7536, R:0.0066, T:0.4317(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.0807 (C:5.7659, R:0.0067, T:0.4127(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.0866 (C:5.7282, R:0.0066, T:0.4235(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0948 (C:5.7178, R:0.0066, T:0.4343(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1118 (C:5.7353, R:0.0066, T:0.4510(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1080 (C:5.7850, R:0.0067, T:0.4414(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.0768 (C:5.7288, R:0.0066, T:0.4123(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.0938 (C:5.7822, R:0.0066, T:0.4328(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0787 (C:5.7428, R:0.0066, T:0.4170(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0893 (C:5.7348, R:0.0066, T:0.4249(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1003 (C:5.7444, R:0.0066, T:0.4400(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1036 (C:5.7815, R:0.0066, T:0.4463(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1012 (C:5.7422, R:0.0067, T:0.4338(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1209 (C:5.7422, R:0.0067, T:0.4549(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1104 (C:5.7196, R:0.0067, T:0.4403(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0792 (C:5.7740, R:0.0066, T:0.4213(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 116 TRAINING SUMMARY:
  Total Loss: 1.0894
  Contrastive: 5.7489
  Reconstruction: 0.0066
  Topological: 0.4261 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.8382
  Contrastive: 5.7291
  Reconstruction: 0.0057
  Topological: 1.2677 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 116/300 COMPLETE (39.1s)
Train Loss: 1.0894 (C:5.7489, R:0.0066, T:0.4261)
Val Loss:   1.8382 (C:5.7291, R:0.0057, T:1.2677)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 117 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.0845 (C:5.7405, R:0.0066, T:0.4231(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0811 (C:5.7228, R:0.0066, T:0.4190(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0812 (C:5.7549, R:0.0066, T:0.4209(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0860 (C:5.7086, R:0.0066, T:0.4254(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0771 (C:5.7498, R:0.0066, T:0.4170(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0965 (C:5.7393, R:0.0067, T:0.4269(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.0886 (C:5.7628, R:0.0066, T:0.4270(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.0801 (C:5.7294, R:0.0066, T:0.4185(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1192 (C:5.7803, R:0.0066, T:0.4604(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1055 (C:5.7976, R:0.0067, T:0.4389(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0773 (C:5.7684, R:0.0067, T:0.4100(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1172 (C:5.7626, R:0.0067, T:0.4515(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.0775 (C:5.6886, R:0.0066, T:0.4179(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.0734 (C:5.7653, R:0.0067, T:0.4082(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0980 (C:5.7316, R:0.0067, T:0.4306(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0933 (C:5.7084, R:0.0066, T:0.4297(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.0869 (C:5.7264, R:0.0066, T:0.4276(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1062 (C:5.7481, R:0.0067, T:0.4388(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0795 (C:5.7340, R:0.0066, T:0.4203(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0770 (C:5.7513, R:0.0066, T:0.4134(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1131 (C:5.7261, R:0.0067, T:0.4467(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0872 (C:5.7325, R:0.0066, T:0.4265(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 117 TRAINING SUMMARY:
  Total Loss: 1.0891
  Contrastive: 5.7471
  Reconstruction: 0.0066
  Topological: 0.4260 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.8968
  Contrastive: 5.7270
  Reconstruction: 0.0057
  Topological: 1.3235 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 117/300 COMPLETE (39.0s)
Train Loss: 1.0891 (C:5.7471, R:0.0066, T:0.4260)
Val Loss:   1.8968 (C:5.7270, R:0.0057, T:1.3235)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 118 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.0931 (C:5.7439, R:0.0067, T:0.4281(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0906 (C:5.7402, R:0.0066, T:0.4293(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0912 (C:5.6822, R:0.0066, T:0.4295(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0791 (C:5.8004, R:0.0067, T:0.4100(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0655 (C:5.7280, R:0.0067, T:0.3997(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0864 (C:5.7800, R:0.0066, T:0.4254(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1047 (C:5.7700, R:0.0066, T:0.4414(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.0937 (C:5.7192, R:0.0067, T:0.4286(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.0680 (C:5.7737, R:0.0066, T:0.4085(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0889 (C:5.7405, R:0.0066, T:0.4269(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0869 (C:5.7733, R:0.0066, T:0.4231(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.0690 (C:5.7585, R:0.0066, T:0.4072(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.0816 (C:5.7372, R:0.0066, T:0.4202(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.0579 (C:5.7496, R:0.0066, T:0.3973(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0927 (C:5.7682, R:0.0067, T:0.4239(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0790 (C:5.7751, R:0.0066, T:0.4165(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.0779 (C:5.7538, R:0.0066, T:0.4198(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0803 (C:5.7392, R:0.0066, T:0.4191(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1068 (C:5.7784, R:0.0066, T:0.4435(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1110 (C:5.7395, R:0.0067, T:0.4448(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.0964 (C:5.7219, R:0.0067, T:0.4290(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0783 (C:5.7391, R:0.0066, T:0.4162(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 118 TRAINING SUMMARY:
  Total Loss: 1.0890
  Contrastive: 5.7508
  Reconstruction: 0.0066
  Topological: 0.4260 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.9040
  Contrastive: 5.7063
  Reconstruction: 0.0057
  Topological: 1.3297 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 118/300 COMPLETE (39.3s)
Train Loss: 1.0890 (C:5.7508, R:0.0066, T:0.4260)
Val Loss:   1.9040 (C:5.7063, R:0.0057, T:1.3297)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 119 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1164 (C:5.7385, R:0.0066, T:0.4576(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0992 (C:5.7495, R:0.0067, T:0.4310(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0920 (C:5.7365, R:0.0067, T:0.4263(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.1037 (C:5.8037, R:0.0067, T:0.4363(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0844 (C:5.7348, R:0.0066, T:0.4198(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0803 (C:5.7349, R:0.0066, T:0.4201(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1046 (C:5.7541, R:0.0067, T:0.4388(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.0916 (C:5.7656, R:0.0067, T:0.4229(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.0932 (C:5.7212, R:0.0066, T:0.4305(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0869 (C:5.7655, R:0.0066, T:0.4259(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1011 (C:5.7640, R:0.0066, T:0.4372(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.0866 (C:5.7480, R:0.0066, T:0.4293(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1106 (C:5.7549, R:0.0067, T:0.4439(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.0752 (C:5.7065, R:0.0066, T:0.4178(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0962 (C:5.7623, R:0.0066, T:0.4321(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1068 (C:5.7676, R:0.0067, T:0.4386(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.0660 (C:5.7579, R:0.0066, T:0.4064(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0757 (C:5.7661, R:0.0066, T:0.4110(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0923 (C:5.7545, R:0.0066, T:0.4321(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0942 (C:5.7290, R:0.0067, T:0.4278(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.0932 (C:5.7550, R:0.0066, T:0.4308(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0750 (C:5.7435, R:0.0066, T:0.4120(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 119 TRAINING SUMMARY:
  Total Loss: 1.0889
  Contrastive: 5.7483
  Reconstruction: 0.0066
  Topological: 0.4260 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.9936
  Contrastive: 5.6472
  Reconstruction: 0.0057
  Topological: 1.4204 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 119/300 COMPLETE (39.5s)
Train Loss: 1.0889 (C:5.7483, R:0.0066, T:0.4260)
Val Loss:   1.9936 (C:5.6472, R:0.0057, T:1.4204)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 120 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1053 (C:5.7051, R:0.0066, T:0.4416(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0834 (C:5.7546, R:0.0066, T:0.4212(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0872 (C:5.7442, R:0.0066, T:0.4236(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0762 (C:5.8018, R:0.0066, T:0.4165(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0855 (C:5.7415, R:0.0066, T:0.4230(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0939 (C:5.7366, R:0.0066, T:0.4312(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1181 (C:5.7551, R:0.0066, T:0.4549(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.0797 (C:5.7404, R:0.0066, T:0.4155(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.0678 (C:5.7431, R:0.0066, T:0.4050(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0811 (C:5.7473, R:0.0066, T:0.4185(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0931 (C:5.7214, R:0.0066, T:0.4303(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.0980 (C:5.7671, R:0.0066, T:0.4348(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1092 (C:5.7458, R:0.0066, T:0.4463(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1000 (C:5.7852, R:0.0066, T:0.4373(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0728 (C:5.7216, R:0.0066, T:0.4152(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0814 (C:5.7218, R:0.0067, T:0.4141(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.0881 (C:5.7401, R:0.0066, T:0.4262(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0834 (C:5.7245, R:0.0067, T:0.4172(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0864 (C:5.7366, R:0.0066, T:0.4268(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0932 (C:5.7503, R:0.0066, T:0.4342(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1052 (C:5.7322, R:0.0066, T:0.4404(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0958 (C:5.7499, R:0.0066, T:0.4361(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4251

ğŸ“Š EPOCH 120 TRAINING SUMMARY:
  Total Loss: 1.0879
  Contrastive: 5.7494
  Reconstruction: 0.0066
  Topological: 0.4251 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.9311
  Contrastive: 5.6813
  Reconstruction: 0.0057
  Topological: 1.3573 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 120/300 COMPLETE (45.9s)
Train Loss: 1.0879 (C:5.7494, R:0.0066, T:0.4251)
Val Loss:   1.9311 (C:5.6813, R:0.0057, T:1.3573)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 121 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.0869 (C:5.7244, R:0.0066, T:0.4262(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0813 (C:5.7201, R:0.0066, T:0.4184(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0837 (C:5.7596, R:0.0067, T:0.4184(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0780 (C:5.7592, R:0.0067, T:0.4127(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1221 (C:5.7322, R:0.0067, T:0.4562(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1000 (C:5.7517, R:0.0067, T:0.4337(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.0773 (C:5.7720, R:0.0066, T:0.4176(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.0722 (C:5.7230, R:0.0066, T:0.4144(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.0728 (C:5.7697, R:0.0066, T:0.4118(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0618 (C:5.7634, R:0.0066, T:0.4003(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0617 (C:5.7455, R:0.0065, T:0.4070(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.0914 (C:5.7712, R:0.0066, T:0.4272(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.0539 (C:5.7265, R:0.0066, T:0.3936(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.0802 (C:5.7121, R:0.0066, T:0.4168(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1112 (C:5.7533, R:0.0066, T:0.4479(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0761 (C:5.7629, R:0.0067, T:0.4108(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1155 (C:5.7460, R:0.0066, T:0.4514(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0987 (C:5.7275, R:0.0066, T:0.4375(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0844 (C:5.7256, R:0.0066, T:0.4206(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0980 (C:5.8026, R:0.0066, T:0.4335(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.0785 (C:5.7637, R:0.0066, T:0.4172(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0770 (C:5.7011, R:0.0067, T:0.4117(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4242

ğŸ“Š EPOCH 121 TRAINING SUMMARY:
  Total Loss: 1.0869
  Contrastive: 5.7477
  Reconstruction: 0.0066
  Topological: 0.4242 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.8666
  Contrastive: 5.7305
  Reconstruction: 0.0057
  Topological: 1.2952 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 121/300 COMPLETE (44.5s)
Train Loss: 1.0869 (C:5.7477, R:0.0066, T:0.4242)
Val Loss:   1.8666 (C:5.7305, R:0.0057, T:1.2952)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 122 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1127 (C:5.7567, R:0.0067, T:0.4457(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0670 (C:5.7341, R:0.0066, T:0.4030(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0780 (C:5.7243, R:0.0066, T:0.4196(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0817 (C:5.7166, R:0.0066, T:0.4169(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0888 (C:5.7594, R:0.0067, T:0.4233(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0869 (C:5.7574, R:0.0066, T:0.4273(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1000 (C:5.6971, R:0.0066, T:0.4375(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.0988 (C:5.7567, R:0.0066, T:0.4359(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.0898 (C:5.7624, R:0.0067, T:0.4182(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0915 (C:5.7650, R:0.0066, T:0.4272(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0969 (C:5.7609, R:0.0066, T:0.4346(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.0998 (C:5.7666, R:0.0066, T:0.4395(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1012 (C:5.7381, R:0.0067, T:0.4335(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1107 (C:5.7635, R:0.0066, T:0.4462(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0713 (C:5.7520, R:0.0066, T:0.4078(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0591 (C:5.7478, R:0.0066, T:0.3972(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.0831 (C:5.7513, R:0.0066, T:0.4202(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1219 (C:5.7258, R:0.0066, T:0.4667(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1220 (C:5.7569, R:0.0066, T:0.4576(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0855 (C:5.7062, R:0.0066, T:0.4285(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.0950 (C:5.7402, R:0.0066, T:0.4313(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0890 (C:5.7379, R:0.0066, T:0.4253(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4239

ğŸ“Š EPOCH 122 TRAINING SUMMARY:
  Total Loss: 1.0865
  Contrastive: 5.7478
  Reconstruction: 0.0066
  Topological: 0.4239 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.8961
  Contrastive: 5.7317
  Reconstruction: 0.0057
  Topological: 1.3245 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 122/300 COMPLETE (44.5s)
Train Loss: 1.0865 (C:5.7478, R:0.0066, T:0.4239)
Val Loss:   1.8961 (C:5.7317, R:0.0057, T:1.3245)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 123 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.0671 (C:5.7585, R:0.0066, T:0.4089(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0852 (C:5.7563, R:0.0066, T:0.4230(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0868 (C:5.7643, R:0.0066, T:0.4255(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0924 (C:5.7538, R:0.0067, T:0.4259(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0862 (C:5.7424, R:0.0067, T:0.4196(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.1168 (C:5.7722, R:0.0066, T:0.4521(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.0929 (C:5.7697, R:0.0066, T:0.4311(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1089 (C:5.7990, R:0.0066, T:0.4452(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.0831 (C:5.7181, R:0.0066, T:0.4268(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1127 (C:5.7295, R:0.0066, T:0.4535(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.1288 (C:5.7756, R:0.0067, T:0.4613(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1050 (C:5.7480, R:0.0067, T:0.4389(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.0818 (C:5.7725, R:0.0067, T:0.4158(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.0709 (C:5.7466, R:0.0066, T:0.4119(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0905 (C:5.7409, R:0.0066, T:0.4287(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0808 (C:5.7536, R:0.0066, T:0.4179(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.0953 (C:5.7780, R:0.0067, T:0.4299(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0740 (C:5.7181, R:0.0066, T:0.4174(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0906 (C:5.7470, R:0.0066, T:0.4258(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0784 (C:5.7652, R:0.0067, T:0.4131(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.0670 (C:5.7434, R:0.0066, T:0.4097(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1200 (C:5.6881, R:0.0067, T:0.4548(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 123 TRAINING SUMMARY:
  Total Loss: 1.0875
  Contrastive: 5.7493
  Reconstruction: 0.0066
  Topological: 0.4249 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.9475
  Contrastive: 5.6869
  Reconstruction: 0.0057
  Topological: 1.3762 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 123/300 COMPLETE (45.8s)
Train Loss: 1.0875 (C:5.7493, R:0.0066, T:0.4249)
Val Loss:   1.9475 (C:5.6869, R:0.0057, T:1.3762)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 124 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.0862 (C:5.7201, R:0.0066, T:0.4295(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0918 (C:5.7561, R:0.0066, T:0.4296(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0684 (C:5.7800, R:0.0067, T:0.3993(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0865 (C:5.7582, R:0.0066, T:0.4242(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0743 (C:5.7572, R:0.0066, T:0.4126(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0650 (C:5.7650, R:0.0066, T:0.4035(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.0862 (C:5.7547, R:0.0066, T:0.4269(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.0740 (C:5.7653, R:0.0066, T:0.4137(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1209 (C:5.7654, R:0.0067, T:0.4551(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0874 (C:5.7494, R:0.0067, T:0.4222(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0966 (C:5.7561, R:0.0067, T:0.4304(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.0768 (C:5.7861, R:0.0066, T:0.4127(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.0621 (C:5.7309, R:0.0066, T:0.4057(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.0723 (C:5.7749, R:0.0066, T:0.4093(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0839 (C:5.7988, R:0.0067, T:0.4152(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0953 (C:5.7450, R:0.0067, T:0.4284(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.0606 (C:5.7621, R:0.0066, T:0.3977(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0638 (C:5.7391, R:0.0066, T:0.4055(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0783 (C:5.7709, R:0.0067, T:0.4129(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0598 (C:5.7411, R:0.0066, T:0.3988(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.0775 (C:5.7200, R:0.0065, T:0.4232(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0933 (C:5.7778, R:0.0066, T:0.4368(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4235

ğŸ“Š EPOCH 124 TRAINING SUMMARY:
  Total Loss: 1.0859
  Contrastive: 5.7481
  Reconstruction: 0.0066
  Topological: 0.4235 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.8358
  Contrastive: 5.7414
  Reconstruction: 0.0057
  Topological: 1.2641 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 124/300 COMPLETE (46.1s)
Train Loss: 1.0859 (C:5.7481, R:0.0066, T:0.4235)
Val Loss:   1.8358 (C:5.7414, R:0.0057, T:1.2641)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 125 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.0699 (C:5.7664, R:0.0066, T:0.4073(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0952 (C:5.7552, R:0.0066, T:0.4343(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0779 (C:5.7584, R:0.0067, T:0.4110(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0802 (C:5.7456, R:0.0066, T:0.4205(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0833 (C:5.7633, R:0.0067, T:0.4175(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0859 (C:5.7553, R:0.0066, T:0.4234(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.0568 (C:5.7956, R:0.0066, T:0.3978(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1051 (C:5.7109, R:0.0066, T:0.4403(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.0828 (C:5.7631, R:0.0066, T:0.4214(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0623 (C:5.7584, R:0.0067, T:0.3967(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0965 (C:5.7839, R:0.0066, T:0.4319(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.1056 (C:5.7856, R:0.0066, T:0.4425(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.0970 (C:5.7669, R:0.0067, T:0.4313(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.0562 (C:5.7320, R:0.0066, T:0.3961(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.1190 (C:5.7589, R:0.0067, T:0.4487(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0699 (C:5.7307, R:0.0066, T:0.4107(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.0834 (C:5.7560, R:0.0067, T:0.4151(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1071 (C:5.7254, R:0.0066, T:0.4458(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0860 (C:5.7442, R:0.0066, T:0.4251(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0678 (C:5.7347, R:0.0066, T:0.4080(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.0723 (C:5.7224, R:0.0066, T:0.4122(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.1020 (C:5.7516, R:0.0066, T:0.4408(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 125 TRAINING SUMMARY:
  Total Loss: 1.0863
  Contrastive: 5.7464
  Reconstruction: 0.0066
  Topological: 0.4239 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.7853
  Contrastive: 5.7523
  Reconstruction: 0.0057
  Topological: 1.2150 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 125/300 COMPLETE (46.8s)
Train Loss: 1.0863 (C:5.7464, R:0.0066, T:0.4239)
Val Loss:   1.7853 (C:5.7523, R:0.0057, T:1.2150)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 126 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1015 (C:5.7629, R:0.0066, T:0.4400(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0729 (C:5.7567, R:0.0066, T:0.4088(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0719 (C:5.7453, R:0.0066, T:0.4125(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0940 (C:5.7720, R:0.0067, T:0.4266(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0767 (C:5.7314, R:0.0066, T:0.4183(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0934 (C:5.7475, R:0.0066, T:0.4295(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.0919 (C:5.7193, R:0.0066, T:0.4319(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1007 (C:5.8239, R:0.0066, T:0.4399(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.0699 (C:5.7383, R:0.0066, T:0.4086(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0991 (C:5.7874, R:0.0067, T:0.4307(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0463 (C:5.7226, R:0.0066, T:0.3892(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.0591 (C:5.7645, R:0.0066, T:0.3951(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.0972 (C:5.7528, R:0.0066, T:0.4327(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.0645 (C:5.7463, R:0.0066, T:0.4076(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0833 (C:5.7693, R:0.0067, T:0.4173(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0913 (C:5.7908, R:0.0067, T:0.4225(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.0882 (C:5.7291, R:0.0066, T:0.4262(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0868 (C:5.7575, R:0.0066, T:0.4249(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0893 (C:5.7710, R:0.0066, T:0.4283(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0580 (C:5.7408, R:0.0066, T:0.3958(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.0802 (C:5.7293, R:0.0066, T:0.4202(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0737 (C:5.7514, R:0.0066, T:0.4101(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4227

ğŸ“Š EPOCH 126 TRAINING SUMMARY:
  Total Loss: 1.0849
  Contrastive: 5.7480
  Reconstruction: 0.0066
  Topological: 0.4227 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.9429
  Contrastive: 5.6885
  Reconstruction: 0.0057
  Topological: 1.3702 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 126/300 COMPLETE (47.3s)
Train Loss: 1.0849 (C:5.7480, R:0.0066, T:0.4227)
Val Loss:   1.9429 (C:5.6885, R:0.0057, T:1.3702)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 127 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1032 (C:5.7382, R:0.0066, T:0.4390(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0902 (C:5.7481, R:0.0066, T:0.4277(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0775 (C:5.7807, R:0.0067, T:0.4108(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0851 (C:5.7443, R:0.0066, T:0.4253(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0519 (C:5.7677, R:0.0065, T:0.3984(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0911 (C:5.7471, R:0.0066, T:0.4286(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.0713 (C:5.7155, R:0.0066, T:0.4112(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.0684 (C:5.7769, R:0.0066, T:0.4113(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.0936 (C:5.7780, R:0.0067, T:0.4274(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0780 (C:5.7101, R:0.0066, T:0.4146(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0791 (C:5.7546, R:0.0066, T:0.4204(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.0751 (C:5.7820, R:0.0066, T:0.4155(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.0839 (C:5.7207, R:0.0066, T:0.4252(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.0923 (C:5.7866, R:0.0066, T:0.4293(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0881 (C:5.7524, R:0.0066, T:0.4314(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0812 (C:5.7653, R:0.0067, T:0.4161(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.0922 (C:5.7604, R:0.0067, T:0.4237(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1165 (C:5.6777, R:0.0066, T:0.4557(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0947 (C:5.7441, R:0.0066, T:0.4368(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0657 (C:5.7100, R:0.0066, T:0.4066(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.0931 (C:5.7701, R:0.0066, T:0.4343(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0964 (C:5.7427, R:0.0066, T:0.4324(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 127 TRAINING SUMMARY:
  Total Loss: 1.0848
  Contrastive: 5.7487
  Reconstruction: 0.0066
  Topological: 0.4227 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.8098
  Contrastive: 5.7274
  Reconstruction: 0.0057
  Topological: 1.2392 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 127/300 COMPLETE (46.3s)
Train Loss: 1.0848 (C:5.7487, R:0.0066, T:0.4227)
Val Loss:   1.8098 (C:5.7274, R:0.0057, T:1.2392)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 128 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.0864 (C:5.7557, R:0.0066, T:0.4233(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0754 (C:5.7521, R:0.0066, T:0.4148(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0984 (C:5.7320, R:0.0067, T:0.4328(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0724 (C:5.7625, R:0.0066, T:0.4116(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1057 (C:5.7279, R:0.0066, T:0.4435(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0687 (C:5.7223, R:0.0067, T:0.4034(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.0983 (C:5.7515, R:0.0067, T:0.4290(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.0775 (C:5.7557, R:0.0066, T:0.4162(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.0801 (C:5.7326, R:0.0066, T:0.4160(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.1086 (C:5.7702, R:0.0067, T:0.4436(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0704 (C:5.7068, R:0.0066, T:0.4099(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.0634 (C:5.7345, R:0.0066, T:0.4028(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1027 (C:5.7176, R:0.0067, T:0.4374(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1311 (C:5.7483, R:0.0067, T:0.4656(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0874 (C:5.7631, R:0.0066, T:0.4282(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0986 (C:5.7459, R:0.0066, T:0.4352(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.0774 (C:5.7443, R:0.0066, T:0.4147(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.1023 (C:5.7908, R:0.0067, T:0.4328(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0880 (C:5.7397, R:0.0066, T:0.4267(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0746 (C:5.7327, R:0.0066, T:0.4187(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.0802 (C:5.7842, R:0.0067, T:0.4146(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0995 (C:5.7639, R:0.0066, T:0.4392(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 128 TRAINING SUMMARY:
  Total Loss: 1.0848
  Contrastive: 5.7482
  Reconstruction: 0.0066
  Topological: 0.4229 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.8706
  Contrastive: 5.7253
  Reconstruction: 0.0057
  Topological: 1.3005 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 128/300 COMPLETE (46.5s)
Train Loss: 1.0848 (C:5.7482, R:0.0066, T:0.4229)
Val Loss:   1.8706 (C:5.7253, R:0.0057, T:1.3005)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 129 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.0869 (C:5.7555, R:0.0066, T:0.4308(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0743 (C:5.7282, R:0.0066, T:0.4157(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0813 (C:5.7377, R:0.0066, T:0.4179(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0839 (C:5.7144, R:0.0066, T:0.4215(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0764 (C:5.7691, R:0.0066, T:0.4183(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0834 (C:5.7705, R:0.0066, T:0.4213(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1060 (C:5.7651, R:0.0066, T:0.4416(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.0791 (C:5.7324, R:0.0066, T:0.4143(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.0877 (C:5.7197, R:0.0066, T:0.4306(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0716 (C:5.7388, R:0.0067, T:0.4024(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0950 (C:5.7447, R:0.0066, T:0.4351(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.0852 (C:5.7257, R:0.0066, T:0.4259(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1077 (C:5.7653, R:0.0066, T:0.4474(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.1058 (C:5.6954, R:0.0066, T:0.4480(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0762 (C:5.7701, R:0.0066, T:0.4141(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0641 (C:5.7641, R:0.0066, T:0.4061(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.0857 (C:5.7341, R:0.0066, T:0.4253(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0596 (C:5.7526, R:0.0065, T:0.4054(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0658 (C:5.7356, R:0.0067, T:0.3997(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0621 (C:5.7369, R:0.0066, T:0.4062(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.0775 (C:5.7295, R:0.0066, T:0.4142(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0762 (C:5.7580, R:0.0067, T:0.4099(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4221

ğŸ“Š EPOCH 129 TRAINING SUMMARY:
  Total Loss: 1.0840
  Contrastive: 5.7476
  Reconstruction: 0.0066
  Topological: 0.4221 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.8951
  Contrastive: 5.7148
  Reconstruction: 0.0057
  Topological: 1.3235 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 129/300 COMPLETE (47.2s)
Train Loss: 1.0840 (C:5.7476, R:0.0066, T:0.4221)
Val Loss:   1.8951 (C:5.7148, R:0.0057, T:1.3235)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 130 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.0616 (C:5.7525, R:0.0066, T:0.3983(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0888 (C:5.7267, R:0.0066, T:0.4286(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0801 (C:5.7571, R:0.0067, T:0.4130(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0719 (C:5.7534, R:0.0066, T:0.4123(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.1029 (C:5.7289, R:0.0066, T:0.4401(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0833 (C:5.7276, R:0.0066, T:0.4229(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.1185 (C:5.7345, R:0.0067, T:0.4529(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.1092 (C:5.7433, R:0.0067, T:0.4429(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.0619 (C:5.7734, R:0.0066, T:0.4003(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0848 (C:5.7235, R:0.0066, T:0.4257(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0771 (C:5.7192, R:0.0066, T:0.4144(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.0951 (C:5.7311, R:0.0066, T:0.4339(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.0842 (C:5.7698, R:0.0066, T:0.4236(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.0530 (C:5.7266, R:0.0066, T:0.3927(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0713 (C:5.7448, R:0.0066, T:0.4078(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.1019 (C:5.7440, R:0.0067, T:0.4368(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.1095 (C:5.7983, R:0.0066, T:0.4465(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0991 (C:5.7470, R:0.0067, T:0.4330(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.1027 (C:5.7455, R:0.0067, T:0.4356(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0914 (C:5.7382, R:0.0066, T:0.4289(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.0702 (C:5.7302, R:0.0066, T:0.4088(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0891 (C:5.7696, R:0.0067, T:0.4233(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 130 TRAINING SUMMARY:
  Total Loss: 1.0843
  Contrastive: 5.7483
  Reconstruction: 0.0066
  Topological: 0.4224 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.8218
  Contrastive: 5.7482
  Reconstruction: 0.0057
  Topological: 1.2512 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 130/300 COMPLETE (47.2s)
Train Loss: 1.0843 (C:5.7483, R:0.0066, T:0.4224)
Val Loss:   1.8218 (C:5.7482, R:0.0057, T:1.2512)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 131 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.0761 (C:5.7702, R:0.0066, T:0.4167(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0912 (C:5.7209, R:0.0066, T:0.4318(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0770 (C:5.7239, R:0.0066, T:0.4163(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0755 (C:5.7678, R:0.0066, T:0.4194(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0801 (C:5.7229, R:0.0066, T:0.4204(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0798 (C:5.7412, R:0.0067, T:0.4134(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.0846 (C:5.7805, R:0.0066, T:0.4229(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.0854 (C:5.7685, R:0.0066, T:0.4274(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.1036 (C:5.7569, R:0.0067, T:0.4364(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0697 (C:5.7748, R:0.0066, T:0.4073(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0620 (C:5.7585, R:0.0066, T:0.4031(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.0860 (C:5.7585, R:0.0066, T:0.4232(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.0678 (C:5.7733, R:0.0066, T:0.4081(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.0794 (C:5.7439, R:0.0066, T:0.4147(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0932 (C:5.7725, R:0.0066, T:0.4312(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0981 (C:5.7562, R:0.0066, T:0.4382(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.0886 (C:5.7480, R:0.0066, T:0.4257(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0574 (C:5.7221, R:0.0066, T:0.4023(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0981 (C:5.7440, R:0.0066, T:0.4400(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.0831 (C:5.7452, R:0.0066, T:0.4223(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.1066 (C:5.7376, R:0.0067, T:0.4415(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0782 (C:5.7519, R:0.0066, T:0.4156(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4214

ğŸ“Š EPOCH 131 TRAINING SUMMARY:
  Total Loss: 1.0830
  Contrastive: 5.7499
  Reconstruction: 0.0066
  Topological: 0.4214 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.8916
  Contrastive: 5.7008
  Reconstruction: 0.0057
  Topological: 1.3221 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 131/300 COMPLETE (46.7s)
Train Loss: 1.0830 (C:5.7499, R:0.0066, T:0.4214)
Val Loss:   1.8916 (C:5.7008, R:0.0057, T:1.3221)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 132 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.0881 (C:5.7570, R:0.0067, T:0.4214(w:1.000)ğŸ‰)
Batch  25/537: Loss=1.0817 (C:5.7310, R:0.0066, T:0.4175(w:1.000)ğŸ‰)
Batch  50/537: Loss=1.0928 (C:5.7656, R:0.0066, T:0.4308(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0873 (C:5.7649, R:0.0066, T:0.4261(w:1.000)ğŸ‰)
Batch 100/537: Loss=1.0627 (C:5.7429, R:0.0066, T:0.4014(w:1.000)ğŸ‰)
Batch 125/537: Loss=1.0782 (C:5.7614, R:0.0066, T:0.4189(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.0764 (C:5.7480, R:0.0067, T:0.4105(w:1.000)ğŸ‰)
Batch 175/537: Loss=1.0706 (C:5.7700, R:0.0066, T:0.4120(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.0802 (C:5.7524, R:0.0066, T:0.4198(w:1.000)ğŸ‰)
Batch 225/537: Loss=1.0851 (C:5.7562, R:0.0066, T:0.4240(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0917 (C:5.7447, R:0.0067, T:0.4257(w:1.000)ğŸ‰)
Batch 275/537: Loss=1.0957 (C:5.7496, R:0.0066, T:0.4342(w:1.000)ğŸ‰)
Batch 300/537: Loss=1.1121 (C:5.7407, R:0.0066, T:0.4535(w:1.000)ğŸ‰)
Batch 325/537: Loss=1.0924 (C:5.7253, R:0.0067, T:0.4210(w:1.000)ğŸ‰)
Batch 350/537: Loss=1.0818 (C:5.7902, R:0.0067, T:0.4127(w:1.000)ğŸ‰)
Batch 375/537: Loss=1.0864 (C:5.7509, R:0.0066, T:0.4235(w:1.000)ğŸ‰)
Batch 400/537: Loss=1.0693 (C:5.7204, R:0.0066, T:0.4114(w:1.000)ğŸ‰)
Batch 425/537: Loss=1.0654 (C:5.7052, R:0.0066, T:0.4088(w:1.000)ğŸ‰)
Batch 450/537: Loss=1.0866 (C:5.7443, R:0.0067, T:0.4180(w:1.000)ğŸ‰)
Batch 475/537: Loss=1.1020 (C:5.7764, R:0.0067, T:0.4364(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.0921 (C:5.7828, R:0.0066, T:0.4275(w:1.000)ğŸ‰)
Batch 525/537: Loss=1.0568 (C:5.7629, R:0.0066, T:0.3930(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 132 TRAINING SUMMARY:
  Total Loss: 1.0835
  Contrastive: 5.7485
  Reconstruction: 0.0066
  Topological: 0.4219 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.8599
  Contrastive: 5.7246
  Reconstruction: 0.0057
  Topological: 1.2894 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 132/300 COMPLETE (46.4s)
Train Loss: 1.0835 (C:5.7485, R:0.0066, T:0.4219)
Val Loss:   1.8599 (C:5.7246, R:0.0057, T:1.2894)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

ğŸ›‘ Early stopping triggered after 132 epochs
Best model was at epoch 112 with Val Loss: 1.7712

======================================================================
ğŸ“ˆ FINAL TOPOLOGICAL LEARNING ANALYSIS
======================================================================
First topological learning: Epoch 1
Epochs with topology: 132/132
Max consecutive topology epochs: 132
Best topological loss: 0.4214
Final topological loss: 0.4219
âœ… SUCCESS: Topological learning achieved!
ğŸš€ EXCELLENT: Very consistent topological learning (>80%)
ğŸ“ˆ Topological learning appears stable

======================================================================
ğŸ¯ TOPOLOGICAL AUTOENCODER TRAINING COMPLETED
======================================================================
âœ… Topological training completed successfully!
Creating topological loss plots...

AttentionAutoencoder initialized:
  Input dim: 1536
  Latent dim: 75
  Hidden dims: [1024, 768, 512, 256, 128]
  Attention Heads: 5
  Total parameters: 3,068,401
FullDatasetContrastiveLoss initialized:
  Margin: 2.0
  Update frequency: 3 epochs
  Max global samples: 5000
FullDatasetCombinedLoss initialized:
  Contrastive weight: 0.0
  Base reconstruction weight: 100.0
MoorTopologicalLoss Initialized: Using 0-dimensional persistence pairings (MST edges).
No prototypes being used for topological loss - whole dataset instead.
TopologicalTrainer initialized on device: cpu
Model parameters: 3,068,401
Enhanced with topological loss monitoring
âœ… Model and trainer loaded successfully
Creating topological loss plots...
Topological loss plots saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/pure_moor_topological_autoencoder_attention_20250724_222029/plots/pure_moor_topological_autoencoder_attention_20250724_222029_topological_training_losses.png
Curriculum learning analysis saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/pure_moor_topological_autoencoder_attention_20250724_222029/plots/pure_moor_topological_autoencoder_attention_20250724_222029_curriculum_analysis.png
Main training plots saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/pure_moor_topological_autoencoder_attention_20250724_222029/plots/pure_moor_topological_autoencoder_attention_20250724_222029_topological_training_losses.png
Curriculum analysis saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/pure_moor_topological_autoencoder_attention_20250724_222029/plots/pure_moor_topological_autoencoder_attention_20250724_222029_curriculum_analysis.png
Training summary saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/pure_moor_topological_autoencoder_attention_20250724_222029/pure_moor_topological_autoencoder_attention_20250724_222029_training_summary.txt
âœ… Plots and summary created successfully
FlexibleEmbedder initialized with type: 'concat'
Output dimension will be: 1536
GlobalDataLoader initialized:
  Embedding type: concat
  Output dimension: 1536
  Sample size: All
Starting data loading pipeline...
============================================================
Loading training data from data/processed/snli_full_standard_SBERT.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 549367 training samples
Loading validation data from data/processed/snli_full_standard_SBERT_validation.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9842 validation samples
Loading test data from data/processed/snli_full_standard_SBERT_test.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9824 test samples
Generating embeddings for training...
Generating concat embeddings on cpu
Processing 549367 samples in batches of 1000
  Processing batch 1/550
  Processing batch 6/550
  Processing batch 11/550
  Processing batch 16/550
  Processing batch 21/550
  Processing batch 26/550
  Processing batch 31/550
  Processing batch 36/550
  Processing batch 41/550
  Processing batch 46/550
  Processing batch 51/550
  Processing batch 56/550
  Processing batch 61/550
  Processing batch 66/550
  Processing batch 71/550
  Processing batch 76/550
  Processing batch 81/550
  Processing batch 86/550
  Processing batch 91/550
  Processing batch 96/550
  Processing batch 101/550
  Processing batch 106/550
  Processing batch 111/550
  Processing batch 116/550
  Processing batch 121/550
  Processing batch 126/550
  Processing batch 131/550
  Processing batch 136/550
  Processing batch 141/550
  Processing batch 146/550
  Processing batch 151/550
  Processing batch 156/550
  Processing batch 161/550
  Processing batch 166/550
  Processing batch 171/550
  Processing batch 176/550
  Processing batch 181/550
  Processing batch 186/550
  Processing batch 191/550
  Processing batch 196/550
  Processing batch 201/550
  Processing batch 206/550
  Processing batch 211/550
  Processing batch 216/550
  Processing batch 221/550
  Processing batch 226/550
  Processing batch 231/550
  Processing batch 236/550
  Processing batch 241/550
  Processing batch 246/550
  Processing batch 251/550
  Processing batch 256/550
  Processing batch 261/550
  Processing batch 266/550
  Processing batch 271/550
  Processing batch 276/550
  Processing batch 281/550
  Processing batch 286/550
  Processing batch 291/550
  Processing batch 296/550
  Processing batch 301/550
  Processing batch 306/550
  Processing batch 311/550
  Processing batch 316/550
  Processing batch 321/550
  Processing batch 326/550
  Processing batch 331/550
  Processing batch 336/550
  Processing batch 341/550
  Processing batch 346/550
  Processing batch 351/550
  Processing batch 356/550
  Processing batch 361/550
  Processing batch 366/550
  Processing batch 371/550
  Processing batch 376/550
  Processing batch 381/550
  Processing batch 386/550
  Processing batch 391/550
  Processing batch 396/550
  Processing batch 401/550
  Processing batch 406/550
  Processing batch 411/550
  Processing batch 416/550
  Processing batch 421/550
  Processing batch 426/550
  Processing batch 431/550
  Processing batch 436/550
  Processing batch 441/550
  Processing batch 446/550
  Processing batch 451/550
  Processing batch 456/550
  Processing batch 461/550
  Processing batch 466/550
  Processing batch 471/550
  Processing batch 476/550
  Processing batch 481/550
  Processing batch 486/550
  Processing batch 491/550
  Processing batch 496/550
  Processing batch 501/550
  Processing batch 506/550
  Processing batch 511/550
  Processing batch 516/550
  Processing batch 521/550
  Processing batch 526/550
  Processing batch 531/550
  Processing batch 536/550
  Processing batch 541/550
  Processing batch 546/550
Generated concat embeddings: torch.Size([549367, 1536])
Generating embeddings for validation...
Generating concat embeddings on cpu
Processing 9842 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9842, 1536])
Generating embeddings for test...
Generating concat embeddings on cpu
Processing 9824 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9824, 1536])
EntailmentDataset created: 549367 samples
  Embedding shape: torch.Size([549367, 1536])
  Class distribution: {'entailment': 183416, 'neutral': 182764, 'contradiction': 183187}
EntailmentDataset created: 9842 samples
  Embedding shape: torch.Size([9842, 1536])
  Class distribution: {'entailment': 3329, 'neutral': 3235, 'contradiction': 3278}
EntailmentDataset created: 9824 samples
  Embedding shape: torch.Size([9824, 1536])
  Class distribution: {'entailment': 3368, 'neutral': 3219, 'contradiction': 3237}

Data loading pipeline completed!
Output embedding dimension: 1536
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 537
  Class 2: 183187 samples
  Class 0: 183416 samples
  Class 1: 182764 samples
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 9
  Class 2: 3278 samples
  Class 0: 3329 samples
  Class 1: 3235 samples
DataLoaders created:
  Batch size: 1020
  Balanced sampling: True
  Train batches: 537
  Val batches: 9
  Test batches: 10
âœ… Data loaded successfully
Starting model evaluation...
GlobalContrastiveEvaluator initialized on cpu
Starting comprehensive evaluation...
============================================================
Extracting latent representations...
  Processed 1/10 batches
Extracted representations: torch.Size([9824, 75])
Evaluating clustering performance...
Clustering Results:
  Silhouette Score: -0.0013
  Adjusted Rand Score: -0.0000
  Clustering Accuracy: 0.3394
Evaluating classification performance...
  Extracting training representations...
Extracting latent representations...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
Extracted representations: torch.Size([547740, 75])
  Extracting validation representations...
Extracting latent representations...
  Processed 1/9 batches
Extracted representations: torch.Size([9180, 75])
Subsampled training to 50000 samples
  Training on 50000 samples, evaluating on 9180 samples
Classification Results:
  Accuracy: 0.5065
  Per-class F1: [0.5595561326879943, 0.4190788275987621, 0.5136487716105551]
Evaluating reconstruction quality...
Reconstruction Results:
  Average MSE: 0.005666
Evaluating separation quality...
Separation Results:
  Positive distances: 5.776 Â± 0.574
  Negative distances: 5.809 Â± 0.557
  Separation ratio: 1.01x
  Gap: -7.589
  Perfect separation: No

Comprehensive evaluation completed!

============================================================
EVALUATION SUMMARY
============================================================
Clustering Performance:
  Silhouette Score: -0.0013
  Clustering Accuracy: 0.3394
  Adjusted Rand Score: -0.0000

Classification Performance:
  Accuracy: 0.5065

Separation Quality:
  Separation Ratio: 1.01x
  Gap: -7.589
  Perfect Separation: False

Reconstruction Quality:
  Average MSE: 0.005666
============================================================
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/pure_moor_topological_autoencoder_attention_20250724_222029/results/evaluation_results_20250725_095236.json
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/pure_moor_topological_autoencoder_attention_20250724_222029/results/evaluation_results_20250725_095236.json
âœ… Model evaluation completed successfully

Key Results:
  Separation ratio: 1.01x
  Perfect separation: False
  Classification accuracy: 0.5065

============================================================
TOPOLOGICAL TRAINING ANALYSIS
============================================================

ğŸ“ˆ TOPOLOGICAL LEARNING DIAGNOSIS:
  Total epochs: 112
  Epochs with topological learning: 112
  Current topological loss: 0.4271
  Current topological weight: 1.0000
  âœ… Topological loss is decreasing (good progress)
ğŸš€ EXCELLENT: Consistent topological learning achieved!
Final topological loss: 0.4271
Epochs with topology: 112/112
âš ï¸  Poor clustering accuracy: 0.339

Final analysis saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/pure_moor_topological_autoencoder_attention_20250724_222029/results/final_analysis.json
âœ… Analysis completed for: entailment_surfaces/supervised_contrastive_autoencoder/experiments/pure_moor_topological_autoencoder_attention_20250724_222029

============================================================
ğŸ‰ ANALYSIS COMPLETED SUCCESSFULLY!
============================================================


Experiment saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/pure_moor_topological_autoencoder_attention_20250724_222029

Analysis completed with exit code: 0
Time: Thu 24 Jul 23:49:00 BST 2025

=== ANALYSIS SUCCESSFUL ===
Regularization successful!


Job finished.
