Starting Surface Distance Metric Analysis job...
Job ID: 182599
Node: gpuvm17
Time: Tue 15 Jul 10:29:31 BST 2025
Loading CUDA...
Activating conda environment...
Activated conda environment: /vol/bitbucket/ahb24/tda_entailment_new
Python location: /vol/bitbucket/ahb24/tda_entailment_new/bin/python
Checking GPU availability...
Tue Jul 15 10:29:33 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.133.07             Driver Version: 570.133.07     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla T4                       Off |   00000000:00:06.0 Off |                    0 |
| N/A   30C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+

Testing PyTorch and CUDA...
PyTorch version: 2.4.1
CUDA available: True
CUDA device: Tesla T4
GPU memory: 15.6 GB
PyTorch setup verified!

Starting Hyperparam Optimization...

======================================================================
COARSE HYPERPARAMETER SEARCH - CONCAT EMBEDDINGS
======================================================================
Baseline accuracy: 81.67% (concat embeddings)
Embedding type: concat (best performing from initial results)
Focus: Classification performance optimization
Reconstruction weight: Fixed at 0.3 (optimize classification first)
Total combinations to test: 12
Search space:
  margin: [1.0, 2.0, 3.0]
  update_frequency: [1, 3]
  max_global_samples: [5000, 10000]
======================================================================

[1/12] Testing: coarse_margin1.0_updatefreq1_max_global_samples5000
  margin: 1.0
  update_frequency: 1
  max_global_samples: 5000
  Reconstruction weight: 0.3 (fixed)
GLOBAL DATASET CONTRASTIVE AUTOENCODER PIPELINE
============================================================
Start time: 2025-07-15 10:30:28.681536
Using device: cuda

Configuration:
  Embedding type: concat
  Batch size: 1020
  Global update frequency: 1 epochs
  Training epochs: 300
Experiment setup completed:
  Experiment directory: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin1.0_updatefreq1_max_global_samples5000_20250715_103028
  Config saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin1.0_updatefreq1_max_global_samples5000_20250715_103028/config.json
Loading data...
========================================
FlexibleEmbedder initialized with type: 'concat'
Output dimension will be: 1536
GlobalDataLoader initialized:
  Embedding type: concat
  Output dimension: 1536
  Sample size: All
Starting data loading pipeline...
============================================================
Loading training data from data/processed/snli_full_standard_SBERT.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 549367 training samples
Loading validation data from data/processed/snli_full_standard_SBERT_validation.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9842 validation samples
Loading test data from data/processed/snli_full_standard_SBERT_test.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9824 test samples
Generating embeddings for training...
Generating concat embeddings on cuda
Processing 549367 samples in batches of 1000
  Processing batch 1/550
  Processing batch 6/550
  Processing batch 11/550
  Processing batch 16/550
  Processing batch 21/550
  Processing batch 26/550
  Processing batch 31/550
  Processing batch 36/550
  Processing batch 41/550
  Processing batch 46/550
  Processing batch 51/550
  Processing batch 56/550
  Processing batch 61/550
  Processing batch 66/550
  Processing batch 71/550
  Processing batch 76/550
  Processing batch 81/550
  Processing batch 86/550
  Processing batch 91/550
  Processing batch 96/550
  Processing batch 101/550
  Processing batch 106/550
  Processing batch 111/550
  Processing batch 116/550
  Processing batch 121/550
  Processing batch 126/550
  Processing batch 131/550
  Processing batch 136/550
  Processing batch 141/550
  Processing batch 146/550
  Processing batch 151/550
  Processing batch 156/550
  Processing batch 161/550
  Processing batch 166/550
  Processing batch 171/550
  Processing batch 176/550
  Processing batch 181/550
  Processing batch 186/550
  Processing batch 191/550
  Processing batch 196/550
  Processing batch 201/550
  Processing batch 206/550
  Processing batch 211/550
  Processing batch 216/550
  Processing batch 221/550
  Processing batch 226/550
  Processing batch 231/550
  Processing batch 236/550
  Processing batch 241/550
  Processing batch 246/550
  Processing batch 251/550
  Processing batch 256/550
  Processing batch 261/550
  Processing batch 266/550
  Processing batch 271/550
  Processing batch 276/550
  Processing batch 281/550
  Processing batch 286/550
  Processing batch 291/550
  Processing batch 296/550
  Processing batch 301/550
  Processing batch 306/550
  Processing batch 311/550
  Processing batch 316/550
  Processing batch 321/550
  Processing batch 326/550
  Processing batch 331/550
  Processing batch 336/550
  Processing batch 341/550
  Processing batch 346/550
  Processing batch 351/550
  Processing batch 356/550
  Processing batch 361/550
  Processing batch 366/550
  Processing batch 371/550
  Processing batch 376/550
  Processing batch 381/550
  Processing batch 386/550
  Processing batch 391/550
  Processing batch 396/550
  Processing batch 401/550
  Processing batch 406/550
  Processing batch 411/550
  Processing batch 416/550
  Processing batch 421/550
  Processing batch 426/550
  Processing batch 431/550
  Processing batch 436/550
  Processing batch 441/550
  Processing batch 446/550
  Processing batch 451/550
  Processing batch 456/550
  Processing batch 461/550
  Processing batch 466/550
  Processing batch 471/550
  Processing batch 476/550
  Processing batch 481/550
  Processing batch 486/550
  Processing batch 491/550
  Processing batch 496/550
  Processing batch 501/550
  Processing batch 506/550
  Processing batch 511/550
  Processing batch 516/550
  Processing batch 521/550
  Processing batch 526/550
  Processing batch 531/550
  Processing batch 536/550
  Processing batch 541/550
  Processing batch 546/550
Generated concat embeddings: torch.Size([549367, 1536])
Generating embeddings for validation...
Generating concat embeddings on cuda
Processing 9842 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9842, 1536])
Generating embeddings for test...
Generating concat embeddings on cuda
Processing 9824 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9824, 1536])
EntailmentDataset created: 549367 samples
  Embedding shape: torch.Size([549367, 1536])
  Class distribution: {'entailment': 183416, 'neutral': 182764, 'contradiction': 183187}
EntailmentDataset created: 9842 samples
  Embedding shape: torch.Size([9842, 1536])
  Class distribution: {'entailment': 3329, 'neutral': 3235, 'contradiction': 3278}
EntailmentDataset created: 9824 samples
  Embedding shape: torch.Size([9824, 1536])
  Class distribution: {'entailment': 3368, 'neutral': 3219, 'contradiction': 3237}

Data loading pipeline completed!
Output embedding dimension: 1536
Updated model input_dim to: 1536
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 537
  Class 2: 183187 samples
  Class 0: 183416 samples
  Class 1: 182764 samples
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 9
  Class 2: 3278 samples
  Class 0: 3329 samples
  Class 1: 3235 samples
DataLoaders created:
  Batch size: 1020
  Balanced sampling: True
  Train batches: 537
  Val batches: 9
  Test batches: 10
Data loading completed!
  Train: 549367 samples, 537 batches
  Val: 9842 samples, 9 batches
  Test: 9824 samples, 10 batches
Creating model and trainer...
========================================
ContrastiveAutoencoder initialized:
  Input dim: 1536
  Latent dim: 75
  Hidden dims: [512, 256]
  Dropout rate: 0.2
  Total parameters: 1,876,555
Model created with 1,876,555 parameters
FullDatasetContrastiveLoss initialized:
  Margin: 1.0
  Update frequency: 1 epochs
  Max global samples: 5000
FullDatasetCombinedLoss initialized:
  Contrastive weight: 1.0
  Base reconstruction weight: 0.0
  Scheduled reconstruction: warmup=30 epochs, max_weight=0.3
Optimizer created (lr=0.0001)
GlobalDatasetTrainer initialized on device: cuda
Model parameters: 1,876,555
Starting training...
========================================
Starting Global Dataset Training...
============================================================

🌍 Updating global dataset at epoch 1
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.091 ± 0.011
    Neg distances: 0.091 ± 0.011
    Separation ratio: 1.00x
    Gap: -0.137
    ❌ Poor global separation

Epoch 1 Training
----------------------------------------
Batch   0/537: Loss=0.9998 (C:0.9998, R:0.0117)
Batch  25/537: Loss=0.9950 (C:0.9950, R:0.0115)
Batch  50/537: Loss=0.9888 (C:0.9888, R:0.0113)
Batch  75/537: Loss=0.9865 (C:0.9865, R:0.0111)
Batch 100/537: Loss=0.9821 (C:0.9821, R:0.0110)
Batch 125/537: Loss=0.9790 (C:0.9790, R:0.0109)
Batch 150/537: Loss=0.9698 (C:0.9698, R:0.0108)
Batch 175/537: Loss=0.9686 (C:0.9686, R:0.0108)
Batch 200/537: Loss=0.9614 (C:0.9614, R:0.0107)
Batch 225/537: Loss=0.9629 (C:0.9629, R:0.0107)
Batch 250/537: Loss=0.9551 (C:0.9551, R:0.0106)
Batch 275/537: Loss=0.9563 (C:0.9563, R:0.0106)
Batch 300/537: Loss=0.9557 (C:0.9557, R:0.0106)
Batch 325/537: Loss=0.9571 (C:0.9571, R:0.0106)
Batch 350/537: Loss=0.9572 (C:0.9572, R:0.0106)
Batch 375/537: Loss=0.9521 (C:0.9521, R:0.0106)
Batch 400/537: Loss=0.9546 (C:0.9546, R:0.0106)
Batch 425/537: Loss=0.9492 (C:0.9492, R:0.0106)
Batch 450/537: Loss=0.9522 (C:0.9522, R:0.0106)
Batch 475/537: Loss=0.9427 (C:0.9427, R:0.0105)
Batch 500/537: Loss=0.9514 (C:0.9514, R:0.0105)
Batch 525/537: Loss=0.9467 (C:0.9467, R:0.0106)

============================================================
Epoch 1/300 completed in 37.7s
Train: Loss=0.9637 (C:0.9637, R:0.0108) Ratio=1.65x
Val:   Loss=0.9432 (C:0.9432, R:0.0105) Ratio=2.19x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.9432)
============================================================

🌍 Updating global dataset at epoch 2
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.336 ± 0.285
    Neg distances: 0.748 ± 0.430
    Separation ratio: 2.22x
    Gap: -1.832
    ✅ Good global separation

Epoch 2 Training
----------------------------------------
Batch   0/537: Loss=0.6827 (C:0.6827, R:0.0106)
Batch  25/537: Loss=0.6827 (C:0.6827, R:0.0106)
Batch  50/537: Loss=0.6665 (C:0.6665, R:0.0105)
Batch  75/537: Loss=0.6795 (C:0.6795, R:0.0105)
Batch 100/537: Loss=0.6781 (C:0.6781, R:0.0105)
Batch 125/537: Loss=0.6707 (C:0.6707, R:0.0105)
Batch 150/537: Loss=0.6689 (C:0.6689, R:0.0105)
Batch 175/537: Loss=0.6759 (C:0.6759, R:0.0105)
Batch 200/537: Loss=0.6704 (C:0.6704, R:0.0105)
Batch 225/537: Loss=0.6585 (C:0.6585, R:0.0105)
Batch 250/537: Loss=0.6576 (C:0.6576, R:0.0105)
Batch 275/537: Loss=0.6744 (C:0.6744, R:0.0105)
Batch 300/537: Loss=0.6600 (C:0.6600, R:0.0105)
Batch 325/537: Loss=0.6621 (C:0.6621, R:0.0105)
Batch 350/537: Loss=0.6824 (C:0.6824, R:0.0105)
Batch 375/537: Loss=0.6635 (C:0.6635, R:0.0105)
Batch 400/537: Loss=0.6659 (C:0.6659, R:0.0105)
Batch 425/537: Loss=0.6600 (C:0.6600, R:0.0105)
Batch 450/537: Loss=0.6760 (C:0.6760, R:0.0105)
Batch 475/537: Loss=0.6603 (C:0.6603, R:0.0105)
Batch 500/537: Loss=0.6494 (C:0.6494, R:0.0105)
Batch 525/537: Loss=0.6500 (C:0.6500, R:0.0105)

============================================================
Epoch 2/300 completed in 28.1s
Train: Loss=0.6699 (C:0.6699, R:0.0105) Ratio=2.24x
Val:   Loss=0.6564 (C:0.6564, R:0.0104) Ratio=2.44x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.6564)
============================================================

🌍 Updating global dataset at epoch 3
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.297 ± 0.281
    Neg distances: 0.773 ± 0.430
    Separation ratio: 2.60x
    Gap: -1.777
    ✅ Good global separation

Epoch 3 Training
----------------------------------------
Batch   0/537: Loss=0.6167 (C:0.6167, R:0.0105)
Batch  25/537: Loss=0.6082 (C:0.6082, R:0.0105)
Batch  50/537: Loss=0.6059 (C:0.6059, R:0.0105)
Batch  75/537: Loss=0.6080 (C:0.6080, R:0.0105)
Batch 100/537: Loss=0.6055 (C:0.6055, R:0.0105)
Batch 125/537: Loss=0.6144 (C:0.6144, R:0.0105)
Batch 150/537: Loss=0.6257 (C:0.6257, R:0.0105)
Batch 175/537: Loss=0.6143 (C:0.6143, R:0.0106)
Batch 200/537: Loss=0.6321 (C:0.6321, R:0.0104)
Batch 225/537: Loss=0.6282 (C:0.6282, R:0.0105)
Batch 250/537: Loss=0.6104 (C:0.6104, R:0.0105)
Batch 275/537: Loss=0.6289 (C:0.6289, R:0.0105)
Batch 300/537: Loss=0.6294 (C:0.6294, R:0.0105)
Batch 325/537: Loss=0.6322 (C:0.6322, R:0.0105)
Batch 350/537: Loss=0.6352 (C:0.6352, R:0.0105)
Batch 375/537: Loss=0.6178 (C:0.6178, R:0.0105)
Batch 400/537: Loss=0.6087 (C:0.6087, R:0.0105)
Batch 425/537: Loss=0.5981 (C:0.5981, R:0.0105)
Batch 450/537: Loss=0.6015 (C:0.6015, R:0.0105)
Batch 475/537: Loss=0.6210 (C:0.6210, R:0.0105)
Batch 500/537: Loss=0.6160 (C:0.6160, R:0.0105)
Batch 525/537: Loss=0.6088 (C:0.6088, R:0.0105)

============================================================
Epoch 3/300 completed in 28.7s
Train: Loss=0.6192 (C:0.6192, R:0.0105) Ratio=2.51x
Val:   Loss=0.6140 (C:0.6140, R:0.0104) Ratio=2.62x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.6140)
============================================================

🌍 Updating global dataset at epoch 4
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.281 ± 0.283
    Neg distances: 0.798 ± 0.431
    Separation ratio: 2.84x
    Gap: -1.752
    ✅ Good global separation

Epoch 4 Training
----------------------------------------
Batch   0/537: Loss=0.5868 (C:0.5868, R:0.0105)
Batch  25/537: Loss=0.5927 (C:0.5927, R:0.0105)
Batch  50/537: Loss=0.5893 (C:0.5893, R:0.0105)
Batch  75/537: Loss=0.6036 (C:0.6036, R:0.0105)
Batch 100/537: Loss=0.5889 (C:0.5889, R:0.0105)
Batch 125/537: Loss=0.5900 (C:0.5900, R:0.0105)
Batch 150/537: Loss=0.5866 (C:0.5866, R:0.0105)
Batch 175/537: Loss=0.5859 (C:0.5859, R:0.0106)
Batch 200/537: Loss=0.5869 (C:0.5869, R:0.0105)
Batch 225/537: Loss=0.5816 (C:0.5816, R:0.0105)
Batch 250/537: Loss=0.5928 (C:0.5928, R:0.0105)
Batch 275/537: Loss=0.5991 (C:0.5991, R:0.0105)
Batch 300/537: Loss=0.6024 (C:0.6024, R:0.0105)
Batch 325/537: Loss=0.5685 (C:0.5685, R:0.0105)
Batch 350/537: Loss=0.5916 (C:0.5916, R:0.0105)
Batch 375/537: Loss=0.5892 (C:0.5892, R:0.0105)
Batch 400/537: Loss=0.5792 (C:0.5792, R:0.0105)
Batch 425/537: Loss=0.5809 (C:0.5809, R:0.0105)
Batch 450/537: Loss=0.5887 (C:0.5887, R:0.0105)
Batch 475/537: Loss=0.5885 (C:0.5885, R:0.0105)
Batch 500/537: Loss=0.5785 (C:0.5785, R:0.0105)
Batch 525/537: Loss=0.5977 (C:0.5977, R:0.0105)

============================================================
Epoch 4/300 completed in 27.2s
Train: Loss=0.5906 (C:0.5906, R:0.0105) Ratio=2.67x
Val:   Loss=0.5822 (C:0.5822, R:0.0104) Ratio=2.70x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.5822)
============================================================

🌍 Updating global dataset at epoch 5
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.269 ± 0.292
    Neg distances: 0.835 ± 0.438
    Separation ratio: 3.10x
    Gap: -1.707
    ✅ Excellent global separation!

Epoch 5 Training
----------------------------------------
Batch   0/537: Loss=0.5689 (C:0.5689, R:0.0105)
Batch  25/537: Loss=0.5680 (C:0.5680, R:0.0105)
Batch  50/537: Loss=0.5654 (C:0.5654, R:0.0105)
Batch  75/537: Loss=0.5713 (C:0.5713, R:0.0105)
Batch 100/537: Loss=0.5601 (C:0.5601, R:0.0105)
Batch 125/537: Loss=0.5546 (C:0.5546, R:0.0105)
Batch 150/537: Loss=0.5659 (C:0.5659, R:0.0105)
Batch 175/537: Loss=0.5590 (C:0.5590, R:0.0105)
Batch 200/537: Loss=0.5640 (C:0.5640, R:0.0105)
Batch 225/537: Loss=0.5561 (C:0.5561, R:0.0105)
Batch 250/537: Loss=0.5747 (C:0.5747, R:0.0105)
Batch 275/537: Loss=0.5667 (C:0.5667, R:0.0105)
Batch 300/537: Loss=0.5678 (C:0.5678, R:0.0105)
Batch 325/537: Loss=0.5601 (C:0.5601, R:0.0105)
Batch 350/537: Loss=0.5717 (C:0.5717, R:0.0105)
Batch 375/537: Loss=0.5633 (C:0.5633, R:0.0105)
Batch 400/537: Loss=0.5626 (C:0.5626, R:0.0105)
Batch 425/537: Loss=0.5636 (C:0.5636, R:0.0105)
Batch 450/537: Loss=0.5651 (C:0.5651, R:0.0105)
Batch 475/537: Loss=0.5606 (C:0.5606, R:0.0105)
Batch 500/537: Loss=0.5461 (C:0.5461, R:0.0105)
Batch 525/537: Loss=0.5550 (C:0.5550, R:0.0105)

============================================================
Epoch 5/300 completed in 26.9s
Train: Loss=0.5648 (C:0.5648, R:0.0105) Ratio=2.78x
Val:   Loss=0.5677 (C:0.5677, R:0.0104) Ratio=2.77x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.5677)
============================================================

🌍 Updating global dataset at epoch 6
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.262 ± 0.289
    Neg distances: 0.873 ± 0.451
    Separation ratio: 3.33x
    Gap: -1.669
    ✅ Excellent global separation!

Epoch 6 Training
----------------------------------------
Batch   0/537: Loss=0.5442 (C:0.5442, R:0.0105)
Batch  25/537: Loss=0.5354 (C:0.5354, R:0.0105)
Batch  50/537: Loss=0.5547 (C:0.5547, R:0.0105)
Batch  75/537: Loss=0.5458 (C:0.5458, R:0.0105)
Batch 100/537: Loss=0.5549 (C:0.5549, R:0.0105)
Batch 125/537: Loss=0.5227 (C:0.5227, R:0.0105)
Batch 150/537: Loss=0.5696 (C:0.5696, R:0.0105)
Batch 175/537: Loss=0.5444 (C:0.5444, R:0.0106)
Batch 200/537: Loss=0.5593 (C:0.5593, R:0.0105)
Batch 225/537: Loss=0.5450 (C:0.5450, R:0.0105)
Batch 250/537: Loss=0.5378 (C:0.5378, R:0.0105)
Batch 275/537: Loss=0.5561 (C:0.5561, R:0.0105)
Batch 300/537: Loss=0.5558 (C:0.5558, R:0.0105)
Batch 325/537: Loss=0.5449 (C:0.5449, R:0.0105)
Batch 350/537: Loss=0.5433 (C:0.5433, R:0.0105)
Batch 375/537: Loss=0.5391 (C:0.5391, R:0.0105)
Batch 400/537: Loss=0.5589 (C:0.5589, R:0.0105)
Batch 425/537: Loss=0.5450 (C:0.5450, R:0.0105)
Batch 450/537: Loss=0.5473 (C:0.5473, R:0.0105)
Batch 475/537: Loss=0.5641 (C:0.5641, R:0.0105)
Batch 500/537: Loss=0.5371 (C:0.5371, R:0.0105)
Batch 525/537: Loss=0.5502 (C:0.5502, R:0.0105)

============================================================
Epoch 6/300 completed in 27.5s
Train: Loss=0.5449 (C:0.5449, R:0.0105) Ratio=2.86x
Val:   Loss=0.5479 (C:0.5479, R:0.0104) Ratio=2.83x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.5479)
============================================================

🌍 Updating global dataset at epoch 7
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.258 ± 0.292
    Neg distances: 0.890 ± 0.453
    Separation ratio: 3.46x
    Gap: -1.636
    ✅ Excellent global separation!

Epoch 7 Training
----------------------------------------
Batch   0/537: Loss=0.5356 (C:0.5356, R:0.0105)
Batch  25/537: Loss=0.5371 (C:0.5371, R:0.0105)
Batch  50/537: Loss=0.5307 (C:0.5307, R:0.0105)
Batch  75/537: Loss=0.5255 (C:0.5255, R:0.0105)
Batch 100/537: Loss=0.5237 (C:0.5237, R:0.0105)
Batch 125/537: Loss=0.5233 (C:0.5233, R:0.0105)
Batch 150/537: Loss=0.5374 (C:0.5374, R:0.0105)
Batch 175/537: Loss=0.5263 (C:0.5263, R:0.0105)
Batch 200/537: Loss=0.5388 (C:0.5388, R:0.0105)
Batch 225/537: Loss=0.5240 (C:0.5240, R:0.0105)
Batch 250/537: Loss=0.5304 (C:0.5304, R:0.0105)
Batch 275/537: Loss=0.5310 (C:0.5310, R:0.0105)
Batch 300/537: Loss=0.5252 (C:0.5252, R:0.0105)
Batch 325/537: Loss=0.5340 (C:0.5340, R:0.0106)
Batch 350/537: Loss=0.5185 (C:0.5185, R:0.0105)
Batch 375/537: Loss=0.5273 (C:0.5273, R:0.0105)
Batch 400/537: Loss=0.5330 (C:0.5330, R:0.0105)
Batch 425/537: Loss=0.5176 (C:0.5176, R:0.0105)
Batch 450/537: Loss=0.5448 (C:0.5448, R:0.0105)
Batch 475/537: Loss=0.5209 (C:0.5209, R:0.0105)
Batch 500/537: Loss=0.5270 (C:0.5270, R:0.0105)
Batch 525/537: Loss=0.5285 (C:0.5285, R:0.0105)

============================================================
Epoch 7/300 completed in 27.2s
Train: Loss=0.5309 (C:0.5309, R:0.0105) Ratio=3.03x
Val:   Loss=0.5416 (C:0.5416, R:0.0104) Ratio=2.84x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.5416)
============================================================

🌍 Updating global dataset at epoch 8
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.259 ± 0.298
    Neg distances: 0.907 ± 0.459
    Separation ratio: 3.50x
    Gap: -1.640
    ✅ Excellent global separation!

Epoch 8 Training
----------------------------------------
Batch   0/537: Loss=0.5044 (C:0.5044, R:0.0105)
Batch  25/537: Loss=0.5104 (C:0.5104, R:0.0105)
Batch  50/537: Loss=0.5344 (C:0.5344, R:0.0105)
Batch  75/537: Loss=0.5273 (C:0.5273, R:0.0105)
Batch 100/537: Loss=0.5122 (C:0.5122, R:0.0106)
Batch 125/537: Loss=0.5366 (C:0.5366, R:0.0105)
Batch 150/537: Loss=0.5277 (C:0.5277, R:0.0105)
Batch 175/537: Loss=0.5062 (C:0.5062, R:0.0105)
Batch 200/537: Loss=0.5338 (C:0.5338, R:0.0106)
Batch 225/537: Loss=0.5260 (C:0.5260, R:0.0105)
Batch 250/537: Loss=0.5379 (C:0.5379, R:0.0105)
Batch 275/537: Loss=0.5248 (C:0.5248, R:0.0106)
Batch 300/537: Loss=0.5248 (C:0.5248, R:0.0105)
Batch 325/537: Loss=0.5151 (C:0.5151, R:0.0105)
Batch 350/537: Loss=0.5406 (C:0.5406, R:0.0106)
Batch 375/537: Loss=0.5386 (C:0.5386, R:0.0105)
Batch 400/537: Loss=0.5220 (C:0.5220, R:0.0105)
Batch 425/537: Loss=0.5392 (C:0.5392, R:0.0105)
Batch 450/537: Loss=0.5151 (C:0.5151, R:0.0105)
Batch 475/537: Loss=0.5246 (C:0.5246, R:0.0105)
Batch 500/537: Loss=0.5264 (C:0.5264, R:0.0105)
Batch 525/537: Loss=0.5439 (C:0.5439, R:0.0105)

============================================================
Epoch 8/300 completed in 27.2s
Train: Loss=0.5244 (C:0.5244, R:0.0105) Ratio=3.07x
Val:   Loss=0.5361 (C:0.5361, R:0.0104) Ratio=2.88x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.5361)
============================================================

🌍 Updating global dataset at epoch 9
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.253 ± 0.294
    Neg distances: 0.929 ± 0.463
    Separation ratio: 3.67x
    Gap: -1.705
    ✅ Excellent global separation!

Epoch 9 Training
----------------------------------------
Batch   0/537: Loss=0.5065 (C:0.5065, R:0.0105)
Batch  25/537: Loss=0.4989 (C:0.4989, R:0.0105)
Batch  50/537: Loss=0.5132 (C:0.5132, R:0.0105)
Batch  75/537: Loss=0.5288 (C:0.5288, R:0.0105)
Batch 100/537: Loss=0.5105 (C:0.5105, R:0.0105)
Batch 125/537: Loss=0.4990 (C:0.4990, R:0.0105)
Batch 150/537: Loss=0.5063 (C:0.5063, R:0.0106)
Batch 175/537: Loss=0.5018 (C:0.5018, R:0.0105)
Batch 200/537: Loss=0.5015 (C:0.5015, R:0.0105)
Batch 225/537: Loss=0.5040 (C:0.5040, R:0.0105)
Batch 250/537: Loss=0.5021 (C:0.5021, R:0.0105)
Batch 275/537: Loss=0.5010 (C:0.5010, R:0.0106)
Batch 300/537: Loss=0.5068 (C:0.5068, R:0.0105)
Batch 325/537: Loss=0.4954 (C:0.4954, R:0.0105)
Batch 350/537: Loss=0.5099 (C:0.5099, R:0.0105)
Batch 375/537: Loss=0.5179 (C:0.5179, R:0.0105)
Batch 400/537: Loss=0.5093 (C:0.5093, R:0.0105)
Batch 425/537: Loss=0.5151 (C:0.5151, R:0.0105)
Batch 450/537: Loss=0.5044 (C:0.5044, R:0.0105)
Batch 475/537: Loss=0.5184 (C:0.5184, R:0.0105)
Batch 500/537: Loss=0.5179 (C:0.5179, R:0.0105)
Batch 525/537: Loss=0.5216 (C:0.5216, R:0.0105)

============================================================
Epoch 9/300 completed in 27.0s
Train: Loss=0.5096 (C:0.5096, R:0.0105) Ratio=3.16x
Val:   Loss=0.5235 (C:0.5235, R:0.0104) Ratio=2.92x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.5235)
============================================================

🌍 Updating global dataset at epoch 10
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.251 ± 0.304
    Neg distances: 0.956 ± 0.470
    Separation ratio: 3.80x
    Gap: -1.758
    ✅ Excellent global separation!

Epoch 10 Training
----------------------------------------
Batch   0/537: Loss=0.4904 (C:0.4904, R:0.0105)
Batch  25/537: Loss=0.4962 (C:0.4962, R:0.0105)
Batch  50/537: Loss=0.4956 (C:0.4956, R:0.0105)
Batch  75/537: Loss=0.4904 (C:0.4904, R:0.0105)
Batch 100/537: Loss=0.4808 (C:0.4808, R:0.0105)
Batch 125/537: Loss=0.4973 (C:0.4973, R:0.0105)
Batch 150/537: Loss=0.4776 (C:0.4776, R:0.0105)
Batch 175/537: Loss=0.4871 (C:0.4871, R:0.0105)
Batch 200/537: Loss=0.4877 (C:0.4877, R:0.0105)
Batch 225/537: Loss=0.5000 (C:0.5000, R:0.0105)
Batch 250/537: Loss=0.5000 (C:0.5000, R:0.0105)
Batch 275/537: Loss=0.4886 (C:0.4886, R:0.0105)
Batch 300/537: Loss=0.4903 (C:0.4903, R:0.0105)
Batch 325/537: Loss=0.4933 (C:0.4933, R:0.0105)
Batch 350/537: Loss=0.4945 (C:0.4945, R:0.0105)
Batch 375/537: Loss=0.4981 (C:0.4981, R:0.0105)
Batch 400/537: Loss=0.5080 (C:0.5080, R:0.0105)
Batch 425/537: Loss=0.4780 (C:0.4780, R:0.0105)
Batch 450/537: Loss=0.4912 (C:0.4912, R:0.0105)
Batch 475/537: Loss=0.5010 (C:0.5010, R:0.0105)
Batch 500/537: Loss=0.4958 (C:0.4958, R:0.0105)
Batch 525/537: Loss=0.5012 (C:0.5012, R:0.0105)

============================================================
Epoch 10/300 completed in 27.1s
Train: Loss=0.4972 (C:0.4972, R:0.0105) Ratio=3.26x
Val:   Loss=0.5095 (C:0.5095, R:0.0104) Ratio=2.92x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.5095)
============================================================

🌍 Updating global dataset at epoch 11
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.237 ± 0.295
    Neg distances: 0.987 ± 0.474
    Separation ratio: 4.16x
    Gap: -1.733
    ✅ Excellent global separation!

Epoch 11 Training
----------------------------------------
Batch   0/537: Loss=0.4758 (C:0.4758, R:0.0105)
Batch  25/537: Loss=0.4559 (C:0.4559, R:0.0105)
Batch  50/537: Loss=0.4514 (C:0.4514, R:0.0105)
Batch  75/537: Loss=0.4620 (C:0.4620, R:0.0105)
Batch 100/537: Loss=0.4730 (C:0.4730, R:0.0105)
Batch 125/537: Loss=0.4787 (C:0.4787, R:0.0106)
Batch 150/537: Loss=0.4834 (C:0.4834, R:0.0105)
Batch 175/537: Loss=0.4725 (C:0.4725, R:0.0106)
Batch 200/537: Loss=0.4897 (C:0.4897, R:0.0105)
Batch 225/537: Loss=0.4638 (C:0.4638, R:0.0105)
Batch 250/537: Loss=0.4686 (C:0.4686, R:0.0105)
Batch 275/537: Loss=0.4907 (C:0.4907, R:0.0105)
Batch 300/537: Loss=0.4604 (C:0.4604, R:0.0105)
Batch 325/537: Loss=0.4573 (C:0.4573, R:0.0105)
Batch 350/537: Loss=0.4635 (C:0.4635, R:0.0105)
Batch 375/537: Loss=0.4699 (C:0.4699, R:0.0105)
Batch 400/537: Loss=0.4670 (C:0.4670, R:0.0105)
Batch 425/537: Loss=0.4652 (C:0.4652, R:0.0105)
Batch 450/537: Loss=0.4782 (C:0.4782, R:0.0105)
Batch 475/537: Loss=0.4692 (C:0.4692, R:0.0106)
Batch 500/537: Loss=0.4676 (C:0.4676, R:0.0105)
Batch 525/537: Loss=0.4758 (C:0.4758, R:0.0105)

============================================================
Epoch 11/300 completed in 26.9s
Train: Loss=0.4764 (C:0.4764, R:0.0105) Ratio=3.33x
Val:   Loss=0.4943 (C:0.4943, R:0.0104) Ratio=2.93x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4943)
============================================================

🌍 Updating global dataset at epoch 12
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.245 ± 0.301
    Neg distances: 1.010 ± 0.487
    Separation ratio: 4.13x
    Gap: -1.799
    ✅ Excellent global separation!

Epoch 12 Training
----------------------------------------
Batch   0/537: Loss=0.4874 (C:0.4874, R:0.0105)
Batch  25/537: Loss=0.4713 (C:0.4713, R:0.0105)
Batch  50/537: Loss=0.4741 (C:0.4741, R:0.0105)
Batch  75/537: Loss=0.4634 (C:0.4634, R:0.0105)
Batch 100/537: Loss=0.4761 (C:0.4761, R:0.0105)
Batch 125/537: Loss=0.4858 (C:0.4858, R:0.0105)
Batch 150/537: Loss=0.4570 (C:0.4570, R:0.0105)
Batch 175/537: Loss=0.4716 (C:0.4716, R:0.0105)
Batch 200/537: Loss=0.4691 (C:0.4691, R:0.0105)
Batch 225/537: Loss=0.4520 (C:0.4520, R:0.0105)
Batch 250/537: Loss=0.4531 (C:0.4531, R:0.0105)
Batch 275/537: Loss=0.4790 (C:0.4790, R:0.0105)
Batch 300/537: Loss=0.4649 (C:0.4649, R:0.0105)
Batch 325/537: Loss=0.4715 (C:0.4715, R:0.0105)
Batch 350/537: Loss=0.4696 (C:0.4696, R:0.0105)
Batch 375/537: Loss=0.4651 (C:0.4651, R:0.0105)
Batch 400/537: Loss=0.4315 (C:0.4315, R:0.0105)
Batch 425/537: Loss=0.4712 (C:0.4712, R:0.0105)
Batch 450/537: Loss=0.4611 (C:0.4611, R:0.0105)
Batch 475/537: Loss=0.4683 (C:0.4683, R:0.0105)
Batch 500/537: Loss=0.4773 (C:0.4773, R:0.0105)
Batch 525/537: Loss=0.4707 (C:0.4707, R:0.0105)

============================================================
Epoch 12/300 completed in 27.1s
Train: Loss=0.4733 (C:0.4733, R:0.0105) Ratio=3.40x
Val:   Loss=0.4909 (C:0.4909, R:0.0104) Ratio=2.96x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4909)
============================================================

🌍 Updating global dataset at epoch 13
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.239 ± 0.305
    Neg distances: 1.025 ± 0.486
    Separation ratio: 4.29x
    Gap: -1.806
    ✅ Excellent global separation!

Epoch 13 Training
----------------------------------------
Batch   0/537: Loss=0.4432 (C:0.4432, R:0.0105)
Batch  25/537: Loss=0.4550 (C:0.4550, R:0.0105)
Batch  50/537: Loss=0.4525 (C:0.4525, R:0.0105)
Batch  75/537: Loss=0.4548 (C:0.4548, R:0.0105)
Batch 100/537: Loss=0.4510 (C:0.4510, R:0.0105)
Batch 125/537: Loss=0.4582 (C:0.4582, R:0.0105)
Batch 150/537: Loss=0.4605 (C:0.4605, R:0.0105)
Batch 175/537: Loss=0.4460 (C:0.4460, R:0.0105)
Batch 200/537: Loss=0.4462 (C:0.4462, R:0.0105)
Batch 225/537: Loss=0.4607 (C:0.4607, R:0.0105)
Batch 250/537: Loss=0.4689 (C:0.4689, R:0.0105)
Batch 275/537: Loss=0.4407 (C:0.4407, R:0.0105)
Batch 300/537: Loss=0.4527 (C:0.4527, R:0.0105)
Batch 325/537: Loss=0.4458 (C:0.4458, R:0.0105)
Batch 350/537: Loss=0.4763 (C:0.4763, R:0.0105)
Batch 375/537: Loss=0.4633 (C:0.4633, R:0.0105)
Batch 400/537: Loss=0.4509 (C:0.4509, R:0.0105)
Batch 425/537: Loss=0.4716 (C:0.4716, R:0.0105)
Batch 450/537: Loss=0.4686 (C:0.4686, R:0.0105)
Batch 475/537: Loss=0.4558 (C:0.4558, R:0.0105)
Batch 500/537: Loss=0.4757 (C:0.4757, R:0.0105)
Batch 525/537: Loss=0.4528 (C:0.4528, R:0.0105)

============================================================
Epoch 13/300 completed in 27.2s
Train: Loss=0.4611 (C:0.4611, R:0.0105) Ratio=3.45x
Val:   Loss=0.4811 (C:0.4811, R:0.0104) Ratio=2.98x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4811)
============================================================

🌍 Updating global dataset at epoch 14
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.239 ± 0.304
    Neg distances: 1.045 ± 0.497
    Separation ratio: 4.37x
    Gap: -1.850
    ✅ Excellent global separation!

Epoch 14 Training
----------------------------------------
Batch   0/537: Loss=0.4579 (C:0.4579, R:0.0105)
Batch  25/537: Loss=0.4612 (C:0.4612, R:0.0105)
Batch  50/537: Loss=0.4242 (C:0.4242, R:0.0105)
Batch  75/537: Loss=0.4475 (C:0.4475, R:0.0105)
Batch 100/537: Loss=0.4575 (C:0.4575, R:0.0105)
Batch 125/537: Loss=0.4462 (C:0.4462, R:0.0105)
Batch 150/537: Loss=0.4579 (C:0.4579, R:0.0105)
Batch 175/537: Loss=0.4564 (C:0.4564, R:0.0105)
Batch 200/537: Loss=0.4549 (C:0.4549, R:0.0105)
Batch 225/537: Loss=0.4429 (C:0.4429, R:0.0105)
Batch 250/537: Loss=0.4649 (C:0.4649, R:0.0105)
Batch 275/537: Loss=0.4442 (C:0.4442, R:0.0105)
Batch 300/537: Loss=0.4598 (C:0.4598, R:0.0105)
Batch 325/537: Loss=0.4412 (C:0.4412, R:0.0105)
Batch 350/537: Loss=0.4618 (C:0.4618, R:0.0105)
Batch 375/537: Loss=0.4441 (C:0.4441, R:0.0105)
Batch 400/537: Loss=0.4599 (C:0.4599, R:0.0105)
Batch 425/537: Loss=0.4421 (C:0.4421, R:0.0105)
Batch 450/537: Loss=0.4528 (C:0.4528, R:0.0105)
Batch 475/537: Loss=0.4549 (C:0.4549, R:0.0105)
Batch 500/537: Loss=0.4644 (C:0.4644, R:0.0105)
Batch 525/537: Loss=0.4527 (C:0.4527, R:0.0105)

============================================================
Epoch 14/300 completed in 27.6s
Train: Loss=0.4543 (C:0.4543, R:0.0105) Ratio=3.51x
Val:   Loss=0.4773 (C:0.4773, R:0.0104) Ratio=2.99x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4773)
============================================================

🌍 Updating global dataset at epoch 15
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.246 ± 0.316
    Neg distances: 1.057 ± 0.502
    Separation ratio: 4.30x
    Gap: -1.867
    ✅ Excellent global separation!

Epoch 15 Training
----------------------------------------
Batch   0/537: Loss=0.4566 (C:0.4566, R:0.0105)
Batch  25/537: Loss=0.4399 (C:0.4399, R:0.0105)
Batch  50/537: Loss=0.4418 (C:0.4418, R:0.0105)
Batch  75/537: Loss=0.4605 (C:0.4605, R:0.0105)
Batch 100/537: Loss=0.4542 (C:0.4542, R:0.0105)
Batch 125/537: Loss=0.4342 (C:0.4342, R:0.0105)
Batch 150/537: Loss=0.4483 (C:0.4483, R:0.0105)
Batch 175/537: Loss=0.4544 (C:0.4544, R:0.0106)
Batch 200/537: Loss=0.4488 (C:0.4488, R:0.0105)
Batch 225/537: Loss=0.4612 (C:0.4612, R:0.0105)
Batch 250/537: Loss=0.4552 (C:0.4552, R:0.0105)
Batch 275/537: Loss=0.4408 (C:0.4408, R:0.0105)
Batch 300/537: Loss=0.4418 (C:0.4418, R:0.0105)
Batch 325/537: Loss=0.4480 (C:0.4480, R:0.0105)
Batch 350/537: Loss=0.4621 (C:0.4621, R:0.0105)
Batch 375/537: Loss=0.4477 (C:0.4477, R:0.0105)
Batch 400/537: Loss=0.4651 (C:0.4651, R:0.0105)
Batch 425/537: Loss=0.4390 (C:0.4390, R:0.0106)
Batch 450/537: Loss=0.4361 (C:0.4361, R:0.0105)
Batch 475/537: Loss=0.4655 (C:0.4655, R:0.0105)
Batch 500/537: Loss=0.4637 (C:0.4637, R:0.0106)
Batch 525/537: Loss=0.4584 (C:0.4584, R:0.0105)

============================================================
Epoch 15/300 completed in 27.5s
Train: Loss=0.4518 (C:0.4518, R:0.0105) Ratio=3.52x
Val:   Loss=0.4759 (C:0.4759, R:0.0104) Ratio=3.01x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4759)
============================================================

🌍 Updating global dataset at epoch 16
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.245 ± 0.319
    Neg distances: 1.095 ± 0.515
    Separation ratio: 4.46x
    Gap: -1.922
    ✅ Excellent global separation!

Epoch 16 Training
----------------------------------------
Batch   0/537: Loss=0.4383 (C:0.4383, R:0.0105)
Batch  25/537: Loss=0.4502 (C:0.4502, R:0.0105)
Batch  50/537: Loss=0.4368 (C:0.4368, R:0.0105)
Batch  75/537: Loss=0.4529 (C:0.4529, R:0.0105)
Batch 100/537: Loss=0.4427 (C:0.4427, R:0.0105)
Batch 125/537: Loss=0.4162 (C:0.4162, R:0.0105)
Batch 150/537: Loss=0.4434 (C:0.4434, R:0.0105)
Batch 175/537: Loss=0.4431 (C:0.4431, R:0.0105)
Batch 200/537: Loss=0.4471 (C:0.4471, R:0.0105)
Batch 225/537: Loss=0.4583 (C:0.4583, R:0.0105)
Batch 250/537: Loss=0.4280 (C:0.4280, R:0.0105)
Batch 275/537: Loss=0.4619 (C:0.4619, R:0.0105)
Batch 300/537: Loss=0.4220 (C:0.4220, R:0.0105)
Batch 325/537: Loss=0.4348 (C:0.4348, R:0.0105)
Batch 350/537: Loss=0.4624 (C:0.4624, R:0.0105)
Batch 375/537: Loss=0.4522 (C:0.4522, R:0.0105)
Batch 400/537: Loss=0.4463 (C:0.4463, R:0.0105)
Batch 425/537: Loss=0.4334 (C:0.4334, R:0.0106)
Batch 450/537: Loss=0.4583 (C:0.4583, R:0.0105)
Batch 475/537: Loss=0.4511 (C:0.4511, R:0.0105)
Batch 500/537: Loss=0.4490 (C:0.4490, R:0.0105)
Batch 525/537: Loss=0.4407 (C:0.4407, R:0.0105)

============================================================
Epoch 16/300 completed in 28.3s
Train: Loss=0.4410 (C:0.4410, R:0.0105) Ratio=3.57x
Val:   Loss=0.4668 (C:0.4668, R:0.0104) Ratio=2.98x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4668)
============================================================

🌍 Updating global dataset at epoch 17
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.238 ± 0.312
    Neg distances: 1.107 ± 0.514
    Separation ratio: 4.66x
    Gap: -1.919
    ✅ Excellent global separation!

Epoch 17 Training
----------------------------------------
Batch   0/537: Loss=0.4303 (C:0.4303, R:0.0105)
Batch  25/537: Loss=0.4292 (C:0.4292, R:0.0105)
Batch  50/537: Loss=0.4394 (C:0.4394, R:0.0105)
Batch  75/537: Loss=0.4297 (C:0.4297, R:0.0106)
Batch 100/537: Loss=0.4175 (C:0.4175, R:0.0105)
Batch 125/537: Loss=0.4303 (C:0.4303, R:0.0105)
Batch 150/537: Loss=0.4211 (C:0.4211, R:0.0105)
Batch 175/537: Loss=0.4238 (C:0.4238, R:0.0105)
Batch 200/537: Loss=0.4244 (C:0.4244, R:0.0104)
Batch 225/537: Loss=0.4489 (C:0.4489, R:0.0105)
Batch 250/537: Loss=0.4326 (C:0.4326, R:0.0105)
Batch 275/537: Loss=0.4320 (C:0.4320, R:0.0105)
Batch 300/537: Loss=0.4288 (C:0.4288, R:0.0105)
Batch 325/537: Loss=0.4238 (C:0.4238, R:0.0105)
Batch 350/537: Loss=0.4302 (C:0.4302, R:0.0105)
Batch 375/537: Loss=0.4415 (C:0.4415, R:0.0105)
Batch 400/537: Loss=0.4405 (C:0.4405, R:0.0105)
Batch 425/537: Loss=0.4205 (C:0.4205, R:0.0106)
Batch 450/537: Loss=0.4061 (C:0.4061, R:0.0105)
Batch 475/537: Loss=0.4325 (C:0.4325, R:0.0105)
Batch 500/537: Loss=0.4289 (C:0.4289, R:0.0105)
Batch 525/537: Loss=0.4304 (C:0.4304, R:0.0105)

============================================================
Epoch 17/300 completed in 28.3s
Train: Loss=0.4289 (C:0.4289, R:0.0105) Ratio=3.59x
Val:   Loss=0.4574 (C:0.4574, R:0.0104) Ratio=3.03x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4574)
============================================================

🌍 Updating global dataset at epoch 18
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.244 ± 0.312
    Neg distances: 1.110 ± 0.519
    Separation ratio: 4.55x
    Gap: -1.961
    ✅ Excellent global separation!

Epoch 18 Training
----------------------------------------
Batch   0/537: Loss=0.4034 (C:0.4034, R:0.0105)
Batch  25/537: Loss=0.4197 (C:0.4197, R:0.0105)
Batch  50/537: Loss=0.4227 (C:0.4227, R:0.0105)
Batch  75/537: Loss=0.4196 (C:0.4196, R:0.0105)
Batch 100/537: Loss=0.4282 (C:0.4282, R:0.0106)
Batch 125/537: Loss=0.4330 (C:0.4330, R:0.0105)
Batch 150/537: Loss=0.4222 (C:0.4222, R:0.0105)
Batch 175/537: Loss=0.4365 (C:0.4365, R:0.0105)
Batch 200/537: Loss=0.4205 (C:0.4205, R:0.0105)
Batch 225/537: Loss=0.4381 (C:0.4381, R:0.0105)
Batch 250/537: Loss=0.4371 (C:0.4371, R:0.0105)
Batch 275/537: Loss=0.4240 (C:0.4240, R:0.0105)
Batch 300/537: Loss=0.4366 (C:0.4366, R:0.0105)
Batch 325/537: Loss=0.4321 (C:0.4321, R:0.0105)
Batch 350/537: Loss=0.4457 (C:0.4457, R:0.0105)
Batch 375/537: Loss=0.4322 (C:0.4322, R:0.0105)
Batch 400/537: Loss=0.4416 (C:0.4416, R:0.0105)
Batch 425/537: Loss=0.4139 (C:0.4139, R:0.0105)
Batch 450/537: Loss=0.4493 (C:0.4493, R:0.0105)
Batch 475/537: Loss=0.4367 (C:0.4367, R:0.0105)
Batch 500/537: Loss=0.4396 (C:0.4396, R:0.0105)
Batch 525/537: Loss=0.4482 (C:0.4482, R:0.0105)

============================================================
Epoch 18/300 completed in 28.1s
Train: Loss=0.4299 (C:0.4299, R:0.0105) Ratio=3.64x
Val:   Loss=0.4591 (C:0.4591, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 19
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.228 ± 0.303
    Neg distances: 1.119 ± 0.514
    Separation ratio: 4.91x
    Gap: -1.957
    ✅ Excellent global separation!

Epoch 19 Training
----------------------------------------
Batch   0/537: Loss=0.4169 (C:0.4169, R:0.0105)
Batch  25/537: Loss=0.3974 (C:0.3974, R:0.0105)
Batch  50/537: Loss=0.4052 (C:0.4052, R:0.0106)
Batch  75/537: Loss=0.3949 (C:0.3949, R:0.0105)
Batch 100/537: Loss=0.4150 (C:0.4150, R:0.0105)
Batch 125/537: Loss=0.3998 (C:0.3998, R:0.0105)
Batch 150/537: Loss=0.4179 (C:0.4179, R:0.0105)
Batch 175/537: Loss=0.4104 (C:0.4104, R:0.0105)
Batch 200/537: Loss=0.4275 (C:0.4275, R:0.0105)
Batch 225/537: Loss=0.4107 (C:0.4107, R:0.0105)
Batch 250/537: Loss=0.4162 (C:0.4162, R:0.0105)
Batch 275/537: Loss=0.4136 (C:0.4136, R:0.0105)
Batch 300/537: Loss=0.4227 (C:0.4227, R:0.0105)
Batch 325/537: Loss=0.4335 (C:0.4335, R:0.0105)
Batch 350/537: Loss=0.4087 (C:0.4087, R:0.0105)
Batch 375/537: Loss=0.4034 (C:0.4034, R:0.0105)
Batch 400/537: Loss=0.4158 (C:0.4158, R:0.0105)
Batch 425/537: Loss=0.4278 (C:0.4278, R:0.0105)
Batch 450/537: Loss=0.4210 (C:0.4210, R:0.0106)
Batch 475/537: Loss=0.4291 (C:0.4291, R:0.0105)
Batch 500/537: Loss=0.4240 (C:0.4240, R:0.0105)
Batch 525/537: Loss=0.4305 (C:0.4305, R:0.0105)

============================================================
Epoch 19/300 completed in 27.8s
Train: Loss=0.4135 (C:0.4135, R:0.0105) Ratio=3.68x
Val:   Loss=0.4465 (C:0.4465, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4465)
============================================================

🌍 Updating global dataset at epoch 20
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.228 ± 0.316
    Neg distances: 1.136 ± 0.518
    Separation ratio: 4.98x
    Gap: -2.015
    ✅ Excellent global separation!

Epoch 20 Training
----------------------------------------
Batch   0/537: Loss=0.3957 (C:0.3957, R:0.0105)
Batch  25/537: Loss=0.3995 (C:0.3995, R:0.0105)
Batch  50/537: Loss=0.4204 (C:0.4204, R:0.0105)
Batch  75/537: Loss=0.4040 (C:0.4040, R:0.0105)
Batch 100/537: Loss=0.3985 (C:0.3985, R:0.0105)
Batch 125/537: Loss=0.3929 (C:0.3929, R:0.0105)
Batch 150/537: Loss=0.4072 (C:0.4072, R:0.0105)
Batch 175/537: Loss=0.4175 (C:0.4175, R:0.0105)
Batch 200/537: Loss=0.4085 (C:0.4085, R:0.0106)
Batch 225/537: Loss=0.4253 (C:0.4253, R:0.0105)
Batch 250/537: Loss=0.3959 (C:0.3959, R:0.0105)
Batch 275/537: Loss=0.4076 (C:0.4076, R:0.0105)
Batch 300/537: Loss=0.3855 (C:0.3855, R:0.0105)
Batch 325/537: Loss=0.4274 (C:0.4274, R:0.0105)
Batch 350/537: Loss=0.4140 (C:0.4140, R:0.0105)
Batch 375/537: Loss=0.3900 (C:0.3900, R:0.0105)
Batch 400/537: Loss=0.4040 (C:0.4040, R:0.0105)
Batch 425/537: Loss=0.4169 (C:0.4169, R:0.0105)
Batch 450/537: Loss=0.4182 (C:0.4182, R:0.0105)
Batch 475/537: Loss=0.4061 (C:0.4061, R:0.0105)
Batch 500/537: Loss=0.4017 (C:0.4017, R:0.0106)
Batch 525/537: Loss=0.4108 (C:0.4108, R:0.0105)

============================================================
Epoch 20/300 completed in 28.2s
Train: Loss=0.4073 (C:0.4073, R:0.0105) Ratio=3.77x
Val:   Loss=0.4401 (C:0.4401, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4401)
Checkpoint saved at epoch 20
============================================================

🌍 Updating global dataset at epoch 21
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.222 ± 0.305
    Neg distances: 1.157 ± 0.525
    Separation ratio: 5.21x
    Gap: -1.993
    ✅ Excellent global separation!

Epoch 21 Training
----------------------------------------
Batch   0/537: Loss=0.3935 (C:0.3935, R:0.0105)
Batch  25/537: Loss=0.3955 (C:0.3955, R:0.0105)
Batch  50/537: Loss=0.3863 (C:0.3863, R:0.0105)
Batch  75/537: Loss=0.3949 (C:0.3949, R:0.0105)
Batch 100/537: Loss=0.3806 (C:0.3806, R:0.0105)
Batch 125/537: Loss=0.3933 (C:0.3933, R:0.0105)
Batch 150/537: Loss=0.3975 (C:0.3975, R:0.0105)
Batch 175/537: Loss=0.4190 (C:0.4190, R:0.0105)
Batch 200/537: Loss=0.3969 (C:0.3969, R:0.0105)
Batch 225/537: Loss=0.4056 (C:0.4056, R:0.0105)
Batch 250/537: Loss=0.3979 (C:0.3979, R:0.0105)
Batch 275/537: Loss=0.4006 (C:0.4006, R:0.0105)
Batch 300/537: Loss=0.4147 (C:0.4147, R:0.0105)
Batch 325/537: Loss=0.4094 (C:0.4094, R:0.0105)
Batch 350/537: Loss=0.3986 (C:0.3986, R:0.0105)
Batch 375/537: Loss=0.3986 (C:0.3986, R:0.0105)
Batch 400/537: Loss=0.3796 (C:0.3796, R:0.0105)
Batch 425/537: Loss=0.4057 (C:0.4057, R:0.0105)
Batch 450/537: Loss=0.4054 (C:0.4054, R:0.0105)
Batch 475/537: Loss=0.3985 (C:0.3985, R:0.0105)
Batch 500/537: Loss=0.3869 (C:0.3869, R:0.0105)
Batch 525/537: Loss=0.4113 (C:0.4113, R:0.0105)

============================================================
Epoch 21/300 completed in 27.2s
Train: Loss=0.3980 (C:0.3980, R:0.0105) Ratio=3.75x
Val:   Loss=0.4356 (C:0.4356, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4356)
============================================================

🌍 Updating global dataset at epoch 22
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.228 ± 0.322
    Neg distances: 1.174 ± 0.533
    Separation ratio: 5.16x
    Gap: -2.045
    ✅ Excellent global separation!

Epoch 22 Training
----------------------------------------
Batch   0/537: Loss=0.3860 (C:0.3860, R:0.0105)
Batch  25/537: Loss=0.4167 (C:0.4167, R:0.0105)
Batch  50/537: Loss=0.3993 (C:0.3993, R:0.0105)
Batch  75/537: Loss=0.4003 (C:0.4003, R:0.0105)
Batch 100/537: Loss=0.3931 (C:0.3931, R:0.0105)
Batch 125/537: Loss=0.3963 (C:0.3963, R:0.0105)
Batch 150/537: Loss=0.3997 (C:0.3997, R:0.0105)
Batch 175/537: Loss=0.3961 (C:0.3961, R:0.0105)
Batch 200/537: Loss=0.3834 (C:0.3834, R:0.0105)
Batch 225/537: Loss=0.4002 (C:0.4002, R:0.0105)
Batch 250/537: Loss=0.4007 (C:0.4007, R:0.0105)
Batch 275/537: Loss=0.4029 (C:0.4029, R:0.0105)
Batch 300/537: Loss=0.4015 (C:0.4015, R:0.0105)
Batch 325/537: Loss=0.3851 (C:0.3851, R:0.0105)
Batch 350/537: Loss=0.4018 (C:0.4018, R:0.0105)
Batch 375/537: Loss=0.3935 (C:0.3935, R:0.0105)
Batch 400/537: Loss=0.3840 (C:0.3840, R:0.0105)
Batch 425/537: Loss=0.3980 (C:0.3980, R:0.0105)
Batch 450/537: Loss=0.4053 (C:0.4053, R:0.0105)
Batch 475/537: Loss=0.3888 (C:0.3888, R:0.0105)
Batch 500/537: Loss=0.4122 (C:0.4122, R:0.0105)
Batch 525/537: Loss=0.4136 (C:0.4136, R:0.0105)

============================================================
Epoch 22/300 completed in 27.5s
Train: Loss=0.3958 (C:0.3958, R:0.0105) Ratio=3.80x
Val:   Loss=0.4321 (C:0.4321, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4321)
============================================================

🌍 Updating global dataset at epoch 23
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.229 ± 0.315
    Neg distances: 1.175 ± 0.533
    Separation ratio: 5.13x
    Gap: -2.082
    ✅ Excellent global separation!

Epoch 23 Training
----------------------------------------
Batch   0/537: Loss=0.3704 (C:0.3704, R:0.0105)
Batch  25/537: Loss=0.3845 (C:0.3845, R:0.0105)
Batch  50/537: Loss=0.4014 (C:0.4014, R:0.0105)
Batch  75/537: Loss=0.3996 (C:0.3996, R:0.0106)
Batch 100/537: Loss=0.3755 (C:0.3755, R:0.0105)
Batch 125/537: Loss=0.3858 (C:0.3858, R:0.0105)
Batch 150/537: Loss=0.4001 (C:0.4001, R:0.0105)
Batch 175/537: Loss=0.3883 (C:0.3883, R:0.0105)
Batch 200/537: Loss=0.4096 (C:0.4096, R:0.0105)
Batch 225/537: Loss=0.4015 (C:0.4015, R:0.0105)
Batch 250/537: Loss=0.3869 (C:0.3869, R:0.0105)
Batch 275/537: Loss=0.3801 (C:0.3801, R:0.0105)
Batch 300/537: Loss=0.4034 (C:0.4034, R:0.0105)
Batch 325/537: Loss=0.4101 (C:0.4101, R:0.0105)
Batch 350/537: Loss=0.3999 (C:0.3999, R:0.0105)
Batch 375/537: Loss=0.4109 (C:0.4109, R:0.0105)
Batch 400/537: Loss=0.3754 (C:0.3754, R:0.0105)
Batch 425/537: Loss=0.3908 (C:0.3908, R:0.0105)
Batch 450/537: Loss=0.3722 (C:0.3722, R:0.0105)
Batch 475/537: Loss=0.4017 (C:0.4017, R:0.0105)
Batch 500/537: Loss=0.3927 (C:0.3927, R:0.0105)
Batch 525/537: Loss=0.3895 (C:0.3895, R:0.0105)

============================================================
Epoch 23/300 completed in 27.8s
Train: Loss=0.3936 (C:0.3936, R:0.0105) Ratio=3.87x
Val:   Loss=0.4308 (C:0.4308, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4308)
============================================================

🌍 Updating global dataset at epoch 24
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.224 ± 0.321
    Neg distances: 1.196 ± 0.539
    Separation ratio: 5.33x
    Gap: -2.113
    ✅ Excellent global separation!

Epoch 24 Training
----------------------------------------
Batch   0/537: Loss=0.3791 (C:0.3791, R:0.0106)
Batch  25/537: Loss=0.3654 (C:0.3654, R:0.0105)
Batch  50/537: Loss=0.3693 (C:0.3693, R:0.0105)
Batch  75/537: Loss=0.3754 (C:0.3754, R:0.0105)
Batch 100/537: Loss=0.3727 (C:0.3727, R:0.0105)
Batch 125/537: Loss=0.3692 (C:0.3692, R:0.0105)
Batch 150/537: Loss=0.3929 (C:0.3929, R:0.0105)
Batch 175/537: Loss=0.3872 (C:0.3872, R:0.0105)
Batch 200/537: Loss=0.3826 (C:0.3826, R:0.0105)
Batch 225/537: Loss=0.3946 (C:0.3946, R:0.0105)
Batch 250/537: Loss=0.4036 (C:0.4036, R:0.0105)
Batch 275/537: Loss=0.3878 (C:0.3878, R:0.0105)
Batch 300/537: Loss=0.3752 (C:0.3752, R:0.0105)
Batch 325/537: Loss=0.4004 (C:0.4004, R:0.0105)
Batch 350/537: Loss=0.3837 (C:0.3837, R:0.0105)
Batch 375/537: Loss=0.3564 (C:0.3564, R:0.0106)
Batch 400/537: Loss=0.3932 (C:0.3932, R:0.0105)
Batch 425/537: Loss=0.3905 (C:0.3905, R:0.0105)
Batch 450/537: Loss=0.3895 (C:0.3895, R:0.0105)
Batch 475/537: Loss=0.3685 (C:0.3685, R:0.0105)
Batch 500/537: Loss=0.3867 (C:0.3867, R:0.0105)
Batch 525/537: Loss=0.3961 (C:0.3961, R:0.0105)

============================================================
Epoch 24/300 completed in 27.5s
Train: Loss=0.3846 (C:0.3846, R:0.0105) Ratio=3.91x
Val:   Loss=0.4221 (C:0.4221, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4221)
============================================================

🌍 Updating global dataset at epoch 25
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.222 ± 0.320
    Neg distances: 1.222 ± 0.548
    Separation ratio: 5.51x
    Gap: -2.112
    ✅ Excellent global separation!

Epoch 25 Training
----------------------------------------
Batch   0/537: Loss=0.3610 (C:0.3610, R:0.0105)
Batch  25/537: Loss=0.3795 (C:0.3795, R:0.0105)
Batch  50/537: Loss=0.3673 (C:0.3673, R:0.0105)
Batch  75/537: Loss=0.3811 (C:0.3811, R:0.0105)
Batch 100/537: Loss=0.3646 (C:0.3646, R:0.0105)
Batch 125/537: Loss=0.3886 (C:0.3886, R:0.0105)
Batch 150/537: Loss=0.3776 (C:0.3776, R:0.0105)
Batch 175/537: Loss=0.3745 (C:0.3745, R:0.0105)
Batch 200/537: Loss=0.3906 (C:0.3906, R:0.0105)
Batch 225/537: Loss=0.3864 (C:0.3864, R:0.0105)
Batch 250/537: Loss=0.3690 (C:0.3690, R:0.0105)
Batch 275/537: Loss=0.3889 (C:0.3889, R:0.0105)
Batch 300/537: Loss=0.3753 (C:0.3753, R:0.0105)
Batch 325/537: Loss=0.3821 (C:0.3821, R:0.0105)
Batch 350/537: Loss=0.3553 (C:0.3553, R:0.0105)
Batch 375/537: Loss=0.4093 (C:0.4093, R:0.0106)
Batch 400/537: Loss=0.3839 (C:0.3839, R:0.0105)
Batch 425/537: Loss=0.3785 (C:0.3785, R:0.0105)
Batch 450/537: Loss=0.3956 (C:0.3956, R:0.0105)
Batch 475/537: Loss=0.3684 (C:0.3684, R:0.0105)
Batch 500/537: Loss=0.3856 (C:0.3856, R:0.0105)
Batch 525/537: Loss=0.3802 (C:0.3802, R:0.0105)

============================================================
Epoch 25/300 completed in 27.1s
Train: Loss=0.3783 (C:0.3783, R:0.0105) Ratio=3.94x
Val:   Loss=0.4217 (C:0.4217, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4217)
============================================================

🌍 Updating global dataset at epoch 26
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.223 ± 0.315
    Neg distances: 1.209 ± 0.542
    Separation ratio: 5.41x
    Gap: -2.104
    ✅ Excellent global separation!

Epoch 26 Training
----------------------------------------
Batch   0/537: Loss=0.4002 (C:0.4002, R:0.0105)
Batch  25/537: Loss=0.3581 (C:0.3581, R:0.0105)
Batch  50/537: Loss=0.3496 (C:0.3496, R:0.0105)
Batch  75/537: Loss=0.3602 (C:0.3602, R:0.0105)
Batch 100/537: Loss=0.3736 (C:0.3736, R:0.0105)
Batch 125/537: Loss=0.3686 (C:0.3686, R:0.0105)
Batch 150/537: Loss=0.3868 (C:0.3868, R:0.0105)
Batch 175/537: Loss=0.3575 (C:0.3575, R:0.0105)
Batch 200/537: Loss=0.3879 (C:0.3879, R:0.0105)
Batch 225/537: Loss=0.3834 (C:0.3834, R:0.0105)
Batch 250/537: Loss=0.3791 (C:0.3791, R:0.0105)
Batch 275/537: Loss=0.3866 (C:0.3866, R:0.0105)
Batch 300/537: Loss=0.3928 (C:0.3928, R:0.0105)
Batch 325/537: Loss=0.3665 (C:0.3665, R:0.0105)
Batch 350/537: Loss=0.3934 (C:0.3934, R:0.0105)
Batch 375/537: Loss=0.3813 (C:0.3813, R:0.0105)
Batch 400/537: Loss=0.3737 (C:0.3737, R:0.0105)
Batch 425/537: Loss=0.3843 (C:0.3843, R:0.0105)
Batch 450/537: Loss=0.3979 (C:0.3979, R:0.0105)
Batch 475/537: Loss=0.3997 (C:0.3997, R:0.0105)
Batch 500/537: Loss=0.3618 (C:0.3618, R:0.0105)
Batch 525/537: Loss=0.3806 (C:0.3806, R:0.0105)

============================================================
Epoch 26/300 completed in 27.1s
Train: Loss=0.3771 (C:0.3771, R:0.0105) Ratio=3.95x
Val:   Loss=0.4198 (C:0.4198, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4198)
============================================================

🌍 Updating global dataset at epoch 27
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.216 ± 0.320
    Neg distances: 1.235 ± 0.550
    Separation ratio: 5.71x
    Gap: -2.132
    ✅ Excellent global separation!

Epoch 27 Training
----------------------------------------
Batch   0/537: Loss=0.3793 (C:0.3793, R:0.0105)
Batch  25/537: Loss=0.3436 (C:0.3436, R:0.0105)
Batch  50/537: Loss=0.3726 (C:0.3726, R:0.0105)
Batch  75/537: Loss=0.3590 (C:0.3590, R:0.0105)
Batch 100/537: Loss=0.3845 (C:0.3845, R:0.0105)
Batch 125/537: Loss=0.3589 (C:0.3589, R:0.0105)
Batch 150/537: Loss=0.3669 (C:0.3669, R:0.0105)
Batch 175/537: Loss=0.3802 (C:0.3802, R:0.0105)
Batch 200/537: Loss=0.3692 (C:0.3692, R:0.0105)
Batch 225/537: Loss=0.3909 (C:0.3909, R:0.0105)
Batch 250/537: Loss=0.3847 (C:0.3847, R:0.0105)
Batch 275/537: Loss=0.3654 (C:0.3654, R:0.0105)
Batch 300/537: Loss=0.3843 (C:0.3843, R:0.0105)
Batch 325/537: Loss=0.3699 (C:0.3699, R:0.0105)
Batch 350/537: Loss=0.3851 (C:0.3851, R:0.0105)
Batch 375/537: Loss=0.3723 (C:0.3723, R:0.0106)
Batch 400/537: Loss=0.3750 (C:0.3750, R:0.0105)
Batch 425/537: Loss=0.3686 (C:0.3686, R:0.0105)
Batch 450/537: Loss=0.3625 (C:0.3625, R:0.0105)
Batch 475/537: Loss=0.3688 (C:0.3688, R:0.0105)
Batch 500/537: Loss=0.3566 (C:0.3566, R:0.0105)
Batch 525/537: Loss=0.3679 (C:0.3679, R:0.0106)

============================================================
Epoch 27/300 completed in 27.7s
Train: Loss=0.3682 (C:0.3682, R:0.0105) Ratio=3.98x
Val:   Loss=0.4125 (C:0.4125, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4125)
============================================================

🌍 Updating global dataset at epoch 28
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.205 ± 0.309
    Neg distances: 1.233 ± 0.541
    Separation ratio: 6.00x
    Gap: -2.120
    ✅ Excellent global separation!

Epoch 28 Training
----------------------------------------
Batch   0/537: Loss=0.3409 (C:0.3409, R:0.0105)
Batch  25/537: Loss=0.3633 (C:0.3633, R:0.0105)
Batch  50/537: Loss=0.3531 (C:0.3531, R:0.0105)
Batch  75/537: Loss=0.3593 (C:0.3593, R:0.0105)
Batch 100/537: Loss=0.3757 (C:0.3757, R:0.0105)
Batch 125/537: Loss=0.3439 (C:0.3439, R:0.0105)
Batch 150/537: Loss=0.3596 (C:0.3596, R:0.0105)
Batch 175/537: Loss=0.3560 (C:0.3560, R:0.0104)
Batch 200/537: Loss=0.3533 (C:0.3533, R:0.0105)
Batch 225/537: Loss=0.3430 (C:0.3430, R:0.0105)
Batch 250/537: Loss=0.3624 (C:0.3624, R:0.0105)
Batch 275/537: Loss=0.3707 (C:0.3707, R:0.0105)
Batch 300/537: Loss=0.3689 (C:0.3689, R:0.0105)
Batch 325/537: Loss=0.3701 (C:0.3701, R:0.0105)
Batch 350/537: Loss=0.3549 (C:0.3549, R:0.0105)
Batch 375/537: Loss=0.3722 (C:0.3722, R:0.0105)
Batch 400/537: Loss=0.3642 (C:0.3642, R:0.0105)
Batch 425/537: Loss=0.3445 (C:0.3445, R:0.0105)
Batch 450/537: Loss=0.3601 (C:0.3601, R:0.0105)
Batch 475/537: Loss=0.3495 (C:0.3495, R:0.0105)
Batch 500/537: Loss=0.3412 (C:0.3412, R:0.0105)
Batch 525/537: Loss=0.3706 (C:0.3706, R:0.0105)

============================================================
Epoch 28/300 completed in 27.0s
Train: Loss=0.3579 (C:0.3579, R:0.0105) Ratio=4.07x
Val:   Loss=0.4055 (C:0.4055, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4055)
============================================================

🌍 Updating global dataset at epoch 29
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.225 ± 0.329
    Neg distances: 1.224 ± 0.549
    Separation ratio: 5.45x
    Gap: -2.141
    ✅ Excellent global separation!

Epoch 29 Training
----------------------------------------
Batch   0/537: Loss=0.3635 (C:0.3635, R:0.0105)
Batch  25/537: Loss=0.3733 (C:0.3733, R:0.0105)
Batch  50/537: Loss=0.3702 (C:0.3702, R:0.0105)
Batch  75/537: Loss=0.3537 (C:0.3537, R:0.0105)
Batch 100/537: Loss=0.3756 (C:0.3756, R:0.0105)
Batch 125/537: Loss=0.3720 (C:0.3720, R:0.0105)
Batch 150/537: Loss=0.3649 (C:0.3649, R:0.0105)
Batch 175/537: Loss=0.3605 (C:0.3605, R:0.0105)
Batch 200/537: Loss=0.3712 (C:0.3712, R:0.0105)
Batch 225/537: Loss=0.3649 (C:0.3649, R:0.0105)
Batch 250/537: Loss=0.3762 (C:0.3762, R:0.0105)
Batch 275/537: Loss=0.3664 (C:0.3664, R:0.0105)
Batch 300/537: Loss=0.3570 (C:0.3570, R:0.0105)
Batch 325/537: Loss=0.3780 (C:0.3780, R:0.0105)
Batch 350/537: Loss=0.3714 (C:0.3714, R:0.0105)
Batch 375/537: Loss=0.3582 (C:0.3582, R:0.0105)
Batch 400/537: Loss=0.3778 (C:0.3778, R:0.0105)
Batch 425/537: Loss=0.3675 (C:0.3675, R:0.0105)
Batch 450/537: Loss=0.3851 (C:0.3851, R:0.0105)
Batch 475/537: Loss=0.3722 (C:0.3722, R:0.0105)
Batch 500/537: Loss=0.3869 (C:0.3869, R:0.0105)
Batch 525/537: Loss=0.3730 (C:0.3730, R:0.0105)

============================================================
Epoch 29/300 completed in 27.3s
Train: Loss=0.3698 (C:0.3698, R:0.0105) Ratio=4.10x
Val:   Loss=0.4163 (C:0.4163, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 30
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.219 ± 0.321
    Neg distances: 1.237 ± 0.552
    Separation ratio: 5.65x
    Gap: -2.128
    ✅ Excellent global separation!

Epoch 30 Training
----------------------------------------
Batch   0/537: Loss=0.3408 (C:0.3408, R:0.0105)
Batch  25/537: Loss=0.3596 (C:0.3596, R:0.0105)
Batch  50/537: Loss=0.3674 (C:0.3674, R:0.0105)
Batch  75/537: Loss=0.3500 (C:0.3500, R:0.0105)
Batch 100/537: Loss=0.3506 (C:0.3506, R:0.0105)
Batch 125/537: Loss=0.3756 (C:0.3756, R:0.0105)
Batch 150/537: Loss=0.3740 (C:0.3740, R:0.0105)
Batch 175/537: Loss=0.3535 (C:0.3535, R:0.0105)
Batch 200/537: Loss=0.3578 (C:0.3578, R:0.0105)
Batch 225/537: Loss=0.3604 (C:0.3604, R:0.0105)
Batch 250/537: Loss=0.3629 (C:0.3629, R:0.0105)
Batch 275/537: Loss=0.3652 (C:0.3652, R:0.0105)
Batch 300/537: Loss=0.3810 (C:0.3810, R:0.0105)
Batch 325/537: Loss=0.3658 (C:0.3658, R:0.0105)
Batch 350/537: Loss=0.3711 (C:0.3711, R:0.0105)
Batch 375/537: Loss=0.3683 (C:0.3683, R:0.0105)
Batch 400/537: Loss=0.3468 (C:0.3468, R:0.0105)
Batch 425/537: Loss=0.3605 (C:0.3605, R:0.0105)
Batch 450/537: Loss=0.3797 (C:0.3797, R:0.0105)
Batch 475/537: Loss=0.3770 (C:0.3770, R:0.0105)
Batch 500/537: Loss=0.3649 (C:0.3649, R:0.0105)
Batch 525/537: Loss=0.3883 (C:0.3883, R:0.0105)

============================================================
Epoch 30/300 completed in 27.7s
Train: Loss=0.3644 (C:0.3644, R:0.0105) Ratio=4.07x
Val:   Loss=0.4137 (C:0.4137, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.000
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 31
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.208 ± 0.312
    Neg distances: 1.243 ± 0.546
    Separation ratio: 5.98x
    Gap: -2.151
    ✅ Excellent global separation!

Epoch 31 Training
----------------------------------------
Batch   0/537: Loss=0.3383 (C:0.3383, R:0.0105)
Batch  25/537: Loss=0.3409 (C:0.3409, R:0.0105)
Batch  50/537: Loss=0.3528 (C:0.3528, R:0.0106)
Batch  75/537: Loss=0.3356 (C:0.3356, R:0.0105)
Batch 100/537: Loss=0.3454 (C:0.3454, R:0.0105)
Batch 125/537: Loss=0.3446 (C:0.3446, R:0.0105)
Batch 150/537: Loss=0.3523 (C:0.3523, R:0.0105)
Batch 175/537: Loss=0.3566 (C:0.3566, R:0.0105)
Batch 200/537: Loss=0.3434 (C:0.3434, R:0.0105)
Batch 225/537: Loss=0.3558 (C:0.3558, R:0.0105)
Batch 250/537: Loss=0.3562 (C:0.3562, R:0.0105)
Batch 275/537: Loss=0.3688 (C:0.3688, R:0.0105)
Batch 300/537: Loss=0.3558 (C:0.3558, R:0.0105)
Batch 325/537: Loss=0.3497 (C:0.3497, R:0.0105)
Batch 350/537: Loss=0.3655 (C:0.3655, R:0.0105)
Batch 375/537: Loss=0.3680 (C:0.3680, R:0.0105)
Batch 400/537: Loss=0.3505 (C:0.3505, R:0.0106)
Batch 425/537: Loss=0.3415 (C:0.3415, R:0.0105)
Batch 450/537: Loss=0.3584 (C:0.3584, R:0.0105)
Batch 475/537: Loss=0.3633 (C:0.3633, R:0.0105)
Batch 500/537: Loss=0.3584 (C:0.3584, R:0.0105)
Batch 525/537: Loss=0.3366 (C:0.3366, R:0.0105)

============================================================
Epoch 31/300 completed in 27.6s
Train: Loss=0.3529 (C:0.3529, R:0.0105) Ratio=4.16x
Val:   Loss=0.4066 (C:0.4066, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.015
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 32
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.217 ± 0.326
    Neg distances: 1.238 ± 0.550
    Separation ratio: 5.70x
    Gap: -2.189
    ✅ Excellent global separation!

Epoch 32 Training
----------------------------------------
Batch   0/537: Loss=0.3598 (C:0.3598, R:0.0105)
Batch  25/537: Loss=0.3520 (C:0.3520, R:0.0105)
Batch  50/537: Loss=0.3451 (C:0.3451, R:0.0105)
Batch  75/537: Loss=0.3468 (C:0.3468, R:0.0105)
Batch 100/537: Loss=0.3421 (C:0.3421, R:0.0105)
Batch 125/537: Loss=0.3657 (C:0.3657, R:0.0105)
Batch 150/537: Loss=0.3563 (C:0.3563, R:0.0105)
Batch 175/537: Loss=0.3635 (C:0.3635, R:0.0105)
Batch 200/537: Loss=0.3528 (C:0.3528, R:0.0105)
Batch 225/537: Loss=0.3667 (C:0.3667, R:0.0105)
Batch 250/537: Loss=0.3681 (C:0.3681, R:0.0105)
Batch 275/537: Loss=0.3502 (C:0.3502, R:0.0105)
Batch 300/537: Loss=0.3663 (C:0.3663, R:0.0105)
Batch 325/537: Loss=0.3467 (C:0.3467, R:0.0105)
Batch 350/537: Loss=0.3789 (C:0.3789, R:0.0105)
Batch 375/537: Loss=0.3612 (C:0.3612, R:0.0105)
Batch 400/537: Loss=0.3550 (C:0.3550, R:0.0105)
Batch 425/537: Loss=0.3544 (C:0.3544, R:0.0105)
Batch 450/537: Loss=0.3818 (C:0.3818, R:0.0105)
Batch 475/537: Loss=0.3608 (C:0.3608, R:0.0106)
Batch 500/537: Loss=0.3669 (C:0.3669, R:0.0105)
Batch 525/537: Loss=0.3744 (C:0.3744, R:0.0105)

============================================================
Epoch 32/300 completed in 27.4s
Train: Loss=0.3587 (C:0.3587, R:0.0105) Ratio=4.19x
Val:   Loss=0.4144 (C:0.4144, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.030
No improvement for 4 epochs
============================================================

🌍 Updating global dataset at epoch 33
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.215 ± 0.335
    Neg distances: 1.264 ± 0.559
    Separation ratio: 5.88x
    Gap: -2.203
    ✅ Excellent global separation!

Epoch 33 Training
----------------------------------------
Batch   0/537: Loss=0.3349 (C:0.3349, R:0.0106)
Batch  25/537: Loss=0.3572 (C:0.3572, R:0.0105)
Batch  50/537: Loss=0.3540 (C:0.3540, R:0.0105)
Batch  75/537: Loss=0.3594 (C:0.3594, R:0.0105)
Batch 100/537: Loss=0.3923 (C:0.3923, R:0.0105)
Batch 125/537: Loss=0.3665 (C:0.3665, R:0.0105)
Batch 150/537: Loss=0.3406 (C:0.3406, R:0.0105)
Batch 175/537: Loss=0.3570 (C:0.3570, R:0.0105)
Batch 200/537: Loss=0.3530 (C:0.3530, R:0.0105)
Batch 225/537: Loss=0.3419 (C:0.3419, R:0.0105)
Batch 250/537: Loss=0.3552 (C:0.3552, R:0.0106)
Batch 275/537: Loss=0.3510 (C:0.3510, R:0.0105)
Batch 300/537: Loss=0.3584 (C:0.3584, R:0.0105)
Batch 325/537: Loss=0.3755 (C:0.3755, R:0.0105)
Batch 350/537: Loss=0.3287 (C:0.3287, R:0.0105)
Batch 375/537: Loss=0.3483 (C:0.3483, R:0.0105)
Batch 400/537: Loss=0.3485 (C:0.3485, R:0.0105)
Batch 425/537: Loss=0.3764 (C:0.3764, R:0.0105)
Batch 450/537: Loss=0.3608 (C:0.3608, R:0.0105)
Batch 475/537: Loss=0.3264 (C:0.3264, R:0.0105)
Batch 500/537: Loss=0.3520 (C:0.3520, R:0.0105)
Batch 525/537: Loss=0.3410 (C:0.3410, R:0.0105)

============================================================
Epoch 33/300 completed in 27.2s
Train: Loss=0.3535 (C:0.3535, R:0.0105) Ratio=4.27x
Val:   Loss=0.4068 (C:0.4068, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.045
No improvement for 5 epochs
============================================================

🌍 Updating global dataset at epoch 34
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.202 ± 0.313
    Neg distances: 1.253 ± 0.550
    Separation ratio: 6.19x
    Gap: -2.176
    ✅ Excellent global separation!

Epoch 34 Training
----------------------------------------
Batch   0/537: Loss=0.3374 (C:0.3374, R:0.0106)
Batch  25/537: Loss=0.3304 (C:0.3304, R:0.0105)
Batch  50/537: Loss=0.3356 (C:0.3356, R:0.0106)
Batch  75/537: Loss=0.3324 (C:0.3324, R:0.0105)
Batch 100/537: Loss=0.3394 (C:0.3394, R:0.0105)
Batch 125/537: Loss=0.3541 (C:0.3541, R:0.0105)
Batch 150/537: Loss=0.3534 (C:0.3534, R:0.0105)
Batch 175/537: Loss=0.3586 (C:0.3586, R:0.0105)
Batch 200/537: Loss=0.3414 (C:0.3414, R:0.0105)
Batch 225/537: Loss=0.3763 (C:0.3763, R:0.0105)
Batch 250/537: Loss=0.3352 (C:0.3352, R:0.0105)
Batch 275/537: Loss=0.3679 (C:0.3679, R:0.0105)
Batch 300/537: Loss=0.3542 (C:0.3542, R:0.0105)
Batch 325/537: Loss=0.3359 (C:0.3359, R:0.0106)
Batch 350/537: Loss=0.3314 (C:0.3314, R:0.0105)
Batch 375/537: Loss=0.3400 (C:0.3400, R:0.0105)
Batch 400/537: Loss=0.3461 (C:0.3461, R:0.0105)
Batch 425/537: Loss=0.3298 (C:0.3298, R:0.0105)
Batch 450/537: Loss=0.3457 (C:0.3457, R:0.0105)
Batch 475/537: Loss=0.3503 (C:0.3503, R:0.0105)
Batch 500/537: Loss=0.3484 (C:0.3484, R:0.0105)
Batch 525/537: Loss=0.3330 (C:0.3330, R:0.0105)

============================================================
Epoch 34/300 completed in 27.9s
Train: Loss=0.3435 (C:0.3435, R:0.0105) Ratio=4.27x
Val:   Loss=0.4026 (C:0.4026, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.060
✅ New best model saved (Val Loss: 0.4026)
============================================================

🌍 Updating global dataset at epoch 35
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.204 ± 0.318
    Neg distances: 1.276 ± 0.557
    Separation ratio: 6.26x
    Gap: -2.193
    ✅ Excellent global separation!

Epoch 35 Training
----------------------------------------
Batch   0/537: Loss=0.3393 (C:0.3393, R:0.0105)
Batch  25/537: Loss=0.3409 (C:0.3409, R:0.0105)
Batch  50/537: Loss=0.3445 (C:0.3445, R:0.0105)
Batch  75/537: Loss=0.3515 (C:0.3515, R:0.0105)
Batch 100/537: Loss=0.3551 (C:0.3551, R:0.0106)
Batch 125/537: Loss=0.3605 (C:0.3605, R:0.0105)
Batch 150/537: Loss=0.3574 (C:0.3574, R:0.0105)
Batch 175/537: Loss=0.3287 (C:0.3287, R:0.0105)
Batch 200/537: Loss=0.3482 (C:0.3482, R:0.0105)
Batch 225/537: Loss=0.3723 (C:0.3723, R:0.0105)
Batch 250/537: Loss=0.3410 (C:0.3410, R:0.0105)
Batch 275/537: Loss=0.3288 (C:0.3288, R:0.0105)
Batch 300/537: Loss=0.3289 (C:0.3289, R:0.0105)
Batch 325/537: Loss=0.3618 (C:0.3618, R:0.0105)
Batch 350/537: Loss=0.3505 (C:0.3505, R:0.0105)
Batch 375/537: Loss=0.3602 (C:0.3602, R:0.0105)
Batch 400/537: Loss=0.3643 (C:0.3643, R:0.0106)
Batch 425/537: Loss=0.3407 (C:0.3407, R:0.0105)
Batch 450/537: Loss=0.3513 (C:0.3513, R:0.0106)
Batch 475/537: Loss=0.3496 (C:0.3496, R:0.0105)
Batch 500/537: Loss=0.3324 (C:0.3324, R:0.0105)
Batch 525/537: Loss=0.3505 (C:0.3505, R:0.0105)

============================================================
Epoch 35/300 completed in 27.6s
Train: Loss=0.3410 (C:0.3410, R:0.0105) Ratio=4.22x
Val:   Loss=0.3976 (C:0.3976, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.075
✅ New best model saved (Val Loss: 0.3976)
============================================================

🌍 Updating global dataset at epoch 36
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.196 ± 0.302
    Neg distances: 1.251 ± 0.545
    Separation ratio: 6.39x
    Gap: -2.139
    ✅ Excellent global separation!

Epoch 36 Training
----------------------------------------
Batch   0/537: Loss=0.3184 (C:0.3184, R:0.0105)
Batch  25/537: Loss=0.3274 (C:0.3274, R:0.0105)
Batch  50/537: Loss=0.3494 (C:0.3494, R:0.0105)
Batch  75/537: Loss=0.3239 (C:0.3239, R:0.0105)
Batch 100/537: Loss=0.3360 (C:0.3360, R:0.0105)
Batch 125/537: Loss=0.3205 (C:0.3205, R:0.0105)
Batch 150/537: Loss=0.3137 (C:0.3137, R:0.0105)
Batch 175/537: Loss=0.3359 (C:0.3359, R:0.0105)
Batch 200/537: Loss=0.3440 (C:0.3440, R:0.0105)
Batch 225/537: Loss=0.3417 (C:0.3417, R:0.0105)
Batch 250/537: Loss=0.3328 (C:0.3328, R:0.0105)
Batch 275/537: Loss=0.3329 (C:0.3329, R:0.0105)
Batch 300/537: Loss=0.3505 (C:0.3505, R:0.0105)
Batch 325/537: Loss=0.3392 (C:0.3392, R:0.0105)
Batch 350/537: Loss=0.3413 (C:0.3413, R:0.0105)
Batch 375/537: Loss=0.3598 (C:0.3598, R:0.0106)
Batch 400/537: Loss=0.3437 (C:0.3437, R:0.0105)
Batch 425/537: Loss=0.3249 (C:0.3249, R:0.0105)
Batch 450/537: Loss=0.3310 (C:0.3310, R:0.0105)
Batch 475/537: Loss=0.3415 (C:0.3415, R:0.0105)
Batch 500/537: Loss=0.3382 (C:0.3382, R:0.0105)
Batch 525/537: Loss=0.3351 (C:0.3351, R:0.0105)

============================================================
Epoch 36/300 completed in 27.2s
Train: Loss=0.3355 (C:0.3355, R:0.0105) Ratio=4.38x
Val:   Loss=0.3973 (C:0.3973, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.090
✅ New best model saved (Val Loss: 0.3973)
============================================================

🌍 Updating global dataset at epoch 37
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.186 ± 0.300
    Neg distances: 1.278 ± 0.552
    Separation ratio: 6.87x
    Gap: -2.177
    ✅ Excellent global separation!

Epoch 37 Training
----------------------------------------
Batch   0/537: Loss=0.3215 (C:0.3215, R:0.0105)
Batch  25/537: Loss=0.3339 (C:0.3339, R:0.0105)
Batch  50/537: Loss=0.3086 (C:0.3086, R:0.0106)
Batch  75/537: Loss=0.3154 (C:0.3154, R:0.0105)
Batch 100/537: Loss=0.3201 (C:0.3201, R:0.0105)
Batch 125/537: Loss=0.3145 (C:0.3145, R:0.0105)
Batch 150/537: Loss=0.3093 (C:0.3093, R:0.0105)
Batch 175/537: Loss=0.3294 (C:0.3294, R:0.0105)
Batch 200/537: Loss=0.3235 (C:0.3235, R:0.0105)
Batch 225/537: Loss=0.3304 (C:0.3304, R:0.0105)
Batch 250/537: Loss=0.3173 (C:0.3173, R:0.0105)
Batch 275/537: Loss=0.3259 (C:0.3259, R:0.0105)
Batch 300/537: Loss=0.3308 (C:0.3308, R:0.0105)
Batch 325/537: Loss=0.3159 (C:0.3159, R:0.0105)
Batch 350/537: Loss=0.3187 (C:0.3187, R:0.0105)
Batch 375/537: Loss=0.3301 (C:0.3301, R:0.0105)
Batch 400/537: Loss=0.3332 (C:0.3332, R:0.0105)
Batch 425/537: Loss=0.3489 (C:0.3489, R:0.0105)
Batch 450/537: Loss=0.3374 (C:0.3374, R:0.0105)
Batch 475/537: Loss=0.3247 (C:0.3247, R:0.0105)
Batch 500/537: Loss=0.3188 (C:0.3188, R:0.0105)
Batch 525/537: Loss=0.3445 (C:0.3445, R:0.0105)

============================================================
Epoch 37/300 completed in 27.5s
Train: Loss=0.3255 (C:0.3255, R:0.0105) Ratio=4.39x
Val:   Loss=0.3823 (C:0.3823, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.105
✅ New best model saved (Val Loss: 0.3823)
============================================================

🌍 Updating global dataset at epoch 38
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.202 ± 0.318
    Neg distances: 1.264 ± 0.555
    Separation ratio: 6.27x
    Gap: -2.170
    ✅ Excellent global separation!

Epoch 38 Training
----------------------------------------
Batch   0/537: Loss=0.3187 (C:0.3187, R:0.0105)
Batch  25/537: Loss=0.3322 (C:0.3322, R:0.0105)
Batch  50/537: Loss=0.3188 (C:0.3188, R:0.0105)
Batch  75/537: Loss=0.3179 (C:0.3179, R:0.0105)
Batch 100/537: Loss=0.3259 (C:0.3259, R:0.0105)
Batch 125/537: Loss=0.3471 (C:0.3471, R:0.0105)
Batch 150/537: Loss=0.3387 (C:0.3387, R:0.0105)
Batch 175/537: Loss=0.3171 (C:0.3171, R:0.0105)
Batch 200/537: Loss=0.3196 (C:0.3196, R:0.0105)
Batch 225/537: Loss=0.3536 (C:0.3536, R:0.0105)
Batch 250/537: Loss=0.3298 (C:0.3298, R:0.0105)
Batch 275/537: Loss=0.3403 (C:0.3403, R:0.0105)
Batch 300/537: Loss=0.3417 (C:0.3417, R:0.0105)
Batch 325/537: Loss=0.3605 (C:0.3605, R:0.0105)
Batch 350/537: Loss=0.3257 (C:0.3257, R:0.0105)
Batch 375/537: Loss=0.3360 (C:0.3360, R:0.0105)
Batch 400/537: Loss=0.3301 (C:0.3301, R:0.0105)
Batch 425/537: Loss=0.3432 (C:0.3432, R:0.0105)
Batch 450/537: Loss=0.3558 (C:0.3558, R:0.0105)
Batch 475/537: Loss=0.3421 (C:0.3421, R:0.0105)
Batch 500/537: Loss=0.3147 (C:0.3147, R:0.0105)
Batch 525/537: Loss=0.3495 (C:0.3495, R:0.0105)

============================================================
Epoch 38/300 completed in 27.4s
Train: Loss=0.3368 (C:0.3368, R:0.0105) Ratio=4.44x
Val:   Loss=0.3922 (C:0.3922, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.120
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 39
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.198 ± 0.324
    Neg distances: 1.260 ± 0.549
    Separation ratio: 6.37x
    Gap: -2.170
    ✅ Excellent global separation!

Epoch 39 Training
----------------------------------------
Batch   0/537: Loss=0.3206 (C:0.3206, R:0.0105)
Batch  25/537: Loss=0.3164 (C:0.3164, R:0.0105)
Batch  50/537: Loss=0.3118 (C:0.3118, R:0.0105)
Batch  75/537: Loss=0.3155 (C:0.3155, R:0.0105)
Batch 100/537: Loss=0.3383 (C:0.3383, R:0.0105)
Batch 125/537: Loss=0.3295 (C:0.3295, R:0.0105)
Batch 150/537: Loss=0.3021 (C:0.3021, R:0.0105)
Batch 175/537: Loss=0.3155 (C:0.3155, R:0.0105)
Batch 200/537: Loss=0.3235 (C:0.3235, R:0.0105)
Batch 225/537: Loss=0.3414 (C:0.3414, R:0.0105)
Batch 250/537: Loss=0.3247 (C:0.3247, R:0.0105)
Batch 275/537: Loss=0.3234 (C:0.3234, R:0.0106)
Batch 300/537: Loss=0.3317 (C:0.3317, R:0.0105)
Batch 325/537: Loss=0.3216 (C:0.3216, R:0.0105)
Batch 350/537: Loss=0.3127 (C:0.3127, R:0.0105)
Batch 375/537: Loss=0.3502 (C:0.3502, R:0.0105)
Batch 400/537: Loss=0.3275 (C:0.3275, R:0.0105)
Batch 425/537: Loss=0.3413 (C:0.3413, R:0.0105)
Batch 450/537: Loss=0.3557 (C:0.3557, R:0.0106)
Batch 475/537: Loss=0.3390 (C:0.3390, R:0.0105)
Batch 500/537: Loss=0.3349 (C:0.3349, R:0.0105)
Batch 525/537: Loss=0.3303 (C:0.3303, R:0.0105)

============================================================
Epoch 39/300 completed in 27.4s
Train: Loss=0.3311 (C:0.3311, R:0.0105) Ratio=4.49x
Val:   Loss=0.3942 (C:0.3942, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.135
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 40
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.187 ± 0.302
    Neg distances: 1.289 ± 0.553
    Separation ratio: 6.89x
    Gap: -2.193
    ✅ Excellent global separation!

Epoch 40 Training
----------------------------------------
Batch   0/537: Loss=0.3161 (C:0.3161, R:0.0105)
Batch  25/537: Loss=0.3018 (C:0.3018, R:0.0106)
Batch  50/537: Loss=0.3216 (C:0.3216, R:0.0105)
Batch  75/537: Loss=0.3005 (C:0.3005, R:0.0105)
Batch 100/537: Loss=0.3108 (C:0.3108, R:0.0105)
Batch 125/537: Loss=0.3202 (C:0.3202, R:0.0105)
Batch 150/537: Loss=0.3134 (C:0.3134, R:0.0105)
Batch 175/537: Loss=0.3191 (C:0.3191, R:0.0105)
Batch 200/537: Loss=0.3301 (C:0.3301, R:0.0105)
Batch 225/537: Loss=0.2997 (C:0.2997, R:0.0105)
Batch 250/537: Loss=0.3519 (C:0.3519, R:0.0105)
Batch 275/537: Loss=0.3171 (C:0.3171, R:0.0105)
Batch 300/537: Loss=0.3348 (C:0.3348, R:0.0105)
Batch 325/537: Loss=0.3252 (C:0.3252, R:0.0105)
Batch 350/537: Loss=0.3147 (C:0.3147, R:0.0105)
Batch 375/537: Loss=0.3313 (C:0.3313, R:0.0105)
Batch 400/537: Loss=0.3191 (C:0.3191, R:0.0105)
Batch 425/537: Loss=0.3377 (C:0.3377, R:0.0105)
Batch 450/537: Loss=0.3150 (C:0.3150, R:0.0105)
Batch 475/537: Loss=0.3347 (C:0.3347, R:0.0106)
Batch 500/537: Loss=0.3178 (C:0.3178, R:0.0105)
Batch 525/537: Loss=0.3227 (C:0.3227, R:0.0105)

============================================================
Epoch 40/300 completed in 27.7s
Train: Loss=0.3211 (C:0.3211, R:0.0105) Ratio=4.43x
Val:   Loss=0.3822 (C:0.3822, R:0.0104) Ratio=3.12x
Reconstruction weight: 0.150
✅ New best model saved (Val Loss: 0.3822)
Checkpoint saved at epoch 40
============================================================

🌍 Updating global dataset at epoch 41
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.195 ± 0.322
    Neg distances: 1.288 ± 0.560
    Separation ratio: 6.61x
    Gap: -2.213
    ✅ Excellent global separation!

Epoch 41 Training
----------------------------------------
Batch   0/537: Loss=0.3218 (C:0.3218, R:0.0105)
Batch  25/537: Loss=0.3370 (C:0.3370, R:0.0105)
Batch  50/537: Loss=0.3160 (C:0.3160, R:0.0105)
Batch  75/537: Loss=0.3195 (C:0.3195, R:0.0105)
Batch 100/537: Loss=0.3316 (C:0.3316, R:0.0105)
Batch 125/537: Loss=0.3147 (C:0.3147, R:0.0105)
Batch 150/537: Loss=0.3294 (C:0.3294, R:0.0105)
Batch 175/537: Loss=0.3215 (C:0.3215, R:0.0105)
Batch 200/537: Loss=0.3222 (C:0.3222, R:0.0105)
Batch 225/537: Loss=0.3206 (C:0.3206, R:0.0105)
Batch 250/537: Loss=0.3315 (C:0.3315, R:0.0105)
Batch 275/537: Loss=0.3173 (C:0.3173, R:0.0105)
Batch 300/537: Loss=0.3224 (C:0.3224, R:0.0105)
Batch 325/537: Loss=0.3346 (C:0.3346, R:0.0105)
Batch 350/537: Loss=0.3238 (C:0.3238, R:0.0105)
Batch 375/537: Loss=0.3224 (C:0.3224, R:0.0105)
Batch 400/537: Loss=0.3306 (C:0.3306, R:0.0105)
Batch 425/537: Loss=0.3503 (C:0.3503, R:0.0105)
Batch 450/537: Loss=0.3321 (C:0.3321, R:0.0105)
Batch 475/537: Loss=0.3309 (C:0.3309, R:0.0105)
Batch 500/537: Loss=0.3236 (C:0.3236, R:0.0105)
Batch 525/537: Loss=0.3520 (C:0.3520, R:0.0105)

============================================================
Epoch 41/300 completed in 27.2s
Train: Loss=0.3257 (C:0.3257, R:0.0105) Ratio=4.44x
Val:   Loss=0.3885 (C:0.3885, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.165
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 42
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.187 ± 0.306
    Neg distances: 1.296 ± 0.557
    Separation ratio: 6.93x
    Gap: -2.216
    ✅ Excellent global separation!

Epoch 42 Training
----------------------------------------
Batch   0/537: Loss=0.3113 (C:0.3113, R:0.0105)
Batch  25/537: Loss=0.3054 (C:0.3054, R:0.0104)
Batch  50/537: Loss=0.2929 (C:0.2929, R:0.0105)
Batch  75/537: Loss=0.3140 (C:0.3140, R:0.0105)
Batch 100/537: Loss=0.3081 (C:0.3081, R:0.0105)
Batch 125/537: Loss=0.3149 (C:0.3149, R:0.0105)
Batch 150/537: Loss=0.3134 (C:0.3134, R:0.0105)
Batch 175/537: Loss=0.3254 (C:0.3254, R:0.0105)
Batch 200/537: Loss=0.3179 (C:0.3179, R:0.0105)
Batch 225/537: Loss=0.3262 (C:0.3262, R:0.0105)
Batch 250/537: Loss=0.3209 (C:0.3209, R:0.0105)
Batch 275/537: Loss=0.3103 (C:0.3103, R:0.0105)
Batch 300/537: Loss=0.3154 (C:0.3154, R:0.0105)
Batch 325/537: Loss=0.3140 (C:0.3140, R:0.0105)
Batch 350/537: Loss=0.3087 (C:0.3087, R:0.0105)
Batch 375/537: Loss=0.3086 (C:0.3086, R:0.0105)
Batch 400/537: Loss=0.3260 (C:0.3260, R:0.0105)
Batch 425/537: Loss=0.3053 (C:0.3053, R:0.0105)
Batch 450/537: Loss=0.3206 (C:0.3206, R:0.0105)
Batch 475/537: Loss=0.3338 (C:0.3338, R:0.0105)
Batch 500/537: Loss=0.3069 (C:0.3069, R:0.0105)
Batch 525/537: Loss=0.3303 (C:0.3303, R:0.0105)

============================================================
Epoch 42/300 completed in 26.9s
Train: Loss=0.3175 (C:0.3175, R:0.0105) Ratio=4.61x
Val:   Loss=0.3849 (C:0.3849, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.180
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 43
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.194 ± 0.325
    Neg distances: 1.284 ± 0.556
    Separation ratio: 6.62x
    Gap: -2.201
    ✅ Excellent global separation!

Epoch 43 Training
----------------------------------------
Batch   0/537: Loss=0.3138 (C:0.3138, R:0.0105)
Batch  25/537: Loss=0.3108 (C:0.3108, R:0.0105)
Batch  50/537: Loss=0.3077 (C:0.3077, R:0.0105)
Batch  75/537: Loss=0.3076 (C:0.3076, R:0.0105)
Batch 100/537: Loss=0.3144 (C:0.3144, R:0.0105)
Batch 125/537: Loss=0.3124 (C:0.3124, R:0.0104)
Batch 150/537: Loss=0.3230 (C:0.3230, R:0.0105)
Batch 175/537: Loss=0.3239 (C:0.3239, R:0.0105)
Batch 200/537: Loss=0.3103 (C:0.3103, R:0.0105)
Batch 225/537: Loss=0.3272 (C:0.3272, R:0.0104)
Batch 250/537: Loss=0.3221 (C:0.3221, R:0.0105)
Batch 275/537: Loss=0.3302 (C:0.3302, R:0.0105)
Batch 300/537: Loss=0.3041 (C:0.3041, R:0.0105)
Batch 325/537: Loss=0.3351 (C:0.3351, R:0.0105)
Batch 350/537: Loss=0.3308 (C:0.3308, R:0.0105)
Batch 375/537: Loss=0.3419 (C:0.3419, R:0.0105)
Batch 400/537: Loss=0.3242 (C:0.3242, R:0.0105)
Batch 425/537: Loss=0.3174 (C:0.3174, R:0.0105)
Batch 450/537: Loss=0.3210 (C:0.3210, R:0.0105)
Batch 475/537: Loss=0.3345 (C:0.3345, R:0.0105)
Batch 500/537: Loss=0.3407 (C:0.3407, R:0.0105)
Batch 525/537: Loss=0.3093 (C:0.3093, R:0.0105)

============================================================
Epoch 43/300 completed in 27.3s
Train: Loss=0.3215 (C:0.3215, R:0.0105) Ratio=4.60x
Val:   Loss=0.3871 (C:0.3871, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.195
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 44
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.194 ± 0.319
    Neg distances: 1.286 ± 0.560
    Separation ratio: 6.64x
    Gap: -2.214
    ✅ Excellent global separation!

Epoch 44 Training
----------------------------------------
Batch   0/537: Loss=0.3039 (C:0.3039, R:0.0105)
Batch  25/537: Loss=0.3191 (C:0.3191, R:0.0105)
Batch  50/537: Loss=0.3288 (C:0.3288, R:0.0105)
Batch  75/537: Loss=0.3110 (C:0.3110, R:0.0105)
Batch 100/537: Loss=0.3015 (C:0.3015, R:0.0105)
Batch 125/537: Loss=0.3236 (C:0.3236, R:0.0105)
Batch 150/537: Loss=0.3203 (C:0.3203, R:0.0105)
Batch 175/537: Loss=0.3341 (C:0.3341, R:0.0105)
Batch 200/537: Loss=0.3069 (C:0.3069, R:0.0105)
Batch 225/537: Loss=0.3140 (C:0.3140, R:0.0105)
Batch 250/537: Loss=0.3184 (C:0.3184, R:0.0105)
Batch 275/537: Loss=0.3210 (C:0.3210, R:0.0105)
Batch 300/537: Loss=0.3000 (C:0.3000, R:0.0105)
Batch 325/537: Loss=0.3242 (C:0.3242, R:0.0105)
Batch 350/537: Loss=0.3074 (C:0.3074, R:0.0105)
Batch 375/537: Loss=0.3148 (C:0.3148, R:0.0105)
Batch 400/537: Loss=0.2979 (C:0.2979, R:0.0105)
Batch 425/537: Loss=0.3239 (C:0.3239, R:0.0105)
Batch 450/537: Loss=0.3078 (C:0.3078, R:0.0105)
Batch 475/537: Loss=0.3156 (C:0.3156, R:0.0105)
Batch 500/537: Loss=0.3071 (C:0.3071, R:0.0105)
Batch 525/537: Loss=0.3265 (C:0.3265, R:0.0105)

============================================================
Epoch 44/300 completed in 26.8s
Train: Loss=0.3212 (C:0.3212, R:0.0105) Ratio=4.68x
Val:   Loss=0.3862 (C:0.3862, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.210
No improvement for 4 epochs
============================================================

🌍 Updating global dataset at epoch 45
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.189 ± 0.320
    Neg distances: 1.305 ± 0.564
    Separation ratio: 6.90x
    Gap: -2.216
    ✅ Excellent global separation!

Epoch 45 Training
----------------------------------------
Batch   0/537: Loss=0.3247 (C:0.3247, R:0.0105)
Batch  25/537: Loss=0.3234 (C:0.3234, R:0.0105)
Batch  50/537: Loss=0.3121 (C:0.3121, R:0.0105)
Batch  75/537: Loss=0.3185 (C:0.3185, R:0.0105)
Batch 100/537: Loss=0.3231 (C:0.3231, R:0.0105)
Batch 125/537: Loss=0.3069 (C:0.3069, R:0.0105)
Batch 150/537: Loss=0.3034 (C:0.3034, R:0.0105)
Batch 175/537: Loss=0.3359 (C:0.3359, R:0.0105)
Batch 200/537: Loss=0.3056 (C:0.3056, R:0.0105)
Batch 225/537: Loss=0.3129 (C:0.3129, R:0.0105)
Batch 250/537: Loss=0.3080 (C:0.3080, R:0.0105)
Batch 275/537: Loss=0.3156 (C:0.3156, R:0.0105)
Batch 300/537: Loss=0.3296 (C:0.3296, R:0.0105)
Batch 325/537: Loss=0.3293 (C:0.3293, R:0.0105)
Batch 350/537: Loss=0.3237 (C:0.3237, R:0.0105)
Batch 375/537: Loss=0.3056 (C:0.3056, R:0.0105)
Batch 400/537: Loss=0.3150 (C:0.3150, R:0.0105)
Batch 425/537: Loss=0.3246 (C:0.3246, R:0.0105)
Batch 450/537: Loss=0.3078 (C:0.3078, R:0.0105)
Batch 475/537: Loss=0.3148 (C:0.3148, R:0.0105)
Batch 500/537: Loss=0.3257 (C:0.3257, R:0.0105)
Batch 525/537: Loss=0.3008 (C:0.3008, R:0.0105)

============================================================
Epoch 45/300 completed in 26.9s
Train: Loss=0.3156 (C:0.3156, R:0.0105) Ratio=4.61x
Val:   Loss=0.3855 (C:0.3855, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.225
No improvement for 5 epochs
============================================================

🌍 Updating global dataset at epoch 46
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.166 ± 0.288
    Neg distances: 1.308 ± 0.550
    Separation ratio: 7.89x
    Gap: -2.186
    ✅ Excellent global separation!

Epoch 46 Training
----------------------------------------
Batch   0/537: Loss=0.2847 (C:0.2847, R:0.0105)
Batch  25/537: Loss=0.2891 (C:0.2891, R:0.0105)
Batch  50/537: Loss=0.2825 (C:0.2825, R:0.0105)
Batch  75/537: Loss=0.2867 (C:0.2867, R:0.0105)
Batch 100/537: Loss=0.2880 (C:0.2880, R:0.0105)
Batch 125/537: Loss=0.3025 (C:0.3025, R:0.0105)
Batch 150/537: Loss=0.3065 (C:0.3065, R:0.0105)
Batch 175/537: Loss=0.2933 (C:0.2933, R:0.0106)
Batch 200/537: Loss=0.3067 (C:0.3067, R:0.0105)
Batch 225/537: Loss=0.2898 (C:0.2898, R:0.0105)
Batch 250/537: Loss=0.2881 (C:0.2881, R:0.0105)
Batch 275/537: Loss=0.3103 (C:0.3103, R:0.0105)
Batch 300/537: Loss=0.3169 (C:0.3169, R:0.0105)
Batch 325/537: Loss=0.2998 (C:0.2998, R:0.0105)
Batch 350/537: Loss=0.3046 (C:0.3046, R:0.0105)
Batch 375/537: Loss=0.3114 (C:0.3114, R:0.0105)
Batch 400/537: Loss=0.2940 (C:0.2940, R:0.0105)
Batch 425/537: Loss=0.2991 (C:0.2991, R:0.0105)
Batch 450/537: Loss=0.3065 (C:0.3065, R:0.0105)
Batch 475/537: Loss=0.3199 (C:0.3199, R:0.0105)
Batch 500/537: Loss=0.2870 (C:0.2870, R:0.0105)
Batch 525/537: Loss=0.2942 (C:0.2942, R:0.0105)

============================================================
Epoch 46/300 completed in 27.0s
Train: Loss=0.2961 (C:0.2961, R:0.0105) Ratio=4.60x
Val:   Loss=0.3669 (C:0.3669, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.240
✅ New best model saved (Val Loss: 0.3669)
============================================================

🌍 Updating global dataset at epoch 47
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.177 ± 0.299
    Neg distances: 1.299 ± 0.554
    Separation ratio: 7.33x
    Gap: -2.190
    ✅ Excellent global separation!

Epoch 47 Training
----------------------------------------
Batch   0/537: Loss=0.3155 (C:0.3155, R:0.0105)
Batch  25/537: Loss=0.3023 (C:0.3023, R:0.0105)
Batch  50/537: Loss=0.3006 (C:0.3006, R:0.0105)
Batch  75/537: Loss=0.2897 (C:0.2897, R:0.0105)
Batch 100/537: Loss=0.3073 (C:0.3073, R:0.0105)
Batch 125/537: Loss=0.3119 (C:0.3119, R:0.0105)
Batch 150/537: Loss=0.2995 (C:0.2995, R:0.0105)
Batch 175/537: Loss=0.3043 (C:0.3043, R:0.0105)
Batch 200/537: Loss=0.2958 (C:0.2958, R:0.0105)
Batch 225/537: Loss=0.3113 (C:0.3113, R:0.0105)
Batch 250/537: Loss=0.2920 (C:0.2920, R:0.0105)
Batch 275/537: Loss=0.3134 (C:0.3134, R:0.0105)
Batch 300/537: Loss=0.3115 (C:0.3115, R:0.0105)
Batch 325/537: Loss=0.3065 (C:0.3065, R:0.0105)
Batch 350/537: Loss=0.2989 (C:0.2989, R:0.0105)
Batch 375/537: Loss=0.3059 (C:0.3059, R:0.0105)
Batch 400/537: Loss=0.3150 (C:0.3150, R:0.0105)
Batch 425/537: Loss=0.3027 (C:0.3027, R:0.0105)
Batch 450/537: Loss=0.3242 (C:0.3242, R:0.0105)
Batch 475/537: Loss=0.3104 (C:0.3104, R:0.0105)
Batch 500/537: Loss=0.3078 (C:0.3078, R:0.0105)
Batch 525/537: Loss=0.2914 (C:0.2914, R:0.0105)

============================================================
Epoch 47/300 completed in 26.8s
Train: Loss=0.3049 (C:0.3049, R:0.0105) Ratio=4.69x
Val:   Loss=0.3699 (C:0.3699, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.255
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 48
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.180 ± 0.300
    Neg distances: 1.295 ± 0.553
    Separation ratio: 7.19x
    Gap: -2.194
    ✅ Excellent global separation!

Epoch 48 Training
----------------------------------------
Batch   0/537: Loss=0.2864 (C:0.2864, R:0.0105)
Batch  25/537: Loss=0.3051 (C:0.3051, R:0.0105)
Batch  50/537: Loss=0.3029 (C:0.3029, R:0.0105)
Batch  75/537: Loss=0.2967 (C:0.2967, R:0.0105)
Batch 100/537: Loss=0.2989 (C:0.2989, R:0.0105)
Batch 125/537: Loss=0.3056 (C:0.3056, R:0.0105)
Batch 150/537: Loss=0.3064 (C:0.3064, R:0.0105)
Batch 175/537: Loss=0.3047 (C:0.3047, R:0.0105)
Batch 200/537: Loss=0.2972 (C:0.2972, R:0.0106)
Batch 225/537: Loss=0.2905 (C:0.2905, R:0.0105)
Batch 250/537: Loss=0.3000 (C:0.3000, R:0.0105)
Batch 275/537: Loss=0.3028 (C:0.3028, R:0.0105)
Batch 300/537: Loss=0.3002 (C:0.3002, R:0.0105)
Batch 325/537: Loss=0.2866 (C:0.2866, R:0.0105)
Batch 350/537: Loss=0.2982 (C:0.2982, R:0.0105)
Batch 375/537: Loss=0.3104 (C:0.3104, R:0.0105)
Batch 400/537: Loss=0.3018 (C:0.3018, R:0.0105)
Batch 425/537: Loss=0.3191 (C:0.3191, R:0.0106)
Batch 450/537: Loss=0.3150 (C:0.3150, R:0.0105)
Batch 475/537: Loss=0.3100 (C:0.3100, R:0.0105)
Batch 500/537: Loss=0.3081 (C:0.3081, R:0.0105)
Batch 525/537: Loss=0.3250 (C:0.3250, R:0.0105)

============================================================
Epoch 48/300 completed in 26.6s
Train: Loss=0.3060 (C:0.3060, R:0.0105) Ratio=4.77x
Val:   Loss=0.3824 (C:0.3824, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.270
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 49
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.175 ± 0.304
    Neg distances: 1.309 ± 0.555
    Separation ratio: 7.49x
    Gap: -2.240
    ✅ Excellent global separation!

Epoch 49 Training
----------------------------------------
Batch   0/537: Loss=0.2901 (C:0.2901, R:0.0106)
Batch  25/537: Loss=0.2907 (C:0.2907, R:0.0105)
Batch  50/537: Loss=0.2806 (C:0.2806, R:0.0105)
Batch  75/537: Loss=0.3059 (C:0.3059, R:0.0105)
Batch 100/537: Loss=0.2959 (C:0.2959, R:0.0105)
Batch 125/537: Loss=0.2925 (C:0.2925, R:0.0105)
Batch 150/537: Loss=0.2968 (C:0.2968, R:0.0105)
Batch 175/537: Loss=0.2877 (C:0.2877, R:0.0105)
Batch 200/537: Loss=0.2865 (C:0.2865, R:0.0105)
Batch 225/537: Loss=0.3042 (C:0.3042, R:0.0106)
Batch 250/537: Loss=0.3012 (C:0.3012, R:0.0105)
Batch 275/537: Loss=0.3066 (C:0.3066, R:0.0105)
Batch 300/537: Loss=0.3027 (C:0.3027, R:0.0105)
Batch 325/537: Loss=0.2921 (C:0.2921, R:0.0105)
Batch 350/537: Loss=0.3065 (C:0.3065, R:0.0105)
Batch 375/537: Loss=0.3063 (C:0.3063, R:0.0105)
Batch 400/537: Loss=0.2916 (C:0.2916, R:0.0105)
Batch 425/537: Loss=0.2964 (C:0.2964, R:0.0105)
Batch 450/537: Loss=0.3138 (C:0.3138, R:0.0106)
Batch 475/537: Loss=0.3149 (C:0.3149, R:0.0105)
Batch 500/537: Loss=0.3212 (C:0.3212, R:0.0105)
Batch 525/537: Loss=0.2890 (C:0.2890, R:0.0105)

============================================================
Epoch 49/300 completed in 27.2s
Train: Loss=0.3001 (C:0.3001, R:0.0105) Ratio=4.76x
Val:   Loss=0.3721 (C:0.3721, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.285
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 50
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.168 ± 0.289
    Neg distances: 1.319 ± 0.553
    Separation ratio: 7.87x
    Gap: -2.302
    ✅ Excellent global separation!

Epoch 50 Training
----------------------------------------
Batch   0/537: Loss=0.2784 (C:0.2784, R:0.0105)
Batch  25/537: Loss=0.2692 (C:0.2692, R:0.0105)
Batch  50/537: Loss=0.2819 (C:0.2819, R:0.0105)
Batch  75/537: Loss=0.3127 (C:0.3127, R:0.0105)
Batch 100/537: Loss=0.2872 (C:0.2872, R:0.0105)
Batch 125/537: Loss=0.3110 (C:0.3110, R:0.0105)
Batch 150/537: Loss=0.3059 (C:0.3059, R:0.0105)
Batch 175/537: Loss=0.3051 (C:0.3051, R:0.0105)
Batch 200/537: Loss=0.3099 (C:0.3099, R:0.0105)
Batch 225/537: Loss=0.2965 (C:0.2965, R:0.0105)
Batch 250/537: Loss=0.2824 (C:0.2824, R:0.0105)
Batch 275/537: Loss=0.3011 (C:0.3011, R:0.0105)
Batch 300/537: Loss=0.3036 (C:0.3036, R:0.0105)
Batch 325/537: Loss=0.3003 (C:0.3003, R:0.0105)
Batch 350/537: Loss=0.2773 (C:0.2773, R:0.0105)
Batch 375/537: Loss=0.3026 (C:0.3026, R:0.0105)
Batch 400/537: Loss=0.2977 (C:0.2977, R:0.0105)
Batch 425/537: Loss=0.3007 (C:0.3007, R:0.0105)
Batch 450/537: Loss=0.2851 (C:0.2851, R:0.0105)
Batch 475/537: Loss=0.2980 (C:0.2980, R:0.0106)
Batch 500/537: Loss=0.3096 (C:0.3096, R:0.0105)
Batch 525/537: Loss=0.2896 (C:0.2896, R:0.0105)

============================================================
Epoch 50/300 completed in 27.6s
Train: Loss=0.2926 (C:0.2926, R:0.0105) Ratio=4.74x
Val:   Loss=0.3657 (C:0.3657, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.3657)
============================================================

🌍 Updating global dataset at epoch 51
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.175 ± 0.314
    Neg distances: 1.313 ± 0.557
    Separation ratio: 7.50x
    Gap: -2.208
    ✅ Excellent global separation!

Epoch 51 Training
----------------------------------------
Batch   0/537: Loss=0.2856 (C:0.2856, R:0.0105)
Batch  25/537: Loss=0.3055 (C:0.3055, R:0.0106)
Batch  50/537: Loss=0.3144 (C:0.3144, R:0.0105)
Batch  75/537: Loss=0.3094 (C:0.3094, R:0.0105)
Batch 100/537: Loss=0.2928 (C:0.2928, R:0.0105)
Batch 125/537: Loss=0.2930 (C:0.2930, R:0.0105)
Batch 150/537: Loss=0.2986 (C:0.2986, R:0.0105)
Batch 175/537: Loss=0.2838 (C:0.2838, R:0.0105)
Batch 200/537: Loss=0.2976 (C:0.2976, R:0.0105)
Batch 225/537: Loss=0.3069 (C:0.3069, R:0.0105)
Batch 250/537: Loss=0.3118 (C:0.3118, R:0.0105)
Batch 275/537: Loss=0.2955 (C:0.2955, R:0.0105)
Batch 300/537: Loss=0.2836 (C:0.2836, R:0.0105)
Batch 325/537: Loss=0.3093 (C:0.3093, R:0.0105)
Batch 350/537: Loss=0.2927 (C:0.2927, R:0.0105)
Batch 375/537: Loss=0.2852 (C:0.2852, R:0.0105)
Batch 400/537: Loss=0.2969 (C:0.2969, R:0.0105)
Batch 425/537: Loss=0.3117 (C:0.3117, R:0.0105)
Batch 450/537: Loss=0.2982 (C:0.2982, R:0.0105)
Batch 475/537: Loss=0.3067 (C:0.3067, R:0.0105)
Batch 500/537: Loss=0.3007 (C:0.3007, R:0.0105)
Batch 525/537: Loss=0.2972 (C:0.2972, R:0.0106)

============================================================
Epoch 51/300 completed in 27.1s
Train: Loss=0.2985 (C:0.2985, R:0.0105) Ratio=4.81x
Val:   Loss=0.3747 (C:0.3747, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 52
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.165 ± 0.294
    Neg distances: 1.321 ± 0.555
    Separation ratio: 7.99x
    Gap: -2.249
    ✅ Excellent global separation!

Epoch 52 Training
----------------------------------------
Batch   0/537: Loss=0.2753 (C:0.2753, R:0.0105)
Batch  25/537: Loss=0.3073 (C:0.3073, R:0.0105)
Batch  50/537: Loss=0.2871 (C:0.2871, R:0.0105)
Batch  75/537: Loss=0.2773 (C:0.2773, R:0.0105)
Batch 100/537: Loss=0.2842 (C:0.2842, R:0.0105)
Batch 125/537: Loss=0.2869 (C:0.2869, R:0.0105)
Batch 150/537: Loss=0.2856 (C:0.2856, R:0.0105)
Batch 175/537: Loss=0.2850 (C:0.2850, R:0.0106)
Batch 200/537: Loss=0.2796 (C:0.2796, R:0.0105)
Batch 225/537: Loss=0.2846 (C:0.2846, R:0.0105)
Batch 250/537: Loss=0.2791 (C:0.2791, R:0.0105)
Batch 275/537: Loss=0.2813 (C:0.2813, R:0.0105)
Batch 300/537: Loss=0.2939 (C:0.2939, R:0.0105)
Batch 325/537: Loss=0.2903 (C:0.2903, R:0.0105)
Batch 350/537: Loss=0.2803 (C:0.2803, R:0.0105)
Batch 375/537: Loss=0.3000 (C:0.3000, R:0.0105)
Batch 400/537: Loss=0.2963 (C:0.2963, R:0.0105)
Batch 425/537: Loss=0.2999 (C:0.2999, R:0.0105)
Batch 450/537: Loss=0.2780 (C:0.2780, R:0.0105)
Batch 475/537: Loss=0.2870 (C:0.2870, R:0.0105)
Batch 500/537: Loss=0.2964 (C:0.2964, R:0.0105)
Batch 525/537: Loss=0.3166 (C:0.3166, R:0.0105)

============================================================
Epoch 52/300 completed in 26.7s
Train: Loss=0.2899 (C:0.2899, R:0.0105) Ratio=4.85x
Val:   Loss=0.3648 (C:0.3648, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.3648)
============================================================

🌍 Updating global dataset at epoch 53
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.159 ± 0.278
    Neg distances: 1.309 ± 0.547
    Separation ratio: 8.25x
    Gap: -2.226
    ✅ Excellent global separation!

Epoch 53 Training
----------------------------------------
Batch   0/537: Loss=0.2928 (C:0.2928, R:0.0105)
Batch  25/537: Loss=0.2955 (C:0.2955, R:0.0106)
Batch  50/537: Loss=0.2589 (C:0.2589, R:0.0105)
Batch  75/537: Loss=0.2708 (C:0.2708, R:0.0105)
Batch 100/537: Loss=0.2662 (C:0.2662, R:0.0106)
Batch 125/537: Loss=0.2926 (C:0.2926, R:0.0105)
Batch 150/537: Loss=0.2887 (C:0.2887, R:0.0105)
Batch 175/537: Loss=0.3059 (C:0.3059, R:0.0105)
Batch 200/537: Loss=0.2938 (C:0.2938, R:0.0105)
Batch 225/537: Loss=0.2880 (C:0.2880, R:0.0105)
Batch 250/537: Loss=0.3088 (C:0.3088, R:0.0105)
Batch 275/537: Loss=0.2869 (C:0.2869, R:0.0105)
Batch 300/537: Loss=0.2860 (C:0.2860, R:0.0106)
Batch 325/537: Loss=0.2918 (C:0.2918, R:0.0105)
Batch 350/537: Loss=0.3095 (C:0.3095, R:0.0105)
Batch 375/537: Loss=0.2947 (C:0.2947, R:0.0105)
Batch 400/537: Loss=0.2985 (C:0.2985, R:0.0105)
Batch 425/537: Loss=0.2832 (C:0.2832, R:0.0105)
Batch 450/537: Loss=0.2820 (C:0.2820, R:0.0105)
Batch 475/537: Loss=0.2759 (C:0.2759, R:0.0105)
Batch 500/537: Loss=0.2824 (C:0.2824, R:0.0105)
Batch 525/537: Loss=0.2633 (C:0.2633, R:0.0105)

============================================================
Epoch 53/300 completed in 26.7s
Train: Loss=0.2849 (C:0.2849, R:0.0105) Ratio=4.80x
Val:   Loss=0.3621 (C:0.3621, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.3621)
============================================================

🌍 Updating global dataset at epoch 54
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.157 ± 0.284
    Neg distances: 1.314 ± 0.548
    Separation ratio: 8.36x
    Gap: -2.255
    ✅ Excellent global separation!

Epoch 54 Training
----------------------------------------
Batch   0/537: Loss=0.2659 (C:0.2659, R:0.0106)
Batch  25/537: Loss=0.2842 (C:0.2842, R:0.0105)
Batch  50/537: Loss=0.2751 (C:0.2751, R:0.0105)
Batch  75/537: Loss=0.2932 (C:0.2932, R:0.0105)
Batch 100/537: Loss=0.2881 (C:0.2881, R:0.0105)
Batch 125/537: Loss=0.2969 (C:0.2969, R:0.0105)
Batch 150/537: Loss=0.2756 (C:0.2756, R:0.0105)
Batch 175/537: Loss=0.2754 (C:0.2754, R:0.0105)
Batch 200/537: Loss=0.2960 (C:0.2960, R:0.0105)
Batch 225/537: Loss=0.2794 (C:0.2794, R:0.0105)
Batch 250/537: Loss=0.2902 (C:0.2902, R:0.0105)
Batch 275/537: Loss=0.2856 (C:0.2856, R:0.0105)
Batch 300/537: Loss=0.2854 (C:0.2854, R:0.0105)
Batch 325/537: Loss=0.2817 (C:0.2817, R:0.0105)
Batch 350/537: Loss=0.2817 (C:0.2817, R:0.0105)
Batch 375/537: Loss=0.2623 (C:0.2623, R:0.0105)
Batch 400/537: Loss=0.3104 (C:0.3104, R:0.0105)
Batch 425/537: Loss=0.2878 (C:0.2878, R:0.0105)
Batch 450/537: Loss=0.3026 (C:0.3026, R:0.0105)
Batch 475/537: Loss=0.2952 (C:0.2952, R:0.0106)
Batch 500/537: Loss=0.2937 (C:0.2937, R:0.0105)
Batch 525/537: Loss=0.2746 (C:0.2746, R:0.0105)

============================================================
Epoch 54/300 completed in 27.6s
Train: Loss=0.2824 (C:0.2824, R:0.0105) Ratio=4.82x
Val:   Loss=0.3616 (C:0.3616, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.3616)
============================================================

🌍 Updating global dataset at epoch 55
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.164 ± 0.303
    Neg distances: 1.328 ± 0.556
    Separation ratio: 8.07x
    Gap: -2.220
    ✅ Excellent global separation!

Epoch 55 Training
----------------------------------------
Batch   0/537: Loss=0.2809 (C:0.2809, R:0.0105)
Batch  25/537: Loss=0.2694 (C:0.2694, R:0.0106)
Batch  50/537: Loss=0.3007 (C:0.3007, R:0.0105)
Batch  75/537: Loss=0.2640 (C:0.2640, R:0.0105)
Batch 100/537: Loss=0.2755 (C:0.2755, R:0.0105)
Batch 125/537: Loss=0.2794 (C:0.2794, R:0.0105)
Batch 150/537: Loss=0.2818 (C:0.2818, R:0.0105)
Batch 175/537: Loss=0.2951 (C:0.2951, R:0.0105)
Batch 200/537: Loss=0.2723 (C:0.2723, R:0.0105)
Batch 225/537: Loss=0.2808 (C:0.2808, R:0.0105)
Batch 250/537: Loss=0.2923 (C:0.2923, R:0.0105)
Batch 275/537: Loss=0.2954 (C:0.2954, R:0.0105)
Batch 300/537: Loss=0.3045 (C:0.3045, R:0.0105)
Batch 325/537: Loss=0.2918 (C:0.2918, R:0.0105)
Batch 350/537: Loss=0.2995 (C:0.2995, R:0.0105)
Batch 375/537: Loss=0.2914 (C:0.2914, R:0.0105)
Batch 400/537: Loss=0.2746 (C:0.2746, R:0.0105)
Batch 425/537: Loss=0.2745 (C:0.2745, R:0.0105)
Batch 450/537: Loss=0.2720 (C:0.2720, R:0.0105)
Batch 475/537: Loss=0.3057 (C:0.3057, R:0.0105)
Batch 500/537: Loss=0.2919 (C:0.2919, R:0.0105)
Batch 525/537: Loss=0.2777 (C:0.2777, R:0.0105)

============================================================
Epoch 55/300 completed in 27.3s
Train: Loss=0.2860 (C:0.2860, R:0.0105) Ratio=4.87x
Val:   Loss=0.3684 (C:0.3684, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 56
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.159 ± 0.291
    Neg distances: 1.330 ± 0.553
    Separation ratio: 8.35x
    Gap: -2.314
    ✅ Excellent global separation!

Epoch 56 Training
----------------------------------------
Batch   0/537: Loss=0.2700 (C:0.2700, R:0.0105)
Batch  25/537: Loss=0.2808 (C:0.2808, R:0.0105)
Batch  50/537: Loss=0.2757 (C:0.2757, R:0.0105)
Batch  75/537: Loss=0.2797 (C:0.2797, R:0.0105)
Batch 100/537: Loss=0.2550 (C:0.2550, R:0.0105)
Batch 125/537: Loss=0.2756 (C:0.2756, R:0.0105)
Batch 150/537: Loss=0.2965 (C:0.2965, R:0.0105)
Batch 175/537: Loss=0.2762 (C:0.2762, R:0.0105)
Batch 200/537: Loss=0.2697 (C:0.2697, R:0.0105)
Batch 225/537: Loss=0.2709 (C:0.2709, R:0.0105)
Batch 250/537: Loss=0.2875 (C:0.2875, R:0.0105)
Batch 275/537: Loss=0.2787 (C:0.2787, R:0.0105)
Batch 300/537: Loss=0.2824 (C:0.2824, R:0.0105)
Batch 325/537: Loss=0.2881 (C:0.2881, R:0.0105)
Batch 350/537: Loss=0.2882 (C:0.2882, R:0.0106)
Batch 375/537: Loss=0.2848 (C:0.2848, R:0.0105)
Batch 400/537: Loss=0.2654 (C:0.2654, R:0.0105)
Batch 425/537: Loss=0.2774 (C:0.2774, R:0.0105)
Batch 450/537: Loss=0.2657 (C:0.2657, R:0.0105)
Batch 475/537: Loss=0.2843 (C:0.2843, R:0.0105)
Batch 500/537: Loss=0.2839 (C:0.2839, R:0.0105)
Batch 525/537: Loss=0.2882 (C:0.2882, R:0.0105)

============================================================
Epoch 56/300 completed in 27.0s
Train: Loss=0.2807 (C:0.2807, R:0.0105) Ratio=4.96x
Val:   Loss=0.3618 (C:0.3618, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 57
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.163 ± 0.288
    Neg distances: 1.319 ± 0.552
    Separation ratio: 8.09x
    Gap: -2.236
    ✅ Excellent global separation!

Epoch 57 Training
----------------------------------------
Batch   0/537: Loss=0.2877 (C:0.2877, R:0.0105)
Batch  25/537: Loss=0.2726 (C:0.2726, R:0.0105)
Batch  50/537: Loss=0.2810 (C:0.2810, R:0.0105)
Batch  75/537: Loss=0.2942 (C:0.2942, R:0.0105)
Batch 100/537: Loss=0.2739 (C:0.2739, R:0.0105)
Batch 125/537: Loss=0.2786 (C:0.2786, R:0.0105)
Batch 150/537: Loss=0.2905 (C:0.2905, R:0.0105)
Batch 175/537: Loss=0.2806 (C:0.2806, R:0.0105)
Batch 200/537: Loss=0.2788 (C:0.2788, R:0.0105)
Batch 225/537: Loss=0.2620 (C:0.2620, R:0.0105)
Batch 250/537: Loss=0.2884 (C:0.2884, R:0.0105)
Batch 275/537: Loss=0.2909 (C:0.2909, R:0.0105)
Batch 300/537: Loss=0.2981 (C:0.2981, R:0.0105)
Batch 325/537: Loss=0.2818 (C:0.2818, R:0.0105)
Batch 350/537: Loss=0.2972 (C:0.2972, R:0.0105)
Batch 375/537: Loss=0.2876 (C:0.2876, R:0.0105)
Batch 400/537: Loss=0.2913 (C:0.2913, R:0.0105)
Batch 425/537: Loss=0.2791 (C:0.2791, R:0.0105)
Batch 450/537: Loss=0.2789 (C:0.2789, R:0.0105)
Batch 475/537: Loss=0.2921 (C:0.2921, R:0.0105)
Batch 500/537: Loss=0.2879 (C:0.2879, R:0.0105)
Batch 525/537: Loss=0.2677 (C:0.2677, R:0.0105)

============================================================
Epoch 57/300 completed in 26.8s
Train: Loss=0.2833 (C:0.2833, R:0.0105) Ratio=4.95x
Val:   Loss=0.3622 (C:0.3622, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 58
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.152 ± 0.278
    Neg distances: 1.311 ± 0.543
    Separation ratio: 8.60x
    Gap: -2.244
    ✅ Excellent global separation!

Epoch 58 Training
----------------------------------------
Batch   0/537: Loss=0.2776 (C:0.2776, R:0.0105)
Batch  25/537: Loss=0.2670 (C:0.2670, R:0.0105)
Batch  50/537: Loss=0.2738 (C:0.2738, R:0.0106)
Batch  75/537: Loss=0.2673 (C:0.2673, R:0.0105)
Batch 100/537: Loss=0.2696 (C:0.2696, R:0.0105)
Batch 125/537: Loss=0.2840 (C:0.2840, R:0.0105)
Batch 150/537: Loss=0.2661 (C:0.2661, R:0.0106)
Batch 175/537: Loss=0.2669 (C:0.2669, R:0.0105)
Batch 200/537: Loss=0.2826 (C:0.2826, R:0.0105)
Batch 225/537: Loss=0.2736 (C:0.2736, R:0.0105)
Batch 250/537: Loss=0.2732 (C:0.2732, R:0.0105)
Batch 275/537: Loss=0.2776 (C:0.2776, R:0.0105)
Batch 300/537: Loss=0.2690 (C:0.2690, R:0.0105)
Batch 325/537: Loss=0.2728 (C:0.2728, R:0.0105)
Batch 350/537: Loss=0.2477 (C:0.2477, R:0.0105)
Batch 375/537: Loss=0.2721 (C:0.2721, R:0.0105)
Batch 400/537: Loss=0.2917 (C:0.2917, R:0.0105)
Batch 425/537: Loss=0.2853 (C:0.2853, R:0.0105)
Batch 450/537: Loss=0.2594 (C:0.2594, R:0.0105)
Batch 475/537: Loss=0.2840 (C:0.2840, R:0.0105)
Batch 500/537: Loss=0.2873 (C:0.2873, R:0.0105)
Batch 525/537: Loss=0.2826 (C:0.2826, R:0.0105)

============================================================
Epoch 58/300 completed in 26.9s
Train: Loss=0.2748 (C:0.2748, R:0.0105) Ratio=4.94x
Val:   Loss=0.3474 (C:0.3474, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.3474)
============================================================

🌍 Updating global dataset at epoch 59
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.155 ± 0.288
    Neg distances: 1.312 ± 0.547
    Separation ratio: 8.44x
    Gap: -2.225
    ✅ Excellent global separation!

Epoch 59 Training
----------------------------------------
Batch   0/537: Loss=0.2557 (C:0.2557, R:0.0105)
Batch  25/537: Loss=0.2790 (C:0.2790, R:0.0105)
Batch  50/537: Loss=0.2504 (C:0.2504, R:0.0105)
Batch  75/537: Loss=0.2680 (C:0.2680, R:0.0105)
Batch 100/537: Loss=0.2722 (C:0.2722, R:0.0105)
Batch 125/537: Loss=0.2826 (C:0.2826, R:0.0105)
Batch 150/537: Loss=0.2956 (C:0.2956, R:0.0105)
Batch 175/537: Loss=0.2763 (C:0.2763, R:0.0105)
Batch 200/537: Loss=0.2636 (C:0.2636, R:0.0105)
Batch 225/537: Loss=0.2656 (C:0.2656, R:0.0105)
Batch 250/537: Loss=0.2698 (C:0.2698, R:0.0105)
Batch 275/537: Loss=0.2805 (C:0.2805, R:0.0105)
Batch 300/537: Loss=0.2664 (C:0.2664, R:0.0105)
Batch 325/537: Loss=0.2870 (C:0.2870, R:0.0105)
Batch 350/537: Loss=0.2715 (C:0.2715, R:0.0105)
Batch 375/537: Loss=0.2982 (C:0.2982, R:0.0106)
Batch 400/537: Loss=0.2663 (C:0.2663, R:0.0105)
Batch 425/537: Loss=0.2747 (C:0.2747, R:0.0105)
Batch 450/537: Loss=0.2890 (C:0.2890, R:0.0105)
Batch 475/537: Loss=0.2797 (C:0.2797, R:0.0105)
Batch 500/537: Loss=0.2772 (C:0.2772, R:0.0105)
Batch 525/537: Loss=0.2835 (C:0.2835, R:0.0105)

============================================================
Epoch 59/300 completed in 27.4s
Train: Loss=0.2773 (C:0.2773, R:0.0105) Ratio=4.99x
Val:   Loss=0.3626 (C:0.3626, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 60
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.163 ± 0.298
    Neg distances: 1.333 ± 0.557
    Separation ratio: 8.20x
    Gap: -2.303
    ✅ Excellent global separation!

Epoch 60 Training
----------------------------------------
Batch   0/537: Loss=0.2755 (C:0.2755, R:0.0105)
Batch  25/537: Loss=0.2781 (C:0.2781, R:0.0105)
Batch  50/537: Loss=0.2688 (C:0.2688, R:0.0105)
Batch  75/537: Loss=0.2794 (C:0.2794, R:0.0105)
Batch 100/537: Loss=0.2754 (C:0.2754, R:0.0105)
Batch 125/537: Loss=0.2808 (C:0.2808, R:0.0105)
Batch 150/537: Loss=0.2528 (C:0.2528, R:0.0105)
Batch 175/537: Loss=0.2914 (C:0.2914, R:0.0105)
Batch 200/537: Loss=0.2843 (C:0.2843, R:0.0105)
Batch 225/537: Loss=0.2760 (C:0.2760, R:0.0105)
Batch 250/537: Loss=0.2882 (C:0.2882, R:0.0106)
Batch 275/537: Loss=0.2904 (C:0.2904, R:0.0105)
Batch 300/537: Loss=0.2864 (C:0.2864, R:0.0105)
Batch 325/537: Loss=0.2969 (C:0.2969, R:0.0105)
Batch 350/537: Loss=0.2716 (C:0.2716, R:0.0105)
Batch 375/537: Loss=0.2799 (C:0.2799, R:0.0105)
Batch 400/537: Loss=0.2804 (C:0.2804, R:0.0105)
Batch 425/537: Loss=0.2912 (C:0.2912, R:0.0105)
Batch 450/537: Loss=0.2980 (C:0.2980, R:0.0105)
Batch 475/537: Loss=0.2774 (C:0.2774, R:0.0105)
Batch 500/537: Loss=0.2801 (C:0.2801, R:0.0105)
Batch 525/537: Loss=0.2686 (C:0.2686, R:0.0105)

============================================================
Epoch 60/300 completed in 27.5s
Train: Loss=0.2811 (C:0.2811, R:0.0105) Ratio=4.94x
Val:   Loss=0.3635 (C:0.3635, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
No improvement for 2 epochs
Checkpoint saved at epoch 60
============================================================

🌍 Updating global dataset at epoch 61
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.161 ± 0.298
    Neg distances: 1.337 ± 0.559
    Separation ratio: 8.33x
    Gap: -2.300
    ✅ Excellent global separation!

Epoch 61 Training
----------------------------------------
Batch   0/537: Loss=0.2767 (C:0.2767, R:0.0105)
Batch  25/537: Loss=0.2860 (C:0.2860, R:0.0105)
Batch  50/537: Loss=0.2844 (C:0.2844, R:0.0105)
Batch  75/537: Loss=0.2666 (C:0.2666, R:0.0105)
Batch 100/537: Loss=0.2838 (C:0.2838, R:0.0105)
Batch 125/537: Loss=0.2692 (C:0.2692, R:0.0105)
Batch 150/537: Loss=0.2809 (C:0.2809, R:0.0105)
Batch 175/537: Loss=0.2807 (C:0.2807, R:0.0105)
Batch 200/537: Loss=0.2786 (C:0.2786, R:0.0105)
Batch 225/537: Loss=0.2707 (C:0.2707, R:0.0105)
Batch 250/537: Loss=0.2921 (C:0.2921, R:0.0105)
Batch 275/537: Loss=0.2696 (C:0.2696, R:0.0105)
Batch 300/537: Loss=0.2718 (C:0.2718, R:0.0105)
Batch 325/537: Loss=0.2836 (C:0.2836, R:0.0105)
Batch 350/537: Loss=0.2812 (C:0.2812, R:0.0105)
Batch 375/537: Loss=0.2876 (C:0.2876, R:0.0105)
Batch 400/537: Loss=0.2795 (C:0.2795, R:0.0105)
Batch 425/537: Loss=0.2739 (C:0.2739, R:0.0105)
Batch 450/537: Loss=0.2658 (C:0.2658, R:0.0105)
Batch 475/537: Loss=0.2944 (C:0.2944, R:0.0105)
Batch 500/537: Loss=0.2807 (C:0.2807, R:0.0105)
Batch 525/537: Loss=0.2746 (C:0.2746, R:0.0106)

============================================================
Epoch 61/300 completed in 27.4s
Train: Loss=0.2788 (C:0.2788, R:0.0105) Ratio=5.06x
Val:   Loss=0.3611 (C:0.3611, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 62
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.158 ± 0.289
    Neg distances: 1.326 ± 0.555
    Separation ratio: 8.39x
    Gap: -2.274
    ✅ Excellent global separation!

Epoch 62 Training
----------------------------------------
Batch   0/537: Loss=0.2607 (C:0.2607, R:0.0105)
Batch  25/537: Loss=0.2618 (C:0.2618, R:0.0105)
Batch  50/537: Loss=0.2599 (C:0.2599, R:0.0105)
Batch  75/537: Loss=0.2632 (C:0.2632, R:0.0105)
Batch 100/537: Loss=0.2754 (C:0.2754, R:0.0105)
Batch 125/537: Loss=0.2727 (C:0.2727, R:0.0105)
Batch 150/537: Loss=0.2645 (C:0.2645, R:0.0105)
Batch 175/537: Loss=0.2613 (C:0.2613, R:0.0105)
Batch 200/537: Loss=0.2914 (C:0.2914, R:0.0105)
Batch 225/537: Loss=0.2875 (C:0.2875, R:0.0106)
Batch 250/537: Loss=0.2923 (C:0.2923, R:0.0105)
Batch 275/537: Loss=0.2920 (C:0.2920, R:0.0105)
Batch 300/537: Loss=0.2736 (C:0.2736, R:0.0105)
Batch 325/537: Loss=0.2621 (C:0.2621, R:0.0105)
Batch 350/537: Loss=0.2954 (C:0.2954, R:0.0105)
Batch 375/537: Loss=0.2875 (C:0.2875, R:0.0105)
Batch 400/537: Loss=0.2742 (C:0.2742, R:0.0105)
Batch 425/537: Loss=0.2892 (C:0.2892, R:0.0105)
Batch 450/537: Loss=0.2922 (C:0.2922, R:0.0105)
Batch 475/537: Loss=0.2836 (C:0.2836, R:0.0105)
Batch 500/537: Loss=0.2734 (C:0.2734, R:0.0105)
Batch 525/537: Loss=0.2593 (C:0.2593, R:0.0105)

============================================================
Epoch 62/300 completed in 27.0s
Train: Loss=0.2773 (C:0.2773, R:0.0105) Ratio=5.02x
Val:   Loss=0.3603 (C:0.3603, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 4 epochs
============================================================

🌍 Updating global dataset at epoch 63
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.155 ± 0.284
    Neg distances: 1.329 ± 0.551
    Separation ratio: 8.57x
    Gap: -2.240
    ✅ Excellent global separation!

Epoch 63 Training
----------------------------------------
Batch   0/537: Loss=0.2696 (C:0.2696, R:0.0105)
Batch  25/537: Loss=0.2548 (C:0.2548, R:0.0105)
Batch  50/537: Loss=0.2797 (C:0.2797, R:0.0105)
Batch  75/537: Loss=0.2656 (C:0.2656, R:0.0105)
Batch 100/537: Loss=0.2537 (C:0.2537, R:0.0105)
Batch 125/537: Loss=0.2750 (C:0.2750, R:0.0105)
Batch 150/537: Loss=0.2730 (C:0.2730, R:0.0105)
Batch 175/537: Loss=0.2613 (C:0.2613, R:0.0105)
Batch 200/537: Loss=0.2833 (C:0.2833, R:0.0106)
Batch 225/537: Loss=0.2837 (C:0.2837, R:0.0105)
Batch 250/537: Loss=0.2697 (C:0.2697, R:0.0105)
Batch 275/537: Loss=0.2884 (C:0.2884, R:0.0105)
Batch 300/537: Loss=0.2704 (C:0.2704, R:0.0105)
Batch 325/537: Loss=0.2711 (C:0.2711, R:0.0105)
Batch 350/537: Loss=0.2551 (C:0.2551, R:0.0105)
Batch 375/537: Loss=0.2780 (C:0.2780, R:0.0105)
Batch 400/537: Loss=0.2650 (C:0.2650, R:0.0106)
Batch 425/537: Loss=0.2669 (C:0.2669, R:0.0105)
Batch 450/537: Loss=0.2784 (C:0.2784, R:0.0105)
Batch 475/537: Loss=0.2652 (C:0.2652, R:0.0105)
Batch 500/537: Loss=0.2810 (C:0.2810, R:0.0105)
Batch 525/537: Loss=0.2647 (C:0.2647, R:0.0105)

============================================================
Epoch 63/300 completed in 27.1s
Train: Loss=0.2732 (C:0.2732, R:0.0105) Ratio=5.16x
Val:   Loss=0.3567 (C:0.3567, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 5 epochs
============================================================

🌍 Updating global dataset at epoch 64
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.153 ± 0.283
    Neg distances: 1.349 ± 0.558
    Separation ratio: 8.81x
    Gap: -2.268
    ✅ Excellent global separation!

Epoch 64 Training
----------------------------------------
Batch   0/537: Loss=0.2551 (C:0.2551, R:0.0105)
Batch  25/537: Loss=0.2533 (C:0.2533, R:0.0106)
Batch  50/537: Loss=0.2657 (C:0.2657, R:0.0105)
Batch  75/537: Loss=0.2581 (C:0.2581, R:0.0105)
Batch 100/537: Loss=0.2766 (C:0.2766, R:0.0105)
Batch 125/537: Loss=0.2691 (C:0.2691, R:0.0105)
Batch 150/537: Loss=0.2602 (C:0.2602, R:0.0105)
Batch 175/537: Loss=0.2749 (C:0.2749, R:0.0105)
Batch 200/537: Loss=0.2525 (C:0.2525, R:0.0105)
Batch 225/537: Loss=0.2663 (C:0.2663, R:0.0105)
Batch 250/537: Loss=0.2862 (C:0.2862, R:0.0105)
Batch 275/537: Loss=0.2733 (C:0.2733, R:0.0105)
Batch 300/537: Loss=0.2658 (C:0.2658, R:0.0105)
Batch 325/537: Loss=0.2692 (C:0.2692, R:0.0105)
Batch 350/537: Loss=0.2748 (C:0.2748, R:0.0105)
Batch 375/537: Loss=0.2725 (C:0.2725, R:0.0105)
Batch 400/537: Loss=0.2724 (C:0.2724, R:0.0105)
Batch 425/537: Loss=0.2692 (C:0.2692, R:0.0105)
Batch 450/537: Loss=0.2756 (C:0.2756, R:0.0105)
Batch 475/537: Loss=0.2777 (C:0.2777, R:0.0105)
Batch 500/537: Loss=0.2869 (C:0.2869, R:0.0105)
Batch 525/537: Loss=0.2841 (C:0.2841, R:0.0105)

============================================================
Epoch 64/300 completed in 27.4s
Train: Loss=0.2702 (C:0.2702, R:0.0105) Ratio=5.19x
Val:   Loss=0.3570 (C:0.3570, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 6 epochs
============================================================

🌍 Updating global dataset at epoch 65
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.148 ± 0.290
    Neg distances: 1.325 ± 0.548
    Separation ratio: 8.94x
    Gap: -2.252
    ✅ Excellent global separation!

Epoch 65 Training
----------------------------------------
Batch   0/537: Loss=0.2574 (C:0.2574, R:0.0105)
Batch  25/537: Loss=0.2466 (C:0.2466, R:0.0105)
Batch  50/537: Loss=0.2543 (C:0.2543, R:0.0105)
Batch  75/537: Loss=0.2556 (C:0.2556, R:0.0105)
Batch 100/537: Loss=0.2581 (C:0.2581, R:0.0105)
Batch 125/537: Loss=0.2583 (C:0.2583, R:0.0105)
Batch 150/537: Loss=0.2665 (C:0.2665, R:0.0105)
Batch 175/537: Loss=0.2521 (C:0.2521, R:0.0105)
Batch 200/537: Loss=0.2705 (C:0.2705, R:0.0105)
Batch 225/537: Loss=0.2580 (C:0.2580, R:0.0105)
Batch 250/537: Loss=0.2750 (C:0.2750, R:0.0105)
Batch 275/537: Loss=0.2679 (C:0.2679, R:0.0105)
Batch 300/537: Loss=0.2673 (C:0.2673, R:0.0105)
Batch 325/537: Loss=0.2640 (C:0.2640, R:0.0105)
Batch 350/537: Loss=0.2571 (C:0.2571, R:0.0105)
Batch 375/537: Loss=0.2517 (C:0.2517, R:0.0105)
Batch 400/537: Loss=0.2573 (C:0.2573, R:0.0105)
Batch 425/537: Loss=0.2643 (C:0.2643, R:0.0105)
Batch 450/537: Loss=0.2780 (C:0.2780, R:0.0105)
Batch 475/537: Loss=0.2621 (C:0.2621, R:0.0105)
Batch 500/537: Loss=0.2834 (C:0.2834, R:0.0105)
Batch 525/537: Loss=0.2762 (C:0.2762, R:0.0105)

============================================================
Epoch 65/300 completed in 27.7s
Train: Loss=0.2666 (C:0.2666, R:0.0105) Ratio=5.17x
Val:   Loss=0.3532 (C:0.3532, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 7 epochs
============================================================

🌍 Updating global dataset at epoch 66
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.146 ± 0.283
    Neg distances: 1.355 ± 0.556
    Separation ratio: 9.27x
    Gap: -2.276
    ✅ Excellent global separation!

Epoch 66 Training
----------------------------------------
Batch   0/537: Loss=0.2574 (C:0.2574, R:0.0105)
Batch  25/537: Loss=0.2527 (C:0.2527, R:0.0105)
Batch  50/537: Loss=0.2700 (C:0.2700, R:0.0105)
Batch  75/537: Loss=0.2668 (C:0.2668, R:0.0105)
Batch 100/537: Loss=0.2495 (C:0.2495, R:0.0105)
Batch 125/537: Loss=0.2745 (C:0.2745, R:0.0105)
Batch 150/537: Loss=0.2458 (C:0.2458, R:0.0105)
Batch 175/537: Loss=0.2625 (C:0.2625, R:0.0105)
Batch 200/537: Loss=0.2691 (C:0.2691, R:0.0105)
Batch 225/537: Loss=0.2667 (C:0.2667, R:0.0105)
Batch 250/537: Loss=0.2658 (C:0.2658, R:0.0105)
Batch 275/537: Loss=0.2653 (C:0.2653, R:0.0106)
Batch 300/537: Loss=0.2768 (C:0.2768, R:0.0105)
Batch 325/537: Loss=0.2672 (C:0.2672, R:0.0105)
Batch 350/537: Loss=0.2692 (C:0.2692, R:0.0105)
Batch 375/537: Loss=0.2664 (C:0.2664, R:0.0105)
Batch 400/537: Loss=0.2547 (C:0.2547, R:0.0105)
Batch 425/537: Loss=0.2848 (C:0.2848, R:0.0105)
Batch 450/537: Loss=0.2741 (C:0.2741, R:0.0105)
Batch 475/537: Loss=0.2687 (C:0.2687, R:0.0105)
Batch 500/537: Loss=0.2716 (C:0.2716, R:0.0105)
Batch 525/537: Loss=0.2696 (C:0.2696, R:0.0105)

============================================================
Epoch 66/300 completed in 28.1s
Train: Loss=0.2633 (C:0.2633, R:0.0105) Ratio=5.09x
Val:   Loss=0.3499 (C:0.3499, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 8 epochs

Early stopping triggered after 66 epochs
Best model was at epoch 58 with Val Loss: 0.3474

Global Dataset Training Completed!
Best epoch: 58
Best validation loss: 0.3474
Final separation ratios: Train=5.09x, Val=3.06x
Training completed!
Loading best model from entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin1.0_updatefreq1_max_global_samples5000_20250715_103028/checkpoints/best_model.pt
Starting model evaluation...
========================================
GlobalContrastiveEvaluator initialized on cuda
Starting comprehensive evaluation...
============================================================
Extracting latent representations...
  Processed 1/10 batches
Extracted representations: torch.Size([9824, 75])
Evaluating clustering performance...
Clustering Results:
  Silhouette Score: 0.4610
  Adjusted Rand Score: 0.5336
  Clustering Accuracy: 0.8162
Evaluating classification performance...
  Extracting training representations...
Extracting latent representations...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
Extracted representations: torch.Size([547740, 75])
  Extracting validation representations...
Extracting latent representations...
  Processed 1/9 batches
Extracted representations: torch.Size([9180, 75])
Subsampled training to 50000 samples
  Training on 50000 samples, evaluating on 9180 samples
Classification Results:
  Accuracy: 0.8146
  Per-class F1: [0.8342644320297952, 0.7557921102066374, 0.8573784006595219]
Evaluating reconstruction quality...
Reconstruction Results:
  Average MSE: 0.010432
Evaluating separation quality...
Separation Results:
  Positive distances: 0.381 ± 0.450
  Negative distances: 1.159 ± 0.617
  Separation ratio: 3.04x
  Gap: -2.221
  Perfect separation: No

Comprehensive evaluation completed!

============================================================
EVALUATION SUMMARY
============================================================
Clustering Performance:
  Silhouette Score: 0.4610
  Clustering Accuracy: 0.8162
  Adjusted Rand Score: 0.5336

Classification Performance:
  Accuracy: 0.8146

Separation Quality:
  Separation Ratio: 3.04x
  Gap: -2.221
  Perfect Separation: False

Reconstruction Quality:
  Average MSE: 0.010432
============================================================
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin1.0_updatefreq1_max_global_samples5000_20250715_103028/results/evaluation_results_20250715_110243.json
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin1.0_updatefreq1_max_global_samples5000_20250715_103028/results/evaluation_results_20250715_110243.json
Saving final experiment results...
Final results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin1.0_updatefreq1_max_global_samples5000_20250715_103028/final_results.json

============================================================
PIPELINE COMPLETED SUCCESSFULLY!
============================================================
Experiment directory: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin1.0_updatefreq1_max_global_samples5000_20250715_103028
Best model: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin1.0_updatefreq1_max_global_samples5000_20250715_103028/checkpoints/best_model.pt
Final results: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin1.0_updatefreq1_max_global_samples5000_20250715_103028/final_results.json

Key Results:
  Separation ratio: 3.04x
  Perfect separation: False
  Classification accuracy: 0.8146
  NEW BEST: 0.8146% (improvement: +-80.86%)
  Saved best experiment: coarse_margin1.0_updatefreq1_max_global_samples5000_20250715_103028

[2/12] Testing: coarse_margin1.0_updatefreq1_max_global_samples10000
  margin: 1.0
  update_frequency: 1
  max_global_samples: 10000
  Reconstruction weight: 0.3 (fixed)
GLOBAL DATASET CONTRASTIVE AUTOENCODER PIPELINE
============================================================
Start time: 2025-07-15 11:02:44.184498
Using device: cuda

Configuration:
  Embedding type: concat
  Batch size: 1020
  Global update frequency: 1 epochs
  Training epochs: 300
Experiment setup completed:
  Experiment directory: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin1.0_updatefreq1_max_global_samples10000_20250715_110244
  Config saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin1.0_updatefreq1_max_global_samples10000_20250715_110244/config.json
Loading data...
========================================
FlexibleEmbedder initialized with type: 'concat'
Output dimension will be: 1536
GlobalDataLoader initialized:
  Embedding type: concat
  Output dimension: 1536
  Sample size: All
Starting data loading pipeline...
============================================================
Loading training data from data/processed/snli_full_standard_SBERT.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 549367 training samples
Loading validation data from data/processed/snli_full_standard_SBERT_validation.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9842 validation samples
Loading test data from data/processed/snli_full_standard_SBERT_test.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9824 test samples
Generating embeddings for training...
Generating concat embeddings on cuda
Processing 549367 samples in batches of 1000
  Processing batch 1/550
  Processing batch 6/550
  Processing batch 11/550
  Processing batch 16/550
  Processing batch 21/550
  Processing batch 26/550
  Processing batch 31/550
  Processing batch 36/550
  Processing batch 41/550
  Processing batch 46/550
  Processing batch 51/550
  Processing batch 56/550
  Processing batch 61/550
  Processing batch 66/550
  Processing batch 71/550
  Processing batch 76/550
  Processing batch 81/550
  Processing batch 86/550
  Processing batch 91/550
  Processing batch 96/550
  Processing batch 101/550
  Processing batch 106/550
  Processing batch 111/550
  Processing batch 116/550
  Processing batch 121/550
  Processing batch 126/550
  Processing batch 131/550
  Processing batch 136/550
  Processing batch 141/550
  Processing batch 146/550
  Processing batch 151/550
  Processing batch 156/550
  Processing batch 161/550
  Processing batch 166/550
  Processing batch 171/550
  Processing batch 176/550
  Processing batch 181/550
  Processing batch 186/550
  Processing batch 191/550
  Processing batch 196/550
  Processing batch 201/550
  Processing batch 206/550
  Processing batch 211/550
  Processing batch 216/550
  Processing batch 221/550
  Processing batch 226/550
  Processing batch 231/550
  Processing batch 236/550
  Processing batch 241/550
  Processing batch 246/550
  Processing batch 251/550
  Processing batch 256/550
  Processing batch 261/550
  Processing batch 266/550
  Processing batch 271/550
  Processing batch 276/550
  Processing batch 281/550
  Processing batch 286/550
  Processing batch 291/550
  Processing batch 296/550
  Processing batch 301/550
  Processing batch 306/550
  Processing batch 311/550
  Processing batch 316/550
  Processing batch 321/550
  Processing batch 326/550
  Processing batch 331/550
  Processing batch 336/550
  Processing batch 341/550
  Processing batch 346/550
  Processing batch 351/550
  Processing batch 356/550
  Processing batch 361/550
  Processing batch 366/550
  Processing batch 371/550
  Processing batch 376/550
  Processing batch 381/550
  Processing batch 386/550
  Processing batch 391/550
  Processing batch 396/550
  Processing batch 401/550
  Processing batch 406/550
  Processing batch 411/550
  Processing batch 416/550
  Processing batch 421/550
  Processing batch 426/550
  Processing batch 431/550
  Processing batch 436/550
  Processing batch 441/550
  Processing batch 446/550
  Processing batch 451/550
  Processing batch 456/550
  Processing batch 461/550
  Processing batch 466/550
  Processing batch 471/550
  Processing batch 476/550
  Processing batch 481/550
  Processing batch 486/550
  Processing batch 491/550
  Processing batch 496/550
  Processing batch 501/550
  Processing batch 506/550
  Processing batch 511/550
  Processing batch 516/550
  Processing batch 521/550
  Processing batch 526/550
  Processing batch 531/550
  Processing batch 536/550
  Processing batch 541/550
  Processing batch 546/550
Generated concat embeddings: torch.Size([549367, 1536])
Generating embeddings for validation...
Generating concat embeddings on cuda
Processing 9842 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9842, 1536])
Generating embeddings for test...
Generating concat embeddings on cuda
Processing 9824 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9824, 1536])
EntailmentDataset created: 549367 samples
  Embedding shape: torch.Size([549367, 1536])
  Class distribution: {'entailment': 183416, 'neutral': 182764, 'contradiction': 183187}
EntailmentDataset created: 9842 samples
  Embedding shape: torch.Size([9842, 1536])
  Class distribution: {'entailment': 3329, 'neutral': 3235, 'contradiction': 3278}
EntailmentDataset created: 9824 samples
  Embedding shape: torch.Size([9824, 1536])
  Class distribution: {'entailment': 3368, 'neutral': 3219, 'contradiction': 3237}

Data loading pipeline completed!
Output embedding dimension: 1536
Updated model input_dim to: 1536
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 537
  Class 2: 183187 samples
  Class 0: 183416 samples
  Class 1: 182764 samples
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 9
  Class 2: 3278 samples
  Class 0: 3329 samples
  Class 1: 3235 samples
DataLoaders created:
  Batch size: 1020
  Balanced sampling: True
  Train batches: 537
  Val batches: 9
  Test batches: 10
Data loading completed!
  Train: 549367 samples, 537 batches
  Val: 9842 samples, 9 batches
  Test: 9824 samples, 10 batches
Creating model and trainer...
========================================
ContrastiveAutoencoder initialized:
  Input dim: 1536
  Latent dim: 75
  Hidden dims: [512, 256]
  Dropout rate: 0.2
  Total parameters: 1,876,555
Model created with 1,876,555 parameters
FullDatasetContrastiveLoss initialized:
  Margin: 1.0
  Update frequency: 1 epochs
  Max global samples: 10000
FullDatasetCombinedLoss initialized:
  Contrastive weight: 1.0
  Base reconstruction weight: 0.0
  Scheduled reconstruction: warmup=30 epochs, max_weight=0.3
Optimizer created (lr=0.0001)
GlobalDatasetTrainer initialized on device: cuda
Model parameters: 1,876,555
Starting training...
========================================
Starting Global Dataset Training...
============================================================

🌍 Updating global dataset at epoch 1
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.088 ± 0.010
    Neg distances: 0.088 ± 0.010
    Separation ratio: 1.00x
    Gap: -0.136
    ❌ Poor global separation

Epoch 1 Training
----------------------------------------
Batch   0/537: Loss=0.9997 (C:0.9997, R:0.0116)
Batch  25/537: Loss=0.9949 (C:0.9949, R:0.0113)
Batch  50/537: Loss=0.9866 (C:0.9866, R:0.0112)
Batch  75/537: Loss=0.9831 (C:0.9831, R:0.0111)
Batch 100/537: Loss=0.9809 (C:0.9809, R:0.0110)
Batch 125/537: Loss=0.9769 (C:0.9769, R:0.0109)
Batch 150/537: Loss=0.9731 (C:0.9731, R:0.0108)
Batch 175/537: Loss=0.9693 (C:0.9693, R:0.0108)
Batch 200/537: Loss=0.9660 (C:0.9660, R:0.0107)
Batch 225/537: Loss=0.9611 (C:0.9611, R:0.0107)
Batch 250/537: Loss=0.9636 (C:0.9636, R:0.0106)
Batch 275/537: Loss=0.9574 (C:0.9574, R:0.0106)
Batch 300/537: Loss=0.9580 (C:0.9580, R:0.0106)
Batch 325/537: Loss=0.9562 (C:0.9562, R:0.0106)
Batch 350/537: Loss=0.9531 (C:0.9531, R:0.0106)
Batch 375/537: Loss=0.9536 (C:0.9536, R:0.0106)
Batch 400/537: Loss=0.9535 (C:0.9535, R:0.0105)
Batch 425/537: Loss=0.9543 (C:0.9543, R:0.0105)
Batch 450/537: Loss=0.9529 (C:0.9529, R:0.0105)
Batch 475/537: Loss=0.9511 (C:0.9511, R:0.0105)
Batch 500/537: Loss=0.9489 (C:0.9489, R:0.0106)
Batch 525/537: Loss=0.9493 (C:0.9493, R:0.0106)

============================================================
Epoch 1/300 completed in 27.5s
Train: Loss=0.9654 (C:0.9654, R:0.0107) Ratio=1.66x
Val:   Loss=0.9465 (C:0.9465, R:0.0105) Ratio=2.15x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.9465)
============================================================

🌍 Updating global dataset at epoch 2
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.329 ± 0.278
    Neg distances: 0.721 ± 0.417
    Separation ratio: 2.19x
    Gap: -2.009
    ✅ Good global separation

Epoch 2 Training
----------------------------------------
Batch   0/537: Loss=0.6873 (C:0.6873, R:0.0105)
Batch  25/537: Loss=0.6903 (C:0.6903, R:0.0106)
Batch  50/537: Loss=0.6851 (C:0.6851, R:0.0105)
Batch  75/537: Loss=0.6745 (C:0.6745, R:0.0105)
Batch 100/537: Loss=0.6881 (C:0.6881, R:0.0105)
Batch 125/537: Loss=0.6890 (C:0.6890, R:0.0105)
Batch 150/537: Loss=0.6607 (C:0.6607, R:0.0105)
Batch 175/537: Loss=0.6656 (C:0.6656, R:0.0105)
Batch 200/537: Loss=0.6805 (C:0.6805, R:0.0105)
Batch 225/537: Loss=0.6799 (C:0.6799, R:0.0105)
Batch 250/537: Loss=0.6833 (C:0.6833, R:0.0105)
Batch 275/537: Loss=0.6741 (C:0.6741, R:0.0105)
Batch 300/537: Loss=0.6765 (C:0.6765, R:0.0105)
Batch 325/537: Loss=0.6857 (C:0.6857, R:0.0105)
Batch 350/537: Loss=0.6854 (C:0.6854, R:0.0105)
Batch 375/537: Loss=0.6829 (C:0.6829, R:0.0105)
Batch 400/537: Loss=0.6748 (C:0.6748, R:0.0105)
Batch 425/537: Loss=0.6663 (C:0.6663, R:0.0105)
Batch 450/537: Loss=0.6736 (C:0.6736, R:0.0105)
Batch 475/537: Loss=0.6847 (C:0.6847, R:0.0105)
Batch 500/537: Loss=0.6696 (C:0.6696, R:0.0105)
Batch 525/537: Loss=0.6654 (C:0.6654, R:0.0105)

============================================================
Epoch 2/300 completed in 27.5s
Train: Loss=0.6748 (C:0.6748, R:0.0105) Ratio=2.20x
Val:   Loss=0.6618 (C:0.6618, R:0.0104) Ratio=2.44x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.6618)
============================================================

🌍 Updating global dataset at epoch 3
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.295 ± 0.286
    Neg distances: 0.769 ± 0.428
    Separation ratio: 2.61x
    Gap: -1.773
    ✅ Good global separation

Epoch 3 Training
----------------------------------------
Batch   0/537: Loss=0.6129 (C:0.6129, R:0.0105)
Batch  25/537: Loss=0.6020 (C:0.6020, R:0.0105)
Batch  50/537: Loss=0.6279 (C:0.6279, R:0.0105)
Batch  75/537: Loss=0.6188 (C:0.6188, R:0.0105)
Batch 100/537: Loss=0.6213 (C:0.6213, R:0.0105)
Batch 125/537: Loss=0.6343 (C:0.6343, R:0.0105)
Batch 150/537: Loss=0.6307 (C:0.6307, R:0.0106)
Batch 175/537: Loss=0.6221 (C:0.6221, R:0.0105)
Batch 200/537: Loss=0.6227 (C:0.6227, R:0.0105)
Batch 225/537: Loss=0.6184 (C:0.6184, R:0.0105)
Batch 250/537: Loss=0.5985 (C:0.5985, R:0.0105)
Batch 275/537: Loss=0.6310 (C:0.6310, R:0.0105)
Batch 300/537: Loss=0.6318 (C:0.6318, R:0.0105)
Batch 325/537: Loss=0.6247 (C:0.6247, R:0.0105)
Batch 350/537: Loss=0.6162 (C:0.6162, R:0.0105)
Batch 375/537: Loss=0.6162 (C:0.6162, R:0.0105)
Batch 400/537: Loss=0.6337 (C:0.6337, R:0.0105)
Batch 425/537: Loss=0.6129 (C:0.6129, R:0.0105)
Batch 450/537: Loss=0.6229 (C:0.6229, R:0.0105)
Batch 475/537: Loss=0.6287 (C:0.6287, R:0.0105)
Batch 500/537: Loss=0.6189 (C:0.6189, R:0.0105)
Batch 525/537: Loss=0.6247 (C:0.6247, R:0.0105)

============================================================
Epoch 3/300 completed in 27.8s
Train: Loss=0.6211 (C:0.6211, R:0.0105) Ratio=2.46x
Val:   Loss=0.6123 (C:0.6123, R:0.0104) Ratio=2.55x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.6123)
============================================================

🌍 Updating global dataset at epoch 4
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.282 ± 0.284
    Neg distances: 0.805 ± 0.434
    Separation ratio: 2.86x
    Gap: -1.751
    ✅ Good global separation

Epoch 4 Training
----------------------------------------
Batch   0/537: Loss=0.5601 (C:0.5601, R:0.0105)
Batch  25/537: Loss=0.5794 (C:0.5794, R:0.0105)
Batch  50/537: Loss=0.5901 (C:0.5901, R:0.0106)
Batch  75/537: Loss=0.5897 (C:0.5897, R:0.0105)
Batch 100/537: Loss=0.5859 (C:0.5859, R:0.0105)
Batch 125/537: Loss=0.5883 (C:0.5883, R:0.0105)
Batch 150/537: Loss=0.5885 (C:0.5885, R:0.0105)
Batch 175/537: Loss=0.5910 (C:0.5910, R:0.0105)
Batch 200/537: Loss=0.6067 (C:0.6067, R:0.0105)
Batch 225/537: Loss=0.5910 (C:0.5910, R:0.0105)
Batch 250/537: Loss=0.5830 (C:0.5830, R:0.0105)
Batch 275/537: Loss=0.5877 (C:0.5877, R:0.0105)
Batch 300/537: Loss=0.6017 (C:0.6017, R:0.0105)
Batch 325/537: Loss=0.5746 (C:0.5746, R:0.0105)
Batch 350/537: Loss=0.5947 (C:0.5947, R:0.0105)
Batch 375/537: Loss=0.5849 (C:0.5849, R:0.0105)
Batch 400/537: Loss=0.5733 (C:0.5733, R:0.0105)
Batch 425/537: Loss=0.5827 (C:0.5827, R:0.0105)
Batch 450/537: Loss=0.5895 (C:0.5895, R:0.0105)
Batch 475/537: Loss=0.5865 (C:0.5865, R:0.0105)
Batch 500/537: Loss=0.5922 (C:0.5922, R:0.0105)
Batch 525/537: Loss=0.5983 (C:0.5983, R:0.0105)

============================================================
Epoch 4/300 completed in 27.5s
Train: Loss=0.5904 (C:0.5904, R:0.0105) Ratio=2.70x
Val:   Loss=0.5885 (C:0.5885, R:0.0104) Ratio=2.68x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.5885)
============================================================

🌍 Updating global dataset at epoch 5
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.276 ± 0.290
    Neg distances: 0.827 ± 0.440
    Separation ratio: 3.00x
    Gap: -1.762
    ✅ Good global separation

Epoch 5 Training
----------------------------------------
Batch   0/537: Loss=0.5544 (C:0.5544, R:0.0105)
Batch  25/537: Loss=0.5896 (C:0.5896, R:0.0105)
Batch  50/537: Loss=0.5742 (C:0.5742, R:0.0105)
Batch  75/537: Loss=0.5757 (C:0.5757, R:0.0105)
Batch 100/537: Loss=0.5720 (C:0.5720, R:0.0105)
Batch 125/537: Loss=0.5728 (C:0.5728, R:0.0105)
Batch 150/537: Loss=0.5776 (C:0.5776, R:0.0105)
Batch 175/537: Loss=0.5807 (C:0.5807, R:0.0105)
Batch 200/537: Loss=0.5705 (C:0.5705, R:0.0105)
Batch 225/537: Loss=0.5596 (C:0.5596, R:0.0105)
Batch 250/537: Loss=0.5761 (C:0.5761, R:0.0105)
Batch 275/537: Loss=0.5645 (C:0.5645, R:0.0105)
Batch 300/537: Loss=0.5789 (C:0.5789, R:0.0105)
Batch 325/537: Loss=0.5733 (C:0.5733, R:0.0105)
Batch 350/537: Loss=0.5712 (C:0.5712, R:0.0105)
Batch 375/537: Loss=0.5736 (C:0.5736, R:0.0105)
Batch 400/537: Loss=0.5472 (C:0.5472, R:0.0105)
Batch 425/537: Loss=0.5782 (C:0.5782, R:0.0105)
Batch 450/537: Loss=0.5762 (C:0.5762, R:0.0105)
Batch 475/537: Loss=0.5839 (C:0.5839, R:0.0105)
Batch 500/537: Loss=0.5515 (C:0.5515, R:0.0105)
Batch 525/537: Loss=0.5791 (C:0.5791, R:0.0105)

============================================================
Epoch 5/300 completed in 26.9s
Train: Loss=0.5727 (C:0.5727, R:0.0105) Ratio=2.79x
Val:   Loss=0.5744 (C:0.5744, R:0.0104) Ratio=2.75x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.5744)
============================================================

🌍 Updating global dataset at epoch 6
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.262 ± 0.290
    Neg distances: 0.852 ± 0.442
    Separation ratio: 3.26x
    Gap: -1.683
    ✅ Excellent global separation!

Epoch 6 Training
----------------------------------------
Batch   0/537: Loss=0.5686 (C:0.5686, R:0.0105)
Batch  25/537: Loss=0.5541 (C:0.5541, R:0.0105)
Batch  50/537: Loss=0.5414 (C:0.5414, R:0.0105)
Batch  75/537: Loss=0.5291 (C:0.5291, R:0.0105)
Batch 100/537: Loss=0.5592 (C:0.5592, R:0.0105)
Batch 125/537: Loss=0.5500 (C:0.5500, R:0.0105)
Batch 150/537: Loss=0.5492 (C:0.5492, R:0.0105)
Batch 175/537: Loss=0.5298 (C:0.5298, R:0.0105)
Batch 200/537: Loss=0.5570 (C:0.5570, R:0.0105)
Batch 225/537: Loss=0.5393 (C:0.5393, R:0.0105)
Batch 250/537: Loss=0.5561 (C:0.5561, R:0.0105)
Batch 275/537: Loss=0.5542 (C:0.5542, R:0.0105)
Batch 300/537: Loss=0.5713 (C:0.5713, R:0.0105)
Batch 325/537: Loss=0.5664 (C:0.5664, R:0.0105)
Batch 350/537: Loss=0.5693 (C:0.5693, R:0.0105)
Batch 375/537: Loss=0.5428 (C:0.5428, R:0.0105)
Batch 400/537: Loss=0.5263 (C:0.5263, R:0.0105)
Batch 425/537: Loss=0.5356 (C:0.5356, R:0.0105)
Batch 450/537: Loss=0.5604 (C:0.5604, R:0.0106)
Batch 475/537: Loss=0.5579 (C:0.5579, R:0.0105)
Batch 500/537: Loss=0.5620 (C:0.5620, R:0.0105)
Batch 525/537: Loss=0.5414 (C:0.5414, R:0.0105)

============================================================
Epoch 6/300 completed in 26.8s
Train: Loss=0.5498 (C:0.5498, R:0.0105) Ratio=2.88x
Val:   Loss=0.5593 (C:0.5593, R:0.0104) Ratio=2.81x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.5593)
============================================================

🌍 Updating global dataset at epoch 7
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.256 ± 0.296
    Neg distances: 0.874 ± 0.449
    Separation ratio: 3.41x
    Gap: -1.683
    ✅ Excellent global separation!

Epoch 7 Training
----------------------------------------
Batch   0/537: Loss=0.5321 (C:0.5321, R:0.0105)
Batch  25/537: Loss=0.5236 (C:0.5236, R:0.0105)
Batch  50/537: Loss=0.5210 (C:0.5210, R:0.0105)
Batch  75/537: Loss=0.5437 (C:0.5437, R:0.0106)
Batch 100/537: Loss=0.5367 (C:0.5367, R:0.0105)
Batch 125/537: Loss=0.5292 (C:0.5292, R:0.0105)
Batch 150/537: Loss=0.5355 (C:0.5355, R:0.0105)
Batch 175/537: Loss=0.5396 (C:0.5396, R:0.0105)
Batch 200/537: Loss=0.5297 (C:0.5297, R:0.0105)
Batch 225/537: Loss=0.5356 (C:0.5356, R:0.0105)
Batch 250/537: Loss=0.5311 (C:0.5311, R:0.0105)
Batch 275/537: Loss=0.5400 (C:0.5400, R:0.0105)
Batch 300/537: Loss=0.5374 (C:0.5374, R:0.0105)
Batch 325/537: Loss=0.5521 (C:0.5521, R:0.0105)
Batch 350/537: Loss=0.5317 (C:0.5317, R:0.0105)
Batch 375/537: Loss=0.5374 (C:0.5374, R:0.0105)
Batch 400/537: Loss=0.5292 (C:0.5292, R:0.0105)
Batch 425/537: Loss=0.5257 (C:0.5257, R:0.0105)
Batch 450/537: Loss=0.5440 (C:0.5440, R:0.0105)
Batch 475/537: Loss=0.5373 (C:0.5373, R:0.0105)
Batch 500/537: Loss=0.5449 (C:0.5449, R:0.0105)
Batch 525/537: Loss=0.5450 (C:0.5450, R:0.0105)

============================================================
Epoch 7/300 completed in 27.5s
Train: Loss=0.5349 (C:0.5349, R:0.0105) Ratio=2.99x
Val:   Loss=0.5421 (C:0.5421, R:0.0104) Ratio=2.83x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.5421)
============================================================

🌍 Updating global dataset at epoch 8
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.251 ± 0.293
    Neg distances: 0.900 ± 0.455
    Separation ratio: 3.58x
    Gap: -1.675
    ✅ Excellent global separation!

Epoch 8 Training
----------------------------------------
Batch   0/537: Loss=0.5359 (C:0.5359, R:0.0105)
Batch  25/537: Loss=0.5197 (C:0.5197, R:0.0105)
Batch  50/537: Loss=0.5013 (C:0.5013, R:0.0105)
Batch  75/537: Loss=0.5305 (C:0.5305, R:0.0105)
Batch 100/537: Loss=0.5218 (C:0.5218, R:0.0105)
Batch 125/537: Loss=0.5298 (C:0.5298, R:0.0105)
Batch 150/537: Loss=0.5250 (C:0.5250, R:0.0105)
Batch 175/537: Loss=0.5286 (C:0.5286, R:0.0106)
Batch 200/537: Loss=0.5110 (C:0.5110, R:0.0105)
Batch 225/537: Loss=0.5209 (C:0.5209, R:0.0105)
Batch 250/537: Loss=0.5060 (C:0.5060, R:0.0105)
Batch 275/537: Loss=0.5088 (C:0.5088, R:0.0105)
Batch 300/537: Loss=0.5211 (C:0.5211, R:0.0105)
Batch 325/537: Loss=0.5288 (C:0.5288, R:0.0105)
Batch 350/537: Loss=0.5189 (C:0.5189, R:0.0105)
Batch 375/537: Loss=0.5236 (C:0.5236, R:0.0105)
Batch 400/537: Loss=0.5316 (C:0.5316, R:0.0105)
Batch 425/537: Loss=0.5187 (C:0.5187, R:0.0105)
Batch 450/537: Loss=0.5084 (C:0.5084, R:0.0105)
Batch 475/537: Loss=0.5236 (C:0.5236, R:0.0105)
Batch 500/537: Loss=0.5104 (C:0.5104, R:0.0105)
Batch 525/537: Loss=0.5531 (C:0.5531, R:0.0105)

============================================================
Epoch 8/300 completed in 27.6s
Train: Loss=0.5213 (C:0.5213, R:0.0105) Ratio=3.03x
Val:   Loss=0.5348 (C:0.5348, R:0.0104) Ratio=2.88x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.5348)
============================================================

🌍 Updating global dataset at epoch 9
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.247 ± 0.294
    Neg distances: 0.925 ± 0.460
    Separation ratio: 3.75x
    Gap: -1.708
    ✅ Excellent global separation!

Epoch 9 Training
----------------------------------------
Batch   0/537: Loss=0.4977 (C:0.4977, R:0.0105)
Batch  25/537: Loss=0.4937 (C:0.4937, R:0.0105)
Batch  50/537: Loss=0.5001 (C:0.5001, R:0.0105)
Batch  75/537: Loss=0.5024 (C:0.5024, R:0.0105)
Batch 100/537: Loss=0.5171 (C:0.5171, R:0.0105)
Batch 125/537: Loss=0.5137 (C:0.5137, R:0.0105)
Batch 150/537: Loss=0.5107 (C:0.5107, R:0.0105)
Batch 175/537: Loss=0.4974 (C:0.4974, R:0.0105)
Batch 200/537: Loss=0.5148 (C:0.5148, R:0.0105)
Batch 225/537: Loss=0.5183 (C:0.5183, R:0.0105)
Batch 250/537: Loss=0.5097 (C:0.5097, R:0.0105)
Batch 275/537: Loss=0.5067 (C:0.5067, R:0.0106)
Batch 300/537: Loss=0.5147 (C:0.5147, R:0.0105)
Batch 325/537: Loss=0.4951 (C:0.4951, R:0.0105)
Batch 350/537: Loss=0.4891 (C:0.4891, R:0.0105)
Batch 375/537: Loss=0.5085 (C:0.5085, R:0.0105)
Batch 400/537: Loss=0.5017 (C:0.5017, R:0.0105)
Batch 425/537: Loss=0.5047 (C:0.5047, R:0.0105)
Batch 450/537: Loss=0.5157 (C:0.5157, R:0.0105)
Batch 475/537: Loss=0.5058 (C:0.5058, R:0.0105)
Batch 500/537: Loss=0.5059 (C:0.5059, R:0.0105)
Batch 525/537: Loss=0.5059 (C:0.5059, R:0.0106)

============================================================
Epoch 9/300 completed in 26.9s
Train: Loss=0.5078 (C:0.5078, R:0.0105) Ratio=3.19x
Val:   Loss=0.5241 (C:0.5241, R:0.0104) Ratio=2.87x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.5241)
============================================================

🌍 Updating global dataset at epoch 10
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.252 ± 0.301
    Neg distances: 0.945 ± 0.467
    Separation ratio: 3.75x
    Gap: -1.710
    ✅ Excellent global separation!

Epoch 10 Training
----------------------------------------
Batch   0/537: Loss=0.4983 (C:0.4983, R:0.0105)
Batch  25/537: Loss=0.4949 (C:0.4949, R:0.0105)
Batch  50/537: Loss=0.4877 (C:0.4877, R:0.0105)
Batch  75/537: Loss=0.5000 (C:0.5000, R:0.0105)
Batch 100/537: Loss=0.5004 (C:0.5004, R:0.0105)
Batch 125/537: Loss=0.4789 (C:0.4789, R:0.0105)
Batch 150/537: Loss=0.5201 (C:0.5201, R:0.0105)
Batch 175/537: Loss=0.5100 (C:0.5100, R:0.0105)
Batch 200/537: Loss=0.5137 (C:0.5137, R:0.0105)
Batch 225/537: Loss=0.4998 (C:0.4998, R:0.0105)
Batch 250/537: Loss=0.5111 (C:0.5111, R:0.0105)
Batch 275/537: Loss=0.5062 (C:0.5062, R:0.0105)
Batch 300/537: Loss=0.5113 (C:0.5113, R:0.0105)
Batch 325/537: Loss=0.5027 (C:0.5027, R:0.0105)
Batch 350/537: Loss=0.5060 (C:0.5060, R:0.0105)
Batch 375/537: Loss=0.5103 (C:0.5103, R:0.0105)
Batch 400/537: Loss=0.5116 (C:0.5116, R:0.0105)
Batch 425/537: Loss=0.4936 (C:0.4936, R:0.0105)
Batch 450/537: Loss=0.4841 (C:0.4841, R:0.0105)
Batch 475/537: Loss=0.4839 (C:0.4839, R:0.0105)
Batch 500/537: Loss=0.4953 (C:0.4953, R:0.0105)
Batch 525/537: Loss=0.5157 (C:0.5157, R:0.0105)

============================================================
Epoch 10/300 completed in 27.5s
Train: Loss=0.5010 (C:0.5010, R:0.0105) Ratio=3.20x
Val:   Loss=0.5162 (C:0.5162, R:0.0104) Ratio=2.90x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.5162)
============================================================

🌍 Updating global dataset at epoch 11
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.246 ± 0.299
    Neg distances: 0.977 ± 0.476
    Separation ratio: 3.97x
    Gap: -1.788
    ✅ Excellent global separation!

Epoch 11 Training
----------------------------------------
Batch   0/537: Loss=0.4822 (C:0.4822, R:0.0105)
Batch  25/537: Loss=0.4945 (C:0.4945, R:0.0105)
Batch  50/537: Loss=0.4844 (C:0.4844, R:0.0105)
Batch  75/537: Loss=0.4983 (C:0.4983, R:0.0105)
Batch 100/537: Loss=0.4920 (C:0.4920, R:0.0105)
Batch 125/537: Loss=0.4814 (C:0.4814, R:0.0105)
Batch 150/537: Loss=0.4818 (C:0.4818, R:0.0105)
Batch 175/537: Loss=0.4809 (C:0.4809, R:0.0105)
Batch 200/537: Loss=0.4768 (C:0.4768, R:0.0105)
Batch 225/537: Loss=0.5075 (C:0.5075, R:0.0105)
Batch 250/537: Loss=0.4852 (C:0.4852, R:0.0105)
Batch 275/537: Loss=0.4774 (C:0.4774, R:0.0105)
Batch 300/537: Loss=0.4821 (C:0.4821, R:0.0105)
Batch 325/537: Loss=0.4886 (C:0.4886, R:0.0105)
Batch 350/537: Loss=0.4650 (C:0.4650, R:0.0105)
Batch 375/537: Loss=0.4902 (C:0.4902, R:0.0105)
Batch 400/537: Loss=0.4963 (C:0.4963, R:0.0105)
Batch 425/537: Loss=0.5029 (C:0.5029, R:0.0105)
Batch 450/537: Loss=0.4857 (C:0.4857, R:0.0105)
Batch 475/537: Loss=0.4997 (C:0.4997, R:0.0105)
Batch 500/537: Loss=0.4951 (C:0.4951, R:0.0105)
Batch 525/537: Loss=0.4734 (C:0.4734, R:0.0105)

============================================================
Epoch 11/300 completed in 28.0s
Train: Loss=0.4860 (C:0.4860, R:0.0105) Ratio=3.24x
Val:   Loss=0.4988 (C:0.4988, R:0.0104) Ratio=2.91x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4988)
============================================================

🌍 Updating global dataset at epoch 12
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.242 ± 0.305
    Neg distances: 0.994 ± 0.478
    Separation ratio: 4.10x
    Gap: -1.811
    ✅ Excellent global separation!

Epoch 12 Training
----------------------------------------
Batch   0/537: Loss=0.4860 (C:0.4860, R:0.0105)
Batch  25/537: Loss=0.4747 (C:0.4747, R:0.0105)
Batch  50/537: Loss=0.4575 (C:0.4575, R:0.0106)
Batch  75/537: Loss=0.4653 (C:0.4653, R:0.0106)
Batch 100/537: Loss=0.4615 (C:0.4615, R:0.0105)
Batch 125/537: Loss=0.4747 (C:0.4747, R:0.0105)
Batch 150/537: Loss=0.4642 (C:0.4642, R:0.0105)
Batch 175/537: Loss=0.4712 (C:0.4712, R:0.0105)
Batch 200/537: Loss=0.4708 (C:0.4708, R:0.0105)
Batch 225/537: Loss=0.4780 (C:0.4780, R:0.0105)
Batch 250/537: Loss=0.4642 (C:0.4642, R:0.0105)
Batch 275/537: Loss=0.4859 (C:0.4859, R:0.0105)
Batch 300/537: Loss=0.4908 (C:0.4908, R:0.0105)
Batch 325/537: Loss=0.4767 (C:0.4767, R:0.0105)
Batch 350/537: Loss=0.4764 (C:0.4764, R:0.0105)
Batch 375/537: Loss=0.4601 (C:0.4601, R:0.0105)
Batch 400/537: Loss=0.4615 (C:0.4615, R:0.0105)
Batch 425/537: Loss=0.4727 (C:0.4727, R:0.0105)
Batch 450/537: Loss=0.4674 (C:0.4674, R:0.0105)
Batch 475/537: Loss=0.5048 (C:0.5048, R:0.0105)
Batch 500/537: Loss=0.4776 (C:0.4776, R:0.0105)
Batch 525/537: Loss=0.4760 (C:0.4760, R:0.0105)

============================================================
Epoch 12/300 completed in 27.9s
Train: Loss=0.4742 (C:0.4742, R:0.0105) Ratio=3.34x
Val:   Loss=0.4973 (C:0.4973, R:0.0104) Ratio=2.93x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4973)
============================================================

🌍 Updating global dataset at epoch 13
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.244 ± 0.308
    Neg distances: 1.006 ± 0.483
    Separation ratio: 4.12x
    Gap: -1.809
    ✅ Excellent global separation!

Epoch 13 Training
----------------------------------------
Batch   0/537: Loss=0.4579 (C:0.4579, R:0.0105)
Batch  25/537: Loss=0.4661 (C:0.4661, R:0.0106)
Batch  50/537: Loss=0.4564 (C:0.4564, R:0.0105)
Batch  75/537: Loss=0.4724 (C:0.4724, R:0.0105)
Batch 100/537: Loss=0.4760 (C:0.4760, R:0.0105)
Batch 125/537: Loss=0.4663 (C:0.4663, R:0.0105)
Batch 150/537: Loss=0.4729 (C:0.4729, R:0.0105)
Batch 175/537: Loss=0.4786 (C:0.4786, R:0.0105)
Batch 200/537: Loss=0.4746 (C:0.4746, R:0.0105)
Batch 225/537: Loss=0.4882 (C:0.4882, R:0.0105)
Batch 250/537: Loss=0.4723 (C:0.4723, R:0.0105)
Batch 275/537: Loss=0.4755 (C:0.4755, R:0.0105)
Batch 300/537: Loss=0.4723 (C:0.4723, R:0.0106)
Batch 325/537: Loss=0.4760 (C:0.4760, R:0.0105)
Batch 350/537: Loss=0.4875 (C:0.4875, R:0.0105)
Batch 375/537: Loss=0.4707 (C:0.4707, R:0.0105)
Batch 400/537: Loss=0.4853 (C:0.4853, R:0.0105)
Batch 425/537: Loss=0.4833 (C:0.4833, R:0.0105)
Batch 450/537: Loss=0.4693 (C:0.4693, R:0.0105)
Batch 475/537: Loss=0.4740 (C:0.4740, R:0.0105)
Batch 500/537: Loss=0.4721 (C:0.4721, R:0.0106)
Batch 525/537: Loss=0.4631 (C:0.4631, R:0.0105)

============================================================
Epoch 13/300 completed in 27.9s
Train: Loss=0.4701 (C:0.4701, R:0.0105) Ratio=3.41x
Val:   Loss=0.4927 (C:0.4927, R:0.0104) Ratio=2.94x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4927)
============================================================

🌍 Updating global dataset at epoch 14
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.243 ± 0.309
    Neg distances: 1.033 ± 0.492
    Separation ratio: 4.24x
    Gap: -1.833
    ✅ Excellent global separation!

Epoch 14 Training
----------------------------------------
Batch   0/537: Loss=0.4579 (C:0.4579, R:0.0105)
Batch  25/537: Loss=0.4577 (C:0.4577, R:0.0105)
Batch  50/537: Loss=0.4791 (C:0.4791, R:0.0105)
Batch  75/537: Loss=0.4586 (C:0.4586, R:0.0105)
Batch 100/537: Loss=0.4749 (C:0.4749, R:0.0105)
Batch 125/537: Loss=0.4521 (C:0.4521, R:0.0105)
Batch 150/537: Loss=0.4350 (C:0.4350, R:0.0105)
Batch 175/537: Loss=0.4466 (C:0.4466, R:0.0105)
Batch 200/537: Loss=0.4598 (C:0.4598, R:0.0105)
Batch 225/537: Loss=0.4516 (C:0.4516, R:0.0105)
Batch 250/537: Loss=0.4446 (C:0.4446, R:0.0105)
Batch 275/537: Loss=0.4432 (C:0.4432, R:0.0105)
Batch 300/537: Loss=0.4704 (C:0.4704, R:0.0105)
Batch 325/537: Loss=0.4653 (C:0.4653, R:0.0105)
Batch 350/537: Loss=0.4619 (C:0.4619, R:0.0105)
Batch 375/537: Loss=0.4451 (C:0.4451, R:0.0105)
Batch 400/537: Loss=0.4652 (C:0.4652, R:0.0105)
Batch 425/537: Loss=0.4757 (C:0.4757, R:0.0105)
Batch 450/537: Loss=0.4673 (C:0.4673, R:0.0105)
Batch 475/537: Loss=0.4696 (C:0.4696, R:0.0105)
Batch 500/537: Loss=0.4580 (C:0.4580, R:0.0105)
Batch 525/537: Loss=0.4567 (C:0.4567, R:0.0105)

============================================================
Epoch 14/300 completed in 28.0s
Train: Loss=0.4598 (C:0.4598, R:0.0105) Ratio=3.45x
Val:   Loss=0.4884 (C:0.4884, R:0.0104) Ratio=3.00x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4884)
============================================================

🌍 Updating global dataset at epoch 15
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.237 ± 0.308
    Neg distances: 1.069 ± 0.502
    Separation ratio: 4.51x
    Gap: -1.901
    ✅ Excellent global separation!

Epoch 15 Training
----------------------------------------
Batch   0/537: Loss=0.4385 (C:0.4385, R:0.0105)
Batch  25/537: Loss=0.4409 (C:0.4409, R:0.0105)
Batch  50/537: Loss=0.4390 (C:0.4390, R:0.0105)
Batch  75/537: Loss=0.4311 (C:0.4311, R:0.0105)
Batch 100/537: Loss=0.4474 (C:0.4474, R:0.0105)
Batch 125/537: Loss=0.4683 (C:0.4683, R:0.0105)
Batch 150/537: Loss=0.4255 (C:0.4255, R:0.0105)
Batch 175/537: Loss=0.4465 (C:0.4465, R:0.0105)
Batch 200/537: Loss=0.4385 (C:0.4385, R:0.0105)
Batch 225/537: Loss=0.4317 (C:0.4317, R:0.0105)
Batch 250/537: Loss=0.4514 (C:0.4514, R:0.0105)
Batch 275/537: Loss=0.4337 (C:0.4337, R:0.0105)
Batch 300/537: Loss=0.4491 (C:0.4491, R:0.0105)
Batch 325/537: Loss=0.4479 (C:0.4479, R:0.0105)
Batch 350/537: Loss=0.4332 (C:0.4332, R:0.0105)
Batch 375/537: Loss=0.4341 (C:0.4341, R:0.0105)
Batch 400/537: Loss=0.4274 (C:0.4274, R:0.0105)
Batch 425/537: Loss=0.4540 (C:0.4540, R:0.0105)
Batch 450/537: Loss=0.4486 (C:0.4486, R:0.0105)
Batch 475/537: Loss=0.4369 (C:0.4369, R:0.0105)
Batch 500/537: Loss=0.4394 (C:0.4394, R:0.0105)
Batch 525/537: Loss=0.4266 (C:0.4266, R:0.0105)

============================================================
Epoch 15/300 completed in 27.7s
Train: Loss=0.4440 (C:0.4440, R:0.0105) Ratio=3.52x
Val:   Loss=0.4721 (C:0.4721, R:0.0104) Ratio=3.02x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4721)
============================================================

🌍 Updating global dataset at epoch 16
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.235 ± 0.310
    Neg distances: 1.077 ± 0.502
    Separation ratio: 4.58x
    Gap: -1.896
    ✅ Excellent global separation!

Epoch 16 Training
----------------------------------------
Batch   0/537: Loss=0.4421 (C:0.4421, R:0.0105)
Batch  25/537: Loss=0.4314 (C:0.4314, R:0.0105)
Batch  50/537: Loss=0.4373 (C:0.4373, R:0.0105)
Batch  75/537: Loss=0.4370 (C:0.4370, R:0.0105)
Batch 100/537: Loss=0.4444 (C:0.4444, R:0.0105)
Batch 125/537: Loss=0.4221 (C:0.4221, R:0.0105)
Batch 150/537: Loss=0.4524 (C:0.4524, R:0.0105)
Batch 175/537: Loss=0.4394 (C:0.4394, R:0.0105)
Batch 200/537: Loss=0.4257 (C:0.4257, R:0.0105)
Batch 225/537: Loss=0.4319 (C:0.4319, R:0.0105)
Batch 250/537: Loss=0.4338 (C:0.4338, R:0.0106)
Batch 275/537: Loss=0.4263 (C:0.4263, R:0.0105)
Batch 300/537: Loss=0.4678 (C:0.4678, R:0.0105)
Batch 325/537: Loss=0.4570 (C:0.4570, R:0.0105)
Batch 350/537: Loss=0.4378 (C:0.4378, R:0.0105)
Batch 375/537: Loss=0.4487 (C:0.4487, R:0.0105)
Batch 400/537: Loss=0.4430 (C:0.4430, R:0.0105)
Batch 425/537: Loss=0.4292 (C:0.4292, R:0.0105)
Batch 450/537: Loss=0.4348 (C:0.4348, R:0.0105)
Batch 475/537: Loss=0.4576 (C:0.4576, R:0.0105)
Batch 500/537: Loss=0.4344 (C:0.4344, R:0.0105)
Batch 525/537: Loss=0.4645 (C:0.4645, R:0.0105)

============================================================
Epoch 16/300 completed in 27.4s
Train: Loss=0.4373 (C:0.4373, R:0.0105) Ratio=3.51x
Val:   Loss=0.4591 (C:0.4591, R:0.0104) Ratio=3.02x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4591)
============================================================

🌍 Updating global dataset at epoch 17
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.236 ± 0.309
    Neg distances: 1.091 ± 0.508
    Separation ratio: 4.63x
    Gap: -1.928
    ✅ Excellent global separation!

Epoch 17 Training
----------------------------------------
Batch   0/537: Loss=0.4223 (C:0.4223, R:0.0105)
Batch  25/537: Loss=0.4433 (C:0.4433, R:0.0105)
Batch  50/537: Loss=0.4390 (C:0.4390, R:0.0105)
Batch  75/537: Loss=0.4261 (C:0.4261, R:0.0105)
Batch 100/537: Loss=0.4264 (C:0.4264, R:0.0105)
Batch 125/537: Loss=0.4311 (C:0.4311, R:0.0106)
Batch 150/537: Loss=0.3921 (C:0.3921, R:0.0105)
Batch 175/537: Loss=0.4432 (C:0.4432, R:0.0105)
Batch 200/537: Loss=0.4472 (C:0.4472, R:0.0105)
Batch 225/537: Loss=0.4391 (C:0.4391, R:0.0105)
Batch 250/537: Loss=0.4326 (C:0.4326, R:0.0105)
Batch 275/537: Loss=0.4258 (C:0.4258, R:0.0105)
Batch 300/537: Loss=0.4259 (C:0.4259, R:0.0105)
Batch 325/537: Loss=0.4206 (C:0.4206, R:0.0105)
Batch 350/537: Loss=0.4286 (C:0.4286, R:0.0105)
Batch 375/537: Loss=0.4270 (C:0.4270, R:0.0105)
Batch 400/537: Loss=0.4151 (C:0.4151, R:0.0105)
Batch 425/537: Loss=0.4228 (C:0.4228, R:0.0105)
Batch 450/537: Loss=0.4307 (C:0.4307, R:0.0105)
Batch 475/537: Loss=0.4207 (C:0.4207, R:0.0105)
Batch 500/537: Loss=0.4435 (C:0.4435, R:0.0105)
Batch 525/537: Loss=0.4261 (C:0.4261, R:0.0106)

============================================================
Epoch 17/300 completed in 27.6s
Train: Loss=0.4312 (C:0.4312, R:0.0105) Ratio=3.66x
Val:   Loss=0.4627 (C:0.4627, R:0.0104) Ratio=2.97x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 18
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.233 ± 0.304
    Neg distances: 1.098 ± 0.507
    Separation ratio: 4.72x
    Gap: -1.934
    ✅ Excellent global separation!

Epoch 18 Training
----------------------------------------
Batch   0/537: Loss=0.3988 (C:0.3988, R:0.0105)
Batch  25/537: Loss=0.4237 (C:0.4237, R:0.0105)
Batch  50/537: Loss=0.4298 (C:0.4298, R:0.0105)
Batch  75/537: Loss=0.4223 (C:0.4223, R:0.0105)
Batch 100/537: Loss=0.4182 (C:0.4182, R:0.0105)
Batch 125/537: Loss=0.4070 (C:0.4070, R:0.0105)
Batch 150/537: Loss=0.4268 (C:0.4268, R:0.0105)
Batch 175/537: Loss=0.4153 (C:0.4153, R:0.0105)
Batch 200/537: Loss=0.4236 (C:0.4236, R:0.0105)
Batch 225/537: Loss=0.4234 (C:0.4234, R:0.0105)
Batch 250/537: Loss=0.4237 (C:0.4237, R:0.0106)
Batch 275/537: Loss=0.4105 (C:0.4105, R:0.0105)
Batch 300/537: Loss=0.4385 (C:0.4385, R:0.0105)
Batch 325/537: Loss=0.4140 (C:0.4140, R:0.0105)
Batch 350/537: Loss=0.3980 (C:0.3980, R:0.0106)
Batch 375/537: Loss=0.4251 (C:0.4251, R:0.0105)
Batch 400/537: Loss=0.4206 (C:0.4206, R:0.0105)
Batch 425/537: Loss=0.4146 (C:0.4146, R:0.0105)
Batch 450/537: Loss=0.4152 (C:0.4152, R:0.0105)
Batch 475/537: Loss=0.4324 (C:0.4324, R:0.0106)
Batch 500/537: Loss=0.4306 (C:0.4306, R:0.0106)
Batch 525/537: Loss=0.4361 (C:0.4361, R:0.0105)

============================================================
Epoch 18/300 completed in 27.7s
Train: Loss=0.4248 (C:0.4248, R:0.0105) Ratio=3.68x
Val:   Loss=0.4611 (C:0.4611, R:0.0104) Ratio=2.98x
Reconstruction weight: 0.000
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 19
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.235 ± 0.314
    Neg distances: 1.123 ± 0.518
    Separation ratio: 4.78x
    Gap: -1.964
    ✅ Excellent global separation!

Epoch 19 Training
----------------------------------------
Batch   0/537: Loss=0.4042 (C:0.4042, R:0.0105)
Batch  25/537: Loss=0.4207 (C:0.4207, R:0.0105)
Batch  50/537: Loss=0.4047 (C:0.4047, R:0.0105)
Batch  75/537: Loss=0.4445 (C:0.4445, R:0.0105)
Batch 100/537: Loss=0.4079 (C:0.4079, R:0.0105)
Batch 125/537: Loss=0.4280 (C:0.4280, R:0.0105)
Batch 150/537: Loss=0.4219 (C:0.4219, R:0.0105)
Batch 175/537: Loss=0.4277 (C:0.4277, R:0.0105)
Batch 200/537: Loss=0.4373 (C:0.4373, R:0.0105)
Batch 225/537: Loss=0.4190 (C:0.4190, R:0.0105)
Batch 250/537: Loss=0.4242 (C:0.4242, R:0.0105)
Batch 275/537: Loss=0.4114 (C:0.4114, R:0.0105)
Batch 300/537: Loss=0.4123 (C:0.4123, R:0.0105)
Batch 325/537: Loss=0.4164 (C:0.4164, R:0.0105)
Batch 350/537: Loss=0.4196 (C:0.4196, R:0.0105)
Batch 375/537: Loss=0.3964 (C:0.3964, R:0.0105)
Batch 400/537: Loss=0.4309 (C:0.4309, R:0.0105)
Batch 425/537: Loss=0.4244 (C:0.4244, R:0.0105)
Batch 450/537: Loss=0.3997 (C:0.3997, R:0.0105)
Batch 475/537: Loss=0.4083 (C:0.4083, R:0.0105)
Batch 500/537: Loss=0.4088 (C:0.4088, R:0.0105)
Batch 525/537: Loss=0.4363 (C:0.4363, R:0.0105)

============================================================
Epoch 19/300 completed in 27.0s
Train: Loss=0.4189 (C:0.4189, R:0.0105) Ratio=3.73x
Val:   Loss=0.4584 (C:0.4584, R:0.0104) Ratio=2.99x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4584)
============================================================

🌍 Updating global dataset at epoch 20
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.230 ± 0.314
    Neg distances: 1.141 ± 0.523
    Separation ratio: 4.96x
    Gap: -1.981
    ✅ Excellent global separation!

Epoch 20 Training
----------------------------------------
Batch   0/537: Loss=0.4195 (C:0.4195, R:0.0105)
Batch  25/537: Loss=0.3954 (C:0.3954, R:0.0105)
Batch  50/537: Loss=0.4066 (C:0.4066, R:0.0105)
Batch  75/537: Loss=0.3923 (C:0.3923, R:0.0105)
Batch 100/537: Loss=0.4043 (C:0.4043, R:0.0105)
Batch 125/537: Loss=0.4114 (C:0.4114, R:0.0105)
Batch 150/537: Loss=0.3997 (C:0.3997, R:0.0105)
Batch 175/537: Loss=0.4136 (C:0.4136, R:0.0105)
Batch 200/537: Loss=0.4115 (C:0.4115, R:0.0105)
Batch 225/537: Loss=0.3821 (C:0.3821, R:0.0105)
Batch 250/537: Loss=0.4036 (C:0.4036, R:0.0105)
Batch 275/537: Loss=0.3888 (C:0.3888, R:0.0105)
Batch 300/537: Loss=0.3966 (C:0.3966, R:0.0105)
Batch 325/537: Loss=0.4003 (C:0.4003, R:0.0105)
Batch 350/537: Loss=0.4064 (C:0.4064, R:0.0105)
Batch 375/537: Loss=0.4133 (C:0.4133, R:0.0105)
Batch 400/537: Loss=0.4103 (C:0.4103, R:0.0105)
Batch 425/537: Loss=0.4198 (C:0.4198, R:0.0105)
Batch 450/537: Loss=0.3983 (C:0.3983, R:0.0105)
Batch 475/537: Loss=0.4126 (C:0.4126, R:0.0105)
Batch 500/537: Loss=0.4147 (C:0.4147, R:0.0105)
Batch 525/537: Loss=0.4154 (C:0.4154, R:0.0105)

============================================================
Epoch 20/300 completed in 26.9s
Train: Loss=0.4102 (C:0.4102, R:0.0105) Ratio=3.78x
Val:   Loss=0.4449 (C:0.4449, R:0.0104) Ratio=2.98x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4449)
Checkpoint saved at epoch 20
============================================================

🌍 Updating global dataset at epoch 21
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.231 ± 0.317
    Neg distances: 1.161 ± 0.528
    Separation ratio: 5.04x
    Gap: -2.056
    ✅ Excellent global separation!

Epoch 21 Training
----------------------------------------
Batch   0/537: Loss=0.3916 (C:0.3916, R:0.0105)
Batch  25/537: Loss=0.4196 (C:0.4196, R:0.0105)
Batch  50/537: Loss=0.4063 (C:0.4063, R:0.0105)
Batch  75/537: Loss=0.4088 (C:0.4088, R:0.0105)
Batch 100/537: Loss=0.4040 (C:0.4040, R:0.0105)
Batch 125/537: Loss=0.4004 (C:0.4004, R:0.0105)
Batch 150/537: Loss=0.4045 (C:0.4045, R:0.0105)
Batch 175/537: Loss=0.3976 (C:0.3976, R:0.0105)
Batch 200/537: Loss=0.4071 (C:0.4071, R:0.0105)
Batch 225/537: Loss=0.4068 (C:0.4068, R:0.0105)
Batch 250/537: Loss=0.4034 (C:0.4034, R:0.0105)
Batch 275/537: Loss=0.4121 (C:0.4121, R:0.0105)
Batch 300/537: Loss=0.4007 (C:0.4007, R:0.0105)
Batch 325/537: Loss=0.4106 (C:0.4106, R:0.0105)
Batch 350/537: Loss=0.4288 (C:0.4288, R:0.0105)
Batch 375/537: Loss=0.3964 (C:0.3964, R:0.0105)
Batch 400/537: Loss=0.4017 (C:0.4017, R:0.0105)
Batch 425/537: Loss=0.4071 (C:0.4071, R:0.0105)
Batch 450/537: Loss=0.4218 (C:0.4218, R:0.0105)
Batch 475/537: Loss=0.4021 (C:0.4021, R:0.0105)
Batch 500/537: Loss=0.4206 (C:0.4206, R:0.0105)
Batch 525/537: Loss=0.4109 (C:0.4109, R:0.0105)

============================================================
Epoch 21/300 completed in 26.8s
Train: Loss=0.4037 (C:0.4037, R:0.0105) Ratio=3.76x
Val:   Loss=0.4424 (C:0.4424, R:0.0104) Ratio=3.01x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4424)
============================================================

🌍 Updating global dataset at epoch 22
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.229 ± 0.315
    Neg distances: 1.177 ± 0.534
    Separation ratio: 5.14x
    Gap: -2.052
    ✅ Excellent global separation!

Epoch 22 Training
----------------------------------------
Batch   0/537: Loss=0.3880 (C:0.3880, R:0.0105)
Batch  25/537: Loss=0.3778 (C:0.3778, R:0.0105)
Batch  50/537: Loss=0.3808 (C:0.3808, R:0.0105)
Batch  75/537: Loss=0.4022 (C:0.4022, R:0.0105)
Batch 100/537: Loss=0.3785 (C:0.3785, R:0.0105)
Batch 125/537: Loss=0.4015 (C:0.4015, R:0.0105)
Batch 150/537: Loss=0.3999 (C:0.3999, R:0.0105)
Batch 175/537: Loss=0.4021 (C:0.4021, R:0.0105)
Batch 200/537: Loss=0.4051 (C:0.4051, R:0.0105)
Batch 225/537: Loss=0.4015 (C:0.4015, R:0.0105)
Batch 250/537: Loss=0.4110 (C:0.4110, R:0.0105)
Batch 275/537: Loss=0.3925 (C:0.3925, R:0.0105)
Batch 300/537: Loss=0.4017 (C:0.4017, R:0.0106)
Batch 325/537: Loss=0.4100 (C:0.4100, R:0.0105)
Batch 350/537: Loss=0.4136 (C:0.4136, R:0.0105)
Batch 375/537: Loss=0.4215 (C:0.4215, R:0.0105)
Batch 400/537: Loss=0.4018 (C:0.4018, R:0.0105)
Batch 425/537: Loss=0.3937 (C:0.3937, R:0.0105)
Batch 450/537: Loss=0.4011 (C:0.4011, R:0.0105)
Batch 475/537: Loss=0.4015 (C:0.4015, R:0.0105)
Batch 500/537: Loss=0.4038 (C:0.4038, R:0.0105)
Batch 525/537: Loss=0.3929 (C:0.3929, R:0.0105)

============================================================
Epoch 22/300 completed in 27.2s
Train: Loss=0.3975 (C:0.3975, R:0.0105) Ratio=3.77x
Val:   Loss=0.4381 (C:0.4381, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4381)
============================================================

🌍 Updating global dataset at epoch 23
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.226 ± 0.320
    Neg distances: 1.184 ± 0.533
    Separation ratio: 5.24x
    Gap: -2.106
    ✅ Excellent global separation!

Epoch 23 Training
----------------------------------------
Batch   0/537: Loss=0.4067 (C:0.4067, R:0.0106)
Batch  25/537: Loss=0.3662 (C:0.3662, R:0.0105)
Batch  50/537: Loss=0.3962 (C:0.3962, R:0.0106)
Batch  75/537: Loss=0.3856 (C:0.3856, R:0.0105)
Batch 100/537: Loss=0.3814 (C:0.3814, R:0.0105)
Batch 125/537: Loss=0.3790 (C:0.3790, R:0.0105)
Batch 150/537: Loss=0.3706 (C:0.3706, R:0.0105)
Batch 175/537: Loss=0.3885 (C:0.3885, R:0.0105)
Batch 200/537: Loss=0.3818 (C:0.3818, R:0.0105)
Batch 225/537: Loss=0.4011 (C:0.4011, R:0.0105)
Batch 250/537: Loss=0.3882 (C:0.3882, R:0.0105)
Batch 275/537: Loss=0.3904 (C:0.3904, R:0.0105)
Batch 300/537: Loss=0.4130 (C:0.4130, R:0.0105)
Batch 325/537: Loss=0.3865 (C:0.3865, R:0.0105)
Batch 350/537: Loss=0.3815 (C:0.3815, R:0.0105)
Batch 375/537: Loss=0.3889 (C:0.3889, R:0.0106)
Batch 400/537: Loss=0.4098 (C:0.4098, R:0.0105)
Batch 425/537: Loss=0.3897 (C:0.3897, R:0.0105)
Batch 450/537: Loss=0.3782 (C:0.3782, R:0.0105)
Batch 475/537: Loss=0.3765 (C:0.3765, R:0.0105)
Batch 500/537: Loss=0.3845 (C:0.3845, R:0.0105)
Batch 525/537: Loss=0.4140 (C:0.4140, R:0.0105)

============================================================
Epoch 23/300 completed in 27.3s
Train: Loss=0.3909 (C:0.3909, R:0.0105) Ratio=3.92x
Val:   Loss=0.4296 (C:0.4296, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4296)
============================================================

🌍 Updating global dataset at epoch 24
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.222 ± 0.315
    Neg distances: 1.197 ± 0.539
    Separation ratio: 5.38x
    Gap: -2.068
    ✅ Excellent global separation!

Epoch 24 Training
----------------------------------------
Batch   0/537: Loss=0.3833 (C:0.3833, R:0.0105)
Batch  25/537: Loss=0.3910 (C:0.3910, R:0.0105)
Batch  50/537: Loss=0.3855 (C:0.3855, R:0.0105)
Batch  75/537: Loss=0.3726 (C:0.3726, R:0.0105)
Batch 100/537: Loss=0.3667 (C:0.3667, R:0.0105)
Batch 125/537: Loss=0.3857 (C:0.3857, R:0.0105)
Batch 150/537: Loss=0.3914 (C:0.3914, R:0.0105)
Batch 175/537: Loss=0.3579 (C:0.3579, R:0.0105)
Batch 200/537: Loss=0.3845 (C:0.3845, R:0.0105)
Batch 225/537: Loss=0.3910 (C:0.3910, R:0.0105)
Batch 250/537: Loss=0.3898 (C:0.3898, R:0.0105)
Batch 275/537: Loss=0.3844 (C:0.3844, R:0.0105)
Batch 300/537: Loss=0.3743 (C:0.3743, R:0.0105)
Batch 325/537: Loss=0.3829 (C:0.3829, R:0.0105)
Batch 350/537: Loss=0.3927 (C:0.3927, R:0.0105)
Batch 375/537: Loss=0.3868 (C:0.3868, R:0.0105)
Batch 400/537: Loss=0.3702 (C:0.3702, R:0.0105)
Batch 425/537: Loss=0.3849 (C:0.3849, R:0.0105)
Batch 450/537: Loss=0.3914 (C:0.3914, R:0.0105)
Batch 475/537: Loss=0.3907 (C:0.3907, R:0.0105)
Batch 500/537: Loss=0.3900 (C:0.3900, R:0.0105)
Batch 525/537: Loss=0.3864 (C:0.3864, R:0.0105)

============================================================
Epoch 24/300 completed in 27.3s
Train: Loss=0.3854 (C:0.3854, R:0.0105) Ratio=3.92x
Val:   Loss=0.4225 (C:0.4225, R:0.0104) Ratio=3.02x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4225)
============================================================

🌍 Updating global dataset at epoch 25
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.219 ± 0.321
    Neg distances: 1.194 ± 0.535
    Separation ratio: 5.44x
    Gap: -2.114
    ✅ Excellent global separation!

Epoch 25 Training
----------------------------------------
Batch   0/537: Loss=0.3868 (C:0.3868, R:0.0105)
Batch  25/537: Loss=0.3783 (C:0.3783, R:0.0105)
Batch  50/537: Loss=0.3745 (C:0.3745, R:0.0105)
Batch  75/537: Loss=0.3904 (C:0.3904, R:0.0105)
Batch 100/537: Loss=0.3957 (C:0.3957, R:0.0105)
Batch 125/537: Loss=0.3961 (C:0.3961, R:0.0105)
Batch 150/537: Loss=0.3740 (C:0.3740, R:0.0105)
Batch 175/537: Loss=0.3693 (C:0.3693, R:0.0105)
Batch 200/537: Loss=0.3901 (C:0.3901, R:0.0105)
Batch 225/537: Loss=0.3857 (C:0.3857, R:0.0105)
Batch 250/537: Loss=0.3652 (C:0.3652, R:0.0105)
Batch 275/537: Loss=0.3675 (C:0.3675, R:0.0105)
Batch 300/537: Loss=0.3812 (C:0.3812, R:0.0105)
Batch 325/537: Loss=0.3743 (C:0.3743, R:0.0106)
Batch 350/537: Loss=0.3822 (C:0.3822, R:0.0105)
Batch 375/537: Loss=0.3991 (C:0.3991, R:0.0105)
Batch 400/537: Loss=0.3937 (C:0.3937, R:0.0105)
Batch 425/537: Loss=0.4109 (C:0.4109, R:0.0105)
Batch 450/537: Loss=0.3873 (C:0.3873, R:0.0105)
Batch 475/537: Loss=0.3780 (C:0.3780, R:0.0105)
Batch 500/537: Loss=0.3918 (C:0.3918, R:0.0105)
Batch 525/537: Loss=0.3733 (C:0.3733, R:0.0105)

============================================================
Epoch 25/300 completed in 26.7s
Train: Loss=0.3811 (C:0.3811, R:0.0105) Ratio=3.91x
Val:   Loss=0.4228 (C:0.4228, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 26
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.219 ± 0.314
    Neg distances: 1.217 ± 0.542
    Separation ratio: 5.56x
    Gap: -2.112
    ✅ Excellent global separation!

Epoch 26 Training
----------------------------------------
Batch   0/537: Loss=0.3636 (C:0.3636, R:0.0105)
Batch  25/537: Loss=0.3823 (C:0.3823, R:0.0105)
Batch  50/537: Loss=0.3697 (C:0.3697, R:0.0105)
Batch  75/537: Loss=0.3636 (C:0.3636, R:0.0105)
Batch 100/537: Loss=0.3587 (C:0.3587, R:0.0106)
Batch 125/537: Loss=0.3622 (C:0.3622, R:0.0105)
Batch 150/537: Loss=0.3740 (C:0.3740, R:0.0105)
Batch 175/537: Loss=0.3890 (C:0.3890, R:0.0105)
Batch 200/537: Loss=0.3753 (C:0.3753, R:0.0105)
Batch 225/537: Loss=0.3604 (C:0.3604, R:0.0105)
Batch 250/537: Loss=0.3623 (C:0.3623, R:0.0105)
Batch 275/537: Loss=0.3653 (C:0.3653, R:0.0105)
Batch 300/537: Loss=0.3662 (C:0.3662, R:0.0105)
Batch 325/537: Loss=0.3686 (C:0.3686, R:0.0105)
Batch 350/537: Loss=0.3649 (C:0.3649, R:0.0105)
Batch 375/537: Loss=0.3837 (C:0.3837, R:0.0105)
Batch 400/537: Loss=0.3675 (C:0.3675, R:0.0105)
Batch 425/537: Loss=0.3698 (C:0.3698, R:0.0105)
Batch 450/537: Loss=0.3649 (C:0.3649, R:0.0105)
Batch 475/537: Loss=0.3624 (C:0.3624, R:0.0105)
Batch 500/537: Loss=0.3713 (C:0.3713, R:0.0105)
Batch 525/537: Loss=0.3860 (C:0.3860, R:0.0105)

============================================================
Epoch 26/300 completed in 26.6s
Train: Loss=0.3747 (C:0.3747, R:0.0105) Ratio=4.03x
Val:   Loss=0.4220 (C:0.4220, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4220)
============================================================

🌍 Updating global dataset at epoch 27
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.213 ± 0.307
    Neg distances: 1.226 ± 0.541
    Separation ratio: 5.76x
    Gap: -2.129
    ✅ Excellent global separation!

Epoch 27 Training
----------------------------------------
Batch   0/537: Loss=0.3432 (C:0.3432, R:0.0106)
Batch  25/537: Loss=0.3877 (C:0.3877, R:0.0105)
Batch  50/537: Loss=0.3891 (C:0.3891, R:0.0105)
Batch  75/537: Loss=0.3956 (C:0.3956, R:0.0105)
Batch 100/537: Loss=0.3620 (C:0.3620, R:0.0105)
Batch 125/537: Loss=0.3776 (C:0.3776, R:0.0105)
Batch 150/537: Loss=0.3478 (C:0.3478, R:0.0105)
Batch 175/537: Loss=0.3610 (C:0.3610, R:0.0105)
Batch 200/537: Loss=0.3661 (C:0.3661, R:0.0105)
Batch 225/537: Loss=0.3617 (C:0.3617, R:0.0105)
Batch 250/537: Loss=0.3681 (C:0.3681, R:0.0105)
Batch 275/537: Loss=0.3715 (C:0.3715, R:0.0105)
Batch 300/537: Loss=0.3910 (C:0.3910, R:0.0105)
Batch 325/537: Loss=0.3784 (C:0.3784, R:0.0105)
Batch 350/537: Loss=0.3702 (C:0.3702, R:0.0105)
Batch 375/537: Loss=0.3572 (C:0.3572, R:0.0105)
Batch 400/537: Loss=0.3806 (C:0.3806, R:0.0105)
Batch 425/537: Loss=0.3732 (C:0.3732, R:0.0105)
Batch 450/537: Loss=0.3648 (C:0.3648, R:0.0106)
Batch 475/537: Loss=0.3711 (C:0.3711, R:0.0105)
Batch 500/537: Loss=0.3689 (C:0.3689, R:0.0105)
Batch 525/537: Loss=0.3533 (C:0.3533, R:0.0105)

============================================================
Epoch 27/300 completed in 26.6s
Train: Loss=0.3672 (C:0.3672, R:0.0105) Ratio=3.98x
Val:   Loss=0.4130 (C:0.4130, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4130)
============================================================

🌍 Updating global dataset at epoch 28
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.211 ± 0.315
    Neg distances: 1.226 ± 0.543
    Separation ratio: 5.80x
    Gap: -2.128
    ✅ Excellent global separation!

Epoch 28 Training
----------------------------------------
Batch   0/537: Loss=0.3677 (C:0.3677, R:0.0105)
Batch  25/537: Loss=0.3706 (C:0.3706, R:0.0105)
Batch  50/537: Loss=0.3819 (C:0.3819, R:0.0104)
Batch  75/537: Loss=0.3672 (C:0.3672, R:0.0105)
Batch 100/537: Loss=0.3610 (C:0.3610, R:0.0105)
Batch 125/537: Loss=0.3963 (C:0.3963, R:0.0105)
Batch 150/537: Loss=0.3553 (C:0.3553, R:0.0105)
Batch 175/537: Loss=0.3736 (C:0.3736, R:0.0105)
Batch 200/537: Loss=0.3640 (C:0.3640, R:0.0105)
Batch 225/537: Loss=0.3743 (C:0.3743, R:0.0105)
Batch 250/537: Loss=0.3733 (C:0.3733, R:0.0105)
Batch 275/537: Loss=0.3585 (C:0.3585, R:0.0105)
Batch 300/537: Loss=0.3476 (C:0.3476, R:0.0105)
Batch 325/537: Loss=0.3630 (C:0.3630, R:0.0105)
Batch 350/537: Loss=0.3912 (C:0.3912, R:0.0105)
Batch 375/537: Loss=0.3683 (C:0.3683, R:0.0105)
Batch 400/537: Loss=0.3656 (C:0.3656, R:0.0105)
Batch 425/537: Loss=0.3672 (C:0.3672, R:0.0106)
Batch 450/537: Loss=0.4046 (C:0.4046, R:0.0105)
Batch 475/537: Loss=0.3668 (C:0.3668, R:0.0105)
Batch 500/537: Loss=0.3836 (C:0.3836, R:0.0105)
Batch 525/537: Loss=0.3917 (C:0.3917, R:0.0105)

============================================================
Epoch 28/300 completed in 27.5s
Train: Loss=0.3646 (C:0.3646, R:0.0105) Ratio=3.98x
Val:   Loss=0.4052 (C:0.4052, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4052)
============================================================

🌍 Updating global dataset at epoch 29
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.213 ± 0.319
    Neg distances: 1.234 ± 0.547
    Separation ratio: 5.78x
    Gap: -2.151
    ✅ Excellent global separation!

Epoch 29 Training
----------------------------------------
Batch   0/537: Loss=0.3443 (C:0.3443, R:0.0105)
Batch  25/537: Loss=0.3535 (C:0.3535, R:0.0105)
Batch  50/537: Loss=0.3678 (C:0.3678, R:0.0105)
Batch  75/537: Loss=0.3587 (C:0.3587, R:0.0105)
Batch 100/537: Loss=0.3569 (C:0.3569, R:0.0105)
Batch 125/537: Loss=0.3634 (C:0.3634, R:0.0105)
Batch 150/537: Loss=0.3567 (C:0.3567, R:0.0105)
Batch 175/537: Loss=0.3625 (C:0.3625, R:0.0105)
Batch 200/537: Loss=0.3577 (C:0.3577, R:0.0105)
Batch 225/537: Loss=0.3757 (C:0.3757, R:0.0105)
Batch 250/537: Loss=0.3810 (C:0.3810, R:0.0105)
Batch 275/537: Loss=0.3604 (C:0.3604, R:0.0105)
Batch 300/537: Loss=0.3883 (C:0.3883, R:0.0105)
Batch 325/537: Loss=0.3766 (C:0.3766, R:0.0105)
Batch 350/537: Loss=0.3694 (C:0.3694, R:0.0105)
Batch 375/537: Loss=0.3728 (C:0.3728, R:0.0105)
Batch 400/537: Loss=0.3511 (C:0.3511, R:0.0105)
Batch 425/537: Loss=0.3761 (C:0.3761, R:0.0105)
Batch 450/537: Loss=0.3609 (C:0.3609, R:0.0105)
Batch 475/537: Loss=0.3565 (C:0.3565, R:0.0104)
Batch 500/537: Loss=0.3725 (C:0.3725, R:0.0105)
Batch 525/537: Loss=0.3728 (C:0.3728, R:0.0106)

============================================================
Epoch 29/300 completed in 27.0s
Train: Loss=0.3630 (C:0.3630, R:0.0105) Ratio=4.08x
Val:   Loss=0.4069 (C:0.4069, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 30
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.203 ± 0.308
    Neg distances: 1.236 ± 0.541
    Separation ratio: 6.10x
    Gap: -2.132
    ✅ Excellent global separation!

Epoch 30 Training
----------------------------------------
Batch   0/537: Loss=0.3388 (C:0.3388, R:0.0105)
Batch  25/537: Loss=0.3571 (C:0.3571, R:0.0105)
Batch  50/537: Loss=0.3545 (C:0.3545, R:0.0105)
Batch  75/537: Loss=0.3549 (C:0.3549, R:0.0105)
Batch 100/537: Loss=0.3668 (C:0.3668, R:0.0105)
Batch 125/537: Loss=0.3264 (C:0.3264, R:0.0105)
Batch 150/537: Loss=0.3361 (C:0.3361, R:0.0105)
Batch 175/537: Loss=0.3576 (C:0.3576, R:0.0105)
Batch 200/537: Loss=0.3526 (C:0.3526, R:0.0105)
Batch 225/537: Loss=0.3624 (C:0.3624, R:0.0105)
Batch 250/537: Loss=0.3621 (C:0.3621, R:0.0105)
Batch 275/537: Loss=0.3318 (C:0.3318, R:0.0105)
Batch 300/537: Loss=0.3718 (C:0.3718, R:0.0105)
Batch 325/537: Loss=0.3622 (C:0.3622, R:0.0105)
Batch 350/537: Loss=0.3592 (C:0.3592, R:0.0105)
Batch 375/537: Loss=0.3592 (C:0.3592, R:0.0106)
Batch 400/537: Loss=0.3386 (C:0.3386, R:0.0105)
Batch 425/537: Loss=0.3526 (C:0.3526, R:0.0105)
Batch 450/537: Loss=0.3512 (C:0.3512, R:0.0105)
Batch 475/537: Loss=0.3546 (C:0.3546, R:0.0105)
Batch 500/537: Loss=0.3423 (C:0.3423, R:0.0105)
Batch 525/537: Loss=0.3440 (C:0.3440, R:0.0105)

============================================================
Epoch 30/300 completed in 26.8s
Train: Loss=0.3522 (C:0.3522, R:0.0105) Ratio=4.19x
Val:   Loss=0.4055 (C:0.4055, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.000
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 31
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.212 ± 0.320
    Neg distances: 1.247 ± 0.551
    Separation ratio: 5.88x
    Gap: -2.168
    ✅ Excellent global separation!

Epoch 31 Training
----------------------------------------
Batch   0/537: Loss=0.3463 (C:0.3463, R:0.0105)
Batch  25/537: Loss=0.3385 (C:0.3385, R:0.0105)
Batch  50/537: Loss=0.3338 (C:0.3338, R:0.0105)
Batch  75/537: Loss=0.3670 (C:0.3670, R:0.0105)
Batch 100/537: Loss=0.3771 (C:0.3771, R:0.0105)
Batch 125/537: Loss=0.3545 (C:0.3545, R:0.0105)
Batch 150/537: Loss=0.3605 (C:0.3605, R:0.0105)
Batch 175/537: Loss=0.3452 (C:0.3452, R:0.0105)
Batch 200/537: Loss=0.3726 (C:0.3726, R:0.0105)
Batch 225/537: Loss=0.3544 (C:0.3544, R:0.0105)
Batch 250/537: Loss=0.3562 (C:0.3562, R:0.0105)
Batch 275/537: Loss=0.3366 (C:0.3366, R:0.0105)
Batch 300/537: Loss=0.3711 (C:0.3711, R:0.0105)
Batch 325/537: Loss=0.3557 (C:0.3557, R:0.0105)
Batch 350/537: Loss=0.3310 (C:0.3310, R:0.0105)
Batch 375/537: Loss=0.3786 (C:0.3786, R:0.0105)
Batch 400/537: Loss=0.3387 (C:0.3387, R:0.0105)
Batch 425/537: Loss=0.3595 (C:0.3595, R:0.0105)
Batch 450/537: Loss=0.3373 (C:0.3373, R:0.0105)
Batch 475/537: Loss=0.3520 (C:0.3520, R:0.0105)
Batch 500/537: Loss=0.3552 (C:0.3552, R:0.0105)
Batch 525/537: Loss=0.3462 (C:0.3462, R:0.0105)

============================================================
Epoch 31/300 completed in 27.1s
Train: Loss=0.3572 (C:0.3572, R:0.0105) Ratio=4.20x
Val:   Loss=0.4038 (C:0.4038, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.015
✅ New best model saved (Val Loss: 0.4038)
============================================================

🌍 Updating global dataset at epoch 32
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.207 ± 0.318
    Neg distances: 1.241 ± 0.545
    Separation ratio: 5.99x
    Gap: -2.197
    ✅ Excellent global separation!

Epoch 32 Training
----------------------------------------
Batch   0/537: Loss=0.3490 (C:0.3490, R:0.0106)
Batch  25/537: Loss=0.3498 (C:0.3498, R:0.0105)
Batch  50/537: Loss=0.3324 (C:0.3324, R:0.0105)
Batch  75/537: Loss=0.3505 (C:0.3505, R:0.0105)
Batch 100/537: Loss=0.3526 (C:0.3526, R:0.0105)
Batch 125/537: Loss=0.3371 (C:0.3371, R:0.0105)
Batch 150/537: Loss=0.3627 (C:0.3627, R:0.0105)
Batch 175/537: Loss=0.3501 (C:0.3501, R:0.0105)
Batch 200/537: Loss=0.3469 (C:0.3469, R:0.0105)
Batch 225/537: Loss=0.3336 (C:0.3336, R:0.0105)
Batch 250/537: Loss=0.3500 (C:0.3500, R:0.0105)
Batch 275/537: Loss=0.3367 (C:0.3367, R:0.0105)
Batch 300/537: Loss=0.3456 (C:0.3456, R:0.0105)
Batch 325/537: Loss=0.3517 (C:0.3517, R:0.0105)
Batch 350/537: Loss=0.3501 (C:0.3501, R:0.0105)
Batch 375/537: Loss=0.3427 (C:0.3427, R:0.0105)
Batch 400/537: Loss=0.3537 (C:0.3537, R:0.0105)
Batch 425/537: Loss=0.3431 (C:0.3431, R:0.0106)
Batch 450/537: Loss=0.3658 (C:0.3658, R:0.0105)
Batch 475/537: Loss=0.3682 (C:0.3682, R:0.0105)
Batch 500/537: Loss=0.3452 (C:0.3452, R:0.0105)
Batch 525/537: Loss=0.3526 (C:0.3526, R:0.0105)

============================================================
Epoch 32/300 completed in 27.5s
Train: Loss=0.3516 (C:0.3516, R:0.0105) Ratio=4.26x
Val:   Loss=0.3987 (C:0.3987, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.030
✅ New best model saved (Val Loss: 0.3987)
============================================================

🌍 Updating global dataset at epoch 33
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.203 ± 0.311
    Neg distances: 1.243 ± 0.546
    Separation ratio: 6.13x
    Gap: -2.144
    ✅ Excellent global separation!

Epoch 33 Training
----------------------------------------
Batch   0/537: Loss=0.3150 (C:0.3150, R:0.0105)
Batch  25/537: Loss=0.3371 (C:0.3371, R:0.0105)
Batch  50/537: Loss=0.3439 (C:0.3439, R:0.0105)
Batch  75/537: Loss=0.3320 (C:0.3320, R:0.0105)
Batch 100/537: Loss=0.3216 (C:0.3216, R:0.0105)
Batch 125/537: Loss=0.3272 (C:0.3272, R:0.0105)
Batch 150/537: Loss=0.3269 (C:0.3269, R:0.0105)
Batch 175/537: Loss=0.3476 (C:0.3476, R:0.0105)
Batch 200/537: Loss=0.3504 (C:0.3504, R:0.0105)
Batch 225/537: Loss=0.3448 (C:0.3448, R:0.0105)
Batch 250/537: Loss=0.3584 (C:0.3584, R:0.0105)
Batch 275/537: Loss=0.3795 (C:0.3795, R:0.0105)
Batch 300/537: Loss=0.3489 (C:0.3489, R:0.0105)
Batch 325/537: Loss=0.3423 (C:0.3423, R:0.0105)
Batch 350/537: Loss=0.3577 (C:0.3577, R:0.0105)
Batch 375/537: Loss=0.3603 (C:0.3603, R:0.0106)
Batch 400/537: Loss=0.3392 (C:0.3392, R:0.0105)
Batch 425/537: Loss=0.3592 (C:0.3592, R:0.0105)
Batch 450/537: Loss=0.3333 (C:0.3333, R:0.0105)
Batch 475/537: Loss=0.3636 (C:0.3636, R:0.0105)
Batch 500/537: Loss=0.3342 (C:0.3342, R:0.0105)
Batch 525/537: Loss=0.3613 (C:0.3613, R:0.0105)

============================================================
Epoch 33/300 completed in 26.7s
Train: Loss=0.3476 (C:0.3476, R:0.0105) Ratio=4.32x
Val:   Loss=0.3994 (C:0.3994, R:0.0104) Ratio=3.13x
Reconstruction weight: 0.045
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 34
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.204 ± 0.308
    Neg distances: 1.249 ± 0.548
    Separation ratio: 6.13x
    Gap: -2.164
    ✅ Excellent global separation!

Epoch 34 Training
----------------------------------------
Batch   0/537: Loss=0.3577 (C:0.3577, R:0.0105)
Batch  25/537: Loss=0.3490 (C:0.3490, R:0.0105)
Batch  50/537: Loss=0.3359 (C:0.3359, R:0.0105)
Batch  75/537: Loss=0.3290 (C:0.3290, R:0.0105)
Batch 100/537: Loss=0.3394 (C:0.3394, R:0.0105)
Batch 125/537: Loss=0.3531 (C:0.3531, R:0.0105)
Batch 150/537: Loss=0.3330 (C:0.3330, R:0.0105)
Batch 175/537: Loss=0.3372 (C:0.3372, R:0.0105)
Batch 200/537: Loss=0.3557 (C:0.3557, R:0.0106)
Batch 225/537: Loss=0.3463 (C:0.3463, R:0.0105)
Batch 250/537: Loss=0.3311 (C:0.3311, R:0.0105)
Batch 275/537: Loss=0.3428 (C:0.3428, R:0.0105)
Batch 300/537: Loss=0.3554 (C:0.3554, R:0.0105)
Batch 325/537: Loss=0.3682 (C:0.3682, R:0.0105)
Batch 350/537: Loss=0.3515 (C:0.3515, R:0.0105)
Batch 375/537: Loss=0.3632 (C:0.3632, R:0.0105)
Batch 400/537: Loss=0.3694 (C:0.3694, R:0.0105)
Batch 425/537: Loss=0.3475 (C:0.3475, R:0.0105)
Batch 450/537: Loss=0.3556 (C:0.3556, R:0.0105)
Batch 475/537: Loss=0.3443 (C:0.3443, R:0.0105)
Batch 500/537: Loss=0.3401 (C:0.3401, R:0.0105)
Batch 525/537: Loss=0.3714 (C:0.3714, R:0.0105)

============================================================
Epoch 34/300 completed in 26.9s
Train: Loss=0.3456 (C:0.3456, R:0.0105) Ratio=4.31x
Val:   Loss=0.4016 (C:0.4016, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.060
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 35
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.205 ± 0.320
    Neg distances: 1.264 ± 0.555
    Separation ratio: 6.17x
    Gap: -2.221
    ✅ Excellent global separation!

Epoch 35 Training
----------------------------------------
Batch   0/537: Loss=0.3385 (C:0.3385, R:0.0105)
Batch  25/537: Loss=0.3391 (C:0.3391, R:0.0105)
Batch  50/537: Loss=0.3430 (C:0.3430, R:0.0105)
Batch  75/537: Loss=0.3520 (C:0.3520, R:0.0105)
Batch 100/537: Loss=0.3639 (C:0.3639, R:0.0105)
Batch 125/537: Loss=0.3434 (C:0.3434, R:0.0105)
Batch 150/537: Loss=0.3544 (C:0.3544, R:0.0105)
Batch 175/537: Loss=0.3364 (C:0.3364, R:0.0105)
Batch 200/537: Loss=0.3652 (C:0.3652, R:0.0105)
Batch 225/537: Loss=0.3395 (C:0.3395, R:0.0105)
Batch 250/537: Loss=0.3334 (C:0.3334, R:0.0105)
Batch 275/537: Loss=0.3431 (C:0.3431, R:0.0105)
Batch 300/537: Loss=0.3661 (C:0.3661, R:0.0105)
Batch 325/537: Loss=0.3540 (C:0.3540, R:0.0105)
Batch 350/537: Loss=0.3639 (C:0.3639, R:0.0105)
Batch 375/537: Loss=0.3513 (C:0.3513, R:0.0105)
Batch 400/537: Loss=0.3340 (C:0.3340, R:0.0105)
Batch 425/537: Loss=0.3760 (C:0.3760, R:0.0105)
Batch 450/537: Loss=0.3484 (C:0.3484, R:0.0105)
Batch 475/537: Loss=0.3411 (C:0.3411, R:0.0105)
Batch 500/537: Loss=0.3293 (C:0.3293, R:0.0105)
Batch 525/537: Loss=0.3715 (C:0.3715, R:0.0105)

============================================================
Epoch 35/300 completed in 26.6s
Train: Loss=0.3440 (C:0.3440, R:0.0105) Ratio=4.23x
Val:   Loss=0.4004 (C:0.4004, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.075
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 36
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.196 ± 0.312
    Neg distances: 1.276 ± 0.555
    Separation ratio: 6.50x
    Gap: -2.174
    ✅ Excellent global separation!

Epoch 36 Training
----------------------------------------
Batch   0/537: Loss=0.3469 (C:0.3469, R:0.0105)
Batch  25/537: Loss=0.3338 (C:0.3338, R:0.0105)
Batch  50/537: Loss=0.3259 (C:0.3259, R:0.0105)
Batch  75/537: Loss=0.3266 (C:0.3266, R:0.0105)
Batch 100/537: Loss=0.3423 (C:0.3423, R:0.0105)
Batch 125/537: Loss=0.3311 (C:0.3311, R:0.0105)
Batch 150/537: Loss=0.3073 (C:0.3073, R:0.0105)
Batch 175/537: Loss=0.3279 (C:0.3279, R:0.0105)
Batch 200/537: Loss=0.3556 (C:0.3556, R:0.0105)
Batch 225/537: Loss=0.3300 (C:0.3300, R:0.0105)
Batch 250/537: Loss=0.3324 (C:0.3324, R:0.0106)
Batch 275/537: Loss=0.3314 (C:0.3314, R:0.0105)
Batch 300/537: Loss=0.3370 (C:0.3370, R:0.0105)
Batch 325/537: Loss=0.3414 (C:0.3414, R:0.0105)
Batch 350/537: Loss=0.3580 (C:0.3580, R:0.0105)
Batch 375/537: Loss=0.3421 (C:0.3421, R:0.0105)
Batch 400/537: Loss=0.3219 (C:0.3219, R:0.0105)
Batch 425/537: Loss=0.3328 (C:0.3328, R:0.0105)
Batch 450/537: Loss=0.3393 (C:0.3393, R:0.0105)
Batch 475/537: Loss=0.3400 (C:0.3400, R:0.0105)
Batch 500/537: Loss=0.3159 (C:0.3159, R:0.0105)
Batch 525/537: Loss=0.3510 (C:0.3510, R:0.0105)

============================================================
Epoch 36/300 completed in 27.0s
Train: Loss=0.3347 (C:0.3347, R:0.0105) Ratio=4.40x
Val:   Loss=0.3896 (C:0.3896, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.090
✅ New best model saved (Val Loss: 0.3896)
============================================================

🌍 Updating global dataset at epoch 37
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.203 ± 0.317
    Neg distances: 1.274 ± 0.555
    Separation ratio: 6.29x
    Gap: -2.259
    ✅ Excellent global separation!

Epoch 37 Training
----------------------------------------
Batch   0/537: Loss=0.3376 (C:0.3376, R:0.0105)
Batch  25/537: Loss=0.3478 (C:0.3478, R:0.0105)
Batch  50/537: Loss=0.3255 (C:0.3255, R:0.0105)
Batch  75/537: Loss=0.3279 (C:0.3279, R:0.0105)
Batch 100/537: Loss=0.3491 (C:0.3491, R:0.0105)
Batch 125/537: Loss=0.3394 (C:0.3394, R:0.0105)
Batch 150/537: Loss=0.3256 (C:0.3256, R:0.0105)
Batch 175/537: Loss=0.3279 (C:0.3279, R:0.0105)
Batch 200/537: Loss=0.3394 (C:0.3394, R:0.0105)
Batch 225/537: Loss=0.3281 (C:0.3281, R:0.0105)
Batch 250/537: Loss=0.3443 (C:0.3443, R:0.0105)
Batch 275/537: Loss=0.3304 (C:0.3304, R:0.0105)
Batch 300/537: Loss=0.3350 (C:0.3350, R:0.0105)
Batch 325/537: Loss=0.3294 (C:0.3294, R:0.0105)
Batch 350/537: Loss=0.3536 (C:0.3536, R:0.0105)
Batch 375/537: Loss=0.3262 (C:0.3262, R:0.0105)
Batch 400/537: Loss=0.3365 (C:0.3365, R:0.0105)
Batch 425/537: Loss=0.3180 (C:0.3180, R:0.0105)
Batch 450/537: Loss=0.3329 (C:0.3329, R:0.0105)
Batch 475/537: Loss=0.3287 (C:0.3287, R:0.0105)
Batch 500/537: Loss=0.3483 (C:0.3483, R:0.0105)
Batch 525/537: Loss=0.3511 (C:0.3511, R:0.0105)

============================================================
Epoch 37/300 completed in 27.3s
Train: Loss=0.3377 (C:0.3377, R:0.0105) Ratio=4.39x
Val:   Loss=0.3935 (C:0.3935, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.105
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 38
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.192 ± 0.310
    Neg distances: 1.276 ± 0.551
    Separation ratio: 6.65x
    Gap: -2.193
    ✅ Excellent global separation!

Epoch 38 Training
----------------------------------------
Batch   0/537: Loss=0.3215 (C:0.3215, R:0.0105)
Batch  25/537: Loss=0.3104 (C:0.3104, R:0.0105)
Batch  50/537: Loss=0.3372 (C:0.3372, R:0.0105)
Batch  75/537: Loss=0.3392 (C:0.3392, R:0.0105)
Batch 100/537: Loss=0.3130 (C:0.3130, R:0.0105)
Batch 125/537: Loss=0.3052 (C:0.3052, R:0.0105)
Batch 150/537: Loss=0.3341 (C:0.3341, R:0.0105)
Batch 175/537: Loss=0.3520 (C:0.3520, R:0.0105)
Batch 200/537: Loss=0.3435 (C:0.3435, R:0.0105)
Batch 225/537: Loss=0.3389 (C:0.3389, R:0.0106)
Batch 250/537: Loss=0.3133 (C:0.3133, R:0.0105)
Batch 275/537: Loss=0.3233 (C:0.3233, R:0.0105)
Batch 300/537: Loss=0.3244 (C:0.3244, R:0.0105)
Batch 325/537: Loss=0.3183 (C:0.3183, R:0.0105)
Batch 350/537: Loss=0.3168 (C:0.3168, R:0.0105)
Batch 375/537: Loss=0.3065 (C:0.3065, R:0.0105)
Batch 400/537: Loss=0.3331 (C:0.3331, R:0.0105)
Batch 425/537: Loss=0.3222 (C:0.3222, R:0.0105)
Batch 450/537: Loss=0.3257 (C:0.3257, R:0.0105)
Batch 475/537: Loss=0.3273 (C:0.3273, R:0.0105)
Batch 500/537: Loss=0.3305 (C:0.3305, R:0.0105)
Batch 525/537: Loss=0.3256 (C:0.3256, R:0.0105)

============================================================
Epoch 38/300 completed in 26.9s
Train: Loss=0.3279 (C:0.3279, R:0.0105) Ratio=4.43x
Val:   Loss=0.3864 (C:0.3864, R:0.0104) Ratio=3.12x
Reconstruction weight: 0.120
✅ New best model saved (Val Loss: 0.3864)
============================================================

🌍 Updating global dataset at epoch 39
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.184 ± 0.295
    Neg distances: 1.274 ± 0.544
    Separation ratio: 6.92x
    Gap: -2.230
    ✅ Excellent global separation!

Epoch 39 Training
----------------------------------------
Batch   0/537: Loss=0.3148 (C:0.3148, R:0.0106)
Batch  25/537: Loss=0.3171 (C:0.3171, R:0.0105)
Batch  50/537: Loss=0.3145 (C:0.3145, R:0.0105)
Batch  75/537: Loss=0.3266 (C:0.3266, R:0.0105)
Batch 100/537: Loss=0.3279 (C:0.3279, R:0.0105)
Batch 125/537: Loss=0.3037 (C:0.3037, R:0.0105)
Batch 150/537: Loss=0.3189 (C:0.3189, R:0.0105)
Batch 175/537: Loss=0.3405 (C:0.3405, R:0.0106)
Batch 200/537: Loss=0.3349 (C:0.3349, R:0.0106)
Batch 225/537: Loss=0.3179 (C:0.3179, R:0.0105)
Batch 250/537: Loss=0.3212 (C:0.3212, R:0.0105)
Batch 275/537: Loss=0.3191 (C:0.3191, R:0.0105)
Batch 300/537: Loss=0.2907 (C:0.2907, R:0.0105)
Batch 325/537: Loss=0.3248 (C:0.3248, R:0.0106)
Batch 350/537: Loss=0.3235 (C:0.3235, R:0.0105)
Batch 375/537: Loss=0.3262 (C:0.3262, R:0.0105)
Batch 400/537: Loss=0.3168 (C:0.3168, R:0.0105)
Batch 425/537: Loss=0.3252 (C:0.3252, R:0.0105)
Batch 450/537: Loss=0.3057 (C:0.3057, R:0.0105)
Batch 475/537: Loss=0.3149 (C:0.3149, R:0.0105)
Batch 500/537: Loss=0.3378 (C:0.3378, R:0.0105)
Batch 525/537: Loss=0.3395 (C:0.3395, R:0.0105)

============================================================
Epoch 39/300 completed in 27.4s
Train: Loss=0.3210 (C:0.3210, R:0.0105) Ratio=4.36x
Val:   Loss=0.3786 (C:0.3786, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.135
✅ New best model saved (Val Loss: 0.3786)
============================================================

🌍 Updating global dataset at epoch 40
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.187 ± 0.302
    Neg distances: 1.298 ± 0.556
    Separation ratio: 6.94x
    Gap: -2.224
    ✅ Excellent global separation!

Epoch 40 Training
----------------------------------------
Batch   0/537: Loss=0.3275 (C:0.3275, R:0.0105)
Batch  25/537: Loss=0.3035 (C:0.3035, R:0.0105)
Batch  50/537: Loss=0.3086 (C:0.3086, R:0.0105)
Batch  75/537: Loss=0.2960 (C:0.2960, R:0.0105)
Batch 100/537: Loss=0.3148 (C:0.3148, R:0.0105)
Batch 125/537: Loss=0.3329 (C:0.3329, R:0.0105)
Batch 150/537: Loss=0.3213 (C:0.3213, R:0.0105)
Batch 175/537: Loss=0.2956 (C:0.2956, R:0.0105)
Batch 200/537: Loss=0.3427 (C:0.3427, R:0.0105)
Batch 225/537: Loss=0.3313 (C:0.3313, R:0.0105)
Batch 250/537: Loss=0.3280 (C:0.3280, R:0.0105)
Batch 275/537: Loss=0.3011 (C:0.3011, R:0.0105)
Batch 300/537: Loss=0.3114 (C:0.3114, R:0.0105)
Batch 325/537: Loss=0.3223 (C:0.3223, R:0.0105)
Batch 350/537: Loss=0.3258 (C:0.3258, R:0.0105)
Batch 375/537: Loss=0.3196 (C:0.3196, R:0.0105)
Batch 400/537: Loss=0.3143 (C:0.3143, R:0.0105)
Batch 425/537: Loss=0.3399 (C:0.3399, R:0.0105)
Batch 450/537: Loss=0.3051 (C:0.3051, R:0.0105)
Batch 475/537: Loss=0.3281 (C:0.3281, R:0.0105)
Batch 500/537: Loss=0.3223 (C:0.3223, R:0.0105)
Batch 525/537: Loss=0.3159 (C:0.3159, R:0.0105)

============================================================
Epoch 40/300 completed in 27.4s
Train: Loss=0.3202 (C:0.3202, R:0.0105) Ratio=4.52x
Val:   Loss=0.3861 (C:0.3861, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.150
No improvement for 1 epochs
Checkpoint saved at epoch 40
============================================================

🌍 Updating global dataset at epoch 41
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.190 ± 0.314
    Neg distances: 1.298 ± 0.559
    Separation ratio: 6.83x
    Gap: -2.218
    ✅ Excellent global separation!

Epoch 41 Training
----------------------------------------
Batch   0/537: Loss=0.2954 (C:0.2954, R:0.0105)
Batch  25/537: Loss=0.3218 (C:0.3218, R:0.0106)
Batch  50/537: Loss=0.3150 (C:0.3150, R:0.0105)
Batch  75/537: Loss=0.3183 (C:0.3183, R:0.0105)
Batch 100/537: Loss=0.3182 (C:0.3182, R:0.0105)
Batch 125/537: Loss=0.3064 (C:0.3064, R:0.0105)
Batch 150/537: Loss=0.3238 (C:0.3238, R:0.0105)
Batch 175/537: Loss=0.3229 (C:0.3229, R:0.0105)
Batch 200/537: Loss=0.3150 (C:0.3150, R:0.0105)
Batch 225/537: Loss=0.3138 (C:0.3138, R:0.0105)
Batch 250/537: Loss=0.3240 (C:0.3240, R:0.0105)
Batch 275/537: Loss=0.3142 (C:0.3142, R:0.0105)
Batch 300/537: Loss=0.3086 (C:0.3086, R:0.0105)
Batch 325/537: Loss=0.3209 (C:0.3209, R:0.0105)
Batch 350/537: Loss=0.3393 (C:0.3393, R:0.0105)
Batch 375/537: Loss=0.3002 (C:0.3002, R:0.0105)
Batch 400/537: Loss=0.3139 (C:0.3139, R:0.0105)
Batch 425/537: Loss=0.3325 (C:0.3325, R:0.0105)
Batch 450/537: Loss=0.3430 (C:0.3430, R:0.0105)
Batch 475/537: Loss=0.3174 (C:0.3174, R:0.0105)
Batch 500/537: Loss=0.3140 (C:0.3140, R:0.0105)
Batch 525/537: Loss=0.3167 (C:0.3167, R:0.0105)

============================================================
Epoch 41/300 completed in 27.2s
Train: Loss=0.3201 (C:0.3201, R:0.0105) Ratio=4.54x
Val:   Loss=0.3854 (C:0.3854, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.165
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 42
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.183 ± 0.303
    Neg distances: 1.293 ± 0.551
    Separation ratio: 7.06x
    Gap: -2.214
    ✅ Excellent global separation!

Epoch 42 Training
----------------------------------------
Batch   0/537: Loss=0.3112 (C:0.3112, R:0.0105)
Batch  25/537: Loss=0.3179 (C:0.3179, R:0.0105)
Batch  50/537: Loss=0.3126 (C:0.3126, R:0.0105)
Batch  75/537: Loss=0.3390 (C:0.3390, R:0.0105)
Batch 100/537: Loss=0.3137 (C:0.3137, R:0.0105)
Batch 125/537: Loss=0.3214 (C:0.3214, R:0.0105)
Batch 150/537: Loss=0.2945 (C:0.2945, R:0.0105)
Batch 175/537: Loss=0.3139 (C:0.3139, R:0.0105)
Batch 200/537: Loss=0.3265 (C:0.3265, R:0.0105)
Batch 225/537: Loss=0.3220 (C:0.3220, R:0.0105)
Batch 250/537: Loss=0.3157 (C:0.3157, R:0.0105)
Batch 275/537: Loss=0.3100 (C:0.3100, R:0.0105)
Batch 300/537: Loss=0.3019 (C:0.3019, R:0.0105)
Batch 325/537: Loss=0.3084 (C:0.3084, R:0.0105)
Batch 350/537: Loss=0.3143 (C:0.3143, R:0.0105)
Batch 375/537: Loss=0.3147 (C:0.3147, R:0.0105)
Batch 400/537: Loss=0.3236 (C:0.3236, R:0.0105)
Batch 425/537: Loss=0.3077 (C:0.3077, R:0.0105)
Batch 450/537: Loss=0.2992 (C:0.2992, R:0.0105)
Batch 475/537: Loss=0.3234 (C:0.3234, R:0.0105)
Batch 500/537: Loss=0.2992 (C:0.2992, R:0.0105)
Batch 525/537: Loss=0.2980 (C:0.2980, R:0.0105)

============================================================
Epoch 42/300 completed in 26.8s
Train: Loss=0.3145 (C:0.3145, R:0.0105) Ratio=4.52x
Val:   Loss=0.3744 (C:0.3744, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.180
✅ New best model saved (Val Loss: 0.3744)
============================================================

🌍 Updating global dataset at epoch 43
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.184 ± 0.306
    Neg distances: 1.279 ± 0.549
    Separation ratio: 6.94x
    Gap: -2.231
    ✅ Excellent global separation!

Epoch 43 Training
----------------------------------------
Batch   0/537: Loss=0.3170 (C:0.3170, R:0.0105)
Batch  25/537: Loss=0.2937 (C:0.2937, R:0.0105)
Batch  50/537: Loss=0.3171 (C:0.3171, R:0.0105)
Batch  75/537: Loss=0.3017 (C:0.3017, R:0.0105)
Batch 100/537: Loss=0.3057 (C:0.3057, R:0.0105)
Batch 125/537: Loss=0.3156 (C:0.3156, R:0.0105)
Batch 150/537: Loss=0.2795 (C:0.2795, R:0.0105)
Batch 175/537: Loss=0.3089 (C:0.3089, R:0.0105)
Batch 200/537: Loss=0.3101 (C:0.3101, R:0.0105)
Batch 225/537: Loss=0.3177 (C:0.3177, R:0.0105)
Batch 250/537: Loss=0.3201 (C:0.3201, R:0.0105)
Batch 275/537: Loss=0.3098 (C:0.3098, R:0.0106)
Batch 300/537: Loss=0.3094 (C:0.3094, R:0.0105)
Batch 325/537: Loss=0.3106 (C:0.3106, R:0.0105)
Batch 350/537: Loss=0.3167 (C:0.3167, R:0.0105)
Batch 375/537: Loss=0.3265 (C:0.3265, R:0.0105)
Batch 400/537: Loss=0.3114 (C:0.3114, R:0.0105)
Batch 425/537: Loss=0.3173 (C:0.3173, R:0.0105)
Batch 450/537: Loss=0.3297 (C:0.3297, R:0.0106)
Batch 475/537: Loss=0.3121 (C:0.3121, R:0.0105)
Batch 500/537: Loss=0.3302 (C:0.3302, R:0.0106)
Batch 525/537: Loss=0.3162 (C:0.3162, R:0.0105)

============================================================
Epoch 43/300 completed in 27.0s
Train: Loss=0.3158 (C:0.3158, R:0.0105) Ratio=4.57x
Val:   Loss=0.3766 (C:0.3766, R:0.0104) Ratio=3.12x
Reconstruction weight: 0.195
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 44
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.178 ± 0.300
    Neg distances: 1.304 ± 0.553
    Separation ratio: 7.31x
    Gap: -2.245
    ✅ Excellent global separation!

Epoch 44 Training
----------------------------------------
Batch   0/537: Loss=0.2893 (C:0.2893, R:0.0105)
Batch  25/537: Loss=0.3245 (C:0.3245, R:0.0105)
Batch  50/537: Loss=0.3030 (C:0.3030, R:0.0105)
Batch  75/537: Loss=0.3088 (C:0.3088, R:0.0105)
Batch 100/537: Loss=0.3122 (C:0.3122, R:0.0105)
Batch 125/537: Loss=0.3080 (C:0.3080, R:0.0106)
Batch 150/537: Loss=0.3092 (C:0.3092, R:0.0105)
Batch 175/537: Loss=0.2937 (C:0.2937, R:0.0105)
Batch 200/537: Loss=0.3158 (C:0.3158, R:0.0105)
Batch 225/537: Loss=0.3243 (C:0.3243, R:0.0105)
Batch 250/537: Loss=0.2859 (C:0.2859, R:0.0105)
Batch 275/537: Loss=0.3027 (C:0.3027, R:0.0105)
Batch 300/537: Loss=0.3125 (C:0.3125, R:0.0105)
Batch 325/537: Loss=0.2901 (C:0.2901, R:0.0105)
Batch 350/537: Loss=0.3272 (C:0.3272, R:0.0105)
Batch 375/537: Loss=0.3171 (C:0.3171, R:0.0105)
Batch 400/537: Loss=0.3032 (C:0.3032, R:0.0105)
Batch 425/537: Loss=0.3090 (C:0.3090, R:0.0105)
Batch 450/537: Loss=0.3014 (C:0.3014, R:0.0105)
Batch 475/537: Loss=0.2955 (C:0.2955, R:0.0105)
Batch 500/537: Loss=0.3080 (C:0.3080, R:0.0105)
Batch 525/537: Loss=0.3013 (C:0.3013, R:0.0105)

============================================================
Epoch 44/300 completed in 27.2s
Train: Loss=0.3088 (C:0.3088, R:0.0105) Ratio=4.62x
Val:   Loss=0.3778 (C:0.3778, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.210
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 45
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.183 ± 0.313
    Neg distances: 1.286 ± 0.552
    Separation ratio: 7.03x
    Gap: -2.202
    ✅ Excellent global separation!

Epoch 45 Training
----------------------------------------
Batch   0/537: Loss=0.3036 (C:0.3036, R:0.0106)
Batch  25/537: Loss=0.3100 (C:0.3100, R:0.0106)
Batch  50/537: Loss=0.3094 (C:0.3094, R:0.0105)
Batch  75/537: Loss=0.3002 (C:0.3002, R:0.0105)
Batch 100/537: Loss=0.3300 (C:0.3300, R:0.0105)
Batch 125/537: Loss=0.3031 (C:0.3031, R:0.0105)
Batch 150/537: Loss=0.3257 (C:0.3257, R:0.0105)
Batch 175/537: Loss=0.3202 (C:0.3202, R:0.0105)
Batch 200/537: Loss=0.3169 (C:0.3169, R:0.0105)
Batch 225/537: Loss=0.3279 (C:0.3279, R:0.0105)
Batch 250/537: Loss=0.3065 (C:0.3065, R:0.0105)
Batch 275/537: Loss=0.3024 (C:0.3024, R:0.0105)
Batch 300/537: Loss=0.3024 (C:0.3024, R:0.0105)
Batch 325/537: Loss=0.3304 (C:0.3304, R:0.0105)
Batch 350/537: Loss=0.3239 (C:0.3239, R:0.0105)
Batch 375/537: Loss=0.3073 (C:0.3073, R:0.0105)
Batch 400/537: Loss=0.3221 (C:0.3221, R:0.0105)
Batch 425/537: Loss=0.3312 (C:0.3312, R:0.0105)
Batch 450/537: Loss=0.3058 (C:0.3058, R:0.0105)
Batch 475/537: Loss=0.3260 (C:0.3260, R:0.0105)
Batch 500/537: Loss=0.3128 (C:0.3128, R:0.0105)
Batch 525/537: Loss=0.3105 (C:0.3105, R:0.0106)

============================================================
Epoch 45/300 completed in 27.1s
Train: Loss=0.3129 (C:0.3129, R:0.0105) Ratio=4.59x
Val:   Loss=0.3811 (C:0.3811, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.225
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 46
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.174 ± 0.296
    Neg distances: 1.300 ± 0.551
    Separation ratio: 7.49x
    Gap: -2.235
    ✅ Excellent global separation!

Epoch 46 Training
----------------------------------------
Batch   0/537: Loss=0.2946 (C:0.2946, R:0.0105)
Batch  25/537: Loss=0.2912 (C:0.2912, R:0.0105)
Batch  50/537: Loss=0.2969 (C:0.2969, R:0.0105)
Batch  75/537: Loss=0.3231 (C:0.3231, R:0.0105)
Batch 100/537: Loss=0.3150 (C:0.3150, R:0.0105)
Batch 125/537: Loss=0.3095 (C:0.3095, R:0.0105)
Batch 150/537: Loss=0.2980 (C:0.2980, R:0.0106)
Batch 175/537: Loss=0.2944 (C:0.2944, R:0.0105)
Batch 200/537: Loss=0.2868 (C:0.2868, R:0.0105)
Batch 225/537: Loss=0.2930 (C:0.2930, R:0.0105)
Batch 250/537: Loss=0.3100 (C:0.3100, R:0.0105)
Batch 275/537: Loss=0.3050 (C:0.3050, R:0.0105)
Batch 300/537: Loss=0.3162 (C:0.3162, R:0.0105)
Batch 325/537: Loss=0.3219 (C:0.3219, R:0.0105)
Batch 350/537: Loss=0.2915 (C:0.2915, R:0.0105)
Batch 375/537: Loss=0.3048 (C:0.3048, R:0.0105)
Batch 400/537: Loss=0.3168 (C:0.3168, R:0.0105)
Batch 425/537: Loss=0.3203 (C:0.3203, R:0.0105)
Batch 450/537: Loss=0.3057 (C:0.3057, R:0.0105)
Batch 475/537: Loss=0.3342 (C:0.3342, R:0.0105)
Batch 500/537: Loss=0.3225 (C:0.3225, R:0.0105)
Batch 525/537: Loss=0.3170 (C:0.3170, R:0.0105)

============================================================
Epoch 46/300 completed in 26.6s
Train: Loss=0.3038 (C:0.3038, R:0.0105) Ratio=4.59x
Val:   Loss=0.3772 (C:0.3772, R:0.0104) Ratio=3.14x
Reconstruction weight: 0.240
No improvement for 4 epochs
============================================================

🌍 Updating global dataset at epoch 47
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.179 ± 0.308
    Neg distances: 1.299 ± 0.555
    Separation ratio: 7.27x
    Gap: -2.200
    ✅ Excellent global separation!

Epoch 47 Training
----------------------------------------
Batch   0/537: Loss=0.3018 (C:0.3018, R:0.0105)
Batch  25/537: Loss=0.3069 (C:0.3069, R:0.0105)
Batch  50/537: Loss=0.3193 (C:0.3193, R:0.0105)
Batch  75/537: Loss=0.3072 (C:0.3072, R:0.0105)
Batch 100/537: Loss=0.3239 (C:0.3239, R:0.0105)
Batch 125/537: Loss=0.3010 (C:0.3010, R:0.0105)
Batch 150/537: Loss=0.2888 (C:0.2888, R:0.0105)
Batch 175/537: Loss=0.3146 (C:0.3146, R:0.0105)
Batch 200/537: Loss=0.2978 (C:0.2978, R:0.0105)
Batch 225/537: Loss=0.3073 (C:0.3073, R:0.0105)
Batch 250/537: Loss=0.3235 (C:0.3235, R:0.0105)
Batch 275/537: Loss=0.2955 (C:0.2955, R:0.0105)
Batch 300/537: Loss=0.3096 (C:0.3096, R:0.0105)
Batch 325/537: Loss=0.2804 (C:0.2804, R:0.0105)
Batch 350/537: Loss=0.2826 (C:0.2826, R:0.0105)
Batch 375/537: Loss=0.2864 (C:0.2864, R:0.0105)
Batch 400/537: Loss=0.2952 (C:0.2952, R:0.0105)
Batch 425/537: Loss=0.3304 (C:0.3304, R:0.0105)
Batch 450/537: Loss=0.3182 (C:0.3182, R:0.0105)
Batch 475/537: Loss=0.3282 (C:0.3282, R:0.0105)
Batch 500/537: Loss=0.2984 (C:0.2984, R:0.0105)
Batch 525/537: Loss=0.2972 (C:0.2972, R:0.0105)

============================================================
Epoch 47/300 completed in 26.6s
Train: Loss=0.3061 (C:0.3061, R:0.0105) Ratio=4.66x
Val:   Loss=0.3798 (C:0.3798, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.255
No improvement for 5 epochs
============================================================

🌍 Updating global dataset at epoch 48
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.171 ± 0.292
    Neg distances: 1.302 ± 0.550
    Separation ratio: 7.61x
    Gap: -2.192
    ✅ Excellent global separation!

Epoch 48 Training
----------------------------------------
Batch   0/537: Loss=0.3152 (C:0.3152, R:0.0104)
Batch  25/537: Loss=0.2984 (C:0.2984, R:0.0105)
Batch  50/537: Loss=0.2929 (C:0.2929, R:0.0105)
Batch  75/537: Loss=0.3002 (C:0.3002, R:0.0105)
Batch 100/537: Loss=0.2993 (C:0.2993, R:0.0105)
Batch 125/537: Loss=0.3042 (C:0.3042, R:0.0105)
Batch 150/537: Loss=0.2990 (C:0.2990, R:0.0105)
Batch 175/537: Loss=0.2884 (C:0.2884, R:0.0105)
Batch 200/537: Loss=0.2901 (C:0.2901, R:0.0105)
Batch 225/537: Loss=0.3003 (C:0.3003, R:0.0105)
Batch 250/537: Loss=0.3140 (C:0.3140, R:0.0105)
Batch 275/537: Loss=0.3038 (C:0.3038, R:0.0105)
Batch 300/537: Loss=0.2784 (C:0.2784, R:0.0105)
Batch 325/537: Loss=0.3094 (C:0.3094, R:0.0105)
Batch 350/537: Loss=0.3175 (C:0.3175, R:0.0105)
Batch 375/537: Loss=0.3006 (C:0.3006, R:0.0105)
Batch 400/537: Loss=0.3002 (C:0.3002, R:0.0105)
Batch 425/537: Loss=0.3083 (C:0.3083, R:0.0105)
Batch 450/537: Loss=0.2924 (C:0.2924, R:0.0105)
Batch 475/537: Loss=0.2869 (C:0.2869, R:0.0105)
Batch 500/537: Loss=0.2937 (C:0.2937, R:0.0106)
Batch 525/537: Loss=0.3026 (C:0.3026, R:0.0105)

============================================================
Epoch 48/300 completed in 26.5s
Train: Loss=0.3005 (C:0.3005, R:0.0105) Ratio=4.70x
Val:   Loss=0.3663 (C:0.3663, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.270
✅ New best model saved (Val Loss: 0.3663)
============================================================

🌍 Updating global dataset at epoch 49
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.168 ± 0.292
    Neg distances: 1.292 ± 0.545
    Separation ratio: 7.67x
    Gap: -2.207
    ✅ Excellent global separation!

Epoch 49 Training
----------------------------------------
Batch   0/537: Loss=0.2853 (C:0.2853, R:0.0105)
Batch  25/537: Loss=0.2893 (C:0.2893, R:0.0105)
Batch  50/537: Loss=0.3035 (C:0.3035, R:0.0105)
Batch  75/537: Loss=0.3048 (C:0.3048, R:0.0105)
Batch 100/537: Loss=0.3025 (C:0.3025, R:0.0105)
Batch 125/537: Loss=0.2744 (C:0.2744, R:0.0105)
Batch 150/537: Loss=0.3020 (C:0.3020, R:0.0105)
Batch 175/537: Loss=0.2913 (C:0.2913, R:0.0105)
Batch 200/537: Loss=0.3032 (C:0.3032, R:0.0105)
Batch 225/537: Loss=0.2988 (C:0.2988, R:0.0105)
Batch 250/537: Loss=0.2988 (C:0.2988, R:0.0105)
Batch 275/537: Loss=0.3142 (C:0.3142, R:0.0105)
Batch 300/537: Loss=0.2923 (C:0.2923, R:0.0105)
Batch 325/537: Loss=0.3012 (C:0.3012, R:0.0105)
Batch 350/537: Loss=0.2829 (C:0.2829, R:0.0106)
Batch 375/537: Loss=0.3008 (C:0.3008, R:0.0105)
Batch 400/537: Loss=0.2952 (C:0.2952, R:0.0105)
Batch 425/537: Loss=0.3036 (C:0.3036, R:0.0105)
Batch 450/537: Loss=0.2882 (C:0.2882, R:0.0105)
Batch 475/537: Loss=0.3084 (C:0.3084, R:0.0105)
Batch 500/537: Loss=0.2919 (C:0.2919, R:0.0105)
Batch 525/537: Loss=0.2999 (C:0.2999, R:0.0105)

============================================================
Epoch 49/300 completed in 26.6s
Train: Loss=0.2975 (C:0.2975, R:0.0105) Ratio=4.69x
Val:   Loss=0.3683 (C:0.3683, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.285
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 50
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.168 ± 0.295
    Neg distances: 1.309 ± 0.552
    Separation ratio: 7.79x
    Gap: -2.236
    ✅ Excellent global separation!

Epoch 50 Training
----------------------------------------
Batch   0/537: Loss=0.2972 (C:0.2972, R:0.0105)
Batch  25/537: Loss=0.2872 (C:0.2872, R:0.0105)
Batch  50/537: Loss=0.2956 (C:0.2956, R:0.0105)
Batch  75/537: Loss=0.2998 (C:0.2998, R:0.0105)
Batch 100/537: Loss=0.2889 (C:0.2889, R:0.0105)
Batch 125/537: Loss=0.2791 (C:0.2791, R:0.0105)
Batch 150/537: Loss=0.2973 (C:0.2973, R:0.0105)
Batch 175/537: Loss=0.2943 (C:0.2943, R:0.0105)
Batch 200/537: Loss=0.3053 (C:0.3053, R:0.0105)
Batch 225/537: Loss=0.2883 (C:0.2883, R:0.0105)
Batch 250/537: Loss=0.2837 (C:0.2837, R:0.0105)
Batch 275/537: Loss=0.2893 (C:0.2893, R:0.0105)
Batch 300/537: Loss=0.3024 (C:0.3024, R:0.0104)
Batch 325/537: Loss=0.2971 (C:0.2971, R:0.0105)
Batch 350/537: Loss=0.3093 (C:0.3093, R:0.0105)
Batch 375/537: Loss=0.2831 (C:0.2831, R:0.0105)
Batch 400/537: Loss=0.3107 (C:0.3107, R:0.0105)
Batch 425/537: Loss=0.3010 (C:0.3010, R:0.0105)
Batch 450/537: Loss=0.3018 (C:0.3018, R:0.0105)
Batch 475/537: Loss=0.2906 (C:0.2906, R:0.0105)
Batch 500/537: Loss=0.3027 (C:0.3027, R:0.0105)
Batch 525/537: Loss=0.2983 (C:0.2983, R:0.0105)

============================================================
Epoch 50/300 completed in 26.6s
Train: Loss=0.2954 (C:0.2954, R:0.0105) Ratio=4.78x
Val:   Loss=0.3665 (C:0.3665, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 51
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.170 ± 0.300
    Neg distances: 1.305 ± 0.550
    Separation ratio: 7.68x
    Gap: -2.283
    ✅ Excellent global separation!

Epoch 51 Training
----------------------------------------
Batch   0/537: Loss=0.3013 (C:0.3013, R:0.0105)
Batch  25/537: Loss=0.2788 (C:0.2788, R:0.0105)
Batch  50/537: Loss=0.2879 (C:0.2879, R:0.0105)
Batch  75/537: Loss=0.2934 (C:0.2934, R:0.0105)
Batch 100/537: Loss=0.2914 (C:0.2914, R:0.0105)
Batch 125/537: Loss=0.2922 (C:0.2922, R:0.0105)
Batch 150/537: Loss=0.2917 (C:0.2917, R:0.0105)
Batch 175/537: Loss=0.2948 (C:0.2948, R:0.0105)
Batch 200/537: Loss=0.3122 (C:0.3122, R:0.0105)
Batch 225/537: Loss=0.2908 (C:0.2908, R:0.0105)
Batch 250/537: Loss=0.2720 (C:0.2720, R:0.0105)
Batch 275/537: Loss=0.3099 (C:0.3099, R:0.0105)
Batch 300/537: Loss=0.3029 (C:0.3029, R:0.0105)
Batch 325/537: Loss=0.2947 (C:0.2947, R:0.0105)
Batch 350/537: Loss=0.3049 (C:0.3049, R:0.0105)
Batch 375/537: Loss=0.3061 (C:0.3061, R:0.0105)
Batch 400/537: Loss=0.2963 (C:0.2963, R:0.0105)
Batch 425/537: Loss=0.3045 (C:0.3045, R:0.0105)
Batch 450/537: Loss=0.3135 (C:0.3135, R:0.0105)
Batch 475/537: Loss=0.3165 (C:0.3165, R:0.0105)
Batch 500/537: Loss=0.2905 (C:0.2905, R:0.0105)
Batch 525/537: Loss=0.3139 (C:0.3139, R:0.0105)

============================================================
Epoch 51/300 completed in 26.6s
Train: Loss=0.2962 (C:0.2962, R:0.0105) Ratio=4.77x
Val:   Loss=0.3686 (C:0.3686, R:0.0104) Ratio=3.12x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 52
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.162 ± 0.284
    Neg distances: 1.305 ± 0.547
    Separation ratio: 8.04x
    Gap: -2.260
    ✅ Excellent global separation!

Epoch 52 Training
----------------------------------------
Batch   0/537: Loss=0.2925 (C:0.2925, R:0.0105)
Batch  25/537: Loss=0.2936 (C:0.2936, R:0.0105)
Batch  50/537: Loss=0.2888 (C:0.2888, R:0.0105)
Batch  75/537: Loss=0.2975 (C:0.2975, R:0.0105)
Batch 100/537: Loss=0.2796 (C:0.2796, R:0.0105)
Batch 125/537: Loss=0.2827 (C:0.2827, R:0.0105)
Batch 150/537: Loss=0.2960 (C:0.2960, R:0.0105)
Batch 175/537: Loss=0.2813 (C:0.2813, R:0.0105)
Batch 200/537: Loss=0.2945 (C:0.2945, R:0.0105)
Batch 225/537: Loss=0.2887 (C:0.2887, R:0.0105)
Batch 250/537: Loss=0.2713 (C:0.2713, R:0.0105)
Batch 275/537: Loss=0.2772 (C:0.2772, R:0.0105)
Batch 300/537: Loss=0.2931 (C:0.2931, R:0.0105)
Batch 325/537: Loss=0.2804 (C:0.2804, R:0.0105)
Batch 350/537: Loss=0.2935 (C:0.2935, R:0.0105)
Batch 375/537: Loss=0.2919 (C:0.2919, R:0.0105)
Batch 400/537: Loss=0.2727 (C:0.2727, R:0.0105)
Batch 425/537: Loss=0.3080 (C:0.3080, R:0.0105)
Batch 450/537: Loss=0.2839 (C:0.2839, R:0.0105)
Batch 475/537: Loss=0.2847 (C:0.2847, R:0.0105)
Batch 500/537: Loss=0.2847 (C:0.2847, R:0.0105)
Batch 525/537: Loss=0.3128 (C:0.3128, R:0.0105)

============================================================
Epoch 52/300 completed in 26.5s
Train: Loss=0.2890 (C:0.2890, R:0.0105) Ratio=4.87x
Val:   Loss=0.3629 (C:0.3629, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.3629)
============================================================

🌍 Updating global dataset at epoch 53
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.167 ± 0.295
    Neg distances: 1.313 ± 0.548
    Separation ratio: 7.89x
    Gap: -2.248
    ✅ Excellent global separation!

Epoch 53 Training
----------------------------------------
Batch   0/537: Loss=0.2902 (C:0.2902, R:0.0105)
Batch  25/537: Loss=0.2973 (C:0.2973, R:0.0105)
Batch  50/537: Loss=0.2944 (C:0.2944, R:0.0105)
Batch  75/537: Loss=0.2865 (C:0.2865, R:0.0105)
Batch 100/537: Loss=0.2891 (C:0.2891, R:0.0105)
Batch 125/537: Loss=0.3027 (C:0.3027, R:0.0105)
Batch 150/537: Loss=0.2861 (C:0.2861, R:0.0105)
Batch 175/537: Loss=0.3063 (C:0.3063, R:0.0105)
Batch 200/537: Loss=0.2670 (C:0.2670, R:0.0105)
Batch 225/537: Loss=0.2985 (C:0.2985, R:0.0105)
Batch 250/537: Loss=0.2876 (C:0.2876, R:0.0105)
Batch 275/537: Loss=0.2959 (C:0.2959, R:0.0105)
Batch 300/537: Loss=0.2953 (C:0.2953, R:0.0105)
Batch 325/537: Loss=0.2965 (C:0.2965, R:0.0105)
Batch 350/537: Loss=0.2891 (C:0.2891, R:0.0105)
Batch 375/537: Loss=0.2846 (C:0.2846, R:0.0105)
Batch 400/537: Loss=0.2884 (C:0.2884, R:0.0105)
Batch 425/537: Loss=0.2869 (C:0.2869, R:0.0105)
Batch 450/537: Loss=0.3021 (C:0.3021, R:0.0105)
Batch 475/537: Loss=0.2846 (C:0.2846, R:0.0105)
Batch 500/537: Loss=0.2882 (C:0.2882, R:0.0105)
Batch 525/537: Loss=0.3340 (C:0.3340, R:0.0105)

============================================================
Epoch 53/300 completed in 27.1s
Train: Loss=0.2904 (C:0.2904, R:0.0105) Ratio=4.77x
Val:   Loss=0.3687 (C:0.3687, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 54
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.161 ± 0.290
    Neg distances: 1.310 ± 0.547
    Separation ratio: 8.14x
    Gap: -2.231
    ✅ Excellent global separation!

Epoch 54 Training
----------------------------------------
Batch   0/537: Loss=0.2783 (C:0.2783, R:0.0105)
Batch  25/537: Loss=0.3004 (C:0.3004, R:0.0105)
Batch  50/537: Loss=0.2874 (C:0.2874, R:0.0106)
Batch  75/537: Loss=0.2935 (C:0.2935, R:0.0105)
Batch 100/537: Loss=0.2942 (C:0.2942, R:0.0106)
Batch 125/537: Loss=0.2774 (C:0.2774, R:0.0105)
Batch 150/537: Loss=0.2877 (C:0.2877, R:0.0105)
Batch 175/537: Loss=0.2785 (C:0.2785, R:0.0105)
Batch 200/537: Loss=0.2796 (C:0.2796, R:0.0105)
Batch 225/537: Loss=0.2832 (C:0.2832, R:0.0105)
Batch 250/537: Loss=0.2912 (C:0.2912, R:0.0105)
Batch 275/537: Loss=0.2895 (C:0.2895, R:0.0105)
Batch 300/537: Loss=0.2544 (C:0.2544, R:0.0105)
Batch 325/537: Loss=0.2880 (C:0.2880, R:0.0106)
Batch 350/537: Loss=0.2845 (C:0.2845, R:0.0105)
Batch 375/537: Loss=0.2765 (C:0.2765, R:0.0105)
Batch 400/537: Loss=0.2754 (C:0.2754, R:0.0105)
Batch 425/537: Loss=0.2885 (C:0.2885, R:0.0105)
Batch 450/537: Loss=0.2804 (C:0.2804, R:0.0105)
Batch 475/537: Loss=0.2764 (C:0.2764, R:0.0105)
Batch 500/537: Loss=0.2784 (C:0.2784, R:0.0105)
Batch 525/537: Loss=0.3019 (C:0.3019, R:0.0105)

============================================================
Epoch 54/300 completed in 27.3s
Train: Loss=0.2860 (C:0.2860, R:0.0105) Ratio=4.86x
Val:   Loss=0.3620 (C:0.3620, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.3620)
============================================================

🌍 Updating global dataset at epoch 55
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.164 ± 0.294
    Neg distances: 1.325 ± 0.556
    Separation ratio: 8.08x
    Gap: -2.214
    ✅ Excellent global separation!

Epoch 55 Training
----------------------------------------
Batch   0/537: Loss=0.2605 (C:0.2605, R:0.0106)
Batch  25/537: Loss=0.2753 (C:0.2753, R:0.0105)
Batch  50/537: Loss=0.2974 (C:0.2974, R:0.0105)
Batch  75/537: Loss=0.2896 (C:0.2896, R:0.0106)
Batch 100/537: Loss=0.2891 (C:0.2891, R:0.0105)
Batch 125/537: Loss=0.2899 (C:0.2899, R:0.0105)
Batch 150/537: Loss=0.2847 (C:0.2847, R:0.0105)
Batch 175/537: Loss=0.2907 (C:0.2907, R:0.0105)
Batch 200/537: Loss=0.2703 (C:0.2703, R:0.0105)
Batch 225/537: Loss=0.2785 (C:0.2785, R:0.0105)
Batch 250/537: Loss=0.2746 (C:0.2746, R:0.0105)
Batch 275/537: Loss=0.2893 (C:0.2893, R:0.0105)
Batch 300/537: Loss=0.2815 (C:0.2815, R:0.0105)
Batch 325/537: Loss=0.2847 (C:0.2847, R:0.0105)
Batch 350/537: Loss=0.2938 (C:0.2938, R:0.0105)
Batch 375/537: Loss=0.2987 (C:0.2987, R:0.0105)
Batch 400/537: Loss=0.2981 (C:0.2981, R:0.0105)
Batch 425/537: Loss=0.2922 (C:0.2922, R:0.0105)
Batch 450/537: Loss=0.2962 (C:0.2962, R:0.0105)
Batch 475/537: Loss=0.2764 (C:0.2764, R:0.0105)
Batch 500/537: Loss=0.3014 (C:0.3014, R:0.0105)
Batch 525/537: Loss=0.2837 (C:0.2837, R:0.0105)

============================================================
Epoch 55/300 completed in 26.9s
Train: Loss=0.2872 (C:0.2872, R:0.0105) Ratio=4.84x
Val:   Loss=0.3638 (C:0.3638, R:0.0104) Ratio=3.14x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 56
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.165 ± 0.296
    Neg distances: 1.319 ± 0.551
    Separation ratio: 8.00x
    Gap: -2.279
    ✅ Excellent global separation!

Epoch 56 Training
----------------------------------------
Batch   0/537: Loss=0.2820 (C:0.2820, R:0.0105)
Batch  25/537: Loss=0.2850 (C:0.2850, R:0.0105)
Batch  50/537: Loss=0.2937 (C:0.2937, R:0.0105)
Batch  75/537: Loss=0.2938 (C:0.2938, R:0.0105)
Batch 100/537: Loss=0.2905 (C:0.2905, R:0.0105)
Batch 125/537: Loss=0.2786 (C:0.2786, R:0.0105)
Batch 150/537: Loss=0.2843 (C:0.2843, R:0.0105)
Batch 175/537: Loss=0.2847 (C:0.2847, R:0.0105)
Batch 200/537: Loss=0.2976 (C:0.2976, R:0.0105)
Batch 225/537: Loss=0.2804 (C:0.2804, R:0.0105)
Batch 250/537: Loss=0.2903 (C:0.2903, R:0.0105)
Batch 275/537: Loss=0.2963 (C:0.2963, R:0.0105)
Batch 300/537: Loss=0.2866 (C:0.2866, R:0.0105)
Batch 325/537: Loss=0.2837 (C:0.2837, R:0.0105)
Batch 350/537: Loss=0.2965 (C:0.2965, R:0.0105)
Batch 375/537: Loss=0.2866 (C:0.2866, R:0.0105)
Batch 400/537: Loss=0.2946 (C:0.2946, R:0.0105)
Batch 425/537: Loss=0.3087 (C:0.3087, R:0.0105)
Batch 450/537: Loss=0.2898 (C:0.2898, R:0.0106)
Batch 475/537: Loss=0.2881 (C:0.2881, R:0.0105)
Batch 500/537: Loss=0.2840 (C:0.2840, R:0.0105)
Batch 525/537: Loss=0.3065 (C:0.3065, R:0.0105)

============================================================
Epoch 56/300 completed in 27.1s
Train: Loss=0.2872 (C:0.2872, R:0.0105) Ratio=4.83x
Val:   Loss=0.3638 (C:0.3638, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 57
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.167 ± 0.302
    Neg distances: 1.328 ± 0.559
    Separation ratio: 7.94x
    Gap: -2.243
    ✅ Excellent global separation!

Epoch 57 Training
----------------------------------------
Batch   0/537: Loss=0.2942 (C:0.2942, R:0.0105)
Batch  25/537: Loss=0.2925 (C:0.2925, R:0.0105)
Batch  50/537: Loss=0.2961 (C:0.2961, R:0.0105)
Batch  75/537: Loss=0.2896 (C:0.2896, R:0.0105)
Batch 100/537: Loss=0.2934 (C:0.2934, R:0.0105)
Batch 125/537: Loss=0.2693 (C:0.2693, R:0.0105)
Batch 150/537: Loss=0.2966 (C:0.2966, R:0.0105)
Batch 175/537: Loss=0.2893 (C:0.2893, R:0.0105)
Batch 200/537: Loss=0.3028 (C:0.3028, R:0.0105)
Batch 225/537: Loss=0.2712 (C:0.2712, R:0.0105)
Batch 250/537: Loss=0.2635 (C:0.2635, R:0.0105)
Batch 275/537: Loss=0.2956 (C:0.2956, R:0.0106)
Batch 300/537: Loss=0.2925 (C:0.2925, R:0.0105)
Batch 325/537: Loss=0.2943 (C:0.2943, R:0.0105)
Batch 350/537: Loss=0.3025 (C:0.3025, R:0.0105)
Batch 375/537: Loss=0.2868 (C:0.2868, R:0.0105)
Batch 400/537: Loss=0.3029 (C:0.3029, R:0.0105)
Batch 425/537: Loss=0.2896 (C:0.2896, R:0.0105)
Batch 450/537: Loss=0.2898 (C:0.2898, R:0.0105)
Batch 475/537: Loss=0.3121 (C:0.3121, R:0.0105)
Batch 500/537: Loss=0.2918 (C:0.2918, R:0.0105)
Batch 525/537: Loss=0.2993 (C:0.2993, R:0.0106)

============================================================
Epoch 57/300 completed in 27.1s
Train: Loss=0.2876 (C:0.2876, R:0.0105) Ratio=4.85x
Val:   Loss=0.3664 (C:0.3664, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 58
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.161 ± 0.294
    Neg distances: 1.318 ± 0.553
    Separation ratio: 8.19x
    Gap: -2.259
    ✅ Excellent global separation!

Epoch 58 Training
----------------------------------------
Batch   0/537: Loss=0.2753 (C:0.2753, R:0.0105)
Batch  25/537: Loss=0.2806 (C:0.2806, R:0.0105)
Batch  50/537: Loss=0.2656 (C:0.2656, R:0.0105)
Batch  75/537: Loss=0.2709 (C:0.2709, R:0.0105)
Batch 100/537: Loss=0.2850 (C:0.2850, R:0.0105)
Batch 125/537: Loss=0.2905 (C:0.2905, R:0.0105)
Batch 150/537: Loss=0.2643 (C:0.2643, R:0.0105)
Batch 175/537: Loss=0.2917 (C:0.2917, R:0.0105)
Batch 200/537: Loss=0.2897 (C:0.2897, R:0.0105)
Batch 225/537: Loss=0.2842 (C:0.2842, R:0.0105)
Batch 250/537: Loss=0.2860 (C:0.2860, R:0.0105)
Batch 275/537: Loss=0.2940 (C:0.2940, R:0.0105)
Batch 300/537: Loss=0.3045 (C:0.3045, R:0.0105)
Batch 325/537: Loss=0.2496 (C:0.2496, R:0.0105)
Batch 350/537: Loss=0.2853 (C:0.2853, R:0.0105)
Batch 375/537: Loss=0.2737 (C:0.2737, R:0.0105)
Batch 400/537: Loss=0.2943 (C:0.2943, R:0.0105)
Batch 425/537: Loss=0.2908 (C:0.2908, R:0.0105)
Batch 450/537: Loss=0.3061 (C:0.3061, R:0.0105)
Batch 475/537: Loss=0.2813 (C:0.2813, R:0.0105)
Batch 500/537: Loss=0.2896 (C:0.2896, R:0.0105)
Batch 525/537: Loss=0.2619 (C:0.2619, R:0.0105)

============================================================
Epoch 58/300 completed in 27.4s
Train: Loss=0.2831 (C:0.2831, R:0.0105) Ratio=4.97x
Val:   Loss=0.3680 (C:0.3680, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 4 epochs
============================================================

🌍 Updating global dataset at epoch 59
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.157 ± 0.287
    Neg distances: 1.321 ± 0.550
    Separation ratio: 8.43x
    Gap: -2.226
    ✅ Excellent global separation!

Epoch 59 Training
----------------------------------------
Batch   0/537: Loss=0.2793 (C:0.2793, R:0.0105)
Batch  25/537: Loss=0.2689 (C:0.2689, R:0.0105)
Batch  50/537: Loss=0.2766 (C:0.2766, R:0.0105)
Batch  75/537: Loss=0.2765 (C:0.2765, R:0.0105)
Batch 100/537: Loss=0.2823 (C:0.2823, R:0.0105)
Batch 125/537: Loss=0.2777 (C:0.2777, R:0.0105)
Batch 150/537: Loss=0.2788 (C:0.2788, R:0.0106)
Batch 175/537: Loss=0.2583 (C:0.2583, R:0.0105)
Batch 200/537: Loss=0.2908 (C:0.2908, R:0.0105)
Batch 225/537: Loss=0.2867 (C:0.2867, R:0.0105)
Batch 250/537: Loss=0.2932 (C:0.2932, R:0.0105)
Batch 275/537: Loss=0.2856 (C:0.2856, R:0.0105)
Batch 300/537: Loss=0.2551 (C:0.2551, R:0.0105)
Batch 325/537: Loss=0.2703 (C:0.2703, R:0.0105)
Batch 350/537: Loss=0.2652 (C:0.2652, R:0.0105)
Batch 375/537: Loss=0.2711 (C:0.2711, R:0.0105)
Batch 400/537: Loss=0.2877 (C:0.2877, R:0.0105)
Batch 425/537: Loss=0.2810 (C:0.2810, R:0.0105)
Batch 450/537: Loss=0.2691 (C:0.2691, R:0.0105)
Batch 475/537: Loss=0.2743 (C:0.2743, R:0.0105)
Batch 500/537: Loss=0.2766 (C:0.2766, R:0.0105)
Batch 525/537: Loss=0.2987 (C:0.2987, R:0.0105)

============================================================
Epoch 59/300 completed in 26.7s
Train: Loss=0.2787 (C:0.2787, R:0.0105) Ratio=4.93x
Val:   Loss=0.3574 (C:0.3574, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.3574)
============================================================

🌍 Updating global dataset at epoch 60
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.157 ± 0.284
    Neg distances: 1.339 ± 0.556
    Separation ratio: 8.53x
    Gap: -2.260
    ✅ Excellent global separation!

Epoch 60 Training
----------------------------------------
Batch   0/537: Loss=0.2702 (C:0.2702, R:0.0105)
Batch  25/537: Loss=0.2786 (C:0.2786, R:0.0105)
Batch  50/537: Loss=0.2848 (C:0.2848, R:0.0105)
Batch  75/537: Loss=0.2921 (C:0.2921, R:0.0105)
Batch 100/537: Loss=0.2767 (C:0.2767, R:0.0105)
Batch 125/537: Loss=0.2699 (C:0.2699, R:0.0105)
Batch 150/537: Loss=0.2659 (C:0.2659, R:0.0105)
Batch 175/537: Loss=0.2758 (C:0.2758, R:0.0105)
Batch 200/537: Loss=0.2786 (C:0.2786, R:0.0105)
Batch 225/537: Loss=0.2854 (C:0.2854, R:0.0105)
Batch 250/537: Loss=0.2751 (C:0.2751, R:0.0105)
Batch 275/537: Loss=0.2720 (C:0.2720, R:0.0105)
Batch 300/537: Loss=0.2643 (C:0.2643, R:0.0105)
Batch 325/537: Loss=0.2796 (C:0.2796, R:0.0105)
Batch 350/537: Loss=0.2904 (C:0.2904, R:0.0105)
Batch 375/537: Loss=0.2757 (C:0.2757, R:0.0105)
Batch 400/537: Loss=0.2770 (C:0.2770, R:0.0105)
Batch 425/537: Loss=0.2790 (C:0.2790, R:0.0106)
Batch 450/537: Loss=0.2684 (C:0.2684, R:0.0105)
Batch 475/537: Loss=0.2653 (C:0.2653, R:0.0105)
Batch 500/537: Loss=0.2712 (C:0.2712, R:0.0105)
Batch 525/537: Loss=0.2802 (C:0.2802, R:0.0105)

============================================================
Epoch 60/300 completed in 26.7s
Train: Loss=0.2768 (C:0.2768, R:0.0105) Ratio=5.00x
Val:   Loss=0.3569 (C:0.3569, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.3569)
Checkpoint saved at epoch 60
============================================================

🌍 Updating global dataset at epoch 61
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.165 ± 0.302
    Neg distances: 1.333 ± 0.559
    Separation ratio: 8.07x
    Gap: -2.268
    ✅ Excellent global separation!

Epoch 61 Training
----------------------------------------
Batch   0/537: Loss=0.2712 (C:0.2712, R:0.0105)
Batch  25/537: Loss=0.2760 (C:0.2760, R:0.0106)
Batch  50/537: Loss=0.2736 (C:0.2736, R:0.0105)
Batch  75/537: Loss=0.2703 (C:0.2703, R:0.0105)
Batch 100/537: Loss=0.2721 (C:0.2721, R:0.0105)
Batch 125/537: Loss=0.2751 (C:0.2751, R:0.0105)
Batch 150/537: Loss=0.2750 (C:0.2750, R:0.0105)
Batch 175/537: Loss=0.2828 (C:0.2828, R:0.0105)
Batch 200/537: Loss=0.2923 (C:0.2923, R:0.0106)
Batch 225/537: Loss=0.2694 (C:0.2694, R:0.0105)
Batch 250/537: Loss=0.2884 (C:0.2884, R:0.0105)
Batch 275/537: Loss=0.2823 (C:0.2823, R:0.0105)
Batch 300/537: Loss=0.2704 (C:0.2704, R:0.0105)
Batch 325/537: Loss=0.2865 (C:0.2865, R:0.0105)
Batch 350/537: Loss=0.2743 (C:0.2743, R:0.0105)
Batch 375/537: Loss=0.2858 (C:0.2858, R:0.0105)
Batch 400/537: Loss=0.2917 (C:0.2917, R:0.0105)
Batch 425/537: Loss=0.2747 (C:0.2747, R:0.0105)
Batch 450/537: Loss=0.3171 (C:0.3171, R:0.0105)
Batch 475/537: Loss=0.2866 (C:0.2866, R:0.0105)
Batch 500/537: Loss=0.2791 (C:0.2791, R:0.0105)
Batch 525/537: Loss=0.2992 (C:0.2992, R:0.0105)

============================================================
Epoch 61/300 completed in 27.2s
Train: Loss=0.2826 (C:0.2826, R:0.0105) Ratio=5.03x
Val:   Loss=0.3630 (C:0.3630, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 62
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.163 ± 0.304
    Neg distances: 1.361 ± 0.568
    Separation ratio: 8.33x
    Gap: -2.392
    ✅ Excellent global separation!

Epoch 62 Training
----------------------------------------
Batch   0/537: Loss=0.2723 (C:0.2723, R:0.0105)
Batch  25/537: Loss=0.2737 (C:0.2737, R:0.0105)
Batch  50/537: Loss=0.2688 (C:0.2688, R:0.0105)
Batch  75/537: Loss=0.2754 (C:0.2754, R:0.0106)
Batch 100/537: Loss=0.2913 (C:0.2913, R:0.0105)
Batch 125/537: Loss=0.2806 (C:0.2806, R:0.0105)
Batch 150/537: Loss=0.2678 (C:0.2678, R:0.0105)
Batch 175/537: Loss=0.2800 (C:0.2800, R:0.0105)
Batch 200/537: Loss=0.2891 (C:0.2891, R:0.0105)
Batch 225/537: Loss=0.2634 (C:0.2634, R:0.0105)
Batch 250/537: Loss=0.2883 (C:0.2883, R:0.0105)
Batch 275/537: Loss=0.2861 (C:0.2861, R:0.0105)
Batch 300/537: Loss=0.2833 (C:0.2833, R:0.0105)
Batch 325/537: Loss=0.2658 (C:0.2658, R:0.0106)
Batch 350/537: Loss=0.2870 (C:0.2870, R:0.0105)
Batch 375/537: Loss=0.2773 (C:0.2773, R:0.0105)
Batch 400/537: Loss=0.2895 (C:0.2895, R:0.0105)
Batch 425/537: Loss=0.2763 (C:0.2763, R:0.0105)
Batch 450/537: Loss=0.2679 (C:0.2679, R:0.0105)
Batch 475/537: Loss=0.2803 (C:0.2803, R:0.0105)
Batch 500/537: Loss=0.2896 (C:0.2896, R:0.0105)
Batch 525/537: Loss=0.2908 (C:0.2908, R:0.0105)

============================================================
Epoch 62/300 completed in 27.1s
Train: Loss=0.2796 (C:0.2796, R:0.0105) Ratio=5.06x
Val:   Loss=0.3595 (C:0.3595, R:0.0104) Ratio=3.12x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 63
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.154 ± 0.287
    Neg distances: 1.349 ± 0.560
    Separation ratio: 8.75x
    Gap: -2.282
    ✅ Excellent global separation!

Epoch 63 Training
----------------------------------------
Batch   0/537: Loss=0.2634 (C:0.2634, R:0.0105)
Batch  25/537: Loss=0.2491 (C:0.2491, R:0.0105)
Batch  50/537: Loss=0.2746 (C:0.2746, R:0.0105)
Batch  75/537: Loss=0.2544 (C:0.2544, R:0.0105)
Batch 100/537: Loss=0.2444 (C:0.2444, R:0.0105)
Batch 125/537: Loss=0.2669 (C:0.2669, R:0.0105)
Batch 150/537: Loss=0.2761 (C:0.2761, R:0.0105)
Batch 175/537: Loss=0.2621 (C:0.2621, R:0.0105)
Batch 200/537: Loss=0.2574 (C:0.2574, R:0.0105)
Batch 225/537: Loss=0.2643 (C:0.2643, R:0.0105)
Batch 250/537: Loss=0.2684 (C:0.2684, R:0.0105)
Batch 275/537: Loss=0.2642 (C:0.2642, R:0.0105)
Batch 300/537: Loss=0.2840 (C:0.2840, R:0.0105)
Batch 325/537: Loss=0.2633 (C:0.2633, R:0.0105)
Batch 350/537: Loss=0.2664 (C:0.2664, R:0.0105)
Batch 375/537: Loss=0.2762 (C:0.2762, R:0.0105)
Batch 400/537: Loss=0.2739 (C:0.2739, R:0.0105)
Batch 425/537: Loss=0.2860 (C:0.2860, R:0.0105)
Batch 450/537: Loss=0.2775 (C:0.2775, R:0.0105)
Batch 475/537: Loss=0.2652 (C:0.2652, R:0.0105)
Batch 500/537: Loss=0.2722 (C:0.2722, R:0.0105)
Batch 525/537: Loss=0.2899 (C:0.2899, R:0.0105)

============================================================
Epoch 63/300 completed in 26.9s
Train: Loss=0.2714 (C:0.2714, R:0.0105) Ratio=5.12x
Val:   Loss=0.3601 (C:0.3601, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 64
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.160 ± 0.295
    Neg distances: 1.347 ± 0.562
    Separation ratio: 8.41x
    Gap: -2.273
    ✅ Excellent global separation!

Epoch 64 Training
----------------------------------------
Batch   0/537: Loss=0.2551 (C:0.2551, R:0.0105)
Batch  25/537: Loss=0.2676 (C:0.2676, R:0.0106)
Batch  50/537: Loss=0.2676 (C:0.2676, R:0.0105)
Batch  75/537: Loss=0.2617 (C:0.2617, R:0.0105)
Batch 100/537: Loss=0.2614 (C:0.2614, R:0.0104)
Batch 125/537: Loss=0.2759 (C:0.2759, R:0.0105)
Batch 150/537: Loss=0.2687 (C:0.2687, R:0.0105)
Batch 175/537: Loss=0.2735 (C:0.2735, R:0.0105)
Batch 200/537: Loss=0.2732 (C:0.2732, R:0.0105)
Batch 225/537: Loss=0.2732 (C:0.2732, R:0.0105)
Batch 250/537: Loss=0.2781 (C:0.2781, R:0.0105)
Batch 275/537: Loss=0.2800 (C:0.2800, R:0.0105)
Batch 300/537: Loss=0.2695 (C:0.2695, R:0.0105)
Batch 325/537: Loss=0.2613 (C:0.2613, R:0.0105)
Batch 350/537: Loss=0.2766 (C:0.2766, R:0.0105)
Batch 375/537: Loss=0.2685 (C:0.2685, R:0.0106)
Batch 400/537: Loss=0.2697 (C:0.2697, R:0.0105)
Batch 425/537: Loss=0.2594 (C:0.2594, R:0.0105)
Batch 450/537: Loss=0.2850 (C:0.2850, R:0.0105)
Batch 475/537: Loss=0.2691 (C:0.2691, R:0.0105)
Batch 500/537: Loss=0.2734 (C:0.2734, R:0.0105)
Batch 525/537: Loss=0.2849 (C:0.2849, R:0.0105)

============================================================
Epoch 64/300 completed in 27.5s
Train: Loss=0.2758 (C:0.2758, R:0.0105) Ratio=5.23x
Val:   Loss=0.3637 (C:0.3637, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 4 epochs
============================================================

🌍 Updating global dataset at epoch 65
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.158 ± 0.294
    Neg distances: 1.338 ± 0.558
    Separation ratio: 8.47x
    Gap: -2.289
    ✅ Excellent global separation!

Epoch 65 Training
----------------------------------------
Batch   0/537: Loss=0.2656 (C:0.2656, R:0.0105)
Batch  25/537: Loss=0.2638 (C:0.2638, R:0.0105)
Batch  50/537: Loss=0.2754 (C:0.2754, R:0.0106)
Batch  75/537: Loss=0.2628 (C:0.2628, R:0.0105)
Batch 100/537: Loss=0.2860 (C:0.2860, R:0.0105)
Batch 125/537: Loss=0.2656 (C:0.2656, R:0.0105)
Batch 150/537: Loss=0.2668 (C:0.2668, R:0.0105)
Batch 175/537: Loss=0.2894 (C:0.2894, R:0.0105)
Batch 200/537: Loss=0.2549 (C:0.2549, R:0.0106)
Batch 225/537: Loss=0.2620 (C:0.2620, R:0.0105)
Batch 250/537: Loss=0.2693 (C:0.2693, R:0.0105)
Batch 275/537: Loss=0.2792 (C:0.2792, R:0.0105)
Batch 300/537: Loss=0.2548 (C:0.2548, R:0.0105)
Batch 325/537: Loss=0.2741 (C:0.2741, R:0.0105)
Batch 350/537: Loss=0.2816 (C:0.2816, R:0.0105)
Batch 375/537: Loss=0.2722 (C:0.2722, R:0.0105)
Batch 400/537: Loss=0.2699 (C:0.2699, R:0.0105)
Batch 425/537: Loss=0.2778 (C:0.2778, R:0.0105)
Batch 450/537: Loss=0.2699 (C:0.2699, R:0.0105)
Batch 475/537: Loss=0.2825 (C:0.2825, R:0.0105)
Batch 500/537: Loss=0.2859 (C:0.2859, R:0.0105)
Batch 525/537: Loss=0.2851 (C:0.2851, R:0.0105)

============================================================
Epoch 65/300 completed in 27.3s
Train: Loss=0.2739 (C:0.2739, R:0.0105) Ratio=5.10x
Val:   Loss=0.3608 (C:0.3608, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 5 epochs
============================================================

🌍 Updating global dataset at epoch 66
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.151 ± 0.288
    Neg distances: 1.351 ± 0.557
    Separation ratio: 8.93x
    Gap: -2.278
    ✅ Excellent global separation!

Epoch 66 Training
----------------------------------------
Batch   0/537: Loss=0.2556 (C:0.2556, R:0.0105)
Batch  25/537: Loss=0.2558 (C:0.2558, R:0.0105)
Batch  50/537: Loss=0.2659 (C:0.2659, R:0.0105)
Batch  75/537: Loss=0.2934 (C:0.2934, R:0.0105)
Batch 100/537: Loss=0.2506 (C:0.2506, R:0.0105)
Batch 125/537: Loss=0.2692 (C:0.2692, R:0.0105)
Batch 150/537: Loss=0.2719 (C:0.2719, R:0.0105)
Batch 175/537: Loss=0.2772 (C:0.2772, R:0.0105)
Batch 200/537: Loss=0.2537 (C:0.2537, R:0.0105)
Batch 225/537: Loss=0.2564 (C:0.2564, R:0.0105)
Batch 250/537: Loss=0.2748 (C:0.2748, R:0.0105)
Batch 275/537: Loss=0.2885 (C:0.2885, R:0.0105)
Batch 300/537: Loss=0.2612 (C:0.2612, R:0.0105)
Batch 325/537: Loss=0.2828 (C:0.2828, R:0.0105)
Batch 350/537: Loss=0.2634 (C:0.2634, R:0.0105)
Batch 375/537: Loss=0.2632 (C:0.2632, R:0.0105)
Batch 400/537: Loss=0.2693 (C:0.2693, R:0.0105)
Batch 425/537: Loss=0.2611 (C:0.2611, R:0.0105)
Batch 450/537: Loss=0.2757 (C:0.2757, R:0.0105)
Batch 475/537: Loss=0.2735 (C:0.2735, R:0.0105)
Batch 500/537: Loss=0.2792 (C:0.2792, R:0.0105)
Batch 525/537: Loss=0.2787 (C:0.2787, R:0.0105)

============================================================
Epoch 66/300 completed in 26.9s
Train: Loss=0.2675 (C:0.2675, R:0.0105) Ratio=5.21x
Val:   Loss=0.3525 (C:0.3525, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.3525)
============================================================

🌍 Updating global dataset at epoch 67
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.147 ± 0.290
    Neg distances: 1.356 ± 0.558
    Separation ratio: 9.22x
    Gap: -2.268
    ✅ Excellent global separation!

Epoch 67 Training
----------------------------------------
Batch   0/537: Loss=0.2433 (C:0.2433, R:0.0105)
Batch  25/537: Loss=0.2404 (C:0.2404, R:0.0105)
Batch  50/537: Loss=0.2551 (C:0.2551, R:0.0105)
Batch  75/537: Loss=0.2594 (C:0.2594, R:0.0105)
Batch 100/537: Loss=0.2748 (C:0.2748, R:0.0105)
Batch 125/537: Loss=0.2576 (C:0.2576, R:0.0105)
Batch 150/537: Loss=0.2692 (C:0.2692, R:0.0105)
Batch 175/537: Loss=0.2426 (C:0.2426, R:0.0105)
Batch 200/537: Loss=0.2501 (C:0.2501, R:0.0106)
Batch 225/537: Loss=0.2633 (C:0.2633, R:0.0105)
Batch 250/537: Loss=0.2667 (C:0.2667, R:0.0105)
Batch 275/537: Loss=0.2692 (C:0.2692, R:0.0105)
Batch 300/537: Loss=0.2823 (C:0.2823, R:0.0105)
Batch 325/537: Loss=0.2641 (C:0.2641, R:0.0105)
Batch 350/537: Loss=0.2571 (C:0.2571, R:0.0106)
Batch 375/537: Loss=0.2608 (C:0.2608, R:0.0105)
Batch 400/537: Loss=0.2817 (C:0.2817, R:0.0105)
Batch 425/537: Loss=0.2646 (C:0.2646, R:0.0105)
Batch 450/537: Loss=0.2676 (C:0.2676, R:0.0105)
Batch 475/537: Loss=0.2564 (C:0.2564, R:0.0106)
Batch 500/537: Loss=0.2700 (C:0.2700, R:0.0105)
Batch 525/537: Loss=0.2596 (C:0.2596, R:0.0105)

============================================================
Epoch 67/300 completed in 27.6s
Train: Loss=0.2641 (C:0.2641, R:0.0105) Ratio=5.29x
Val:   Loss=0.3547 (C:0.3547, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 68
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.146 ± 0.279
    Neg distances: 1.356 ± 0.555
    Separation ratio: 9.28x
    Gap: -2.299
    ✅ Excellent global separation!

Epoch 68 Training
----------------------------------------
Batch   0/537: Loss=0.2692 (C:0.2692, R:0.0106)
Batch  25/537: Loss=0.2444 (C:0.2444, R:0.0105)
Batch  50/537: Loss=0.2688 (C:0.2688, R:0.0105)
Batch  75/537: Loss=0.2385 (C:0.2385, R:0.0105)
Batch 100/537: Loss=0.2653 (C:0.2653, R:0.0105)
Batch 125/537: Loss=0.2434 (C:0.2434, R:0.0105)
Batch 150/537: Loss=0.2579 (C:0.2579, R:0.0105)
Batch 175/537: Loss=0.2493 (C:0.2493, R:0.0105)
Batch 200/537: Loss=0.2702 (C:0.2702, R:0.0105)
Batch 225/537: Loss=0.2603 (C:0.2603, R:0.0105)
Batch 250/537: Loss=0.2546 (C:0.2546, R:0.0105)
Batch 275/537: Loss=0.2569 (C:0.2569, R:0.0105)
Batch 300/537: Loss=0.2545 (C:0.2545, R:0.0105)
Batch 325/537: Loss=0.2593 (C:0.2593, R:0.0105)
Batch 350/537: Loss=0.2609 (C:0.2609, R:0.0105)
Batch 375/537: Loss=0.2661 (C:0.2661, R:0.0105)
Batch 400/537: Loss=0.2654 (C:0.2654, R:0.0105)
Batch 425/537: Loss=0.2769 (C:0.2769, R:0.0105)
Batch 450/537: Loss=0.2587 (C:0.2587, R:0.0105)
Batch 475/537: Loss=0.2613 (C:0.2613, R:0.0105)
Batch 500/537: Loss=0.2745 (C:0.2745, R:0.0105)
Batch 525/537: Loss=0.2686 (C:0.2686, R:0.0105)

============================================================
Epoch 68/300 completed in 27.3s
Train: Loss=0.2618 (C:0.2618, R:0.0105) Ratio=5.25x
Val:   Loss=0.3481 (C:0.3481, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.3481)
============================================================

🌍 Updating global dataset at epoch 69
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.151 ± 0.292
    Neg distances: 1.356 ± 0.560
    Separation ratio: 9.01x
    Gap: -2.306
    ✅ Excellent global separation!

Epoch 69 Training
----------------------------------------
Batch   0/537: Loss=0.2455 (C:0.2455, R:0.0105)
Batch  25/537: Loss=0.2670 (C:0.2670, R:0.0105)
Batch  50/537: Loss=0.2562 (C:0.2562, R:0.0105)
Batch  75/537: Loss=0.2500 (C:0.2500, R:0.0105)
Batch 100/537: Loss=0.2718 (C:0.2718, R:0.0105)
Batch 125/537: Loss=0.2765 (C:0.2765, R:0.0105)
Batch 150/537: Loss=0.2588 (C:0.2588, R:0.0105)
Batch 175/537: Loss=0.2533 (C:0.2533, R:0.0105)
Batch 200/537: Loss=0.2579 (C:0.2579, R:0.0105)
Batch 225/537: Loss=0.2678 (C:0.2678, R:0.0105)
Batch 250/537: Loss=0.2617 (C:0.2617, R:0.0105)
Batch 275/537: Loss=0.2642 (C:0.2642, R:0.0105)
Batch 300/537: Loss=0.2638 (C:0.2638, R:0.0105)
Batch 325/537: Loss=0.2698 (C:0.2698, R:0.0105)
Batch 350/537: Loss=0.2519 (C:0.2519, R:0.0105)
Batch 375/537: Loss=0.2526 (C:0.2526, R:0.0105)
Batch 400/537: Loss=0.2558 (C:0.2558, R:0.0105)
Batch 425/537: Loss=0.2696 (C:0.2696, R:0.0105)
Batch 450/537: Loss=0.2685 (C:0.2685, R:0.0105)
Batch 475/537: Loss=0.2723 (C:0.2723, R:0.0105)
Batch 500/537: Loss=0.2642 (C:0.2642, R:0.0105)
Batch 525/537: Loss=0.2641 (C:0.2641, R:0.0105)

============================================================
Epoch 69/300 completed in 27.1s
Train: Loss=0.2648 (C:0.2648, R:0.0105) Ratio=5.18x
Val:   Loss=0.3526 (C:0.3526, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 70
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.151 ± 0.291
    Neg distances: 1.345 ± 0.557
    Separation ratio: 8.91x
    Gap: -2.372
    ✅ Excellent global separation!

Epoch 70 Training
----------------------------------------
Batch   0/537: Loss=0.2638 (C:0.2638, R:0.0105)
Batch  25/537: Loss=0.2799 (C:0.2799, R:0.0105)
Batch  50/537: Loss=0.2621 (C:0.2621, R:0.0105)
Batch  75/537: Loss=0.2731 (C:0.2731, R:0.0105)
Batch 100/537: Loss=0.2715 (C:0.2715, R:0.0105)
Batch 125/537: Loss=0.2681 (C:0.2681, R:0.0105)
Batch 150/537: Loss=0.2702 (C:0.2702, R:0.0105)
Batch 175/537: Loss=0.2671 (C:0.2671, R:0.0105)
Batch 200/537: Loss=0.2567 (C:0.2567, R:0.0105)
Batch 225/537: Loss=0.2640 (C:0.2640, R:0.0105)
Batch 250/537: Loss=0.2708 (C:0.2708, R:0.0105)
Batch 275/537: Loss=0.2691 (C:0.2691, R:0.0105)
Batch 300/537: Loss=0.2470 (C:0.2470, R:0.0105)
Batch 325/537: Loss=0.2712 (C:0.2712, R:0.0105)
Batch 350/537: Loss=0.2674 (C:0.2674, R:0.0105)
Batch 375/537: Loss=0.2635 (C:0.2635, R:0.0105)
Batch 400/537: Loss=0.2667 (C:0.2667, R:0.0105)
Batch 425/537: Loss=0.2735 (C:0.2735, R:0.0105)
Batch 450/537: Loss=0.2542 (C:0.2542, R:0.0106)
Batch 475/537: Loss=0.2616 (C:0.2616, R:0.0105)
Batch 500/537: Loss=0.2640 (C:0.2640, R:0.0105)
Batch 525/537: Loss=0.2634 (C:0.2634, R:0.0105)

============================================================
Epoch 70/300 completed in 27.3s
Train: Loss=0.2651 (C:0.2651, R:0.0105) Ratio=5.14x
Val:   Loss=0.3549 (C:0.3549, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 71
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.150 ± 0.290
    Neg distances: 1.346 ± 0.557
    Separation ratio: 8.98x
    Gap: -2.304
    ✅ Excellent global separation!

Epoch 71 Training
----------------------------------------
Batch   0/537: Loss=0.2506 (C:0.2506, R:0.0105)
Batch  25/537: Loss=0.2413 (C:0.2413, R:0.0105)
Batch  50/537: Loss=0.2679 (C:0.2679, R:0.0105)
Batch  75/537: Loss=0.2419 (C:0.2419, R:0.0105)
Batch 100/537: Loss=0.2654 (C:0.2654, R:0.0105)
Batch 125/537: Loss=0.2495 (C:0.2495, R:0.0105)
Batch 150/537: Loss=0.2625 (C:0.2625, R:0.0105)
Batch 175/537: Loss=0.2568 (C:0.2568, R:0.0105)
Batch 200/537: Loss=0.2688 (C:0.2688, R:0.0105)
Batch 225/537: Loss=0.2571 (C:0.2571, R:0.0105)
Batch 250/537: Loss=0.2637 (C:0.2637, R:0.0105)
Batch 275/537: Loss=0.2712 (C:0.2712, R:0.0105)
Batch 300/537: Loss=0.2785 (C:0.2785, R:0.0105)
Batch 325/537: Loss=0.2728 (C:0.2728, R:0.0105)
Batch 350/537: Loss=0.2692 (C:0.2692, R:0.0105)
Batch 375/537: Loss=0.2666 (C:0.2666, R:0.0105)
Batch 400/537: Loss=0.2537 (C:0.2537, R:0.0105)
Batch 425/537: Loss=0.2757 (C:0.2757, R:0.0105)
Batch 450/537: Loss=0.2669 (C:0.2669, R:0.0105)
Batch 475/537: Loss=0.2727 (C:0.2727, R:0.0105)
Batch 500/537: Loss=0.2617 (C:0.2617, R:0.0105)
Batch 525/537: Loss=0.2657 (C:0.2657, R:0.0105)

============================================================
Epoch 71/300 completed in 27.3s
Train: Loss=0.2628 (C:0.2628, R:0.0105) Ratio=5.23x
Val:   Loss=0.3517 (C:0.3517, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 72
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.151 ± 0.286
    Neg distances: 1.348 ± 0.560
    Separation ratio: 8.95x
    Gap: -2.303
    ✅ Excellent global separation!

Epoch 72 Training
----------------------------------------
Batch   0/537: Loss=0.2523 (C:0.2523, R:0.0105)
Batch  25/537: Loss=0.2393 (C:0.2393, R:0.0105)
Batch  50/537: Loss=0.2550 (C:0.2550, R:0.0105)
Batch  75/537: Loss=0.2618 (C:0.2618, R:0.0106)
Batch 100/537: Loss=0.2458 (C:0.2458, R:0.0105)
Batch 125/537: Loss=0.2604 (C:0.2604, R:0.0105)
Batch 150/537: Loss=0.2614 (C:0.2614, R:0.0105)
Batch 175/537: Loss=0.2647 (C:0.2647, R:0.0105)
Batch 200/537: Loss=0.2835 (C:0.2835, R:0.0105)
Batch 225/537: Loss=0.2533 (C:0.2533, R:0.0105)
Batch 250/537: Loss=0.2835 (C:0.2835, R:0.0105)
Batch 275/537: Loss=0.2545 (C:0.2545, R:0.0105)
Batch 300/537: Loss=0.2307 (C:0.2307, R:0.0105)
Batch 325/537: Loss=0.2647 (C:0.2647, R:0.0105)
Batch 350/537: Loss=0.2627 (C:0.2627, R:0.0105)
Batch 375/537: Loss=0.2509 (C:0.2509, R:0.0105)
Batch 400/537: Loss=0.2629 (C:0.2629, R:0.0105)
Batch 425/537: Loss=0.2498 (C:0.2498, R:0.0105)
Batch 450/537: Loss=0.2625 (C:0.2625, R:0.0105)
Batch 475/537: Loss=0.2633 (C:0.2633, R:0.0105)
Batch 500/537: Loss=0.2570 (C:0.2570, R:0.0105)
Batch 525/537: Loss=0.2654 (C:0.2654, R:0.0105)

============================================================
Epoch 72/300 completed in 26.9s
Train: Loss=0.2641 (C:0.2641, R:0.0105) Ratio=5.41x
Val:   Loss=0.3605 (C:0.3605, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 4 epochs
============================================================

🌍 Updating global dataset at epoch 73
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.153 ± 0.295
    Neg distances: 1.358 ± 0.562
    Separation ratio: 8.87x
    Gap: -2.366
    ✅ Excellent global separation!

Epoch 73 Training
----------------------------------------
Batch   0/537: Loss=0.2457 (C:0.2457, R:0.0105)
Batch  25/537: Loss=0.2711 (C:0.2711, R:0.0105)
Batch  50/537: Loss=0.2505 (C:0.2505, R:0.0105)
Batch  75/537: Loss=0.2640 (C:0.2640, R:0.0105)
Batch 100/537: Loss=0.2603 (C:0.2603, R:0.0105)
Batch 125/537: Loss=0.2598 (C:0.2598, R:0.0105)
Batch 150/537: Loss=0.2648 (C:0.2648, R:0.0106)
Batch 175/537: Loss=0.2631 (C:0.2631, R:0.0105)
Batch 200/537: Loss=0.2785 (C:0.2785, R:0.0105)
Batch 225/537: Loss=0.2508 (C:0.2508, R:0.0105)
Batch 250/537: Loss=0.2603 (C:0.2603, R:0.0105)
Batch 275/537: Loss=0.2763 (C:0.2763, R:0.0105)
Batch 300/537: Loss=0.2722 (C:0.2722, R:0.0105)
Batch 325/537: Loss=0.2628 (C:0.2628, R:0.0105)
Batch 350/537: Loss=0.2539 (C:0.2539, R:0.0105)
Batch 375/537: Loss=0.2790 (C:0.2790, R:0.0105)
Batch 400/537: Loss=0.2809 (C:0.2809, R:0.0105)
Batch 425/537: Loss=0.2593 (C:0.2593, R:0.0105)
Batch 450/537: Loss=0.2836 (C:0.2836, R:0.0105)
Batch 475/537: Loss=0.2879 (C:0.2879, R:0.0105)
Batch 500/537: Loss=0.2648 (C:0.2648, R:0.0105)
Batch 525/537: Loss=0.2773 (C:0.2773, R:0.0105)

============================================================
Epoch 73/300 completed in 28.0s
Train: Loss=0.2637 (C:0.2637, R:0.0105) Ratio=5.28x
Val:   Loss=0.3549 (C:0.3549, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 5 epochs
============================================================

🌍 Updating global dataset at epoch 74
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.146 ± 0.287
    Neg distances: 1.363 ± 0.560
    Separation ratio: 9.33x
    Gap: -2.289
    ✅ Excellent global separation!

Epoch 74 Training
----------------------------------------
Batch   0/537: Loss=0.2576 (C:0.2576, R:0.0105)
Batch  25/537: Loss=0.2512 (C:0.2512, R:0.0105)
Batch  50/537: Loss=0.2470 (C:0.2470, R:0.0106)
Batch  75/537: Loss=0.2710 (C:0.2710, R:0.0105)
Batch 100/537: Loss=0.2571 (C:0.2571, R:0.0105)
Batch 125/537: Loss=0.2471 (C:0.2471, R:0.0105)
Batch 150/537: Loss=0.2443 (C:0.2443, R:0.0105)
Batch 175/537: Loss=0.2603 (C:0.2603, R:0.0105)
Batch 200/537: Loss=0.2601 (C:0.2601, R:0.0105)
Batch 225/537: Loss=0.2618 (C:0.2618, R:0.0105)
Batch 250/537: Loss=0.2554 (C:0.2554, R:0.0105)
Batch 275/537: Loss=0.2739 (C:0.2739, R:0.0105)
Batch 300/537: Loss=0.2558 (C:0.2558, R:0.0105)
Batch 325/537: Loss=0.2592 (C:0.2592, R:0.0105)
Batch 350/537: Loss=0.2668 (C:0.2668, R:0.0105)
Batch 375/537: Loss=0.2740 (C:0.2740, R:0.0105)
Batch 400/537: Loss=0.2503 (C:0.2503, R:0.0105)
Batch 425/537: Loss=0.2642 (C:0.2642, R:0.0105)
Batch 450/537: Loss=0.2483 (C:0.2483, R:0.0105)
Batch 475/537: Loss=0.2584 (C:0.2584, R:0.0105)
Batch 500/537: Loss=0.2610 (C:0.2610, R:0.0105)
Batch 525/537: Loss=0.2592 (C:0.2592, R:0.0105)

============================================================
Epoch 74/300 completed in 27.4s
Train: Loss=0.2583 (C:0.2583, R:0.0105) Ratio=5.30x
Val:   Loss=0.3484 (C:0.3484, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 6 epochs
============================================================

🌍 Updating global dataset at epoch 75
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.141 ± 0.274
    Neg distances: 1.374 ± 0.562
    Separation ratio: 9.72x
    Gap: -2.330
    ✅ Excellent global separation!

Epoch 75 Training
----------------------------------------
Batch   0/537: Loss=0.2462 (C:0.2462, R:0.0105)
Batch  25/537: Loss=0.2514 (C:0.2514, R:0.0105)
Batch  50/537: Loss=0.2405 (C:0.2405, R:0.0105)
Batch  75/537: Loss=0.2368 (C:0.2368, R:0.0105)
Batch 100/537: Loss=0.2599 (C:0.2599, R:0.0105)
Batch 125/537: Loss=0.2409 (C:0.2409, R:0.0105)
Batch 150/537: Loss=0.2695 (C:0.2695, R:0.0105)
Batch 175/537: Loss=0.2373 (C:0.2373, R:0.0105)
Batch 200/537: Loss=0.2620 (C:0.2620, R:0.0105)
Batch 225/537: Loss=0.2417 (C:0.2417, R:0.0105)
Batch 250/537: Loss=0.2546 (C:0.2546, R:0.0105)
Batch 275/537: Loss=0.2502 (C:0.2502, R:0.0105)
Batch 300/537: Loss=0.2629 (C:0.2629, R:0.0105)
Batch 325/537: Loss=0.2652 (C:0.2652, R:0.0105)
Batch 350/537: Loss=0.2647 (C:0.2647, R:0.0105)
Batch 375/537: Loss=0.2563 (C:0.2563, R:0.0105)
Batch 400/537: Loss=0.2446 (C:0.2446, R:0.0105)
Batch 425/537: Loss=0.2757 (C:0.2757, R:0.0105)
Batch 450/537: Loss=0.2658 (C:0.2658, R:0.0105)
Batch 475/537: Loss=0.2398 (C:0.2398, R:0.0106)
Batch 500/537: Loss=0.2554 (C:0.2554, R:0.0105)
Batch 525/537: Loss=0.2590 (C:0.2590, R:0.0105)

============================================================
Epoch 75/300 completed in 27.9s
Train: Loss=0.2540 (C:0.2540, R:0.0105) Ratio=5.32x
Val:   Loss=0.3462 (C:0.3462, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.3462)
============================================================

🌍 Updating global dataset at epoch 76
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.145 ± 0.285
    Neg distances: 1.383 ± 0.566
    Separation ratio: 9.55x
    Gap: -2.299
    ✅ Excellent global separation!

Epoch 76 Training
----------------------------------------
Batch   0/537: Loss=0.2560 (C:0.2560, R:0.0105)
Batch  25/537: Loss=0.2612 (C:0.2612, R:0.0105)
Batch  50/537: Loss=0.2752 (C:0.2752, R:0.0105)
Batch  75/537: Loss=0.2455 (C:0.2455, R:0.0105)
Batch 100/537: Loss=0.2429 (C:0.2429, R:0.0105)
Batch 125/537: Loss=0.2574 (C:0.2574, R:0.0105)
Batch 150/537: Loss=0.2603 (C:0.2603, R:0.0105)
Batch 175/537: Loss=0.2412 (C:0.2412, R:0.0105)
Batch 200/537: Loss=0.2511 (C:0.2511, R:0.0105)
Batch 225/537: Loss=0.2510 (C:0.2510, R:0.0105)
Batch 250/537: Loss=0.2615 (C:0.2615, R:0.0105)
Batch 275/537: Loss=0.2495 (C:0.2495, R:0.0105)
Batch 300/537: Loss=0.2459 (C:0.2459, R:0.0105)
Batch 325/537: Loss=0.2595 (C:0.2595, R:0.0105)
Batch 350/537: Loss=0.2513 (C:0.2513, R:0.0105)
Batch 375/537: Loss=0.2653 (C:0.2653, R:0.0105)
Batch 400/537: Loss=0.2446 (C:0.2446, R:0.0105)
Batch 425/537: Loss=0.2539 (C:0.2539, R:0.0105)
Batch 450/537: Loss=0.2480 (C:0.2480, R:0.0104)
Batch 475/537: Loss=0.2600 (C:0.2600, R:0.0105)
Batch 500/537: Loss=0.2543 (C:0.2543, R:0.0105)
Batch 525/537: Loss=0.2611 (C:0.2611, R:0.0105)

============================================================
Epoch 76/300 completed in 27.8s
Train: Loss=0.2554 (C:0.2554, R:0.0105) Ratio=5.40x
Val:   Loss=0.3460 (C:0.3460, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.3460)
============================================================

🌍 Updating global dataset at epoch 77
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.148 ± 0.288
    Neg distances: 1.376 ± 0.566
    Separation ratio: 9.33x
    Gap: -2.328
    ✅ Excellent global separation!

Epoch 77 Training
----------------------------------------
Batch   0/537: Loss=0.2765 (C:0.2765, R:0.0105)
Batch  25/537: Loss=0.2544 (C:0.2544, R:0.0105)
Batch  50/537: Loss=0.2623 (C:0.2623, R:0.0105)
Batch  75/537: Loss=0.2525 (C:0.2525, R:0.0105)
Batch 100/537: Loss=0.2452 (C:0.2452, R:0.0105)
Batch 125/537: Loss=0.2602 (C:0.2602, R:0.0105)
Batch 150/537: Loss=0.2641 (C:0.2641, R:0.0105)
Batch 175/537: Loss=0.2590 (C:0.2590, R:0.0105)
Batch 200/537: Loss=0.2529 (C:0.2529, R:0.0105)
Batch 225/537: Loss=0.2523 (C:0.2523, R:0.0105)
Batch 250/537: Loss=0.2386 (C:0.2386, R:0.0105)
Batch 275/537: Loss=0.2612 (C:0.2612, R:0.0105)
Batch 300/537: Loss=0.2435 (C:0.2435, R:0.0105)
Batch 325/537: Loss=0.2711 (C:0.2711, R:0.0105)
Batch 350/537: Loss=0.2628 (C:0.2628, R:0.0105)
Batch 375/537: Loss=0.2531 (C:0.2531, R:0.0105)
Batch 400/537: Loss=0.2547 (C:0.2547, R:0.0105)
Batch 425/537: Loss=0.2619 (C:0.2619, R:0.0105)
Batch 450/537: Loss=0.2616 (C:0.2616, R:0.0105)
Batch 475/537: Loss=0.2542 (C:0.2542, R:0.0105)
Batch 500/537: Loss=0.2494 (C:0.2494, R:0.0105)
Batch 525/537: Loss=0.2401 (C:0.2401, R:0.0105)

============================================================
Epoch 77/300 completed in 27.3s
Train: Loss=0.2578 (C:0.2578, R:0.0105) Ratio=5.42x
Val:   Loss=0.3550 (C:0.3550, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 78
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.139 ± 0.278
    Neg distances: 1.364 ± 0.558
    Separation ratio: 9.81x
    Gap: -2.264
    ✅ Excellent global separation!

Epoch 78 Training
----------------------------------------
Batch   0/537: Loss=0.2455 (C:0.2455, R:0.0105)
Batch  25/537: Loss=0.2484 (C:0.2484, R:0.0105)
Batch  50/537: Loss=0.2649 (C:0.2649, R:0.0105)
Batch  75/537: Loss=0.2524 (C:0.2524, R:0.0105)
Batch 100/537: Loss=0.2517 (C:0.2517, R:0.0106)
Batch 125/537: Loss=0.2576 (C:0.2576, R:0.0105)
Batch 150/537: Loss=0.2453 (C:0.2453, R:0.0105)
Batch 175/537: Loss=0.2397 (C:0.2397, R:0.0105)
Batch 200/537: Loss=0.2411 (C:0.2411, R:0.0105)
Batch 225/537: Loss=0.2457 (C:0.2457, R:0.0105)
Batch 250/537: Loss=0.2574 (C:0.2574, R:0.0105)
Batch 275/537: Loss=0.2464 (C:0.2464, R:0.0105)
Batch 300/537: Loss=0.2775 (C:0.2775, R:0.0105)
Batch 325/537: Loss=0.2664 (C:0.2664, R:0.0105)
Batch 350/537: Loss=0.2798 (C:0.2798, R:0.0105)
Batch 375/537: Loss=0.2385 (C:0.2385, R:0.0106)
Batch 400/537: Loss=0.2597 (C:0.2597, R:0.0105)
Batch 425/537: Loss=0.2441 (C:0.2441, R:0.0105)
Batch 450/537: Loss=0.2283 (C:0.2283, R:0.0105)
Batch 475/537: Loss=0.2540 (C:0.2540, R:0.0105)
Batch 500/537: Loss=0.2506 (C:0.2506, R:0.0105)
Batch 525/537: Loss=0.2333 (C:0.2333, R:0.0106)

============================================================
Epoch 78/300 completed in 27.3s
Train: Loss=0.2512 (C:0.2512, R:0.0105) Ratio=5.40x
Val:   Loss=0.3470 (C:0.3470, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 79
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.130 ± 0.265
    Neg distances: 1.364 ± 0.550
    Separation ratio: 10.47x
    Gap: -2.307
    ✅ Excellent global separation!

Epoch 79 Training
----------------------------------------
Batch   0/537: Loss=0.2409 (C:0.2409, R:0.0105)
Batch  25/537: Loss=0.2378 (C:0.2378, R:0.0106)
Batch  50/537: Loss=0.2455 (C:0.2455, R:0.0105)
Batch  75/537: Loss=0.2528 (C:0.2528, R:0.0105)
Batch 100/537: Loss=0.2432 (C:0.2432, R:0.0105)
Batch 125/537: Loss=0.2535 (C:0.2535, R:0.0105)
Batch 150/537: Loss=0.2473 (C:0.2473, R:0.0105)
Batch 175/537: Loss=0.2567 (C:0.2567, R:0.0105)
Batch 200/537: Loss=0.2473 (C:0.2473, R:0.0105)
Batch 225/537: Loss=0.2472 (C:0.2472, R:0.0105)
Batch 250/537: Loss=0.2500 (C:0.2500, R:0.0105)
Batch 275/537: Loss=0.2506 (C:0.2506, R:0.0105)
Batch 300/537: Loss=0.2262 (C:0.2262, R:0.0105)
Batch 325/537: Loss=0.2489 (C:0.2489, R:0.0105)
Batch 350/537: Loss=0.2461 (C:0.2461, R:0.0105)
Batch 375/537: Loss=0.2397 (C:0.2397, R:0.0105)
Batch 400/537: Loss=0.2375 (C:0.2375, R:0.0105)
Batch 425/537: Loss=0.2452 (C:0.2452, R:0.0105)
Batch 450/537: Loss=0.2626 (C:0.2626, R:0.0105)
Batch 475/537: Loss=0.2386 (C:0.2386, R:0.0105)
Batch 500/537: Loss=0.2441 (C:0.2441, R:0.0106)
Batch 525/537: Loss=0.2576 (C:0.2576, R:0.0105)

============================================================
Epoch 79/300 completed in 26.8s
Train: Loss=0.2434 (C:0.2434, R:0.0105) Ratio=5.34x
Val:   Loss=0.3393 (C:0.3393, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.3393)
============================================================

🌍 Updating global dataset at epoch 80
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.138 ± 0.286
    Neg distances: 1.374 ± 0.558
    Separation ratio: 9.92x
    Gap: -2.355
    ✅ Excellent global separation!

Epoch 80 Training
----------------------------------------
Batch   0/537: Loss=0.2692 (C:0.2692, R:0.0106)
Batch  25/537: Loss=0.2364 (C:0.2364, R:0.0105)
Batch  50/537: Loss=0.2467 (C:0.2467, R:0.0105)
Batch  75/537: Loss=0.2299 (C:0.2299, R:0.0105)
Batch 100/537: Loss=0.2399 (C:0.2399, R:0.0105)
Batch 125/537: Loss=0.2529 (C:0.2529, R:0.0105)
Batch 150/537: Loss=0.2414 (C:0.2414, R:0.0105)
Batch 175/537: Loss=0.2411 (C:0.2411, R:0.0105)
Batch 200/537: Loss=0.2448 (C:0.2448, R:0.0105)
Batch 225/537: Loss=0.2521 (C:0.2521, R:0.0105)
Batch 250/537: Loss=0.2618 (C:0.2618, R:0.0106)
Batch 275/537: Loss=0.2508 (C:0.2508, R:0.0105)
Batch 300/537: Loss=0.2546 (C:0.2546, R:0.0105)
Batch 325/537: Loss=0.2484 (C:0.2484, R:0.0105)
Batch 350/537: Loss=0.2488 (C:0.2488, R:0.0105)
Batch 375/537: Loss=0.2432 (C:0.2432, R:0.0105)
Batch 400/537: Loss=0.2340 (C:0.2340, R:0.0105)
Batch 425/537: Loss=0.2325 (C:0.2325, R:0.0105)
Batch 450/537: Loss=0.2452 (C:0.2452, R:0.0105)
Batch 475/537: Loss=0.2569 (C:0.2569, R:0.0105)
Batch 500/537: Loss=0.2469 (C:0.2469, R:0.0105)
Batch 525/537: Loss=0.2485 (C:0.2485, R:0.0105)

============================================================
Epoch 80/300 completed in 27.8s
Train: Loss=0.2477 (C:0.2477, R:0.0105) Ratio=5.46x
Val:   Loss=0.3467 (C:0.3467, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 1 epochs
Checkpoint saved at epoch 80
============================================================

🌍 Updating global dataset at epoch 81
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.138 ± 0.277
    Neg distances: 1.370 ± 0.558
    Separation ratio: 9.94x
    Gap: -2.307
    ✅ Excellent global separation!

Epoch 81 Training
----------------------------------------
Batch   0/537: Loss=0.2314 (C:0.2314, R:0.0105)
Batch  25/537: Loss=0.2383 (C:0.2383, R:0.0105)
Batch  50/537: Loss=0.2503 (C:0.2503, R:0.0106)
Batch  75/537: Loss=0.2461 (C:0.2461, R:0.0105)
Batch 100/537: Loss=0.2552 (C:0.2552, R:0.0105)
Batch 125/537: Loss=0.2416 (C:0.2416, R:0.0105)
Batch 150/537: Loss=0.2622 (C:0.2622, R:0.0105)
Batch 175/537: Loss=0.2650 (C:0.2650, R:0.0105)
Batch 200/537: Loss=0.2433 (C:0.2433, R:0.0105)
Batch 225/537: Loss=0.2456 (C:0.2456, R:0.0105)
Batch 250/537: Loss=0.2435 (C:0.2435, R:0.0105)
Batch 275/537: Loss=0.2618 (C:0.2618, R:0.0105)
Batch 300/537: Loss=0.2632 (C:0.2632, R:0.0105)
Batch 325/537: Loss=0.2681 (C:0.2681, R:0.0105)
Batch 350/537: Loss=0.2505 (C:0.2505, R:0.0105)
Batch 375/537: Loss=0.2464 (C:0.2464, R:0.0105)
Batch 400/537: Loss=0.2470 (C:0.2470, R:0.0105)
Batch 425/537: Loss=0.2582 (C:0.2582, R:0.0106)
Batch 450/537: Loss=0.2519 (C:0.2519, R:0.0105)
Batch 475/537: Loss=0.2619 (C:0.2619, R:0.0105)
Batch 500/537: Loss=0.2495 (C:0.2495, R:0.0105)
Batch 525/537: Loss=0.2688 (C:0.2688, R:0.0105)

============================================================
Epoch 81/300 completed in 27.1s
Train: Loss=0.2489 (C:0.2489, R:0.0105) Ratio=5.37x
Val:   Loss=0.3400 (C:0.3400, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 82
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.140 ± 0.282
    Neg distances: 1.369 ± 0.560
    Separation ratio: 9.80x
    Gap: -2.301
    ✅ Excellent global separation!

Epoch 82 Training
----------------------------------------
Batch   0/537: Loss=0.2435 (C:0.2435, R:0.0105)
Batch  25/537: Loss=0.2502 (C:0.2502, R:0.0105)
Batch  50/537: Loss=0.2550 (C:0.2550, R:0.0105)
Batch  75/537: Loss=0.2598 (C:0.2598, R:0.0105)
Batch 100/537: Loss=0.2399 (C:0.2399, R:0.0105)
Batch 125/537: Loss=0.2406 (C:0.2406, R:0.0105)
Batch 150/537: Loss=0.2463 (C:0.2463, R:0.0105)
Batch 175/537: Loss=0.2453 (C:0.2453, R:0.0105)
Batch 200/537: Loss=0.2553 (C:0.2553, R:0.0105)
Batch 225/537: Loss=0.2367 (C:0.2367, R:0.0105)
Batch 250/537: Loss=0.2284 (C:0.2284, R:0.0105)
Batch 275/537: Loss=0.2486 (C:0.2486, R:0.0105)
Batch 300/537: Loss=0.2509 (C:0.2509, R:0.0105)
Batch 325/537: Loss=0.2526 (C:0.2526, R:0.0105)
Batch 350/537: Loss=0.2484 (C:0.2484, R:0.0105)
Batch 375/537: Loss=0.2451 (C:0.2451, R:0.0105)
Batch 400/537: Loss=0.2525 (C:0.2525, R:0.0105)
Batch 425/537: Loss=0.2474 (C:0.2474, R:0.0105)
Batch 450/537: Loss=0.2506 (C:0.2506, R:0.0105)
Batch 475/537: Loss=0.2501 (C:0.2501, R:0.0105)
Batch 500/537: Loss=0.2705 (C:0.2705, R:0.0105)
Batch 525/537: Loss=0.2282 (C:0.2282, R:0.0105)

============================================================
Epoch 82/300 completed in 28.2s
Train: Loss=0.2489 (C:0.2489, R:0.0105) Ratio=5.53x
Val:   Loss=0.3446 (C:0.3446, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 83
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.138 ± 0.280
    Neg distances: 1.375 ± 0.560
    Separation ratio: 9.99x
    Gap: -2.303
    ✅ Excellent global separation!

Epoch 83 Training
----------------------------------------
Batch   0/537: Loss=0.2521 (C:0.2521, R:0.0105)
Batch  25/537: Loss=0.2491 (C:0.2491, R:0.0106)
Batch  50/537: Loss=0.2451 (C:0.2451, R:0.0105)
Batch  75/537: Loss=0.2383 (C:0.2383, R:0.0105)
Batch 100/537: Loss=0.2398 (C:0.2398, R:0.0105)
Batch 125/537: Loss=0.2206 (C:0.2206, R:0.0105)
Batch 150/537: Loss=0.2621 (C:0.2621, R:0.0105)
Batch 175/537: Loss=0.2676 (C:0.2676, R:0.0105)
Batch 200/537: Loss=0.2712 (C:0.2712, R:0.0105)
Batch 225/537: Loss=0.2538 (C:0.2538, R:0.0105)
Batch 250/537: Loss=0.2487 (C:0.2487, R:0.0105)
Batch 275/537: Loss=0.2276 (C:0.2276, R:0.0105)
Batch 300/537: Loss=0.2383 (C:0.2383, R:0.0105)
Batch 325/537: Loss=0.2431 (C:0.2431, R:0.0105)
Batch 350/537: Loss=0.2407 (C:0.2407, R:0.0105)
Batch 375/537: Loss=0.2372 (C:0.2372, R:0.0105)
Batch 400/537: Loss=0.2490 (C:0.2490, R:0.0105)
Batch 425/537: Loss=0.2438 (C:0.2438, R:0.0105)
Batch 450/537: Loss=0.2427 (C:0.2427, R:0.0105)
Batch 475/537: Loss=0.2393 (C:0.2393, R:0.0105)
Batch 500/537: Loss=0.2378 (C:0.2378, R:0.0105)
Batch 525/537: Loss=0.2450 (C:0.2450, R:0.0105)

============================================================
Epoch 83/300 completed in 27.6s
Train: Loss=0.2464 (C:0.2464, R:0.0105) Ratio=5.51x
Val:   Loss=0.3427 (C:0.3427, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.300
No improvement for 4 epochs
============================================================

🌍 Updating global dataset at epoch 84
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.137 ± 0.275
    Neg distances: 1.367 ± 0.558
    Separation ratio: 9.98x
    Gap: -2.320
    ✅ Excellent global separation!

Epoch 84 Training
----------------------------------------
Batch   0/537: Loss=0.2300 (C:0.2300, R:0.0105)
Batch  25/537: Loss=0.2414 (C:0.2414, R:0.0105)
Batch  50/537: Loss=0.2485 (C:0.2485, R:0.0105)
Batch  75/537: Loss=0.2335 (C:0.2335, R:0.0105)
Batch 100/537: Loss=0.2506 (C:0.2506, R:0.0105)
Batch 125/537: Loss=0.2439 (C:0.2439, R:0.0105)
Batch 150/537: Loss=0.2709 (C:0.2709, R:0.0105)
Batch 175/537: Loss=0.2343 (C:0.2343, R:0.0105)
Batch 200/537: Loss=0.2483 (C:0.2483, R:0.0105)
Batch 225/537: Loss=0.2285 (C:0.2285, R:0.0105)
Batch 250/537: Loss=0.2374 (C:0.2374, R:0.0105)
Batch 275/537: Loss=0.2645 (C:0.2645, R:0.0105)
Batch 300/537: Loss=0.2361 (C:0.2361, R:0.0105)
Batch 325/537: Loss=0.2318 (C:0.2318, R:0.0105)
Batch 350/537: Loss=0.2589 (C:0.2589, R:0.0105)
Batch 375/537: Loss=0.2559 (C:0.2559, R:0.0105)
Batch 400/537: Loss=0.2376 (C:0.2376, R:0.0105)
Batch 425/537: Loss=0.2398 (C:0.2398, R:0.0105)
Batch 450/537: Loss=0.2272 (C:0.2272, R:0.0105)
Batch 475/537: Loss=0.2606 (C:0.2606, R:0.0105)
Batch 500/537: Loss=0.2604 (C:0.2604, R:0.0105)
Batch 525/537: Loss=0.2449 (C:0.2449, R:0.0105)

============================================================
Epoch 84/300 completed in 27.3s
Train: Loss=0.2461 (C:0.2461, R:0.0105) Ratio=5.47x
Val:   Loss=0.3409 (C:0.3409, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
No improvement for 5 epochs
============================================================

🌍 Updating global dataset at epoch 85
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.132 ± 0.269
    Neg distances: 1.357 ± 0.551
    Separation ratio: 10.28x
    Gap: -2.299
    ✅ Excellent global separation!

Epoch 85 Training
----------------------------------------
Batch   0/537: Loss=0.2503 (C:0.2503, R:0.0105)
Batch  25/537: Loss=0.2423 (C:0.2423, R:0.0105)
Batch  50/537: Loss=0.2700 (C:0.2700, R:0.0105)
Batch  75/537: Loss=0.2287 (C:0.2287, R:0.0105)
Batch 100/537: Loss=0.2609 (C:0.2609, R:0.0105)
Batch 125/537: Loss=0.2494 (C:0.2494, R:0.0105)
Batch 150/537: Loss=0.2420 (C:0.2420, R:0.0106)
Batch 175/537: Loss=0.2386 (C:0.2386, R:0.0105)
Batch 200/537: Loss=0.2458 (C:0.2458, R:0.0105)
Batch 225/537: Loss=0.2496 (C:0.2496, R:0.0105)
Batch 250/537: Loss=0.2522 (C:0.2522, R:0.0105)
Batch 275/537: Loss=0.2210 (C:0.2210, R:0.0104)
Batch 300/537: Loss=0.2448 (C:0.2448, R:0.0105)
Batch 325/537: Loss=0.2312 (C:0.2312, R:0.0105)
Batch 350/537: Loss=0.2576 (C:0.2576, R:0.0105)
Batch 375/537: Loss=0.2515 (C:0.2515, R:0.0105)
Batch 400/537: Loss=0.2366 (C:0.2366, R:0.0105)
Batch 425/537: Loss=0.2537 (C:0.2537, R:0.0105)
Batch 450/537: Loss=0.2540 (C:0.2540, R:0.0105)
Batch 475/537: Loss=0.2631 (C:0.2631, R:0.0105)
Batch 500/537: Loss=0.2443 (C:0.2443, R:0.0105)
Batch 525/537: Loss=0.2377 (C:0.2377, R:0.0105)

============================================================
Epoch 85/300 completed in 27.6s
Train: Loss=0.2430 (C:0.2430, R:0.0105) Ratio=5.36x
Val:   Loss=0.3395 (C:0.3395, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
No improvement for 6 epochs
============================================================

🌍 Updating global dataset at epoch 86
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.133 ± 0.274
    Neg distances: 1.369 ± 0.555
    Separation ratio: 10.28x
    Gap: -2.272
    ✅ Excellent global separation!

Epoch 86 Training
----------------------------------------
Batch   0/537: Loss=0.2365 (C:0.2365, R:0.0105)
Batch  25/537: Loss=0.2379 (C:0.2379, R:0.0105)
Batch  50/537: Loss=0.2264 (C:0.2264, R:0.0105)
Batch  75/537: Loss=0.2659 (C:0.2659, R:0.0105)
Batch 100/537: Loss=0.2402 (C:0.2402, R:0.0105)
Batch 125/537: Loss=0.2529 (C:0.2529, R:0.0105)
Batch 150/537: Loss=0.2318 (C:0.2318, R:0.0105)
Batch 175/537: Loss=0.2578 (C:0.2578, R:0.0105)
Batch 200/537: Loss=0.2235 (C:0.2235, R:0.0105)
Batch 225/537: Loss=0.2536 (C:0.2536, R:0.0105)
Batch 250/537: Loss=0.2570 (C:0.2570, R:0.0105)
Batch 275/537: Loss=0.2540 (C:0.2540, R:0.0105)
Batch 300/537: Loss=0.2496 (C:0.2496, R:0.0105)
Batch 325/537: Loss=0.2659 (C:0.2659, R:0.0106)
Batch 350/537: Loss=0.2359 (C:0.2359, R:0.0105)
Batch 375/537: Loss=0.2230 (C:0.2230, R:0.0105)
Batch 400/537: Loss=0.2402 (C:0.2402, R:0.0105)
Batch 425/537: Loss=0.2463 (C:0.2463, R:0.0105)
Batch 450/537: Loss=0.2530 (C:0.2530, R:0.0105)
Batch 475/537: Loss=0.2477 (C:0.2477, R:0.0106)
Batch 500/537: Loss=0.2481 (C:0.2481, R:0.0105)
Batch 525/537: Loss=0.2462 (C:0.2462, R:0.0105)

============================================================
Epoch 86/300 completed in 26.7s
Train: Loss=0.2426 (C:0.2426, R:0.0105) Ratio=5.44x
Val:   Loss=0.3381 (C:0.3381, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.3381)
============================================================

🌍 Updating global dataset at epoch 87
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.130 ± 0.273
    Neg distances: 1.358 ± 0.551
    Separation ratio: 10.44x
    Gap: -2.275
    ✅ Excellent global separation!

Epoch 87 Training
----------------------------------------
Batch   0/537: Loss=0.2261 (C:0.2261, R:0.0105)
Batch  25/537: Loss=0.2270 (C:0.2270, R:0.0105)
Batch  50/537: Loss=0.2340 (C:0.2340, R:0.0105)
Batch  75/537: Loss=0.2381 (C:0.2381, R:0.0105)
Batch 100/537: Loss=0.2499 (C:0.2499, R:0.0105)
Batch 125/537: Loss=0.2528 (C:0.2528, R:0.0105)
Batch 150/537: Loss=0.2494 (C:0.2494, R:0.0105)
Batch 175/537: Loss=0.2372 (C:0.2372, R:0.0105)
Batch 200/537: Loss=0.2469 (C:0.2469, R:0.0105)
Batch 225/537: Loss=0.2553 (C:0.2553, R:0.0105)
Batch 250/537: Loss=0.2455 (C:0.2455, R:0.0105)
Batch 275/537: Loss=0.2378 (C:0.2378, R:0.0105)
Batch 300/537: Loss=0.2432 (C:0.2432, R:0.0105)
Batch 325/537: Loss=0.2486 (C:0.2486, R:0.0105)
Batch 350/537: Loss=0.2313 (C:0.2313, R:0.0105)
Batch 375/537: Loss=0.2435 (C:0.2435, R:0.0105)
Batch 400/537: Loss=0.2346 (C:0.2346, R:0.0105)
Batch 425/537: Loss=0.2295 (C:0.2295, R:0.0105)
Batch 450/537: Loss=0.2472 (C:0.2472, R:0.0105)
Batch 475/537: Loss=0.2519 (C:0.2519, R:0.0105)
Batch 500/537: Loss=0.2497 (C:0.2497, R:0.0105)
Batch 525/537: Loss=0.2523 (C:0.2523, R:0.0105)

============================================================
Epoch 87/300 completed in 26.7s
Train: Loss=0.2405 (C:0.2405, R:0.0105) Ratio=5.58x
Val:   Loss=0.3350 (C:0.3350, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.3350)
============================================================

🌍 Updating global dataset at epoch 88
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.126 ± 0.265
    Neg distances: 1.366 ± 0.550
    Separation ratio: 10.86x
    Gap: -2.269
    ✅ Excellent global separation!

Epoch 88 Training
----------------------------------------
Batch   0/537: Loss=0.2056 (C:0.2056, R:0.0105)
Batch  25/537: Loss=0.2279 (C:0.2279, R:0.0105)
Batch  50/537: Loss=0.2311 (C:0.2311, R:0.0105)
Batch  75/537: Loss=0.2395 (C:0.2395, R:0.0105)
Batch 100/537: Loss=0.2186 (C:0.2186, R:0.0105)
Batch 125/537: Loss=0.2136 (C:0.2136, R:0.0105)
Batch 150/537: Loss=0.2274 (C:0.2274, R:0.0105)
Batch 175/537: Loss=0.2252 (C:0.2252, R:0.0105)
Batch 200/537: Loss=0.2509 (C:0.2509, R:0.0105)
Batch 225/537: Loss=0.2414 (C:0.2414, R:0.0105)
Batch 250/537: Loss=0.2567 (C:0.2567, R:0.0105)
Batch 275/537: Loss=0.2328 (C:0.2328, R:0.0105)
Batch 300/537: Loss=0.2457 (C:0.2457, R:0.0105)
Batch 325/537: Loss=0.2436 (C:0.2436, R:0.0105)
Batch 350/537: Loss=0.2503 (C:0.2503, R:0.0105)
Batch 375/537: Loss=0.2376 (C:0.2376, R:0.0105)
Batch 400/537: Loss=0.2401 (C:0.2401, R:0.0105)
Batch 425/537: Loss=0.2278 (C:0.2278, R:0.0105)
Batch 450/537: Loss=0.2278 (C:0.2278, R:0.0105)
Batch 475/537: Loss=0.2447 (C:0.2447, R:0.0105)
Batch 500/537: Loss=0.2425 (C:0.2425, R:0.0105)
Batch 525/537: Loss=0.2345 (C:0.2345, R:0.0105)

============================================================
Epoch 88/300 completed in 26.8s
Train: Loss=0.2361 (C:0.2361, R:0.0105) Ratio=5.58x
Val:   Loss=0.3362 (C:0.3362, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 89
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.129 ± 0.267
    Neg distances: 1.357 ± 0.549
    Separation ratio: 10.52x
    Gap: -2.256
    ✅ Excellent global separation!

Epoch 89 Training
----------------------------------------
Batch   0/537: Loss=0.2334 (C:0.2334, R:0.0106)
Batch  25/537: Loss=0.2352 (C:0.2352, R:0.0105)
Batch  50/537: Loss=0.2236 (C:0.2236, R:0.0105)
Batch  75/537: Loss=0.2346 (C:0.2346, R:0.0105)
Batch 100/537: Loss=0.2368 (C:0.2368, R:0.0105)
Batch 125/537: Loss=0.2317 (C:0.2317, R:0.0105)
Batch 150/537: Loss=0.2355 (C:0.2355, R:0.0105)
Batch 175/537: Loss=0.2659 (C:0.2659, R:0.0105)
Batch 200/537: Loss=0.2409 (C:0.2409, R:0.0105)
Batch 225/537: Loss=0.2199 (C:0.2199, R:0.0106)
Batch 250/537: Loss=0.2264 (C:0.2264, R:0.0105)
Batch 275/537: Loss=0.2381 (C:0.2381, R:0.0105)
Batch 300/537: Loss=0.2365 (C:0.2365, R:0.0105)
Batch 325/537: Loss=0.2288 (C:0.2288, R:0.0105)
Batch 350/537: Loss=0.2221 (C:0.2221, R:0.0105)
Batch 375/537: Loss=0.2328 (C:0.2328, R:0.0105)
Batch 400/537: Loss=0.2384 (C:0.2384, R:0.0105)
Batch 425/537: Loss=0.2446 (C:0.2446, R:0.0105)
Batch 450/537: Loss=0.2494 (C:0.2494, R:0.0105)
Batch 475/537: Loss=0.2334 (C:0.2334, R:0.0105)
Batch 500/537: Loss=0.2299 (C:0.2299, R:0.0105)
Batch 525/537: Loss=0.2409 (C:0.2409, R:0.0105)

============================================================
Epoch 89/300 completed in 26.6s
Train: Loss=0.2388 (C:0.2388, R:0.0105) Ratio=5.73x
Val:   Loss=0.3380 (C:0.3380, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 90
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.128 ± 0.268
    Neg distances: 1.362 ± 0.549
    Separation ratio: 10.62x
    Gap: -2.276
    ✅ Excellent global separation!

Epoch 90 Training
----------------------------------------
Batch   0/537: Loss=0.2194 (C:0.2194, R:0.0105)
Batch  25/537: Loss=0.2281 (C:0.2281, R:0.0105)
Batch  50/537: Loss=0.2615 (C:0.2615, R:0.0105)
Batch  75/537: Loss=0.2344 (C:0.2344, R:0.0105)
Batch 100/537: Loss=0.2299 (C:0.2299, R:0.0105)
Batch 125/537: Loss=0.2363 (C:0.2363, R:0.0105)
Batch 150/537: Loss=0.2241 (C:0.2241, R:0.0105)
Batch 175/537: Loss=0.2362 (C:0.2362, R:0.0105)
Batch 200/537: Loss=0.2352 (C:0.2352, R:0.0105)
Batch 225/537: Loss=0.2397 (C:0.2397, R:0.0105)
Batch 250/537: Loss=0.2324 (C:0.2324, R:0.0105)
Batch 275/537: Loss=0.2276 (C:0.2276, R:0.0105)
Batch 300/537: Loss=0.2518 (C:0.2518, R:0.0105)
Batch 325/537: Loss=0.2442 (C:0.2442, R:0.0105)
Batch 350/537: Loss=0.2338 (C:0.2338, R:0.0105)
Batch 375/537: Loss=0.2601 (C:0.2601, R:0.0105)
Batch 400/537: Loss=0.2413 (C:0.2413, R:0.0105)
Batch 425/537: Loss=0.2387 (C:0.2387, R:0.0105)
Batch 450/537: Loss=0.2364 (C:0.2364, R:0.0105)
Batch 475/537: Loss=0.2287 (C:0.2287, R:0.0105)
Batch 500/537: Loss=0.2337 (C:0.2337, R:0.0105)
Batch 525/537: Loss=0.2443 (C:0.2443, R:0.0105)

============================================================
Epoch 90/300 completed in 26.8s
Train: Loss=0.2373 (C:0.2373, R:0.0105) Ratio=5.54x
Val:   Loss=0.3359 (C:0.3359, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 91
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.132 ± 0.271
    Neg distances: 1.362 ± 0.553
    Separation ratio: 10.34x
    Gap: -2.307
    ✅ Excellent global separation!

Epoch 91 Training
----------------------------------------
Batch   0/537: Loss=0.2445 (C:0.2445, R:0.0105)
Batch  25/537: Loss=0.2326 (C:0.2326, R:0.0105)
Batch  50/537: Loss=0.2389 (C:0.2389, R:0.0105)
Batch  75/537: Loss=0.2274 (C:0.2274, R:0.0105)
Batch 100/537: Loss=0.2299 (C:0.2299, R:0.0105)
Batch 125/537: Loss=0.2433 (C:0.2433, R:0.0105)
Batch 150/537: Loss=0.2254 (C:0.2254, R:0.0105)
Batch 175/537: Loss=0.2415 (C:0.2415, R:0.0105)
Batch 200/537: Loss=0.2271 (C:0.2271, R:0.0105)
Batch 225/537: Loss=0.2396 (C:0.2396, R:0.0105)
Batch 250/537: Loss=0.2436 (C:0.2436, R:0.0106)
Batch 275/537: Loss=0.2460 (C:0.2460, R:0.0105)
Batch 300/537: Loss=0.2309 (C:0.2309, R:0.0105)
Batch 325/537: Loss=0.2253 (C:0.2253, R:0.0105)
Batch 350/537: Loss=0.2526 (C:0.2526, R:0.0105)
Batch 375/537: Loss=0.2392 (C:0.2392, R:0.0105)
Batch 400/537: Loss=0.2370 (C:0.2370, R:0.0105)
Batch 425/537: Loss=0.2350 (C:0.2350, R:0.0105)
Batch 450/537: Loss=0.2470 (C:0.2470, R:0.0105)
Batch 475/537: Loss=0.2427 (C:0.2427, R:0.0105)
Batch 500/537: Loss=0.2379 (C:0.2379, R:0.0105)
Batch 525/537: Loss=0.2404 (C:0.2404, R:0.0105)

============================================================
Epoch 91/300 completed in 27.5s
Train: Loss=0.2392 (C:0.2392, R:0.0105) Ratio=5.74x
Val:   Loss=0.3427 (C:0.3427, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 4 epochs
============================================================

🌍 Updating global dataset at epoch 92
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.130 ± 0.272
    Neg distances: 1.366 ± 0.554
    Separation ratio: 10.49x
    Gap: -2.288
    ✅ Excellent global separation!

Epoch 92 Training
----------------------------------------
Batch   0/537: Loss=0.2255 (C:0.2255, R:0.0105)
Batch  25/537: Loss=0.2404 (C:0.2404, R:0.0105)
Batch  50/537: Loss=0.2326 (C:0.2326, R:0.0105)
Batch  75/537: Loss=0.2328 (C:0.2328, R:0.0105)
Batch 100/537: Loss=0.2202 (C:0.2202, R:0.0105)
Batch 125/537: Loss=0.2464 (C:0.2464, R:0.0105)
Batch 150/537: Loss=0.2370 (C:0.2370, R:0.0105)
Batch 175/537: Loss=0.2314 (C:0.2314, R:0.0105)
Batch 200/537: Loss=0.2351 (C:0.2351, R:0.0105)
Batch 225/537: Loss=0.2340 (C:0.2340, R:0.0105)
Batch 250/537: Loss=0.2290 (C:0.2290, R:0.0105)
Batch 275/537: Loss=0.2473 (C:0.2473, R:0.0105)
Batch 300/537: Loss=0.2498 (C:0.2498, R:0.0105)
Batch 325/537: Loss=0.2377 (C:0.2377, R:0.0105)
Batch 350/537: Loss=0.2373 (C:0.2373, R:0.0105)
Batch 375/537: Loss=0.2497 (C:0.2497, R:0.0105)
Batch 400/537: Loss=0.2227 (C:0.2227, R:0.0105)
Batch 425/537: Loss=0.2385 (C:0.2385, R:0.0105)
Batch 450/537: Loss=0.2331 (C:0.2331, R:0.0105)
Batch 475/537: Loss=0.2531 (C:0.2531, R:0.0105)
Batch 500/537: Loss=0.2375 (C:0.2375, R:0.0105)
Batch 525/537: Loss=0.2364 (C:0.2364, R:0.0105)

============================================================
Epoch 92/300 completed in 28.5s
Train: Loss=0.2379 (C:0.2379, R:0.0105) Ratio=5.70x
Val:   Loss=0.3404 (C:0.3404, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 5 epochs
============================================================

🌍 Updating global dataset at epoch 93
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.128 ± 0.268
    Neg distances: 1.365 ± 0.553
    Separation ratio: 10.66x
    Gap: -2.309
    ✅ Excellent global separation!

Epoch 93 Training
----------------------------------------
Batch   0/537: Loss=0.2377 (C:0.2377, R:0.0105)
Batch  25/537: Loss=0.2292 (C:0.2292, R:0.0105)
Batch  50/537: Loss=0.2301 (C:0.2301, R:0.0105)
Batch  75/537: Loss=0.2507 (C:0.2507, R:0.0105)
Batch 100/537: Loss=0.2337 (C:0.2337, R:0.0105)
Batch 125/537: Loss=0.2197 (C:0.2197, R:0.0105)
Batch 150/537: Loss=0.2213 (C:0.2213, R:0.0105)
Batch 175/537: Loss=0.2241 (C:0.2241, R:0.0105)
Batch 200/537: Loss=0.2491 (C:0.2491, R:0.0105)
Batch 225/537: Loss=0.2330 (C:0.2330, R:0.0105)
Batch 250/537: Loss=0.2366 (C:0.2366, R:0.0105)
Batch 275/537: Loss=0.2482 (C:0.2482, R:0.0105)
Batch 300/537: Loss=0.2285 (C:0.2285, R:0.0105)
Batch 325/537: Loss=0.2347 (C:0.2347, R:0.0105)
Batch 350/537: Loss=0.2452 (C:0.2452, R:0.0105)
Batch 375/537: Loss=0.2420 (C:0.2420, R:0.0105)
Batch 400/537: Loss=0.2464 (C:0.2464, R:0.0105)
Batch 425/537: Loss=0.2387 (C:0.2387, R:0.0105)
Batch 450/537: Loss=0.2429 (C:0.2429, R:0.0105)
Batch 475/537: Loss=0.2452 (C:0.2452, R:0.0105)
Batch 500/537: Loss=0.2396 (C:0.2396, R:0.0105)
Batch 525/537: Loss=0.2385 (C:0.2385, R:0.0105)

============================================================
Epoch 93/300 completed in 27.2s
Train: Loss=0.2363 (C:0.2363, R:0.0105) Ratio=5.63x
Val:   Loss=0.3365 (C:0.3365, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 6 epochs
============================================================

🌍 Updating global dataset at epoch 94
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.127 ± 0.271
    Neg distances: 1.370 ± 0.550
    Separation ratio: 10.79x
    Gap: -2.326
    ✅ Excellent global separation!

Epoch 94 Training
----------------------------------------
Batch   0/537: Loss=0.2383 (C:0.2383, R:0.0105)
Batch  25/537: Loss=0.2171 (C:0.2171, R:0.0105)
Batch  50/537: Loss=0.2241 (C:0.2241, R:0.0105)
Batch  75/537: Loss=0.2274 (C:0.2274, R:0.0105)
Batch 100/537: Loss=0.2316 (C:0.2316, R:0.0105)
Batch 125/537: Loss=0.2221 (C:0.2221, R:0.0105)
Batch 150/537: Loss=0.2300 (C:0.2300, R:0.0105)
Batch 175/537: Loss=0.2593 (C:0.2593, R:0.0105)
Batch 200/537: Loss=0.2296 (C:0.2296, R:0.0105)
Batch 225/537: Loss=0.2274 (C:0.2274, R:0.0105)
Batch 250/537: Loss=0.2287 (C:0.2287, R:0.0105)
Batch 275/537: Loss=0.2255 (C:0.2255, R:0.0105)
Batch 300/537: Loss=0.2370 (C:0.2370, R:0.0105)
Batch 325/537: Loss=0.2515 (C:0.2515, R:0.0105)
Batch 350/537: Loss=0.2290 (C:0.2290, R:0.0105)
Batch 375/537: Loss=0.2241 (C:0.2241, R:0.0105)
Batch 400/537: Loss=0.2329 (C:0.2329, R:0.0105)
Batch 425/537: Loss=0.2334 (C:0.2334, R:0.0105)
Batch 450/537: Loss=0.2324 (C:0.2324, R:0.0105)
Batch 475/537: Loss=0.2419 (C:0.2419, R:0.0105)
Batch 500/537: Loss=0.2278 (C:0.2278, R:0.0105)
Batch 525/537: Loss=0.2298 (C:0.2298, R:0.0105)

============================================================
Epoch 94/300 completed in 27.2s
Train: Loss=0.2330 (C:0.2330, R:0.0105) Ratio=5.67x
Val:   Loss=0.3384 (C:0.3384, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.300
No improvement for 7 epochs
============================================================

🌍 Updating global dataset at epoch 95
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.125 ± 0.266
    Neg distances: 1.364 ± 0.549
    Separation ratio: 10.89x
    Gap: -2.339
    ✅ Excellent global separation!

Epoch 95 Training
----------------------------------------
Batch   0/537: Loss=0.2297 (C:0.2297, R:0.0105)
Batch  25/537: Loss=0.2253 (C:0.2253, R:0.0105)
Batch  50/537: Loss=0.2061 (C:0.2061, R:0.0105)
Batch  75/537: Loss=0.2291 (C:0.2291, R:0.0105)
Batch 100/537: Loss=0.2296 (C:0.2296, R:0.0105)
Batch 125/537: Loss=0.2354 (C:0.2354, R:0.0105)
Batch 150/537: Loss=0.2263 (C:0.2263, R:0.0105)
Batch 175/537: Loss=0.2350 (C:0.2350, R:0.0105)
Batch 200/537: Loss=0.2436 (C:0.2436, R:0.0105)
Batch 225/537: Loss=0.2226 (C:0.2226, R:0.0105)
Batch 250/537: Loss=0.2213 (C:0.2213, R:0.0106)
Batch 275/537: Loss=0.2393 (C:0.2393, R:0.0105)
Batch 300/537: Loss=0.2387 (C:0.2387, R:0.0105)
Batch 325/537: Loss=0.2344 (C:0.2344, R:0.0105)
Batch 350/537: Loss=0.2483 (C:0.2483, R:0.0105)
Batch 375/537: Loss=0.2335 (C:0.2335, R:0.0105)
Batch 400/537: Loss=0.2258 (C:0.2258, R:0.0105)
Batch 425/537: Loss=0.2316 (C:0.2316, R:0.0105)
Batch 450/537: Loss=0.2281 (C:0.2281, R:0.0105)
Batch 475/537: Loss=0.2327 (C:0.2327, R:0.0105)
Batch 500/537: Loss=0.2524 (C:0.2524, R:0.0105)
Batch 525/537: Loss=0.2415 (C:0.2415, R:0.0105)

============================================================
Epoch 95/300 completed in 27.1s
Train: Loss=0.2316 (C:0.2316, R:0.0105) Ratio=5.72x
Val:   Loss=0.3344 (C:0.3344, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.3344)
============================================================

🌍 Updating global dataset at epoch 96
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.118 ± 0.255
    Neg distances: 1.376 ± 0.550
    Separation ratio: 11.62x
    Gap: -2.270
    ✅ Excellent global separation!

Epoch 96 Training
----------------------------------------
Batch   0/537: Loss=0.2183 (C:0.2183, R:0.0105)
Batch  25/537: Loss=0.2227 (C:0.2227, R:0.0105)
Batch  50/537: Loss=0.2396 (C:0.2396, R:0.0105)
Batch  75/537: Loss=0.2236 (C:0.2236, R:0.0105)
Batch 100/537: Loss=0.2397 (C:0.2397, R:0.0106)
Batch 125/537: Loss=0.2219 (C:0.2219, R:0.0105)
Batch 150/537: Loss=0.2089 (C:0.2089, R:0.0105)
Batch 175/537: Loss=0.2288 (C:0.2288, R:0.0105)
Batch 200/537: Loss=0.2264 (C:0.2264, R:0.0105)
Batch 225/537: Loss=0.2187 (C:0.2187, R:0.0105)
Batch 250/537: Loss=0.2292 (C:0.2292, R:0.0105)
Batch 275/537: Loss=0.2207 (C:0.2207, R:0.0105)
Batch 300/537: Loss=0.2151 (C:0.2151, R:0.0105)
Batch 325/537: Loss=0.2380 (C:0.2380, R:0.0105)
Batch 350/537: Loss=0.2364 (C:0.2364, R:0.0105)
Batch 375/537: Loss=0.2180 (C:0.2180, R:0.0105)
Batch 400/537: Loss=0.2266 (C:0.2266, R:0.0105)
Batch 425/537: Loss=0.2272 (C:0.2272, R:0.0105)
Batch 450/537: Loss=0.2419 (C:0.2419, R:0.0105)
Batch 475/537: Loss=0.2198 (C:0.2198, R:0.0105)
Batch 500/537: Loss=0.2432 (C:0.2432, R:0.0106)
Batch 525/537: Loss=0.2164 (C:0.2164, R:0.0106)

============================================================
Epoch 96/300 completed in 26.9s
Train: Loss=0.2273 (C:0.2273, R:0.0105) Ratio=5.76x
Val:   Loss=0.3313 (C:0.3313, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.3313)
============================================================

🌍 Updating global dataset at epoch 97
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.131 ± 0.275
    Neg distances: 1.366 ± 0.554
    Separation ratio: 10.46x
    Gap: -2.297
    ✅ Excellent global separation!

Epoch 97 Training
----------------------------------------
Batch   0/537: Loss=0.2301 (C:0.2301, R:0.0105)
Batch  25/537: Loss=0.2352 (C:0.2352, R:0.0105)
Batch  50/537: Loss=0.2359 (C:0.2359, R:0.0105)
Batch  75/537: Loss=0.2354 (C:0.2354, R:0.0105)
Batch 100/537: Loss=0.2552 (C:0.2552, R:0.0105)
Batch 125/537: Loss=0.2599 (C:0.2599, R:0.0105)
Batch 150/537: Loss=0.2356 (C:0.2356, R:0.0105)
Batch 175/537: Loss=0.2258 (C:0.2258, R:0.0105)
Batch 200/537: Loss=0.2510 (C:0.2510, R:0.0105)
Batch 225/537: Loss=0.2351 (C:0.2351, R:0.0105)
Batch 250/537: Loss=0.2474 (C:0.2474, R:0.0105)
Batch 275/537: Loss=0.2370 (C:0.2370, R:0.0105)
Batch 300/537: Loss=0.2552 (C:0.2552, R:0.0105)
Batch 325/537: Loss=0.2436 (C:0.2436, R:0.0106)
Batch 350/537: Loss=0.2065 (C:0.2065, R:0.0105)
Batch 375/537: Loss=0.2583 (C:0.2583, R:0.0105)
Batch 400/537: Loss=0.2384 (C:0.2384, R:0.0105)
Batch 425/537: Loss=0.2482 (C:0.2482, R:0.0105)
Batch 450/537: Loss=0.2340 (C:0.2340, R:0.0105)
Batch 475/537: Loss=0.2568 (C:0.2568, R:0.0105)
Batch 500/537: Loss=0.2273 (C:0.2273, R:0.0105)
Batch 525/537: Loss=0.2541 (C:0.2541, R:0.0105)

============================================================
Epoch 97/300 completed in 27.2s
Train: Loss=0.2358 (C:0.2358, R:0.0105) Ratio=5.62x
Val:   Loss=0.3361 (C:0.3361, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 98
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.125 ± 0.271
    Neg distances: 1.374 ± 0.552
    Separation ratio: 11.00x
    Gap: -2.341
    ✅ Excellent global separation!

Epoch 98 Training
----------------------------------------
Batch   0/537: Loss=0.2396 (C:0.2396, R:0.0105)
Batch  25/537: Loss=0.2394 (C:0.2394, R:0.0105)
Batch  50/537: Loss=0.2313 (C:0.2313, R:0.0105)
Batch  75/537: Loss=0.2245 (C:0.2245, R:0.0105)
Batch 100/537: Loss=0.2291 (C:0.2291, R:0.0105)
Batch 125/537: Loss=0.2359 (C:0.2359, R:0.0105)
Batch 150/537: Loss=0.2273 (C:0.2273, R:0.0105)
Batch 175/537: Loss=0.2384 (C:0.2384, R:0.0105)
Batch 200/537: Loss=0.2451 (C:0.2451, R:0.0105)
Batch 225/537: Loss=0.2514 (C:0.2514, R:0.0105)
Batch 250/537: Loss=0.2252 (C:0.2252, R:0.0105)
Batch 275/537: Loss=0.2381 (C:0.2381, R:0.0105)
Batch 300/537: Loss=0.2290 (C:0.2290, R:0.0105)
Batch 325/537: Loss=0.2213 (C:0.2213, R:0.0105)
Batch 350/537: Loss=0.2432 (C:0.2432, R:0.0106)
Batch 375/537: Loss=0.2373 (C:0.2373, R:0.0105)
Batch 400/537: Loss=0.2304 (C:0.2304, R:0.0105)
Batch 425/537: Loss=0.2409 (C:0.2409, R:0.0105)
Batch 450/537: Loss=0.2351 (C:0.2351, R:0.0106)
Batch 475/537: Loss=0.2321 (C:0.2321, R:0.0105)
Batch 500/537: Loss=0.2399 (C:0.2399, R:0.0105)
Batch 525/537: Loss=0.2528 (C:0.2528, R:0.0105)

============================================================
Epoch 98/300 completed in 26.9s
Train: Loss=0.2302 (C:0.2302, R:0.0105) Ratio=5.66x
Val:   Loss=0.3413 (C:0.3413, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 99
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.123 ± 0.267
    Neg distances: 1.390 ± 0.557
    Separation ratio: 11.31x
    Gap: -2.295
    ✅ Excellent global separation!

Epoch 99 Training
----------------------------------------
Batch   0/537: Loss=0.2251 (C:0.2251, R:0.0105)
Batch  25/537: Loss=0.2271 (C:0.2271, R:0.0105)
Batch  50/537: Loss=0.2385 (C:0.2385, R:0.0105)
Batch  75/537: Loss=0.2155 (C:0.2155, R:0.0105)
Batch 100/537: Loss=0.2316 (C:0.2316, R:0.0105)
Batch 125/537: Loss=0.2276 (C:0.2276, R:0.0105)
Batch 150/537: Loss=0.2312 (C:0.2312, R:0.0105)
Batch 175/537: Loss=0.2146 (C:0.2146, R:0.0105)
Batch 200/537: Loss=0.2396 (C:0.2396, R:0.0105)
Batch 225/537: Loss=0.2216 (C:0.2216, R:0.0105)
Batch 250/537: Loss=0.2174 (C:0.2174, R:0.0105)
Batch 275/537: Loss=0.2421 (C:0.2421, R:0.0105)
Batch 300/537: Loss=0.2254 (C:0.2254, R:0.0105)
Batch 325/537: Loss=0.2186 (C:0.2186, R:0.0105)
Batch 350/537: Loss=0.2377 (C:0.2377, R:0.0105)
Batch 375/537: Loss=0.2366 (C:0.2366, R:0.0105)
Batch 400/537: Loss=0.2258 (C:0.2258, R:0.0105)
Batch 425/537: Loss=0.2230 (C:0.2230, R:0.0105)
Batch 450/537: Loss=0.2297 (C:0.2297, R:0.0106)
Batch 475/537: Loss=0.2265 (C:0.2265, R:0.0105)
Batch 500/537: Loss=0.2407 (C:0.2407, R:0.0105)
Batch 525/537: Loss=0.2371 (C:0.2371, R:0.0104)

============================================================
Epoch 99/300 completed in 26.8s
Train: Loss=0.2276 (C:0.2276, R:0.0105) Ratio=5.71x
Val:   Loss=0.3377 (C:0.3377, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 100
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.128 ± 0.271
    Neg distances: 1.385 ± 0.559
    Separation ratio: 10.81x
    Gap: -2.287
    ✅ Excellent global separation!

Epoch 100 Training
----------------------------------------
Batch   0/537: Loss=0.2082 (C:0.2082, R:0.0105)
Batch  25/537: Loss=0.2245 (C:0.2245, R:0.0105)
Batch  50/537: Loss=0.2188 (C:0.2188, R:0.0105)
Batch  75/537: Loss=0.2369 (C:0.2369, R:0.0105)
Batch 100/537: Loss=0.2189 (C:0.2189, R:0.0105)
Batch 125/537: Loss=0.2183 (C:0.2183, R:0.0105)
Batch 150/537: Loss=0.2374 (C:0.2374, R:0.0105)
Batch 175/537: Loss=0.2313 (C:0.2313, R:0.0105)
Batch 200/537: Loss=0.2321 (C:0.2321, R:0.0105)
Batch 225/537: Loss=0.2211 (C:0.2211, R:0.0105)
Batch 250/537: Loss=0.2441 (C:0.2441, R:0.0105)
Batch 275/537: Loss=0.2448 (C:0.2448, R:0.0105)
Batch 300/537: Loss=0.2312 (C:0.2312, R:0.0105)
Batch 325/537: Loss=0.2328 (C:0.2328, R:0.0105)
Batch 350/537: Loss=0.2316 (C:0.2316, R:0.0105)
Batch 375/537: Loss=0.2337 (C:0.2337, R:0.0105)
Batch 400/537: Loss=0.2333 (C:0.2333, R:0.0105)
Batch 425/537: Loss=0.2270 (C:0.2270, R:0.0105)
Batch 450/537: Loss=0.2398 (C:0.2398, R:0.0105)
Batch 475/537: Loss=0.2531 (C:0.2531, R:0.0105)
Batch 500/537: Loss=0.2442 (C:0.2442, R:0.0105)
Batch 525/537: Loss=0.2455 (C:0.2455, R:0.0105)

============================================================
Epoch 100/300 completed in 26.8s
Train: Loss=0.2328 (C:0.2328, R:0.0105) Ratio=5.75x
Val:   Loss=0.3391 (C:0.3391, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.300
No improvement for 4 epochs
Checkpoint saved at epoch 100
============================================================

🌍 Updating global dataset at epoch 101
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.127 ± 0.268
    Neg distances: 1.379 ± 0.555
    Separation ratio: 10.89x
    Gap: -2.354
    ✅ Excellent global separation!

Epoch 101 Training
----------------------------------------
Batch   0/537: Loss=0.2226 (C:0.2226, R:0.0105)
Batch  25/537: Loss=0.2142 (C:0.2142, R:0.0105)
Batch  50/537: Loss=0.2411 (C:0.2411, R:0.0105)
Batch  75/537: Loss=0.2222 (C:0.2222, R:0.0105)
Batch 100/537: Loss=0.2320 (C:0.2320, R:0.0105)
Batch 125/537: Loss=0.2204 (C:0.2204, R:0.0105)
Batch 150/537: Loss=0.2387 (C:0.2387, R:0.0105)
Batch 175/537: Loss=0.2276 (C:0.2276, R:0.0105)
Batch 200/537: Loss=0.2211 (C:0.2211, R:0.0105)
Batch 225/537: Loss=0.2306 (C:0.2306, R:0.0105)
Batch 250/537: Loss=0.2450 (C:0.2450, R:0.0105)
Batch 275/537: Loss=0.2400 (C:0.2400, R:0.0105)
Batch 300/537: Loss=0.2369 (C:0.2369, R:0.0105)
Batch 325/537: Loss=0.2214 (C:0.2214, R:0.0105)
Batch 350/537: Loss=0.2475 (C:0.2475, R:0.0105)
Batch 375/537: Loss=0.2373 (C:0.2373, R:0.0105)
Batch 400/537: Loss=0.2329 (C:0.2329, R:0.0105)
Batch 425/537: Loss=0.2375 (C:0.2375, R:0.0105)
Batch 450/537: Loss=0.2345 (C:0.2345, R:0.0105)
Batch 475/537: Loss=0.2259 (C:0.2259, R:0.0105)
Batch 500/537: Loss=0.2220 (C:0.2220, R:0.0105)
Batch 525/537: Loss=0.2298 (C:0.2298, R:0.0106)

============================================================
Epoch 101/300 completed in 26.9s
Train: Loss=0.2312 (C:0.2312, R:0.0105) Ratio=5.84x
Val:   Loss=0.3459 (C:0.3459, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.300
No improvement for 5 epochs
============================================================

🌍 Updating global dataset at epoch 102
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.133 ± 0.276
    Neg distances: 1.391 ± 0.563
    Separation ratio: 10.50x
    Gap: -2.331
    ✅ Excellent global separation!

Epoch 102 Training
----------------------------------------
Batch   0/537: Loss=0.2484 (C:0.2484, R:0.0105)
Batch  25/537: Loss=0.2368 (C:0.2368, R:0.0105)
Batch  50/537: Loss=0.2398 (C:0.2398, R:0.0105)
Batch  75/537: Loss=0.2277 (C:0.2277, R:0.0105)
Batch 100/537: Loss=0.2223 (C:0.2223, R:0.0105)
Batch 125/537: Loss=0.2392 (C:0.2392, R:0.0105)
Batch 150/537: Loss=0.2504 (C:0.2504, R:0.0105)
Batch 175/537: Loss=0.2382 (C:0.2382, R:0.0105)
Batch 200/537: Loss=0.2423 (C:0.2423, R:0.0105)
Batch 225/537: Loss=0.2486 (C:0.2486, R:0.0105)
Batch 250/537: Loss=0.2043 (C:0.2043, R:0.0105)
Batch 275/537: Loss=0.2386 (C:0.2386, R:0.0105)
Batch 300/537: Loss=0.2303 (C:0.2303, R:0.0105)
Batch 325/537: Loss=0.2397 (C:0.2397, R:0.0105)
Batch 350/537: Loss=0.2525 (C:0.2525, R:0.0105)
Batch 375/537: Loss=0.2417 (C:0.2417, R:0.0105)
Batch 400/537: Loss=0.2381 (C:0.2381, R:0.0105)
Batch 425/537: Loss=0.2485 (C:0.2485, R:0.0105)
Batch 450/537: Loss=0.2239 (C:0.2239, R:0.0105)
Batch 475/537: Loss=0.2084 (C:0.2084, R:0.0106)
Batch 500/537: Loss=0.2374 (C:0.2374, R:0.0105)
Batch 525/537: Loss=0.2508 (C:0.2508, R:0.0105)

============================================================
Epoch 102/300 completed in 27.1s
Train: Loss=0.2354 (C:0.2354, R:0.0105) Ratio=5.75x
Val:   Loss=0.3464 (C:0.3464, R:0.0104) Ratio=3.03x
Reconstruction weight: 0.300
No improvement for 6 epochs
============================================================

🌍 Updating global dataset at epoch 103
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.121 ± 0.267
    Neg distances: 1.388 ± 0.556
    Separation ratio: 11.45x
    Gap: -2.362
    ✅ Excellent global separation!

Epoch 103 Training
----------------------------------------
Batch   0/537: Loss=0.2214 (C:0.2214, R:0.0105)
Batch  25/537: Loss=0.2469 (C:0.2469, R:0.0105)
Batch  50/537: Loss=0.2219 (C:0.2219, R:0.0105)
Batch  75/537: Loss=0.2287 (C:0.2287, R:0.0105)
Batch 100/537: Loss=0.2318 (C:0.2318, R:0.0105)
Batch 125/537: Loss=0.2191 (C:0.2191, R:0.0105)
Batch 150/537: Loss=0.2024 (C:0.2024, R:0.0105)
Batch 175/537: Loss=0.2250 (C:0.2250, R:0.0105)
Batch 200/537: Loss=0.2253 (C:0.2253, R:0.0105)
Batch 225/537: Loss=0.2314 (C:0.2314, R:0.0105)
Batch 250/537: Loss=0.2275 (C:0.2275, R:0.0105)
Batch 275/537: Loss=0.2303 (C:0.2303, R:0.0105)
Batch 300/537: Loss=0.2248 (C:0.2248, R:0.0105)
Batch 325/537: Loss=0.2359 (C:0.2359, R:0.0105)
Batch 350/537: Loss=0.2344 (C:0.2344, R:0.0105)
Batch 375/537: Loss=0.2043 (C:0.2043, R:0.0105)
Batch 400/537: Loss=0.2253 (C:0.2253, R:0.0105)
Batch 425/537: Loss=0.2287 (C:0.2287, R:0.0105)
Batch 450/537: Loss=0.2224 (C:0.2224, R:0.0105)
Batch 475/537: Loss=0.2254 (C:0.2254, R:0.0105)
Batch 500/537: Loss=0.2200 (C:0.2200, R:0.0105)
Batch 525/537: Loss=0.2308 (C:0.2308, R:0.0105)

============================================================
Epoch 103/300 completed in 27.7s
Train: Loss=0.2255 (C:0.2255, R:0.0105) Ratio=5.82x
Val:   Loss=0.3351 (C:0.3351, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
No improvement for 7 epochs
============================================================

🌍 Updating global dataset at epoch 104
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.124 ± 0.265
    Neg distances: 1.382 ± 0.556
    Separation ratio: 11.11x
    Gap: -2.309
    ✅ Excellent global separation!

Epoch 104 Training
----------------------------------------
Batch   0/537: Loss=0.2178 (C:0.2178, R:0.0105)
Batch  25/537: Loss=0.2275 (C:0.2275, R:0.0105)
Batch  50/537: Loss=0.2238 (C:0.2238, R:0.0106)
Batch  75/537: Loss=0.2313 (C:0.2313, R:0.0105)
Batch 100/537: Loss=0.2555 (C:0.2555, R:0.0105)
Batch 125/537: Loss=0.2280 (C:0.2280, R:0.0105)
Batch 150/537: Loss=0.2186 (C:0.2186, R:0.0105)
Batch 175/537: Loss=0.2347 (C:0.2347, R:0.0105)
Batch 200/537: Loss=0.2453 (C:0.2453, R:0.0105)
Batch 225/537: Loss=0.2216 (C:0.2216, R:0.0105)
Batch 250/537: Loss=0.2352 (C:0.2352, R:0.0105)
Batch 275/537: Loss=0.2245 (C:0.2245, R:0.0105)
Batch 300/537: Loss=0.2361 (C:0.2361, R:0.0105)
Batch 325/537: Loss=0.2340 (C:0.2340, R:0.0105)
Batch 350/537: Loss=0.2488 (C:0.2488, R:0.0105)
Batch 375/537: Loss=0.2501 (C:0.2501, R:0.0105)
Batch 400/537: Loss=0.2141 (C:0.2141, R:0.0105)
Batch 425/537: Loss=0.2123 (C:0.2123, R:0.0105)
Batch 450/537: Loss=0.2417 (C:0.2417, R:0.0105)
Batch 475/537: Loss=0.2051 (C:0.2051, R:0.0105)
Batch 500/537: Loss=0.2191 (C:0.2191, R:0.0105)
Batch 525/537: Loss=0.2296 (C:0.2296, R:0.0105)

============================================================
Epoch 104/300 completed in 27.5s
Train: Loss=0.2276 (C:0.2276, R:0.0105) Ratio=5.76x
Val:   Loss=0.3330 (C:0.3330, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 8 epochs

Early stopping triggered after 104 epochs
Best model was at epoch 96 with Val Loss: 0.3313

Global Dataset Training Completed!
Best epoch: 96
Best validation loss: 0.3313
Final separation ratios: Train=5.76x, Val=3.06x
Training completed!
Loading best model from entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin1.0_updatefreq1_max_global_samples10000_20250715_110244/checkpoints/best_model.pt
Starting model evaluation...
========================================
GlobalContrastiveEvaluator initialized on cuda
Starting comprehensive evaluation...
============================================================
Extracting latent representations...
  Processed 1/10 batches
Extracted representations: torch.Size([9824, 75])
Evaluating clustering performance...
Clustering Results:
  Silhouette Score: 0.4578
  Adjusted Rand Score: 0.5193
  Clustering Accuracy: 0.8101
Evaluating classification performance...
  Extracting training representations...
Extracting latent representations...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
Extracted representations: torch.Size([547740, 75])
  Extracting validation representations...
Extracting latent representations...
  Processed 1/9 batches
Extracted representations: torch.Size([9180, 75])
Subsampled training to 50000 samples
  Training on 50000 samples, evaluating on 9180 samples
Classification Results:
  Accuracy: 0.8112
  Per-class F1: [0.831602247573642, 0.751694393099199, 0.8557130942452044]
Evaluating reconstruction quality...
Reconstruction Results:
  Average MSE: 0.010432
Evaluating separation quality...
Separation Results:
  Positive distances: 0.391 ± 0.466
  Negative distances: 1.178 ± 0.635
  Separation ratio: 3.01x
  Gap: -2.299
  Perfect separation: No

Comprehensive evaluation completed!

============================================================
EVALUATION SUMMARY
============================================================
Clustering Performance:
  Silhouette Score: 0.4578
  Clustering Accuracy: 0.8101
  Adjusted Rand Score: 0.5193

Classification Performance:
  Accuracy: 0.8112

Separation Quality:
  Separation Ratio: 3.01x
  Gap: -2.299
  Perfect Separation: False

Reconstruction Quality:
  Average MSE: 0.010432
============================================================
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin1.0_updatefreq1_max_global_samples10000_20250715_110244/results/evaluation_results_20250715_115010.json
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin1.0_updatefreq1_max_global_samples10000_20250715_110244/results/evaluation_results_20250715_115010.json
Saving final experiment results...
Final results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin1.0_updatefreq1_max_global_samples10000_20250715_110244/final_results.json

============================================================
PIPELINE COMPLETED SUCCESSFULLY!
============================================================
Experiment directory: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin1.0_updatefreq1_max_global_samples10000_20250715_110244
Best model: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin1.0_updatefreq1_max_global_samples10000_20250715_110244/checkpoints/best_model.pt
Final results: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin1.0_updatefreq1_max_global_samples10000_20250715_110244/final_results.json

Key Results:
  Separation ratio: 3.01x
  Perfect separation: False
  Classification accuracy: 0.8112
  Result: 0.8112% (improvement: +-80.86%)
  Cleaning up: coarse_margin1.0_updatefreq1_max_global_samples10000_20250715_110244

[3/12] Testing: coarse_margin1.0_updatefreq3_max_global_samples5000
  margin: 1.0
  update_frequency: 3
  max_global_samples: 5000
  Reconstruction weight: 0.3 (fixed)
GLOBAL DATASET CONTRASTIVE AUTOENCODER PIPELINE
============================================================
Start time: 2025-07-15 11:50:10.411681
Using device: cuda

Configuration:
  Embedding type: concat
  Batch size: 1020
  Global update frequency: 3 epochs
  Training epochs: 300
Experiment setup completed:
  Experiment directory: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin1.0_updatefreq3_max_global_samples5000_20250715_115010
  Config saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin1.0_updatefreq3_max_global_samples5000_20250715_115010/config.json
Loading data...
========================================
FlexibleEmbedder initialized with type: 'concat'
Output dimension will be: 1536
GlobalDataLoader initialized:
  Embedding type: concat
  Output dimension: 1536
  Sample size: All
Starting data loading pipeline...
============================================================
Loading training data from data/processed/snli_full_standard_SBERT.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 549367 training samples
Loading validation data from data/processed/snli_full_standard_SBERT_validation.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9842 validation samples
Loading test data from data/processed/snli_full_standard_SBERT_test.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9824 test samples
Generating embeddings for training...
Generating concat embeddings on cuda
Processing 549367 samples in batches of 1000
  Processing batch 1/550
  Processing batch 6/550
  Processing batch 11/550
  Processing batch 16/550
  Processing batch 21/550
  Processing batch 26/550
  Processing batch 31/550
  Processing batch 36/550
  Processing batch 41/550
  Processing batch 46/550
  Processing batch 51/550
  Processing batch 56/550
  Processing batch 61/550
  Processing batch 66/550
  Processing batch 71/550
  Processing batch 76/550
  Processing batch 81/550
  Processing batch 86/550
  Processing batch 91/550
  Processing batch 96/550
  Processing batch 101/550
  Processing batch 106/550
  Processing batch 111/550
  Processing batch 116/550
  Processing batch 121/550
  Processing batch 126/550
  Processing batch 131/550
  Processing batch 136/550
  Processing batch 141/550
  Processing batch 146/550
  Processing batch 151/550
  Processing batch 156/550
  Processing batch 161/550
  Processing batch 166/550
  Processing batch 171/550
  Processing batch 176/550
  Processing batch 181/550
  Processing batch 186/550
  Processing batch 191/550
  Processing batch 196/550
  Processing batch 201/550
  Processing batch 206/550
  Processing batch 211/550
  Processing batch 216/550
  Processing batch 221/550
  Processing batch 226/550
  Processing batch 231/550
  Processing batch 236/550
  Processing batch 241/550
  Processing batch 246/550
  Processing batch 251/550
  Processing batch 256/550
  Processing batch 261/550
  Processing batch 266/550
  Processing batch 271/550
  Processing batch 276/550
  Processing batch 281/550
  Processing batch 286/550
  Processing batch 291/550
  Processing batch 296/550
  Processing batch 301/550
  Processing batch 306/550
  Processing batch 311/550
  Processing batch 316/550
  Processing batch 321/550
  Processing batch 326/550
  Processing batch 331/550
  Processing batch 336/550
  Processing batch 341/550
  Processing batch 346/550
  Processing batch 351/550
  Processing batch 356/550
  Processing batch 361/550
  Processing batch 366/550
  Processing batch 371/550
  Processing batch 376/550
  Processing batch 381/550
  Processing batch 386/550
  Processing batch 391/550
  Processing batch 396/550
  Processing batch 401/550
  Processing batch 406/550
  Processing batch 411/550
  Processing batch 416/550
  Processing batch 421/550
  Processing batch 426/550
  Processing batch 431/550
  Processing batch 436/550
  Processing batch 441/550
  Processing batch 446/550
  Processing batch 451/550
  Processing batch 456/550
  Processing batch 461/550
  Processing batch 466/550
  Processing batch 471/550
  Processing batch 476/550
  Processing batch 481/550
  Processing batch 486/550
  Processing batch 491/550
  Processing batch 496/550
  Processing batch 501/550
  Processing batch 506/550
  Processing batch 511/550
  Processing batch 516/550
  Processing batch 521/550
  Processing batch 526/550
  Processing batch 531/550
  Processing batch 536/550
  Processing batch 541/550
  Processing batch 546/550
Generated concat embeddings: torch.Size([549367, 1536])
Generating embeddings for validation...
Generating concat embeddings on cuda
Processing 9842 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9842, 1536])
Generating embeddings for test...
Generating concat embeddings on cuda
Processing 9824 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9824, 1536])
EntailmentDataset created: 549367 samples
  Embedding shape: torch.Size([549367, 1536])
  Class distribution: {'entailment': 183416, 'neutral': 182764, 'contradiction': 183187}
EntailmentDataset created: 9842 samples
  Embedding shape: torch.Size([9842, 1536])
  Class distribution: {'entailment': 3329, 'neutral': 3235, 'contradiction': 3278}
EntailmentDataset created: 9824 samples
  Embedding shape: torch.Size([9824, 1536])
  Class distribution: {'entailment': 3368, 'neutral': 3219, 'contradiction': 3237}

Data loading pipeline completed!
Output embedding dimension: 1536
Updated model input_dim to: 1536
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 537
  Class 2: 183187 samples
  Class 0: 183416 samples
  Class 1: 182764 samples
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 9
  Class 2: 3278 samples
  Class 0: 3329 samples
  Class 1: 3235 samples
DataLoaders created:
  Batch size: 1020
  Balanced sampling: True
  Train batches: 537
  Val batches: 9
  Test batches: 10
Data loading completed!
  Train: 549367 samples, 537 batches
  Val: 9842 samples, 9 batches
  Test: 9824 samples, 10 batches
Creating model and trainer...
========================================
ContrastiveAutoencoder initialized:
  Input dim: 1536
  Latent dim: 75
  Hidden dims: [512, 256]
  Dropout rate: 0.2
  Total parameters: 1,876,555
Model created with 1,876,555 parameters
FullDatasetContrastiveLoss initialized:
  Margin: 1.0
  Update frequency: 3 epochs
  Max global samples: 5000
FullDatasetCombinedLoss initialized:
  Contrastive weight: 1.0
  Base reconstruction weight: 0.0
  Scheduled reconstruction: warmup=30 epochs, max_weight=0.3
Optimizer created (lr=0.0001)
GlobalDatasetTrainer initialized on device: cuda
Model parameters: 1,876,555
Starting training...
========================================
Starting Global Dataset Training...
============================================================

🌍 Updating global dataset at epoch 1
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.091 ± 0.011
    Neg distances: 0.091 ± 0.011
    Separation ratio: 1.00x
    Gap: -0.115
    ❌ Poor global separation

Epoch 1 Training
----------------------------------------
Batch   0/537: Loss=0.9998 (C:0.9998, R:0.0115)
Batch  25/537: Loss=0.9947 (C:0.9947, R:0.0113)
Batch  50/537: Loss=0.9885 (C:0.9885, R:0.0111)
Batch  75/537: Loss=0.9858 (C:0.9858, R:0.0111)
Batch 100/537: Loss=0.9829 (C:0.9829, R:0.0109)
Batch 125/537: Loss=0.9749 (C:0.9749, R:0.0109)
Batch 150/537: Loss=0.9701 (C:0.9701, R:0.0108)
Batch 175/537: Loss=0.9683 (C:0.9683, R:0.0107)
Batch 200/537: Loss=0.9613 (C:0.9613, R:0.0107)
Batch 225/537: Loss=0.9636 (C:0.9636, R:0.0106)
Batch 250/537: Loss=0.9598 (C:0.9598, R:0.0106)
Batch 275/537: Loss=0.9553 (C:0.9553, R:0.0106)
Batch 300/537: Loss=0.9574 (C:0.9574, R:0.0106)
Batch 325/537: Loss=0.9547 (C:0.9547, R:0.0106)
Batch 350/537: Loss=0.9527 (C:0.9527, R:0.0105)
Batch 375/537: Loss=0.9534 (C:0.9534, R:0.0105)
Batch 400/537: Loss=0.9486 (C:0.9486, R:0.0105)
Batch 425/537: Loss=0.9571 (C:0.9571, R:0.0105)
Batch 450/537: Loss=0.9480 (C:0.9480, R:0.0105)
Batch 475/537: Loss=0.9498 (C:0.9498, R:0.0105)
Batch 500/537: Loss=0.9532 (C:0.9532, R:0.0105)
Batch 525/537: Loss=0.9484 (C:0.9484, R:0.0105)

============================================================
Epoch 1/300 completed in 27.0s
Train: Loss=0.9639 (C:0.9639, R:0.0107) Ratio=1.63x
Val:   Loss=0.9430 (C:0.9430, R:0.0105) Ratio=2.16x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.9430)
============================================================

Epoch 2 Training
----------------------------------------
Batch   0/537: Loss=0.9407 (C:0.9407, R:0.0105)
Batch  25/537: Loss=0.9479 (C:0.9479, R:0.0105)
Batch  50/537: Loss=0.9452 (C:0.9452, R:0.0105)
Batch  75/537: Loss=0.9374 (C:0.9374, R:0.0105)
Batch 100/537: Loss=0.9482 (C:0.9482, R:0.0105)
Batch 125/537: Loss=0.9482 (C:0.9482, R:0.0105)
Batch 150/537: Loss=0.9472 (C:0.9472, R:0.0105)
Batch 175/537: Loss=0.9442 (C:0.9442, R:0.0105)
Batch 200/537: Loss=0.9385 (C:0.9385, R:0.0105)
Batch 225/537: Loss=0.9394 (C:0.9394, R:0.0105)
Batch 250/537: Loss=0.9389 (C:0.9389, R:0.0105)
Batch 275/537: Loss=0.9400 (C:0.9400, R:0.0105)
Batch 300/537: Loss=0.9416 (C:0.9416, R:0.0105)
Batch 325/537: Loss=0.9385 (C:0.9385, R:0.0106)
Batch 350/537: Loss=0.9393 (C:0.9393, R:0.0106)
Batch 375/537: Loss=0.9375 (C:0.9375, R:0.0105)
Batch 400/537: Loss=0.9318 (C:0.9318, R:0.0105)
Batch 425/537: Loss=0.9361 (C:0.9361, R:0.0105)
Batch 450/537: Loss=0.9298 (C:0.9298, R:0.0105)
Batch 475/537: Loss=0.9353 (C:0.9353, R:0.0105)
Batch 500/537: Loss=0.9402 (C:0.9402, R:0.0105)
Batch 525/537: Loss=0.9365 (C:0.9365, R:0.0105)

============================================================
Epoch 2/300 completed in 21.5s
Train: Loss=0.9420 (C:0.9420, R:0.0105) Ratio=2.20x
Val:   Loss=0.9367 (C:0.9367, R:0.0104) Ratio=2.37x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.9367)
============================================================

Epoch 3 Training
----------------------------------------
Batch   0/537: Loss=0.9376 (C:0.9376, R:0.0105)
Batch  25/537: Loss=0.9380 (C:0.9380, R:0.0105)
Batch  50/537: Loss=0.9343 (C:0.9343, R:0.0105)
Batch  75/537: Loss=0.9425 (C:0.9425, R:0.0105)
Batch 100/537: Loss=0.9317 (C:0.9317, R:0.0105)
Batch 125/537: Loss=0.9359 (C:0.9359, R:0.0105)
Batch 150/537: Loss=0.9325 (C:0.9325, R:0.0105)
Batch 175/537: Loss=0.9399 (C:0.9399, R:0.0105)
Batch 200/537: Loss=0.9359 (C:0.9359, R:0.0105)
Batch 225/537: Loss=0.9415 (C:0.9415, R:0.0105)
Batch 250/537: Loss=0.9406 (C:0.9406, R:0.0105)
Batch 275/537: Loss=0.9287 (C:0.9287, R:0.0105)
Batch 300/537: Loss=0.9305 (C:0.9305, R:0.0104)
Batch 325/537: Loss=0.9328 (C:0.9328, R:0.0105)
Batch 350/537: Loss=0.9323 (C:0.9323, R:0.0105)
Batch 375/537: Loss=0.9313 (C:0.9313, R:0.0105)
Batch 400/537: Loss=0.9440 (C:0.9440, R:0.0105)
Batch 425/537: Loss=0.9419 (C:0.9419, R:0.0105)
Batch 450/537: Loss=0.9340 (C:0.9340, R:0.0105)
Batch 475/537: Loss=0.9396 (C:0.9396, R:0.0105)
Batch 500/537: Loss=0.9380 (C:0.9380, R:0.0105)
Batch 525/537: Loss=0.9328 (C:0.9328, R:0.0105)

============================================================
Epoch 3/300 completed in 21.2s
Train: Loss=0.9358 (C:0.9358, R:0.0105) Ratio=2.40x
Val:   Loss=0.9326 (C:0.9326, R:0.0104) Ratio=2.51x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.9326)
============================================================

🌍 Updating global dataset at epoch 4
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.284 ± 0.284
    Neg distances: 0.776 ± 0.426
    Separation ratio: 2.73x
    Gap: -1.706
    ✅ Good global separation

Epoch 4 Training
----------------------------------------
Batch   0/537: Loss=0.6132 (C:0.6132, R:0.0105)
Batch  25/537: Loss=0.6006 (C:0.6006, R:0.0105)
Batch  50/537: Loss=0.6013 (C:0.6013, R:0.0105)
Batch  75/537: Loss=0.6159 (C:0.6159, R:0.0104)
Batch 100/537: Loss=0.6181 (C:0.6181, R:0.0105)
Batch 125/537: Loss=0.6149 (C:0.6149, R:0.0105)
Batch 150/537: Loss=0.5964 (C:0.5964, R:0.0105)
Batch 175/537: Loss=0.6045 (C:0.6045, R:0.0105)
Batch 200/537: Loss=0.6197 (C:0.6197, R:0.0105)
Batch 225/537: Loss=0.6279 (C:0.6279, R:0.0105)
Batch 250/537: Loss=0.6143 (C:0.6143, R:0.0105)
Batch 275/537: Loss=0.6188 (C:0.6188, R:0.0105)
Batch 300/537: Loss=0.6080 (C:0.6080, R:0.0105)
Batch 325/537: Loss=0.6032 (C:0.6032, R:0.0105)
Batch 350/537: Loss=0.6197 (C:0.6197, R:0.0105)
Batch 375/537: Loss=0.5898 (C:0.5898, R:0.0105)
Batch 400/537: Loss=0.5953 (C:0.5953, R:0.0105)
Batch 425/537: Loss=0.5993 (C:0.5993, R:0.0105)
Batch 450/537: Loss=0.6022 (C:0.6022, R:0.0105)
Batch 475/537: Loss=0.5984 (C:0.5984, R:0.0105)
Batch 500/537: Loss=0.6122 (C:0.6122, R:0.0105)
Batch 525/537: Loss=0.6120 (C:0.6120, R:0.0105)

============================================================
Epoch 4/300 completed in 26.8s
Train: Loss=0.6079 (C:0.6079, R:0.0105) Ratio=2.53x
Val:   Loss=0.6021 (C:0.6021, R:0.0104) Ratio=2.61x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.6021)
============================================================

Epoch 5 Training
----------------------------------------
Batch   0/537: Loss=0.5892 (C:0.5892, R:0.0105)
Batch  25/537: Loss=0.5795 (C:0.5795, R:0.0105)
Batch  50/537: Loss=0.6101 (C:0.6101, R:0.0105)
Batch  75/537: Loss=0.6032 (C:0.6032, R:0.0105)
Batch 100/537: Loss=0.6135 (C:0.6135, R:0.0105)
Batch 125/537: Loss=0.5867 (C:0.5867, R:0.0105)
Batch 150/537: Loss=0.6078 (C:0.6078, R:0.0105)
Batch 175/537: Loss=0.5901 (C:0.5901, R:0.0106)
Batch 200/537: Loss=0.5861 (C:0.5861, R:0.0105)
Batch 225/537: Loss=0.5762 (C:0.5762, R:0.0105)
Batch 250/537: Loss=0.5966 (C:0.5966, R:0.0105)
Batch 275/537: Loss=0.6009 (C:0.6009, R:0.0105)
Batch 300/537: Loss=0.5912 (C:0.5912, R:0.0106)
Batch 325/537: Loss=0.5981 (C:0.5981, R:0.0105)
Batch 350/537: Loss=0.6116 (C:0.6116, R:0.0105)
Batch 375/537: Loss=0.5849 (C:0.5849, R:0.0105)
Batch 400/537: Loss=0.5934 (C:0.5934, R:0.0105)
Batch 425/537: Loss=0.5695 (C:0.5695, R:0.0105)
Batch 450/537: Loss=0.5973 (C:0.5973, R:0.0105)
Batch 475/537: Loss=0.5963 (C:0.5963, R:0.0105)
Batch 500/537: Loss=0.5872 (C:0.5872, R:0.0105)
Batch 525/537: Loss=0.5967 (C:0.5967, R:0.0105)

============================================================
Epoch 5/300 completed in 21.4s
Train: Loss=0.5956 (C:0.5956, R:0.0105) Ratio=2.77x
Val:   Loss=0.6001 (C:0.6001, R:0.0104) Ratio=2.76x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.6001)
============================================================

Epoch 6 Training
----------------------------------------
Batch   0/537: Loss=0.5809 (C:0.5809, R:0.0105)
Batch  25/537: Loss=0.5858 (C:0.5858, R:0.0105)
Batch  50/537: Loss=0.5947 (C:0.5947, R:0.0105)
Batch  75/537: Loss=0.5811 (C:0.5811, R:0.0105)
Batch 100/537: Loss=0.5761 (C:0.5761, R:0.0105)
Batch 125/537: Loss=0.5890 (C:0.5890, R:0.0105)
Batch 150/537: Loss=0.5846 (C:0.5846, R:0.0105)
Batch 175/537: Loss=0.5889 (C:0.5889, R:0.0105)
Batch 200/537: Loss=0.6054 (C:0.6054, R:0.0105)
Batch 225/537: Loss=0.5824 (C:0.5824, R:0.0105)
Batch 250/537: Loss=0.6065 (C:0.6065, R:0.0105)
Batch 275/537: Loss=0.5791 (C:0.5791, R:0.0105)
Batch 300/537: Loss=0.6026 (C:0.6026, R:0.0105)
Batch 325/537: Loss=0.5868 (C:0.5868, R:0.0105)
Batch 350/537: Loss=0.5799 (C:0.5799, R:0.0105)
Batch 375/537: Loss=0.6102 (C:0.6102, R:0.0105)
Batch 400/537: Loss=0.5750 (C:0.5750, R:0.0105)
Batch 425/537: Loss=0.5915 (C:0.5915, R:0.0105)
Batch 450/537: Loss=0.6013 (C:0.6013, R:0.0105)
Batch 475/537: Loss=0.5904 (C:0.5904, R:0.0105)
Batch 500/537: Loss=0.5960 (C:0.5960, R:0.0105)
Batch 525/537: Loss=0.5947 (C:0.5947, R:0.0105)

============================================================
Epoch 6/300 completed in 22.0s
Train: Loss=0.5888 (C:0.5888, R:0.0105) Ratio=2.88x
Val:   Loss=0.5905 (C:0.5905, R:0.0104) Ratio=2.78x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.5905)
============================================================

🌍 Updating global dataset at epoch 7
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.237 ± 0.273
    Neg distances: 0.832 ± 0.428
    Separation ratio: 3.52x
    Gap: -1.565
    ✅ Excellent global separation!

Epoch 7 Training
----------------------------------------
Batch   0/537: Loss=0.5176 (C:0.5176, R:0.0105)
Batch  25/537: Loss=0.5259 (C:0.5259, R:0.0105)
Batch  50/537: Loss=0.5362 (C:0.5362, R:0.0105)
Batch  75/537: Loss=0.5474 (C:0.5474, R:0.0105)
Batch 100/537: Loss=0.5261 (C:0.5261, R:0.0106)
Batch 125/537: Loss=0.5362 (C:0.5362, R:0.0105)
Batch 150/537: Loss=0.5494 (C:0.5494, R:0.0106)
Batch 175/537: Loss=0.5368 (C:0.5368, R:0.0105)
Batch 200/537: Loss=0.5362 (C:0.5362, R:0.0105)
Batch 225/537: Loss=0.5397 (C:0.5397, R:0.0105)
Batch 250/537: Loss=0.5243 (C:0.5243, R:0.0105)
Batch 275/537: Loss=0.5293 (C:0.5293, R:0.0105)
Batch 300/537: Loss=0.5342 (C:0.5342, R:0.0105)
Batch 325/537: Loss=0.5356 (C:0.5356, R:0.0105)
Batch 350/537: Loss=0.5527 (C:0.5527, R:0.0105)
Batch 375/537: Loss=0.5159 (C:0.5159, R:0.0105)
Batch 400/537: Loss=0.5350 (C:0.5350, R:0.0105)
Batch 425/537: Loss=0.5406 (C:0.5406, R:0.0105)
Batch 450/537: Loss=0.5300 (C:0.5300, R:0.0105)
Batch 475/537: Loss=0.5297 (C:0.5297, R:0.0105)
Batch 500/537: Loss=0.5455 (C:0.5455, R:0.0105)
Batch 525/537: Loss=0.5514 (C:0.5514, R:0.0105)

============================================================
Epoch 7/300 completed in 28.0s
Train: Loss=0.5357 (C:0.5357, R:0.0105) Ratio=3.00x
Val:   Loss=0.5392 (C:0.5392, R:0.0104) Ratio=2.85x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.5392)
============================================================

Epoch 8 Training
----------------------------------------
Batch   0/537: Loss=0.5305 (C:0.5305, R:0.0105)
Batch  25/537: Loss=0.5230 (C:0.5230, R:0.0105)
Batch  50/537: Loss=0.5255 (C:0.5255, R:0.0105)
Batch  75/537: Loss=0.5219 (C:0.5219, R:0.0105)
Batch 100/537: Loss=0.5231 (C:0.5231, R:0.0105)
Batch 125/537: Loss=0.5374 (C:0.5374, R:0.0105)
Batch 150/537: Loss=0.5258 (C:0.5258, R:0.0105)
Batch 175/537: Loss=0.5275 (C:0.5275, R:0.0105)
Batch 200/537: Loss=0.5404 (C:0.5404, R:0.0105)
Batch 225/537: Loss=0.5331 (C:0.5331, R:0.0105)
Batch 250/537: Loss=0.5175 (C:0.5175, R:0.0105)
Batch 275/537: Loss=0.5464 (C:0.5464, R:0.0105)
Batch 300/537: Loss=0.5329 (C:0.5329, R:0.0105)
Batch 325/537: Loss=0.5114 (C:0.5114, R:0.0105)
Batch 350/537: Loss=0.5230 (C:0.5230, R:0.0105)
Batch 375/537: Loss=0.5401 (C:0.5401, R:0.0105)
Batch 400/537: Loss=0.5335 (C:0.5335, R:0.0105)
Batch 425/537: Loss=0.5221 (C:0.5221, R:0.0105)
Batch 450/537: Loss=0.5175 (C:0.5175, R:0.0105)
Batch 475/537: Loss=0.5448 (C:0.5448, R:0.0105)
Batch 500/537: Loss=0.5258 (C:0.5258, R:0.0105)
Batch 525/537: Loss=0.5362 (C:0.5362, R:0.0105)

============================================================
Epoch 8/300 completed in 21.2s
Train: Loss=0.5309 (C:0.5309, R:0.0105) Ratio=3.09x
Val:   Loss=0.5397 (C:0.5397, R:0.0104) Ratio=2.85x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

Epoch 9 Training
----------------------------------------
Batch   0/537: Loss=0.5251 (C:0.5251, R:0.0105)
Batch  25/537: Loss=0.5429 (C:0.5429, R:0.0105)
Batch  50/537: Loss=0.5147 (C:0.5147, R:0.0105)
Batch  75/537: Loss=0.5169 (C:0.5169, R:0.0105)
Batch 100/537: Loss=0.5117 (C:0.5117, R:0.0105)
Batch 125/537: Loss=0.5219 (C:0.5219, R:0.0105)
Batch 150/537: Loss=0.5343 (C:0.5343, R:0.0105)
Batch 175/537: Loss=0.5394 (C:0.5394, R:0.0105)
Batch 200/537: Loss=0.5317 (C:0.5317, R:0.0105)
Batch 225/537: Loss=0.5320 (C:0.5320, R:0.0105)
Batch 250/537: Loss=0.5316 (C:0.5316, R:0.0105)
Batch 275/537: Loss=0.5183 (C:0.5183, R:0.0105)
Batch 300/537: Loss=0.5368 (C:0.5368, R:0.0105)
Batch 325/537: Loss=0.5301 (C:0.5301, R:0.0105)
Batch 350/537: Loss=0.5437 (C:0.5437, R:0.0105)
Batch 375/537: Loss=0.5204 (C:0.5204, R:0.0105)
Batch 400/537: Loss=0.5225 (C:0.5225, R:0.0105)
Batch 425/537: Loss=0.5347 (C:0.5347, R:0.0106)
Batch 450/537: Loss=0.5490 (C:0.5490, R:0.0105)
Batch 475/537: Loss=0.5416 (C:0.5416, R:0.0105)
Batch 500/537: Loss=0.5264 (C:0.5264, R:0.0105)
Batch 525/537: Loss=0.5283 (C:0.5283, R:0.0105)

============================================================
Epoch 9/300 completed in 22.0s
Train: Loss=0.5269 (C:0.5269, R:0.0105) Ratio=3.11x
Val:   Loss=0.5410 (C:0.5410, R:0.0104) Ratio=2.91x
Reconstruction weight: 0.000
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 10
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.236 ± 0.290
    Neg distances: 0.879 ± 0.443
    Separation ratio: 3.72x
    Gap: -1.620
    ✅ Excellent global separation!

Epoch 10 Training
----------------------------------------
Batch   0/537: Loss=0.4980 (C:0.4980, R:0.0106)
Batch  25/537: Loss=0.4984 (C:0.4984, R:0.0105)
Batch  50/537: Loss=0.4954 (C:0.4954, R:0.0105)
Batch  75/537: Loss=0.5082 (C:0.5082, R:0.0105)
Batch 100/537: Loss=0.4942 (C:0.4942, R:0.0105)
Batch 125/537: Loss=0.4959 (C:0.4959, R:0.0105)
Batch 150/537: Loss=0.5146 (C:0.5146, R:0.0105)
Batch 175/537: Loss=0.5115 (C:0.5115, R:0.0105)
Batch 200/537: Loss=0.5133 (C:0.5133, R:0.0105)
Batch 225/537: Loss=0.4963 (C:0.4963, R:0.0105)
Batch 250/537: Loss=0.5185 (C:0.5185, R:0.0105)
Batch 275/537: Loss=0.5074 (C:0.5074, R:0.0105)
Batch 300/537: Loss=0.5173 (C:0.5173, R:0.0105)
Batch 325/537: Loss=0.5107 (C:0.5107, R:0.0105)
Batch 350/537: Loss=0.5115 (C:0.5115, R:0.0105)
Batch 375/537: Loss=0.5340 (C:0.5340, R:0.0105)
Batch 400/537: Loss=0.5280 (C:0.5280, R:0.0105)
Batch 425/537: Loss=0.5087 (C:0.5087, R:0.0105)
Batch 450/537: Loss=0.5296 (C:0.5296, R:0.0105)
Batch 475/537: Loss=0.5194 (C:0.5194, R:0.0105)
Batch 500/537: Loss=0.5202 (C:0.5202, R:0.0105)
Batch 525/537: Loss=0.5178 (C:0.5178, R:0.0105)

============================================================
Epoch 10/300 completed in 28.6s
Train: Loss=0.5115 (C:0.5115, R:0.0105) Ratio=3.26x
Val:   Loss=0.5267 (C:0.5267, R:0.0104) Ratio=2.91x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.5267)
============================================================

Epoch 11 Training
----------------------------------------
Batch   0/537: Loss=0.5035 (C:0.5035, R:0.0105)
Batch  25/537: Loss=0.5022 (C:0.5022, R:0.0105)
Batch  50/537: Loss=0.5142 (C:0.5142, R:0.0105)
Batch  75/537: Loss=0.4878 (C:0.4878, R:0.0105)
Batch 100/537: Loss=0.5095 (C:0.5095, R:0.0105)
Batch 125/537: Loss=0.5195 (C:0.5195, R:0.0105)
Batch 150/537: Loss=0.5113 (C:0.5113, R:0.0105)
Batch 175/537: Loss=0.5143 (C:0.5143, R:0.0105)
Batch 200/537: Loss=0.5104 (C:0.5104, R:0.0105)
Batch 225/537: Loss=0.5035 (C:0.5035, R:0.0105)
Batch 250/537: Loss=0.5045 (C:0.5045, R:0.0105)
Batch 275/537: Loss=0.5027 (C:0.5027, R:0.0105)
Batch 300/537: Loss=0.4930 (C:0.4930, R:0.0105)
Batch 325/537: Loss=0.5172 (C:0.5172, R:0.0105)
Batch 350/537: Loss=0.5151 (C:0.5151, R:0.0105)
Batch 375/537: Loss=0.5162 (C:0.5162, R:0.0105)
Batch 400/537: Loss=0.5145 (C:0.5145, R:0.0105)
Batch 425/537: Loss=0.5080 (C:0.5080, R:0.0105)
Batch 450/537: Loss=0.5057 (C:0.5057, R:0.0105)
Batch 475/537: Loss=0.5267 (C:0.5267, R:0.0105)
Batch 500/537: Loss=0.5033 (C:0.5033, R:0.0105)
Batch 525/537: Loss=0.5065 (C:0.5065, R:0.0105)

============================================================
Epoch 11/300 completed in 21.9s
Train: Loss=0.5085 (C:0.5085, R:0.0105) Ratio=3.31x
Val:   Loss=0.5286 (C:0.5286, R:0.0104) Ratio=2.93x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

Epoch 12 Training
----------------------------------------
Batch   0/537: Loss=0.5232 (C:0.5232, R:0.0105)
Batch  25/537: Loss=0.5035 (C:0.5035, R:0.0105)
Batch  50/537: Loss=0.5069 (C:0.5069, R:0.0105)
Batch  75/537: Loss=0.5061 (C:0.5061, R:0.0105)
Batch 100/537: Loss=0.4950 (C:0.4950, R:0.0105)
Batch 125/537: Loss=0.5021 (C:0.5021, R:0.0105)
Batch 150/537: Loss=0.5086 (C:0.5086, R:0.0105)
Batch 175/537: Loss=0.5120 (C:0.5120, R:0.0105)
Batch 200/537: Loss=0.4919 (C:0.4919, R:0.0105)
Batch 225/537: Loss=0.4862 (C:0.4862, R:0.0105)
Batch 250/537: Loss=0.5019 (C:0.5019, R:0.0105)
Batch 275/537: Loss=0.5074 (C:0.5074, R:0.0105)
Batch 300/537: Loss=0.5089 (C:0.5089, R:0.0105)
Batch 325/537: Loss=0.5166 (C:0.5166, R:0.0105)
Batch 350/537: Loss=0.5081 (C:0.5081, R:0.0105)
Batch 375/537: Loss=0.5040 (C:0.5040, R:0.0105)
Batch 400/537: Loss=0.5157 (C:0.5157, R:0.0105)
Batch 425/537: Loss=0.4987 (C:0.4987, R:0.0105)
Batch 450/537: Loss=0.5082 (C:0.5082, R:0.0105)
Batch 475/537: Loss=0.5259 (C:0.5259, R:0.0105)
Batch 500/537: Loss=0.5186 (C:0.5186, R:0.0106)
Batch 525/537: Loss=0.5126 (C:0.5126, R:0.0105)

============================================================
Epoch 12/300 completed in 21.7s
Train: Loss=0.5048 (C:0.5048, R:0.0105) Ratio=3.33x
Val:   Loss=0.5281 (C:0.5281, R:0.0104) Ratio=2.97x
Reconstruction weight: 0.000
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 13
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.223 ± 0.282
    Neg distances: 0.923 ± 0.452
    Separation ratio: 4.13x
    Gap: -1.655
    ✅ Excellent global separation!

Epoch 13 Training
----------------------------------------
Batch   0/537: Loss=0.4787 (C:0.4787, R:0.0105)
Batch  25/537: Loss=0.4741 (C:0.4741, R:0.0105)
Batch  50/537: Loss=0.4917 (C:0.4917, R:0.0105)
Batch  75/537: Loss=0.4647 (C:0.4647, R:0.0105)
Batch 100/537: Loss=0.4759 (C:0.4759, R:0.0105)
Batch 125/537: Loss=0.4831 (C:0.4831, R:0.0105)
Batch 150/537: Loss=0.4740 (C:0.4740, R:0.0105)
Batch 175/537: Loss=0.4846 (C:0.4846, R:0.0105)
Batch 200/537: Loss=0.4926 (C:0.4926, R:0.0106)
Batch 225/537: Loss=0.4869 (C:0.4869, R:0.0105)
Batch 250/537: Loss=0.4845 (C:0.4845, R:0.0105)
Batch 275/537: Loss=0.4845 (C:0.4845, R:0.0105)
Batch 300/537: Loss=0.4878 (C:0.4878, R:0.0105)
Batch 325/537: Loss=0.5051 (C:0.5051, R:0.0105)
Batch 350/537: Loss=0.4783 (C:0.4783, R:0.0105)
Batch 375/537: Loss=0.4781 (C:0.4781, R:0.0105)
Batch 400/537: Loss=0.4941 (C:0.4941, R:0.0105)
Batch 425/537: Loss=0.4670 (C:0.4670, R:0.0105)
Batch 450/537: Loss=0.4933 (C:0.4933, R:0.0105)
Batch 475/537: Loss=0.4842 (C:0.4842, R:0.0106)
Batch 500/537: Loss=0.4809 (C:0.4809, R:0.0105)
Batch 525/537: Loss=0.4798 (C:0.4798, R:0.0105)

============================================================
Epoch 13/300 completed in 27.4s
Train: Loss=0.4814 (C:0.4814, R:0.0105) Ratio=3.40x
Val:   Loss=0.5074 (C:0.5074, R:0.0104) Ratio=2.94x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.5074)
============================================================

Epoch 14 Training
----------------------------------------
Batch   0/537: Loss=0.4834 (C:0.4834, R:0.0105)
Batch  25/537: Loss=0.4702 (C:0.4702, R:0.0105)
Batch  50/537: Loss=0.4744 (C:0.4744, R:0.0105)
Batch  75/537: Loss=0.4676 (C:0.4676, R:0.0105)
Batch 100/537: Loss=0.4647 (C:0.4647, R:0.0105)
Batch 125/537: Loss=0.4765 (C:0.4765, R:0.0105)
Batch 150/537: Loss=0.4779 (C:0.4779, R:0.0105)
Batch 175/537: Loss=0.4886 (C:0.4886, R:0.0105)
Batch 200/537: Loss=0.4668 (C:0.4668, R:0.0105)
Batch 225/537: Loss=0.4688 (C:0.4688, R:0.0105)
Batch 250/537: Loss=0.4774 (C:0.4774, R:0.0105)
Batch 275/537: Loss=0.4867 (C:0.4867, R:0.0105)
Batch 300/537: Loss=0.4879 (C:0.4879, R:0.0105)
Batch 325/537: Loss=0.4763 (C:0.4763, R:0.0105)
Batch 350/537: Loss=0.4900 (C:0.4900, R:0.0105)
Batch 375/537: Loss=0.4885 (C:0.4885, R:0.0105)
Batch 400/537: Loss=0.4744 (C:0.4744, R:0.0106)
Batch 425/537: Loss=0.4934 (C:0.4934, R:0.0105)
Batch 450/537: Loss=0.4850 (C:0.4850, R:0.0105)
Batch 475/537: Loss=0.4731 (C:0.4731, R:0.0105)
Batch 500/537: Loss=0.4757 (C:0.4757, R:0.0105)
Batch 525/537: Loss=0.4894 (C:0.4894, R:0.0105)

============================================================
Epoch 14/300 completed in 21.8s
Train: Loss=0.4782 (C:0.4782, R:0.0105) Ratio=3.46x
Val:   Loss=0.5043 (C:0.5043, R:0.0104) Ratio=2.97x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.5043)
============================================================

Epoch 15 Training
----------------------------------------
Batch   0/537: Loss=0.4724 (C:0.4724, R:0.0106)
Batch  25/537: Loss=0.4703 (C:0.4703, R:0.0105)
Batch  50/537: Loss=0.4817 (C:0.4817, R:0.0105)
Batch  75/537: Loss=0.4806 (C:0.4806, R:0.0105)
Batch 100/537: Loss=0.4869 (C:0.4869, R:0.0105)
Batch 125/537: Loss=0.4661 (C:0.4661, R:0.0105)
Batch 150/537: Loss=0.5007 (C:0.5007, R:0.0106)
Batch 175/537: Loss=0.4795 (C:0.4795, R:0.0105)
Batch 200/537: Loss=0.4892 (C:0.4892, R:0.0105)
Batch 225/537: Loss=0.4767 (C:0.4767, R:0.0105)
Batch 250/537: Loss=0.4794 (C:0.4794, R:0.0105)
Batch 275/537: Loss=0.4581 (C:0.4581, R:0.0105)
Batch 300/537: Loss=0.4759 (C:0.4759, R:0.0105)
Batch 325/537: Loss=0.4738 (C:0.4738, R:0.0105)
Batch 350/537: Loss=0.4985 (C:0.4985, R:0.0105)
Batch 375/537: Loss=0.4871 (C:0.4871, R:0.0105)
Batch 400/537: Loss=0.4784 (C:0.4784, R:0.0105)
Batch 425/537: Loss=0.4738 (C:0.4738, R:0.0105)
Batch 450/537: Loss=0.4705 (C:0.4705, R:0.0105)
Batch 475/537: Loss=0.4794 (C:0.4794, R:0.0105)
Batch 500/537: Loss=0.4705 (C:0.4705, R:0.0105)
Batch 525/537: Loss=0.4776 (C:0.4776, R:0.0105)

============================================================
Epoch 15/300 completed in 21.8s
Train: Loss=0.4761 (C:0.4761, R:0.0105) Ratio=3.52x
Val:   Loss=0.4996 (C:0.4996, R:0.0104) Ratio=3.02x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4996)
============================================================

🌍 Updating global dataset at epoch 16
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.203 ± 0.268
    Neg distances: 0.975 ± 0.458
    Separation ratio: 4.81x
    Gap: -1.675
    ✅ Excellent global separation!

Epoch 16 Training
----------------------------------------
Batch   0/537: Loss=0.4509 (C:0.4509, R:0.0105)
Batch  25/537: Loss=0.4222 (C:0.4222, R:0.0105)
Batch  50/537: Loss=0.4492 (C:0.4492, R:0.0105)
Batch  75/537: Loss=0.4325 (C:0.4325, R:0.0105)
Batch 100/537: Loss=0.4278 (C:0.4278, R:0.0105)
Batch 125/537: Loss=0.4501 (C:0.4501, R:0.0105)
Batch 150/537: Loss=0.4722 (C:0.4722, R:0.0105)
Batch 175/537: Loss=0.4324 (C:0.4324, R:0.0105)
Batch 200/537: Loss=0.4422 (C:0.4422, R:0.0106)
Batch 225/537: Loss=0.4530 (C:0.4530, R:0.0105)
Batch 250/537: Loss=0.4439 (C:0.4439, R:0.0105)
Batch 275/537: Loss=0.4464 (C:0.4464, R:0.0105)
Batch 300/537: Loss=0.4579 (C:0.4579, R:0.0105)
Batch 325/537: Loss=0.4453 (C:0.4453, R:0.0105)
Batch 350/537: Loss=0.4484 (C:0.4484, R:0.0105)
Batch 375/537: Loss=0.4496 (C:0.4496, R:0.0105)
Batch 400/537: Loss=0.4428 (C:0.4428, R:0.0105)
Batch 425/537: Loss=0.4399 (C:0.4399, R:0.0105)
Batch 450/537: Loss=0.4402 (C:0.4402, R:0.0105)
Batch 475/537: Loss=0.4549 (C:0.4549, R:0.0105)
Batch 500/537: Loss=0.4516 (C:0.4516, R:0.0105)
Batch 525/537: Loss=0.4424 (C:0.4424, R:0.0105)

============================================================
Epoch 16/300 completed in 27.0s
Train: Loss=0.4459 (C:0.4459, R:0.0105) Ratio=3.59x
Val:   Loss=0.4706 (C:0.4706, R:0.0104) Ratio=3.00x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4706)
============================================================

Epoch 17 Training
----------------------------------------
Batch   0/537: Loss=0.4364 (C:0.4364, R:0.0105)
Batch  25/537: Loss=0.4491 (C:0.4491, R:0.0105)
Batch  50/537: Loss=0.4418 (C:0.4418, R:0.0105)
Batch  75/537: Loss=0.4533 (C:0.4533, R:0.0105)
Batch 100/537: Loss=0.4368 (C:0.4368, R:0.0105)
Batch 125/537: Loss=0.4406 (C:0.4406, R:0.0105)
Batch 150/537: Loss=0.4574 (C:0.4574, R:0.0105)
Batch 175/537: Loss=0.4342 (C:0.4342, R:0.0105)
Batch 200/537: Loss=0.4535 (C:0.4535, R:0.0105)
Batch 225/537: Loss=0.4460 (C:0.4460, R:0.0105)
Batch 250/537: Loss=0.4358 (C:0.4358, R:0.0105)
Batch 275/537: Loss=0.4347 (C:0.4347, R:0.0105)
Batch 300/537: Loss=0.4437 (C:0.4437, R:0.0105)
Batch 325/537: Loss=0.4422 (C:0.4422, R:0.0105)
Batch 350/537: Loss=0.4227 (C:0.4227, R:0.0105)
Batch 375/537: Loss=0.4473 (C:0.4473, R:0.0105)
Batch 400/537: Loss=0.4403 (C:0.4403, R:0.0105)
Batch 425/537: Loss=0.4417 (C:0.4417, R:0.0105)
Batch 450/537: Loss=0.4321 (C:0.4321, R:0.0105)
Batch 475/537: Loss=0.4439 (C:0.4439, R:0.0105)
Batch 500/537: Loss=0.4386 (C:0.4386, R:0.0105)
Batch 525/537: Loss=0.4524 (C:0.4524, R:0.0105)

============================================================
Epoch 17/300 completed in 22.2s
Train: Loss=0.4437 (C:0.4437, R:0.0105) Ratio=3.69x
Val:   Loss=0.4754 (C:0.4754, R:0.0104) Ratio=3.00x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

Epoch 18 Training
----------------------------------------
Batch   0/537: Loss=0.4355 (C:0.4355, R:0.0105)
Batch  25/537: Loss=0.4374 (C:0.4374, R:0.0105)
Batch  50/537: Loss=0.4365 (C:0.4365, R:0.0105)
Batch  75/537: Loss=0.4247 (C:0.4247, R:0.0105)
Batch 100/537: Loss=0.4308 (C:0.4308, R:0.0105)
Batch 125/537: Loss=0.4354 (C:0.4354, R:0.0105)
Batch 150/537: Loss=0.4373 (C:0.4373, R:0.0105)
Batch 175/537: Loss=0.4094 (C:0.4094, R:0.0105)
Batch 200/537: Loss=0.4550 (C:0.4550, R:0.0105)
Batch 225/537: Loss=0.4473 (C:0.4473, R:0.0105)
Batch 250/537: Loss=0.4310 (C:0.4310, R:0.0105)
Batch 275/537: Loss=0.4494 (C:0.4494, R:0.0105)
Batch 300/537: Loss=0.4422 (C:0.4422, R:0.0106)
Batch 325/537: Loss=0.4386 (C:0.4386, R:0.0105)
Batch 350/537: Loss=0.4283 (C:0.4283, R:0.0105)
Batch 375/537: Loss=0.4372 (C:0.4372, R:0.0105)
Batch 400/537: Loss=0.4471 (C:0.4471, R:0.0105)
Batch 425/537: Loss=0.4507 (C:0.4507, R:0.0105)
Batch 450/537: Loss=0.4330 (C:0.4330, R:0.0105)
Batch 475/537: Loss=0.4557 (C:0.4557, R:0.0105)
Batch 500/537: Loss=0.4465 (C:0.4465, R:0.0105)
Batch 525/537: Loss=0.4441 (C:0.4441, R:0.0105)

============================================================
Epoch 18/300 completed in 22.0s
Train: Loss=0.4419 (C:0.4419, R:0.0105) Ratio=3.68x
Val:   Loss=0.4736 (C:0.4736, R:0.0104) Ratio=3.01x
Reconstruction weight: 0.000
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 19
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.210 ± 0.275
    Neg distances: 1.001 ± 0.468
    Separation ratio: 4.77x
    Gap: -1.754
    ✅ Excellent global separation!

Epoch 19 Training
----------------------------------------
Batch   0/537: Loss=0.4415 (C:0.4415, R:0.0105)
Batch  25/537: Loss=0.4376 (C:0.4376, R:0.0105)
Batch  50/537: Loss=0.4291 (C:0.4291, R:0.0105)
Batch  75/537: Loss=0.4310 (C:0.4310, R:0.0105)
Batch 100/537: Loss=0.4385 (C:0.4385, R:0.0105)
Batch 125/537: Loss=0.4406 (C:0.4406, R:0.0105)
Batch 150/537: Loss=0.4276 (C:0.4276, R:0.0105)
Batch 175/537: Loss=0.4364 (C:0.4364, R:0.0105)
Batch 200/537: Loss=0.4304 (C:0.4304, R:0.0105)
Batch 225/537: Loss=0.4381 (C:0.4381, R:0.0105)
Batch 250/537: Loss=0.4478 (C:0.4478, R:0.0105)
Batch 275/537: Loss=0.4485 (C:0.4485, R:0.0105)
Batch 300/537: Loss=0.4238 (C:0.4238, R:0.0105)
Batch 325/537: Loss=0.4555 (C:0.4555, R:0.0105)
Batch 350/537: Loss=0.4461 (C:0.4461, R:0.0105)
Batch 375/537: Loss=0.4361 (C:0.4361, R:0.0105)
Batch 400/537: Loss=0.4301 (C:0.4301, R:0.0105)
Batch 425/537: Loss=0.4451 (C:0.4451, R:0.0105)
Batch 450/537: Loss=0.4261 (C:0.4261, R:0.0105)
Batch 475/537: Loss=0.4499 (C:0.4499, R:0.0105)
Batch 500/537: Loss=0.4429 (C:0.4429, R:0.0105)
Batch 525/537: Loss=0.4325 (C:0.4325, R:0.0105)

============================================================
Epoch 19/300 completed in 27.6s
Train: Loss=0.4359 (C:0.4359, R:0.0105) Ratio=3.71x
Val:   Loss=0.4718 (C:0.4718, R:0.0104) Ratio=3.01x
Reconstruction weight: 0.000
No improvement for 3 epochs
============================================================

Epoch 20 Training
----------------------------------------
Batch   0/537: Loss=0.4203 (C:0.4203, R:0.0105)
Batch  25/537: Loss=0.4169 (C:0.4169, R:0.0105)
Batch  50/537: Loss=0.4179 (C:0.4179, R:0.0105)
Batch  75/537: Loss=0.4364 (C:0.4364, R:0.0105)
Batch 100/537: Loss=0.4426 (C:0.4426, R:0.0105)
Batch 125/537: Loss=0.4037 (C:0.4037, R:0.0105)
Batch 150/537: Loss=0.4144 (C:0.4144, R:0.0105)
Batch 175/537: Loss=0.4140 (C:0.4140, R:0.0105)
Batch 200/537: Loss=0.4403 (C:0.4403, R:0.0105)
Batch 225/537: Loss=0.4124 (C:0.4124, R:0.0105)
Batch 250/537: Loss=0.4253 (C:0.4253, R:0.0105)
Batch 275/537: Loss=0.4246 (C:0.4246, R:0.0105)
Batch 300/537: Loss=0.4299 (C:0.4299, R:0.0105)
Batch 325/537: Loss=0.4346 (C:0.4346, R:0.0105)
Batch 350/537: Loss=0.4389 (C:0.4389, R:0.0105)
Batch 375/537: Loss=0.4453 (C:0.4453, R:0.0105)
Batch 400/537: Loss=0.4470 (C:0.4470, R:0.0105)
Batch 425/537: Loss=0.4494 (C:0.4494, R:0.0105)
Batch 450/537: Loss=0.4434 (C:0.4434, R:0.0105)
Batch 475/537: Loss=0.4286 (C:0.4286, R:0.0105)
Batch 500/537: Loss=0.4344 (C:0.4344, R:0.0105)
Batch 525/537: Loss=0.4422 (C:0.4422, R:0.0105)

============================================================
Epoch 20/300 completed in 21.4s
Train: Loss=0.4334 (C:0.4334, R:0.0105) Ratio=3.81x
Val:   Loss=0.4752 (C:0.4752, R:0.0104) Ratio=3.02x
Reconstruction weight: 0.000
No improvement for 4 epochs
Checkpoint saved at epoch 20
============================================================

Epoch 21 Training
----------------------------------------
Batch   0/537: Loss=0.4181 (C:0.4181, R:0.0105)
Batch  25/537: Loss=0.4439 (C:0.4439, R:0.0105)
Batch  50/537: Loss=0.4385 (C:0.4385, R:0.0105)
Batch  75/537: Loss=0.4216 (C:0.4216, R:0.0105)
Batch 100/537: Loss=0.4257 (C:0.4257, R:0.0105)
Batch 125/537: Loss=0.4144 (C:0.4144, R:0.0105)
Batch 150/537: Loss=0.4604 (C:0.4604, R:0.0106)
Batch 175/537: Loss=0.4318 (C:0.4318, R:0.0105)
Batch 200/537: Loss=0.4271 (C:0.4271, R:0.0105)
Batch 225/537: Loss=0.4255 (C:0.4255, R:0.0105)
Batch 250/537: Loss=0.4149 (C:0.4149, R:0.0105)
Batch 275/537: Loss=0.4378 (C:0.4378, R:0.0105)
Batch 300/537: Loss=0.4334 (C:0.4334, R:0.0105)
Batch 325/537: Loss=0.4411 (C:0.4411, R:0.0106)
Batch 350/537: Loss=0.4504 (C:0.4504, R:0.0105)
Batch 375/537: Loss=0.4432 (C:0.4432, R:0.0105)
Batch 400/537: Loss=0.4330 (C:0.4330, R:0.0105)
Batch 425/537: Loss=0.4459 (C:0.4459, R:0.0105)
Batch 450/537: Loss=0.4432 (C:0.4432, R:0.0105)
Batch 475/537: Loss=0.4214 (C:0.4214, R:0.0105)
Batch 500/537: Loss=0.4336 (C:0.4336, R:0.0106)
Batch 525/537: Loss=0.4306 (C:0.4306, R:0.0105)

============================================================
Epoch 21/300 completed in 21.7s
Train: Loss=0.4317 (C:0.4317, R:0.0105) Ratio=3.81x
Val:   Loss=0.4721 (C:0.4721, R:0.0104) Ratio=3.03x
Reconstruction weight: 0.000
No improvement for 5 epochs
============================================================

🌍 Updating global dataset at epoch 22
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.208 ± 0.288
    Neg distances: 1.045 ± 0.474
    Separation ratio: 5.03x
    Gap: -1.828
    ✅ Excellent global separation!

Epoch 22 Training
----------------------------------------
Batch   0/537: Loss=0.4127 (C:0.4127, R:0.0105)
Batch  25/537: Loss=0.3976 (C:0.3976, R:0.0105)
Batch  50/537: Loss=0.4202 (C:0.4202, R:0.0105)
Batch  75/537: Loss=0.4034 (C:0.4034, R:0.0105)
Batch 100/537: Loss=0.4010 (C:0.4010, R:0.0105)
Batch 125/537: Loss=0.4333 (C:0.4333, R:0.0105)
Batch 150/537: Loss=0.4129 (C:0.4129, R:0.0105)
Batch 175/537: Loss=0.4280 (C:0.4280, R:0.0105)
Batch 200/537: Loss=0.4102 (C:0.4102, R:0.0105)
Batch 225/537: Loss=0.4045 (C:0.4045, R:0.0105)
Batch 250/537: Loss=0.4103 (C:0.4103, R:0.0105)
Batch 275/537: Loss=0.4088 (C:0.4088, R:0.0105)
Batch 300/537: Loss=0.4132 (C:0.4132, R:0.0105)
Batch 325/537: Loss=0.4288 (C:0.4288, R:0.0105)
Batch 350/537: Loss=0.4116 (C:0.4116, R:0.0105)
Batch 375/537: Loss=0.4404 (C:0.4404, R:0.0105)
Batch 400/537: Loss=0.4116 (C:0.4116, R:0.0105)
Batch 425/537: Loss=0.4123 (C:0.4123, R:0.0105)
Batch 450/537: Loss=0.4074 (C:0.4074, R:0.0105)
Batch 475/537: Loss=0.4124 (C:0.4124, R:0.0105)
Batch 500/537: Loss=0.4190 (C:0.4190, R:0.0105)
Batch 525/537: Loss=0.4243 (C:0.4243, R:0.0105)

============================================================
Epoch 22/300 completed in 28.0s
Train: Loss=0.4140 (C:0.4140, R:0.0105) Ratio=3.87x
Val:   Loss=0.4550 (C:0.4550, R:0.0104) Ratio=3.01x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4550)
============================================================

Epoch 23 Training
----------------------------------------
Batch   0/537: Loss=0.4000 (C:0.4000, R:0.0105)
Batch  25/537: Loss=0.4340 (C:0.4340, R:0.0105)
Batch  50/537: Loss=0.4044 (C:0.4044, R:0.0105)
Batch  75/537: Loss=0.4074 (C:0.4074, R:0.0105)
Batch 100/537: Loss=0.4160 (C:0.4160, R:0.0105)
Batch 125/537: Loss=0.4072 (C:0.4072, R:0.0106)
Batch 150/537: Loss=0.4293 (C:0.4293, R:0.0105)
Batch 175/537: Loss=0.4155 (C:0.4155, R:0.0105)
Batch 200/537: Loss=0.4019 (C:0.4019, R:0.0105)
Batch 225/537: Loss=0.4209 (C:0.4209, R:0.0105)
Batch 250/537: Loss=0.3939 (C:0.3939, R:0.0105)
Batch 275/537: Loss=0.4096 (C:0.4096, R:0.0105)
Batch 300/537: Loss=0.4288 (C:0.4288, R:0.0105)
Batch 325/537: Loss=0.3965 (C:0.3965, R:0.0105)
Batch 350/537: Loss=0.4336 (C:0.4336, R:0.0105)
Batch 375/537: Loss=0.4151 (C:0.4151, R:0.0105)
Batch 400/537: Loss=0.3910 (C:0.3910, R:0.0105)
Batch 425/537: Loss=0.4200 (C:0.4200, R:0.0105)
Batch 450/537: Loss=0.4235 (C:0.4235, R:0.0105)
Batch 475/537: Loss=0.3974 (C:0.3974, R:0.0105)
Batch 500/537: Loss=0.4075 (C:0.4075, R:0.0105)
Batch 525/537: Loss=0.4082 (C:0.4082, R:0.0105)

============================================================
Epoch 23/300 completed in 22.7s
Train: Loss=0.4115 (C:0.4115, R:0.0105) Ratio=3.90x
Val:   Loss=0.4566 (C:0.4566, R:0.0104) Ratio=3.01x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

Epoch 24 Training
----------------------------------------
Batch   0/537: Loss=0.4095 (C:0.4095, R:0.0106)
Batch  25/537: Loss=0.4057 (C:0.4057, R:0.0105)
Batch  50/537: Loss=0.3954 (C:0.3954, R:0.0105)
Batch  75/537: Loss=0.3905 (C:0.3905, R:0.0105)
Batch 100/537: Loss=0.4137 (C:0.4137, R:0.0105)
Batch 125/537: Loss=0.4008 (C:0.4008, R:0.0105)
Batch 150/537: Loss=0.4175 (C:0.4175, R:0.0105)
Batch 175/537: Loss=0.3932 (C:0.3932, R:0.0106)
Batch 200/537: Loss=0.4180 (C:0.4180, R:0.0105)
Batch 225/537: Loss=0.4139 (C:0.4139, R:0.0105)
Batch 250/537: Loss=0.4010 (C:0.4010, R:0.0105)
Batch 275/537: Loss=0.4135 (C:0.4135, R:0.0105)
Batch 300/537: Loss=0.4075 (C:0.4075, R:0.0105)
Batch 325/537: Loss=0.4168 (C:0.4168, R:0.0105)
Batch 350/537: Loss=0.4247 (C:0.4247, R:0.0105)
Batch 375/537: Loss=0.4256 (C:0.4256, R:0.0105)
Batch 400/537: Loss=0.4101 (C:0.4101, R:0.0105)
Batch 425/537: Loss=0.4102 (C:0.4102, R:0.0105)
Batch 450/537: Loss=0.4196 (C:0.4196, R:0.0105)
Batch 475/537: Loss=0.4158 (C:0.4158, R:0.0105)
Batch 500/537: Loss=0.3986 (C:0.3986, R:0.0105)
Batch 525/537: Loss=0.4070 (C:0.4070, R:0.0105)

============================================================
Epoch 24/300 completed in 22.4s
Train: Loss=0.4110 (C:0.4110, R:0.0105) Ratio=3.95x
Val:   Loss=0.4490 (C:0.4490, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4490)
============================================================

🌍 Updating global dataset at epoch 25
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.201 ± 0.274
    Neg distances: 1.097 ± 0.492
    Separation ratio: 5.46x
    Gap: -1.895
    ✅ Excellent global separation!

Epoch 25 Training
----------------------------------------
Batch   0/537: Loss=0.3835 (C:0.3835, R:0.0105)
Batch  25/537: Loss=0.3805 (C:0.3805, R:0.0105)
Batch  50/537: Loss=0.3817 (C:0.3817, R:0.0105)
Batch  75/537: Loss=0.3860 (C:0.3860, R:0.0105)
Batch 100/537: Loss=0.3879 (C:0.3879, R:0.0105)
Batch 125/537: Loss=0.3939 (C:0.3939, R:0.0105)
Batch 150/537: Loss=0.3935 (C:0.3935, R:0.0106)
Batch 175/537: Loss=0.3803 (C:0.3803, R:0.0105)
Batch 200/537: Loss=0.3919 (C:0.3919, R:0.0105)
Batch 225/537: Loss=0.4003 (C:0.4003, R:0.0105)
Batch 250/537: Loss=0.3939 (C:0.3939, R:0.0105)
Batch 275/537: Loss=0.3913 (C:0.3913, R:0.0106)
Batch 300/537: Loss=0.3997 (C:0.3997, R:0.0105)
Batch 325/537: Loss=0.3974 (C:0.3974, R:0.0105)
Batch 350/537: Loss=0.3956 (C:0.3956, R:0.0105)
Batch 375/537: Loss=0.3870 (C:0.3870, R:0.0105)
Batch 400/537: Loss=0.3928 (C:0.3928, R:0.0105)
Batch 425/537: Loss=0.3680 (C:0.3680, R:0.0105)
Batch 450/537: Loss=0.4042 (C:0.4042, R:0.0105)
Batch 475/537: Loss=0.3783 (C:0.3783, R:0.0105)
Batch 500/537: Loss=0.3970 (C:0.3970, R:0.0105)
Batch 525/537: Loss=0.4055 (C:0.4055, R:0.0105)

============================================================
Epoch 25/300 completed in 27.7s
Train: Loss=0.3920 (C:0.3920, R:0.0105) Ratio=4.01x
Val:   Loss=0.4346 (C:0.4346, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4346)
============================================================

Epoch 26 Training
----------------------------------------
Batch   0/537: Loss=0.3686 (C:0.3686, R:0.0105)
Batch  25/537: Loss=0.3907 (C:0.3907, R:0.0105)
Batch  50/537: Loss=0.3824 (C:0.3824, R:0.0105)
Batch  75/537: Loss=0.3975 (C:0.3975, R:0.0105)
Batch 100/537: Loss=0.3823 (C:0.3823, R:0.0105)
Batch 125/537: Loss=0.3918 (C:0.3918, R:0.0105)
Batch 150/537: Loss=0.3931 (C:0.3931, R:0.0105)
Batch 175/537: Loss=0.3884 (C:0.3884, R:0.0105)
Batch 200/537: Loss=0.3947 (C:0.3947, R:0.0105)
Batch 225/537: Loss=0.3951 (C:0.3951, R:0.0105)
Batch 250/537: Loss=0.3729 (C:0.3729, R:0.0105)
Batch 275/537: Loss=0.3991 (C:0.3991, R:0.0105)
Batch 300/537: Loss=0.3902 (C:0.3902, R:0.0105)
Batch 325/537: Loss=0.3911 (C:0.3911, R:0.0105)
Batch 350/537: Loss=0.3913 (C:0.3913, R:0.0105)
Batch 375/537: Loss=0.3902 (C:0.3902, R:0.0105)
Batch 400/537: Loss=0.3932 (C:0.3932, R:0.0105)
Batch 425/537: Loss=0.4235 (C:0.4235, R:0.0105)
Batch 450/537: Loss=0.3756 (C:0.3756, R:0.0105)
Batch 475/537: Loss=0.4110 (C:0.4110, R:0.0105)
Batch 500/537: Loss=0.3914 (C:0.3914, R:0.0105)
Batch 525/537: Loss=0.3760 (C:0.3760, R:0.0105)

============================================================
Epoch 26/300 completed in 22.3s
Train: Loss=0.3911 (C:0.3911, R:0.0105) Ratio=4.01x
Val:   Loss=0.4355 (C:0.4355, R:0.0104) Ratio=3.03x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

Epoch 27 Training
----------------------------------------
Batch   0/537: Loss=0.4014 (C:0.4014, R:0.0105)
Batch  25/537: Loss=0.3891 (C:0.3891, R:0.0105)
Batch  50/537: Loss=0.3971 (C:0.3971, R:0.0105)
Batch  75/537: Loss=0.3791 (C:0.3791, R:0.0105)
Batch 100/537: Loss=0.3799 (C:0.3799, R:0.0105)
Batch 125/537: Loss=0.3855 (C:0.3855, R:0.0105)
Batch 150/537: Loss=0.3691 (C:0.3691, R:0.0105)
Batch 175/537: Loss=0.3902 (C:0.3902, R:0.0105)
Batch 200/537: Loss=0.4124 (C:0.4124, R:0.0105)
Batch 225/537: Loss=0.3898 (C:0.3898, R:0.0105)
Batch 250/537: Loss=0.3900 (C:0.3900, R:0.0105)
Batch 275/537: Loss=0.4047 (C:0.4047, R:0.0105)
Batch 300/537: Loss=0.3759 (C:0.3759, R:0.0105)
Batch 325/537: Loss=0.3772 (C:0.3772, R:0.0105)
Batch 350/537: Loss=0.3807 (C:0.3807, R:0.0105)
Batch 375/537: Loss=0.4029 (C:0.4029, R:0.0105)
Batch 400/537: Loss=0.4028 (C:0.4028, R:0.0105)
Batch 425/537: Loss=0.3880 (C:0.3880, R:0.0105)
Batch 450/537: Loss=0.3990 (C:0.3990, R:0.0105)
Batch 475/537: Loss=0.4058 (C:0.4058, R:0.0105)
Batch 500/537: Loss=0.3996 (C:0.3996, R:0.0105)
Batch 525/537: Loss=0.3851 (C:0.3851, R:0.0105)

============================================================
Epoch 27/300 completed in 22.1s
Train: Loss=0.3889 (C:0.3889, R:0.0105) Ratio=4.01x
Val:   Loss=0.4310 (C:0.4310, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4310)
============================================================

🌍 Updating global dataset at epoch 28
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.200 ± 0.285
    Neg distances: 1.133 ± 0.503
    Separation ratio: 5.65x
    Gap: -1.950
    ✅ Excellent global separation!

Epoch 28 Training
----------------------------------------
Batch   0/537: Loss=0.3773 (C:0.3773, R:0.0105)
Batch  25/537: Loss=0.3744 (C:0.3744, R:0.0105)
Batch  50/537: Loss=0.3650 (C:0.3650, R:0.0105)
Batch  75/537: Loss=0.3801 (C:0.3801, R:0.0105)
Batch 100/537: Loss=0.3671 (C:0.3671, R:0.0105)
Batch 125/537: Loss=0.3722 (C:0.3722, R:0.0105)
Batch 150/537: Loss=0.3763 (C:0.3763, R:0.0105)
Batch 175/537: Loss=0.3785 (C:0.3785, R:0.0105)
Batch 200/537: Loss=0.3746 (C:0.3746, R:0.0105)
Batch 225/537: Loss=0.3809 (C:0.3809, R:0.0105)
Batch 250/537: Loss=0.3659 (C:0.3659, R:0.0105)
Batch 275/537: Loss=0.3875 (C:0.3875, R:0.0105)
Batch 300/537: Loss=0.3753 (C:0.3753, R:0.0105)
Batch 325/537: Loss=0.3851 (C:0.3851, R:0.0105)
Batch 350/537: Loss=0.3805 (C:0.3805, R:0.0105)
Batch 375/537: Loss=0.3518 (C:0.3518, R:0.0105)
Batch 400/537: Loss=0.3720 (C:0.3720, R:0.0105)
Batch 425/537: Loss=0.3686 (C:0.3686, R:0.0105)
Batch 450/537: Loss=0.3623 (C:0.3623, R:0.0106)
Batch 475/537: Loss=0.3593 (C:0.3593, R:0.0105)
Batch 500/537: Loss=0.3764 (C:0.3764, R:0.0105)
Batch 525/537: Loss=0.3644 (C:0.3644, R:0.0105)

============================================================
Epoch 28/300 completed in 28.5s
Train: Loss=0.3781 (C:0.3781, R:0.0105) Ratio=4.16x
Val:   Loss=0.4285 (C:0.4285, R:0.0104) Ratio=3.02x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4285)
============================================================

Epoch 29 Training
----------------------------------------
Batch   0/537: Loss=0.3639 (C:0.3639, R:0.0105)
Batch  25/537: Loss=0.3836 (C:0.3836, R:0.0105)
Batch  50/537: Loss=0.3755 (C:0.3755, R:0.0105)
Batch  75/537: Loss=0.3788 (C:0.3788, R:0.0105)
Batch 100/537: Loss=0.3752 (C:0.3752, R:0.0105)
Batch 125/537: Loss=0.3698 (C:0.3698, R:0.0105)
Batch 150/537: Loss=0.3789 (C:0.3789, R:0.0105)
Batch 175/537: Loss=0.3628 (C:0.3628, R:0.0105)
Batch 200/537: Loss=0.3761 (C:0.3761, R:0.0105)
Batch 225/537: Loss=0.3679 (C:0.3679, R:0.0105)
Batch 250/537: Loss=0.3700 (C:0.3700, R:0.0105)
Batch 275/537: Loss=0.3688 (C:0.3688, R:0.0105)
Batch 300/537: Loss=0.3780 (C:0.3780, R:0.0105)
Batch 325/537: Loss=0.3813 (C:0.3813, R:0.0105)
Batch 350/537: Loss=0.3733 (C:0.3733, R:0.0105)
Batch 375/537: Loss=0.3931 (C:0.3931, R:0.0105)
Batch 400/537: Loss=0.3786 (C:0.3786, R:0.0105)
Batch 425/537: Loss=0.3920 (C:0.3920, R:0.0105)
Batch 450/537: Loss=0.3857 (C:0.3857, R:0.0105)
Batch 475/537: Loss=0.3909 (C:0.3909, R:0.0105)
Batch 500/537: Loss=0.3826 (C:0.3826, R:0.0105)
Batch 525/537: Loss=0.3579 (C:0.3579, R:0.0105)

============================================================
Epoch 29/300 completed in 21.7s
Train: Loss=0.3766 (C:0.3766, R:0.0105) Ratio=4.12x
Val:   Loss=0.4248 (C:0.4248, R:0.0104) Ratio=3.03x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4248)
============================================================

Epoch 30 Training
----------------------------------------
Batch   0/537: Loss=0.3820 (C:0.3820, R:0.0105)
Batch  25/537: Loss=0.3669 (C:0.3669, R:0.0105)
Batch  50/537: Loss=0.3653 (C:0.3653, R:0.0105)
Batch  75/537: Loss=0.3663 (C:0.3663, R:0.0105)
Batch 100/537: Loss=0.3798 (C:0.3798, R:0.0105)
Batch 125/537: Loss=0.3853 (C:0.3853, R:0.0105)
Batch 150/537: Loss=0.3790 (C:0.3790, R:0.0105)
Batch 175/537: Loss=0.3863 (C:0.3863, R:0.0105)
Batch 200/537: Loss=0.3789 (C:0.3789, R:0.0105)
Batch 225/537: Loss=0.3721 (C:0.3721, R:0.0106)
Batch 250/537: Loss=0.3726 (C:0.3726, R:0.0105)
Batch 275/537: Loss=0.3918 (C:0.3918, R:0.0105)
Batch 300/537: Loss=0.3702 (C:0.3702, R:0.0105)
Batch 325/537: Loss=0.3831 (C:0.3831, R:0.0105)
Batch 350/537: Loss=0.3877 (C:0.3877, R:0.0105)
Batch 375/537: Loss=0.3838 (C:0.3838, R:0.0105)
Batch 400/537: Loss=0.3712 (C:0.3712, R:0.0105)
Batch 425/537: Loss=0.3932 (C:0.3932, R:0.0105)
Batch 450/537: Loss=0.3822 (C:0.3822, R:0.0105)
Batch 475/537: Loss=0.3739 (C:0.3739, R:0.0105)
Batch 500/537: Loss=0.3708 (C:0.3708, R:0.0105)
Batch 525/537: Loss=0.3694 (C:0.3694, R:0.0105)

============================================================
Epoch 30/300 completed in 21.7s
Train: Loss=0.3745 (C:0.3745, R:0.0105) Ratio=4.13x
Val:   Loss=0.4225 (C:0.4225, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4225)
============================================================

🌍 Updating global dataset at epoch 31
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.195 ± 0.283
    Neg distances: 1.163 ± 0.510
    Separation ratio: 5.97x
    Gap: -2.017
    ✅ Excellent global separation!

Epoch 31 Training
----------------------------------------
Batch   0/537: Loss=0.3637 (C:0.3637, R:0.0105)
Batch  25/537: Loss=0.3600 (C:0.3600, R:0.0105)
Batch  50/537: Loss=0.3580 (C:0.3580, R:0.0105)
Batch  75/537: Loss=0.3427 (C:0.3427, R:0.0106)
Batch 100/537: Loss=0.3549 (C:0.3549, R:0.0105)
Batch 125/537: Loss=0.3440 (C:0.3440, R:0.0105)
Batch 150/537: Loss=0.3571 (C:0.3571, R:0.0105)
Batch 175/537: Loss=0.3678 (C:0.3678, R:0.0105)
Batch 200/537: Loss=0.3537 (C:0.3537, R:0.0105)
Batch 225/537: Loss=0.3742 (C:0.3742, R:0.0105)
Batch 250/537: Loss=0.3698 (C:0.3698, R:0.0105)
Batch 275/537: Loss=0.3701 (C:0.3701, R:0.0105)
Batch 300/537: Loss=0.3565 (C:0.3565, R:0.0105)
Batch 325/537: Loss=0.3572 (C:0.3572, R:0.0105)
Batch 350/537: Loss=0.3594 (C:0.3594, R:0.0105)
Batch 375/537: Loss=0.3736 (C:0.3736, R:0.0105)
Batch 400/537: Loss=0.3771 (C:0.3771, R:0.0105)
Batch 425/537: Loss=0.3664 (C:0.3664, R:0.0105)
Batch 450/537: Loss=0.3559 (C:0.3559, R:0.0105)
Batch 475/537: Loss=0.3690 (C:0.3690, R:0.0105)
Batch 500/537: Loss=0.3585 (C:0.3585, R:0.0105)
Batch 525/537: Loss=0.3857 (C:0.3857, R:0.0105)

============================================================
Epoch 31/300 completed in 27.6s
Train: Loss=0.3612 (C:0.3612, R:0.0105) Ratio=4.19x
Val:   Loss=0.4091 (C:0.4091, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.015
✅ New best model saved (Val Loss: 0.4091)
============================================================

Epoch 32 Training
----------------------------------------
Batch   0/537: Loss=0.3510 (C:0.3510, R:0.0105)
Batch  25/537: Loss=0.3712 (C:0.3712, R:0.0105)
Batch  50/537: Loss=0.3439 (C:0.3439, R:0.0106)
Batch  75/537: Loss=0.3701 (C:0.3701, R:0.0105)
Batch 100/537: Loss=0.3551 (C:0.3551, R:0.0105)
Batch 125/537: Loss=0.3511 (C:0.3511, R:0.0105)
Batch 150/537: Loss=0.3371 (C:0.3371, R:0.0105)
Batch 175/537: Loss=0.3569 (C:0.3569, R:0.0105)
Batch 200/537: Loss=0.3583 (C:0.3583, R:0.0105)
Batch 225/537: Loss=0.3576 (C:0.3576, R:0.0105)
Batch 250/537: Loss=0.3704 (C:0.3704, R:0.0105)
Batch 275/537: Loss=0.3543 (C:0.3543, R:0.0105)
Batch 300/537: Loss=0.3599 (C:0.3599, R:0.0105)
Batch 325/537: Loss=0.3468 (C:0.3468, R:0.0105)
Batch 350/537: Loss=0.3645 (C:0.3645, R:0.0105)
Batch 375/537: Loss=0.3685 (C:0.3685, R:0.0105)
Batch 400/537: Loss=0.3528 (C:0.3528, R:0.0105)
Batch 425/537: Loss=0.3574 (C:0.3574, R:0.0105)
Batch 450/537: Loss=0.3592 (C:0.3592, R:0.0105)
Batch 475/537: Loss=0.3413 (C:0.3413, R:0.0105)
Batch 500/537: Loss=0.3450 (C:0.3450, R:0.0105)
Batch 525/537: Loss=0.3632 (C:0.3632, R:0.0105)

============================================================
Epoch 32/300 completed in 21.7s
Train: Loss=0.3590 (C:0.3590, R:0.0105) Ratio=4.26x
Val:   Loss=0.4165 (C:0.4165, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.030
No improvement for 1 epochs
============================================================

Epoch 33 Training
----------------------------------------
Batch   0/537: Loss=0.3534 (C:0.3534, R:0.0105)
Batch  25/537: Loss=0.3508 (C:0.3508, R:0.0105)
Batch  50/537: Loss=0.3503 (C:0.3503, R:0.0105)
Batch  75/537: Loss=0.3555 (C:0.3555, R:0.0105)
Batch 100/537: Loss=0.3671 (C:0.3671, R:0.0105)
Batch 125/537: Loss=0.3401 (C:0.3401, R:0.0105)
Batch 150/537: Loss=0.3556 (C:0.3556, R:0.0105)
Batch 175/537: Loss=0.3415 (C:0.3415, R:0.0105)
Batch 200/537: Loss=0.3603 (C:0.3603, R:0.0106)
Batch 225/537: Loss=0.3631 (C:0.3631, R:0.0105)
Batch 250/537: Loss=0.3590 (C:0.3590, R:0.0105)
Batch 275/537: Loss=0.3471 (C:0.3471, R:0.0105)
Batch 300/537: Loss=0.3443 (C:0.3443, R:0.0105)
Batch 325/537: Loss=0.3491 (C:0.3491, R:0.0105)
Batch 350/537: Loss=0.3466 (C:0.3466, R:0.0105)
Batch 375/537: Loss=0.3625 (C:0.3625, R:0.0105)
Batch 400/537: Loss=0.3573 (C:0.3573, R:0.0105)
Batch 425/537: Loss=0.3494 (C:0.3494, R:0.0105)
Batch 450/537: Loss=0.3626 (C:0.3626, R:0.0105)
Batch 475/537: Loss=0.3616 (C:0.3616, R:0.0105)
Batch 500/537: Loss=0.3456 (C:0.3456, R:0.0105)
Batch 525/537: Loss=0.3629 (C:0.3629, R:0.0105)

============================================================
Epoch 33/300 completed in 22.1s
Train: Loss=0.3577 (C:0.3577, R:0.0105) Ratio=4.37x
Val:   Loss=0.4085 (C:0.4085, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.045
✅ New best model saved (Val Loss: 0.4085)
============================================================

🌍 Updating global dataset at epoch 34
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.184 ± 0.287
    Neg distances: 1.198 ± 0.516
    Separation ratio: 6.50x
    Gap: -2.104
    ✅ Excellent global separation!

Epoch 34 Training
----------------------------------------
Batch   0/537: Loss=0.3192 (C:0.3192, R:0.0105)
Batch  25/537: Loss=0.3318 (C:0.3318, R:0.0105)
Batch  50/537: Loss=0.3469 (C:0.3469, R:0.0105)
Batch  75/537: Loss=0.3345 (C:0.3345, R:0.0105)
Batch 100/537: Loss=0.3487 (C:0.3487, R:0.0105)
Batch 125/537: Loss=0.3384 (C:0.3384, R:0.0105)
Batch 150/537: Loss=0.3542 (C:0.3542, R:0.0105)
Batch 175/537: Loss=0.3485 (C:0.3485, R:0.0105)
Batch 200/537: Loss=0.3543 (C:0.3543, R:0.0105)
Batch 225/537: Loss=0.3497 (C:0.3497, R:0.0105)
Batch 250/537: Loss=0.3570 (C:0.3570, R:0.0105)
Batch 275/537: Loss=0.3533 (C:0.3533, R:0.0105)
Batch 300/537: Loss=0.3464 (C:0.3464, R:0.0105)
Batch 325/537: Loss=0.3343 (C:0.3343, R:0.0105)
Batch 350/537: Loss=0.3336 (C:0.3336, R:0.0105)
Batch 375/537: Loss=0.3358 (C:0.3358, R:0.0105)
Batch 400/537: Loss=0.3455 (C:0.3455, R:0.0105)
Batch 425/537: Loss=0.3405 (C:0.3405, R:0.0105)
Batch 450/537: Loss=0.3397 (C:0.3397, R:0.0105)
Batch 475/537: Loss=0.3452 (C:0.3452, R:0.0105)
Batch 500/537: Loss=0.3424 (C:0.3424, R:0.0105)
Batch 525/537: Loss=0.3423 (C:0.3423, R:0.0105)

============================================================
Epoch 34/300 completed in 27.7s
Train: Loss=0.3426 (C:0.3426, R:0.0105) Ratio=4.30x
Val:   Loss=0.3981 (C:0.3981, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.060
✅ New best model saved (Val Loss: 0.3981)
============================================================

Epoch 35 Training
----------------------------------------
Batch   0/537: Loss=0.3393 (C:0.3393, R:0.0105)
Batch  25/537: Loss=0.3429 (C:0.3429, R:0.0105)
Batch  50/537: Loss=0.3223 (C:0.3223, R:0.0105)
Batch  75/537: Loss=0.3444 (C:0.3444, R:0.0105)
Batch 100/537: Loss=0.3508 (C:0.3508, R:0.0105)
Batch 125/537: Loss=0.3425 (C:0.3425, R:0.0105)
Batch 150/537: Loss=0.3492 (C:0.3492, R:0.0105)
Batch 175/537: Loss=0.3218 (C:0.3218, R:0.0105)
Batch 200/537: Loss=0.3421 (C:0.3421, R:0.0105)
Batch 225/537: Loss=0.3336 (C:0.3336, R:0.0105)
Batch 250/537: Loss=0.3504 (C:0.3504, R:0.0105)
Batch 275/537: Loss=0.3438 (C:0.3438, R:0.0105)
Batch 300/537: Loss=0.3307 (C:0.3307, R:0.0105)
Batch 325/537: Loss=0.3425 (C:0.3425, R:0.0105)
Batch 350/537: Loss=0.3380 (C:0.3380, R:0.0105)
Batch 375/537: Loss=0.3544 (C:0.3544, R:0.0105)
Batch 400/537: Loss=0.3397 (C:0.3397, R:0.0105)
Batch 425/537: Loss=0.3302 (C:0.3302, R:0.0105)
Batch 450/537: Loss=0.3373 (C:0.3373, R:0.0105)
Batch 475/537: Loss=0.3568 (C:0.3568, R:0.0105)
Batch 500/537: Loss=0.3524 (C:0.3524, R:0.0105)
Batch 525/537: Loss=0.3441 (C:0.3441, R:0.0105)

============================================================
Epoch 35/300 completed in 21.4s
Train: Loss=0.3414 (C:0.3414, R:0.0105) Ratio=4.31x
Val:   Loss=0.3980 (C:0.3980, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.075
✅ New best model saved (Val Loss: 0.3980)
============================================================

Epoch 36 Training
----------------------------------------
Batch   0/537: Loss=0.3304 (C:0.3304, R:0.0105)
Batch  25/537: Loss=0.3434 (C:0.3434, R:0.0105)
Batch  50/537: Loss=0.3302 (C:0.3302, R:0.0105)
Batch  75/537: Loss=0.3474 (C:0.3474, R:0.0105)
Batch 100/537: Loss=0.3340 (C:0.3340, R:0.0105)
Batch 125/537: Loss=0.3464 (C:0.3464, R:0.0105)
Batch 150/537: Loss=0.3372 (C:0.3372, R:0.0105)
Batch 175/537: Loss=0.3348 (C:0.3348, R:0.0105)
Batch 200/537: Loss=0.3302 (C:0.3302, R:0.0106)
Batch 225/537: Loss=0.3348 (C:0.3348, R:0.0105)
Batch 250/537: Loss=0.3329 (C:0.3329, R:0.0105)
Batch 275/537: Loss=0.3468 (C:0.3468, R:0.0105)
Batch 300/537: Loss=0.3389 (C:0.3389, R:0.0105)
Batch 325/537: Loss=0.3614 (C:0.3614, R:0.0105)
Batch 350/537: Loss=0.3428 (C:0.3428, R:0.0105)
Batch 375/537: Loss=0.3411 (C:0.3411, R:0.0105)
Batch 400/537: Loss=0.3293 (C:0.3293, R:0.0105)
Batch 425/537: Loss=0.3354 (C:0.3354, R:0.0105)
Batch 450/537: Loss=0.3456 (C:0.3456, R:0.0105)
Batch 475/537: Loss=0.3389 (C:0.3389, R:0.0105)
Batch 500/537: Loss=0.3572 (C:0.3572, R:0.0105)
Batch 525/537: Loss=0.3429 (C:0.3429, R:0.0105)

============================================================
Epoch 36/300 completed in 21.4s
Train: Loss=0.3398 (C:0.3398, R:0.0105) Ratio=4.34x
Val:   Loss=0.3980 (C:0.3980, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.090
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 37
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.188 ± 0.297
    Neg distances: 1.216 ± 0.527
    Separation ratio: 6.47x
    Gap: -2.077
    ✅ Excellent global separation!

Epoch 37 Training
----------------------------------------
Batch   0/537: Loss=0.3237 (C:0.3237, R:0.0105)
Batch  25/537: Loss=0.3267 (C:0.3267, R:0.0105)
Batch  50/537: Loss=0.3385 (C:0.3385, R:0.0105)
Batch  75/537: Loss=0.3306 (C:0.3306, R:0.0105)
Batch 100/537: Loss=0.3343 (C:0.3343, R:0.0105)
Batch 125/537: Loss=0.3211 (C:0.3211, R:0.0105)
Batch 150/537: Loss=0.3357 (C:0.3357, R:0.0105)
Batch 175/537: Loss=0.3419 (C:0.3419, R:0.0105)
Batch 200/537: Loss=0.3247 (C:0.3247, R:0.0105)
Batch 225/537: Loss=0.3455 (C:0.3455, R:0.0105)
Batch 250/537: Loss=0.3281 (C:0.3281, R:0.0105)
Batch 275/537: Loss=0.3378 (C:0.3378, R:0.0105)
Batch 300/537: Loss=0.3310 (C:0.3310, R:0.0106)
Batch 325/537: Loss=0.3453 (C:0.3453, R:0.0105)
Batch 350/537: Loss=0.3503 (C:0.3503, R:0.0105)
Batch 375/537: Loss=0.3326 (C:0.3326, R:0.0105)
Batch 400/537: Loss=0.3329 (C:0.3329, R:0.0105)
Batch 425/537: Loss=0.3361 (C:0.3361, R:0.0105)
Batch 450/537: Loss=0.3485 (C:0.3485, R:0.0106)
Batch 475/537: Loss=0.3292 (C:0.3292, R:0.0105)
Batch 500/537: Loss=0.3382 (C:0.3382, R:0.0105)
Batch 525/537: Loss=0.3321 (C:0.3321, R:0.0105)

============================================================
Epoch 37/300 completed in 27.8s
Train: Loss=0.3356 (C:0.3356, R:0.0105) Ratio=4.41x
Val:   Loss=0.3907 (C:0.3907, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.105
✅ New best model saved (Val Loss: 0.3907)
============================================================

Epoch 38 Training
----------------------------------------
Batch   0/537: Loss=0.3298 (C:0.3298, R:0.0106)
Batch  25/537: Loss=0.3341 (C:0.3341, R:0.0105)
Batch  50/537: Loss=0.3206 (C:0.3206, R:0.0105)
Batch  75/537: Loss=0.3250 (C:0.3250, R:0.0106)
Batch 100/537: Loss=0.3371 (C:0.3371, R:0.0105)
Batch 125/537: Loss=0.3427 (C:0.3427, R:0.0105)
Batch 150/537: Loss=0.3186 (C:0.3186, R:0.0105)
Batch 175/537: Loss=0.3126 (C:0.3126, R:0.0105)
Batch 200/537: Loss=0.3390 (C:0.3390, R:0.0105)
Batch 225/537: Loss=0.3333 (C:0.3333, R:0.0105)
Batch 250/537: Loss=0.3338 (C:0.3338, R:0.0105)
Batch 275/537: Loss=0.3447 (C:0.3447, R:0.0105)
Batch 300/537: Loss=0.3358 (C:0.3358, R:0.0105)
Batch 325/537: Loss=0.3353 (C:0.3353, R:0.0105)
Batch 350/537: Loss=0.3251 (C:0.3251, R:0.0105)
Batch 375/537: Loss=0.3585 (C:0.3585, R:0.0105)
Batch 400/537: Loss=0.3302 (C:0.3302, R:0.0105)
Batch 425/537: Loss=0.3321 (C:0.3321, R:0.0105)
Batch 450/537: Loss=0.3375 (C:0.3375, R:0.0105)
Batch 475/537: Loss=0.3348 (C:0.3348, R:0.0106)
Batch 500/537: Loss=0.3494 (C:0.3494, R:0.0105)
Batch 525/537: Loss=0.3384 (C:0.3384, R:0.0105)

============================================================
Epoch 38/300 completed in 21.8s
Train: Loss=0.3346 (C:0.3346, R:0.0105) Ratio=4.42x
Val:   Loss=0.3961 (C:0.3961, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.120
No improvement for 1 epochs
============================================================

Epoch 39 Training
----------------------------------------
Batch   0/537: Loss=0.3413 (C:0.3413, R:0.0105)
Batch  25/537: Loss=0.3448 (C:0.3448, R:0.0105)
Batch  50/537: Loss=0.3323 (C:0.3323, R:0.0105)
Batch  75/537: Loss=0.3118 (C:0.3118, R:0.0105)
Batch 100/537: Loss=0.3394 (C:0.3394, R:0.0105)
Batch 125/537: Loss=0.3351 (C:0.3351, R:0.0105)
Batch 150/537: Loss=0.3467 (C:0.3467, R:0.0105)
Batch 175/537: Loss=0.3258 (C:0.3258, R:0.0105)
Batch 200/537: Loss=0.3246 (C:0.3246, R:0.0105)
Batch 225/537: Loss=0.3380 (C:0.3380, R:0.0105)
Batch 250/537: Loss=0.3203 (C:0.3203, R:0.0105)
Batch 275/537: Loss=0.3227 (C:0.3227, R:0.0105)
Batch 300/537: Loss=0.3408 (C:0.3408, R:0.0105)
Batch 325/537: Loss=0.3367 (C:0.3367, R:0.0105)
Batch 350/537: Loss=0.3436 (C:0.3436, R:0.0105)
Batch 375/537: Loss=0.3526 (C:0.3526, R:0.0105)
Batch 400/537: Loss=0.3304 (C:0.3304, R:0.0105)
Batch 425/537: Loss=0.3445 (C:0.3445, R:0.0105)
Batch 450/537: Loss=0.3443 (C:0.3443, R:0.0105)
Batch 475/537: Loss=0.3347 (C:0.3347, R:0.0105)
Batch 500/537: Loss=0.3237 (C:0.3237, R:0.0105)
Batch 525/537: Loss=0.3358 (C:0.3358, R:0.0105)

============================================================
Epoch 39/300 completed in 21.3s
Train: Loss=0.3335 (C:0.3335, R:0.0105) Ratio=4.47x
Val:   Loss=0.3942 (C:0.3942, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.135
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 40
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.190 ± 0.297
    Neg distances: 1.240 ± 0.537
    Separation ratio: 6.52x
    Gap: -2.158
    ✅ Excellent global separation!

Epoch 40 Training
----------------------------------------
Batch   0/537: Loss=0.3252 (C:0.3252, R:0.0105)
Batch  25/537: Loss=0.3301 (C:0.3301, R:0.0105)
Batch  50/537: Loss=0.3109 (C:0.3109, R:0.0105)
Batch  75/537: Loss=0.3298 (C:0.3298, R:0.0105)
Batch 100/537: Loss=0.3261 (C:0.3261, R:0.0105)
Batch 125/537: Loss=0.3317 (C:0.3317, R:0.0105)
Batch 150/537: Loss=0.3342 (C:0.3342, R:0.0105)
Batch 175/537: Loss=0.3300 (C:0.3300, R:0.0105)
Batch 200/537: Loss=0.3215 (C:0.3215, R:0.0105)
Batch 225/537: Loss=0.3339 (C:0.3339, R:0.0105)
Batch 250/537: Loss=0.3395 (C:0.3395, R:0.0105)
Batch 275/537: Loss=0.3389 (C:0.3389, R:0.0105)
Batch 300/537: Loss=0.3362 (C:0.3362, R:0.0105)
Batch 325/537: Loss=0.3297 (C:0.3297, R:0.0105)
Batch 350/537: Loss=0.3320 (C:0.3320, R:0.0105)
Batch 375/537: Loss=0.3322 (C:0.3322, R:0.0106)
Batch 400/537: Loss=0.3343 (C:0.3343, R:0.0105)
Batch 425/537: Loss=0.3491 (C:0.3491, R:0.0105)
Batch 450/537: Loss=0.3429 (C:0.3429, R:0.0105)
Batch 475/537: Loss=0.3292 (C:0.3292, R:0.0105)
Batch 500/537: Loss=0.3250 (C:0.3250, R:0.0105)
Batch 525/537: Loss=0.3281 (C:0.3281, R:0.0105)

============================================================
Epoch 40/300 completed in 26.9s
Train: Loss=0.3296 (C:0.3296, R:0.0105) Ratio=4.45x
Val:   Loss=0.3944 (C:0.3944, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.150
No improvement for 3 epochs
Checkpoint saved at epoch 40
============================================================

Epoch 41 Training
----------------------------------------
Batch   0/537: Loss=0.3192 (C:0.3192, R:0.0105)
Batch  25/537: Loss=0.3331 (C:0.3331, R:0.0105)
Batch  50/537: Loss=0.3351 (C:0.3351, R:0.0105)
Batch  75/537: Loss=0.3244 (C:0.3244, R:0.0105)
Batch 100/537: Loss=0.3071 (C:0.3071, R:0.0105)
Batch 125/537: Loss=0.3327 (C:0.3327, R:0.0105)
Batch 150/537: Loss=0.3232 (C:0.3232, R:0.0105)
Batch 175/537: Loss=0.3240 (C:0.3240, R:0.0105)
Batch 200/537: Loss=0.3151 (C:0.3151, R:0.0105)
Batch 225/537: Loss=0.3329 (C:0.3329, R:0.0105)
Batch 250/537: Loss=0.3314 (C:0.3314, R:0.0105)
Batch 275/537: Loss=0.3339 (C:0.3339, R:0.0106)
Batch 300/537: Loss=0.3336 (C:0.3336, R:0.0105)
Batch 325/537: Loss=0.3451 (C:0.3451, R:0.0105)
Batch 350/537: Loss=0.3327 (C:0.3327, R:0.0105)
Batch 375/537: Loss=0.3427 (C:0.3427, R:0.0105)
Batch 400/537: Loss=0.3270 (C:0.3270, R:0.0105)
Batch 425/537: Loss=0.3204 (C:0.3204, R:0.0105)
Batch 450/537: Loss=0.3203 (C:0.3203, R:0.0105)
Batch 475/537: Loss=0.3291 (C:0.3291, R:0.0105)
Batch 500/537: Loss=0.3247 (C:0.3247, R:0.0105)
Batch 525/537: Loss=0.3373 (C:0.3373, R:0.0105)

============================================================
Epoch 41/300 completed in 21.1s
Train: Loss=0.3283 (C:0.3283, R:0.0105) Ratio=4.51x
Val:   Loss=0.3933 (C:0.3933, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.165
No improvement for 4 epochs
============================================================

Epoch 42 Training
----------------------------------------
Batch   0/537: Loss=0.3239 (C:0.3239, R:0.0105)
Batch  25/537: Loss=0.3008 (C:0.3008, R:0.0105)
Batch  50/537: Loss=0.3350 (C:0.3350, R:0.0105)
Batch  75/537: Loss=0.3415 (C:0.3415, R:0.0105)
Batch 100/537: Loss=0.3390 (C:0.3390, R:0.0105)
Batch 125/537: Loss=0.3181 (C:0.3181, R:0.0105)
Batch 150/537: Loss=0.3150 (C:0.3150, R:0.0105)
Batch 175/537: Loss=0.3211 (C:0.3211, R:0.0105)
Batch 200/537: Loss=0.3164 (C:0.3164, R:0.0105)
Batch 225/537: Loss=0.3297 (C:0.3297, R:0.0105)
Batch 250/537: Loss=0.3229 (C:0.3229, R:0.0105)
Batch 275/537: Loss=0.3322 (C:0.3322, R:0.0105)
Batch 300/537: Loss=0.3305 (C:0.3305, R:0.0105)
Batch 325/537: Loss=0.3080 (C:0.3080, R:0.0105)
Batch 350/537: Loss=0.3247 (C:0.3247, R:0.0105)
Batch 375/537: Loss=0.3189 (C:0.3189, R:0.0105)
Batch 400/537: Loss=0.3252 (C:0.3252, R:0.0105)
Batch 425/537: Loss=0.3401 (C:0.3401, R:0.0105)
Batch 450/537: Loss=0.3032 (C:0.3032, R:0.0105)
Batch 475/537: Loss=0.3372 (C:0.3372, R:0.0105)
Batch 500/537: Loss=0.3451 (C:0.3451, R:0.0105)
Batch 525/537: Loss=0.3155 (C:0.3155, R:0.0105)

============================================================
Epoch 42/300 completed in 21.6s
Train: Loss=0.3269 (C:0.3269, R:0.0105) Ratio=4.59x
Val:   Loss=0.3946 (C:0.3946, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.180
No improvement for 5 epochs
============================================================

🌍 Updating global dataset at epoch 43
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.176 ± 0.292
    Neg distances: 1.277 ± 0.539
    Separation ratio: 7.26x
    Gap: -2.197
    ✅ Excellent global separation!

Epoch 43 Training
----------------------------------------
Batch   0/537: Loss=0.3163 (C:0.3163, R:0.0106)
Batch  25/537: Loss=0.3346 (C:0.3346, R:0.0105)
Batch  50/537: Loss=0.3137 (C:0.3137, R:0.0106)
Batch  75/537: Loss=0.2890 (C:0.2890, R:0.0105)
Batch 100/537: Loss=0.3111 (C:0.3111, R:0.0105)
Batch 125/537: Loss=0.2988 (C:0.2988, R:0.0105)
Batch 150/537: Loss=0.2999 (C:0.2999, R:0.0105)
Batch 175/537: Loss=0.3260 (C:0.3260, R:0.0105)
Batch 200/537: Loss=0.3084 (C:0.3084, R:0.0105)
Batch 225/537: Loss=0.3172 (C:0.3172, R:0.0105)
Batch 250/537: Loss=0.2925 (C:0.2925, R:0.0105)
Batch 275/537: Loss=0.3177 (C:0.3177, R:0.0105)
Batch 300/537: Loss=0.3085 (C:0.3085, R:0.0105)
Batch 325/537: Loss=0.3083 (C:0.3083, R:0.0105)
Batch 350/537: Loss=0.3082 (C:0.3082, R:0.0105)
Batch 375/537: Loss=0.2959 (C:0.2959, R:0.0105)
Batch 400/537: Loss=0.3006 (C:0.3006, R:0.0105)
Batch 425/537: Loss=0.3172 (C:0.3172, R:0.0106)
Batch 450/537: Loss=0.3090 (C:0.3090, R:0.0105)
Batch 475/537: Loss=0.3265 (C:0.3265, R:0.0105)
Batch 500/537: Loss=0.2986 (C:0.2986, R:0.0105)
Batch 525/537: Loss=0.3049 (C:0.3049, R:0.0105)

============================================================
Epoch 43/300 completed in 27.5s
Train: Loss=0.3096 (C:0.3096, R:0.0105) Ratio=4.61x
Val:   Loss=0.3790 (C:0.3790, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.195
✅ New best model saved (Val Loss: 0.3790)
============================================================

Epoch 44 Training
----------------------------------------
Batch   0/537: Loss=0.2888 (C:0.2888, R:0.0105)
Batch  25/537: Loss=0.2924 (C:0.2924, R:0.0105)
Batch  50/537: Loss=0.3110 (C:0.3110, R:0.0105)
Batch  75/537: Loss=0.3021 (C:0.3021, R:0.0105)
Batch 100/537: Loss=0.3186 (C:0.3186, R:0.0105)
Batch 125/537: Loss=0.3060 (C:0.3060, R:0.0105)
Batch 150/537: Loss=0.3049 (C:0.3049, R:0.0105)
Batch 175/537: Loss=0.3096 (C:0.3096, R:0.0105)
Batch 200/537: Loss=0.3118 (C:0.3118, R:0.0105)
Batch 225/537: Loss=0.3120 (C:0.3120, R:0.0105)
Batch 250/537: Loss=0.2980 (C:0.2980, R:0.0105)
Batch 275/537: Loss=0.3027 (C:0.3027, R:0.0105)
Batch 300/537: Loss=0.3077 (C:0.3077, R:0.0105)
Batch 325/537: Loss=0.3342 (C:0.3342, R:0.0106)
Batch 350/537: Loss=0.3216 (C:0.3216, R:0.0105)
Batch 375/537: Loss=0.3013 (C:0.3013, R:0.0105)
Batch 400/537: Loss=0.3027 (C:0.3027, R:0.0105)
Batch 425/537: Loss=0.3202 (C:0.3202, R:0.0105)
Batch 450/537: Loss=0.3065 (C:0.3065, R:0.0105)
Batch 475/537: Loss=0.2946 (C:0.2946, R:0.0105)
Batch 500/537: Loss=0.3032 (C:0.3032, R:0.0106)
Batch 525/537: Loss=0.3029 (C:0.3029, R:0.0105)

============================================================
Epoch 44/300 completed in 21.2s
Train: Loss=0.3085 (C:0.3085, R:0.0105) Ratio=4.64x
Val:   Loss=0.3730 (C:0.3730, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.210
✅ New best model saved (Val Loss: 0.3730)
============================================================

Epoch 45 Training
----------------------------------------
Batch   0/537: Loss=0.3106 (C:0.3106, R:0.0105)
Batch  25/537: Loss=0.3169 (C:0.3169, R:0.0106)
Batch  50/537: Loss=0.2917 (C:0.2917, R:0.0105)
Batch  75/537: Loss=0.2952 (C:0.2952, R:0.0105)
Batch 100/537: Loss=0.3221 (C:0.3221, R:0.0105)
Batch 125/537: Loss=0.3088 (C:0.3088, R:0.0105)
Batch 150/537: Loss=0.3085 (C:0.3085, R:0.0105)
Batch 175/537: Loss=0.2920 (C:0.2920, R:0.0105)
Batch 200/537: Loss=0.3021 (C:0.3021, R:0.0105)
Batch 225/537: Loss=0.3076 (C:0.3076, R:0.0105)
Batch 250/537: Loss=0.3228 (C:0.3228, R:0.0105)
Batch 275/537: Loss=0.3049 (C:0.3049, R:0.0105)
Batch 300/537: Loss=0.3131 (C:0.3131, R:0.0105)
Batch 325/537: Loss=0.2901 (C:0.2901, R:0.0105)
Batch 350/537: Loss=0.3207 (C:0.3207, R:0.0106)
Batch 375/537: Loss=0.3019 (C:0.3019, R:0.0105)
Batch 400/537: Loss=0.2908 (C:0.2908, R:0.0105)
Batch 425/537: Loss=0.3108 (C:0.3108, R:0.0105)
Batch 450/537: Loss=0.3125 (C:0.3125, R:0.0106)
Batch 475/537: Loss=0.3386 (C:0.3386, R:0.0105)
Batch 500/537: Loss=0.3250 (C:0.3250, R:0.0105)
Batch 525/537: Loss=0.3173 (C:0.3173, R:0.0105)

============================================================
Epoch 45/300 completed in 21.0s
Train: Loss=0.3072 (C:0.3072, R:0.0105) Ratio=4.67x
Val:   Loss=0.3721 (C:0.3721, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.225
✅ New best model saved (Val Loss: 0.3721)
============================================================

🌍 Updating global dataset at epoch 46
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.172 ± 0.298
    Neg distances: 1.279 ± 0.539
    Separation ratio: 7.43x
    Gap: -2.183
    ✅ Excellent global separation!

Epoch 46 Training
----------------------------------------
Batch   0/537: Loss=0.2758 (C:0.2758, R:0.0105)
Batch  25/537: Loss=0.3098 (C:0.3098, R:0.0105)
Batch  50/537: Loss=0.2976 (C:0.2976, R:0.0105)
Batch  75/537: Loss=0.3185 (C:0.3185, R:0.0105)
Batch 100/537: Loss=0.3176 (C:0.3176, R:0.0105)
Batch 125/537: Loss=0.2890 (C:0.2890, R:0.0106)
Batch 150/537: Loss=0.2983 (C:0.2983, R:0.0105)
Batch 175/537: Loss=0.3019 (C:0.3019, R:0.0105)
Batch 200/537: Loss=0.2960 (C:0.2960, R:0.0105)
Batch 225/537: Loss=0.2967 (C:0.2967, R:0.0105)
Batch 250/537: Loss=0.3063 (C:0.3063, R:0.0106)
Batch 275/537: Loss=0.2993 (C:0.2993, R:0.0105)
Batch 300/537: Loss=0.3117 (C:0.3117, R:0.0105)
Batch 325/537: Loss=0.3089 (C:0.3089, R:0.0105)
Batch 350/537: Loss=0.2923 (C:0.2923, R:0.0105)
Batch 375/537: Loss=0.3073 (C:0.3073, R:0.0105)
Batch 400/537: Loss=0.3009 (C:0.3009, R:0.0105)
Batch 425/537: Loss=0.3149 (C:0.3149, R:0.0105)
Batch 450/537: Loss=0.3220 (C:0.3220, R:0.0105)
Batch 475/537: Loss=0.3123 (C:0.3123, R:0.0105)
Batch 500/537: Loss=0.3025 (C:0.3025, R:0.0105)
Batch 525/537: Loss=0.3039 (C:0.3039, R:0.0105)

============================================================
Epoch 46/300 completed in 26.7s
Train: Loss=0.3031 (C:0.3031, R:0.0105) Ratio=4.61x
Val:   Loss=0.3741 (C:0.3741, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.240
No improvement for 1 epochs
============================================================

Epoch 47 Training
----------------------------------------
Batch   0/537: Loss=0.2894 (C:0.2894, R:0.0105)
Batch  25/537: Loss=0.2797 (C:0.2797, R:0.0105)
Batch  50/537: Loss=0.3038 (C:0.3038, R:0.0105)
Batch  75/537: Loss=0.2932 (C:0.2932, R:0.0106)
Batch 100/537: Loss=0.2902 (C:0.2902, R:0.0105)
Batch 125/537: Loss=0.2861 (C:0.2861, R:0.0105)
Batch 150/537: Loss=0.3042 (C:0.3042, R:0.0106)
Batch 175/537: Loss=0.3055 (C:0.3055, R:0.0105)
Batch 200/537: Loss=0.3140 (C:0.3140, R:0.0105)
Batch 225/537: Loss=0.3056 (C:0.3056, R:0.0105)
Batch 250/537: Loss=0.2781 (C:0.2781, R:0.0105)
Batch 275/537: Loss=0.2993 (C:0.2993, R:0.0105)
Batch 300/537: Loss=0.3079 (C:0.3079, R:0.0105)
Batch 325/537: Loss=0.2960 (C:0.2960, R:0.0105)
Batch 350/537: Loss=0.3217 (C:0.3217, R:0.0105)
Batch 375/537: Loss=0.3116 (C:0.3116, R:0.0105)
Batch 400/537: Loss=0.3052 (C:0.3052, R:0.0105)
Batch 425/537: Loss=0.3060 (C:0.3060, R:0.0105)
Batch 450/537: Loss=0.3029 (C:0.3029, R:0.0105)
Batch 475/537: Loss=0.2963 (C:0.2963, R:0.0105)
Batch 500/537: Loss=0.2960 (C:0.2960, R:0.0105)
Batch 525/537: Loss=0.3026 (C:0.3026, R:0.0105)

============================================================
Epoch 47/300 completed in 21.1s
Train: Loss=0.3027 (C:0.3027, R:0.0105) Ratio=4.76x
Val:   Loss=0.3678 (C:0.3678, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.255
✅ New best model saved (Val Loss: 0.3678)
============================================================

Epoch 48 Training
----------------------------------------
Batch   0/537: Loss=0.2896 (C:0.2896, R:0.0105)
Batch  25/537: Loss=0.2917 (C:0.2917, R:0.0105)
Batch  50/537: Loss=0.3064 (C:0.3064, R:0.0105)
Batch  75/537: Loss=0.2862 (C:0.2862, R:0.0105)
Batch 100/537: Loss=0.3092 (C:0.3092, R:0.0105)
Batch 125/537: Loss=0.3173 (C:0.3173, R:0.0106)
Batch 150/537: Loss=0.2942 (C:0.2942, R:0.0105)
Batch 175/537: Loss=0.2982 (C:0.2982, R:0.0105)
Batch 200/537: Loss=0.3031 (C:0.3031, R:0.0105)
Batch 225/537: Loss=0.2986 (C:0.2986, R:0.0105)
Batch 250/537: Loss=0.2940 (C:0.2940, R:0.0105)
Batch 275/537: Loss=0.3236 (C:0.3236, R:0.0105)
Batch 300/537: Loss=0.3056 (C:0.3056, R:0.0105)
Batch 325/537: Loss=0.3139 (C:0.3139, R:0.0105)
Batch 350/537: Loss=0.3009 (C:0.3009, R:0.0105)
Batch 375/537: Loss=0.3060 (C:0.3060, R:0.0105)
Batch 400/537: Loss=0.3081 (C:0.3081, R:0.0105)
Batch 425/537: Loss=0.2932 (C:0.2932, R:0.0105)
Batch 450/537: Loss=0.2986 (C:0.2986, R:0.0105)
Batch 475/537: Loss=0.2978 (C:0.2978, R:0.0105)
Batch 500/537: Loss=0.3023 (C:0.3023, R:0.0105)
Batch 525/537: Loss=0.2914 (C:0.2914, R:0.0105)

============================================================
Epoch 48/300 completed in 21.1s
Train: Loss=0.3012 (C:0.3012, R:0.0105) Ratio=4.79x
Val:   Loss=0.3742 (C:0.3742, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.270
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 49
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.179 ± 0.304
    Neg distances: 1.299 ± 0.551
    Separation ratio: 7.25x
    Gap: -2.209
    ✅ Excellent global separation!

Epoch 49 Training
----------------------------------------
Batch   0/537: Loss=0.3122 (C:0.3122, R:0.0105)
Batch  25/537: Loss=0.2910 (C:0.2910, R:0.0105)
Batch  50/537: Loss=0.3163 (C:0.3163, R:0.0105)
Batch  75/537: Loss=0.2983 (C:0.2983, R:0.0105)
Batch 100/537: Loss=0.3033 (C:0.3033, R:0.0105)
Batch 125/537: Loss=0.2961 (C:0.2961, R:0.0105)
Batch 150/537: Loss=0.2941 (C:0.2941, R:0.0105)
Batch 175/537: Loss=0.3088 (C:0.3088, R:0.0105)
Batch 200/537: Loss=0.3021 (C:0.3021, R:0.0105)
Batch 225/537: Loss=0.2729 (C:0.2729, R:0.0105)
Batch 250/537: Loss=0.3192 (C:0.3192, R:0.0105)
Batch 275/537: Loss=0.3044 (C:0.3044, R:0.0105)
Batch 300/537: Loss=0.3164 (C:0.3164, R:0.0105)
Batch 325/537: Loss=0.3066 (C:0.3066, R:0.0105)
Batch 350/537: Loss=0.3012 (C:0.3012, R:0.0105)
Batch 375/537: Loss=0.2976 (C:0.2976, R:0.0105)
Batch 400/537: Loss=0.3017 (C:0.3017, R:0.0105)
Batch 425/537: Loss=0.3038 (C:0.3038, R:0.0105)
Batch 450/537: Loss=0.3093 (C:0.3093, R:0.0105)
Batch 475/537: Loss=0.3094 (C:0.3094, R:0.0105)
Batch 500/537: Loss=0.3057 (C:0.3057, R:0.0105)
Batch 525/537: Loss=0.3138 (C:0.3138, R:0.0105)

============================================================
Epoch 49/300 completed in 26.8s
Train: Loss=0.3033 (C:0.3033, R:0.0105) Ratio=4.78x
Val:   Loss=0.3762 (C:0.3762, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.285
No improvement for 2 epochs
============================================================

Epoch 50 Training
----------------------------------------
Batch   0/537: Loss=0.2929 (C:0.2929, R:0.0105)
Batch  25/537: Loss=0.3060 (C:0.3060, R:0.0105)
Batch  50/537: Loss=0.2914 (C:0.2914, R:0.0105)
Batch  75/537: Loss=0.2904 (C:0.2904, R:0.0105)
Batch 100/537: Loss=0.2952 (C:0.2952, R:0.0105)
Batch 125/537: Loss=0.2959 (C:0.2959, R:0.0105)
Batch 150/537: Loss=0.3072 (C:0.3072, R:0.0105)
Batch 175/537: Loss=0.3013 (C:0.3013, R:0.0105)
Batch 200/537: Loss=0.2946 (C:0.2946, R:0.0105)
Batch 225/537: Loss=0.3382 (C:0.3382, R:0.0105)
Batch 250/537: Loss=0.3168 (C:0.3168, R:0.0105)
Batch 275/537: Loss=0.2998 (C:0.2998, R:0.0106)
Batch 300/537: Loss=0.3026 (C:0.3026, R:0.0105)
Batch 325/537: Loss=0.2935 (C:0.2935, R:0.0105)
Batch 350/537: Loss=0.3062 (C:0.3062, R:0.0105)
Batch 375/537: Loss=0.3129 (C:0.3129, R:0.0105)
Batch 400/537: Loss=0.2884 (C:0.2884, R:0.0105)
Batch 425/537: Loss=0.3188 (C:0.3188, R:0.0105)
Batch 450/537: Loss=0.3016 (C:0.3016, R:0.0105)
Batch 475/537: Loss=0.3091 (C:0.3091, R:0.0105)
Batch 500/537: Loss=0.2946 (C:0.2946, R:0.0105)
Batch 525/537: Loss=0.3044 (C:0.3044, R:0.0105)

============================================================
Epoch 50/300 completed in 21.6s
Train: Loss=0.3020 (C:0.3020, R:0.0105) Ratio=4.80x
Val:   Loss=0.3782 (C:0.3782, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

Epoch 51 Training
----------------------------------------
Batch   0/537: Loss=0.3115 (C:0.3115, R:0.0106)
Batch  25/537: Loss=0.3006 (C:0.3006, R:0.0106)
Batch  50/537: Loss=0.2926 (C:0.2926, R:0.0105)
Batch  75/537: Loss=0.3041 (C:0.3041, R:0.0105)
Batch 100/537: Loss=0.3020 (C:0.3020, R:0.0105)
Batch 125/537: Loss=0.2971 (C:0.2971, R:0.0105)
Batch 150/537: Loss=0.3344 (C:0.3344, R:0.0105)
Batch 175/537: Loss=0.2974 (C:0.2974, R:0.0105)
Batch 200/537: Loss=0.2977 (C:0.2977, R:0.0105)
Batch 225/537: Loss=0.3016 (C:0.3016, R:0.0105)
Batch 250/537: Loss=0.3044 (C:0.3044, R:0.0105)
Batch 275/537: Loss=0.3100 (C:0.3100, R:0.0105)
Batch 300/537: Loss=0.3048 (C:0.3048, R:0.0105)
Batch 325/537: Loss=0.2907 (C:0.2907, R:0.0105)
Batch 350/537: Loss=0.3088 (C:0.3088, R:0.0105)
Batch 375/537: Loss=0.3083 (C:0.3083, R:0.0105)
Batch 400/537: Loss=0.3101 (C:0.3101, R:0.0105)
Batch 425/537: Loss=0.3064 (C:0.3064, R:0.0105)
Batch 450/537: Loss=0.3066 (C:0.3066, R:0.0105)
Batch 475/537: Loss=0.3102 (C:0.3102, R:0.0106)
Batch 500/537: Loss=0.2902 (C:0.2902, R:0.0105)
Batch 525/537: Loss=0.3158 (C:0.3158, R:0.0105)

============================================================
Epoch 51/300 completed in 21.4s
Train: Loss=0.3020 (C:0.3020, R:0.0105) Ratio=4.74x
Val:   Loss=0.3768 (C:0.3768, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
No improvement for 4 epochs
============================================================

🌍 Updating global dataset at epoch 52
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.163 ± 0.286
    Neg distances: 1.304 ± 0.544
    Separation ratio: 7.98x
    Gap: -2.230
    ✅ Excellent global separation!

Epoch 52 Training
----------------------------------------
Batch   0/537: Loss=0.2880 (C:0.2880, R:0.0105)
Batch  25/537: Loss=0.2834 (C:0.2834, R:0.0105)
Batch  50/537: Loss=0.2859 (C:0.2859, R:0.0104)
Batch  75/537: Loss=0.2826 (C:0.2826, R:0.0105)
Batch 100/537: Loss=0.2713 (C:0.2713, R:0.0105)
Batch 125/537: Loss=0.2857 (C:0.2857, R:0.0105)
Batch 150/537: Loss=0.2915 (C:0.2915, R:0.0105)
Batch 175/537: Loss=0.2772 (C:0.2772, R:0.0105)
Batch 200/537: Loss=0.3045 (C:0.3045, R:0.0105)
Batch 225/537: Loss=0.2786 (C:0.2786, R:0.0105)
Batch 250/537: Loss=0.2920 (C:0.2920, R:0.0105)
Batch 275/537: Loss=0.2901 (C:0.2901, R:0.0105)
Batch 300/537: Loss=0.2707 (C:0.2707, R:0.0105)
Batch 325/537: Loss=0.2920 (C:0.2920, R:0.0106)
Batch 350/537: Loss=0.2827 (C:0.2827, R:0.0105)
Batch 375/537: Loss=0.2771 (C:0.2771, R:0.0105)
Batch 400/537: Loss=0.2830 (C:0.2830, R:0.0105)
Batch 425/537: Loss=0.2907 (C:0.2907, R:0.0106)
Batch 450/537: Loss=0.2934 (C:0.2934, R:0.0105)
Batch 475/537: Loss=0.2929 (C:0.2929, R:0.0105)
Batch 500/537: Loss=0.2766 (C:0.2766, R:0.0106)
Batch 525/537: Loss=0.2854 (C:0.2854, R:0.0105)

============================================================
Epoch 52/300 completed in 26.7s
Train: Loss=0.2878 (C:0.2878, R:0.0105) Ratio=4.91x
Val:   Loss=0.3647 (C:0.3647, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.3647)
============================================================

Epoch 53 Training
----------------------------------------
Batch   0/537: Loss=0.2891 (C:0.2891, R:0.0105)
Batch  25/537: Loss=0.2800 (C:0.2800, R:0.0105)
Batch  50/537: Loss=0.2892 (C:0.2892, R:0.0105)
Batch  75/537: Loss=0.2910 (C:0.2910, R:0.0105)
Batch 100/537: Loss=0.2861 (C:0.2861, R:0.0105)
Batch 125/537: Loss=0.2753 (C:0.2753, R:0.0105)
Batch 150/537: Loss=0.3024 (C:0.3024, R:0.0105)
Batch 175/537: Loss=0.2923 (C:0.2923, R:0.0105)
Batch 200/537: Loss=0.2725 (C:0.2725, R:0.0105)
Batch 225/537: Loss=0.2912 (C:0.2912, R:0.0105)
Batch 250/537: Loss=0.2673 (C:0.2673, R:0.0105)
Batch 275/537: Loss=0.3107 (C:0.3107, R:0.0105)
Batch 300/537: Loss=0.2908 (C:0.2908, R:0.0105)
Batch 325/537: Loss=0.2896 (C:0.2896, R:0.0105)
Batch 350/537: Loss=0.2777 (C:0.2777, R:0.0105)
Batch 375/537: Loss=0.2969 (C:0.2969, R:0.0105)
Batch 400/537: Loss=0.2912 (C:0.2912, R:0.0105)
Batch 425/537: Loss=0.2936 (C:0.2936, R:0.0105)
Batch 450/537: Loss=0.2770 (C:0.2770, R:0.0105)
Batch 475/537: Loss=0.3082 (C:0.3082, R:0.0105)
Batch 500/537: Loss=0.2905 (C:0.2905, R:0.0105)
Batch 525/537: Loss=0.2920 (C:0.2920, R:0.0105)

============================================================
Epoch 53/300 completed in 21.0s
Train: Loss=0.2881 (C:0.2881, R:0.0105) Ratio=4.81x
Val:   Loss=0.3675 (C:0.3675, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

Epoch 54 Training
----------------------------------------
Batch   0/537: Loss=0.2836 (C:0.2836, R:0.0105)
Batch  25/537: Loss=0.2832 (C:0.2832, R:0.0105)
Batch  50/537: Loss=0.2828 (C:0.2828, R:0.0105)
Batch  75/537: Loss=0.2809 (C:0.2809, R:0.0105)
Batch 100/537: Loss=0.2806 (C:0.2806, R:0.0105)
Batch 125/537: Loss=0.3036 (C:0.3036, R:0.0105)
Batch 150/537: Loss=0.2846 (C:0.2846, R:0.0105)
Batch 175/537: Loss=0.2807 (C:0.2807, R:0.0105)
Batch 200/537: Loss=0.2789 (C:0.2789, R:0.0105)
Batch 225/537: Loss=0.2755 (C:0.2755, R:0.0105)
Batch 250/537: Loss=0.2875 (C:0.2875, R:0.0105)
Batch 275/537: Loss=0.2936 (C:0.2936, R:0.0105)
Batch 300/537: Loss=0.2769 (C:0.2769, R:0.0105)
Batch 325/537: Loss=0.2749 (C:0.2749, R:0.0105)
Batch 350/537: Loss=0.2881 (C:0.2881, R:0.0105)
Batch 375/537: Loss=0.2869 (C:0.2869, R:0.0105)
Batch 400/537: Loss=0.2871 (C:0.2871, R:0.0105)
Batch 425/537: Loss=0.2946 (C:0.2946, R:0.0105)
Batch 450/537: Loss=0.3022 (C:0.3022, R:0.0105)
Batch 475/537: Loss=0.2930 (C:0.2930, R:0.0105)
Batch 500/537: Loss=0.2727 (C:0.2727, R:0.0105)
Batch 525/537: Loss=0.2856 (C:0.2856, R:0.0105)

============================================================
Epoch 54/300 completed in 21.4s
Train: Loss=0.2863 (C:0.2863, R:0.0105) Ratio=4.85x
Val:   Loss=0.3661 (C:0.3661, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 55
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.164 ± 0.290
    Neg distances: 1.302 ± 0.545
    Separation ratio: 7.94x
    Gap: -2.235
    ✅ Excellent global separation!

Epoch 55 Training
----------------------------------------
Batch   0/537: Loss=0.2763 (C:0.2763, R:0.0105)
Batch  25/537: Loss=0.2891 (C:0.2891, R:0.0105)
Batch  50/537: Loss=0.2979 (C:0.2979, R:0.0105)
Batch  75/537: Loss=0.2696 (C:0.2696, R:0.0105)
Batch 100/537: Loss=0.2966 (C:0.2966, R:0.0105)
Batch 125/537: Loss=0.2825 (C:0.2825, R:0.0105)
Batch 150/537: Loss=0.2764 (C:0.2764, R:0.0105)
Batch 175/537: Loss=0.2982 (C:0.2982, R:0.0105)
Batch 200/537: Loss=0.2753 (C:0.2753, R:0.0105)
Batch 225/537: Loss=0.2813 (C:0.2813, R:0.0105)
Batch 250/537: Loss=0.2818 (C:0.2818, R:0.0105)
Batch 275/537: Loss=0.3006 (C:0.3006, R:0.0105)
Batch 300/537: Loss=0.2758 (C:0.2758, R:0.0105)
Batch 325/537: Loss=0.2888 (C:0.2888, R:0.0105)
Batch 350/537: Loss=0.2983 (C:0.2983, R:0.0105)
Batch 375/537: Loss=0.3043 (C:0.3043, R:0.0105)
Batch 400/537: Loss=0.2670 (C:0.2670, R:0.0105)
Batch 425/537: Loss=0.2774 (C:0.2774, R:0.0105)
Batch 450/537: Loss=0.2726 (C:0.2726, R:0.0105)
Batch 475/537: Loss=0.3052 (C:0.3052, R:0.0105)
Batch 500/537: Loss=0.2899 (C:0.2899, R:0.0105)
Batch 525/537: Loss=0.2787 (C:0.2787, R:0.0105)

============================================================
Epoch 55/300 completed in 26.8s
Train: Loss=0.2867 (C:0.2867, R:0.0105) Ratio=4.88x
Val:   Loss=0.3632 (C:0.3632, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.3632)
============================================================

Epoch 56 Training
----------------------------------------
Batch   0/537: Loss=0.2771 (C:0.2771, R:0.0105)
Batch  25/537: Loss=0.2839 (C:0.2839, R:0.0105)
Batch  50/537: Loss=0.2918 (C:0.2918, R:0.0105)
Batch  75/537: Loss=0.2769 (C:0.2769, R:0.0105)
Batch 100/537: Loss=0.2676 (C:0.2676, R:0.0105)
Batch 125/537: Loss=0.2772 (C:0.2772, R:0.0105)
Batch 150/537: Loss=0.2912 (C:0.2912, R:0.0105)
Batch 175/537: Loss=0.2797 (C:0.2797, R:0.0105)
Batch 200/537: Loss=0.2791 (C:0.2791, R:0.0105)
Batch 225/537: Loss=0.2899 (C:0.2899, R:0.0105)
Batch 250/537: Loss=0.2852 (C:0.2852, R:0.0105)
Batch 275/537: Loss=0.2977 (C:0.2977, R:0.0105)
Batch 300/537: Loss=0.2874 (C:0.2874, R:0.0105)
Batch 325/537: Loss=0.2786 (C:0.2786, R:0.0105)
Batch 350/537: Loss=0.3099 (C:0.3099, R:0.0105)
Batch 375/537: Loss=0.3012 (C:0.3012, R:0.0105)
Batch 400/537: Loss=0.2799 (C:0.2799, R:0.0105)
Batch 425/537: Loss=0.2976 (C:0.2976, R:0.0105)
Batch 450/537: Loss=0.2776 (C:0.2776, R:0.0105)
Batch 475/537: Loss=0.2628 (C:0.2628, R:0.0106)
Batch 500/537: Loss=0.2880 (C:0.2880, R:0.0105)
Batch 525/537: Loss=0.2937 (C:0.2937, R:0.0105)

============================================================
Epoch 56/300 completed in 21.2s
Train: Loss=0.2851 (C:0.2851, R:0.0105) Ratio=4.94x
Val:   Loss=0.3648 (C:0.3648, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

Epoch 57 Training
----------------------------------------
Batch   0/537: Loss=0.2756 (C:0.2756, R:0.0105)
Batch  25/537: Loss=0.2986 (C:0.2986, R:0.0105)
Batch  50/537: Loss=0.2805 (C:0.2805, R:0.0105)
Batch  75/537: Loss=0.2805 (C:0.2805, R:0.0105)
Batch 100/537: Loss=0.2723 (C:0.2723, R:0.0105)
Batch 125/537: Loss=0.2647 (C:0.2647, R:0.0105)
Batch 150/537: Loss=0.2685 (C:0.2685, R:0.0105)
Batch 175/537: Loss=0.2767 (C:0.2767, R:0.0105)
Batch 200/537: Loss=0.2831 (C:0.2831, R:0.0105)
Batch 225/537: Loss=0.2785 (C:0.2785, R:0.0105)
Batch 250/537: Loss=0.2928 (C:0.2928, R:0.0105)
Batch 275/537: Loss=0.2820 (C:0.2820, R:0.0105)
Batch 300/537: Loss=0.2885 (C:0.2885, R:0.0105)
Batch 325/537: Loss=0.2783 (C:0.2783, R:0.0106)
Batch 350/537: Loss=0.2937 (C:0.2937, R:0.0105)
Batch 375/537: Loss=0.2903 (C:0.2903, R:0.0105)
Batch 400/537: Loss=0.2847 (C:0.2847, R:0.0105)
Batch 425/537: Loss=0.2772 (C:0.2772, R:0.0105)
Batch 450/537: Loss=0.3039 (C:0.3039, R:0.0105)
Batch 475/537: Loss=0.2988 (C:0.2988, R:0.0105)
Batch 500/537: Loss=0.3077 (C:0.3077, R:0.0105)
Batch 525/537: Loss=0.2959 (C:0.2959, R:0.0105)

============================================================
Epoch 57/300 completed in 21.0s
Train: Loss=0.2853 (C:0.2853, R:0.0105) Ratio=4.97x
Val:   Loss=0.3634 (C:0.3634, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 58
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.166 ± 0.294
    Neg distances: 1.315 ± 0.550
    Separation ratio: 7.93x
    Gap: -2.222
    ✅ Excellent global separation!

Epoch 58 Training
----------------------------------------
Batch   0/537: Loss=0.3001 (C:0.3001, R:0.0105)
Batch  25/537: Loss=0.2685 (C:0.2685, R:0.0105)
Batch  50/537: Loss=0.2863 (C:0.2863, R:0.0105)
Batch  75/537: Loss=0.2932 (C:0.2932, R:0.0105)
Batch 100/537: Loss=0.2891 (C:0.2891, R:0.0105)
Batch 125/537: Loss=0.2956 (C:0.2956, R:0.0105)
Batch 150/537: Loss=0.3038 (C:0.3038, R:0.0105)
Batch 175/537: Loss=0.2762 (C:0.2762, R:0.0105)
Batch 200/537: Loss=0.2859 (C:0.2859, R:0.0105)
Batch 225/537: Loss=0.2896 (C:0.2896, R:0.0105)
Batch 250/537: Loss=0.3065 (C:0.3065, R:0.0105)
Batch 275/537: Loss=0.2977 (C:0.2977, R:0.0105)
Batch 300/537: Loss=0.2744 (C:0.2744, R:0.0105)
Batch 325/537: Loss=0.2853 (C:0.2853, R:0.0105)
Batch 350/537: Loss=0.2941 (C:0.2941, R:0.0105)
Batch 375/537: Loss=0.2786 (C:0.2786, R:0.0105)
Batch 400/537: Loss=0.2926 (C:0.2926, R:0.0105)
Batch 425/537: Loss=0.2855 (C:0.2855, R:0.0105)
Batch 450/537: Loss=0.2874 (C:0.2874, R:0.0105)
Batch 475/537: Loss=0.2754 (C:0.2754, R:0.0105)
Batch 500/537: Loss=0.2910 (C:0.2910, R:0.0105)
Batch 525/537: Loss=0.2866 (C:0.2866, R:0.0105)

============================================================
Epoch 58/300 completed in 26.5s
Train: Loss=0.2848 (C:0.2848, R:0.0105) Ratio=4.90x
Val:   Loss=0.3687 (C:0.3687, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

Epoch 59 Training
----------------------------------------
Batch   0/537: Loss=0.2567 (C:0.2567, R:0.0105)
Batch  25/537: Loss=0.2953 (C:0.2953, R:0.0105)
Batch  50/537: Loss=0.2683 (C:0.2683, R:0.0105)
Batch  75/537: Loss=0.2793 (C:0.2793, R:0.0105)
Batch 100/537: Loss=0.2887 (C:0.2887, R:0.0105)
Batch 125/537: Loss=0.2922 (C:0.2922, R:0.0105)
Batch 150/537: Loss=0.2728 (C:0.2728, R:0.0105)
Batch 175/537: Loss=0.2866 (C:0.2866, R:0.0105)
Batch 200/537: Loss=0.2712 (C:0.2712, R:0.0105)
Batch 225/537: Loss=0.2752 (C:0.2752, R:0.0105)
Batch 250/537: Loss=0.2681 (C:0.2681, R:0.0105)
Batch 275/537: Loss=0.2687 (C:0.2687, R:0.0105)
Batch 300/537: Loss=0.2946 (C:0.2946, R:0.0105)
Batch 325/537: Loss=0.2795 (C:0.2795, R:0.0105)
Batch 350/537: Loss=0.3185 (C:0.3185, R:0.0105)
Batch 375/537: Loss=0.3044 (C:0.3044, R:0.0106)
Batch 400/537: Loss=0.2847 (C:0.2847, R:0.0105)
Batch 425/537: Loss=0.2724 (C:0.2724, R:0.0105)
Batch 450/537: Loss=0.2733 (C:0.2733, R:0.0105)
Batch 475/537: Loss=0.2704 (C:0.2704, R:0.0105)
Batch 500/537: Loss=0.3027 (C:0.3027, R:0.0105)
Batch 525/537: Loss=0.2927 (C:0.2927, R:0.0105)

============================================================
Epoch 59/300 completed in 21.2s
Train: Loss=0.2839 (C:0.2839, R:0.0105) Ratio=5.12x
Val:   Loss=0.3652 (C:0.3652, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
No improvement for 4 epochs
============================================================

Epoch 60 Training
----------------------------------------
Batch   0/537: Loss=0.2717 (C:0.2717, R:0.0105)
Batch  25/537: Loss=0.2786 (C:0.2786, R:0.0105)
Batch  50/537: Loss=0.2937 (C:0.2937, R:0.0105)
Batch  75/537: Loss=0.2743 (C:0.2743, R:0.0105)
Batch 100/537: Loss=0.3053 (C:0.3053, R:0.0106)
Batch 125/537: Loss=0.2801 (C:0.2801, R:0.0106)
Batch 150/537: Loss=0.2831 (C:0.2831, R:0.0105)
Batch 175/537: Loss=0.2766 (C:0.2766, R:0.0105)
Batch 200/537: Loss=0.2618 (C:0.2618, R:0.0105)
Batch 225/537: Loss=0.2797 (C:0.2797, R:0.0105)
Batch 250/537: Loss=0.2872 (C:0.2872, R:0.0105)
Batch 275/537: Loss=0.2903 (C:0.2903, R:0.0105)
Batch 300/537: Loss=0.2850 (C:0.2850, R:0.0105)
Batch 325/537: Loss=0.2845 (C:0.2845, R:0.0105)
Batch 350/537: Loss=0.2962 (C:0.2962, R:0.0105)
Batch 375/537: Loss=0.3047 (C:0.3047, R:0.0105)
Batch 400/537: Loss=0.2940 (C:0.2940, R:0.0105)
Batch 425/537: Loss=0.2848 (C:0.2848, R:0.0105)
Batch 450/537: Loss=0.2670 (C:0.2670, R:0.0105)
Batch 475/537: Loss=0.2783 (C:0.2783, R:0.0105)
Batch 500/537: Loss=0.3012 (C:0.3012, R:0.0105)
Batch 525/537: Loss=0.2958 (C:0.2958, R:0.0105)

============================================================
Epoch 60/300 completed in 21.0s
Train: Loss=0.2837 (C:0.2837, R:0.0105) Ratio=5.03x
Val:   Loss=0.3677 (C:0.3677, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 5 epochs
Checkpoint saved at epoch 60
============================================================

🌍 Updating global dataset at epoch 61
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.157 ± 0.292
    Neg distances: 1.325 ± 0.550
    Separation ratio: 8.42x
    Gap: -2.229
    ✅ Excellent global separation!

Epoch 61 Training
----------------------------------------
Batch   0/537: Loss=0.2622 (C:0.2622, R:0.0105)
Batch  25/537: Loss=0.2754 (C:0.2754, R:0.0105)
Batch  50/537: Loss=0.2909 (C:0.2909, R:0.0105)
Batch  75/537: Loss=0.2729 (C:0.2729, R:0.0106)
Batch 100/537: Loss=0.2737 (C:0.2737, R:0.0105)
Batch 125/537: Loss=0.2687 (C:0.2687, R:0.0105)
Batch 150/537: Loss=0.2705 (C:0.2705, R:0.0105)
Batch 175/537: Loss=0.2887 (C:0.2887, R:0.0105)
Batch 200/537: Loss=0.2819 (C:0.2819, R:0.0105)
Batch 225/537: Loss=0.2581 (C:0.2581, R:0.0105)
Batch 250/537: Loss=0.2821 (C:0.2821, R:0.0105)
Batch 275/537: Loss=0.2622 (C:0.2622, R:0.0105)
Batch 300/537: Loss=0.2794 (C:0.2794, R:0.0105)
Batch 325/537: Loss=0.2687 (C:0.2687, R:0.0105)
Batch 350/537: Loss=0.2632 (C:0.2632, R:0.0105)
Batch 375/537: Loss=0.2692 (C:0.2692, R:0.0105)
Batch 400/537: Loss=0.2705 (C:0.2705, R:0.0105)
Batch 425/537: Loss=0.2724 (C:0.2724, R:0.0105)
Batch 450/537: Loss=0.2706 (C:0.2706, R:0.0105)
Batch 475/537: Loss=0.2809 (C:0.2809, R:0.0105)
Batch 500/537: Loss=0.2911 (C:0.2911, R:0.0106)
Batch 525/537: Loss=0.2776 (C:0.2776, R:0.0105)

============================================================
Epoch 61/300 completed in 27.0s
Train: Loss=0.2760 (C:0.2760, R:0.0105) Ratio=5.06x
Val:   Loss=0.3570 (C:0.3570, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.3570)
============================================================

Epoch 62 Training
----------------------------------------
Batch   0/537: Loss=0.2674 (C:0.2674, R:0.0105)
Batch  25/537: Loss=0.2814 (C:0.2814, R:0.0105)
Batch  50/537: Loss=0.2827 (C:0.2827, R:0.0105)
Batch  75/537: Loss=0.2615 (C:0.2615, R:0.0105)
Batch 100/537: Loss=0.2737 (C:0.2737, R:0.0105)
Batch 125/537: Loss=0.2653 (C:0.2653, R:0.0105)
Batch 150/537: Loss=0.2639 (C:0.2639, R:0.0105)
Batch 175/537: Loss=0.2721 (C:0.2721, R:0.0105)
Batch 200/537: Loss=0.2808 (C:0.2808, R:0.0105)
Batch 225/537: Loss=0.2654 (C:0.2654, R:0.0105)
Batch 250/537: Loss=0.2889 (C:0.2889, R:0.0105)
Batch 275/537: Loss=0.2693 (C:0.2693, R:0.0105)
Batch 300/537: Loss=0.2559 (C:0.2559, R:0.0105)
Batch 325/537: Loss=0.2537 (C:0.2537, R:0.0105)
Batch 350/537: Loss=0.2736 (C:0.2736, R:0.0105)
Batch 375/537: Loss=0.3033 (C:0.3033, R:0.0105)
Batch 400/537: Loss=0.2855 (C:0.2855, R:0.0105)
Batch 425/537: Loss=0.2849 (C:0.2849, R:0.0105)
Batch 450/537: Loss=0.3083 (C:0.3083, R:0.0105)
Batch 475/537: Loss=0.2988 (C:0.2988, R:0.0105)
Batch 500/537: Loss=0.2718 (C:0.2718, R:0.0105)
Batch 525/537: Loss=0.2662 (C:0.2662, R:0.0105)

============================================================
Epoch 62/300 completed in 21.1s
Train: Loss=0.2749 (C:0.2749, R:0.0105) Ratio=5.08x
Val:   Loss=0.3603 (C:0.3603, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

Epoch 63 Training
----------------------------------------
Batch   0/537: Loss=0.2728 (C:0.2728, R:0.0105)
Batch  25/537: Loss=0.2645 (C:0.2645, R:0.0105)
Batch  50/537: Loss=0.2679 (C:0.2679, R:0.0105)
Batch  75/537: Loss=0.2826 (C:0.2826, R:0.0105)
Batch 100/537: Loss=0.2691 (C:0.2691, R:0.0105)
Batch 125/537: Loss=0.2743 (C:0.2743, R:0.0105)
Batch 150/537: Loss=0.2678 (C:0.2678, R:0.0105)
Batch 175/537: Loss=0.2820 (C:0.2820, R:0.0105)
Batch 200/537: Loss=0.2690 (C:0.2690, R:0.0105)
Batch 225/537: Loss=0.2586 (C:0.2586, R:0.0105)
Batch 250/537: Loss=0.2882 (C:0.2882, R:0.0105)
Batch 275/537: Loss=0.2722 (C:0.2722, R:0.0105)
Batch 300/537: Loss=0.2753 (C:0.2753, R:0.0106)
Batch 325/537: Loss=0.2848 (C:0.2848, R:0.0105)
Batch 350/537: Loss=0.2897 (C:0.2897, R:0.0105)
Batch 375/537: Loss=0.2726 (C:0.2726, R:0.0105)
Batch 400/537: Loss=0.2606 (C:0.2606, R:0.0105)
Batch 425/537: Loss=0.2733 (C:0.2733, R:0.0105)
Batch 450/537: Loss=0.2834 (C:0.2834, R:0.0105)
Batch 475/537: Loss=0.2542 (C:0.2542, R:0.0105)
Batch 500/537: Loss=0.2862 (C:0.2862, R:0.0104)
Batch 525/537: Loss=0.2523 (C:0.2523, R:0.0105)

============================================================
Epoch 63/300 completed in 21.3s
Train: Loss=0.2744 (C:0.2744, R:0.0105) Ratio=5.15x
Val:   Loss=0.3583 (C:0.3583, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 64
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.148 ± 0.269
    Neg distances: 1.305 ± 0.537
    Separation ratio: 8.80x
    Gap: -2.209
    ✅ Excellent global separation!

Epoch 64 Training
----------------------------------------
Batch   0/537: Loss=0.2618 (C:0.2618, R:0.0105)
Batch  25/537: Loss=0.2372 (C:0.2372, R:0.0106)
Batch  50/537: Loss=0.2645 (C:0.2645, R:0.0105)
Batch  75/537: Loss=0.2501 (C:0.2501, R:0.0105)
Batch 100/537: Loss=0.2738 (C:0.2738, R:0.0105)
Batch 125/537: Loss=0.2615 (C:0.2615, R:0.0106)
Batch 150/537: Loss=0.2629 (C:0.2629, R:0.0105)
Batch 175/537: Loss=0.2665 (C:0.2665, R:0.0105)
Batch 200/537: Loss=0.2558 (C:0.2558, R:0.0105)
Batch 225/537: Loss=0.2585 (C:0.2585, R:0.0106)
Batch 250/537: Loss=0.2663 (C:0.2663, R:0.0105)
Batch 275/537: Loss=0.2746 (C:0.2746, R:0.0105)
Batch 300/537: Loss=0.2779 (C:0.2779, R:0.0105)
Batch 325/537: Loss=0.2736 (C:0.2736, R:0.0106)
Batch 350/537: Loss=0.2687 (C:0.2687, R:0.0105)
Batch 375/537: Loss=0.2723 (C:0.2723, R:0.0105)
Batch 400/537: Loss=0.2625 (C:0.2625, R:0.0105)
Batch 425/537: Loss=0.2784 (C:0.2784, R:0.0105)
Batch 450/537: Loss=0.2749 (C:0.2749, R:0.0105)
Batch 475/537: Loss=0.2718 (C:0.2718, R:0.0105)
Batch 500/537: Loss=0.2752 (C:0.2752, R:0.0105)
Batch 525/537: Loss=0.2621 (C:0.2621, R:0.0105)

============================================================
Epoch 64/300 completed in 27.3s
Train: Loss=0.2672 (C:0.2672, R:0.0105) Ratio=5.16x
Val:   Loss=0.3544 (C:0.3544, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.3544)
============================================================

Epoch 65 Training
----------------------------------------
Batch   0/537: Loss=0.2546 (C:0.2546, R:0.0105)
Batch  25/537: Loss=0.2558 (C:0.2558, R:0.0105)
Batch  50/537: Loss=0.2822 (C:0.2822, R:0.0105)
Batch  75/537: Loss=0.2742 (C:0.2742, R:0.0105)
Batch 100/537: Loss=0.2582 (C:0.2582, R:0.0105)
Batch 125/537: Loss=0.2664 (C:0.2664, R:0.0105)
Batch 150/537: Loss=0.2720 (C:0.2720, R:0.0105)
Batch 175/537: Loss=0.2570 (C:0.2570, R:0.0105)
Batch 200/537: Loss=0.2495 (C:0.2495, R:0.0105)
Batch 225/537: Loss=0.2611 (C:0.2611, R:0.0105)
Batch 250/537: Loss=0.2728 (C:0.2728, R:0.0105)
Batch 275/537: Loss=0.2663 (C:0.2663, R:0.0105)
Batch 300/537: Loss=0.2660 (C:0.2660, R:0.0105)
Batch 325/537: Loss=0.2729 (C:0.2729, R:0.0105)
Batch 350/537: Loss=0.2580 (C:0.2580, R:0.0105)
Batch 375/537: Loss=0.2614 (C:0.2614, R:0.0105)
Batch 400/537: Loss=0.2774 (C:0.2774, R:0.0105)
Batch 425/537: Loss=0.2881 (C:0.2881, R:0.0105)
Batch 450/537: Loss=0.2666 (C:0.2666, R:0.0105)
Batch 475/537: Loss=0.2803 (C:0.2803, R:0.0105)
Batch 500/537: Loss=0.2632 (C:0.2632, R:0.0105)
Batch 525/537: Loss=0.2718 (C:0.2718, R:0.0105)

============================================================
Epoch 65/300 completed in 21.4s
Train: Loss=0.2668 (C:0.2668, R:0.0105) Ratio=5.10x
Val:   Loss=0.3514 (C:0.3514, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.3514)
============================================================

Epoch 66 Training
----------------------------------------
Batch   0/537: Loss=0.2555 (C:0.2555, R:0.0105)
Batch  25/537: Loss=0.2273 (C:0.2273, R:0.0105)
Batch  50/537: Loss=0.2629 (C:0.2629, R:0.0105)
Batch  75/537: Loss=0.2608 (C:0.2608, R:0.0105)
Batch 100/537: Loss=0.2778 (C:0.2778, R:0.0105)
Batch 125/537: Loss=0.2827 (C:0.2827, R:0.0105)
Batch 150/537: Loss=0.2697 (C:0.2697, R:0.0105)
Batch 175/537: Loss=0.2481 (C:0.2481, R:0.0106)
Batch 200/537: Loss=0.2773 (C:0.2773, R:0.0105)
Batch 225/537: Loss=0.2783 (C:0.2783, R:0.0105)
Batch 250/537: Loss=0.2637 (C:0.2637, R:0.0105)
Batch 275/537: Loss=0.2607 (C:0.2607, R:0.0105)
Batch 300/537: Loss=0.2733 (C:0.2733, R:0.0105)
Batch 325/537: Loss=0.2489 (C:0.2489, R:0.0105)
Batch 350/537: Loss=0.2607 (C:0.2607, R:0.0105)
Batch 375/537: Loss=0.2679 (C:0.2679, R:0.0105)
Batch 400/537: Loss=0.3006 (C:0.3006, R:0.0105)
Batch 425/537: Loss=0.2753 (C:0.2753, R:0.0105)
Batch 450/537: Loss=0.2689 (C:0.2689, R:0.0105)
Batch 475/537: Loss=0.2668 (C:0.2668, R:0.0105)
Batch 500/537: Loss=0.2828 (C:0.2828, R:0.0105)
Batch 525/537: Loss=0.2671 (C:0.2671, R:0.0105)

============================================================
Epoch 66/300 completed in 21.5s
Train: Loss=0.2665 (C:0.2665, R:0.0105) Ratio=5.13x
Val:   Loss=0.3537 (C:0.3537, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 67
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.154 ± 0.291
    Neg distances: 1.321 ± 0.550
    Separation ratio: 8.57x
    Gap: -2.278
    ✅ Excellent global separation!

Epoch 67 Training
----------------------------------------
Batch   0/537: Loss=0.2605 (C:0.2605, R:0.0106)
Batch  25/537: Loss=0.2525 (C:0.2525, R:0.0105)
Batch  50/537: Loss=0.2877 (C:0.2877, R:0.0105)
Batch  75/537: Loss=0.2800 (C:0.2800, R:0.0105)
Batch 100/537: Loss=0.2553 (C:0.2553, R:0.0105)
Batch 125/537: Loss=0.2685 (C:0.2685, R:0.0105)
Batch 150/537: Loss=0.2581 (C:0.2581, R:0.0105)
Batch 175/537: Loss=0.2774 (C:0.2774, R:0.0105)
Batch 200/537: Loss=0.2664 (C:0.2664, R:0.0105)
Batch 225/537: Loss=0.2837 (C:0.2837, R:0.0105)
Batch 250/537: Loss=0.2937 (C:0.2937, R:0.0105)
Batch 275/537: Loss=0.2661 (C:0.2661, R:0.0105)
Batch 300/537: Loss=0.2665 (C:0.2665, R:0.0105)
Batch 325/537: Loss=0.2707 (C:0.2707, R:0.0105)
Batch 350/537: Loss=0.2628 (C:0.2628, R:0.0105)
Batch 375/537: Loss=0.2693 (C:0.2693, R:0.0105)
Batch 400/537: Loss=0.2812 (C:0.2812, R:0.0105)
Batch 425/537: Loss=0.2852 (C:0.2852, R:0.0105)
Batch 450/537: Loss=0.2795 (C:0.2795, R:0.0105)
Batch 475/537: Loss=0.2885 (C:0.2885, R:0.0105)
Batch 500/537: Loss=0.2609 (C:0.2609, R:0.0105)
Batch 525/537: Loss=0.2871 (C:0.2871, R:0.0105)

============================================================
Epoch 67/300 completed in 27.2s
Train: Loss=0.2701 (C:0.2701, R:0.0105) Ratio=5.12x
Val:   Loss=0.3583 (C:0.3583, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

Epoch 68 Training
----------------------------------------
Batch   0/537: Loss=0.2632 (C:0.2632, R:0.0105)
Batch  25/537: Loss=0.2410 (C:0.2410, R:0.0105)
Batch  50/537: Loss=0.2641 (C:0.2641, R:0.0105)
Batch  75/537: Loss=0.2730 (C:0.2730, R:0.0106)
Batch 100/537: Loss=0.2545 (C:0.2545, R:0.0105)
Batch 125/537: Loss=0.2676 (C:0.2676, R:0.0105)
Batch 150/537: Loss=0.2647 (C:0.2647, R:0.0105)
Batch 175/537: Loss=0.2843 (C:0.2843, R:0.0105)
Batch 200/537: Loss=0.2729 (C:0.2729, R:0.0105)
Batch 225/537: Loss=0.2633 (C:0.2633, R:0.0106)
Batch 250/537: Loss=0.2487 (C:0.2487, R:0.0105)
Batch 275/537: Loss=0.2729 (C:0.2729, R:0.0105)
Batch 300/537: Loss=0.2485 (C:0.2485, R:0.0105)
Batch 325/537: Loss=0.2861 (C:0.2861, R:0.0105)
Batch 350/537: Loss=0.2641 (C:0.2641, R:0.0105)
Batch 375/537: Loss=0.2612 (C:0.2612, R:0.0105)
Batch 400/537: Loss=0.2791 (C:0.2791, R:0.0105)
Batch 425/537: Loss=0.2744 (C:0.2744, R:0.0106)
Batch 450/537: Loss=0.2681 (C:0.2681, R:0.0105)
Batch 475/537: Loss=0.2676 (C:0.2676, R:0.0105)
Batch 500/537: Loss=0.2737 (C:0.2737, R:0.0105)
Batch 525/537: Loss=0.2679 (C:0.2679, R:0.0105)

============================================================
Epoch 68/300 completed in 21.5s
Train: Loss=0.2689 (C:0.2689, R:0.0105) Ratio=5.29x
Val:   Loss=0.3565 (C:0.3565, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

Epoch 69 Training
----------------------------------------
Batch   0/537: Loss=0.2593 (C:0.2593, R:0.0105)
Batch  25/537: Loss=0.2574 (C:0.2574, R:0.0105)
Batch  50/537: Loss=0.2532 (C:0.2532, R:0.0105)
Batch  75/537: Loss=0.2513 (C:0.2513, R:0.0106)
Batch 100/537: Loss=0.2526 (C:0.2526, R:0.0105)
Batch 125/537: Loss=0.2732 (C:0.2732, R:0.0105)
Batch 150/537: Loss=0.2588 (C:0.2588, R:0.0105)
Batch 175/537: Loss=0.2861 (C:0.2861, R:0.0105)
Batch 200/537: Loss=0.2680 (C:0.2680, R:0.0105)
Batch 225/537: Loss=0.2819 (C:0.2819, R:0.0105)
Batch 250/537: Loss=0.2671 (C:0.2671, R:0.0105)
Batch 275/537: Loss=0.2728 (C:0.2728, R:0.0105)
Batch 300/537: Loss=0.2677 (C:0.2677, R:0.0105)
Batch 325/537: Loss=0.2729 (C:0.2729, R:0.0105)
Batch 350/537: Loss=0.2635 (C:0.2635, R:0.0105)
Batch 375/537: Loss=0.2747 (C:0.2747, R:0.0105)
Batch 400/537: Loss=0.2706 (C:0.2706, R:0.0105)
Batch 425/537: Loss=0.2639 (C:0.2639, R:0.0105)
Batch 450/537: Loss=0.2690 (C:0.2690, R:0.0105)
Batch 475/537: Loss=0.2693 (C:0.2693, R:0.0105)
Batch 500/537: Loss=0.2721 (C:0.2721, R:0.0105)
Batch 525/537: Loss=0.2773 (C:0.2773, R:0.0105)

============================================================
Epoch 69/300 completed in 21.4s
Train: Loss=0.2685 (C:0.2685, R:0.0105) Ratio=5.18x
Val:   Loss=0.3558 (C:0.3558, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
No improvement for 4 epochs
============================================================

🌍 Updating global dataset at epoch 70
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.152 ± 0.287
    Neg distances: 1.334 ± 0.551
    Separation ratio: 8.80x
    Gap: -2.299
    ✅ Excellent global separation!

Epoch 70 Training
----------------------------------------
Batch   0/537: Loss=0.2492 (C:0.2492, R:0.0105)
Batch  25/537: Loss=0.2620 (C:0.2620, R:0.0105)
Batch  50/537: Loss=0.2570 (C:0.2570, R:0.0105)
Batch  75/537: Loss=0.2567 (C:0.2567, R:0.0105)
Batch 100/537: Loss=0.2569 (C:0.2569, R:0.0105)
Batch 125/537: Loss=0.2550 (C:0.2550, R:0.0106)
Batch 150/537: Loss=0.2740 (C:0.2740, R:0.0106)
Batch 175/537: Loss=0.2633 (C:0.2633, R:0.0105)
Batch 200/537: Loss=0.2611 (C:0.2611, R:0.0105)
Batch 225/537: Loss=0.2653 (C:0.2653, R:0.0106)
Batch 250/537: Loss=0.2646 (C:0.2646, R:0.0105)
Batch 275/537: Loss=0.2552 (C:0.2552, R:0.0105)
Batch 300/537: Loss=0.2718 (C:0.2718, R:0.0105)
Batch 325/537: Loss=0.2594 (C:0.2594, R:0.0105)
Batch 350/537: Loss=0.2417 (C:0.2417, R:0.0105)
Batch 375/537: Loss=0.2457 (C:0.2457, R:0.0105)
Batch 400/537: Loss=0.2517 (C:0.2517, R:0.0105)
Batch 425/537: Loss=0.2585 (C:0.2585, R:0.0105)
Batch 450/537: Loss=0.2714 (C:0.2714, R:0.0105)
Batch 475/537: Loss=0.2730 (C:0.2730, R:0.0105)
Batch 500/537: Loss=0.2628 (C:0.2628, R:0.0105)
Batch 525/537: Loss=0.2558 (C:0.2558, R:0.0105)

============================================================
Epoch 70/300 completed in 26.6s
Train: Loss=0.2646 (C:0.2646, R:0.0105) Ratio=5.34x
Val:   Loss=0.3540 (C:0.3540, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
No improvement for 5 epochs
============================================================

Epoch 71 Training
----------------------------------------
Batch   0/537: Loss=0.2618 (C:0.2618, R:0.0105)
Batch  25/537: Loss=0.2609 (C:0.2609, R:0.0105)
Batch  50/537: Loss=0.2519 (C:0.2519, R:0.0105)
Batch  75/537: Loss=0.2611 (C:0.2611, R:0.0105)
Batch 100/537: Loss=0.2668 (C:0.2668, R:0.0105)
Batch 125/537: Loss=0.2376 (C:0.2376, R:0.0106)
Batch 150/537: Loss=0.2632 (C:0.2632, R:0.0105)
Batch 175/537: Loss=0.2642 (C:0.2642, R:0.0105)
Batch 200/537: Loss=0.2533 (C:0.2533, R:0.0105)
Batch 225/537: Loss=0.2626 (C:0.2626, R:0.0105)
Batch 250/537: Loss=0.2556 (C:0.2556, R:0.0105)
Batch 275/537: Loss=0.2574 (C:0.2574, R:0.0105)
Batch 300/537: Loss=0.2730 (C:0.2730, R:0.0105)
Batch 325/537: Loss=0.2585 (C:0.2585, R:0.0105)
Batch 350/537: Loss=0.2662 (C:0.2662, R:0.0105)
Batch 375/537: Loss=0.2708 (C:0.2708, R:0.0105)
Batch 400/537: Loss=0.2660 (C:0.2660, R:0.0105)
Batch 425/537: Loss=0.2819 (C:0.2819, R:0.0105)
Batch 450/537: Loss=0.2651 (C:0.2651, R:0.0105)
Batch 475/537: Loss=0.2638 (C:0.2638, R:0.0105)
Batch 500/537: Loss=0.2638 (C:0.2638, R:0.0105)
Batch 525/537: Loss=0.2731 (C:0.2731, R:0.0105)

============================================================
Epoch 71/300 completed in 21.1s
Train: Loss=0.2650 (C:0.2650, R:0.0105) Ratio=5.31x
Val:   Loss=0.3546 (C:0.3546, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.300
No improvement for 6 epochs
============================================================

Epoch 72 Training
----------------------------------------
Batch   0/537: Loss=0.2629 (C:0.2629, R:0.0105)
Batch  25/537: Loss=0.2725 (C:0.2725, R:0.0105)
Batch  50/537: Loss=0.2770 (C:0.2770, R:0.0106)
Batch  75/537: Loss=0.2488 (C:0.2488, R:0.0105)
Batch 100/537: Loss=0.2630 (C:0.2630, R:0.0105)
Batch 125/537: Loss=0.2545 (C:0.2545, R:0.0105)
Batch 150/537: Loss=0.2600 (C:0.2600, R:0.0105)
Batch 175/537: Loss=0.2513 (C:0.2513, R:0.0105)
Batch 200/537: Loss=0.2679 (C:0.2679, R:0.0105)
Batch 225/537: Loss=0.2523 (C:0.2523, R:0.0105)
Batch 250/537: Loss=0.2730 (C:0.2730, R:0.0106)
Batch 275/537: Loss=0.2758 (C:0.2758, R:0.0105)
Batch 300/537: Loss=0.2693 (C:0.2693, R:0.0105)
Batch 325/537: Loss=0.2588 (C:0.2588, R:0.0105)
Batch 350/537: Loss=0.2674 (C:0.2674, R:0.0105)
Batch 375/537: Loss=0.2678 (C:0.2678, R:0.0105)
Batch 400/537: Loss=0.2714 (C:0.2714, R:0.0105)
Batch 425/537: Loss=0.2536 (C:0.2536, R:0.0105)
Batch 450/537: Loss=0.2563 (C:0.2563, R:0.0105)
Batch 475/537: Loss=0.2692 (C:0.2692, R:0.0105)
Batch 500/537: Loss=0.2570 (C:0.2570, R:0.0105)
Batch 525/537: Loss=0.2688 (C:0.2688, R:0.0105)

============================================================
Epoch 72/300 completed in 21.9s
Train: Loss=0.2637 (C:0.2637, R:0.0105) Ratio=5.25x
Val:   Loss=0.3560 (C:0.3560, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 7 epochs
============================================================

🌍 Updating global dataset at epoch 73
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.140 ± 0.270
    Neg distances: 1.356 ± 0.554
    Separation ratio: 9.66x
    Gap: -2.264
    ✅ Excellent global separation!

Epoch 73 Training
----------------------------------------
Batch   0/537: Loss=0.2384 (C:0.2384, R:0.0105)
Batch  25/537: Loss=0.2393 (C:0.2393, R:0.0105)
Batch  50/537: Loss=0.2550 (C:0.2550, R:0.0105)
Batch  75/537: Loss=0.2656 (C:0.2656, R:0.0105)
Batch 100/537: Loss=0.2294 (C:0.2294, R:0.0105)
Batch 125/537: Loss=0.2660 (C:0.2660, R:0.0105)
Batch 150/537: Loss=0.2594 (C:0.2594, R:0.0105)
Batch 175/537: Loss=0.2560 (C:0.2560, R:0.0105)
Batch 200/537: Loss=0.2474 (C:0.2474, R:0.0105)
Batch 225/537: Loss=0.2682 (C:0.2682, R:0.0105)
Batch 250/537: Loss=0.2497 (C:0.2497, R:0.0105)
Batch 275/537: Loss=0.2393 (C:0.2393, R:0.0104)
Batch 300/537: Loss=0.2629 (C:0.2629, R:0.0105)
Batch 325/537: Loss=0.2411 (C:0.2411, R:0.0105)
Batch 350/537: Loss=0.2646 (C:0.2646, R:0.0105)
Batch 375/537: Loss=0.2403 (C:0.2403, R:0.0106)
Batch 400/537: Loss=0.2583 (C:0.2583, R:0.0105)
Batch 425/537: Loss=0.2615 (C:0.2615, R:0.0105)
Batch 450/537: Loss=0.2773 (C:0.2773, R:0.0105)
Batch 475/537: Loss=0.2674 (C:0.2674, R:0.0105)
Batch 500/537: Loss=0.2464 (C:0.2464, R:0.0105)
Batch 525/537: Loss=0.2696 (C:0.2696, R:0.0105)

============================================================
Epoch 73/300 completed in 28.2s
Train: Loss=0.2541 (C:0.2541, R:0.0105) Ratio=5.26x
Val:   Loss=0.3468 (C:0.3468, R:0.0104) Ratio=3.12x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.3468)
============================================================

Epoch 74 Training
----------------------------------------
Batch   0/537: Loss=0.2573 (C:0.2573, R:0.0105)
Batch  25/537: Loss=0.2513 (C:0.2513, R:0.0105)
Batch  50/537: Loss=0.2545 (C:0.2545, R:0.0105)
Batch  75/537: Loss=0.2685 (C:0.2685, R:0.0105)
Batch 100/537: Loss=0.2428 (C:0.2428, R:0.0105)
Batch 125/537: Loss=0.2518 (C:0.2518, R:0.0105)
Batch 150/537: Loss=0.2487 (C:0.2487, R:0.0105)
Batch 175/537: Loss=0.2552 (C:0.2552, R:0.0105)
Batch 200/537: Loss=0.2512 (C:0.2512, R:0.0105)
Batch 225/537: Loss=0.2541 (C:0.2541, R:0.0106)
Batch 250/537: Loss=0.2614 (C:0.2614, R:0.0105)
Batch 275/537: Loss=0.2562 (C:0.2562, R:0.0105)
Batch 300/537: Loss=0.2495 (C:0.2495, R:0.0105)
Batch 325/537: Loss=0.2688 (C:0.2688, R:0.0105)
Batch 350/537: Loss=0.2644 (C:0.2644, R:0.0105)
Batch 375/537: Loss=0.2591 (C:0.2591, R:0.0105)
Batch 400/537: Loss=0.2573 (C:0.2573, R:0.0105)
Batch 425/537: Loss=0.2585 (C:0.2585, R:0.0105)
Batch 450/537: Loss=0.2427 (C:0.2427, R:0.0105)
Batch 475/537: Loss=0.2489 (C:0.2489, R:0.0105)
Batch 500/537: Loss=0.2523 (C:0.2523, R:0.0105)
Batch 525/537: Loss=0.2693 (C:0.2693, R:0.0106)

============================================================
Epoch 74/300 completed in 21.2s
Train: Loss=0.2529 (C:0.2529, R:0.0105) Ratio=5.30x
Val:   Loss=0.3498 (C:0.3498, R:0.0104) Ratio=3.03x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

Epoch 75 Training
----------------------------------------
Batch   0/537: Loss=0.2575 (C:0.2575, R:0.0105)
Batch  25/537: Loss=0.2554 (C:0.2554, R:0.0105)
Batch  50/537: Loss=0.2587 (C:0.2587, R:0.0105)
Batch  75/537: Loss=0.2544 (C:0.2544, R:0.0105)
Batch 100/537: Loss=0.2500 (C:0.2500, R:0.0105)
Batch 125/537: Loss=0.2502 (C:0.2502, R:0.0105)
Batch 150/537: Loss=0.2477 (C:0.2477, R:0.0105)
Batch 175/537: Loss=0.2547 (C:0.2547, R:0.0105)
Batch 200/537: Loss=0.2402 (C:0.2402, R:0.0105)
Batch 225/537: Loss=0.2424 (C:0.2424, R:0.0105)
Batch 250/537: Loss=0.2395 (C:0.2395, R:0.0105)
Batch 275/537: Loss=0.2483 (C:0.2483, R:0.0105)
Batch 300/537: Loss=0.2616 (C:0.2616, R:0.0105)
Batch 325/537: Loss=0.2612 (C:0.2612, R:0.0105)
Batch 350/537: Loss=0.2485 (C:0.2485, R:0.0105)
Batch 375/537: Loss=0.2623 (C:0.2623, R:0.0105)
Batch 400/537: Loss=0.2599 (C:0.2599, R:0.0105)
Batch 425/537: Loss=0.2420 (C:0.2420, R:0.0105)
Batch 450/537: Loss=0.2539 (C:0.2539, R:0.0105)
Batch 475/537: Loss=0.2507 (C:0.2507, R:0.0105)
Batch 500/537: Loss=0.2526 (C:0.2526, R:0.0105)
Batch 525/537: Loss=0.2561 (C:0.2561, R:0.0105)

============================================================
Epoch 75/300 completed in 21.6s
Train: Loss=0.2529 (C:0.2529, R:0.0105) Ratio=5.35x
Val:   Loss=0.3474 (C:0.3474, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 76
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.135 ± 0.254
    Neg distances: 1.380 ± 0.555
    Separation ratio: 10.23x
    Gap: -2.290
    ✅ Excellent global separation!

Epoch 76 Training
----------------------------------------
Batch   0/537: Loss=0.2364 (C:0.2364, R:0.0105)
Batch  25/537: Loss=0.2540 (C:0.2540, R:0.0105)
Batch  50/537: Loss=0.2439 (C:0.2439, R:0.0105)
Batch  75/537: Loss=0.2510 (C:0.2510, R:0.0105)
Batch 100/537: Loss=0.2514 (C:0.2514, R:0.0105)
Batch 125/537: Loss=0.2282 (C:0.2282, R:0.0105)
Batch 150/537: Loss=0.2484 (C:0.2484, R:0.0105)
Batch 175/537: Loss=0.2442 (C:0.2442, R:0.0105)
Batch 200/537: Loss=0.2355 (C:0.2355, R:0.0105)
Batch 225/537: Loss=0.2558 (C:0.2558, R:0.0105)
Batch 250/537: Loss=0.2500 (C:0.2500, R:0.0105)
Batch 275/537: Loss=0.2344 (C:0.2344, R:0.0105)
Batch 300/537: Loss=0.2519 (C:0.2519, R:0.0105)
Batch 325/537: Loss=0.2475 (C:0.2475, R:0.0105)
Batch 350/537: Loss=0.2529 (C:0.2529, R:0.0106)
Batch 375/537: Loss=0.2621 (C:0.2621, R:0.0105)
Batch 400/537: Loss=0.2487 (C:0.2487, R:0.0105)
Batch 425/537: Loss=0.2328 (C:0.2328, R:0.0105)
Batch 450/537: Loss=0.2551 (C:0.2551, R:0.0106)
Batch 475/537: Loss=0.2580 (C:0.2580, R:0.0105)
Batch 500/537: Loss=0.2529 (C:0.2529, R:0.0105)
Batch 525/537: Loss=0.2392 (C:0.2392, R:0.0105)

============================================================
Epoch 76/300 completed in 27.4s
Train: Loss=0.2479 (C:0.2479, R:0.0105) Ratio=5.41x
Val:   Loss=0.3443 (C:0.3443, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.3443)
============================================================

Epoch 77 Training
----------------------------------------
Batch   0/537: Loss=0.2353 (C:0.2353, R:0.0105)
Batch  25/537: Loss=0.2569 (C:0.2569, R:0.0105)
Batch  50/537: Loss=0.2393 (C:0.2393, R:0.0105)
Batch  75/537: Loss=0.2409 (C:0.2409, R:0.0105)
Batch 100/537: Loss=0.2498 (C:0.2498, R:0.0105)
Batch 125/537: Loss=0.2426 (C:0.2426, R:0.0105)
Batch 150/537: Loss=0.2359 (C:0.2359, R:0.0105)
Batch 175/537: Loss=0.2493 (C:0.2493, R:0.0105)
Batch 200/537: Loss=0.2643 (C:0.2643, R:0.0105)
Batch 225/537: Loss=0.2565 (C:0.2565, R:0.0105)
Batch 250/537: Loss=0.2553 (C:0.2553, R:0.0106)
Batch 275/537: Loss=0.2355 (C:0.2355, R:0.0105)
Batch 300/537: Loss=0.2511 (C:0.2511, R:0.0105)
Batch 325/537: Loss=0.2437 (C:0.2437, R:0.0104)
Batch 350/537: Loss=0.2483 (C:0.2483, R:0.0105)
Batch 375/537: Loss=0.2578 (C:0.2578, R:0.0105)
Batch 400/537: Loss=0.2472 (C:0.2472, R:0.0105)
Batch 425/537: Loss=0.2513 (C:0.2513, R:0.0105)
Batch 450/537: Loss=0.2353 (C:0.2353, R:0.0105)
Batch 475/537: Loss=0.2689 (C:0.2689, R:0.0106)
Batch 500/537: Loss=0.2435 (C:0.2435, R:0.0105)
Batch 525/537: Loss=0.2450 (C:0.2450, R:0.0105)

============================================================
Epoch 77/300 completed in 21.1s
Train: Loss=0.2463 (C:0.2463, R:0.0105) Ratio=5.34x
Val:   Loss=0.3419 (C:0.3419, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.3419)
============================================================

Epoch 78 Training
----------------------------------------
Batch   0/537: Loss=0.2362 (C:0.2362, R:0.0105)
Batch  25/537: Loss=0.2405 (C:0.2405, R:0.0105)
Batch  50/537: Loss=0.2504 (C:0.2504, R:0.0105)
Batch  75/537: Loss=0.2369 (C:0.2369, R:0.0105)
Batch 100/537: Loss=0.2368 (C:0.2368, R:0.0105)
Batch 125/537: Loss=0.2388 (C:0.2388, R:0.0105)
Batch 150/537: Loss=0.2383 (C:0.2383, R:0.0105)
Batch 175/537: Loss=0.2478 (C:0.2478, R:0.0105)
Batch 200/537: Loss=0.2353 (C:0.2353, R:0.0105)
Batch 225/537: Loss=0.2560 (C:0.2560, R:0.0105)
Batch 250/537: Loss=0.2291 (C:0.2291, R:0.0105)
Batch 275/537: Loss=0.2274 (C:0.2274, R:0.0105)
Batch 300/537: Loss=0.2409 (C:0.2409, R:0.0105)
Batch 325/537: Loss=0.2665 (C:0.2665, R:0.0105)
Batch 350/537: Loss=0.2368 (C:0.2368, R:0.0105)
Batch 375/537: Loss=0.2354 (C:0.2354, R:0.0105)
Batch 400/537: Loss=0.2378 (C:0.2378, R:0.0104)
Batch 425/537: Loss=0.2537 (C:0.2537, R:0.0105)
Batch 450/537: Loss=0.2535 (C:0.2535, R:0.0105)
Batch 475/537: Loss=0.2553 (C:0.2553, R:0.0105)
Batch 500/537: Loss=0.2558 (C:0.2558, R:0.0105)
Batch 525/537: Loss=0.2612 (C:0.2612, R:0.0105)

============================================================
Epoch 78/300 completed in 21.2s
Train: Loss=0.2458 (C:0.2458, R:0.0105) Ratio=5.45x
Val:   Loss=0.3406 (C:0.3406, R:0.0104) Ratio=3.12x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.3406)
============================================================

🌍 Updating global dataset at epoch 79
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.136 ± 0.268
    Neg distances: 1.362 ± 0.554
    Separation ratio: 9.99x
    Gap: -2.241
    ✅ Excellent global separation!

Epoch 79 Training
----------------------------------------
Batch   0/537: Loss=0.2506 (C:0.2506, R:0.0105)
Batch  25/537: Loss=0.2370 (C:0.2370, R:0.0105)
Batch  50/537: Loss=0.2585 (C:0.2585, R:0.0105)
Batch  75/537: Loss=0.2482 (C:0.2482, R:0.0105)
Batch 100/537: Loss=0.2537 (C:0.2537, R:0.0105)
Batch 125/537: Loss=0.2384 (C:0.2384, R:0.0105)
Batch 150/537: Loss=0.2492 (C:0.2492, R:0.0105)
Batch 175/537: Loss=0.2319 (C:0.2319, R:0.0105)
Batch 200/537: Loss=0.2521 (C:0.2521, R:0.0105)
Batch 225/537: Loss=0.2474 (C:0.2474, R:0.0105)
Batch 250/537: Loss=0.2565 (C:0.2565, R:0.0105)
Batch 275/537: Loss=0.2406 (C:0.2406, R:0.0105)
Batch 300/537: Loss=0.2502 (C:0.2502, R:0.0105)
Batch 325/537: Loss=0.2519 (C:0.2519, R:0.0105)
Batch 350/537: Loss=0.2532 (C:0.2532, R:0.0105)
Batch 375/537: Loss=0.2660 (C:0.2660, R:0.0105)
Batch 400/537: Loss=0.2677 (C:0.2677, R:0.0106)
Batch 425/537: Loss=0.2434 (C:0.2434, R:0.0105)
Batch 450/537: Loss=0.2418 (C:0.2418, R:0.0105)
Batch 475/537: Loss=0.2733 (C:0.2733, R:0.0105)
Batch 500/537: Loss=0.2377 (C:0.2377, R:0.0105)
Batch 525/537: Loss=0.2395 (C:0.2395, R:0.0105)

============================================================
Epoch 79/300 completed in 28.2s
Train: Loss=0.2484 (C:0.2484, R:0.0105) Ratio=5.39x
Val:   Loss=0.3468 (C:0.3468, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

Epoch 80 Training
----------------------------------------
Batch   0/537: Loss=0.2488 (C:0.2488, R:0.0105)
Batch  25/537: Loss=0.2534 (C:0.2534, R:0.0105)
Batch  50/537: Loss=0.2452 (C:0.2452, R:0.0105)
Batch  75/537: Loss=0.2521 (C:0.2521, R:0.0105)
Batch 100/537: Loss=0.2468 (C:0.2468, R:0.0105)
Batch 125/537: Loss=0.2385 (C:0.2385, R:0.0105)
Batch 150/537: Loss=0.2301 (C:0.2301, R:0.0105)
Batch 175/537: Loss=0.2544 (C:0.2544, R:0.0105)
Batch 200/537: Loss=0.2345 (C:0.2345, R:0.0105)
Batch 225/537: Loss=0.2260 (C:0.2260, R:0.0105)
Batch 250/537: Loss=0.2542 (C:0.2542, R:0.0105)
Batch 275/537: Loss=0.2399 (C:0.2399, R:0.0105)
Batch 300/537: Loss=0.2496 (C:0.2496, R:0.0105)
Batch 325/537: Loss=0.2506 (C:0.2506, R:0.0105)
Batch 350/537: Loss=0.2486 (C:0.2486, R:0.0105)
Batch 375/537: Loss=0.2370 (C:0.2370, R:0.0106)
Batch 400/537: Loss=0.2581 (C:0.2581, R:0.0105)
Batch 425/537: Loss=0.2543 (C:0.2543, R:0.0105)
Batch 450/537: Loss=0.2436 (C:0.2436, R:0.0105)
Batch 475/537: Loss=0.2445 (C:0.2445, R:0.0105)
Batch 500/537: Loss=0.2470 (C:0.2470, R:0.0105)
Batch 525/537: Loss=0.2536 (C:0.2536, R:0.0105)

============================================================
Epoch 80/300 completed in 21.6s
Train: Loss=0.2475 (C:0.2475, R:0.0105) Ratio=5.49x
Val:   Loss=0.3420 (C:0.3420, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
No improvement for 2 epochs
Checkpoint saved at epoch 80
============================================================

Epoch 81 Training
----------------------------------------
Batch   0/537: Loss=0.2463 (C:0.2463, R:0.0105)
Batch  25/537: Loss=0.2500 (C:0.2500, R:0.0105)
Batch  50/537: Loss=0.2258 (C:0.2258, R:0.0106)
Batch  75/537: Loss=0.2569 (C:0.2569, R:0.0105)
Batch 100/537: Loss=0.2580 (C:0.2580, R:0.0105)
Batch 125/537: Loss=0.2445 (C:0.2445, R:0.0105)
Batch 150/537: Loss=0.2160 (C:0.2160, R:0.0105)
Batch 175/537: Loss=0.2490 (C:0.2490, R:0.0105)
Batch 200/537: Loss=0.2488 (C:0.2488, R:0.0105)
Batch 225/537: Loss=0.2430 (C:0.2430, R:0.0105)
Batch 250/537: Loss=0.2534 (C:0.2534, R:0.0105)
Batch 275/537: Loss=0.2482 (C:0.2482, R:0.0105)
Batch 300/537: Loss=0.2643 (C:0.2643, R:0.0105)
Batch 325/537: Loss=0.2573 (C:0.2573, R:0.0105)
Batch 350/537: Loss=0.2709 (C:0.2709, R:0.0105)
Batch 375/537: Loss=0.2546 (C:0.2546, R:0.0105)
Batch 400/537: Loss=0.2642 (C:0.2642, R:0.0105)
Batch 425/537: Loss=0.2469 (C:0.2469, R:0.0105)
Batch 450/537: Loss=0.2427 (C:0.2427, R:0.0105)
Batch 475/537: Loss=0.2579 (C:0.2579, R:0.0105)
Batch 500/537: Loss=0.2602 (C:0.2602, R:0.0105)
Batch 525/537: Loss=0.2354 (C:0.2354, R:0.0105)

============================================================
Epoch 81/300 completed in 22.0s
Train: Loss=0.2469 (C:0.2469, R:0.0105) Ratio=5.43x
Val:   Loss=0.3423 (C:0.3423, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 82
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.147 ± 0.292
    Neg distances: 1.364 ± 0.557
    Separation ratio: 9.30x
    Gap: -2.311
    ✅ Excellent global separation!

Epoch 82 Training
----------------------------------------
Batch   0/537: Loss=0.2513 (C:0.2513, R:0.0105)
Batch  25/537: Loss=0.2557 (C:0.2557, R:0.0105)
Batch  50/537: Loss=0.2391 (C:0.2391, R:0.0105)
Batch  75/537: Loss=0.2420 (C:0.2420, R:0.0105)
Batch 100/537: Loss=0.2517 (C:0.2517, R:0.0105)
Batch 125/537: Loss=0.2556 (C:0.2556, R:0.0105)
Batch 150/537: Loss=0.2700 (C:0.2700, R:0.0105)
Batch 175/537: Loss=0.2469 (C:0.2469, R:0.0105)
Batch 200/537: Loss=0.2604 (C:0.2604, R:0.0105)
Batch 225/537: Loss=0.2655 (C:0.2655, R:0.0105)
Batch 250/537: Loss=0.2625 (C:0.2625, R:0.0105)
Batch 275/537: Loss=0.2541 (C:0.2541, R:0.0105)
Batch 300/537: Loss=0.2613 (C:0.2613, R:0.0105)
Batch 325/537: Loss=0.2644 (C:0.2644, R:0.0105)
Batch 350/537: Loss=0.2432 (C:0.2432, R:0.0105)
Batch 375/537: Loss=0.2508 (C:0.2508, R:0.0105)
Batch 400/537: Loss=0.2607 (C:0.2607, R:0.0105)
Batch 425/537: Loss=0.2422 (C:0.2422, R:0.0105)
Batch 450/537: Loss=0.2468 (C:0.2468, R:0.0105)
Batch 475/537: Loss=0.2580 (C:0.2580, R:0.0105)
Batch 500/537: Loss=0.2670 (C:0.2670, R:0.0105)
Batch 525/537: Loss=0.2424 (C:0.2424, R:0.0105)

============================================================
Epoch 82/300 completed in 27.8s
Train: Loss=0.2522 (C:0.2522, R:0.0105) Ratio=5.49x
Val:   Loss=0.3528 (C:0.3528, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.300
No improvement for 4 epochs
============================================================

Epoch 83 Training
----------------------------------------
Batch   0/537: Loss=0.2532 (C:0.2532, R:0.0105)
Batch  25/537: Loss=0.2555 (C:0.2555, R:0.0106)
Batch  50/537: Loss=0.2474 (C:0.2474, R:0.0105)
Batch  75/537: Loss=0.2431 (C:0.2431, R:0.0105)
Batch 100/537: Loss=0.2452 (C:0.2452, R:0.0105)
Batch 125/537: Loss=0.2531 (C:0.2531, R:0.0106)
Batch 150/537: Loss=0.2546 (C:0.2546, R:0.0105)
Batch 175/537: Loss=0.2586 (C:0.2586, R:0.0105)
Batch 200/537: Loss=0.2410 (C:0.2410, R:0.0105)
Batch 225/537: Loss=0.2522 (C:0.2522, R:0.0105)
Batch 250/537: Loss=0.2621 (C:0.2621, R:0.0105)
Batch 275/537: Loss=0.2702 (C:0.2702, R:0.0105)
Batch 300/537: Loss=0.2473 (C:0.2473, R:0.0105)
Batch 325/537: Loss=0.2654 (C:0.2654, R:0.0105)
Batch 350/537: Loss=0.2456 (C:0.2456, R:0.0105)
Batch 375/537: Loss=0.2578 (C:0.2578, R:0.0105)
Batch 400/537: Loss=0.2532 (C:0.2532, R:0.0105)
Batch 425/537: Loss=0.2693 (C:0.2693, R:0.0105)
Batch 450/537: Loss=0.2477 (C:0.2477, R:0.0106)
Batch 475/537: Loss=0.2516 (C:0.2516, R:0.0105)
Batch 500/537: Loss=0.2518 (C:0.2518, R:0.0105)
Batch 525/537: Loss=0.2388 (C:0.2388, R:0.0105)

============================================================
Epoch 83/300 completed in 21.9s
Train: Loss=0.2521 (C:0.2521, R:0.0105) Ratio=5.53x
Val:   Loss=0.3489 (C:0.3489, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 5 epochs
============================================================

Epoch 84 Training
----------------------------------------
Batch   0/537: Loss=0.2510 (C:0.2510, R:0.0105)
Batch  25/537: Loss=0.2344 (C:0.2344, R:0.0105)
Batch  50/537: Loss=0.2486 (C:0.2486, R:0.0105)
Batch  75/537: Loss=0.2460 (C:0.2460, R:0.0105)
Batch 100/537: Loss=0.2564 (C:0.2564, R:0.0105)
Batch 125/537: Loss=0.2521 (C:0.2521, R:0.0105)
Batch 150/537: Loss=0.2483 (C:0.2483, R:0.0105)
Batch 175/537: Loss=0.2583 (C:0.2583, R:0.0105)
Batch 200/537: Loss=0.2619 (C:0.2619, R:0.0106)
Batch 225/537: Loss=0.2669 (C:0.2669, R:0.0105)
Batch 250/537: Loss=0.2711 (C:0.2711, R:0.0106)
Batch 275/537: Loss=0.2687 (C:0.2687, R:0.0105)
Batch 300/537: Loss=0.2455 (C:0.2455, R:0.0105)
Batch 325/537: Loss=0.2359 (C:0.2359, R:0.0105)
Batch 350/537: Loss=0.2504 (C:0.2504, R:0.0105)
Batch 375/537: Loss=0.2547 (C:0.2547, R:0.0105)
Batch 400/537: Loss=0.2571 (C:0.2571, R:0.0105)
Batch 425/537: Loss=0.2578 (C:0.2578, R:0.0105)
Batch 450/537: Loss=0.2536 (C:0.2536, R:0.0106)
Batch 475/537: Loss=0.2660 (C:0.2660, R:0.0105)
Batch 500/537: Loss=0.2493 (C:0.2493, R:0.0105)
Batch 525/537: Loss=0.2459 (C:0.2459, R:0.0105)

============================================================
Epoch 84/300 completed in 21.8s
Train: Loss=0.2519 (C:0.2519, R:0.0105) Ratio=5.53x
Val:   Loss=0.3519 (C:0.3519, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
No improvement for 6 epochs
============================================================

🌍 Updating global dataset at epoch 85
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.135 ± 0.269
    Neg distances: 1.371 ± 0.554
    Separation ratio: 10.16x
    Gap: -2.256
    ✅ Excellent global separation!

Epoch 85 Training
----------------------------------------
Batch   0/537: Loss=0.2572 (C:0.2572, R:0.0105)
Batch  25/537: Loss=0.2441 (C:0.2441, R:0.0105)
Batch  50/537: Loss=0.2464 (C:0.2464, R:0.0105)
Batch  75/537: Loss=0.2387 (C:0.2387, R:0.0105)
Batch 100/537: Loss=0.2287 (C:0.2287, R:0.0105)
Batch 125/537: Loss=0.2549 (C:0.2549, R:0.0105)
Batch 150/537: Loss=0.2471 (C:0.2471, R:0.0105)
Batch 175/537: Loss=0.2385 (C:0.2385, R:0.0105)
Batch 200/537: Loss=0.2357 (C:0.2357, R:0.0105)
Batch 225/537: Loss=0.2442 (C:0.2442, R:0.0105)
Batch 250/537: Loss=0.2405 (C:0.2405, R:0.0105)
Batch 275/537: Loss=0.2396 (C:0.2396, R:0.0105)
Batch 300/537: Loss=0.2674 (C:0.2674, R:0.0105)
Batch 325/537: Loss=0.2450 (C:0.2450, R:0.0105)
Batch 350/537: Loss=0.2480 (C:0.2480, R:0.0105)
Batch 375/537: Loss=0.2418 (C:0.2418, R:0.0105)
Batch 400/537: Loss=0.2562 (C:0.2562, R:0.0104)
Batch 425/537: Loss=0.2497 (C:0.2497, R:0.0105)
Batch 450/537: Loss=0.2477 (C:0.2477, R:0.0105)
Batch 475/537: Loss=0.2415 (C:0.2415, R:0.0105)
Batch 500/537: Loss=0.2328 (C:0.2328, R:0.0106)
Batch 525/537: Loss=0.2577 (C:0.2577, R:0.0105)

============================================================
Epoch 85/300 completed in 27.4s
Train: Loss=0.2434 (C:0.2434, R:0.0105) Ratio=5.51x
Val:   Loss=0.3421 (C:0.3421, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 7 epochs
============================================================

Epoch 86 Training
----------------------------------------
Batch   0/537: Loss=0.2377 (C:0.2377, R:0.0105)
Batch  25/537: Loss=0.2454 (C:0.2454, R:0.0105)
Batch  50/537: Loss=0.2531 (C:0.2531, R:0.0105)
Batch  75/537: Loss=0.2380 (C:0.2380, R:0.0105)
Batch 100/537: Loss=0.2384 (C:0.2384, R:0.0105)
Batch 125/537: Loss=0.2419 (C:0.2419, R:0.0105)
Batch 150/537: Loss=0.2434 (C:0.2434, R:0.0105)
Batch 175/537: Loss=0.2316 (C:0.2316, R:0.0105)
Batch 200/537: Loss=0.2518 (C:0.2518, R:0.0105)
Batch 225/537: Loss=0.2337 (C:0.2337, R:0.0105)
Batch 250/537: Loss=0.2406 (C:0.2406, R:0.0106)
Batch 275/537: Loss=0.2405 (C:0.2405, R:0.0105)
Batch 300/537: Loss=0.2398 (C:0.2398, R:0.0105)
Batch 325/537: Loss=0.2286 (C:0.2286, R:0.0105)
Batch 350/537: Loss=0.2549 (C:0.2549, R:0.0105)
Batch 375/537: Loss=0.2497 (C:0.2497, R:0.0105)
Batch 400/537: Loss=0.2622 (C:0.2622, R:0.0105)
Batch 425/537: Loss=0.2611 (C:0.2611, R:0.0105)
Batch 450/537: Loss=0.2443 (C:0.2443, R:0.0105)
Batch 475/537: Loss=0.2669 (C:0.2669, R:0.0105)
Batch 500/537: Loss=0.2290 (C:0.2290, R:0.0105)
Batch 525/537: Loss=0.2589 (C:0.2589, R:0.0105)

============================================================
Epoch 86/300 completed in 22.0s
Train: Loss=0.2425 (C:0.2425, R:0.0105) Ratio=5.54x
Val:   Loss=0.3439 (C:0.3439, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 8 epochs

Early stopping triggered after 86 epochs
Best model was at epoch 78 with Val Loss: 0.3406

Global Dataset Training Completed!
Best epoch: 78
Best validation loss: 0.3406
Final separation ratios: Train=5.54x, Val=3.06x
Training completed!
Loading best model from entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin1.0_updatefreq3_max_global_samples5000_20250715_115010/checkpoints/best_model.pt
Starting model evaluation...
========================================
GlobalContrastiveEvaluator initialized on cuda
Starting comprehensive evaluation...
============================================================
Extracting latent representations...
  Processed 1/10 batches
Extracted representations: torch.Size([9824, 75])
Evaluating clustering performance...
Clustering Results:
  Silhouette Score: 0.4578
  Adjusted Rand Score: 0.5283
  Clustering Accuracy: 0.8139
Evaluating classification performance...
  Extracting training representations...
Extracting latent representations...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
Extracted representations: torch.Size([547740, 75])
  Extracting validation representations...
Extracting latent representations...
  Processed 1/9 batches
Extracted representations: torch.Size([9180, 75])
Subsampled training to 50000 samples
  Training on 50000 samples, evaluating on 9180 samples
Classification Results:
  Accuracy: 0.8115
  Per-class F1: [0.8323993886907795, 0.7487577639751553, 0.8582324655944289]
Evaluating reconstruction quality...
Reconstruction Results:
  Average MSE: 0.010432
Evaluating separation quality...
Separation Results:
  Positive distances: 0.391 ± 0.462
  Negative distances: 1.178 ± 0.630
  Separation ratio: 3.01x
  Gap: -2.289
  Perfect separation: No

Comprehensive evaluation completed!

============================================================
EVALUATION SUMMARY
============================================================
Clustering Performance:
  Silhouette Score: 0.4578
  Clustering Accuracy: 0.8139
  Adjusted Rand Score: 0.5283

Classification Performance:
  Accuracy: 0.8115

Separation Quality:
  Separation Ratio: 3.01x
  Gap: -2.289
  Perfect Separation: False

Reconstruction Quality:
  Average MSE: 0.010432
============================================================
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin1.0_updatefreq3_max_global_samples5000_20250715_115010/results/evaluation_results_20250715_122412.json
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin1.0_updatefreq3_max_global_samples5000_20250715_115010/results/evaluation_results_20250715_122412.json
Saving final experiment results...
Final results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin1.0_updatefreq3_max_global_samples5000_20250715_115010/final_results.json

============================================================
PIPELINE COMPLETED SUCCESSFULLY!
============================================================
Experiment directory: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin1.0_updatefreq3_max_global_samples5000_20250715_115010
Best model: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin1.0_updatefreq3_max_global_samples5000_20250715_115010/checkpoints/best_model.pt
Final results: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin1.0_updatefreq3_max_global_samples5000_20250715_115010/final_results.json

Key Results:
  Separation ratio: 3.01x
  Perfect separation: False
  Classification accuracy: 0.8115
  Result: 0.8115% (improvement: +-80.86%)
  Cleaning up: coarse_margin1.0_updatefreq3_max_global_samples5000_20250715_115010

[4/12] Testing: coarse_margin1.0_updatefreq3_max_global_samples10000
  margin: 1.0
  update_frequency: 3
  max_global_samples: 10000
  Reconstruction weight: 0.3 (fixed)
GLOBAL DATASET CONTRASTIVE AUTOENCODER PIPELINE
============================================================
Start time: 2025-07-15 12:24:12.907896
Using device: cuda

Configuration:
  Embedding type: concat
  Batch size: 1020
  Global update frequency: 3 epochs
  Training epochs: 300
Experiment setup completed:
  Experiment directory: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin1.0_updatefreq3_max_global_samples10000_20250715_122412
  Config saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin1.0_updatefreq3_max_global_samples10000_20250715_122412/config.json
Loading data...
========================================
FlexibleEmbedder initialized with type: 'concat'
Output dimension will be: 1536
GlobalDataLoader initialized:
  Embedding type: concat
  Output dimension: 1536
  Sample size: All
Starting data loading pipeline...
============================================================
Loading training data from data/processed/snli_full_standard_SBERT.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 549367 training samples
Loading validation data from data/processed/snli_full_standard_SBERT_validation.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9842 validation samples
Loading test data from data/processed/snli_full_standard_SBERT_test.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9824 test samples
Generating embeddings for training...
Generating concat embeddings on cuda
Processing 549367 samples in batches of 1000
  Processing batch 1/550
  Processing batch 6/550
  Processing batch 11/550
  Processing batch 16/550
  Processing batch 21/550
  Processing batch 26/550
  Processing batch 31/550
  Processing batch 36/550
  Processing batch 41/550
  Processing batch 46/550
  Processing batch 51/550
  Processing batch 56/550
  Processing batch 61/550
  Processing batch 66/550
  Processing batch 71/550
  Processing batch 76/550
  Processing batch 81/550
  Processing batch 86/550
  Processing batch 91/550
  Processing batch 96/550
  Processing batch 101/550
  Processing batch 106/550
  Processing batch 111/550
  Processing batch 116/550
  Processing batch 121/550
  Processing batch 126/550
  Processing batch 131/550
  Processing batch 136/550
  Processing batch 141/550
  Processing batch 146/550
  Processing batch 151/550
  Processing batch 156/550
  Processing batch 161/550
  Processing batch 166/550
  Processing batch 171/550
  Processing batch 176/550
  Processing batch 181/550
  Processing batch 186/550
  Processing batch 191/550
  Processing batch 196/550
  Processing batch 201/550
  Processing batch 206/550
  Processing batch 211/550
  Processing batch 216/550
  Processing batch 221/550
  Processing batch 226/550
  Processing batch 231/550
  Processing batch 236/550
  Processing batch 241/550
  Processing batch 246/550
  Processing batch 251/550
  Processing batch 256/550
  Processing batch 261/550
  Processing batch 266/550
  Processing batch 271/550
  Processing batch 276/550
  Processing batch 281/550
  Processing batch 286/550
  Processing batch 291/550
  Processing batch 296/550
  Processing batch 301/550
  Processing batch 306/550
  Processing batch 311/550
  Processing batch 316/550
  Processing batch 321/550
  Processing batch 326/550
  Processing batch 331/550
  Processing batch 336/550
  Processing batch 341/550
  Processing batch 346/550
  Processing batch 351/550
  Processing batch 356/550
  Processing batch 361/550
  Processing batch 366/550
  Processing batch 371/550
  Processing batch 376/550
  Processing batch 381/550
  Processing batch 386/550
  Processing batch 391/550
  Processing batch 396/550
  Processing batch 401/550
  Processing batch 406/550
  Processing batch 411/550
  Processing batch 416/550
  Processing batch 421/550
  Processing batch 426/550
  Processing batch 431/550
  Processing batch 436/550
  Processing batch 441/550
  Processing batch 446/550
  Processing batch 451/550
  Processing batch 456/550
  Processing batch 461/550
  Processing batch 466/550
  Processing batch 471/550
  Processing batch 476/550
  Processing batch 481/550
  Processing batch 486/550
  Processing batch 491/550
  Processing batch 496/550
  Processing batch 501/550
  Processing batch 506/550
  Processing batch 511/550
  Processing batch 516/550
  Processing batch 521/550
  Processing batch 526/550
  Processing batch 531/550
  Processing batch 536/550
  Processing batch 541/550
  Processing batch 546/550
Generated concat embeddings: torch.Size([549367, 1536])
Generating embeddings for validation...
Generating concat embeddings on cuda
Processing 9842 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9842, 1536])
Generating embeddings for test...
Generating concat embeddings on cuda
Processing 9824 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9824, 1536])
EntailmentDataset created: 549367 samples
  Embedding shape: torch.Size([549367, 1536])
  Class distribution: {'entailment': 183416, 'neutral': 182764, 'contradiction': 183187}
EntailmentDataset created: 9842 samples
  Embedding shape: torch.Size([9842, 1536])
  Class distribution: {'entailment': 3329, 'neutral': 3235, 'contradiction': 3278}
EntailmentDataset created: 9824 samples
  Embedding shape: torch.Size([9824, 1536])
  Class distribution: {'entailment': 3368, 'neutral': 3219, 'contradiction': 3237}

Data loading pipeline completed!
Output embedding dimension: 1536
Updated model input_dim to: 1536
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 537
  Class 2: 183187 samples
  Class 0: 183416 samples
  Class 1: 182764 samples
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 9
  Class 2: 3278 samples
  Class 0: 3329 samples
  Class 1: 3235 samples
DataLoaders created:
  Batch size: 1020
  Balanced sampling: True
  Train batches: 537
  Val batches: 9
  Test batches: 10
Data loading completed!
  Train: 549367 samples, 537 batches
  Val: 9842 samples, 9 batches
  Test: 9824 samples, 10 batches
Creating model and trainer...
========================================
ContrastiveAutoencoder initialized:
  Input dim: 1536
  Latent dim: 75
  Hidden dims: [512, 256]
  Dropout rate: 0.2
  Total parameters: 1,876,555
Model created with 1,876,555 parameters
FullDatasetContrastiveLoss initialized:
  Margin: 1.0
  Update frequency: 3 epochs
  Max global samples: 10000
FullDatasetCombinedLoss initialized:
  Contrastive weight: 1.0
  Base reconstruction weight: 0.0
  Scheduled reconstruction: warmup=30 epochs, max_weight=0.3
Optimizer created (lr=0.0001)
GlobalDatasetTrainer initialized on device: cuda
Model parameters: 1,876,555
Starting training...
========================================
Starting Global Dataset Training...
============================================================

🌍 Updating global dataset at epoch 1
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.087 ± 0.010
    Neg distances: 0.087 ± 0.010
    Separation ratio: 1.00x
    Gap: -0.135
    ❌ Poor global separation

Epoch 1 Training
----------------------------------------
Batch   0/537: Loss=0.9998 (C:0.9998, R:0.0117)
Batch  25/537: Loss=0.9951 (C:0.9951, R:0.0114)
Batch  50/537: Loss=0.9879 (C:0.9879, R:0.0113)
Batch  75/537: Loss=0.9849 (C:0.9849, R:0.0111)
Batch 100/537: Loss=0.9795 (C:0.9795, R:0.0110)
Batch 125/537: Loss=0.9763 (C:0.9763, R:0.0109)
Batch 150/537: Loss=0.9726 (C:0.9726, R:0.0108)
Batch 175/537: Loss=0.9682 (C:0.9682, R:0.0108)
Batch 200/537: Loss=0.9682 (C:0.9682, R:0.0107)
Batch 225/537: Loss=0.9564 (C:0.9564, R:0.0107)
Batch 250/537: Loss=0.9588 (C:0.9588, R:0.0107)
Batch 275/537: Loss=0.9656 (C:0.9656, R:0.0106)
Batch 300/537: Loss=0.9606 (C:0.9606, R:0.0106)
Batch 325/537: Loss=0.9572 (C:0.9572, R:0.0106)
Batch 350/537: Loss=0.9527 (C:0.9527, R:0.0106)
Batch 375/537: Loss=0.9503 (C:0.9503, R:0.0105)
Batch 400/537: Loss=0.9523 (C:0.9523, R:0.0106)
Batch 425/537: Loss=0.9534 (C:0.9534, R:0.0105)
Batch 450/537: Loss=0.9504 (C:0.9504, R:0.0105)
Batch 475/537: Loss=0.9551 (C:0.9551, R:0.0106)
Batch 500/537: Loss=0.9496 (C:0.9496, R:0.0106)
Batch 525/537: Loss=0.9501 (C:0.9501, R:0.0105)

============================================================
Epoch 1/300 completed in 27.1s
Train: Loss=0.9642 (C:0.9642, R:0.0108) Ratio=1.65x
Val:   Loss=0.9453 (C:0.9453, R:0.0105) Ratio=2.19x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.9453)
============================================================

Epoch 2 Training
----------------------------------------
Batch   0/537: Loss=0.9440 (C:0.9440, R:0.0105)
Batch  25/537: Loss=0.9453 (C:0.9453, R:0.0105)
Batch  50/537: Loss=0.9445 (C:0.9445, R:0.0105)
Batch  75/537: Loss=0.9456 (C:0.9456, R:0.0105)
Batch 100/537: Loss=0.9422 (C:0.9422, R:0.0105)
Batch 125/537: Loss=0.9413 (C:0.9413, R:0.0105)
Batch 150/537: Loss=0.9450 (C:0.9450, R:0.0105)
Batch 175/537: Loss=0.9471 (C:0.9471, R:0.0105)
Batch 200/537: Loss=0.9405 (C:0.9405, R:0.0105)
Batch 225/537: Loss=0.9428 (C:0.9428, R:0.0105)
Batch 250/537: Loss=0.9462 (C:0.9462, R:0.0105)
Batch 275/537: Loss=0.9494 (C:0.9494, R:0.0105)
Batch 300/537: Loss=0.9418 (C:0.9418, R:0.0105)
Batch 325/537: Loss=0.9390 (C:0.9390, R:0.0105)
Batch 350/537: Loss=0.9458 (C:0.9458, R:0.0105)
Batch 375/537: Loss=0.9359 (C:0.9359, R:0.0105)
Batch 400/537: Loss=0.9453 (C:0.9453, R:0.0105)
Batch 425/537: Loss=0.9417 (C:0.9417, R:0.0105)
Batch 450/537: Loss=0.9402 (C:0.9402, R:0.0105)
Batch 475/537: Loss=0.9396 (C:0.9396, R:0.0105)
Batch 500/537: Loss=0.9421 (C:0.9421, R:0.0105)
Batch 525/537: Loss=0.9478 (C:0.9478, R:0.0105)

============================================================
Epoch 2/300 completed in 21.0s
Train: Loss=0.9436 (C:0.9436, R:0.0105) Ratio=2.23x
Val:   Loss=0.9381 (C:0.9381, R:0.0104) Ratio=2.43x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.9381)
============================================================

Epoch 3 Training
----------------------------------------
Batch   0/537: Loss=0.9352 (C:0.9352, R:0.0105)
Batch  25/537: Loss=0.9396 (C:0.9396, R:0.0105)
Batch  50/537: Loss=0.9309 (C:0.9309, R:0.0105)
Batch  75/537: Loss=0.9388 (C:0.9388, R:0.0105)
Batch 100/537: Loss=0.9381 (C:0.9381, R:0.0105)
Batch 125/537: Loss=0.9327 (C:0.9327, R:0.0105)
Batch 150/537: Loss=0.9395 (C:0.9395, R:0.0105)
Batch 175/537: Loss=0.9327 (C:0.9327, R:0.0105)
Batch 200/537: Loss=0.9378 (C:0.9378, R:0.0105)
Batch 225/537: Loss=0.9264 (C:0.9264, R:0.0105)
Batch 250/537: Loss=0.9402 (C:0.9402, R:0.0105)
Batch 275/537: Loss=0.9388 (C:0.9388, R:0.0105)
Batch 300/537: Loss=0.9351 (C:0.9351, R:0.0105)
Batch 325/537: Loss=0.9337 (C:0.9337, R:0.0105)
Batch 350/537: Loss=0.9404 (C:0.9404, R:0.0105)
Batch 375/537: Loss=0.9378 (C:0.9378, R:0.0105)
Batch 400/537: Loss=0.9326 (C:0.9326, R:0.0105)
Batch 425/537: Loss=0.9344 (C:0.9344, R:0.0105)
Batch 450/537: Loss=0.9464 (C:0.9464, R:0.0105)
Batch 475/537: Loss=0.9391 (C:0.9391, R:0.0106)
Batch 500/537: Loss=0.9391 (C:0.9391, R:0.0105)
Batch 525/537: Loss=0.9456 (C:0.9456, R:0.0105)

============================================================
Epoch 3/300 completed in 21.0s
Train: Loss=0.9374 (C:0.9374, R:0.0105) Ratio=2.45x
Val:   Loss=0.9323 (C:0.9323, R:0.0104) Ratio=2.58x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.9323)
============================================================

🌍 Updating global dataset at epoch 4
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.245 ± 0.277
    Neg distances: 0.701 ± 0.414
    Separation ratio: 2.86x
    Gap: -1.426
    ✅ Good global separation

Epoch 4 Training
----------------------------------------
Batch   0/537: Loss=0.5911 (C:0.5911, R:0.0105)
Batch  25/537: Loss=0.5950 (C:0.5950, R:0.0105)
Batch  50/537: Loss=0.5858 (C:0.5858, R:0.0105)
Batch  75/537: Loss=0.6096 (C:0.6096, R:0.0105)
Batch 100/537: Loss=0.6111 (C:0.6111, R:0.0105)
Batch 125/537: Loss=0.6066 (C:0.6066, R:0.0105)
Batch 150/537: Loss=0.5954 (C:0.5954, R:0.0105)
Batch 175/537: Loss=0.5984 (C:0.5984, R:0.0105)
Batch 200/537: Loss=0.6116 (C:0.6116, R:0.0105)
Batch 225/537: Loss=0.6130 (C:0.6130, R:0.0105)
Batch 250/537: Loss=0.6043 (C:0.6043, R:0.0105)
Batch 275/537: Loss=0.5894 (C:0.5894, R:0.0105)
Batch 300/537: Loss=0.6084 (C:0.6084, R:0.0105)
Batch 325/537: Loss=0.6035 (C:0.6035, R:0.0105)
Batch 350/537: Loss=0.6219 (C:0.6219, R:0.0105)
Batch 375/537: Loss=0.6121 (C:0.6121, R:0.0105)
Batch 400/537: Loss=0.6038 (C:0.6038, R:0.0105)
Batch 425/537: Loss=0.6226 (C:0.6226, R:0.0105)
Batch 450/537: Loss=0.5919 (C:0.5919, R:0.0105)
Batch 475/537: Loss=0.6091 (C:0.6091, R:0.0105)
Batch 500/537: Loss=0.6099 (C:0.6099, R:0.0105)
Batch 525/537: Loss=0.6116 (C:0.6116, R:0.0105)

============================================================
Epoch 4/300 completed in 27.4s
Train: Loss=0.6067 (C:0.6067, R:0.0105) Ratio=2.59x
Val:   Loss=0.5975 (C:0.5975, R:0.0104) Ratio=2.68x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.5975)
============================================================

Epoch 5 Training
----------------------------------------
Batch   0/537: Loss=0.5934 (C:0.5934, R:0.0105)
Batch  25/537: Loss=0.6039 (C:0.6039, R:0.0105)
Batch  50/537: Loss=0.5814 (C:0.5814, R:0.0105)
Batch  75/537: Loss=0.5826 (C:0.5826, R:0.0105)
Batch 100/537: Loss=0.5950 (C:0.5950, R:0.0105)
Batch 125/537: Loss=0.5917 (C:0.5917, R:0.0105)
Batch 150/537: Loss=0.5920 (C:0.5920, R:0.0105)
Batch 175/537: Loss=0.5981 (C:0.5981, R:0.0105)
Batch 200/537: Loss=0.5897 (C:0.5897, R:0.0105)
Batch 225/537: Loss=0.6009 (C:0.6009, R:0.0105)
Batch 250/537: Loss=0.5986 (C:0.5986, R:0.0105)
Batch 275/537: Loss=0.5979 (C:0.5979, R:0.0105)
Batch 300/537: Loss=0.6058 (C:0.6058, R:0.0105)
Batch 325/537: Loss=0.6002 (C:0.6002, R:0.0105)
Batch 350/537: Loss=0.6023 (C:0.6023, R:0.0105)
Batch 375/537: Loss=0.5799 (C:0.5799, R:0.0105)
Batch 400/537: Loss=0.6150 (C:0.6150, R:0.0105)
Batch 425/537: Loss=0.5835 (C:0.5835, R:0.0105)
Batch 450/537: Loss=0.6160 (C:0.6160, R:0.0105)
Batch 475/537: Loss=0.6079 (C:0.6079, R:0.0105)
Batch 500/537: Loss=0.5890 (C:0.5890, R:0.0105)
Batch 525/537: Loss=0.5769 (C:0.5769, R:0.0105)

============================================================
Epoch 5/300 completed in 21.7s
Train: Loss=0.5965 (C:0.5965, R:0.0105) Ratio=2.80x
Val:   Loss=0.5966 (C:0.5966, R:0.0104) Ratio=2.78x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.5966)
============================================================

Epoch 6 Training
----------------------------------------
Batch   0/537: Loss=0.5726 (C:0.5726, R:0.0105)
Batch  25/537: Loss=0.5794 (C:0.5794, R:0.0105)
Batch  50/537: Loss=0.5813 (C:0.5813, R:0.0105)
Batch  75/537: Loss=0.5884 (C:0.5884, R:0.0105)
Batch 100/537: Loss=0.5809 (C:0.5809, R:0.0105)
Batch 125/537: Loss=0.5777 (C:0.5777, R:0.0105)
Batch 150/537: Loss=0.5917 (C:0.5917, R:0.0105)
Batch 175/537: Loss=0.5842 (C:0.5842, R:0.0105)
Batch 200/537: Loss=0.5865 (C:0.5865, R:0.0105)
Batch 225/537: Loss=0.6090 (C:0.6090, R:0.0105)
Batch 250/537: Loss=0.6018 (C:0.6018, R:0.0105)
Batch 275/537: Loss=0.5875 (C:0.5875, R:0.0105)
Batch 300/537: Loss=0.5932 (C:0.5932, R:0.0105)
Batch 325/537: Loss=0.5952 (C:0.5952, R:0.0105)
Batch 350/537: Loss=0.5908 (C:0.5908, R:0.0105)
Batch 375/537: Loss=0.5850 (C:0.5850, R:0.0105)
Batch 400/537: Loss=0.5772 (C:0.5772, R:0.0105)
Batch 425/537: Loss=0.5935 (C:0.5935, R:0.0105)
Batch 450/537: Loss=0.5913 (C:0.5913, R:0.0105)
Batch 475/537: Loss=0.5937 (C:0.5937, R:0.0105)
Batch 500/537: Loss=0.5931 (C:0.5931, R:0.0105)
Batch 525/537: Loss=0.6095 (C:0.6095, R:0.0105)

============================================================
Epoch 6/300 completed in 21.9s
Train: Loss=0.5911 (C:0.5911, R:0.0105) Ratio=2.94x
Val:   Loss=0.5940 (C:0.5940, R:0.0104) Ratio=2.85x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.5940)
============================================================

🌍 Updating global dataset at epoch 7
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.222 ± 0.277
    Neg distances: 0.755 ± 0.424
    Separation ratio: 3.40x
    Gap: -1.445
    ✅ Excellent global separation!

Epoch 7 Training
----------------------------------------
Batch   0/537: Loss=0.5481 (C:0.5481, R:0.0105)
Batch  25/537: Loss=0.5538 (C:0.5538, R:0.0105)
Batch  50/537: Loss=0.5611 (C:0.5611, R:0.0105)
Batch  75/537: Loss=0.5562 (C:0.5562, R:0.0105)
Batch 100/537: Loss=0.5501 (C:0.5501, R:0.0105)
Batch 125/537: Loss=0.5743 (C:0.5743, R:0.0105)
Batch 150/537: Loss=0.5476 (C:0.5476, R:0.0105)
Batch 175/537: Loss=0.5549 (C:0.5549, R:0.0105)
Batch 200/537: Loss=0.5722 (C:0.5722, R:0.0105)
Batch 225/537: Loss=0.5688 (C:0.5688, R:0.0105)
Batch 250/537: Loss=0.5487 (C:0.5487, R:0.0105)
Batch 275/537: Loss=0.5576 (C:0.5576, R:0.0105)
Batch 300/537: Loss=0.5379 (C:0.5379, R:0.0105)
Batch 325/537: Loss=0.5603 (C:0.5603, R:0.0105)
Batch 350/537: Loss=0.5581 (C:0.5581, R:0.0105)
Batch 375/537: Loss=0.5609 (C:0.5609, R:0.0105)
Batch 400/537: Loss=0.5366 (C:0.5366, R:0.0105)
Batch 425/537: Loss=0.5464 (C:0.5464, R:0.0105)
Batch 450/537: Loss=0.5578 (C:0.5578, R:0.0105)
Batch 475/537: Loss=0.5756 (C:0.5756, R:0.0105)
Batch 500/537: Loss=0.5641 (C:0.5641, R:0.0105)
Batch 525/537: Loss=0.5508 (C:0.5508, R:0.0105)

============================================================
Epoch 7/300 completed in 27.8s
Train: Loss=0.5526 (C:0.5526, R:0.0105) Ratio=2.99x
Val:   Loss=0.5583 (C:0.5583, R:0.0104) Ratio=2.87x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.5583)
============================================================

Epoch 8 Training
----------------------------------------
Batch   0/537: Loss=0.5632 (C:0.5632, R:0.0105)
Batch  25/537: Loss=0.5512 (C:0.5512, R:0.0105)
Batch  50/537: Loss=0.5430 (C:0.5430, R:0.0105)
Batch  75/537: Loss=0.5518 (C:0.5518, R:0.0105)
Batch 100/537: Loss=0.5511 (C:0.5511, R:0.0105)
Batch 125/537: Loss=0.5393 (C:0.5393, R:0.0105)
Batch 150/537: Loss=0.5543 (C:0.5543, R:0.0106)
Batch 175/537: Loss=0.5514 (C:0.5514, R:0.0105)
Batch 200/537: Loss=0.5410 (C:0.5410, R:0.0105)
Batch 225/537: Loss=0.5477 (C:0.5477, R:0.0105)
Batch 250/537: Loss=0.5444 (C:0.5444, R:0.0105)
Batch 275/537: Loss=0.5506 (C:0.5506, R:0.0105)
Batch 300/537: Loss=0.5628 (C:0.5628, R:0.0105)
Batch 325/537: Loss=0.5572 (C:0.5572, R:0.0105)
Batch 350/537: Loss=0.5413 (C:0.5413, R:0.0105)
Batch 375/537: Loss=0.5456 (C:0.5456, R:0.0105)
Batch 400/537: Loss=0.5478 (C:0.5478, R:0.0105)
Batch 425/537: Loss=0.5465 (C:0.5465, R:0.0105)
Batch 450/537: Loss=0.5629 (C:0.5629, R:0.0105)
Batch 475/537: Loss=0.5451 (C:0.5451, R:0.0105)
Batch 500/537: Loss=0.5399 (C:0.5399, R:0.0106)
Batch 525/537: Loss=0.5467 (C:0.5467, R:0.0105)

============================================================
Epoch 8/300 completed in 21.6s
Train: Loss=0.5480 (C:0.5480, R:0.0105) Ratio=3.13x
Val:   Loss=0.5574 (C:0.5574, R:0.0104) Ratio=2.86x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.5574)
============================================================

Epoch 9 Training
----------------------------------------
Batch   0/537: Loss=0.5347 (C:0.5347, R:0.0105)
Batch  25/537: Loss=0.5414 (C:0.5414, R:0.0105)
Batch  50/537: Loss=0.5433 (C:0.5433, R:0.0105)
Batch  75/537: Loss=0.5563 (C:0.5563, R:0.0105)
Batch 100/537: Loss=0.5432 (C:0.5432, R:0.0105)
Batch 125/537: Loss=0.5278 (C:0.5278, R:0.0105)
Batch 150/537: Loss=0.5690 (C:0.5690, R:0.0105)
Batch 175/537: Loss=0.5531 (C:0.5531, R:0.0105)
Batch 200/537: Loss=0.5407 (C:0.5407, R:0.0105)
Batch 225/537: Loss=0.5482 (C:0.5482, R:0.0105)
Batch 250/537: Loss=0.5514 (C:0.5514, R:0.0105)
Batch 275/537: Loss=0.5498 (C:0.5498, R:0.0105)
Batch 300/537: Loss=0.5582 (C:0.5582, R:0.0105)
Batch 325/537: Loss=0.5287 (C:0.5287, R:0.0105)
Batch 350/537: Loss=0.5533 (C:0.5533, R:0.0105)
Batch 375/537: Loss=0.5518 (C:0.5518, R:0.0105)
Batch 400/537: Loss=0.5382 (C:0.5382, R:0.0105)
Batch 425/537: Loss=0.5470 (C:0.5470, R:0.0105)
Batch 450/537: Loss=0.5495 (C:0.5495, R:0.0105)
Batch 475/537: Loss=0.5533 (C:0.5533, R:0.0105)
Batch 500/537: Loss=0.5429 (C:0.5429, R:0.0105)
Batch 525/537: Loss=0.5302 (C:0.5302, R:0.0105)

============================================================
Epoch 9/300 completed in 21.5s
Train: Loss=0.5446 (C:0.5446, R:0.0105) Ratio=3.28x
Val:   Loss=0.5596 (C:0.5596, R:0.0104) Ratio=2.91x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 10
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.199 ± 0.268
    Neg distances: 0.794 ± 0.425
    Separation ratio: 3.99x
    Gap: -1.523
    ✅ Excellent global separation!

Epoch 10 Training
----------------------------------------
Batch   0/537: Loss=0.5072 (C:0.5072, R:0.0105)
Batch  25/537: Loss=0.5081 (C:0.5081, R:0.0105)
Batch  50/537: Loss=0.5121 (C:0.5121, R:0.0105)
Batch  75/537: Loss=0.5074 (C:0.5074, R:0.0105)
Batch 100/537: Loss=0.5082 (C:0.5082, R:0.0105)
Batch 125/537: Loss=0.5170 (C:0.5170, R:0.0106)
Batch 150/537: Loss=0.5377 (C:0.5377, R:0.0105)
Batch 175/537: Loss=0.4938 (C:0.4938, R:0.0105)
Batch 200/537: Loss=0.5123 (C:0.5123, R:0.0105)
Batch 225/537: Loss=0.5174 (C:0.5174, R:0.0105)
Batch 250/537: Loss=0.5109 (C:0.5109, R:0.0105)
Batch 275/537: Loss=0.5237 (C:0.5237, R:0.0105)
Batch 300/537: Loss=0.5093 (C:0.5093, R:0.0105)
Batch 325/537: Loss=0.5159 (C:0.5159, R:0.0105)
Batch 350/537: Loss=0.5165 (C:0.5165, R:0.0105)
Batch 375/537: Loss=0.5049 (C:0.5049, R:0.0105)
Batch 400/537: Loss=0.5084 (C:0.5084, R:0.0105)
Batch 425/537: Loss=0.5190 (C:0.5190, R:0.0105)
Batch 450/537: Loss=0.5372 (C:0.5372, R:0.0105)
Batch 475/537: Loss=0.5045 (C:0.5045, R:0.0105)
Batch 500/537: Loss=0.4961 (C:0.4961, R:0.0105)
Batch 525/537: Loss=0.5171 (C:0.5171, R:0.0105)

============================================================
Epoch 10/300 completed in 27.3s
Train: Loss=0.5129 (C:0.5129, R:0.0105) Ratio=3.32x
Val:   Loss=0.5269 (C:0.5269, R:0.0104) Ratio=2.93x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.5269)
============================================================

Epoch 11 Training
----------------------------------------
Batch   0/537: Loss=0.4981 (C:0.4981, R:0.0105)
Batch  25/537: Loss=0.5068 (C:0.5068, R:0.0106)
Batch  50/537: Loss=0.4986 (C:0.4986, R:0.0105)
Batch  75/537: Loss=0.5108 (C:0.5108, R:0.0105)
Batch 100/537: Loss=0.5105 (C:0.5105, R:0.0105)
Batch 125/537: Loss=0.5129 (C:0.5129, R:0.0105)
Batch 150/537: Loss=0.5038 (C:0.5038, R:0.0105)
Batch 175/537: Loss=0.5201 (C:0.5201, R:0.0105)
Batch 200/537: Loss=0.4954 (C:0.4954, R:0.0105)
Batch 225/537: Loss=0.5107 (C:0.5107, R:0.0105)
Batch 250/537: Loss=0.5292 (C:0.5292, R:0.0105)
Batch 275/537: Loss=0.5090 (C:0.5090, R:0.0105)
Batch 300/537: Loss=0.5176 (C:0.5176, R:0.0105)
Batch 325/537: Loss=0.4877 (C:0.4877, R:0.0105)
Batch 350/537: Loss=0.5084 (C:0.5084, R:0.0105)
Batch 375/537: Loss=0.5288 (C:0.5288, R:0.0106)
Batch 400/537: Loss=0.5281 (C:0.5281, R:0.0105)
Batch 425/537: Loss=0.5049 (C:0.5049, R:0.0105)
Batch 450/537: Loss=0.5290 (C:0.5290, R:0.0105)
Batch 475/537: Loss=0.5155 (C:0.5155, R:0.0105)
Batch 500/537: Loss=0.4993 (C:0.4993, R:0.0105)
Batch 525/537: Loss=0.5164 (C:0.5164, R:0.0105)

============================================================
Epoch 11/300 completed in 21.1s
Train: Loss=0.5094 (C:0.5094, R:0.0105) Ratio=3.41x
Val:   Loss=0.5302 (C:0.5302, R:0.0104) Ratio=2.94x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

Epoch 12 Training
----------------------------------------
Batch   0/537: Loss=0.5233 (C:0.5233, R:0.0105)
Batch  25/537: Loss=0.4969 (C:0.4969, R:0.0105)
Batch  50/537: Loss=0.4964 (C:0.4964, R:0.0105)
Batch  75/537: Loss=0.4888 (C:0.4888, R:0.0105)
Batch 100/537: Loss=0.5045 (C:0.5045, R:0.0105)
Batch 125/537: Loss=0.4962 (C:0.4962, R:0.0105)
Batch 150/537: Loss=0.5081 (C:0.5081, R:0.0105)
Batch 175/537: Loss=0.5190 (C:0.5190, R:0.0105)
Batch 200/537: Loss=0.5182 (C:0.5182, R:0.0105)
Batch 225/537: Loss=0.4923 (C:0.4923, R:0.0105)
Batch 250/537: Loss=0.5147 (C:0.5147, R:0.0105)
Batch 275/537: Loss=0.5077 (C:0.5077, R:0.0105)
Batch 300/537: Loss=0.4919 (C:0.4919, R:0.0105)
Batch 325/537: Loss=0.4907 (C:0.4907, R:0.0105)
Batch 350/537: Loss=0.5195 (C:0.5195, R:0.0105)
Batch 375/537: Loss=0.5005 (C:0.5005, R:0.0105)
Batch 400/537: Loss=0.5258 (C:0.5258, R:0.0105)
Batch 425/537: Loss=0.5013 (C:0.5013, R:0.0105)
Batch 450/537: Loss=0.5139 (C:0.5139, R:0.0105)
Batch 475/537: Loss=0.5057 (C:0.5057, R:0.0105)
Batch 500/537: Loss=0.5233 (C:0.5233, R:0.0105)
Batch 525/537: Loss=0.5048 (C:0.5048, R:0.0105)

============================================================
Epoch 12/300 completed in 21.4s
Train: Loss=0.5063 (C:0.5063, R:0.0105) Ratio=3.54x
Val:   Loss=0.5325 (C:0.5325, R:0.0104) Ratio=2.93x
Reconstruction weight: 0.000
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 13
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.185 ± 0.263
    Neg distances: 0.834 ± 0.432
    Separation ratio: 4.52x
    Gap: -1.582
    ✅ Excellent global separation!

Epoch 13 Training
----------------------------------------
Batch   0/537: Loss=0.4649 (C:0.4649, R:0.0105)
Batch  25/537: Loss=0.4902 (C:0.4902, R:0.0105)
Batch  50/537: Loss=0.4919 (C:0.4919, R:0.0105)
Batch  75/537: Loss=0.4855 (C:0.4855, R:0.0105)
Batch 100/537: Loss=0.4783 (C:0.4783, R:0.0105)
Batch 125/537: Loss=0.4803 (C:0.4803, R:0.0105)
Batch 150/537: Loss=0.4792 (C:0.4792, R:0.0105)
Batch 175/537: Loss=0.4850 (C:0.4850, R:0.0105)
Batch 200/537: Loss=0.4924 (C:0.4924, R:0.0105)
Batch 225/537: Loss=0.4597 (C:0.4597, R:0.0106)
Batch 250/537: Loss=0.4766 (C:0.4766, R:0.0105)
Batch 275/537: Loss=0.4676 (C:0.4676, R:0.0105)
Batch 300/537: Loss=0.4908 (C:0.4908, R:0.0106)
Batch 325/537: Loss=0.4960 (C:0.4960, R:0.0105)
Batch 350/537: Loss=0.4618 (C:0.4618, R:0.0105)
Batch 375/537: Loss=0.4902 (C:0.4902, R:0.0105)
Batch 400/537: Loss=0.4904 (C:0.4904, R:0.0105)
Batch 425/537: Loss=0.5133 (C:0.5133, R:0.0105)
Batch 450/537: Loss=0.4828 (C:0.4828, R:0.0105)
Batch 475/537: Loss=0.4695 (C:0.4695, R:0.0105)
Batch 500/537: Loss=0.4811 (C:0.4811, R:0.0105)
Batch 525/537: Loss=0.4968 (C:0.4968, R:0.0106)

============================================================
Epoch 13/300 completed in 26.9s
Train: Loss=0.4825 (C:0.4825, R:0.0105) Ratio=3.56x
Val:   Loss=0.5105 (C:0.5105, R:0.0104) Ratio=2.89x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.5105)
============================================================

Epoch 14 Training
----------------------------------------
Batch   0/537: Loss=0.4767 (C:0.4767, R:0.0105)
Batch  25/537: Loss=0.4837 (C:0.4837, R:0.0105)
Batch  50/537: Loss=0.4672 (C:0.4672, R:0.0105)
Batch  75/537: Loss=0.4649 (C:0.4649, R:0.0105)
Batch 100/537: Loss=0.4878 (C:0.4878, R:0.0105)
Batch 125/537: Loss=0.4641 (C:0.4641, R:0.0105)
Batch 150/537: Loss=0.4716 (C:0.4716, R:0.0105)
Batch 175/537: Loss=0.4621 (C:0.4621, R:0.0105)
Batch 200/537: Loss=0.4613 (C:0.4613, R:0.0105)
Batch 225/537: Loss=0.4873 (C:0.4873, R:0.0105)
Batch 250/537: Loss=0.4700 (C:0.4700, R:0.0105)
Batch 275/537: Loss=0.4569 (C:0.4569, R:0.0105)
Batch 300/537: Loss=0.4811 (C:0.4811, R:0.0105)
Batch 325/537: Loss=0.4692 (C:0.4692, R:0.0105)
Batch 350/537: Loss=0.4731 (C:0.4731, R:0.0105)
Batch 375/537: Loss=0.4788 (C:0.4788, R:0.0105)
Batch 400/537: Loss=0.4751 (C:0.4751, R:0.0105)
Batch 425/537: Loss=0.4849 (C:0.4849, R:0.0105)
Batch 450/537: Loss=0.4918 (C:0.4918, R:0.0105)
Batch 475/537: Loss=0.4822 (C:0.4822, R:0.0105)
Batch 500/537: Loss=0.4764 (C:0.4764, R:0.0105)
Batch 525/537: Loss=0.4792 (C:0.4792, R:0.0105)

============================================================
Epoch 14/300 completed in 21.2s
Train: Loss=0.4796 (C:0.4796, R:0.0105) Ratio=3.66x
Val:   Loss=0.5100 (C:0.5100, R:0.0104) Ratio=2.91x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.5100)
============================================================

Epoch 15 Training
----------------------------------------
Batch   0/537: Loss=0.4767 (C:0.4767, R:0.0105)
Batch  25/537: Loss=0.4969 (C:0.4969, R:0.0105)
Batch  50/537: Loss=0.4779 (C:0.4779, R:0.0106)
Batch  75/537: Loss=0.4661 (C:0.4661, R:0.0105)
Batch 100/537: Loss=0.4750 (C:0.4750, R:0.0105)
Batch 125/537: Loss=0.4712 (C:0.4712, R:0.0105)
Batch 150/537: Loss=0.4793 (C:0.4793, R:0.0105)
Batch 175/537: Loss=0.4721 (C:0.4721, R:0.0105)
Batch 200/537: Loss=0.4912 (C:0.4912, R:0.0105)
Batch 225/537: Loss=0.4858 (C:0.4858, R:0.0105)
Batch 250/537: Loss=0.4962 (C:0.4962, R:0.0105)
Batch 275/537: Loss=0.4781 (C:0.4781, R:0.0105)
Batch 300/537: Loss=0.4637 (C:0.4637, R:0.0105)
Batch 325/537: Loss=0.4609 (C:0.4609, R:0.0105)
Batch 350/537: Loss=0.4963 (C:0.4963, R:0.0105)
Batch 375/537: Loss=0.4855 (C:0.4855, R:0.0105)
Batch 400/537: Loss=0.4573 (C:0.4573, R:0.0105)
Batch 425/537: Loss=0.4801 (C:0.4801, R:0.0105)
Batch 450/537: Loss=0.4782 (C:0.4782, R:0.0105)
Batch 475/537: Loss=0.4784 (C:0.4784, R:0.0105)
Batch 500/537: Loss=0.4793 (C:0.4793, R:0.0105)
Batch 525/537: Loss=0.4765 (C:0.4765, R:0.0105)

============================================================
Epoch 15/300 completed in 21.3s
Train: Loss=0.4774 (C:0.4774, R:0.0105) Ratio=3.68x
Val:   Loss=0.5127 (C:0.5127, R:0.0104) Ratio=2.94x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 16
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.179 ± 0.259
    Neg distances: 0.864 ± 0.440
    Separation ratio: 4.82x
    Gap: -1.594
    ✅ Excellent global separation!

Epoch 16 Training
----------------------------------------
Batch   0/537: Loss=0.4691 (C:0.4691, R:0.0104)
Batch  25/537: Loss=0.4501 (C:0.4501, R:0.0105)
Batch  50/537: Loss=0.4802 (C:0.4802, R:0.0105)
Batch  75/537: Loss=0.4474 (C:0.4474, R:0.0105)
Batch 100/537: Loss=0.4562 (C:0.4562, R:0.0105)
Batch 125/537: Loss=0.4658 (C:0.4658, R:0.0105)
Batch 150/537: Loss=0.4645 (C:0.4645, R:0.0105)
Batch 175/537: Loss=0.4653 (C:0.4653, R:0.0105)
Batch 200/537: Loss=0.4524 (C:0.4524, R:0.0106)
Batch 225/537: Loss=0.4621 (C:0.4621, R:0.0105)
Batch 250/537: Loss=0.4639 (C:0.4639, R:0.0105)
Batch 275/537: Loss=0.4539 (C:0.4539, R:0.0105)
Batch 300/537: Loss=0.4612 (C:0.4612, R:0.0105)
Batch 325/537: Loss=0.4741 (C:0.4741, R:0.0106)
Batch 350/537: Loss=0.4624 (C:0.4624, R:0.0105)
Batch 375/537: Loss=0.4681 (C:0.4681, R:0.0106)
Batch 400/537: Loss=0.4573 (C:0.4573, R:0.0106)
Batch 425/537: Loss=0.4803 (C:0.4803, R:0.0106)
Batch 450/537: Loss=0.4619 (C:0.4619, R:0.0106)
Batch 475/537: Loss=0.4664 (C:0.4664, R:0.0105)
Batch 500/537: Loss=0.4536 (C:0.4536, R:0.0105)
Batch 525/537: Loss=0.4499 (C:0.4499, R:0.0105)

============================================================
Epoch 16/300 completed in 27.5s
Train: Loss=0.4639 (C:0.4639, R:0.0105) Ratio=3.74x
Val:   Loss=0.5031 (C:0.5031, R:0.0104) Ratio=2.96x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.5031)
============================================================

Epoch 17 Training
----------------------------------------
Batch   0/537: Loss=0.4657 (C:0.4657, R:0.0105)
Batch  25/537: Loss=0.4559 (C:0.4559, R:0.0105)
Batch  50/537: Loss=0.4452 (C:0.4452, R:0.0105)
Batch  75/537: Loss=0.4658 (C:0.4658, R:0.0105)
Batch 100/537: Loss=0.4450 (C:0.4450, R:0.0105)
Batch 125/537: Loss=0.4636 (C:0.4636, R:0.0105)
Batch 150/537: Loss=0.4670 (C:0.4670, R:0.0105)
Batch 175/537: Loss=0.4549 (C:0.4549, R:0.0105)
Batch 200/537: Loss=0.4494 (C:0.4494, R:0.0105)
Batch 225/537: Loss=0.4542 (C:0.4542, R:0.0105)
Batch 250/537: Loss=0.4747 (C:0.4747, R:0.0105)
Batch 275/537: Loss=0.4705 (C:0.4705, R:0.0105)
Batch 300/537: Loss=0.4743 (C:0.4743, R:0.0105)
Batch 325/537: Loss=0.4578 (C:0.4578, R:0.0105)
Batch 350/537: Loss=0.4491 (C:0.4491, R:0.0105)
Batch 375/537: Loss=0.4716 (C:0.4716, R:0.0105)
Batch 400/537: Loss=0.4610 (C:0.4610, R:0.0105)
Batch 425/537: Loss=0.4722 (C:0.4722, R:0.0105)
Batch 450/537: Loss=0.4538 (C:0.4538, R:0.0105)
Batch 475/537: Loss=0.4658 (C:0.4658, R:0.0105)
Batch 500/537: Loss=0.4650 (C:0.4650, R:0.0105)
Batch 525/537: Loss=0.4533 (C:0.4533, R:0.0105)

============================================================
Epoch 17/300 completed in 21.7s
Train: Loss=0.4611 (C:0.4611, R:0.0105) Ratio=3.84x
Val:   Loss=0.5002 (C:0.5002, R:0.0104) Ratio=2.93x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.5002)
============================================================

Epoch 18 Training
----------------------------------------
Batch   0/537: Loss=0.4492 (C:0.4492, R:0.0105)
Batch  25/537: Loss=0.4614 (C:0.4614, R:0.0106)
Batch  50/537: Loss=0.4591 (C:0.4591, R:0.0105)
Batch  75/537: Loss=0.4541 (C:0.4541, R:0.0105)
Batch 100/537: Loss=0.4581 (C:0.4581, R:0.0105)
Batch 125/537: Loss=0.4592 (C:0.4592, R:0.0105)
Batch 150/537: Loss=0.4700 (C:0.4700, R:0.0105)
Batch 175/537: Loss=0.4542 (C:0.4542, R:0.0105)
Batch 200/537: Loss=0.4490 (C:0.4490, R:0.0105)
Batch 225/537: Loss=0.4538 (C:0.4538, R:0.0105)
Batch 250/537: Loss=0.4610 (C:0.4610, R:0.0105)
Batch 275/537: Loss=0.4655 (C:0.4655, R:0.0105)
Batch 300/537: Loss=0.4694 (C:0.4694, R:0.0106)
Batch 325/537: Loss=0.4748 (C:0.4748, R:0.0105)
Batch 350/537: Loss=0.4571 (C:0.4571, R:0.0105)
Batch 375/537: Loss=0.4409 (C:0.4409, R:0.0106)
Batch 400/537: Loss=0.4642 (C:0.4642, R:0.0105)
Batch 425/537: Loss=0.4497 (C:0.4497, R:0.0105)
Batch 450/537: Loss=0.4419 (C:0.4419, R:0.0105)
Batch 475/537: Loss=0.4612 (C:0.4612, R:0.0105)
Batch 500/537: Loss=0.4461 (C:0.4461, R:0.0106)
Batch 525/537: Loss=0.4461 (C:0.4461, R:0.0105)

============================================================
Epoch 18/300 completed in 21.6s
Train: Loss=0.4594 (C:0.4594, R:0.0105) Ratio=3.85x
Val:   Loss=0.4950 (C:0.4950, R:0.0104) Ratio=2.91x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4950)
============================================================

🌍 Updating global dataset at epoch 19
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.181 ± 0.269
    Neg distances: 0.891 ± 0.445
    Separation ratio: 4.92x
    Gap: -1.648
    ✅ Excellent global separation!

Epoch 19 Training
----------------------------------------
Batch   0/537: Loss=0.4380 (C:0.4380, R:0.0105)
Batch  25/537: Loss=0.4439 (C:0.4439, R:0.0105)
Batch  50/537: Loss=0.4262 (C:0.4262, R:0.0105)
Batch  75/537: Loss=0.4491 (C:0.4491, R:0.0105)
Batch 100/537: Loss=0.4324 (C:0.4324, R:0.0106)
Batch 125/537: Loss=0.4262 (C:0.4262, R:0.0105)
Batch 150/537: Loss=0.4680 (C:0.4680, R:0.0105)
Batch 175/537: Loss=0.4418 (C:0.4418, R:0.0105)
Batch 200/537: Loss=0.4519 (C:0.4519, R:0.0105)
Batch 225/537: Loss=0.4590 (C:0.4590, R:0.0105)
Batch 250/537: Loss=0.4302 (C:0.4302, R:0.0105)
Batch 275/537: Loss=0.4427 (C:0.4427, R:0.0105)
Batch 300/537: Loss=0.4504 (C:0.4504, R:0.0105)
Batch 325/537: Loss=0.4596 (C:0.4596, R:0.0105)
Batch 350/537: Loss=0.4481 (C:0.4481, R:0.0105)
Batch 375/537: Loss=0.4532 (C:0.4532, R:0.0105)
Batch 400/537: Loss=0.4663 (C:0.4663, R:0.0105)
Batch 425/537: Loss=0.4735 (C:0.4735, R:0.0105)
Batch 450/537: Loss=0.4406 (C:0.4406, R:0.0105)
Batch 475/537: Loss=0.4406 (C:0.4406, R:0.0105)
Batch 500/537: Loss=0.4484 (C:0.4484, R:0.0105)
Batch 525/537: Loss=0.4485 (C:0.4485, R:0.0105)

============================================================
Epoch 19/300 completed in 27.3s
Train: Loss=0.4507 (C:0.4507, R:0.0105) Ratio=3.99x
Val:   Loss=0.4921 (C:0.4921, R:0.0104) Ratio=2.94x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4921)
============================================================

Epoch 20 Training
----------------------------------------
Batch   0/537: Loss=0.4559 (C:0.4559, R:0.0106)
Batch  25/537: Loss=0.4405 (C:0.4405, R:0.0105)
Batch  50/537: Loss=0.4526 (C:0.4526, R:0.0105)
Batch  75/537: Loss=0.4545 (C:0.4545, R:0.0105)
Batch 100/537: Loss=0.4520 (C:0.4520, R:0.0105)
Batch 125/537: Loss=0.4457 (C:0.4457, R:0.0105)
Batch 150/537: Loss=0.4638 (C:0.4638, R:0.0105)
Batch 175/537: Loss=0.4444 (C:0.4444, R:0.0106)
Batch 200/537: Loss=0.4732 (C:0.4732, R:0.0105)
Batch 225/537: Loss=0.4534 (C:0.4534, R:0.0105)
Batch 250/537: Loss=0.4322 (C:0.4322, R:0.0106)
Batch 275/537: Loss=0.4582 (C:0.4582, R:0.0105)
Batch 300/537: Loss=0.4496 (C:0.4496, R:0.0105)
Batch 325/537: Loss=0.4435 (C:0.4435, R:0.0105)
Batch 350/537: Loss=0.4529 (C:0.4529, R:0.0105)
Batch 375/537: Loss=0.4449 (C:0.4449, R:0.0105)
Batch 400/537: Loss=0.4533 (C:0.4533, R:0.0105)
Batch 425/537: Loss=0.4632 (C:0.4632, R:0.0105)
Batch 450/537: Loss=0.4540 (C:0.4540, R:0.0105)
Batch 475/537: Loss=0.4449 (C:0.4449, R:0.0105)
Batch 500/537: Loss=0.4408 (C:0.4408, R:0.0105)
Batch 525/537: Loss=0.4419 (C:0.4419, R:0.0105)

============================================================
Epoch 20/300 completed in 21.4s
Train: Loss=0.4486 (C:0.4486, R:0.0105) Ratio=3.96x
Val:   Loss=0.4883 (C:0.4883, R:0.0104) Ratio=2.95x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4883)
Checkpoint saved at epoch 20
============================================================

Epoch 21 Training
----------------------------------------
Batch   0/537: Loss=0.4466 (C:0.4466, R:0.0105)
Batch  25/537: Loss=0.4414 (C:0.4414, R:0.0105)
Batch  50/537: Loss=0.4323 (C:0.4323, R:0.0105)
Batch  75/537: Loss=0.4466 (C:0.4466, R:0.0106)
Batch 100/537: Loss=0.4553 (C:0.4553, R:0.0105)
Batch 125/537: Loss=0.4466 (C:0.4466, R:0.0105)
Batch 150/537: Loss=0.4564 (C:0.4564, R:0.0105)
Batch 175/537: Loss=0.4469 (C:0.4469, R:0.0105)
Batch 200/537: Loss=0.4538 (C:0.4538, R:0.0105)
Batch 225/537: Loss=0.4731 (C:0.4731, R:0.0105)
Batch 250/537: Loss=0.4538 (C:0.4538, R:0.0105)
Batch 275/537: Loss=0.4426 (C:0.4426, R:0.0105)
Batch 300/537: Loss=0.4370 (C:0.4370, R:0.0105)
Batch 325/537: Loss=0.4484 (C:0.4484, R:0.0105)
Batch 350/537: Loss=0.4569 (C:0.4569, R:0.0105)
Batch 375/537: Loss=0.4414 (C:0.4414, R:0.0105)
Batch 400/537: Loss=0.4445 (C:0.4445, R:0.0105)
Batch 425/537: Loss=0.4420 (C:0.4420, R:0.0105)
Batch 450/537: Loss=0.4580 (C:0.4580, R:0.0105)
Batch 475/537: Loss=0.4443 (C:0.4443, R:0.0105)
Batch 500/537: Loss=0.4710 (C:0.4710, R:0.0105)
Batch 525/537: Loss=0.4298 (C:0.4298, R:0.0105)

============================================================
Epoch 21/300 completed in 21.2s
Train: Loss=0.4472 (C:0.4472, R:0.0105) Ratio=4.01x
Val:   Loss=0.4912 (C:0.4912, R:0.0104) Ratio=2.91x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 22
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.170 ± 0.253
    Neg distances: 0.914 ± 0.445
    Separation ratio: 5.39x
    Gap: -1.689
    ✅ Excellent global separation!

Epoch 22 Training
----------------------------------------
Batch   0/537: Loss=0.4303 (C:0.4303, R:0.0105)
Batch  25/537: Loss=0.4382 (C:0.4382, R:0.0105)
Batch  50/537: Loss=0.4341 (C:0.4341, R:0.0105)
Batch  75/537: Loss=0.4244 (C:0.4244, R:0.0105)
Batch 100/537: Loss=0.4267 (C:0.4267, R:0.0105)
Batch 125/537: Loss=0.4365 (C:0.4365, R:0.0105)
Batch 150/537: Loss=0.4393 (C:0.4393, R:0.0105)
Batch 175/537: Loss=0.4368 (C:0.4368, R:0.0105)
Batch 200/537: Loss=0.4252 (C:0.4252, R:0.0106)
Batch 225/537: Loss=0.4144 (C:0.4144, R:0.0105)
Batch 250/537: Loss=0.4256 (C:0.4256, R:0.0105)
Batch 275/537: Loss=0.4295 (C:0.4295, R:0.0105)
Batch 300/537: Loss=0.4228 (C:0.4228, R:0.0105)
Batch 325/537: Loss=0.4171 (C:0.4171, R:0.0105)
Batch 350/537: Loss=0.4391 (C:0.4391, R:0.0105)
Batch 375/537: Loss=0.4286 (C:0.4286, R:0.0105)
Batch 400/537: Loss=0.4426 (C:0.4426, R:0.0105)
Batch 425/537: Loss=0.4172 (C:0.4172, R:0.0105)
Batch 450/537: Loss=0.4369 (C:0.4369, R:0.0105)
Batch 475/537: Loss=0.4562 (C:0.4562, R:0.0105)
Batch 500/537: Loss=0.4209 (C:0.4209, R:0.0105)
Batch 525/537: Loss=0.4460 (C:0.4460, R:0.0105)

============================================================
Epoch 22/300 completed in 27.0s
Train: Loss=0.4315 (C:0.4315, R:0.0105) Ratio=4.12x
Val:   Loss=0.4710 (C:0.4710, R:0.0104) Ratio=2.94x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4710)
============================================================

Epoch 23 Training
----------------------------------------
Batch   0/537: Loss=0.4168 (C:0.4168, R:0.0105)
Batch  25/537: Loss=0.4285 (C:0.4285, R:0.0105)
Batch  50/537: Loss=0.4321 (C:0.4321, R:0.0105)
Batch  75/537: Loss=0.4197 (C:0.4197, R:0.0105)
Batch 100/537: Loss=0.4201 (C:0.4201, R:0.0105)
Batch 125/537: Loss=0.4406 (C:0.4406, R:0.0105)
Batch 150/537: Loss=0.4240 (C:0.4240, R:0.0105)
Batch 175/537: Loss=0.4505 (C:0.4505, R:0.0105)
Batch 200/537: Loss=0.4269 (C:0.4269, R:0.0105)
Batch 225/537: Loss=0.4312 (C:0.4312, R:0.0105)
Batch 250/537: Loss=0.4192 (C:0.4192, R:0.0105)
Batch 275/537: Loss=0.4427 (C:0.4427, R:0.0105)
Batch 300/537: Loss=0.4407 (C:0.4407, R:0.0105)
Batch 325/537: Loss=0.4406 (C:0.4406, R:0.0105)
Batch 350/537: Loss=0.4277 (C:0.4277, R:0.0105)
Batch 375/537: Loss=0.4320 (C:0.4320, R:0.0105)
Batch 400/537: Loss=0.4237 (C:0.4237, R:0.0105)
Batch 425/537: Loss=0.4422 (C:0.4422, R:0.0105)
Batch 450/537: Loss=0.4315 (C:0.4315, R:0.0105)
Batch 475/537: Loss=0.4309 (C:0.4309, R:0.0105)
Batch 500/537: Loss=0.4230 (C:0.4230, R:0.0106)
Batch 525/537: Loss=0.4195 (C:0.4195, R:0.0105)

============================================================
Epoch 23/300 completed in 21.2s
Train: Loss=0.4304 (C:0.4304, R:0.0105) Ratio=4.13x
Val:   Loss=0.4779 (C:0.4779, R:0.0104) Ratio=2.91x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

Epoch 24 Training
----------------------------------------
Batch   0/537: Loss=0.4225 (C:0.4225, R:0.0105)
Batch  25/537: Loss=0.4145 (C:0.4145, R:0.0105)
Batch  50/537: Loss=0.4318 (C:0.4318, R:0.0105)
Batch  75/537: Loss=0.4263 (C:0.4263, R:0.0105)
Batch 100/537: Loss=0.4191 (C:0.4191, R:0.0105)
Batch 125/537: Loss=0.4256 (C:0.4256, R:0.0105)
Batch 150/537: Loss=0.4278 (C:0.4278, R:0.0106)
Batch 175/537: Loss=0.4131 (C:0.4131, R:0.0105)
Batch 200/537: Loss=0.4218 (C:0.4218, R:0.0105)
Batch 225/537: Loss=0.4302 (C:0.4302, R:0.0105)
Batch 250/537: Loss=0.4227 (C:0.4227, R:0.0105)
Batch 275/537: Loss=0.4176 (C:0.4176, R:0.0105)
Batch 300/537: Loss=0.4362 (C:0.4362, R:0.0105)
Batch 325/537: Loss=0.4416 (C:0.4416, R:0.0105)
Batch 350/537: Loss=0.4439 (C:0.4439, R:0.0105)
Batch 375/537: Loss=0.4290 (C:0.4290, R:0.0105)
Batch 400/537: Loss=0.4348 (C:0.4348, R:0.0105)
Batch 425/537: Loss=0.4224 (C:0.4224, R:0.0105)
Batch 450/537: Loss=0.4182 (C:0.4182, R:0.0105)
Batch 475/537: Loss=0.4434 (C:0.4434, R:0.0105)
Batch 500/537: Loss=0.4449 (C:0.4449, R:0.0105)
Batch 525/537: Loss=0.4377 (C:0.4377, R:0.0105)

============================================================
Epoch 24/300 completed in 21.2s
Train: Loss=0.4285 (C:0.4285, R:0.0105) Ratio=4.14x
Val:   Loss=0.4756 (C:0.4756, R:0.0104) Ratio=2.94x
Reconstruction weight: 0.000
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 25
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.171 ± 0.255
    Neg distances: 0.938 ± 0.453
    Separation ratio: 5.49x
    Gap: -1.671
    ✅ Excellent global separation!

Epoch 25 Training
----------------------------------------
Batch   0/537: Loss=0.4263 (C:0.4263, R:0.0105)
Batch  25/537: Loss=0.4147 (C:0.4147, R:0.0105)
Batch  50/537: Loss=0.4313 (C:0.4313, R:0.0105)
Batch  75/537: Loss=0.4283 (C:0.4283, R:0.0105)
Batch 100/537: Loss=0.4171 (C:0.4171, R:0.0105)
Batch 125/537: Loss=0.4253 (C:0.4253, R:0.0106)
Batch 150/537: Loss=0.4206 (C:0.4206, R:0.0105)
Batch 175/537: Loss=0.4058 (C:0.4058, R:0.0105)
Batch 200/537: Loss=0.4272 (C:0.4272, R:0.0105)
Batch 225/537: Loss=0.4338 (C:0.4338, R:0.0106)
Batch 250/537: Loss=0.4175 (C:0.4175, R:0.0105)
Batch 275/537: Loss=0.4329 (C:0.4329, R:0.0105)
Batch 300/537: Loss=0.4352 (C:0.4352, R:0.0105)
Batch 325/537: Loss=0.4233 (C:0.4233, R:0.0105)
Batch 350/537: Loss=0.4432 (C:0.4432, R:0.0105)
Batch 375/537: Loss=0.4084 (C:0.4084, R:0.0105)
Batch 400/537: Loss=0.4149 (C:0.4149, R:0.0105)
Batch 425/537: Loss=0.4301 (C:0.4301, R:0.0106)
Batch 450/537: Loss=0.4384 (C:0.4384, R:0.0105)
Batch 475/537: Loss=0.4296 (C:0.4296, R:0.0105)
Batch 500/537: Loss=0.4202 (C:0.4202, R:0.0105)
Batch 525/537: Loss=0.4172 (C:0.4172, R:0.0105)

============================================================
Epoch 25/300 completed in 26.8s
Train: Loss=0.4227 (C:0.4227, R:0.0105) Ratio=4.02x
Val:   Loss=0.4684 (C:0.4684, R:0.0104) Ratio=2.91x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4684)
============================================================

Epoch 26 Training
----------------------------------------
Batch   0/537: Loss=0.3985 (C:0.3985, R:0.0105)
Batch  25/537: Loss=0.4241 (C:0.4241, R:0.0105)
Batch  50/537: Loss=0.4263 (C:0.4263, R:0.0105)
Batch  75/537: Loss=0.4124 (C:0.4124, R:0.0105)
Batch 100/537: Loss=0.4336 (C:0.4336, R:0.0105)
Batch 125/537: Loss=0.4117 (C:0.4117, R:0.0105)
Batch 150/537: Loss=0.4246 (C:0.4246, R:0.0105)
Batch 175/537: Loss=0.4118 (C:0.4118, R:0.0105)
Batch 200/537: Loss=0.4112 (C:0.4112, R:0.0105)
Batch 225/537: Loss=0.4236 (C:0.4236, R:0.0105)
Batch 250/537: Loss=0.4065 (C:0.4065, R:0.0105)
Batch 275/537: Loss=0.4160 (C:0.4160, R:0.0105)
Batch 300/537: Loss=0.4421 (C:0.4421, R:0.0105)
Batch 325/537: Loss=0.4026 (C:0.4026, R:0.0105)
Batch 350/537: Loss=0.4177 (C:0.4177, R:0.0105)
Batch 375/537: Loss=0.4154 (C:0.4154, R:0.0105)
Batch 400/537: Loss=0.4253 (C:0.4253, R:0.0105)
Batch 425/537: Loss=0.4272 (C:0.4272, R:0.0105)
Batch 450/537: Loss=0.4309 (C:0.4309, R:0.0105)
Batch 475/537: Loss=0.4605 (C:0.4605, R:0.0105)
Batch 500/537: Loss=0.4244 (C:0.4244, R:0.0105)
Batch 525/537: Loss=0.4094 (C:0.4094, R:0.0105)

============================================================
Epoch 26/300 completed in 21.3s
Train: Loss=0.4205 (C:0.4205, R:0.0105) Ratio=4.23x
Val:   Loss=0.4706 (C:0.4706, R:0.0104) Ratio=2.95x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

Epoch 27 Training
----------------------------------------
Batch   0/537: Loss=0.4408 (C:0.4408, R:0.0105)
Batch  25/537: Loss=0.4267 (C:0.4267, R:0.0105)
Batch  50/537: Loss=0.4194 (C:0.4194, R:0.0105)
Batch  75/537: Loss=0.4207 (C:0.4207, R:0.0105)
Batch 100/537: Loss=0.4012 (C:0.4012, R:0.0105)
Batch 125/537: Loss=0.4147 (C:0.4147, R:0.0105)
Batch 150/537: Loss=0.3994 (C:0.3994, R:0.0105)
Batch 175/537: Loss=0.4278 (C:0.4278, R:0.0105)
Batch 200/537: Loss=0.4181 (C:0.4181, R:0.0105)
Batch 225/537: Loss=0.4194 (C:0.4194, R:0.0105)
Batch 250/537: Loss=0.4243 (C:0.4243, R:0.0106)
Batch 275/537: Loss=0.4244 (C:0.4244, R:0.0105)
Batch 300/537: Loss=0.4115 (C:0.4115, R:0.0105)
Batch 325/537: Loss=0.3938 (C:0.3938, R:0.0105)
Batch 350/537: Loss=0.4242 (C:0.4242, R:0.0105)
Batch 375/537: Loss=0.4255 (C:0.4255, R:0.0105)
Batch 400/537: Loss=0.4154 (C:0.4154, R:0.0105)
Batch 425/537: Loss=0.4329 (C:0.4329, R:0.0105)
Batch 450/537: Loss=0.4271 (C:0.4271, R:0.0105)
Batch 475/537: Loss=0.4277 (C:0.4277, R:0.0105)
Batch 500/537: Loss=0.4134 (C:0.4134, R:0.0105)
Batch 525/537: Loss=0.4160 (C:0.4160, R:0.0105)

============================================================
Epoch 27/300 completed in 21.2s
Train: Loss=0.4200 (C:0.4200, R:0.0105) Ratio=4.24x
Val:   Loss=0.4678 (C:0.4678, R:0.0104) Ratio=2.97x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4678)
============================================================

🌍 Updating global dataset at epoch 28
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.160 ± 0.249
    Neg distances: 0.979 ± 0.455
    Separation ratio: 6.11x
    Gap: -1.705
    ✅ Excellent global separation!

Epoch 28 Training
----------------------------------------
Batch   0/537: Loss=0.3921 (C:0.3921, R:0.0105)
Batch  25/537: Loss=0.3831 (C:0.3831, R:0.0105)
Batch  50/537: Loss=0.3877 (C:0.3877, R:0.0105)
Batch  75/537: Loss=0.3893 (C:0.3893, R:0.0105)
Batch 100/537: Loss=0.3953 (C:0.3953, R:0.0105)
Batch 125/537: Loss=0.3986 (C:0.3986, R:0.0105)
Batch 150/537: Loss=0.3986 (C:0.3986, R:0.0105)
Batch 175/537: Loss=0.4047 (C:0.4047, R:0.0105)
Batch 200/537: Loss=0.4217 (C:0.4217, R:0.0105)
Batch 225/537: Loss=0.4041 (C:0.4041, R:0.0105)
Batch 250/537: Loss=0.4071 (C:0.4071, R:0.0105)
Batch 275/537: Loss=0.3883 (C:0.3883, R:0.0106)
Batch 300/537: Loss=0.4085 (C:0.4085, R:0.0105)
Batch 325/537: Loss=0.3909 (C:0.3909, R:0.0105)
Batch 350/537: Loss=0.4142 (C:0.4142, R:0.0105)
Batch 375/537: Loss=0.3943 (C:0.3943, R:0.0105)
Batch 400/537: Loss=0.3877 (C:0.3877, R:0.0105)
Batch 425/537: Loss=0.3942 (C:0.3942, R:0.0105)
Batch 450/537: Loss=0.4048 (C:0.4048, R:0.0105)
Batch 475/537: Loss=0.4293 (C:0.4293, R:0.0105)
Batch 500/537: Loss=0.3788 (C:0.3788, R:0.0105)
Batch 525/537: Loss=0.4066 (C:0.4066, R:0.0105)

============================================================
Epoch 28/300 completed in 27.0s
Train: Loss=0.3989 (C:0.3989, R:0.0105) Ratio=4.31x
Val:   Loss=0.4507 (C:0.4507, R:0.0104) Ratio=2.96x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.4507)
============================================================

Epoch 29 Training
----------------------------------------
Batch   0/537: Loss=0.3729 (C:0.3729, R:0.0105)
Batch  25/537: Loss=0.3916 (C:0.3916, R:0.0105)
Batch  50/537: Loss=0.4025 (C:0.4025, R:0.0105)
Batch  75/537: Loss=0.3962 (C:0.3962, R:0.0105)
Batch 100/537: Loss=0.4105 (C:0.4105, R:0.0105)
Batch 125/537: Loss=0.3896 (C:0.3896, R:0.0105)
Batch 150/537: Loss=0.4048 (C:0.4048, R:0.0105)
Batch 175/537: Loss=0.3838 (C:0.3838, R:0.0105)
Batch 200/537: Loss=0.4023 (C:0.4023, R:0.0105)
Batch 225/537: Loss=0.3862 (C:0.3862, R:0.0105)
Batch 250/537: Loss=0.4013 (C:0.4013, R:0.0105)
Batch 275/537: Loss=0.3968 (C:0.3968, R:0.0105)
Batch 300/537: Loss=0.3931 (C:0.3931, R:0.0105)
Batch 325/537: Loss=0.3925 (C:0.3925, R:0.0105)
Batch 350/537: Loss=0.3923 (C:0.3923, R:0.0105)
Batch 375/537: Loss=0.3975 (C:0.3975, R:0.0105)
Batch 400/537: Loss=0.4140 (C:0.4140, R:0.0105)
Batch 425/537: Loss=0.3870 (C:0.3870, R:0.0105)
Batch 450/537: Loss=0.4173 (C:0.4173, R:0.0105)
Batch 475/537: Loss=0.4117 (C:0.4117, R:0.0105)
Batch 500/537: Loss=0.3855 (C:0.3855, R:0.0105)
Batch 525/537: Loss=0.4181 (C:0.4181, R:0.0105)

============================================================
Epoch 29/300 completed in 21.0s
Train: Loss=0.3974 (C:0.3974, R:0.0105) Ratio=4.30x
Val:   Loss=0.4523 (C:0.4523, R:0.0104) Ratio=2.98x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

Epoch 30 Training
----------------------------------------
Batch   0/537: Loss=0.3813 (C:0.3813, R:0.0105)
Batch  25/537: Loss=0.3865 (C:0.3865, R:0.0105)
Batch  50/537: Loss=0.3898 (C:0.3898, R:0.0105)
Batch  75/537: Loss=0.4116 (C:0.4116, R:0.0105)
Batch 100/537: Loss=0.3963 (C:0.3963, R:0.0105)
Batch 125/537: Loss=0.4135 (C:0.4135, R:0.0105)
Batch 150/537: Loss=0.3881 (C:0.3881, R:0.0105)
Batch 175/537: Loss=0.4037 (C:0.4037, R:0.0105)
Batch 200/537: Loss=0.3934 (C:0.3934, R:0.0105)
Batch 225/537: Loss=0.3964 (C:0.3964, R:0.0105)
Batch 250/537: Loss=0.3872 (C:0.3872, R:0.0105)
Batch 275/537: Loss=0.3933 (C:0.3933, R:0.0105)
Batch 300/537: Loss=0.3984 (C:0.3984, R:0.0105)
Batch 325/537: Loss=0.3869 (C:0.3869, R:0.0105)
Batch 350/537: Loss=0.4115 (C:0.4115, R:0.0105)
Batch 375/537: Loss=0.3990 (C:0.3990, R:0.0105)
Batch 400/537: Loss=0.3853 (C:0.3853, R:0.0105)
Batch 425/537: Loss=0.4092 (C:0.4092, R:0.0105)
Batch 450/537: Loss=0.3855 (C:0.3855, R:0.0105)
Batch 475/537: Loss=0.3983 (C:0.3983, R:0.0105)
Batch 500/537: Loss=0.3978 (C:0.3978, R:0.0105)
Batch 525/537: Loss=0.4051 (C:0.4051, R:0.0105)

============================================================
Epoch 30/300 completed in 21.0s
Train: Loss=0.3961 (C:0.3961, R:0.0105) Ratio=4.37x
Val:   Loss=0.4531 (C:0.4531, R:0.0104) Ratio=2.95x
Reconstruction weight: 0.000
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 31
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.168 ± 0.261
    Neg distances: 0.991 ± 0.459
    Separation ratio: 5.91x
    Gap: -1.804
    ✅ Excellent global separation!

Epoch 31 Training
----------------------------------------
Batch   0/537: Loss=0.3842 (C:0.3842, R:0.0105)
Batch  25/537: Loss=0.4075 (C:0.4075, R:0.0105)
Batch  50/537: Loss=0.3976 (C:0.3976, R:0.0105)
Batch  75/537: Loss=0.3933 (C:0.3933, R:0.0105)
Batch 100/537: Loss=0.3771 (C:0.3771, R:0.0105)
Batch 125/537: Loss=0.4070 (C:0.4070, R:0.0105)
Batch 150/537: Loss=0.3954 (C:0.3954, R:0.0105)
Batch 175/537: Loss=0.3948 (C:0.3948, R:0.0105)
Batch 200/537: Loss=0.4068 (C:0.4068, R:0.0105)
Batch 225/537: Loss=0.4020 (C:0.4020, R:0.0105)
Batch 250/537: Loss=0.3882 (C:0.3882, R:0.0105)
Batch 275/537: Loss=0.3959 (C:0.3959, R:0.0105)
Batch 300/537: Loss=0.4056 (C:0.4056, R:0.0105)
Batch 325/537: Loss=0.3777 (C:0.3777, R:0.0105)
Batch 350/537: Loss=0.4158 (C:0.4158, R:0.0105)
Batch 375/537: Loss=0.3971 (C:0.3971, R:0.0105)
Batch 400/537: Loss=0.4039 (C:0.4039, R:0.0105)
Batch 425/537: Loss=0.4004 (C:0.4004, R:0.0105)
Batch 450/537: Loss=0.3897 (C:0.3897, R:0.0105)
Batch 475/537: Loss=0.3995 (C:0.3995, R:0.0105)
Batch 500/537: Loss=0.3928 (C:0.3928, R:0.0105)
Batch 525/537: Loss=0.3918 (C:0.3918, R:0.0105)

============================================================
Epoch 31/300 completed in 27.3s
Train: Loss=0.3961 (C:0.3961, R:0.0105) Ratio=4.35x
Val:   Loss=0.4489 (C:0.4489, R:0.0104) Ratio=2.98x
Reconstruction weight: 0.015
✅ New best model saved (Val Loss: 0.4489)
============================================================

Epoch 32 Training
----------------------------------------
Batch   0/537: Loss=0.3925 (C:0.3925, R:0.0105)
Batch  25/537: Loss=0.3881 (C:0.3881, R:0.0105)
Batch  50/537: Loss=0.3755 (C:0.3755, R:0.0105)
Batch  75/537: Loss=0.3796 (C:0.3796, R:0.0105)
Batch 100/537: Loss=0.3884 (C:0.3884, R:0.0105)
Batch 125/537: Loss=0.3765 (C:0.3765, R:0.0105)
Batch 150/537: Loss=0.3961 (C:0.3961, R:0.0105)
Batch 175/537: Loss=0.4040 (C:0.4040, R:0.0105)
Batch 200/537: Loss=0.4073 (C:0.4073, R:0.0105)
Batch 225/537: Loss=0.3908 (C:0.3908, R:0.0105)
Batch 250/537: Loss=0.4047 (C:0.4047, R:0.0106)
Batch 275/537: Loss=0.3880 (C:0.3880, R:0.0105)
Batch 300/537: Loss=0.4018 (C:0.4018, R:0.0105)
Batch 325/537: Loss=0.4088 (C:0.4088, R:0.0105)
Batch 350/537: Loss=0.3951 (C:0.3951, R:0.0105)
Batch 375/537: Loss=0.3928 (C:0.3928, R:0.0105)
Batch 400/537: Loss=0.3885 (C:0.3885, R:0.0105)
Batch 425/537: Loss=0.4025 (C:0.4025, R:0.0105)
Batch 450/537: Loss=0.4019 (C:0.4019, R:0.0105)
Batch 475/537: Loss=0.3981 (C:0.3981, R:0.0105)
Batch 500/537: Loss=0.4079 (C:0.4079, R:0.0105)
Batch 525/537: Loss=0.4076 (C:0.4076, R:0.0105)

============================================================
Epoch 32/300 completed in 21.2s
Train: Loss=0.3947 (C:0.3947, R:0.0105) Ratio=4.34x
Val:   Loss=0.4505 (C:0.4505, R:0.0104) Ratio=2.93x
Reconstruction weight: 0.030
No improvement for 1 epochs
============================================================

Epoch 33 Training
----------------------------------------
Batch   0/537: Loss=0.3795 (C:0.3795, R:0.0105)
Batch  25/537: Loss=0.3992 (C:0.3992, R:0.0105)
Batch  50/537: Loss=0.3825 (C:0.3825, R:0.0105)
Batch  75/537: Loss=0.3948 (C:0.3948, R:0.0105)
Batch 100/537: Loss=0.4019 (C:0.4019, R:0.0105)
Batch 125/537: Loss=0.3929 (C:0.3929, R:0.0105)
Batch 150/537: Loss=0.3941 (C:0.3941, R:0.0105)
Batch 175/537: Loss=0.3826 (C:0.3826, R:0.0105)
Batch 200/537: Loss=0.3875 (C:0.3875, R:0.0106)
Batch 225/537: Loss=0.3979 (C:0.3979, R:0.0105)
Batch 250/537: Loss=0.3931 (C:0.3931, R:0.0105)
Batch 275/537: Loss=0.3955 (C:0.3955, R:0.0105)
Batch 300/537: Loss=0.3801 (C:0.3801, R:0.0105)
Batch 325/537: Loss=0.3807 (C:0.3807, R:0.0105)
Batch 350/537: Loss=0.4017 (C:0.4017, R:0.0105)
Batch 375/537: Loss=0.3755 (C:0.3755, R:0.0105)
Batch 400/537: Loss=0.3680 (C:0.3680, R:0.0105)
Batch 425/537: Loss=0.3534 (C:0.3534, R:0.0105)
Batch 450/537: Loss=0.3961 (C:0.3961, R:0.0105)
Batch 475/537: Loss=0.4160 (C:0.4160, R:0.0105)
Batch 500/537: Loss=0.4055 (C:0.4055, R:0.0105)
Batch 525/537: Loss=0.4061 (C:0.4061, R:0.0105)

============================================================
Epoch 33/300 completed in 20.9s
Train: Loss=0.3942 (C:0.3942, R:0.0105) Ratio=4.48x
Val:   Loss=0.4528 (C:0.4528, R:0.0104) Ratio=2.97x
Reconstruction weight: 0.045
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 34
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.157 ± 0.247
    Neg distances: 1.012 ± 0.456
    Separation ratio: 6.44x
    Gap: -1.808
    ✅ Excellent global separation!

Epoch 34 Training
----------------------------------------
Batch   0/537: Loss=0.3788 (C:0.3788, R:0.0105)
Batch  25/537: Loss=0.3905 (C:0.3905, R:0.0105)
Batch  50/537: Loss=0.3654 (C:0.3654, R:0.0105)
Batch  75/537: Loss=0.3729 (C:0.3729, R:0.0105)
Batch 100/537: Loss=0.3966 (C:0.3966, R:0.0105)
Batch 125/537: Loss=0.3755 (C:0.3755, R:0.0105)
Batch 150/537: Loss=0.3750 (C:0.3750, R:0.0105)
Batch 175/537: Loss=0.3857 (C:0.3857, R:0.0105)
Batch 200/537: Loss=0.3708 (C:0.3708, R:0.0105)
Batch 225/537: Loss=0.3721 (C:0.3721, R:0.0105)
Batch 250/537: Loss=0.3899 (C:0.3899, R:0.0105)
Batch 275/537: Loss=0.3797 (C:0.3797, R:0.0105)
Batch 300/537: Loss=0.3789 (C:0.3789, R:0.0105)
Batch 325/537: Loss=0.3877 (C:0.3877, R:0.0105)
Batch 350/537: Loss=0.3729 (C:0.3729, R:0.0105)
Batch 375/537: Loss=0.3918 (C:0.3918, R:0.0105)
Batch 400/537: Loss=0.3607 (C:0.3607, R:0.0105)
Batch 425/537: Loss=0.3895 (C:0.3895, R:0.0105)
Batch 450/537: Loss=0.3743 (C:0.3743, R:0.0105)
Batch 475/537: Loss=0.3990 (C:0.3990, R:0.0105)
Batch 500/537: Loss=0.3781 (C:0.3781, R:0.0105)
Batch 525/537: Loss=0.3893 (C:0.3893, R:0.0105)

============================================================
Epoch 34/300 completed in 27.0s
Train: Loss=0.3791 (C:0.3791, R:0.0105) Ratio=4.37x
Val:   Loss=0.4414 (C:0.4414, R:0.0104) Ratio=2.95x
Reconstruction weight: 0.060
✅ New best model saved (Val Loss: 0.4414)
============================================================

Epoch 35 Training
----------------------------------------
Batch   0/537: Loss=0.3662 (C:0.3662, R:0.0105)
Batch  25/537: Loss=0.3873 (C:0.3873, R:0.0105)
Batch  50/537: Loss=0.3743 (C:0.3743, R:0.0105)
Batch  75/537: Loss=0.3987 (C:0.3987, R:0.0105)
Batch 100/537: Loss=0.3644 (C:0.3644, R:0.0105)
Batch 125/537: Loss=0.3799 (C:0.3799, R:0.0105)
Batch 150/537: Loss=0.3656 (C:0.3656, R:0.0105)
Batch 175/537: Loss=0.3850 (C:0.3850, R:0.0105)
Batch 200/537: Loss=0.3610 (C:0.3610, R:0.0106)
Batch 225/537: Loss=0.3717 (C:0.3717, R:0.0105)
Batch 250/537: Loss=0.4005 (C:0.4005, R:0.0105)
Batch 275/537: Loss=0.3417 (C:0.3417, R:0.0105)
Batch 300/537: Loss=0.3896 (C:0.3896, R:0.0105)
Batch 325/537: Loss=0.3847 (C:0.3847, R:0.0105)
Batch 350/537: Loss=0.3806 (C:0.3806, R:0.0105)
Batch 375/537: Loss=0.3837 (C:0.3837, R:0.0105)
Batch 400/537: Loss=0.3821 (C:0.3821, R:0.0105)
Batch 425/537: Loss=0.3876 (C:0.3876, R:0.0105)
Batch 450/537: Loss=0.3817 (C:0.3817, R:0.0105)
Batch 475/537: Loss=0.3854 (C:0.3854, R:0.0105)
Batch 500/537: Loss=0.3859 (C:0.3859, R:0.0105)
Batch 525/537: Loss=0.3588 (C:0.3588, R:0.0105)

============================================================
Epoch 35/300 completed in 21.3s
Train: Loss=0.3780 (C:0.3780, R:0.0105) Ratio=4.40x
Val:   Loss=0.4347 (C:0.4347, R:0.0104) Ratio=2.97x
Reconstruction weight: 0.075
✅ New best model saved (Val Loss: 0.4347)
============================================================

Epoch 36 Training
----------------------------------------
Batch   0/537: Loss=0.3721 (C:0.3721, R:0.0105)
Batch  25/537: Loss=0.3601 (C:0.3601, R:0.0105)
Batch  50/537: Loss=0.3826 (C:0.3826, R:0.0105)
Batch  75/537: Loss=0.3808 (C:0.3808, R:0.0105)
Batch 100/537: Loss=0.3803 (C:0.3803, R:0.0105)
Batch 125/537: Loss=0.3821 (C:0.3821, R:0.0106)
Batch 150/537: Loss=0.3846 (C:0.3846, R:0.0105)
Batch 175/537: Loss=0.3621 (C:0.3621, R:0.0105)
Batch 200/537: Loss=0.3787 (C:0.3787, R:0.0105)
Batch 225/537: Loss=0.3803 (C:0.3803, R:0.0105)
Batch 250/537: Loss=0.3572 (C:0.3572, R:0.0105)
Batch 275/537: Loss=0.3651 (C:0.3651, R:0.0105)
Batch 300/537: Loss=0.3845 (C:0.3845, R:0.0105)
Batch 325/537: Loss=0.3819 (C:0.3819, R:0.0105)
Batch 350/537: Loss=0.3662 (C:0.3662, R:0.0105)
Batch 375/537: Loss=0.3947 (C:0.3947, R:0.0105)
Batch 400/537: Loss=0.3935 (C:0.3935, R:0.0105)
Batch 425/537: Loss=0.3778 (C:0.3778, R:0.0105)
Batch 450/537: Loss=0.3734 (C:0.3734, R:0.0105)
Batch 475/537: Loss=0.3929 (C:0.3929, R:0.0105)
Batch 500/537: Loss=0.3745 (C:0.3745, R:0.0105)
Batch 525/537: Loss=0.3957 (C:0.3957, R:0.0105)

============================================================
Epoch 36/300 completed in 21.4s
Train: Loss=0.3768 (C:0.3768, R:0.0105) Ratio=4.41x
Val:   Loss=0.4374 (C:0.4374, R:0.0104) Ratio=2.98x
Reconstruction weight: 0.090
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 37
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.162 ± 0.264
    Neg distances: 1.051 ± 0.473
    Separation ratio: 6.47x
    Gap: -1.833
    ✅ Excellent global separation!

Epoch 37 Training
----------------------------------------
Batch   0/537: Loss=0.3677 (C:0.3677, R:0.0105)
Batch  25/537: Loss=0.3684 (C:0.3684, R:0.0105)
Batch  50/537: Loss=0.3687 (C:0.3687, R:0.0105)
Batch  75/537: Loss=0.3633 (C:0.3633, R:0.0105)
Batch 100/537: Loss=0.3577 (C:0.3577, R:0.0105)
Batch 125/537: Loss=0.3645 (C:0.3645, R:0.0105)
Batch 150/537: Loss=0.3706 (C:0.3706, R:0.0105)
Batch 175/537: Loss=0.3751 (C:0.3751, R:0.0105)
Batch 200/537: Loss=0.3736 (C:0.3736, R:0.0105)
Batch 225/537: Loss=0.3588 (C:0.3588, R:0.0105)
Batch 250/537: Loss=0.3613 (C:0.3613, R:0.0105)
Batch 275/537: Loss=0.3950 (C:0.3950, R:0.0105)
Batch 300/537: Loss=0.3953 (C:0.3953, R:0.0105)
Batch 325/537: Loss=0.3624 (C:0.3624, R:0.0105)
Batch 350/537: Loss=0.3846 (C:0.3846, R:0.0105)
Batch 375/537: Loss=0.3763 (C:0.3763, R:0.0105)
Batch 400/537: Loss=0.3753 (C:0.3753, R:0.0105)
Batch 425/537: Loss=0.3587 (C:0.3587, R:0.0105)
Batch 450/537: Loss=0.3809 (C:0.3809, R:0.0105)
Batch 475/537: Loss=0.3519 (C:0.3519, R:0.0105)
Batch 500/537: Loss=0.3980 (C:0.3980, R:0.0105)
Batch 525/537: Loss=0.3739 (C:0.3739, R:0.0105)

============================================================
Epoch 37/300 completed in 28.2s
Train: Loss=0.3708 (C:0.3708, R:0.0105) Ratio=4.50x
Val:   Loss=0.4277 (C:0.4277, R:0.0104) Ratio=2.97x
Reconstruction weight: 0.105
✅ New best model saved (Val Loss: 0.4277)
============================================================

Epoch 38 Training
----------------------------------------
Batch   0/537: Loss=0.3805 (C:0.3805, R:0.0105)
Batch  25/537: Loss=0.3624 (C:0.3624, R:0.0105)
Batch  50/537: Loss=0.3573 (C:0.3573, R:0.0105)
Batch  75/537: Loss=0.3431 (C:0.3431, R:0.0105)
Batch 100/537: Loss=0.3883 (C:0.3883, R:0.0106)
Batch 125/537: Loss=0.3621 (C:0.3621, R:0.0105)
Batch 150/537: Loss=0.3707 (C:0.3707, R:0.0105)
Batch 175/537: Loss=0.3696 (C:0.3696, R:0.0105)
Batch 200/537: Loss=0.3789 (C:0.3789, R:0.0105)
Batch 225/537: Loss=0.3731 (C:0.3731, R:0.0105)
Batch 250/537: Loss=0.3860 (C:0.3860, R:0.0105)
Batch 275/537: Loss=0.3676 (C:0.3676, R:0.0105)
Batch 300/537: Loss=0.3903 (C:0.3903, R:0.0105)
Batch 325/537: Loss=0.3813 (C:0.3813, R:0.0105)
Batch 350/537: Loss=0.3692 (C:0.3692, R:0.0105)
Batch 375/537: Loss=0.3569 (C:0.3569, R:0.0105)
Batch 400/537: Loss=0.3662 (C:0.3662, R:0.0105)
Batch 425/537: Loss=0.3601 (C:0.3601, R:0.0105)
Batch 450/537: Loss=0.3634 (C:0.3634, R:0.0105)
Batch 475/537: Loss=0.3768 (C:0.3768, R:0.0105)
Batch 500/537: Loss=0.3928 (C:0.3928, R:0.0105)
Batch 525/537: Loss=0.3567 (C:0.3567, R:0.0105)

============================================================
Epoch 38/300 completed in 21.2s
Train: Loss=0.3697 (C:0.3697, R:0.0105) Ratio=4.47x
Val:   Loss=0.4330 (C:0.4330, R:0.0104) Ratio=3.01x
Reconstruction weight: 0.120
No improvement for 1 epochs
============================================================

Epoch 39 Training
----------------------------------------
Batch   0/537: Loss=0.3648 (C:0.3648, R:0.0105)
Batch  25/537: Loss=0.3470 (C:0.3470, R:0.0105)
Batch  50/537: Loss=0.3750 (C:0.3750, R:0.0105)
Batch  75/537: Loss=0.3545 (C:0.3545, R:0.0105)
Batch 100/537: Loss=0.3624 (C:0.3624, R:0.0105)
Batch 125/537: Loss=0.3729 (C:0.3729, R:0.0105)
Batch 150/537: Loss=0.3667 (C:0.3667, R:0.0106)
Batch 175/537: Loss=0.3530 (C:0.3530, R:0.0105)
Batch 200/537: Loss=0.3855 (C:0.3855, R:0.0105)
Batch 225/537: Loss=0.3773 (C:0.3773, R:0.0105)
Batch 250/537: Loss=0.3748 (C:0.3748, R:0.0105)
Batch 275/537: Loss=0.3821 (C:0.3821, R:0.0105)
Batch 300/537: Loss=0.3864 (C:0.3864, R:0.0105)
Batch 325/537: Loss=0.3596 (C:0.3596, R:0.0105)
Batch 350/537: Loss=0.3593 (C:0.3593, R:0.0106)
Batch 375/537: Loss=0.3854 (C:0.3854, R:0.0105)
Batch 400/537: Loss=0.3670 (C:0.3670, R:0.0105)
Batch 425/537: Loss=0.3492 (C:0.3492, R:0.0105)
Batch 450/537: Loss=0.3560 (C:0.3560, R:0.0105)
Batch 475/537: Loss=0.3762 (C:0.3762, R:0.0105)
Batch 500/537: Loss=0.3600 (C:0.3600, R:0.0105)
Batch 525/537: Loss=0.3748 (C:0.3748, R:0.0105)

============================================================
Epoch 39/300 completed in 21.1s
Train: Loss=0.3684 (C:0.3684, R:0.0105) Ratio=4.59x
Val:   Loss=0.4373 (C:0.4373, R:0.0104) Ratio=2.94x
Reconstruction weight: 0.135
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 40
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.170 ± 0.274
    Neg distances: 1.074 ± 0.480
    Separation ratio: 6.30x
    Gap: -1.885
    ✅ Excellent global separation!

Epoch 40 Training
----------------------------------------
Batch   0/537: Loss=0.3675 (C:0.3675, R:0.0105)
Batch  25/537: Loss=0.3625 (C:0.3625, R:0.0105)
Batch  50/537: Loss=0.3419 (C:0.3419, R:0.0105)
Batch  75/537: Loss=0.3504 (C:0.3504, R:0.0105)
Batch 100/537: Loss=0.3540 (C:0.3540, R:0.0105)
Batch 125/537: Loss=0.3573 (C:0.3573, R:0.0105)
Batch 150/537: Loss=0.3534 (C:0.3534, R:0.0105)
Batch 175/537: Loss=0.3631 (C:0.3631, R:0.0105)
Batch 200/537: Loss=0.3892 (C:0.3892, R:0.0105)
Batch 225/537: Loss=0.3645 (C:0.3645, R:0.0105)
Batch 250/537: Loss=0.3538 (C:0.3538, R:0.0105)
Batch 275/537: Loss=0.3606 (C:0.3606, R:0.0105)
Batch 300/537: Loss=0.3823 (C:0.3823, R:0.0106)
Batch 325/537: Loss=0.3601 (C:0.3601, R:0.0105)
Batch 350/537: Loss=0.3610 (C:0.3610, R:0.0105)
Batch 375/537: Loss=0.3553 (C:0.3553, R:0.0105)
Batch 400/537: Loss=0.3705 (C:0.3705, R:0.0105)
Batch 425/537: Loss=0.3627 (C:0.3627, R:0.0105)
Batch 450/537: Loss=0.3870 (C:0.3870, R:0.0105)
Batch 475/537: Loss=0.3676 (C:0.3676, R:0.0105)
Batch 500/537: Loss=0.3574 (C:0.3574, R:0.0105)
Batch 525/537: Loss=0.3655 (C:0.3655, R:0.0105)

============================================================
Epoch 40/300 completed in 27.6s
Train: Loss=0.3656 (C:0.3656, R:0.0105) Ratio=4.62x
Val:   Loss=0.4275 (C:0.4275, R:0.0104) Ratio=2.96x
Reconstruction weight: 0.150
✅ New best model saved (Val Loss: 0.4275)
Checkpoint saved at epoch 40
============================================================

Epoch 41 Training
----------------------------------------
Batch   0/537: Loss=0.3514 (C:0.3514, R:0.0105)
Batch  25/537: Loss=0.3634 (C:0.3634, R:0.0105)
Batch  50/537: Loss=0.3533 (C:0.3533, R:0.0105)
Batch  75/537: Loss=0.3716 (C:0.3716, R:0.0105)
Batch 100/537: Loss=0.3671 (C:0.3671, R:0.0105)
Batch 125/537: Loss=0.3457 (C:0.3457, R:0.0105)
Batch 150/537: Loss=0.3677 (C:0.3677, R:0.0105)
Batch 175/537: Loss=0.3565 (C:0.3565, R:0.0105)
Batch 200/537: Loss=0.3577 (C:0.3577, R:0.0105)
Batch 225/537: Loss=0.3600 (C:0.3600, R:0.0105)
Batch 250/537: Loss=0.3581 (C:0.3581, R:0.0105)
Batch 275/537: Loss=0.3847 (C:0.3847, R:0.0105)
Batch 300/537: Loss=0.3468 (C:0.3468, R:0.0105)
Batch 325/537: Loss=0.3826 (C:0.3826, R:0.0105)
Batch 350/537: Loss=0.3558 (C:0.3558, R:0.0105)
Batch 375/537: Loss=0.3584 (C:0.3584, R:0.0105)
Batch 400/537: Loss=0.3771 (C:0.3771, R:0.0105)
Batch 425/537: Loss=0.3690 (C:0.3690, R:0.0105)
Batch 450/537: Loss=0.3685 (C:0.3685, R:0.0105)
Batch 475/537: Loss=0.3626 (C:0.3626, R:0.0105)
Batch 500/537: Loss=0.3726 (C:0.3726, R:0.0105)
Batch 525/537: Loss=0.3667 (C:0.3667, R:0.0105)

============================================================
Epoch 41/300 completed in 21.5s
Train: Loss=0.3653 (C:0.3653, R:0.0105) Ratio=4.64x
Val:   Loss=0.4301 (C:0.4301, R:0.0104) Ratio=2.97x
Reconstruction weight: 0.165
No improvement for 1 epochs
============================================================

Epoch 42 Training
----------------------------------------
Batch   0/537: Loss=0.3699 (C:0.3699, R:0.0105)
Batch  25/537: Loss=0.3465 (C:0.3465, R:0.0105)
Batch  50/537: Loss=0.3522 (C:0.3522, R:0.0105)
Batch  75/537: Loss=0.3691 (C:0.3691, R:0.0105)
Batch 100/537: Loss=0.3759 (C:0.3759, R:0.0105)
Batch 125/537: Loss=0.3489 (C:0.3489, R:0.0105)
Batch 150/537: Loss=0.3628 (C:0.3628, R:0.0105)
Batch 175/537: Loss=0.3718 (C:0.3718, R:0.0105)
Batch 200/537: Loss=0.3691 (C:0.3691, R:0.0105)
Batch 225/537: Loss=0.3674 (C:0.3674, R:0.0105)
Batch 250/537: Loss=0.3629 (C:0.3629, R:0.0105)
Batch 275/537: Loss=0.3865 (C:0.3865, R:0.0105)
Batch 300/537: Loss=0.3599 (C:0.3599, R:0.0105)
Batch 325/537: Loss=0.3656 (C:0.3656, R:0.0105)
Batch 350/537: Loss=0.3684 (C:0.3684, R:0.0105)
Batch 375/537: Loss=0.3763 (C:0.3763, R:0.0105)
Batch 400/537: Loss=0.3674 (C:0.3674, R:0.0105)
Batch 425/537: Loss=0.3576 (C:0.3576, R:0.0105)
Batch 450/537: Loss=0.3586 (C:0.3586, R:0.0105)
Batch 475/537: Loss=0.3616 (C:0.3616, R:0.0105)
Batch 500/537: Loss=0.3915 (C:0.3915, R:0.0105)
Batch 525/537: Loss=0.3583 (C:0.3583, R:0.0105)

============================================================
Epoch 42/300 completed in 21.5s
Train: Loss=0.3640 (C:0.3640, R:0.0105) Ratio=4.51x
Val:   Loss=0.4290 (C:0.4290, R:0.0104) Ratio=3.00x
Reconstruction weight: 0.180
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 43
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.166 ± 0.268
    Neg distances: 1.093 ± 0.482
    Separation ratio: 6.59x
    Gap: -1.872
    ✅ Excellent global separation!

Epoch 43 Training
----------------------------------------
Batch   0/537: Loss=0.3519 (C:0.3519, R:0.0105)
Batch  25/537: Loss=0.3563 (C:0.3563, R:0.0105)
Batch  50/537: Loss=0.3409 (C:0.3409, R:0.0105)
Batch  75/537: Loss=0.3349 (C:0.3349, R:0.0105)
Batch 100/537: Loss=0.3599 (C:0.3599, R:0.0105)
Batch 125/537: Loss=0.3519 (C:0.3519, R:0.0105)
Batch 150/537: Loss=0.3525 (C:0.3525, R:0.0105)
Batch 175/537: Loss=0.3557 (C:0.3557, R:0.0105)
Batch 200/537: Loss=0.3616 (C:0.3616, R:0.0105)
Batch 225/537: Loss=0.3594 (C:0.3594, R:0.0105)
Batch 250/537: Loss=0.3632 (C:0.3632, R:0.0105)
Batch 275/537: Loss=0.3609 (C:0.3609, R:0.0105)
Batch 300/537: Loss=0.3553 (C:0.3553, R:0.0105)
Batch 325/537: Loss=0.3554 (C:0.3554, R:0.0105)
Batch 350/537: Loss=0.3524 (C:0.3524, R:0.0105)
Batch 375/537: Loss=0.3554 (C:0.3554, R:0.0105)
Batch 400/537: Loss=0.3732 (C:0.3732, R:0.0105)
Batch 425/537: Loss=0.3526 (C:0.3526, R:0.0105)
Batch 450/537: Loss=0.3544 (C:0.3544, R:0.0105)
Batch 475/537: Loss=0.3520 (C:0.3520, R:0.0105)
Batch 500/537: Loss=0.3572 (C:0.3572, R:0.0105)
Batch 525/537: Loss=0.3590 (C:0.3590, R:0.0105)

============================================================
Epoch 43/300 completed in 28.1s
Train: Loss=0.3545 (C:0.3545, R:0.0105) Ratio=4.60x
Val:   Loss=0.4219 (C:0.4219, R:0.0104) Ratio=3.00x
Reconstruction weight: 0.195
✅ New best model saved (Val Loss: 0.4219)
============================================================

Epoch 44 Training
----------------------------------------
Batch   0/537: Loss=0.3535 (C:0.3535, R:0.0105)
Batch  25/537: Loss=0.3484 (C:0.3484, R:0.0105)
Batch  50/537: Loss=0.3430 (C:0.3430, R:0.0105)
Batch  75/537: Loss=0.3523 (C:0.3523, R:0.0105)
Batch 100/537: Loss=0.3617 (C:0.3617, R:0.0105)
Batch 125/537: Loss=0.3622 (C:0.3622, R:0.0105)
Batch 150/537: Loss=0.3633 (C:0.3633, R:0.0105)
Batch 175/537: Loss=0.3492 (C:0.3492, R:0.0105)
Batch 200/537: Loss=0.3288 (C:0.3288, R:0.0105)
Batch 225/537: Loss=0.3468 (C:0.3468, R:0.0105)
Batch 250/537: Loss=0.3373 (C:0.3373, R:0.0105)
Batch 275/537: Loss=0.3561 (C:0.3561, R:0.0105)
Batch 300/537: Loss=0.3550 (C:0.3550, R:0.0105)
Batch 325/537: Loss=0.3660 (C:0.3660, R:0.0105)
Batch 350/537: Loss=0.3474 (C:0.3474, R:0.0105)
Batch 375/537: Loss=0.3554 (C:0.3554, R:0.0105)
Batch 400/537: Loss=0.3595 (C:0.3595, R:0.0105)
Batch 425/537: Loss=0.3488 (C:0.3488, R:0.0105)
Batch 450/537: Loss=0.3694 (C:0.3694, R:0.0105)
Batch 475/537: Loss=0.3504 (C:0.3504, R:0.0105)
Batch 500/537: Loss=0.3522 (C:0.3522, R:0.0105)
Batch 525/537: Loss=0.3594 (C:0.3594, R:0.0105)

============================================================
Epoch 44/300 completed in 21.7s
Train: Loss=0.3540 (C:0.3540, R:0.0105) Ratio=4.60x
Val:   Loss=0.4240 (C:0.4240, R:0.0104) Ratio=2.99x
Reconstruction weight: 0.210
No improvement for 1 epochs
============================================================

Epoch 45 Training
----------------------------------------
Batch   0/537: Loss=0.3472 (C:0.3472, R:0.0105)
Batch  25/537: Loss=0.3457 (C:0.3457, R:0.0105)
Batch  50/537: Loss=0.3360 (C:0.3360, R:0.0105)
Batch  75/537: Loss=0.3596 (C:0.3596, R:0.0105)
Batch 100/537: Loss=0.3518 (C:0.3518, R:0.0105)
Batch 125/537: Loss=0.3507 (C:0.3507, R:0.0105)
Batch 150/537: Loss=0.3562 (C:0.3562, R:0.0105)
Batch 175/537: Loss=0.3520 (C:0.3520, R:0.0105)
Batch 200/537: Loss=0.3432 (C:0.3432, R:0.0105)
Batch 225/537: Loss=0.3560 (C:0.3560, R:0.0105)
Batch 250/537: Loss=0.3459 (C:0.3459, R:0.0106)
Batch 275/537: Loss=0.3527 (C:0.3527, R:0.0105)
Batch 300/537: Loss=0.3521 (C:0.3521, R:0.0105)
Batch 325/537: Loss=0.3561 (C:0.3561, R:0.0105)
Batch 350/537: Loss=0.3753 (C:0.3753, R:0.0105)
Batch 375/537: Loss=0.3512 (C:0.3512, R:0.0105)
Batch 400/537: Loss=0.3692 (C:0.3692, R:0.0105)
Batch 425/537: Loss=0.3588 (C:0.3588, R:0.0105)
Batch 450/537: Loss=0.3558 (C:0.3558, R:0.0105)
Batch 475/537: Loss=0.3464 (C:0.3464, R:0.0105)
Batch 500/537: Loss=0.3449 (C:0.3449, R:0.0105)
Batch 525/537: Loss=0.3530 (C:0.3530, R:0.0105)

============================================================
Epoch 45/300 completed in 22.1s
Train: Loss=0.3528 (C:0.3528, R:0.0105) Ratio=4.72x
Val:   Loss=0.4201 (C:0.4201, R:0.0104) Ratio=2.96x
Reconstruction weight: 0.225
✅ New best model saved (Val Loss: 0.4201)
============================================================

🌍 Updating global dataset at epoch 46
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.165 ± 0.273
    Neg distances: 1.127 ± 0.491
    Separation ratio: 6.82x
    Gap: -1.945
    ✅ Excellent global separation!

Epoch 46 Training
----------------------------------------
Batch   0/537: Loss=0.3361 (C:0.3361, R:0.0105)
Batch  25/537: Loss=0.3472 (C:0.3472, R:0.0105)
Batch  50/537: Loss=0.3375 (C:0.3375, R:0.0106)
Batch  75/537: Loss=0.3465 (C:0.3465, R:0.0105)
Batch 100/537: Loss=0.3348 (C:0.3348, R:0.0105)
Batch 125/537: Loss=0.3386 (C:0.3386, R:0.0105)
Batch 150/537: Loss=0.3387 (C:0.3387, R:0.0105)
Batch 175/537: Loss=0.3494 (C:0.3494, R:0.0105)
Batch 200/537: Loss=0.3523 (C:0.3523, R:0.0105)
Batch 225/537: Loss=0.3530 (C:0.3530, R:0.0105)
Batch 250/537: Loss=0.3262 (C:0.3262, R:0.0105)
Batch 275/537: Loss=0.3457 (C:0.3457, R:0.0105)
Batch 300/537: Loss=0.3579 (C:0.3579, R:0.0105)
Batch 325/537: Loss=0.3376 (C:0.3376, R:0.0105)
Batch 350/537: Loss=0.3416 (C:0.3416, R:0.0105)
Batch 375/537: Loss=0.3502 (C:0.3502, R:0.0105)
Batch 400/537: Loss=0.3414 (C:0.3414, R:0.0105)
Batch 425/537: Loss=0.3344 (C:0.3344, R:0.0105)
Batch 450/537: Loss=0.3511 (C:0.3511, R:0.0105)
Batch 475/537: Loss=0.3263 (C:0.3263, R:0.0105)
Batch 500/537: Loss=0.3540 (C:0.3540, R:0.0105)
Batch 525/537: Loss=0.3330 (C:0.3330, R:0.0105)

============================================================
Epoch 46/300 completed in 28.1s
Train: Loss=0.3425 (C:0.3425, R:0.0105) Ratio=4.60x
Val:   Loss=0.4221 (C:0.4221, R:0.0104) Ratio=2.92x
Reconstruction weight: 0.240
No improvement for 1 epochs
============================================================

Epoch 47 Training
----------------------------------------
Batch   0/537: Loss=0.3371 (C:0.3371, R:0.0105)
Batch  25/537: Loss=0.3583 (C:0.3583, R:0.0105)
Batch  50/537: Loss=0.3475 (C:0.3475, R:0.0105)
Batch  75/537: Loss=0.3359 (C:0.3359, R:0.0105)
Batch 100/537: Loss=0.3404 (C:0.3404, R:0.0105)
Batch 125/537: Loss=0.3349 (C:0.3349, R:0.0105)
Batch 150/537: Loss=0.3433 (C:0.3433, R:0.0105)
Batch 175/537: Loss=0.3380 (C:0.3380, R:0.0105)
Batch 200/537: Loss=0.3371 (C:0.3371, R:0.0105)
Batch 225/537: Loss=0.3423 (C:0.3423, R:0.0105)
Batch 250/537: Loss=0.3326 (C:0.3326, R:0.0105)
Batch 275/537: Loss=0.3476 (C:0.3476, R:0.0105)
Batch 300/537: Loss=0.3465 (C:0.3465, R:0.0105)
Batch 325/537: Loss=0.3584 (C:0.3584, R:0.0105)
Batch 350/537: Loss=0.3387 (C:0.3387, R:0.0105)
Batch 375/537: Loss=0.3392 (C:0.3392, R:0.0105)
Batch 400/537: Loss=0.3370 (C:0.3370, R:0.0105)
Batch 425/537: Loss=0.3464 (C:0.3464, R:0.0105)
Batch 450/537: Loss=0.3396 (C:0.3396, R:0.0105)
Batch 475/537: Loss=0.3391 (C:0.3391, R:0.0105)
Batch 500/537: Loss=0.3475 (C:0.3475, R:0.0105)
Batch 525/537: Loss=0.3386 (C:0.3386, R:0.0105)

============================================================
Epoch 47/300 completed in 21.5s
Train: Loss=0.3407 (C:0.3407, R:0.0105) Ratio=4.65x
Val:   Loss=0.4166 (C:0.4166, R:0.0104) Ratio=2.93x
Reconstruction weight: 0.255
✅ New best model saved (Val Loss: 0.4166)
============================================================

Epoch 48 Training
----------------------------------------
Batch   0/537: Loss=0.3421 (C:0.3421, R:0.0105)
Batch  25/537: Loss=0.3282 (C:0.3282, R:0.0105)
Batch  50/537: Loss=0.3394 (C:0.3394, R:0.0105)
Batch  75/537: Loss=0.3331 (C:0.3331, R:0.0105)
Batch 100/537: Loss=0.3333 (C:0.3333, R:0.0105)
Batch 125/537: Loss=0.3417 (C:0.3417, R:0.0105)
Batch 150/537: Loss=0.3351 (C:0.3351, R:0.0105)
Batch 175/537: Loss=0.3400 (C:0.3400, R:0.0105)
Batch 200/537: Loss=0.3364 (C:0.3364, R:0.0105)
Batch 225/537: Loss=0.3337 (C:0.3337, R:0.0105)
Batch 250/537: Loss=0.3345 (C:0.3345, R:0.0105)
Batch 275/537: Loss=0.3409 (C:0.3409, R:0.0105)
Batch 300/537: Loss=0.3414 (C:0.3414, R:0.0105)
Batch 325/537: Loss=0.3490 (C:0.3490, R:0.0105)
Batch 350/537: Loss=0.3394 (C:0.3394, R:0.0105)
Batch 375/537: Loss=0.3383 (C:0.3383, R:0.0105)
Batch 400/537: Loss=0.3412 (C:0.3412, R:0.0105)
Batch 425/537: Loss=0.3426 (C:0.3426, R:0.0105)
Batch 450/537: Loss=0.3599 (C:0.3599, R:0.0105)
Batch 475/537: Loss=0.3389 (C:0.3389, R:0.0105)
Batch 500/537: Loss=0.3511 (C:0.3511, R:0.0105)
Batch 525/537: Loss=0.3480 (C:0.3480, R:0.0105)

============================================================
Epoch 48/300 completed in 22.1s
Train: Loss=0.3400 (C:0.3400, R:0.0105) Ratio=4.68x
Val:   Loss=0.4107 (C:0.4107, R:0.0104) Ratio=2.96x
Reconstruction weight: 0.270
✅ New best model saved (Val Loss: 0.4107)
============================================================

🌍 Updating global dataset at epoch 49
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.169 ± 0.284
    Neg distances: 1.159 ± 0.505
    Separation ratio: 6.87x
    Gap: -1.996
    ✅ Excellent global separation!

Epoch 49 Training
----------------------------------------
Batch   0/537: Loss=0.3226 (C:0.3226, R:0.0105)
Batch  25/537: Loss=0.3293 (C:0.3293, R:0.0105)
Batch  50/537: Loss=0.3213 (C:0.3213, R:0.0105)
Batch  75/537: Loss=0.3333 (C:0.3333, R:0.0105)
Batch 100/537: Loss=0.3620 (C:0.3620, R:0.0105)
Batch 125/537: Loss=0.3348 (C:0.3348, R:0.0105)
Batch 150/537: Loss=0.3259 (C:0.3259, R:0.0105)
Batch 175/537: Loss=0.3297 (C:0.3297, R:0.0105)
Batch 200/537: Loss=0.3369 (C:0.3369, R:0.0105)
Batch 225/537: Loss=0.3296 (C:0.3296, R:0.0105)
Batch 250/537: Loss=0.3367 (C:0.3367, R:0.0105)
Batch 275/537: Loss=0.3388 (C:0.3388, R:0.0105)
Batch 300/537: Loss=0.3375 (C:0.3375, R:0.0105)
Batch 325/537: Loss=0.3267 (C:0.3267, R:0.0105)
Batch 350/537: Loss=0.3303 (C:0.3303, R:0.0105)
Batch 375/537: Loss=0.3192 (C:0.3192, R:0.0105)
Batch 400/537: Loss=0.3398 (C:0.3398, R:0.0105)
Batch 425/537: Loss=0.3401 (C:0.3401, R:0.0105)
Batch 450/537: Loss=0.3346 (C:0.3346, R:0.0105)
Batch 475/537: Loss=0.3324 (C:0.3324, R:0.0105)
Batch 500/537: Loss=0.3403 (C:0.3403, R:0.0105)
Batch 525/537: Loss=0.3514 (C:0.3514, R:0.0105)

============================================================
Epoch 49/300 completed in 28.4s
Train: Loss=0.3343 (C:0.3343, R:0.0105) Ratio=4.66x
Val:   Loss=0.4085 (C:0.4085, R:0.0104) Ratio=2.94x
Reconstruction weight: 0.285
✅ New best model saved (Val Loss: 0.4085)
============================================================

Epoch 50 Training
----------------------------------------
Batch   0/537: Loss=0.3313 (C:0.3313, R:0.0105)
Batch  25/537: Loss=0.3144 (C:0.3144, R:0.0105)
Batch  50/537: Loss=0.3298 (C:0.3298, R:0.0105)
Batch  75/537: Loss=0.3101 (C:0.3101, R:0.0105)
Batch 100/537: Loss=0.3242 (C:0.3242, R:0.0105)
Batch 125/537: Loss=0.3644 (C:0.3644, R:0.0105)
Batch 150/537: Loss=0.3315 (C:0.3315, R:0.0105)
Batch 175/537: Loss=0.3335 (C:0.3335, R:0.0105)
Batch 200/537: Loss=0.3369 (C:0.3369, R:0.0105)
Batch 225/537: Loss=0.3330 (C:0.3330, R:0.0105)
Batch 250/537: Loss=0.3191 (C:0.3191, R:0.0105)
Batch 275/537: Loss=0.3426 (C:0.3426, R:0.0105)
Batch 300/537: Loss=0.3312 (C:0.3312, R:0.0105)
Batch 325/537: Loss=0.3174 (C:0.3174, R:0.0105)
Batch 350/537: Loss=0.3457 (C:0.3457, R:0.0105)
Batch 375/537: Loss=0.3410 (C:0.3410, R:0.0105)
Batch 400/537: Loss=0.3447 (C:0.3447, R:0.0105)
Batch 425/537: Loss=0.3449 (C:0.3449, R:0.0105)
Batch 450/537: Loss=0.3170 (C:0.3170, R:0.0105)
Batch 475/537: Loss=0.3416 (C:0.3416, R:0.0105)
Batch 500/537: Loss=0.3473 (C:0.3473, R:0.0105)
Batch 525/537: Loss=0.3436 (C:0.3436, R:0.0105)

============================================================
Epoch 50/300 completed in 21.9s
Train: Loss=0.3338 (C:0.3338, R:0.0105) Ratio=4.70x
Val:   Loss=0.4038 (C:0.4038, R:0.0104) Ratio=2.99x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.4038)
============================================================

Epoch 51 Training
----------------------------------------
Batch   0/537: Loss=0.3269 (C:0.3269, R:0.0105)
Batch  25/537: Loss=0.3307 (C:0.3307, R:0.0105)
Batch  50/537: Loss=0.3419 (C:0.3419, R:0.0105)
Batch  75/537: Loss=0.3431 (C:0.3431, R:0.0105)
Batch 100/537: Loss=0.3476 (C:0.3476, R:0.0105)
Batch 125/537: Loss=0.3274 (C:0.3274, R:0.0105)
Batch 150/537: Loss=0.3233 (C:0.3233, R:0.0105)
Batch 175/537: Loss=0.3358 (C:0.3358, R:0.0105)
Batch 200/537: Loss=0.3289 (C:0.3289, R:0.0106)
Batch 225/537: Loss=0.3172 (C:0.3172, R:0.0105)
Batch 250/537: Loss=0.3525 (C:0.3525, R:0.0105)
Batch 275/537: Loss=0.3386 (C:0.3386, R:0.0105)
Batch 300/537: Loss=0.3602 (C:0.3602, R:0.0105)
Batch 325/537: Loss=0.3207 (C:0.3207, R:0.0106)
Batch 350/537: Loss=0.3572 (C:0.3572, R:0.0105)
Batch 375/537: Loss=0.3365 (C:0.3365, R:0.0105)
Batch 400/537: Loss=0.3346 (C:0.3346, R:0.0105)
Batch 425/537: Loss=0.3575 (C:0.3575, R:0.0105)
Batch 450/537: Loss=0.3416 (C:0.3416, R:0.0105)
Batch 475/537: Loss=0.3337 (C:0.3337, R:0.0105)
Batch 500/537: Loss=0.3344 (C:0.3344, R:0.0105)
Batch 525/537: Loss=0.3288 (C:0.3288, R:0.0105)

============================================================
Epoch 51/300 completed in 21.9s
Train: Loss=0.3327 (C:0.3327, R:0.0105) Ratio=4.72x
Val:   Loss=0.4106 (C:0.4106, R:0.0104) Ratio=2.98x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 52
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.164 ± 0.279
    Neg distances: 1.189 ± 0.512
    Separation ratio: 7.23x
    Gap: -2.028
    ✅ Excellent global separation!

Epoch 52 Training
----------------------------------------
Batch   0/537: Loss=0.3313 (C:0.3313, R:0.0105)
Batch  25/537: Loss=0.3088 (C:0.3088, R:0.0105)
Batch  50/537: Loss=0.3105 (C:0.3105, R:0.0105)
Batch  75/537: Loss=0.3140 (C:0.3140, R:0.0105)
Batch 100/537: Loss=0.3318 (C:0.3318, R:0.0105)
Batch 125/537: Loss=0.3211 (C:0.3211, R:0.0105)
Batch 150/537: Loss=0.3240 (C:0.3240, R:0.0105)
Batch 175/537: Loss=0.3006 (C:0.3006, R:0.0105)
Batch 200/537: Loss=0.3278 (C:0.3278, R:0.0105)
Batch 225/537: Loss=0.3167 (C:0.3167, R:0.0105)
Batch 250/537: Loss=0.3259 (C:0.3259, R:0.0105)
Batch 275/537: Loss=0.3321 (C:0.3321, R:0.0105)
Batch 300/537: Loss=0.3082 (C:0.3082, R:0.0105)
Batch 325/537: Loss=0.3121 (C:0.3121, R:0.0105)
Batch 350/537: Loss=0.3282 (C:0.3282, R:0.0105)
Batch 375/537: Loss=0.3300 (C:0.3300, R:0.0105)
Batch 400/537: Loss=0.3303 (C:0.3303, R:0.0105)
Batch 425/537: Loss=0.3361 (C:0.3361, R:0.0105)
Batch 450/537: Loss=0.3173 (C:0.3173, R:0.0105)
Batch 475/537: Loss=0.3125 (C:0.3125, R:0.0105)
Batch 500/537: Loss=0.3406 (C:0.3406, R:0.0105)
Batch 525/537: Loss=0.3410 (C:0.3410, R:0.0105)

============================================================
Epoch 52/300 completed in 27.8s
Train: Loss=0.3228 (C:0.3228, R:0.0105) Ratio=4.76x
Val:   Loss=0.4022 (C:0.4022, R:0.0104) Ratio=2.92x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.4022)
============================================================

Epoch 53 Training
----------------------------------------
Batch   0/537: Loss=0.3239 (C:0.3239, R:0.0105)
Batch  25/537: Loss=0.3019 (C:0.3019, R:0.0105)
Batch  50/537: Loss=0.3221 (C:0.3221, R:0.0105)
Batch  75/537: Loss=0.3153 (C:0.3153, R:0.0105)
Batch 100/537: Loss=0.3134 (C:0.3134, R:0.0105)
Batch 125/537: Loss=0.3098 (C:0.3098, R:0.0105)
Batch 150/537: Loss=0.3183 (C:0.3183, R:0.0106)
Batch 175/537: Loss=0.3333 (C:0.3333, R:0.0105)
Batch 200/537: Loss=0.3176 (C:0.3176, R:0.0105)
Batch 225/537: Loss=0.3228 (C:0.3228, R:0.0105)
Batch 250/537: Loss=0.3344 (C:0.3344, R:0.0105)
Batch 275/537: Loss=0.3269 (C:0.3269, R:0.0105)
Batch 300/537: Loss=0.3100 (C:0.3100, R:0.0105)
Batch 325/537: Loss=0.2989 (C:0.2989, R:0.0105)
Batch 350/537: Loss=0.3186 (C:0.3186, R:0.0105)
Batch 375/537: Loss=0.3332 (C:0.3332, R:0.0105)
Batch 400/537: Loss=0.3286 (C:0.3286, R:0.0105)
Batch 425/537: Loss=0.3142 (C:0.3142, R:0.0105)
Batch 450/537: Loss=0.3132 (C:0.3132, R:0.0105)
Batch 475/537: Loss=0.3266 (C:0.3266, R:0.0105)
Batch 500/537: Loss=0.3227 (C:0.3227, R:0.0105)
Batch 525/537: Loss=0.3270 (C:0.3270, R:0.0106)

============================================================
Epoch 53/300 completed in 21.8s
Train: Loss=0.3216 (C:0.3216, R:0.0105) Ratio=4.91x
Val:   Loss=0.4032 (C:0.4032, R:0.0104) Ratio=2.98x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

Epoch 54 Training
----------------------------------------
Batch   0/537: Loss=0.3250 (C:0.3250, R:0.0105)
Batch  25/537: Loss=0.3126 (C:0.3126, R:0.0105)
Batch  50/537: Loss=0.3122 (C:0.3122, R:0.0105)
Batch  75/537: Loss=0.3126 (C:0.3126, R:0.0105)
Batch 100/537: Loss=0.3166 (C:0.3166, R:0.0105)
Batch 125/537: Loss=0.3198 (C:0.3198, R:0.0105)
Batch 150/537: Loss=0.3196 (C:0.3196, R:0.0105)
Batch 175/537: Loss=0.3317 (C:0.3317, R:0.0105)
Batch 200/537: Loss=0.3239 (C:0.3239, R:0.0105)
Batch 225/537: Loss=0.3189 (C:0.3189, R:0.0105)
Batch 250/537: Loss=0.3180 (C:0.3180, R:0.0105)
Batch 275/537: Loss=0.3334 (C:0.3334, R:0.0105)
Batch 300/537: Loss=0.3121 (C:0.3121, R:0.0105)
Batch 325/537: Loss=0.3292 (C:0.3292, R:0.0105)
Batch 350/537: Loss=0.3079 (C:0.3079, R:0.0105)
Batch 375/537: Loss=0.3198 (C:0.3198, R:0.0105)
Batch 400/537: Loss=0.3221 (C:0.3221, R:0.0105)
Batch 425/537: Loss=0.3136 (C:0.3136, R:0.0105)
Batch 450/537: Loss=0.3251 (C:0.3251, R:0.0105)
Batch 475/537: Loss=0.3264 (C:0.3264, R:0.0105)
Batch 500/537: Loss=0.3035 (C:0.3035, R:0.0105)
Batch 525/537: Loss=0.3163 (C:0.3163, R:0.0105)

============================================================
Epoch 54/300 completed in 21.8s
Train: Loss=0.3205 (C:0.3205, R:0.0105) Ratio=4.83x
Val:   Loss=0.4011 (C:0.4011, R:0.0104) Ratio=2.97x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.4011)
============================================================

🌍 Updating global dataset at epoch 55
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.166 ± 0.283
    Neg distances: 1.211 ± 0.522
    Separation ratio: 7.28x
    Gap: -2.085
    ✅ Excellent global separation!

Epoch 55 Training
----------------------------------------
Batch   0/537: Loss=0.3159 (C:0.3159, R:0.0105)
Batch  25/537: Loss=0.3185 (C:0.3185, R:0.0105)
Batch  50/537: Loss=0.3167 (C:0.3167, R:0.0105)
Batch  75/537: Loss=0.3179 (C:0.3179, R:0.0105)
Batch 100/537: Loss=0.3180 (C:0.3180, R:0.0105)
Batch 125/537: Loss=0.3062 (C:0.3062, R:0.0105)
Batch 150/537: Loss=0.3249 (C:0.3249, R:0.0105)
Batch 175/537: Loss=0.3251 (C:0.3251, R:0.0105)
Batch 200/537: Loss=0.3180 (C:0.3180, R:0.0105)
Batch 225/537: Loss=0.3123 (C:0.3123, R:0.0105)
Batch 250/537: Loss=0.3349 (C:0.3349, R:0.0105)
Batch 275/537: Loss=0.3252 (C:0.3252, R:0.0105)
Batch 300/537: Loss=0.3056 (C:0.3056, R:0.0105)
Batch 325/537: Loss=0.3186 (C:0.3186, R:0.0105)
Batch 350/537: Loss=0.3064 (C:0.3064, R:0.0105)
Batch 375/537: Loss=0.3255 (C:0.3255, R:0.0105)
Batch 400/537: Loss=0.3161 (C:0.3161, R:0.0105)
Batch 425/537: Loss=0.3323 (C:0.3323, R:0.0105)
Batch 450/537: Loss=0.3293 (C:0.3293, R:0.0105)
Batch 475/537: Loss=0.3354 (C:0.3354, R:0.0105)
Batch 500/537: Loss=0.3002 (C:0.3002, R:0.0105)
Batch 525/537: Loss=0.3103 (C:0.3103, R:0.0105)

============================================================
Epoch 55/300 completed in 28.2s
Train: Loss=0.3177 (C:0.3177, R:0.0105) Ratio=4.84x
Val:   Loss=0.3932 (C:0.3932, R:0.0104) Ratio=2.98x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.3932)
============================================================

Epoch 56 Training
----------------------------------------
Batch   0/537: Loss=0.3195 (C:0.3195, R:0.0105)
Batch  25/537: Loss=0.3211 (C:0.3211, R:0.0105)
Batch  50/537: Loss=0.3136 (C:0.3136, R:0.0106)
Batch  75/537: Loss=0.3252 (C:0.3252, R:0.0105)
Batch 100/537: Loss=0.3147 (C:0.3147, R:0.0106)
Batch 125/537: Loss=0.3043 (C:0.3043, R:0.0105)
Batch 150/537: Loss=0.3223 (C:0.3223, R:0.0105)
Batch 175/537: Loss=0.3227 (C:0.3227, R:0.0105)
Batch 200/537: Loss=0.3246 (C:0.3246, R:0.0105)
Batch 225/537: Loss=0.3168 (C:0.3168, R:0.0105)
Batch 250/537: Loss=0.3026 (C:0.3026, R:0.0105)
Batch 275/537: Loss=0.3161 (C:0.3161, R:0.0105)
Batch 300/537: Loss=0.3107 (C:0.3107, R:0.0105)
Batch 325/537: Loss=0.3206 (C:0.3206, R:0.0105)
Batch 350/537: Loss=0.3257 (C:0.3257, R:0.0105)
Batch 375/537: Loss=0.3190 (C:0.3190, R:0.0105)
Batch 400/537: Loss=0.3170 (C:0.3170, R:0.0105)
Batch 425/537: Loss=0.2983 (C:0.2983, R:0.0105)
Batch 450/537: Loss=0.3179 (C:0.3179, R:0.0105)
Batch 475/537: Loss=0.3233 (C:0.3233, R:0.0105)
Batch 500/537: Loss=0.3038 (C:0.3038, R:0.0105)
Batch 525/537: Loss=0.3108 (C:0.3108, R:0.0105)

============================================================
Epoch 56/300 completed in 21.2s
Train: Loss=0.3174 (C:0.3174, R:0.0105) Ratio=4.83x
Val:   Loss=0.4009 (C:0.4009, R:0.0104) Ratio=2.95x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

Epoch 57 Training
----------------------------------------
Batch   0/537: Loss=0.3190 (C:0.3190, R:0.0105)
Batch  25/537: Loss=0.2943 (C:0.2943, R:0.0105)
Batch  50/537: Loss=0.3125 (C:0.3125, R:0.0105)
Batch  75/537: Loss=0.3532 (C:0.3532, R:0.0105)
Batch 100/537: Loss=0.3036 (C:0.3036, R:0.0105)
Batch 125/537: Loss=0.2954 (C:0.2954, R:0.0105)
Batch 150/537: Loss=0.3093 (C:0.3093, R:0.0105)
Batch 175/537: Loss=0.3321 (C:0.3321, R:0.0105)
Batch 200/537: Loss=0.3319 (C:0.3319, R:0.0105)
Batch 225/537: Loss=0.3382 (C:0.3382, R:0.0105)
Batch 250/537: Loss=0.3213 (C:0.3213, R:0.0105)
Batch 275/537: Loss=0.3198 (C:0.3198, R:0.0105)
Batch 300/537: Loss=0.2967 (C:0.2967, R:0.0105)
Batch 325/537: Loss=0.3151 (C:0.3151, R:0.0105)
Batch 350/537: Loss=0.3207 (C:0.3207, R:0.0105)
Batch 375/537: Loss=0.3178 (C:0.3178, R:0.0105)
Batch 400/537: Loss=0.3101 (C:0.3101, R:0.0105)
Batch 425/537: Loss=0.3130 (C:0.3130, R:0.0105)
Batch 450/537: Loss=0.3216 (C:0.3216, R:0.0105)
Batch 475/537: Loss=0.3050 (C:0.3050, R:0.0105)
Batch 500/537: Loss=0.3030 (C:0.3030, R:0.0105)
Batch 525/537: Loss=0.3215 (C:0.3215, R:0.0105)

============================================================
Epoch 57/300 completed in 21.4s
Train: Loss=0.3172 (C:0.3172, R:0.0105) Ratio=4.94x
Val:   Loss=0.3935 (C:0.3935, R:0.0104) Ratio=3.00x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 58
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.170 ± 0.289
    Neg distances: 1.223 ± 0.527
    Separation ratio: 7.20x
    Gap: -2.129
    ✅ Excellent global separation!

Epoch 58 Training
----------------------------------------
Batch   0/537: Loss=0.2963 (C:0.2963, R:0.0106)
Batch  25/537: Loss=0.3032 (C:0.3032, R:0.0105)
Batch  50/537: Loss=0.3071 (C:0.3071, R:0.0106)
Batch  75/537: Loss=0.3019 (C:0.3019, R:0.0105)
Batch 100/537: Loss=0.3075 (C:0.3075, R:0.0105)
Batch 125/537: Loss=0.3132 (C:0.3132, R:0.0105)
Batch 150/537: Loss=0.3092 (C:0.3092, R:0.0105)
Batch 175/537: Loss=0.2914 (C:0.2914, R:0.0105)
Batch 200/537: Loss=0.3354 (C:0.3354, R:0.0105)
Batch 225/537: Loss=0.3059 (C:0.3059, R:0.0105)
Batch 250/537: Loss=0.3076 (C:0.3076, R:0.0105)
Batch 275/537: Loss=0.3138 (C:0.3138, R:0.0105)
Batch 300/537: Loss=0.3339 (C:0.3339, R:0.0105)
Batch 325/537: Loss=0.3238 (C:0.3238, R:0.0105)
Batch 350/537: Loss=0.3152 (C:0.3152, R:0.0105)
Batch 375/537: Loss=0.3428 (C:0.3428, R:0.0105)
Batch 400/537: Loss=0.3247 (C:0.3247, R:0.0105)
Batch 425/537: Loss=0.3119 (C:0.3119, R:0.0105)
Batch 450/537: Loss=0.3280 (C:0.3280, R:0.0105)
Batch 475/537: Loss=0.3054 (C:0.3054, R:0.0105)
Batch 500/537: Loss=0.3246 (C:0.3246, R:0.0105)
Batch 525/537: Loss=0.3181 (C:0.3181, R:0.0105)

============================================================
Epoch 58/300 completed in 27.4s
Train: Loss=0.3140 (C:0.3140, R:0.0105) Ratio=4.89x
Val:   Loss=0.3985 (C:0.3985, R:0.0104) Ratio=2.94x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

Epoch 59 Training
----------------------------------------
Batch   0/537: Loss=0.2878 (C:0.2878, R:0.0105)
Batch  25/537: Loss=0.3037 (C:0.3037, R:0.0105)
Batch  50/537: Loss=0.2933 (C:0.2933, R:0.0105)
Batch  75/537: Loss=0.2956 (C:0.2956, R:0.0105)
Batch 100/537: Loss=0.3339 (C:0.3339, R:0.0105)
Batch 125/537: Loss=0.3226 (C:0.3226, R:0.0105)
Batch 150/537: Loss=0.3172 (C:0.3172, R:0.0105)
Batch 175/537: Loss=0.3235 (C:0.3235, R:0.0105)
Batch 200/537: Loss=0.3176 (C:0.3176, R:0.0105)
Batch 225/537: Loss=0.3034 (C:0.3034, R:0.0105)
Batch 250/537: Loss=0.3192 (C:0.3192, R:0.0105)
Batch 275/537: Loss=0.3062 (C:0.3062, R:0.0105)
Batch 300/537: Loss=0.3108 (C:0.3108, R:0.0105)
Batch 325/537: Loss=0.3242 (C:0.3242, R:0.0105)
Batch 350/537: Loss=0.3055 (C:0.3055, R:0.0105)
Batch 375/537: Loss=0.3068 (C:0.3068, R:0.0105)
Batch 400/537: Loss=0.3152 (C:0.3152, R:0.0105)
Batch 425/537: Loss=0.3042 (C:0.3042, R:0.0105)
Batch 450/537: Loss=0.3091 (C:0.3091, R:0.0105)
Batch 475/537: Loss=0.3170 (C:0.3170, R:0.0105)
Batch 500/537: Loss=0.3130 (C:0.3130, R:0.0105)
Batch 525/537: Loss=0.3240 (C:0.3240, R:0.0105)

============================================================
Epoch 59/300 completed in 21.3s
Train: Loss=0.3137 (C:0.3137, R:0.0105) Ratio=5.05x
Val:   Loss=0.3993 (C:0.3993, R:0.0104) Ratio=2.96x
Reconstruction weight: 0.300
No improvement for 4 epochs
============================================================

Epoch 60 Training
----------------------------------------
Batch   0/537: Loss=0.3115 (C:0.3115, R:0.0105)
Batch  25/537: Loss=0.3117 (C:0.3117, R:0.0105)
Batch  50/537: Loss=0.3320 (C:0.3320, R:0.0105)
Batch  75/537: Loss=0.3178 (C:0.3178, R:0.0105)
Batch 100/537: Loss=0.3086 (C:0.3086, R:0.0105)
Batch 125/537: Loss=0.3054 (C:0.3054, R:0.0105)
Batch 150/537: Loss=0.3136 (C:0.3136, R:0.0105)
Batch 175/537: Loss=0.3171 (C:0.3171, R:0.0105)
Batch 200/537: Loss=0.3031 (C:0.3031, R:0.0105)
Batch 225/537: Loss=0.3025 (C:0.3025, R:0.0105)
Batch 250/537: Loss=0.3138 (C:0.3138, R:0.0105)
Batch 275/537: Loss=0.3213 (C:0.3213, R:0.0105)
Batch 300/537: Loss=0.3068 (C:0.3068, R:0.0105)
Batch 325/537: Loss=0.3149 (C:0.3149, R:0.0106)
Batch 350/537: Loss=0.3068 (C:0.3068, R:0.0105)
Batch 375/537: Loss=0.3332 (C:0.3332, R:0.0105)
Batch 400/537: Loss=0.3139 (C:0.3139, R:0.0105)
Batch 425/537: Loss=0.3204 (C:0.3204, R:0.0105)
Batch 450/537: Loss=0.3130 (C:0.3130, R:0.0105)
Batch 475/537: Loss=0.3156 (C:0.3156, R:0.0105)
Batch 500/537: Loss=0.3202 (C:0.3202, R:0.0105)
Batch 525/537: Loss=0.3128 (C:0.3128, R:0.0105)

============================================================
Epoch 60/300 completed in 21.3s
Train: Loss=0.3137 (C:0.3137, R:0.0105) Ratio=4.95x
Val:   Loss=0.3942 (C:0.3942, R:0.0104) Ratio=2.96x
Reconstruction weight: 0.300
No improvement for 5 epochs
Checkpoint saved at epoch 60
============================================================

🌍 Updating global dataset at epoch 61
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.158 ± 0.270
    Neg distances: 1.237 ± 0.522
    Separation ratio: 7.82x
    Gap: -2.091
    ✅ Excellent global separation!

Epoch 61 Training
----------------------------------------
Batch   0/537: Loss=0.3057 (C:0.3057, R:0.0105)
Batch  25/537: Loss=0.3098 (C:0.3098, R:0.0105)
Batch  50/537: Loss=0.3050 (C:0.3050, R:0.0105)
Batch  75/537: Loss=0.2994 (C:0.2994, R:0.0105)
Batch 100/537: Loss=0.3088 (C:0.3088, R:0.0105)
Batch 125/537: Loss=0.3132 (C:0.3132, R:0.0105)
Batch 150/537: Loss=0.2871 (C:0.2871, R:0.0105)
Batch 175/537: Loss=0.3189 (C:0.3189, R:0.0105)
Batch 200/537: Loss=0.2889 (C:0.2889, R:0.0105)
Batch 225/537: Loss=0.3003 (C:0.3003, R:0.0105)
Batch 250/537: Loss=0.3108 (C:0.3108, R:0.0105)
Batch 275/537: Loss=0.3127 (C:0.3127, R:0.0105)
Batch 300/537: Loss=0.3230 (C:0.3230, R:0.0105)
Batch 325/537: Loss=0.2927 (C:0.2927, R:0.0105)
Batch 350/537: Loss=0.3007 (C:0.3007, R:0.0105)
Batch 375/537: Loss=0.2852 (C:0.2852, R:0.0105)
Batch 400/537: Loss=0.3013 (C:0.3013, R:0.0105)
Batch 425/537: Loss=0.2995 (C:0.2995, R:0.0106)
Batch 450/537: Loss=0.2886 (C:0.2886, R:0.0105)
Batch 475/537: Loss=0.3269 (C:0.3269, R:0.0105)
Batch 500/537: Loss=0.3082 (C:0.3082, R:0.0105)
Batch 525/537: Loss=0.3207 (C:0.3207, R:0.0105)

============================================================
Epoch 61/300 completed in 26.7s
Train: Loss=0.3015 (C:0.3015, R:0.0105) Ratio=4.95x
Val:   Loss=0.3896 (C:0.3896, R:0.0104) Ratio=2.94x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.3896)
============================================================

Epoch 62 Training
----------------------------------------
Batch   0/537: Loss=0.2765 (C:0.2765, R:0.0105)
Batch  25/537: Loss=0.2957 (C:0.2957, R:0.0105)
Batch  50/537: Loss=0.3172 (C:0.3172, R:0.0105)
Batch  75/537: Loss=0.3014 (C:0.3014, R:0.0106)
Batch 100/537: Loss=0.2827 (C:0.2827, R:0.0105)
Batch 125/537: Loss=0.3109 (C:0.3109, R:0.0105)
Batch 150/537: Loss=0.3006 (C:0.3006, R:0.0105)
Batch 175/537: Loss=0.3057 (C:0.3057, R:0.0106)
Batch 200/537: Loss=0.2979 (C:0.2979, R:0.0105)
Batch 225/537: Loss=0.2770 (C:0.2770, R:0.0105)
Batch 250/537: Loss=0.2801 (C:0.2801, R:0.0105)
Batch 275/537: Loss=0.3129 (C:0.3129, R:0.0105)
Batch 300/537: Loss=0.2795 (C:0.2795, R:0.0105)
Batch 325/537: Loss=0.2918 (C:0.2918, R:0.0105)
Batch 350/537: Loss=0.2996 (C:0.2996, R:0.0105)
Batch 375/537: Loss=0.2823 (C:0.2823, R:0.0105)
Batch 400/537: Loss=0.3283 (C:0.3283, R:0.0105)
Batch 425/537: Loss=0.2969 (C:0.2969, R:0.0105)
Batch 450/537: Loss=0.2949 (C:0.2949, R:0.0105)
Batch 475/537: Loss=0.3085 (C:0.3085, R:0.0106)
Batch 500/537: Loss=0.3053 (C:0.3053, R:0.0105)
Batch 525/537: Loss=0.3092 (C:0.3092, R:0.0105)

============================================================
Epoch 62/300 completed in 21.5s
Train: Loss=0.3009 (C:0.3009, R:0.0105) Ratio=5.06x
Val:   Loss=0.3831 (C:0.3831, R:0.0104) Ratio=2.94x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.3831)
============================================================

Epoch 63 Training
----------------------------------------
Batch   0/537: Loss=0.2970 (C:0.2970, R:0.0105)
Batch  25/537: Loss=0.2910 (C:0.2910, R:0.0105)
Batch  50/537: Loss=0.3068 (C:0.3068, R:0.0105)
Batch  75/537: Loss=0.3060 (C:0.3060, R:0.0105)
Batch 100/537: Loss=0.2850 (C:0.2850, R:0.0105)
Batch 125/537: Loss=0.2980 (C:0.2980, R:0.0105)
Batch 150/537: Loss=0.2869 (C:0.2869, R:0.0105)
Batch 175/537: Loss=0.2978 (C:0.2978, R:0.0105)
Batch 200/537: Loss=0.2971 (C:0.2971, R:0.0105)
Batch 225/537: Loss=0.3151 (C:0.3151, R:0.0105)
Batch 250/537: Loss=0.2905 (C:0.2905, R:0.0105)
Batch 275/537: Loss=0.2947 (C:0.2947, R:0.0105)
Batch 300/537: Loss=0.2846 (C:0.2846, R:0.0105)
Batch 325/537: Loss=0.2902 (C:0.2902, R:0.0105)
Batch 350/537: Loss=0.3095 (C:0.3095, R:0.0105)
Batch 375/537: Loss=0.3010 (C:0.3010, R:0.0105)
Batch 400/537: Loss=0.2936 (C:0.2936, R:0.0105)
Batch 425/537: Loss=0.2946 (C:0.2946, R:0.0105)
Batch 450/537: Loss=0.2966 (C:0.2966, R:0.0105)
Batch 475/537: Loss=0.3118 (C:0.3118, R:0.0105)
Batch 500/537: Loss=0.3065 (C:0.3065, R:0.0105)
Batch 525/537: Loss=0.3128 (C:0.3128, R:0.0105)

============================================================
Epoch 63/300 completed in 21.1s
Train: Loss=0.2994 (C:0.2994, R:0.0105) Ratio=5.02x
Val:   Loss=0.3855 (C:0.3855, R:0.0104) Ratio=2.97x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 64
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.154 ± 0.280
    Neg distances: 1.260 ± 0.529
    Separation ratio: 8.19x
    Gap: -2.130
    ✅ Excellent global separation!

Epoch 64 Training
----------------------------------------
Batch   0/537: Loss=0.2799 (C:0.2799, R:0.0105)
Batch  25/537: Loss=0.2945 (C:0.2945, R:0.0105)
Batch  50/537: Loss=0.2920 (C:0.2920, R:0.0105)
Batch  75/537: Loss=0.2811 (C:0.2811, R:0.0105)
Batch 100/537: Loss=0.2739 (C:0.2739, R:0.0105)
Batch 125/537: Loss=0.3042 (C:0.3042, R:0.0105)
Batch 150/537: Loss=0.2749 (C:0.2749, R:0.0105)
Batch 175/537: Loss=0.2734 (C:0.2734, R:0.0105)
Batch 200/537: Loss=0.2785 (C:0.2785, R:0.0105)
Batch 225/537: Loss=0.3126 (C:0.3126, R:0.0105)
Batch 250/537: Loss=0.2950 (C:0.2950, R:0.0106)
Batch 275/537: Loss=0.2803 (C:0.2803, R:0.0105)
Batch 300/537: Loss=0.2927 (C:0.2927, R:0.0105)
Batch 325/537: Loss=0.3036 (C:0.3036, R:0.0105)
Batch 350/537: Loss=0.2566 (C:0.2566, R:0.0105)
Batch 375/537: Loss=0.2937 (C:0.2937, R:0.0105)
Batch 400/537: Loss=0.3217 (C:0.3217, R:0.0105)
Batch 425/537: Loss=0.2887 (C:0.2887, R:0.0105)
Batch 450/537: Loss=0.3059 (C:0.3059, R:0.0105)
Batch 475/537: Loss=0.2789 (C:0.2789, R:0.0105)
Batch 500/537: Loss=0.2930 (C:0.2930, R:0.0105)
Batch 525/537: Loss=0.2983 (C:0.2983, R:0.0105)

============================================================
Epoch 64/300 completed in 27.0s
Train: Loss=0.2929 (C:0.2929, R:0.0105) Ratio=5.04x
Val:   Loss=0.3784 (C:0.3784, R:0.0104) Ratio=2.96x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.3784)
============================================================

Epoch 65 Training
----------------------------------------
Batch   0/537: Loss=0.3065 (C:0.3065, R:0.0105)
Batch  25/537: Loss=0.3001 (C:0.3001, R:0.0105)
Batch  50/537: Loss=0.3011 (C:0.3011, R:0.0105)
Batch  75/537: Loss=0.3008 (C:0.3008, R:0.0105)
Batch 100/537: Loss=0.2873 (C:0.2873, R:0.0105)
Batch 125/537: Loss=0.3162 (C:0.3162, R:0.0105)
Batch 150/537: Loss=0.2822 (C:0.2822, R:0.0105)
Batch 175/537: Loss=0.2947 (C:0.2947, R:0.0105)
Batch 200/537: Loss=0.2818 (C:0.2818, R:0.0105)
Batch 225/537: Loss=0.2905 (C:0.2905, R:0.0105)
Batch 250/537: Loss=0.2819 (C:0.2819, R:0.0105)
Batch 275/537: Loss=0.2831 (C:0.2831, R:0.0105)
Batch 300/537: Loss=0.2880 (C:0.2880, R:0.0106)
Batch 325/537: Loss=0.2930 (C:0.2930, R:0.0105)
Batch 350/537: Loss=0.2929 (C:0.2929, R:0.0105)
Batch 375/537: Loss=0.3007 (C:0.3007, R:0.0105)
Batch 400/537: Loss=0.3039 (C:0.3039, R:0.0105)
Batch 425/537: Loss=0.3068 (C:0.3068, R:0.0105)
Batch 450/537: Loss=0.2930 (C:0.2930, R:0.0105)
Batch 475/537: Loss=0.2910 (C:0.2910, R:0.0105)
Batch 500/537: Loss=0.2780 (C:0.2780, R:0.0105)
Batch 525/537: Loss=0.2829 (C:0.2829, R:0.0105)

============================================================
Epoch 65/300 completed in 21.0s
Train: Loss=0.2919 (C:0.2919, R:0.0105) Ratio=5.06x
Val:   Loss=0.3831 (C:0.3831, R:0.0104) Ratio=2.93x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

Epoch 66 Training
----------------------------------------
Batch   0/537: Loss=0.2886 (C:0.2886, R:0.0105)
Batch  25/537: Loss=0.2640 (C:0.2640, R:0.0105)
Batch  50/537: Loss=0.2952 (C:0.2952, R:0.0105)
Batch  75/537: Loss=0.2971 (C:0.2971, R:0.0105)
Batch 100/537: Loss=0.3146 (C:0.3146, R:0.0106)
Batch 125/537: Loss=0.2916 (C:0.2916, R:0.0105)
Batch 150/537: Loss=0.2977 (C:0.2977, R:0.0105)
Batch 175/537: Loss=0.2801 (C:0.2801, R:0.0105)
Batch 200/537: Loss=0.2895 (C:0.2895, R:0.0105)
Batch 225/537: Loss=0.2801 (C:0.2801, R:0.0105)
Batch 250/537: Loss=0.3076 (C:0.3076, R:0.0105)
Batch 275/537: Loss=0.2804 (C:0.2804, R:0.0105)
Batch 300/537: Loss=0.2821 (C:0.2821, R:0.0105)
Batch 325/537: Loss=0.2834 (C:0.2834, R:0.0105)
Batch 350/537: Loss=0.2779 (C:0.2779, R:0.0105)
Batch 375/537: Loss=0.2950 (C:0.2950, R:0.0105)
Batch 400/537: Loss=0.3035 (C:0.3035, R:0.0105)
Batch 425/537: Loss=0.2952 (C:0.2952, R:0.0105)
Batch 450/537: Loss=0.2874 (C:0.2874, R:0.0105)
Batch 475/537: Loss=0.2853 (C:0.2853, R:0.0106)
Batch 500/537: Loss=0.2961 (C:0.2961, R:0.0105)
Batch 525/537: Loss=0.3132 (C:0.3132, R:0.0105)

============================================================
Epoch 66/300 completed in 21.1s
Train: Loss=0.2916 (C:0.2916, R:0.0105) Ratio=5.02x
Val:   Loss=0.3750 (C:0.3750, R:0.0104) Ratio=2.98x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.3750)
============================================================

🌍 Updating global dataset at epoch 67
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.162 ± 0.288
    Neg distances: 1.266 ± 0.535
    Separation ratio: 7.84x
    Gap: -2.119
    ✅ Excellent global separation!

Epoch 67 Training
----------------------------------------
Batch   0/537: Loss=0.2981 (C:0.2981, R:0.0105)
Batch  25/537: Loss=0.2901 (C:0.2901, R:0.0106)
Batch  50/537: Loss=0.2778 (C:0.2778, R:0.0105)
Batch  75/537: Loss=0.2795 (C:0.2795, R:0.0105)
Batch 100/537: Loss=0.2935 (C:0.2935, R:0.0105)
Batch 125/537: Loss=0.2935 (C:0.2935, R:0.0105)
Batch 150/537: Loss=0.3030 (C:0.3030, R:0.0105)
Batch 175/537: Loss=0.3064 (C:0.3064, R:0.0105)
Batch 200/537: Loss=0.3021 (C:0.3021, R:0.0105)
Batch 225/537: Loss=0.2887 (C:0.2887, R:0.0105)
Batch 250/537: Loss=0.2781 (C:0.2781, R:0.0105)
Batch 275/537: Loss=0.3041 (C:0.3041, R:0.0105)
Batch 300/537: Loss=0.2957 (C:0.2957, R:0.0106)
Batch 325/537: Loss=0.2958 (C:0.2958, R:0.0105)
Batch 350/537: Loss=0.2853 (C:0.2853, R:0.0105)
Batch 375/537: Loss=0.3146 (C:0.3146, R:0.0105)
Batch 400/537: Loss=0.3200 (C:0.3200, R:0.0106)
Batch 425/537: Loss=0.3083 (C:0.3083, R:0.0105)
Batch 450/537: Loss=0.2961 (C:0.2961, R:0.0105)
Batch 475/537: Loss=0.2855 (C:0.2855, R:0.0105)
Batch 500/537: Loss=0.3150 (C:0.3150, R:0.0105)
Batch 525/537: Loss=0.2804 (C:0.2804, R:0.0105)

============================================================
Epoch 67/300 completed in 26.9s
Train: Loss=0.2952 (C:0.2952, R:0.0105) Ratio=5.08x
Val:   Loss=0.3770 (C:0.3770, R:0.0104) Ratio=3.01x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

Epoch 68 Training
----------------------------------------
Batch   0/537: Loss=0.2691 (C:0.2691, R:0.0105)
Batch  25/537: Loss=0.2786 (C:0.2786, R:0.0105)
Batch  50/537: Loss=0.2930 (C:0.2930, R:0.0105)
Batch  75/537: Loss=0.2818 (C:0.2818, R:0.0105)
Batch 100/537: Loss=0.3039 (C:0.3039, R:0.0105)
Batch 125/537: Loss=0.2862 (C:0.2862, R:0.0105)
Batch 150/537: Loss=0.3143 (C:0.3143, R:0.0105)
Batch 175/537: Loss=0.2951 (C:0.2951, R:0.0105)
Batch 200/537: Loss=0.2979 (C:0.2979, R:0.0105)
Batch 225/537: Loss=0.3022 (C:0.3022, R:0.0105)
Batch 250/537: Loss=0.2908 (C:0.2908, R:0.0105)
Batch 275/537: Loss=0.2898 (C:0.2898, R:0.0105)
Batch 300/537: Loss=0.3136 (C:0.3136, R:0.0105)
Batch 325/537: Loss=0.2914 (C:0.2914, R:0.0105)
Batch 350/537: Loss=0.2919 (C:0.2919, R:0.0105)
Batch 375/537: Loss=0.3047 (C:0.3047, R:0.0105)
Batch 400/537: Loss=0.2956 (C:0.2956, R:0.0105)
Batch 425/537: Loss=0.3010 (C:0.3010, R:0.0105)
Batch 450/537: Loss=0.2962 (C:0.2962, R:0.0105)
Batch 475/537: Loss=0.3053 (C:0.3053, R:0.0105)
Batch 500/537: Loss=0.2986 (C:0.2986, R:0.0105)
Batch 525/537: Loss=0.2936 (C:0.2936, R:0.0105)

============================================================
Epoch 68/300 completed in 21.4s
Train: Loss=0.2952 (C:0.2952, R:0.0105) Ratio=5.07x
Val:   Loss=0.3815 (C:0.3815, R:0.0104) Ratio=2.99x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

Epoch 69 Training
----------------------------------------
Batch   0/537: Loss=0.2779 (C:0.2779, R:0.0105)
Batch  25/537: Loss=0.2770 (C:0.2770, R:0.0105)
Batch  50/537: Loss=0.2960 (C:0.2960, R:0.0105)
Batch  75/537: Loss=0.2886 (C:0.2886, R:0.0105)
Batch 100/537: Loss=0.2965 (C:0.2965, R:0.0105)
Batch 125/537: Loss=0.2869 (C:0.2869, R:0.0105)
Batch 150/537: Loss=0.2899 (C:0.2899, R:0.0105)
Batch 175/537: Loss=0.2969 (C:0.2969, R:0.0105)
Batch 200/537: Loss=0.2979 (C:0.2979, R:0.0105)
Batch 225/537: Loss=0.3167 (C:0.3167, R:0.0105)
Batch 250/537: Loss=0.3053 (C:0.3053, R:0.0105)
Batch 275/537: Loss=0.2858 (C:0.2858, R:0.0105)
Batch 300/537: Loss=0.2817 (C:0.2817, R:0.0105)
Batch 325/537: Loss=0.2931 (C:0.2931, R:0.0105)
Batch 350/537: Loss=0.2925 (C:0.2925, R:0.0105)
Batch 375/537: Loss=0.2867 (C:0.2867, R:0.0105)
Batch 400/537: Loss=0.2982 (C:0.2982, R:0.0105)
Batch 425/537: Loss=0.3151 (C:0.3151, R:0.0106)
Batch 450/537: Loss=0.2953 (C:0.2953, R:0.0105)
Batch 475/537: Loss=0.3169 (C:0.3169, R:0.0106)
Batch 500/537: Loss=0.3032 (C:0.3032, R:0.0104)
Batch 525/537: Loss=0.2838 (C:0.2838, R:0.0105)

============================================================
Epoch 69/300 completed in 21.1s
Train: Loss=0.2942 (C:0.2942, R:0.0105) Ratio=5.09x
Val:   Loss=0.3827 (C:0.3827, R:0.0104) Ratio=2.97x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 70
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.159 ± 0.281
    Neg distances: 1.266 ± 0.532
    Separation ratio: 7.95x
    Gap: -2.177
    ✅ Excellent global separation!

Epoch 70 Training
----------------------------------------
Batch   0/537: Loss=0.3019 (C:0.3019, R:0.0105)
Batch  25/537: Loss=0.2742 (C:0.2742, R:0.0105)
Batch  50/537: Loss=0.2843 (C:0.2843, R:0.0105)
Batch  75/537: Loss=0.2899 (C:0.2899, R:0.0105)
Batch 100/537: Loss=0.2947 (C:0.2947, R:0.0105)
Batch 125/537: Loss=0.2942 (C:0.2942, R:0.0105)
Batch 150/537: Loss=0.2931 (C:0.2931, R:0.0105)
Batch 175/537: Loss=0.3078 (C:0.3078, R:0.0105)
Batch 200/537: Loss=0.3067 (C:0.3067, R:0.0105)
Batch 225/537: Loss=0.2799 (C:0.2799, R:0.0105)
Batch 250/537: Loss=0.2915 (C:0.2915, R:0.0105)
Batch 275/537: Loss=0.3116 (C:0.3116, R:0.0105)
Batch 300/537: Loss=0.2901 (C:0.2901, R:0.0105)
Batch 325/537: Loss=0.2844 (C:0.2844, R:0.0105)
Batch 350/537: Loss=0.2770 (C:0.2770, R:0.0105)
Batch 375/537: Loss=0.3010 (C:0.3010, R:0.0105)
Batch 400/537: Loss=0.2873 (C:0.2873, R:0.0105)
Batch 425/537: Loss=0.3183 (C:0.3183, R:0.0105)
Batch 450/537: Loss=0.2962 (C:0.2962, R:0.0105)
Batch 475/537: Loss=0.2796 (C:0.2796, R:0.0105)
Batch 500/537: Loss=0.2879 (C:0.2879, R:0.0105)
Batch 525/537: Loss=0.2835 (C:0.2835, R:0.0105)

============================================================
Epoch 70/300 completed in 27.3s
Train: Loss=0.2912 (C:0.2912, R:0.0105) Ratio=5.05x
Val:   Loss=0.3827 (C:0.3827, R:0.0104) Ratio=2.94x
Reconstruction weight: 0.300
No improvement for 4 epochs
============================================================

Epoch 71 Training
----------------------------------------
Batch   0/537: Loss=0.2729 (C:0.2729, R:0.0105)
Batch  25/537: Loss=0.2801 (C:0.2801, R:0.0105)
Batch  50/537: Loss=0.2967 (C:0.2967, R:0.0105)
Batch  75/537: Loss=0.2879 (C:0.2879, R:0.0105)
Batch 100/537: Loss=0.2748 (C:0.2748, R:0.0105)
Batch 125/537: Loss=0.2659 (C:0.2659, R:0.0105)
Batch 150/537: Loss=0.2862 (C:0.2862, R:0.0105)
Batch 175/537: Loss=0.2799 (C:0.2799, R:0.0105)
Batch 200/537: Loss=0.2868 (C:0.2868, R:0.0104)
Batch 225/537: Loss=0.2892 (C:0.2892, R:0.0105)
Batch 250/537: Loss=0.2662 (C:0.2662, R:0.0105)
Batch 275/537: Loss=0.2845 (C:0.2845, R:0.0105)
Batch 300/537: Loss=0.2850 (C:0.2850, R:0.0105)
Batch 325/537: Loss=0.3100 (C:0.3100, R:0.0105)
Batch 350/537: Loss=0.2860 (C:0.2860, R:0.0105)
Batch 375/537: Loss=0.2781 (C:0.2781, R:0.0105)
Batch 400/537: Loss=0.2994 (C:0.2994, R:0.0105)
Batch 425/537: Loss=0.2827 (C:0.2827, R:0.0105)
Batch 450/537: Loss=0.3108 (C:0.3108, R:0.0105)
Batch 475/537: Loss=0.3149 (C:0.3149, R:0.0105)
Batch 500/537: Loss=0.2927 (C:0.2927, R:0.0105)
Batch 525/537: Loss=0.2856 (C:0.2856, R:0.0105)

============================================================
Epoch 71/300 completed in 21.0s
Train: Loss=0.2897 (C:0.2897, R:0.0105) Ratio=5.20x
Val:   Loss=0.3802 (C:0.3802, R:0.0104) Ratio=2.96x
Reconstruction weight: 0.300
No improvement for 5 epochs
============================================================

Epoch 72 Training
----------------------------------------
Batch   0/537: Loss=0.2996 (C:0.2996, R:0.0105)
Batch  25/537: Loss=0.3066 (C:0.3066, R:0.0105)
Batch  50/537: Loss=0.2798 (C:0.2798, R:0.0105)
Batch  75/537: Loss=0.3076 (C:0.3076, R:0.0105)
Batch 100/537: Loss=0.2969 (C:0.2969, R:0.0105)
Batch 125/537: Loss=0.3016 (C:0.3016, R:0.0105)
Batch 150/537: Loss=0.2737 (C:0.2737, R:0.0106)
Batch 175/537: Loss=0.2957 (C:0.2957, R:0.0105)
Batch 200/537: Loss=0.2935 (C:0.2935, R:0.0105)
Batch 225/537: Loss=0.2985 (C:0.2985, R:0.0105)
Batch 250/537: Loss=0.2914 (C:0.2914, R:0.0105)
Batch 275/537: Loss=0.2933 (C:0.2933, R:0.0105)
Batch 300/537: Loss=0.2874 (C:0.2874, R:0.0105)
Batch 325/537: Loss=0.2942 (C:0.2942, R:0.0105)
Batch 350/537: Loss=0.2978 (C:0.2978, R:0.0105)
Batch 375/537: Loss=0.3008 (C:0.3008, R:0.0105)
Batch 400/537: Loss=0.2816 (C:0.2816, R:0.0105)
Batch 425/537: Loss=0.2897 (C:0.2897, R:0.0105)
Batch 450/537: Loss=0.2956 (C:0.2956, R:0.0105)
Batch 475/537: Loss=0.3026 (C:0.3026, R:0.0105)
Batch 500/537: Loss=0.2815 (C:0.2815, R:0.0105)
Batch 525/537: Loss=0.2974 (C:0.2974, R:0.0105)

============================================================
Epoch 72/300 completed in 21.2s
Train: Loss=0.2902 (C:0.2902, R:0.0105) Ratio=5.12x
Val:   Loss=0.3815 (C:0.3815, R:0.0104) Ratio=2.98x
Reconstruction weight: 0.300
No improvement for 6 epochs
============================================================

🌍 Updating global dataset at epoch 73
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.159 ± 0.290
    Neg distances: 1.283 ± 0.540
    Separation ratio: 8.05x
    Gap: -2.164
    ✅ Excellent global separation!

Epoch 73 Training
----------------------------------------
Batch   0/537: Loss=0.2917 (C:0.2917, R:0.0105)
Batch  25/537: Loss=0.2898 (C:0.2898, R:0.0105)
Batch  50/537: Loss=0.2867 (C:0.2867, R:0.0105)
Batch  75/537: Loss=0.2864 (C:0.2864, R:0.0105)
Batch 100/537: Loss=0.2994 (C:0.2994, R:0.0105)
Batch 125/537: Loss=0.2712 (C:0.2712, R:0.0105)
Batch 150/537: Loss=0.2815 (C:0.2815, R:0.0105)
Batch 175/537: Loss=0.2934 (C:0.2934, R:0.0105)
Batch 200/537: Loss=0.3049 (C:0.3049, R:0.0104)
Batch 225/537: Loss=0.2683 (C:0.2683, R:0.0105)
Batch 250/537: Loss=0.2818 (C:0.2818, R:0.0105)
Batch 275/537: Loss=0.2858 (C:0.2858, R:0.0105)
Batch 300/537: Loss=0.2720 (C:0.2720, R:0.0105)
Batch 325/537: Loss=0.2856 (C:0.2856, R:0.0105)
Batch 350/537: Loss=0.2873 (C:0.2873, R:0.0105)
Batch 375/537: Loss=0.2862 (C:0.2862, R:0.0105)
Batch 400/537: Loss=0.2855 (C:0.2855, R:0.0105)
Batch 425/537: Loss=0.2967 (C:0.2967, R:0.0105)
Batch 450/537: Loss=0.3119 (C:0.3119, R:0.0105)
Batch 475/537: Loss=0.2793 (C:0.2793, R:0.0105)
Batch 500/537: Loss=0.2826 (C:0.2826, R:0.0105)
Batch 525/537: Loss=0.2968 (C:0.2968, R:0.0105)

============================================================
Epoch 73/300 completed in 27.5s
Train: Loss=0.2874 (C:0.2874, R:0.0105) Ratio=5.13x
Val:   Loss=0.3800 (C:0.3800, R:0.0104) Ratio=2.96x
Reconstruction weight: 0.300
No improvement for 7 epochs
============================================================

Epoch 74 Training
----------------------------------------
Batch   0/537: Loss=0.2816 (C:0.2816, R:0.0105)
Batch  25/537: Loss=0.2886 (C:0.2886, R:0.0105)
Batch  50/537: Loss=0.2843 (C:0.2843, R:0.0105)
Batch  75/537: Loss=0.2800 (C:0.2800, R:0.0105)
Batch 100/537: Loss=0.2916 (C:0.2916, R:0.0105)
Batch 125/537: Loss=0.3181 (C:0.3181, R:0.0105)
Batch 150/537: Loss=0.2886 (C:0.2886, R:0.0106)
Batch 175/537: Loss=0.2777 (C:0.2777, R:0.0105)
Batch 200/537: Loss=0.2689 (C:0.2689, R:0.0105)
Batch 225/537: Loss=0.2897 (C:0.2897, R:0.0105)
Batch 250/537: Loss=0.2772 (C:0.2772, R:0.0105)
Batch 275/537: Loss=0.2999 (C:0.2999, R:0.0105)
Batch 300/537: Loss=0.2975 (C:0.2975, R:0.0105)
Batch 325/537: Loss=0.2789 (C:0.2789, R:0.0105)
Batch 350/537: Loss=0.2885 (C:0.2885, R:0.0105)
Batch 375/537: Loss=0.2902 (C:0.2902, R:0.0105)
Batch 400/537: Loss=0.2743 (C:0.2743, R:0.0105)
Batch 425/537: Loss=0.2941 (C:0.2941, R:0.0105)
Batch 450/537: Loss=0.2817 (C:0.2817, R:0.0105)
Batch 475/537: Loss=0.2971 (C:0.2971, R:0.0105)
Batch 500/537: Loss=0.3079 (C:0.3079, R:0.0106)
Batch 525/537: Loss=0.2729 (C:0.2729, R:0.0105)

============================================================
Epoch 74/300 completed in 21.6s
Train: Loss=0.2873 (C:0.2873, R:0.0105) Ratio=5.17x
Val:   Loss=0.3805 (C:0.3805, R:0.0104) Ratio=2.98x
Reconstruction weight: 0.300
No improvement for 8 epochs

Early stopping triggered after 74 epochs
Best model was at epoch 66 with Val Loss: 0.3750

Global Dataset Training Completed!
Best epoch: 66
Best validation loss: 0.3750
Final separation ratios: Train=5.17x, Val=2.98x
Training completed!
Loading best model from entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin1.0_updatefreq3_max_global_samples10000_20250715_122412/checkpoints/best_model.pt
Starting model evaluation...
========================================
GlobalContrastiveEvaluator initialized on cuda
Starting comprehensive evaluation...
============================================================
Extracting latent representations...
  Processed 1/10 batches
Extracted representations: torch.Size([9824, 75])
Evaluating clustering performance...
Clustering Results:
  Silhouette Score: 0.4533
  Adjusted Rand Score: 0.5301
  Clustering Accuracy: 0.8120
Evaluating classification performance...
  Extracting training representations...
Extracting latent representations...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
Extracted representations: torch.Size([547740, 75])
  Extracting validation representations...
Extracting latent representations...
  Processed 1/9 batches
Extracted representations: torch.Size([9180, 75])
Subsampled training to 50000 samples
  Training on 50000 samples, evaluating on 9180 samples
Classification Results:
  Accuracy: 0.8040
  Per-class F1: [0.8216528084167657, 0.7373608903020668, 0.8551076574388863]
Evaluating reconstruction quality...
Reconstruction Results:
  Average MSE: 0.010432
Evaluating separation quality...
Separation Results:
  Positive distances: 0.369 ± 0.442
  Negative distances: 1.129 ± 0.600
  Separation ratio: 3.06x
  Gap: -2.169
  Perfect separation: No

Comprehensive evaluation completed!

============================================================
EVALUATION SUMMARY
============================================================
Clustering Performance:
  Silhouette Score: 0.4533
  Clustering Accuracy: 0.8120
  Adjusted Rand Score: 0.5301

Classification Performance:
  Accuracy: 0.8040

Separation Quality:
  Separation Ratio: 3.06x
  Gap: -2.169
  Perfect Separation: False

Reconstruction Quality:
  Average MSE: 0.010432
============================================================
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin1.0_updatefreq3_max_global_samples10000_20250715_122412/results/evaluation_results_20250715_125326.json
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin1.0_updatefreq3_max_global_samples10000_20250715_122412/results/evaluation_results_20250715_125326.json
Saving final experiment results...
Final results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin1.0_updatefreq3_max_global_samples10000_20250715_122412/final_results.json

============================================================
PIPELINE COMPLETED SUCCESSFULLY!
============================================================
Experiment directory: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin1.0_updatefreq3_max_global_samples10000_20250715_122412
Best model: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin1.0_updatefreq3_max_global_samples10000_20250715_122412/checkpoints/best_model.pt
Final results: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin1.0_updatefreq3_max_global_samples10000_20250715_122412/final_results.json

Key Results:
  Separation ratio: 3.06x
  Perfect separation: False
  Classification accuracy: 0.8040
  Result: 0.8040% (improvement: +-80.87%)
  Cleaning up: coarse_margin1.0_updatefreq3_max_global_samples10000_20250715_122412

[5/12] Testing: coarse_margin2.0_updatefreq1_max_global_samples5000
  margin: 2.0
  update_frequency: 1
  max_global_samples: 5000
  Reconstruction weight: 0.3 (fixed)
GLOBAL DATASET CONTRASTIVE AUTOENCODER PIPELINE
============================================================
Start time: 2025-07-15 12:53:26.390476
Using device: cuda

Configuration:
  Embedding type: concat
  Batch size: 1020
  Global update frequency: 1 epochs
  Training epochs: 300
Experiment setup completed:
  Experiment directory: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin2.0_updatefreq1_max_global_samples5000_20250715_125326
  Config saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin2.0_updatefreq1_max_global_samples5000_20250715_125326/config.json
Loading data...
========================================
FlexibleEmbedder initialized with type: 'concat'
Output dimension will be: 1536
GlobalDataLoader initialized:
  Embedding type: concat
  Output dimension: 1536
  Sample size: All
Starting data loading pipeline...
============================================================
Loading training data from data/processed/snli_full_standard_SBERT.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 549367 training samples
Loading validation data from data/processed/snli_full_standard_SBERT_validation.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9842 validation samples
Loading test data from data/processed/snli_full_standard_SBERT_test.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9824 test samples
Generating embeddings for training...
Generating concat embeddings on cuda
Processing 549367 samples in batches of 1000
  Processing batch 1/550
  Processing batch 6/550
  Processing batch 11/550
  Processing batch 16/550
  Processing batch 21/550
  Processing batch 26/550
  Processing batch 31/550
  Processing batch 36/550
  Processing batch 41/550
  Processing batch 46/550
  Processing batch 51/550
  Processing batch 56/550
  Processing batch 61/550
  Processing batch 66/550
  Processing batch 71/550
  Processing batch 76/550
  Processing batch 81/550
  Processing batch 86/550
  Processing batch 91/550
  Processing batch 96/550
  Processing batch 101/550
  Processing batch 106/550
  Processing batch 111/550
  Processing batch 116/550
  Processing batch 121/550
  Processing batch 126/550
  Processing batch 131/550
  Processing batch 136/550
  Processing batch 141/550
  Processing batch 146/550
  Processing batch 151/550
  Processing batch 156/550
  Processing batch 161/550
  Processing batch 166/550
  Processing batch 171/550
  Processing batch 176/550
  Processing batch 181/550
  Processing batch 186/550
  Processing batch 191/550
  Processing batch 196/550
  Processing batch 201/550
  Processing batch 206/550
  Processing batch 211/550
  Processing batch 216/550
  Processing batch 221/550
  Processing batch 226/550
  Processing batch 231/550
  Processing batch 236/550
  Processing batch 241/550
  Processing batch 246/550
  Processing batch 251/550
  Processing batch 256/550
  Processing batch 261/550
  Processing batch 266/550
  Processing batch 271/550
  Processing batch 276/550
  Processing batch 281/550
  Processing batch 286/550
  Processing batch 291/550
  Processing batch 296/550
  Processing batch 301/550
  Processing batch 306/550
  Processing batch 311/550
  Processing batch 316/550
  Processing batch 321/550
  Processing batch 326/550
  Processing batch 331/550
  Processing batch 336/550
  Processing batch 341/550
  Processing batch 346/550
  Processing batch 351/550
  Processing batch 356/550
  Processing batch 361/550
  Processing batch 366/550
  Processing batch 371/550
  Processing batch 376/550
  Processing batch 381/550
  Processing batch 386/550
  Processing batch 391/550
  Processing batch 396/550
  Processing batch 401/550
  Processing batch 406/550
  Processing batch 411/550
  Processing batch 416/550
  Processing batch 421/550
  Processing batch 426/550
  Processing batch 431/550
  Processing batch 436/550
  Processing batch 441/550
  Processing batch 446/550
  Processing batch 451/550
  Processing batch 456/550
  Processing batch 461/550
  Processing batch 466/550
  Processing batch 471/550
  Processing batch 476/550
  Processing batch 481/550
  Processing batch 486/550
  Processing batch 491/550
  Processing batch 496/550
  Processing batch 501/550
  Processing batch 506/550
  Processing batch 511/550
  Processing batch 516/550
  Processing batch 521/550
  Processing batch 526/550
  Processing batch 531/550
  Processing batch 536/550
  Processing batch 541/550
  Processing batch 546/550
Generated concat embeddings: torch.Size([549367, 1536])
Generating embeddings for validation...
Generating concat embeddings on cuda
Processing 9842 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9842, 1536])
Generating embeddings for test...
Generating concat embeddings on cuda
Processing 9824 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9824, 1536])
EntailmentDataset created: 549367 samples
  Embedding shape: torch.Size([549367, 1536])
  Class distribution: {'entailment': 183416, 'neutral': 182764, 'contradiction': 183187}
EntailmentDataset created: 9842 samples
  Embedding shape: torch.Size([9842, 1536])
  Class distribution: {'entailment': 3329, 'neutral': 3235, 'contradiction': 3278}
EntailmentDataset created: 9824 samples
  Embedding shape: torch.Size([9824, 1536])
  Class distribution: {'entailment': 3368, 'neutral': 3219, 'contradiction': 3237}

Data loading pipeline completed!
Output embedding dimension: 1536
Updated model input_dim to: 1536
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 537
  Class 2: 183187 samples
  Class 0: 183416 samples
  Class 1: 182764 samples
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 9
  Class 2: 3278 samples
  Class 0: 3329 samples
  Class 1: 3235 samples
DataLoaders created:
  Batch size: 1020
  Balanced sampling: True
  Train batches: 537
  Val batches: 9
  Test batches: 10
Data loading completed!
  Train: 549367 samples, 537 batches
  Val: 9842 samples, 9 batches
  Test: 9824 samples, 10 batches
Creating model and trainer...
========================================
ContrastiveAutoencoder initialized:
  Input dim: 1536
  Latent dim: 75
  Hidden dims: [512, 256]
  Dropout rate: 0.2
  Total parameters: 1,876,555
Model created with 1,876,555 parameters
FullDatasetContrastiveLoss initialized:
  Margin: 2.0
  Update frequency: 1 epochs
  Max global samples: 5000
FullDatasetCombinedLoss initialized:
  Contrastive weight: 1.0
  Base reconstruction weight: 0.0
  Scheduled reconstruction: warmup=30 epochs, max_weight=0.3
Optimizer created (lr=0.0001)
GlobalDatasetTrainer initialized on device: cuda
Model parameters: 1,876,555
Starting training...
========================================
Starting Global Dataset Training...
============================================================

🌍 Updating global dataset at epoch 1
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.089 ± 0.010
    Neg distances: 0.090 ± 0.010
    Separation ratio: 1.00x
    Gap: -0.124
    ❌ Poor global separation

Epoch 1 Training
----------------------------------------
Batch   0/537: Loss=1.9998 (C:1.9998, R:0.0118)
Batch  25/537: Loss=1.9956 (C:1.9956, R:0.0115)
Batch  50/537: Loss=1.9793 (C:1.9793, R:0.0113)
Batch  75/537: Loss=1.9751 (C:1.9751, R:0.0112)
Batch 100/537: Loss=1.9721 (C:1.9721, R:0.0110)
Batch 125/537: Loss=1.9637 (C:1.9637, R:0.0110)
Batch 150/537: Loss=1.9482 (C:1.9482, R:0.0108)
Batch 175/537: Loss=1.9503 (C:1.9503, R:0.0108)
Batch 200/537: Loss=1.9412 (C:1.9412, R:0.0107)
Batch 225/537: Loss=1.9281 (C:1.9281, R:0.0107)
Batch 250/537: Loss=1.9257 (C:1.9257, R:0.0106)
Batch 275/537: Loss=1.9157 (C:1.9157, R:0.0107)
Batch 300/537: Loss=1.9064 (C:1.9064, R:0.0106)
Batch 325/537: Loss=1.9202 (C:1.9202, R:0.0106)
Batch 350/537: Loss=1.9125 (C:1.9125, R:0.0106)
Batch 375/537: Loss=1.9085 (C:1.9085, R:0.0106)
Batch 400/537: Loss=1.9052 (C:1.9052, R:0.0105)
Batch 425/537: Loss=1.9103 (C:1.9103, R:0.0105)
Batch 450/537: Loss=1.9105 (C:1.9105, R:0.0105)
Batch 475/537: Loss=1.9154 (C:1.9154, R:0.0105)
Batch 500/537: Loss=1.8964 (C:1.8964, R:0.0105)
Batch 525/537: Loss=1.9090 (C:1.9090, R:0.0106)

============================================================
Epoch 1/300 completed in 27.5s
Train: Loss=1.9342 (C:1.9342, R:0.0108) Ratio=1.61x
Val:   Loss=1.8903 (C:1.8903, R:0.0105) Ratio=2.13x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.8903)
============================================================

🌍 Updating global dataset at epoch 2
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.622 ± 0.537
    Neg distances: 1.385 ± 0.799
    Separation ratio: 2.23x
    Gap: -3.256
    ✅ Good global separation

Epoch 2 Training
----------------------------------------
Batch   0/537: Loss=1.3658 (C:1.3658, R:0.0105)
Batch  25/537: Loss=1.3332 (C:1.3332, R:0.0105)
Batch  50/537: Loss=1.3609 (C:1.3609, R:0.0105)
Batch  75/537: Loss=1.3453 (C:1.3453, R:0.0105)
Batch 100/537: Loss=1.3720 (C:1.3720, R:0.0105)
Batch 125/537: Loss=1.3409 (C:1.3409, R:0.0105)
Batch 150/537: Loss=1.3555 (C:1.3555, R:0.0105)
Batch 175/537: Loss=1.3567 (C:1.3567, R:0.0105)
Batch 200/537: Loss=1.3443 (C:1.3443, R:0.0105)
Batch 225/537: Loss=1.3483 (C:1.3483, R:0.0105)
Batch 250/537: Loss=1.3431 (C:1.3431, R:0.0105)
Batch 275/537: Loss=1.3489 (C:1.3489, R:0.0105)
Batch 300/537: Loss=1.3328 (C:1.3328, R:0.0105)
Batch 325/537: Loss=1.3314 (C:1.3314, R:0.0105)
Batch 350/537: Loss=1.3515 (C:1.3515, R:0.0105)
Batch 375/537: Loss=1.3230 (C:1.3230, R:0.0105)
Batch 400/537: Loss=1.3426 (C:1.3426, R:0.0106)
Batch 425/537: Loss=1.3236 (C:1.3236, R:0.0105)
Batch 450/537: Loss=1.2930 (C:1.2930, R:0.0105)
Batch 475/537: Loss=1.3311 (C:1.3311, R:0.0105)
Batch 500/537: Loss=1.3301 (C:1.3301, R:0.0105)
Batch 525/537: Loss=1.3214 (C:1.3214, R:0.0105)

============================================================
Epoch 2/300 completed in 27.3s
Train: Loss=1.3473 (C:1.3473, R:0.0105) Ratio=2.20x
Val:   Loss=1.3166 (C:1.3166, R:0.0104) Ratio=2.43x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.3166)
============================================================

🌍 Updating global dataset at epoch 3
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.579 ± 0.570
    Neg distances: 1.473 ± 0.829
    Separation ratio: 2.55x
    Gap: -3.182
    ✅ Good global separation

Epoch 3 Training
----------------------------------------
Batch   0/537: Loss=1.2445 (C:1.2445, R:0.0105)
Batch  25/537: Loss=1.2138 (C:1.2138, R:0.0105)
Batch  50/537: Loss=1.2117 (C:1.2117, R:0.0105)
Batch  75/537: Loss=1.2624 (C:1.2624, R:0.0105)
Batch 100/537: Loss=1.2268 (C:1.2268, R:0.0105)
Batch 125/537: Loss=1.2234 (C:1.2234, R:0.0105)
Batch 150/537: Loss=1.2737 (C:1.2737, R:0.0105)
Batch 175/537: Loss=1.2546 (C:1.2546, R:0.0105)
Batch 200/537: Loss=1.2675 (C:1.2675, R:0.0105)
Batch 225/537: Loss=1.2668 (C:1.2668, R:0.0105)
Batch 250/537: Loss=1.2615 (C:1.2615, R:0.0105)
Batch 275/537: Loss=1.2735 (C:1.2735, R:0.0105)
Batch 300/537: Loss=1.2531 (C:1.2531, R:0.0105)
Batch 325/537: Loss=1.2463 (C:1.2463, R:0.0105)
Batch 350/537: Loss=1.2397 (C:1.2397, R:0.0105)
Batch 375/537: Loss=1.2578 (C:1.2578, R:0.0105)
Batch 400/537: Loss=1.2714 (C:1.2714, R:0.0105)
Batch 425/537: Loss=1.2500 (C:1.2500, R:0.0105)
Batch 450/537: Loss=1.2748 (C:1.2748, R:0.0105)
Batch 475/537: Loss=1.2593 (C:1.2593, R:0.0105)
Batch 500/537: Loss=1.2423 (C:1.2423, R:0.0106)
Batch 525/537: Loss=1.2208 (C:1.2208, R:0.0105)

============================================================
Epoch 3/300 completed in 26.7s
Train: Loss=1.2560 (C:1.2560, R:0.0105) Ratio=2.45x
Val:   Loss=1.2383 (C:1.2383, R:0.0104) Ratio=2.58x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.2383)
============================================================

🌍 Updating global dataset at epoch 4
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.571 ± 0.584
    Neg distances: 1.538 ± 0.857
    Separation ratio: 2.69x
    Gap: -3.318
    ✅ Good global separation

Epoch 4 Training
----------------------------------------
Batch   0/537: Loss=1.2542 (C:1.2542, R:0.0105)
Batch  25/537: Loss=1.1923 (C:1.1923, R:0.0105)
Batch  50/537: Loss=1.2234 (C:1.2234, R:0.0105)
Batch  75/537: Loss=1.2254 (C:1.2254, R:0.0105)
Batch 100/537: Loss=1.2474 (C:1.2474, R:0.0105)
Batch 125/537: Loss=1.2197 (C:1.2197, R:0.0105)
Batch 150/537: Loss=1.2340 (C:1.2340, R:0.0105)
Batch 175/537: Loss=1.2049 (C:1.2049, R:0.0105)
Batch 200/537: Loss=1.2144 (C:1.2144, R:0.0106)
Batch 225/537: Loss=1.2311 (C:1.2311, R:0.0105)
Batch 250/537: Loss=1.2031 (C:1.2031, R:0.0105)
Batch 275/537: Loss=1.2351 (C:1.2351, R:0.0105)
Batch 300/537: Loss=1.1885 (C:1.1885, R:0.0105)
Batch 325/537: Loss=1.1931 (C:1.1931, R:0.0105)
Batch 350/537: Loss=1.2228 (C:1.2228, R:0.0105)
Batch 375/537: Loss=1.1956 (C:1.1956, R:0.0105)
Batch 400/537: Loss=1.2186 (C:1.2186, R:0.0105)
Batch 425/537: Loss=1.2246 (C:1.2246, R:0.0105)
Batch 450/537: Loss=1.2230 (C:1.2230, R:0.0105)
Batch 475/537: Loss=1.1931 (C:1.1931, R:0.0105)
Batch 500/537: Loss=1.2028 (C:1.2028, R:0.0105)
Batch 525/537: Loss=1.2597 (C:1.2597, R:0.0105)

============================================================
Epoch 4/300 completed in 27.3s
Train: Loss=1.2130 (C:1.2130, R:0.0105) Ratio=2.59x
Val:   Loss=1.2126 (C:1.2126, R:0.0104) Ratio=2.69x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.2126)
============================================================

🌍 Updating global dataset at epoch 5
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.559 ± 0.589
    Neg distances: 1.589 ± 0.864
    Separation ratio: 2.84x
    Gap: -3.366
    ✅ Good global separation

Epoch 5 Training
----------------------------------------
Batch   0/537: Loss=1.1750 (C:1.1750, R:0.0105)
Batch  25/537: Loss=1.1621 (C:1.1621, R:0.0105)
Batch  50/537: Loss=1.1503 (C:1.1503, R:0.0105)
Batch  75/537: Loss=1.1952 (C:1.1952, R:0.0105)
Batch 100/537: Loss=1.1582 (C:1.1582, R:0.0105)
Batch 125/537: Loss=1.1539 (C:1.1539, R:0.0105)
Batch 150/537: Loss=1.1470 (C:1.1470, R:0.0105)
Batch 175/537: Loss=1.1460 (C:1.1460, R:0.0105)
Batch 200/537: Loss=1.1845 (C:1.1845, R:0.0105)
Batch 225/537: Loss=1.1677 (C:1.1677, R:0.0105)
Batch 250/537: Loss=1.1491 (C:1.1491, R:0.0105)
Batch 275/537: Loss=1.1685 (C:1.1685, R:0.0105)
Batch 300/537: Loss=1.1755 (C:1.1755, R:0.0105)
Batch 325/537: Loss=1.2057 (C:1.2057, R:0.0105)
Batch 350/537: Loss=1.1728 (C:1.1728, R:0.0105)
Batch 375/537: Loss=1.1502 (C:1.1502, R:0.0105)
Batch 400/537: Loss=1.1780 (C:1.1780, R:0.0105)
Batch 425/537: Loss=1.1438 (C:1.1438, R:0.0105)
Batch 450/537: Loss=1.1731 (C:1.1731, R:0.0105)
Batch 475/537: Loss=1.1662 (C:1.1662, R:0.0105)
Batch 500/537: Loss=1.1459 (C:1.1459, R:0.0105)
Batch 525/537: Loss=1.1662 (C:1.1662, R:0.0105)

============================================================
Epoch 5/300 completed in 28.0s
Train: Loss=1.1753 (C:1.1753, R:0.0105) Ratio=2.78x
Val:   Loss=1.1692 (C:1.1692, R:0.0104) Ratio=2.76x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.1692)
============================================================

🌍 Updating global dataset at epoch 6
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.492 ± 0.538
    Neg distances: 1.649 ± 0.854
    Separation ratio: 3.35x
    Gap: -3.224
    ✅ Excellent global separation!

Epoch 6 Training
----------------------------------------
Batch   0/537: Loss=1.1137 (C:1.1137, R:0.0105)
Batch  25/537: Loss=1.1190 (C:1.1190, R:0.0105)
Batch  50/537: Loss=1.0978 (C:1.0978, R:0.0105)
Batch  75/537: Loss=1.1052 (C:1.1052, R:0.0105)
Batch 100/537: Loss=1.0846 (C:1.0846, R:0.0105)
Batch 125/537: Loss=1.0877 (C:1.0877, R:0.0105)
Batch 150/537: Loss=1.1040 (C:1.1040, R:0.0105)
Batch 175/537: Loss=1.1298 (C:1.1298, R:0.0105)
Batch 200/537: Loss=1.0783 (C:1.0783, R:0.0105)
Batch 225/537: Loss=1.0796 (C:1.0796, R:0.0105)
Batch 250/537: Loss=1.1117 (C:1.1117, R:0.0105)
Batch 275/537: Loss=1.0547 (C:1.0547, R:0.0105)
Batch 300/537: Loss=1.0612 (C:1.0612, R:0.0105)
Batch 325/537: Loss=1.1185 (C:1.1185, R:0.0105)
Batch 350/537: Loss=1.1066 (C:1.1066, R:0.0105)
Batch 375/537: Loss=1.1093 (C:1.1093, R:0.0105)
Batch 400/537: Loss=1.1059 (C:1.1059, R:0.0105)
Batch 425/537: Loss=1.1190 (C:1.1190, R:0.0105)
Batch 450/537: Loss=1.1069 (C:1.1069, R:0.0105)
Batch 475/537: Loss=1.1105 (C:1.1105, R:0.0105)
Batch 500/537: Loss=1.0907 (C:1.0907, R:0.0105)
Batch 525/537: Loss=1.1189 (C:1.1189, R:0.0105)

============================================================
Epoch 6/300 completed in 27.3s
Train: Loss=1.0991 (C:1.0991, R:0.0105) Ratio=2.82x
Val:   Loss=1.1073 (C:1.1073, R:0.0104) Ratio=2.80x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.1073)
============================================================

🌍 Updating global dataset at epoch 7
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.509 ± 0.591
    Neg distances: 1.700 ± 0.877
    Separation ratio: 3.34x
    Gap: -3.196
    ✅ Excellent global separation!

Epoch 7 Training
----------------------------------------
Batch   0/537: Loss=1.1046 (C:1.1046, R:0.0105)
Batch  25/537: Loss=1.0821 (C:1.0821, R:0.0105)
Batch  50/537: Loss=1.0829 (C:1.0829, R:0.0105)
Batch  75/537: Loss=1.0716 (C:1.0716, R:0.0105)
Batch 100/537: Loss=1.0800 (C:1.0800, R:0.0105)
Batch 125/537: Loss=1.0977 (C:1.0977, R:0.0105)
Batch 150/537: Loss=1.0966 (C:1.0966, R:0.0105)
Batch 175/537: Loss=1.1190 (C:1.1190, R:0.0105)
Batch 200/537: Loss=1.0785 (C:1.0785, R:0.0105)
Batch 225/537: Loss=1.0618 (C:1.0618, R:0.0105)
Batch 250/537: Loss=1.0552 (C:1.0552, R:0.0105)
Batch 275/537: Loss=1.0726 (C:1.0726, R:0.0105)
Batch 300/537: Loss=1.0900 (C:1.0900, R:0.0105)
Batch 325/537: Loss=1.0843 (C:1.0843, R:0.0105)
Batch 350/537: Loss=1.0722 (C:1.0722, R:0.0105)
Batch 375/537: Loss=1.1140 (C:1.1140, R:0.0106)
Batch 400/537: Loss=1.0988 (C:1.0988, R:0.0105)
Batch 425/537: Loss=1.0614 (C:1.0614, R:0.0105)
Batch 450/537: Loss=1.0947 (C:1.0947, R:0.0105)
Batch 475/537: Loss=1.0912 (C:1.0912, R:0.0106)
Batch 500/537: Loss=1.0869 (C:1.0869, R:0.0105)
Batch 525/537: Loss=1.0920 (C:1.0920, R:0.0105)

============================================================
Epoch 7/300 completed in 27.4s
Train: Loss=1.0876 (C:1.0876, R:0.0105) Ratio=2.99x
Val:   Loss=1.0997 (C:1.0997, R:0.0104) Ratio=2.86x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.0997)
============================================================

🌍 Updating global dataset at epoch 8
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.508 ± 0.584
    Neg distances: 1.743 ± 0.896
    Separation ratio: 3.43x
    Gap: -3.314
    ✅ Excellent global separation!

Epoch 8 Training
----------------------------------------
Batch   0/537: Loss=1.0588 (C:1.0588, R:0.0105)
Batch  25/537: Loss=1.0654 (C:1.0654, R:0.0105)
Batch  50/537: Loss=1.0709 (C:1.0709, R:0.0105)
Batch  75/537: Loss=1.0435 (C:1.0435, R:0.0105)
Batch 100/537: Loss=1.0762 (C:1.0762, R:0.0105)
Batch 125/537: Loss=1.0505 (C:1.0505, R:0.0105)
Batch 150/537: Loss=1.0856 (C:1.0856, R:0.0104)
Batch 175/537: Loss=1.0607 (C:1.0607, R:0.0105)
Batch 200/537: Loss=1.0876 (C:1.0876, R:0.0105)
Batch 225/537: Loss=1.0703 (C:1.0703, R:0.0105)
Batch 250/537: Loss=1.0834 (C:1.0834, R:0.0105)
Batch 275/537: Loss=1.0671 (C:1.0671, R:0.0105)
Batch 300/537: Loss=1.0782 (C:1.0782, R:0.0105)
Batch 325/537: Loss=1.0643 (C:1.0643, R:0.0105)
Batch 350/537: Loss=1.0925 (C:1.0925, R:0.0105)
Batch 375/537: Loss=1.0789 (C:1.0789, R:0.0105)
Batch 400/537: Loss=1.0983 (C:1.0983, R:0.0105)
Batch 425/537: Loss=1.0542 (C:1.0542, R:0.0105)
Batch 450/537: Loss=1.0679 (C:1.0679, R:0.0105)
Batch 475/537: Loss=1.0721 (C:1.0721, R:0.0105)
Batch 500/537: Loss=1.0999 (C:1.0999, R:0.0105)
Batch 525/537: Loss=1.0514 (C:1.0514, R:0.0105)

============================================================
Epoch 8/300 completed in 27.7s
Train: Loss=1.0664 (C:1.0664, R:0.0105) Ratio=3.00x
Val:   Loss=1.0695 (C:1.0695, R:0.0104) Ratio=2.91x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.0695)
============================================================

🌍 Updating global dataset at epoch 9
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.489 ± 0.566
    Neg distances: 1.801 ± 0.902
    Separation ratio: 3.69x
    Gap: -3.371
    ✅ Excellent global separation!

Epoch 9 Training
----------------------------------------
Batch   0/537: Loss=1.0333 (C:1.0333, R:0.0105)
Batch  25/537: Loss=1.0040 (C:1.0040, R:0.0105)
Batch  50/537: Loss=1.0413 (C:1.0413, R:0.0105)
Batch  75/537: Loss=1.0427 (C:1.0427, R:0.0105)
Batch 100/537: Loss=1.0121 (C:1.0121, R:0.0105)
Batch 125/537: Loss=1.0264 (C:1.0264, R:0.0105)
Batch 150/537: Loss=1.0128 (C:1.0128, R:0.0105)
Batch 175/537: Loss=1.0065 (C:1.0065, R:0.0105)
Batch 200/537: Loss=1.0359 (C:1.0359, R:0.0105)
Batch 225/537: Loss=1.0125 (C:1.0125, R:0.0105)
Batch 250/537: Loss=1.0256 (C:1.0256, R:0.0105)
Batch 275/537: Loss=0.9829 (C:0.9829, R:0.0105)
Batch 300/537: Loss=1.0026 (C:1.0026, R:0.0105)
Batch 325/537: Loss=1.0452 (C:1.0452, R:0.0105)
Batch 350/537: Loss=1.0255 (C:1.0255, R:0.0105)
Batch 375/537: Loss=1.0116 (C:1.0116, R:0.0106)
Batch 400/537: Loss=1.0220 (C:1.0220, R:0.0105)
Batch 425/537: Loss=1.0688 (C:1.0688, R:0.0105)
Batch 450/537: Loss=1.0322 (C:1.0322, R:0.0105)
Batch 475/537: Loss=1.0149 (C:1.0149, R:0.0105)
Batch 500/537: Loss=1.0159 (C:1.0159, R:0.0105)
Batch 525/537: Loss=1.0050 (C:1.0050, R:0.0105)

============================================================
Epoch 9/300 completed in 28.1s
Train: Loss=1.0282 (C:1.0282, R:0.0105) Ratio=3.17x
Val:   Loss=1.0537 (C:1.0537, R:0.0104) Ratio=2.92x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.0537)
============================================================

🌍 Updating global dataset at epoch 10
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.497 ± 0.595
    Neg distances: 1.843 ± 0.915
    Separation ratio: 3.71x
    Gap: -3.372
    ✅ Excellent global separation!

Epoch 10 Training
----------------------------------------
Batch   0/537: Loss=0.9760 (C:0.9760, R:0.0105)
Batch  25/537: Loss=1.0235 (C:1.0235, R:0.0105)
Batch  50/537: Loss=1.0063 (C:1.0063, R:0.0105)
Batch  75/537: Loss=1.0351 (C:1.0351, R:0.0105)
Batch 100/537: Loss=0.9826 (C:0.9826, R:0.0105)
Batch 125/537: Loss=1.0187 (C:1.0187, R:0.0105)
Batch 150/537: Loss=1.0045 (C:1.0045, R:0.0105)
Batch 175/537: Loss=1.0176 (C:1.0176, R:0.0105)
Batch 200/537: Loss=1.0150 (C:1.0150, R:0.0105)
Batch 225/537: Loss=1.0089 (C:1.0089, R:0.0105)
Batch 250/537: Loss=1.0170 (C:1.0170, R:0.0105)
Batch 275/537: Loss=1.0113 (C:1.0113, R:0.0105)
Batch 300/537: Loss=1.0410 (C:1.0410, R:0.0105)
Batch 325/537: Loss=1.0097 (C:1.0097, R:0.0105)
Batch 350/537: Loss=1.0097 (C:1.0097, R:0.0105)
Batch 375/537: Loss=1.0172 (C:1.0172, R:0.0106)
Batch 400/537: Loss=1.0175 (C:1.0175, R:0.0105)
Batch 425/537: Loss=0.9894 (C:0.9894, R:0.0105)
Batch 450/537: Loss=1.0317 (C:1.0317, R:0.0105)
Batch 475/537: Loss=1.0056 (C:1.0056, R:0.0106)
Batch 500/537: Loss=1.0083 (C:1.0083, R:0.0105)
Batch 525/537: Loss=1.0383 (C:1.0383, R:0.0105)

============================================================
Epoch 10/300 completed in 27.2s
Train: Loss=1.0146 (C:1.0146, R:0.0105) Ratio=3.17x
Val:   Loss=1.0427 (C:1.0427, R:0.0104) Ratio=2.94x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.0427)
============================================================

🌍 Updating global dataset at epoch 11
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.511 ± 0.594
    Neg distances: 1.885 ± 0.936
    Separation ratio: 3.69x
    Gap: -3.434
    ✅ Excellent global separation!

Epoch 11 Training
----------------------------------------
Batch   0/537: Loss=0.9973 (C:0.9973, R:0.0105)
Batch  25/537: Loss=0.9731 (C:0.9731, R:0.0105)
Batch  50/537: Loss=1.0236 (C:1.0236, R:0.0105)
Batch  75/537: Loss=1.0469 (C:1.0469, R:0.0105)
Batch 100/537: Loss=1.0086 (C:1.0086, R:0.0105)
Batch 125/537: Loss=1.0229 (C:1.0229, R:0.0105)
Batch 150/537: Loss=0.9958 (C:0.9958, R:0.0105)
Batch 175/537: Loss=0.9979 (C:0.9979, R:0.0105)
Batch 200/537: Loss=0.9811 (C:0.9811, R:0.0105)
Batch 225/537: Loss=1.0121 (C:1.0121, R:0.0105)
Batch 250/537: Loss=1.0353 (C:1.0353, R:0.0105)
Batch 275/537: Loss=0.9995 (C:0.9995, R:0.0105)
Batch 300/537: Loss=1.0065 (C:1.0065, R:0.0105)
Batch 325/537: Loss=1.0169 (C:1.0169, R:0.0105)
Batch 350/537: Loss=1.0228 (C:1.0228, R:0.0105)
Batch 375/537: Loss=1.0078 (C:1.0078, R:0.0105)
Batch 400/537: Loss=0.9645 (C:0.9645, R:0.0105)
Batch 425/537: Loss=1.0499 (C:1.0499, R:0.0105)
Batch 450/537: Loss=1.0356 (C:1.0356, R:0.0105)
Batch 475/537: Loss=1.0105 (C:1.0105, R:0.0105)
Batch 500/537: Loss=1.0222 (C:1.0222, R:0.0105)
Batch 525/537: Loss=1.0204 (C:1.0204, R:0.0105)

============================================================
Epoch 11/300 completed in 27.6s
Train: Loss=1.0039 (C:1.0039, R:0.0105) Ratio=3.16x
Val:   Loss=1.0269 (C:1.0269, R:0.0104) Ratio=3.00x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.0269)
============================================================

🌍 Updating global dataset at epoch 12
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.473 ± 0.575
    Neg distances: 1.969 ± 0.946
    Separation ratio: 4.17x
    Gap: -3.558
    ✅ Excellent global separation!

Epoch 12 Training
----------------------------------------
Batch   0/537: Loss=0.9239 (C:0.9239, R:0.0105)
Batch  25/537: Loss=0.9048 (C:0.9048, R:0.0105)
Batch  50/537: Loss=0.9519 (C:0.9519, R:0.0105)
Batch  75/537: Loss=0.9041 (C:0.9041, R:0.0105)
Batch 100/537: Loss=0.9587 (C:0.9587, R:0.0105)
Batch 125/537: Loss=0.9751 (C:0.9751, R:0.0105)
Batch 150/537: Loss=0.9499 (C:0.9499, R:0.0105)
Batch 175/537: Loss=0.9839 (C:0.9839, R:0.0105)
Batch 200/537: Loss=0.9664 (C:0.9664, R:0.0105)
Batch 225/537: Loss=0.9368 (C:0.9368, R:0.0105)
Batch 250/537: Loss=0.9640 (C:0.9640, R:0.0105)
Batch 275/537: Loss=0.9479 (C:0.9479, R:0.0105)
Batch 300/537: Loss=0.9645 (C:0.9645, R:0.0105)
Batch 325/537: Loss=0.9513 (C:0.9513, R:0.0105)
Batch 350/537: Loss=0.9579 (C:0.9579, R:0.0105)
Batch 375/537: Loss=0.9373 (C:0.9373, R:0.0105)
Batch 400/537: Loss=0.9786 (C:0.9786, R:0.0105)
Batch 425/537: Loss=0.9713 (C:0.9713, R:0.0105)
Batch 450/537: Loss=0.9637 (C:0.9637, R:0.0105)
Batch 475/537: Loss=0.9672 (C:0.9672, R:0.0105)
Batch 500/537: Loss=0.9659 (C:0.9659, R:0.0106)
Batch 525/537: Loss=0.9519 (C:0.9519, R:0.0105)

============================================================
Epoch 12/300 completed in 26.7s
Train: Loss=0.9502 (C:0.9502, R:0.0105) Ratio=3.26x
Val:   Loss=0.9859 (C:0.9859, R:0.0104) Ratio=3.00x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.9859)
============================================================

🌍 Updating global dataset at epoch 13
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.487 ± 0.599
    Neg distances: 2.046 ± 0.980
    Separation ratio: 4.20x
    Gap: -3.712
    ✅ Excellent global separation!

Epoch 13 Training
----------------------------------------
Batch   0/537: Loss=0.8942 (C:0.8942, R:0.0105)
Batch  25/537: Loss=0.9581 (C:0.9581, R:0.0105)
Batch  50/537: Loss=0.9701 (C:0.9701, R:0.0105)
Batch  75/537: Loss=0.9093 (C:0.9093, R:0.0105)
Batch 100/537: Loss=0.9482 (C:0.9482, R:0.0105)
Batch 125/537: Loss=0.9294 (C:0.9294, R:0.0106)
Batch 150/537: Loss=0.8827 (C:0.8827, R:0.0105)
Batch 175/537: Loss=0.9453 (C:0.9453, R:0.0105)
Batch 200/537: Loss=0.9054 (C:0.9054, R:0.0105)
Batch 225/537: Loss=0.9532 (C:0.9532, R:0.0105)
Batch 250/537: Loss=0.9600 (C:0.9600, R:0.0105)
Batch 275/537: Loss=0.9500 (C:0.9500, R:0.0105)
Batch 300/537: Loss=0.9190 (C:0.9190, R:0.0105)
Batch 325/537: Loss=0.9106 (C:0.9106, R:0.0105)
Batch 350/537: Loss=0.9367 (C:0.9367, R:0.0105)
Batch 375/537: Loss=0.9372 (C:0.9372, R:0.0105)
Batch 400/537: Loss=0.9118 (C:0.9118, R:0.0105)
Batch 425/537: Loss=0.9027 (C:0.9027, R:0.0105)
Batch 450/537: Loss=0.9415 (C:0.9415, R:0.0105)
Batch 475/537: Loss=0.9601 (C:0.9601, R:0.0105)
Batch 500/537: Loss=0.9425 (C:0.9425, R:0.0105)
Batch 525/537: Loss=0.9701 (C:0.9701, R:0.0105)

============================================================
Epoch 13/300 completed in 26.6s
Train: Loss=0.9349 (C:0.9349, R:0.0105) Ratio=3.36x
Val:   Loss=0.9727 (C:0.9727, R:0.0104) Ratio=3.00x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.9727)
============================================================

🌍 Updating global dataset at epoch 14
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.521 ± 0.642
    Neg distances: 2.076 ± 1.009
    Separation ratio: 3.99x
    Gap: -3.738
    ✅ Excellent global separation!

Epoch 14 Training
----------------------------------------
Batch   0/537: Loss=0.9311 (C:0.9311, R:0.0105)
Batch  25/537: Loss=0.9398 (C:0.9398, R:0.0105)
Batch  50/537: Loss=0.9237 (C:0.9237, R:0.0105)
Batch  75/537: Loss=0.9006 (C:0.9006, R:0.0105)
Batch 100/537: Loss=0.9449 (C:0.9449, R:0.0105)
Batch 125/537: Loss=0.9370 (C:0.9370, R:0.0105)
Batch 150/537: Loss=0.9243 (C:0.9243, R:0.0105)
Batch 175/537: Loss=0.9290 (C:0.9290, R:0.0105)
Batch 200/537: Loss=0.9492 (C:0.9492, R:0.0105)
Batch 225/537: Loss=0.9581 (C:0.9581, R:0.0105)
Batch 250/537: Loss=0.9139 (C:0.9139, R:0.0105)
Batch 275/537: Loss=0.9747 (C:0.9747, R:0.0105)
Batch 300/537: Loss=0.9868 (C:0.9868, R:0.0105)
Batch 325/537: Loss=0.9111 (C:0.9111, R:0.0105)
Batch 350/537: Loss=0.9421 (C:0.9421, R:0.0105)
Batch 375/537: Loss=0.9366 (C:0.9366, R:0.0105)
Batch 400/537: Loss=0.9321 (C:0.9321, R:0.0106)
Batch 425/537: Loss=0.9531 (C:0.9531, R:0.0105)
Batch 450/537: Loss=0.9654 (C:0.9654, R:0.0106)
Batch 475/537: Loss=0.8958 (C:0.8958, R:0.0105)
Batch 500/537: Loss=0.9710 (C:0.9710, R:0.0105)
Batch 525/537: Loss=0.8949 (C:0.8949, R:0.0105)

============================================================
Epoch 14/300 completed in 26.7s
Train: Loss=0.9423 (C:0.9423, R:0.0105) Ratio=3.42x
Val:   Loss=0.9869 (C:0.9869, R:0.0104) Ratio=3.00x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 15
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.509 ± 0.646
    Neg distances: 2.146 ± 1.030
    Separation ratio: 4.22x
    Gap: -3.810
    ✅ Excellent global separation!

Epoch 15 Training
----------------------------------------
Batch   0/537: Loss=0.8948 (C:0.8948, R:0.0105)
Batch  25/537: Loss=0.8698 (C:0.8698, R:0.0105)
Batch  50/537: Loss=0.9278 (C:0.9278, R:0.0105)
Batch  75/537: Loss=0.8943 (C:0.8943, R:0.0105)
Batch 100/537: Loss=0.9070 (C:0.9070, R:0.0105)
Batch 125/537: Loss=0.9226 (C:0.9226, R:0.0105)
Batch 150/537: Loss=0.8875 (C:0.8875, R:0.0105)
Batch 175/537: Loss=0.9258 (C:0.9258, R:0.0105)
Batch 200/537: Loss=0.9267 (C:0.9267, R:0.0105)
Batch 225/537: Loss=0.9202 (C:0.9202, R:0.0105)
Batch 250/537: Loss=0.9002 (C:0.9002, R:0.0105)
Batch 275/537: Loss=0.9196 (C:0.9196, R:0.0105)
Batch 300/537: Loss=0.9066 (C:0.9066, R:0.0105)
Batch 325/537: Loss=0.8899 (C:0.8899, R:0.0105)
Batch 350/537: Loss=0.9001 (C:0.9001, R:0.0105)
Batch 375/537: Loss=0.9070 (C:0.9070, R:0.0105)
Batch 400/537: Loss=0.9093 (C:0.9093, R:0.0105)
Batch 425/537: Loss=0.9453 (C:0.9453, R:0.0105)
Batch 450/537: Loss=0.9150 (C:0.9150, R:0.0105)
Batch 475/537: Loss=0.9672 (C:0.9672, R:0.0105)
Batch 500/537: Loss=0.8980 (C:0.8980, R:0.0105)
Batch 525/537: Loss=0.9184 (C:0.9184, R:0.0105)

============================================================
Epoch 15/300 completed in 27.1s
Train: Loss=0.9114 (C:0.9114, R:0.0105) Ratio=3.43x
Val:   Loss=0.9509 (C:0.9509, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.9509)
============================================================

🌍 Updating global dataset at epoch 16
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.488 ± 0.639
    Neg distances: 2.198 ± 1.032
    Separation ratio: 4.51x
    Gap: -3.881
    ✅ Excellent global separation!

Epoch 16 Training
----------------------------------------
Batch   0/537: Loss=0.8585 (C:0.8585, R:0.0105)
Batch  25/537: Loss=0.8502 (C:0.8502, R:0.0105)
Batch  50/537: Loss=0.8791 (C:0.8791, R:0.0105)
Batch  75/537: Loss=0.8673 (C:0.8673, R:0.0105)
Batch 100/537: Loss=0.9048 (C:0.9048, R:0.0105)
Batch 125/537: Loss=0.8784 (C:0.8784, R:0.0105)
Batch 150/537: Loss=0.8570 (C:0.8570, R:0.0105)
Batch 175/537: Loss=0.8776 (C:0.8776, R:0.0105)
Batch 200/537: Loss=0.8633 (C:0.8633, R:0.0106)
Batch 225/537: Loss=0.9183 (C:0.9183, R:0.0105)
Batch 250/537: Loss=0.8762 (C:0.8762, R:0.0105)
Batch 275/537: Loss=0.8631 (C:0.8631, R:0.0105)
Batch 300/537: Loss=0.8757 (C:0.8757, R:0.0105)
Batch 325/537: Loss=0.8562 (C:0.8562, R:0.0105)
Batch 350/537: Loss=0.8598 (C:0.8598, R:0.0105)
Batch 375/537: Loss=0.8968 (C:0.8968, R:0.0105)
Batch 400/537: Loss=0.8648 (C:0.8648, R:0.0105)
Batch 425/537: Loss=0.9279 (C:0.9279, R:0.0105)
Batch 450/537: Loss=0.8988 (C:0.8988, R:0.0105)
Batch 475/537: Loss=0.8845 (C:0.8845, R:0.0105)
Batch 500/537: Loss=0.8516 (C:0.8516, R:0.0105)
Batch 525/537: Loss=0.8728 (C:0.8728, R:0.0105)

============================================================
Epoch 16/300 completed in 26.8s
Train: Loss=0.8797 (C:0.8797, R:0.0105) Ratio=3.55x
Val:   Loss=0.9209 (C:0.9209, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.9209)
============================================================

🌍 Updating global dataset at epoch 17
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.492 ± 0.636
    Neg distances: 2.221 ± 1.044
    Separation ratio: 4.52x
    Gap: -3.886
    ✅ Excellent global separation!

Epoch 17 Training
----------------------------------------
Batch   0/537: Loss=0.8751 (C:0.8751, R:0.0105)
Batch  25/537: Loss=0.8323 (C:0.8323, R:0.0105)
Batch  50/537: Loss=0.9130 (C:0.9130, R:0.0105)
Batch  75/537: Loss=0.8496 (C:0.8496, R:0.0105)
Batch 100/537: Loss=0.8440 (C:0.8440, R:0.0105)
Batch 125/537: Loss=0.8868 (C:0.8868, R:0.0105)
Batch 150/537: Loss=0.8532 (C:0.8532, R:0.0105)
Batch 175/537: Loss=0.8869 (C:0.8869, R:0.0105)
Batch 200/537: Loss=0.8463 (C:0.8463, R:0.0105)
Batch 225/537: Loss=0.8584 (C:0.8584, R:0.0105)
Batch 250/537: Loss=0.8785 (C:0.8785, R:0.0105)
Batch 275/537: Loss=0.8786 (C:0.8786, R:0.0105)
Batch 300/537: Loss=0.8870 (C:0.8870, R:0.0105)
Batch 325/537: Loss=0.8722 (C:0.8722, R:0.0105)
Batch 350/537: Loss=0.8628 (C:0.8628, R:0.0105)
Batch 375/537: Loss=0.8857 (C:0.8857, R:0.0105)
Batch 400/537: Loss=0.8884 (C:0.8884, R:0.0106)
Batch 425/537: Loss=0.8833 (C:0.8833, R:0.0105)
Batch 450/537: Loss=0.8685 (C:0.8685, R:0.0105)
Batch 475/537: Loss=0.8714 (C:0.8714, R:0.0105)
Batch 500/537: Loss=0.8676 (C:0.8676, R:0.0105)
Batch 525/537: Loss=0.8872 (C:0.8872, R:0.0105)

============================================================
Epoch 17/300 completed in 27.2s
Train: Loss=0.8697 (C:0.8697, R:0.0105) Ratio=3.58x
Val:   Loss=0.9253 (C:0.9253, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 18
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.482 ± 0.649
    Neg distances: 2.277 ± 1.058
    Separation ratio: 4.72x
    Gap: -4.048
    ✅ Excellent global separation!

Epoch 18 Training
----------------------------------------
Batch   0/537: Loss=0.8542 (C:0.8542, R:0.0105)
Batch  25/537: Loss=0.8251 (C:0.8251, R:0.0105)
Batch  50/537: Loss=0.8308 (C:0.8308, R:0.0105)
Batch  75/537: Loss=0.8534 (C:0.8534, R:0.0105)
Batch 100/537: Loss=0.8252 (C:0.8252, R:0.0105)
Batch 125/537: Loss=0.8200 (C:0.8200, R:0.0105)
Batch 150/537: Loss=0.8612 (C:0.8612, R:0.0106)
Batch 175/537: Loss=0.8484 (C:0.8484, R:0.0105)
Batch 200/537: Loss=0.8550 (C:0.8550, R:0.0105)
Batch 225/537: Loss=0.8080 (C:0.8080, R:0.0105)
Batch 250/537: Loss=0.8056 (C:0.8056, R:0.0105)
Batch 275/537: Loss=0.8069 (C:0.8069, R:0.0105)
Batch 300/537: Loss=0.8697 (C:0.8697, R:0.0105)
Batch 325/537: Loss=0.8527 (C:0.8527, R:0.0105)
Batch 350/537: Loss=0.8485 (C:0.8485, R:0.0105)
Batch 375/537: Loss=0.8267 (C:0.8267, R:0.0105)
Batch 400/537: Loss=0.8671 (C:0.8671, R:0.0106)
Batch 425/537: Loss=0.8552 (C:0.8552, R:0.0105)
Batch 450/537: Loss=0.8677 (C:0.8677, R:0.0105)
Batch 475/537: Loss=0.8775 (C:0.8775, R:0.0105)
Batch 500/537: Loss=0.8493 (C:0.8493, R:0.0105)
Batch 525/537: Loss=0.8704 (C:0.8704, R:0.0105)

============================================================
Epoch 18/300 completed in 27.2s
Train: Loss=0.8491 (C:0.8491, R:0.0105) Ratio=3.63x
Val:   Loss=0.9049 (C:0.9049, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.9049)
============================================================

🌍 Updating global dataset at epoch 19
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.468 ± 0.636
    Neg distances: 2.304 ± 1.066
    Separation ratio: 4.93x
    Gap: -4.049
    ✅ Excellent global separation!

Epoch 19 Training
----------------------------------------
Batch   0/537: Loss=0.8185 (C:0.8185, R:0.0105)
Batch  25/537: Loss=0.8464 (C:0.8464, R:0.0105)
Batch  50/537: Loss=0.7815 (C:0.7815, R:0.0105)
Batch  75/537: Loss=0.7815 (C:0.7815, R:0.0105)
Batch 100/537: Loss=0.8212 (C:0.8212, R:0.0105)
Batch 125/537: Loss=0.8502 (C:0.8502, R:0.0105)
Batch 150/537: Loss=0.7864 (C:0.7864, R:0.0105)
Batch 175/537: Loss=0.8230 (C:0.8230, R:0.0105)
Batch 200/537: Loss=0.8360 (C:0.8360, R:0.0105)
Batch 225/537: Loss=0.8188 (C:0.8188, R:0.0105)
Batch 250/537: Loss=0.8108 (C:0.8108, R:0.0105)
Batch 275/537: Loss=0.8369 (C:0.8369, R:0.0105)
Batch 300/537: Loss=0.8557 (C:0.8557, R:0.0105)
Batch 325/537: Loss=0.7965 (C:0.7965, R:0.0105)
Batch 350/537: Loss=0.8498 (C:0.8498, R:0.0105)
Batch 375/537: Loss=0.8252 (C:0.8252, R:0.0105)
Batch 400/537: Loss=0.8224 (C:0.8224, R:0.0105)
Batch 425/537: Loss=0.8513 (C:0.8513, R:0.0105)
Batch 450/537: Loss=0.8403 (C:0.8403, R:0.0105)
Batch 475/537: Loss=0.8644 (C:0.8644, R:0.0105)
Batch 500/537: Loss=0.8382 (C:0.8382, R:0.0105)
Batch 525/537: Loss=0.8380 (C:0.8380, R:0.0105)

============================================================
Epoch 19/300 completed in 27.0s
Train: Loss=0.8264 (C:0.8264, R:0.0105) Ratio=3.66x
Val:   Loss=0.8908 (C:0.8908, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.8908)
============================================================

🌍 Updating global dataset at epoch 20
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.481 ± 0.643
    Neg distances: 2.295 ± 1.059
    Separation ratio: 4.78x
    Gap: -4.093
    ✅ Excellent global separation!

Epoch 20 Training
----------------------------------------
Batch   0/537: Loss=0.8215 (C:0.8215, R:0.0105)
Batch  25/537: Loss=0.8222 (C:0.8222, R:0.0105)
Batch  50/537: Loss=0.8170 (C:0.8170, R:0.0105)
Batch  75/537: Loss=0.8104 (C:0.8104, R:0.0105)
Batch 100/537: Loss=0.7876 (C:0.7876, R:0.0105)
Batch 125/537: Loss=0.8215 (C:0.8215, R:0.0105)
Batch 150/537: Loss=0.8183 (C:0.8183, R:0.0105)
Batch 175/537: Loss=0.8336 (C:0.8336, R:0.0105)
Batch 200/537: Loss=0.8403 (C:0.8403, R:0.0105)
Batch 225/537: Loss=0.8212 (C:0.8212, R:0.0105)
Batch 250/537: Loss=0.7900 (C:0.7900, R:0.0105)
Batch 275/537: Loss=0.8450 (C:0.8450, R:0.0105)
Batch 300/537: Loss=0.8246 (C:0.8246, R:0.0105)
Batch 325/537: Loss=0.8104 (C:0.8104, R:0.0105)
Batch 350/537: Loss=0.8051 (C:0.8051, R:0.0105)
Batch 375/537: Loss=0.8225 (C:0.8225, R:0.0105)
Batch 400/537: Loss=0.8208 (C:0.8208, R:0.0105)
Batch 425/537: Loss=0.8266 (C:0.8266, R:0.0105)
Batch 450/537: Loss=0.8338 (C:0.8338, R:0.0105)
Batch 475/537: Loss=0.8417 (C:0.8417, R:0.0105)
Batch 500/537: Loss=0.8182 (C:0.8182, R:0.0106)
Batch 525/537: Loss=0.8612 (C:0.8612, R:0.0105)

============================================================
Epoch 20/300 completed in 26.7s
Train: Loss=0.8257 (C:0.8257, R:0.0105) Ratio=3.72x
Val:   Loss=0.8885 (C:0.8885, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.8885)
Checkpoint saved at epoch 20
============================================================

🌍 Updating global dataset at epoch 21
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.465 ± 0.630
    Neg distances: 2.328 ± 1.060
    Separation ratio: 5.01x
    Gap: -4.132
    ✅ Excellent global separation!

Epoch 21 Training
----------------------------------------
Batch   0/537: Loss=0.7777 (C:0.7777, R:0.0105)
Batch  25/537: Loss=0.8360 (C:0.8360, R:0.0105)
Batch  50/537: Loss=0.7900 (C:0.7900, R:0.0105)
Batch  75/537: Loss=0.8190 (C:0.8190, R:0.0105)
Batch 100/537: Loss=0.8420 (C:0.8420, R:0.0105)
Batch 125/537: Loss=0.7925 (C:0.7925, R:0.0105)
Batch 150/537: Loss=0.7895 (C:0.7895, R:0.0105)
Batch 175/537: Loss=0.8237 (C:0.8237, R:0.0105)
Batch 200/537: Loss=0.8241 (C:0.8241, R:0.0105)
Batch 225/537: Loss=0.7690 (C:0.7690, R:0.0105)
Batch 250/537: Loss=0.7777 (C:0.7777, R:0.0105)
Batch 275/537: Loss=0.8161 (C:0.8161, R:0.0105)
Batch 300/537: Loss=0.8385 (C:0.8385, R:0.0105)
Batch 325/537: Loss=0.7871 (C:0.7871, R:0.0105)
Batch 350/537: Loss=0.8294 (C:0.8294, R:0.0105)
Batch 375/537: Loss=0.8166 (C:0.8166, R:0.0105)
Batch 400/537: Loss=0.8395 (C:0.8395, R:0.0105)
Batch 425/537: Loss=0.8199 (C:0.8199, R:0.0105)
Batch 450/537: Loss=0.8040 (C:0.8040, R:0.0105)
Batch 475/537: Loss=0.8206 (C:0.8206, R:0.0105)
Batch 500/537: Loss=0.7686 (C:0.7686, R:0.0105)
Batch 525/537: Loss=0.8288 (C:0.8288, R:0.0105)

============================================================
Epoch 21/300 completed in 26.6s
Train: Loss=0.8034 (C:0.8034, R:0.0105) Ratio=3.71x
Val:   Loss=0.8643 (C:0.8643, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.8643)
============================================================

🌍 Updating global dataset at epoch 22
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.474 ± 0.673
    Neg distances: 2.362 ± 1.077
    Separation ratio: 4.98x
    Gap: -4.232
    ✅ Excellent global separation!

Epoch 22 Training
----------------------------------------
Batch   0/537: Loss=0.7946 (C:0.7946, R:0.0105)
Batch  25/537: Loss=0.7769 (C:0.7769, R:0.0105)
Batch  50/537: Loss=0.7874 (C:0.7874, R:0.0105)
Batch  75/537: Loss=0.7697 (C:0.7697, R:0.0105)
Batch 100/537: Loss=0.7649 (C:0.7649, R:0.0105)
Batch 125/537: Loss=0.8082 (C:0.8082, R:0.0106)
Batch 150/537: Loss=0.8144 (C:0.8144, R:0.0105)
Batch 175/537: Loss=0.7792 (C:0.7792, R:0.0105)
Batch 200/537: Loss=0.8098 (C:0.8098, R:0.0106)
Batch 225/537: Loss=0.7607 (C:0.7607, R:0.0105)
Batch 250/537: Loss=0.8175 (C:0.8175, R:0.0105)
Batch 275/537: Loss=0.7915 (C:0.7915, R:0.0105)
Batch 300/537: Loss=0.7906 (C:0.7906, R:0.0105)
Batch 325/537: Loss=0.7913 (C:0.7913, R:0.0105)
Batch 350/537: Loss=0.7795 (C:0.7795, R:0.0105)
Batch 375/537: Loss=0.8022 (C:0.8022, R:0.0105)
Batch 400/537: Loss=0.7923 (C:0.7923, R:0.0105)
Batch 425/537: Loss=0.8058 (C:0.8058, R:0.0105)
Batch 450/537: Loss=0.8050 (C:0.8050, R:0.0105)
Batch 475/537: Loss=0.7767 (C:0.7767, R:0.0105)
Batch 500/537: Loss=0.8059 (C:0.8059, R:0.0105)
Batch 525/537: Loss=0.8033 (C:0.8033, R:0.0105)

============================================================
Epoch 22/300 completed in 26.7s
Train: Loss=0.7971 (C:0.7971, R:0.0105) Ratio=3.82x
Val:   Loss=0.8625 (C:0.8625, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.8625)
============================================================

🌍 Updating global dataset at epoch 23
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.465 ± 0.645
    Neg distances: 2.388 ± 1.084
    Separation ratio: 5.14x
    Gap: -4.222
    ✅ Excellent global separation!

Epoch 23 Training
----------------------------------------
Batch   0/537: Loss=0.7490 (C:0.7490, R:0.0105)
Batch  25/537: Loss=0.8146 (C:0.8146, R:0.0105)
Batch  50/537: Loss=0.7600 (C:0.7600, R:0.0105)
Batch  75/537: Loss=0.7700 (C:0.7700, R:0.0105)
Batch 100/537: Loss=0.7916 (C:0.7916, R:0.0105)
Batch 125/537: Loss=0.7923 (C:0.7923, R:0.0105)
Batch 150/537: Loss=0.7493 (C:0.7493, R:0.0105)
Batch 175/537: Loss=0.8122 (C:0.8122, R:0.0105)
Batch 200/537: Loss=0.7614 (C:0.7614, R:0.0105)
Batch 225/537: Loss=0.7724 (C:0.7724, R:0.0105)
Batch 250/537: Loss=0.7646 (C:0.7646, R:0.0106)
Batch 275/537: Loss=0.7849 (C:0.7849, R:0.0105)
Batch 300/537: Loss=0.7909 (C:0.7909, R:0.0105)
Batch 325/537: Loss=0.7931 (C:0.7931, R:0.0105)
Batch 350/537: Loss=0.7881 (C:0.7881, R:0.0105)
Batch 375/537: Loss=0.7924 (C:0.7924, R:0.0105)
Batch 400/537: Loss=0.8075 (C:0.8075, R:0.0105)
Batch 425/537: Loss=0.8095 (C:0.8095, R:0.0105)
Batch 450/537: Loss=0.7950 (C:0.7950, R:0.0105)
Batch 475/537: Loss=0.7945 (C:0.7945, R:0.0105)
Batch 500/537: Loss=0.8103 (C:0.8103, R:0.0105)
Batch 525/537: Loss=0.8415 (C:0.8415, R:0.0105)

============================================================
Epoch 23/300 completed in 26.7s
Train: Loss=0.7833 (C:0.7833, R:0.0105) Ratio=3.82x
Val:   Loss=0.8584 (C:0.8584, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.8584)
============================================================

🌍 Updating global dataset at epoch 24
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.477 ± 0.675
    Neg distances: 2.382 ± 1.091
    Separation ratio: 4.99x
    Gap: -4.214
    ✅ Excellent global separation!

Epoch 24 Training
----------------------------------------
Batch   0/537: Loss=0.7734 (C:0.7734, R:0.0105)
Batch  25/537: Loss=0.7627 (C:0.7627, R:0.0105)
Batch  50/537: Loss=0.8149 (C:0.8149, R:0.0105)
Batch  75/537: Loss=0.8289 (C:0.8289, R:0.0105)
Batch 100/537: Loss=0.7538 (C:0.7538, R:0.0105)
Batch 125/537: Loss=0.8046 (C:0.8046, R:0.0105)
Batch 150/537: Loss=0.7784 (C:0.7784, R:0.0105)
Batch 175/537: Loss=0.7798 (C:0.7798, R:0.0105)
Batch 200/537: Loss=0.7962 (C:0.7962, R:0.0105)
Batch 225/537: Loss=0.7832 (C:0.7832, R:0.0105)
Batch 250/537: Loss=0.7657 (C:0.7657, R:0.0105)
Batch 275/537: Loss=0.7690 (C:0.7690, R:0.0105)
Batch 300/537: Loss=0.8010 (C:0.8010, R:0.0105)
Batch 325/537: Loss=0.7792 (C:0.7792, R:0.0105)
Batch 350/537: Loss=0.8036 (C:0.8036, R:0.0105)
Batch 375/537: Loss=0.7843 (C:0.7843, R:0.0105)
Batch 400/537: Loss=0.8284 (C:0.8284, R:0.0105)
Batch 425/537: Loss=0.8090 (C:0.8090, R:0.0105)
Batch 450/537: Loss=0.7824 (C:0.7824, R:0.0105)
Batch 475/537: Loss=0.7541 (C:0.7541, R:0.0105)
Batch 500/537: Loss=0.8343 (C:0.8343, R:0.0105)
Batch 525/537: Loss=0.7806 (C:0.7806, R:0.0105)

============================================================
Epoch 24/300 completed in 26.8s
Train: Loss=0.7889 (C:0.7889, R:0.0105) Ratio=3.89x
Val:   Loss=0.8636 (C:0.8636, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 25
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.446 ± 0.640
    Neg distances: 2.404 ± 1.082
    Separation ratio: 5.39x
    Gap: -4.271
    ✅ Excellent global separation!

Epoch 25 Training
----------------------------------------
Batch   0/537: Loss=0.7625 (C:0.7625, R:0.0105)
Batch  25/537: Loss=0.7302 (C:0.7302, R:0.0105)
Batch  50/537: Loss=0.7696 (C:0.7696, R:0.0106)
Batch  75/537: Loss=0.7888 (C:0.7888, R:0.0105)
Batch 100/537: Loss=0.7484 (C:0.7484, R:0.0105)
Batch 125/537: Loss=0.8325 (C:0.8325, R:0.0105)
Batch 150/537: Loss=0.7754 (C:0.7754, R:0.0105)
Batch 175/537: Loss=0.7700 (C:0.7700, R:0.0105)
Batch 200/537: Loss=0.7367 (C:0.7367, R:0.0105)
Batch 225/537: Loss=0.7481 (C:0.7481, R:0.0105)
Batch 250/537: Loss=0.8119 (C:0.8119, R:0.0105)
Batch 275/537: Loss=0.7574 (C:0.7574, R:0.0105)
Batch 300/537: Loss=0.7468 (C:0.7468, R:0.0105)
Batch 325/537: Loss=0.7707 (C:0.7707, R:0.0105)
Batch 350/537: Loss=0.7516 (C:0.7516, R:0.0105)
Batch 375/537: Loss=0.7571 (C:0.7571, R:0.0105)
Batch 400/537: Loss=0.7571 (C:0.7571, R:0.0105)
Batch 425/537: Loss=0.8274 (C:0.8274, R:0.0105)
Batch 450/537: Loss=0.7797 (C:0.7797, R:0.0105)
Batch 475/537: Loss=0.7600 (C:0.7600, R:0.0105)
Batch 500/537: Loss=0.7749 (C:0.7749, R:0.0105)
Batch 525/537: Loss=0.7511 (C:0.7511, R:0.0105)

============================================================
Epoch 25/300 completed in 28.1s
Train: Loss=0.7592 (C:0.7592, R:0.0105) Ratio=3.87x
Val:   Loss=0.8365 (C:0.8365, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.8365)
============================================================

🌍 Updating global dataset at epoch 26
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.451 ± 0.647
    Neg distances: 2.399 ± 1.086
    Separation ratio: 5.32x
    Gap: -4.208
    ✅ Excellent global separation!

Epoch 26 Training
----------------------------------------
Batch   0/537: Loss=0.7781 (C:0.7781, R:0.0105)
Batch  25/537: Loss=0.7658 (C:0.7658, R:0.0105)
Batch  50/537: Loss=0.7751 (C:0.7751, R:0.0105)
Batch  75/537: Loss=0.7570 (C:0.7570, R:0.0105)
Batch 100/537: Loss=0.7397 (C:0.7397, R:0.0105)
Batch 125/537: Loss=0.7889 (C:0.7889, R:0.0105)
Batch 150/537: Loss=0.7377 (C:0.7377, R:0.0105)
Batch 175/537: Loss=0.7382 (C:0.7382, R:0.0105)
Batch 200/537: Loss=0.8011 (C:0.8011, R:0.0105)
Batch 225/537: Loss=0.7512 (C:0.7512, R:0.0106)
Batch 250/537: Loss=0.7458 (C:0.7458, R:0.0105)
Batch 275/537: Loss=0.7666 (C:0.7666, R:0.0105)
Batch 300/537: Loss=0.7910 (C:0.7910, R:0.0105)
Batch 325/537: Loss=0.7098 (C:0.7098, R:0.0105)
Batch 350/537: Loss=0.6900 (C:0.6900, R:0.0105)
Batch 375/537: Loss=0.7638 (C:0.7638, R:0.0105)
Batch 400/537: Loss=0.7386 (C:0.7386, R:0.0105)
Batch 425/537: Loss=0.7396 (C:0.7396, R:0.0105)
Batch 450/537: Loss=0.8026 (C:0.8026, R:0.0105)
Batch 475/537: Loss=0.7676 (C:0.7676, R:0.0105)
Batch 500/537: Loss=0.7407 (C:0.7407, R:0.0105)
Batch 525/537: Loss=0.7313 (C:0.7313, R:0.0105)

============================================================
Epoch 26/300 completed in 27.4s
Train: Loss=0.7578 (C:0.7578, R:0.0105) Ratio=4.01x
Val:   Loss=0.8546 (C:0.8546, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 27
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.434 ± 0.644
    Neg distances: 2.425 ± 1.087
    Separation ratio: 5.58x
    Gap: -4.339
    ✅ Excellent global separation!

Epoch 27 Training
----------------------------------------
Batch   0/537: Loss=0.7387 (C:0.7387, R:0.0105)
Batch  25/537: Loss=0.7450 (C:0.7450, R:0.0105)
Batch  50/537: Loss=0.7174 (C:0.7174, R:0.0105)
Batch  75/537: Loss=0.7178 (C:0.7178, R:0.0105)
Batch 100/537: Loss=0.7523 (C:0.7523, R:0.0105)
Batch 125/537: Loss=0.7311 (C:0.7311, R:0.0105)
Batch 150/537: Loss=0.7117 (C:0.7117, R:0.0105)
Batch 175/537: Loss=0.7413 (C:0.7413, R:0.0105)
Batch 200/537: Loss=0.7142 (C:0.7142, R:0.0105)
Batch 225/537: Loss=0.7419 (C:0.7419, R:0.0105)
Batch 250/537: Loss=0.7304 (C:0.7304, R:0.0105)
Batch 275/537: Loss=0.7507 (C:0.7507, R:0.0105)
Batch 300/537: Loss=0.7240 (C:0.7240, R:0.0105)
Batch 325/537: Loss=0.7477 (C:0.7477, R:0.0105)
Batch 350/537: Loss=0.7737 (C:0.7737, R:0.0105)
Batch 375/537: Loss=0.7250 (C:0.7250, R:0.0105)
Batch 400/537: Loss=0.7447 (C:0.7447, R:0.0106)
Batch 425/537: Loss=0.7020 (C:0.7020, R:0.0105)
Batch 450/537: Loss=0.7650 (C:0.7650, R:0.0105)
Batch 475/537: Loss=0.7616 (C:0.7616, R:0.0105)
Batch 500/537: Loss=0.7524 (C:0.7524, R:0.0105)
Batch 525/537: Loss=0.7554 (C:0.7554, R:0.0105)

============================================================
Epoch 27/300 completed in 28.0s
Train: Loss=0.7364 (C:0.7364, R:0.0105) Ratio=4.03x
Val:   Loss=0.8245 (C:0.8245, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.8245)
============================================================

🌍 Updating global dataset at epoch 28
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.444 ± 0.650
    Neg distances: 2.424 ± 1.088
    Separation ratio: 5.47x
    Gap: -4.265
    ✅ Excellent global separation!

Epoch 28 Training
----------------------------------------
Batch   0/537: Loss=0.7335 (C:0.7335, R:0.0105)
Batch  25/537: Loss=0.7487 (C:0.7487, R:0.0105)
Batch  50/537: Loss=0.7160 (C:0.7160, R:0.0105)
Batch  75/537: Loss=0.7324 (C:0.7324, R:0.0105)
Batch 100/537: Loss=0.7318 (C:0.7318, R:0.0105)
Batch 125/537: Loss=0.7206 (C:0.7206, R:0.0105)
Batch 150/537: Loss=0.7244 (C:0.7244, R:0.0105)
Batch 175/537: Loss=0.7245 (C:0.7245, R:0.0105)
Batch 200/537: Loss=0.7077 (C:0.7077, R:0.0105)
Batch 225/537: Loss=0.7659 (C:0.7659, R:0.0105)
Batch 250/537: Loss=0.7170 (C:0.7170, R:0.0105)
Batch 275/537: Loss=0.7522 (C:0.7522, R:0.0105)
Batch 300/537: Loss=0.7693 (C:0.7693, R:0.0106)
Batch 325/537: Loss=0.7878 (C:0.7878, R:0.0105)
Batch 350/537: Loss=0.7584 (C:0.7584, R:0.0105)
Batch 375/537: Loss=0.7590 (C:0.7590, R:0.0105)
Batch 400/537: Loss=0.7484 (C:0.7484, R:0.0105)
Batch 425/537: Loss=0.7546 (C:0.7546, R:0.0105)
Batch 450/537: Loss=0.7009 (C:0.7009, R:0.0106)
Batch 475/537: Loss=0.8090 (C:0.8090, R:0.0105)
Batch 500/537: Loss=0.7302 (C:0.7302, R:0.0105)
Batch 525/537: Loss=0.7515 (C:0.7515, R:0.0105)

============================================================
Epoch 28/300 completed in 27.9s
Train: Loss=0.7408 (C:0.7408, R:0.0105) Ratio=4.06x
Val:   Loss=0.8141 (C:0.8141, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.8141)
============================================================

🌍 Updating global dataset at epoch 29
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.440 ± 0.669
    Neg distances: 2.455 ± 1.106
    Separation ratio: 5.58x
    Gap: -4.361
    ✅ Excellent global separation!

Epoch 29 Training
----------------------------------------
Batch   0/537: Loss=0.7022 (C:0.7022, R:0.0105)
Batch  25/537: Loss=0.7171 (C:0.7171, R:0.0105)
Batch  50/537: Loss=0.7134 (C:0.7134, R:0.0106)
Batch  75/537: Loss=0.6962 (C:0.6962, R:0.0105)
Batch 100/537: Loss=0.7346 (C:0.7346, R:0.0105)
Batch 125/537: Loss=0.7378 (C:0.7378, R:0.0105)
Batch 150/537: Loss=0.6896 (C:0.6896, R:0.0105)
Batch 175/537: Loss=0.7402 (C:0.7402, R:0.0106)
Batch 200/537: Loss=0.7698 (C:0.7698, R:0.0105)
Batch 225/537: Loss=0.7505 (C:0.7505, R:0.0106)
Batch 250/537: Loss=0.6949 (C:0.6949, R:0.0105)
Batch 275/537: Loss=0.7564 (C:0.7564, R:0.0105)
Batch 300/537: Loss=0.7682 (C:0.7682, R:0.0105)
Batch 325/537: Loss=0.6974 (C:0.6974, R:0.0105)
Batch 350/537: Loss=0.7413 (C:0.7413, R:0.0105)
Batch 375/537: Loss=0.7319 (C:0.7319, R:0.0105)
Batch 400/537: Loss=0.7358 (C:0.7358, R:0.0105)
Batch 425/537: Loss=0.7143 (C:0.7143, R:0.0105)
Batch 450/537: Loss=0.7616 (C:0.7616, R:0.0105)
Batch 475/537: Loss=0.7070 (C:0.7070, R:0.0106)
Batch 500/537: Loss=0.7733 (C:0.7733, R:0.0105)
Batch 525/537: Loss=0.7674 (C:0.7674, R:0.0105)

============================================================
Epoch 29/300 completed in 27.7s
Train: Loss=0.7313 (C:0.7313, R:0.0105) Ratio=4.07x
Val:   Loss=0.8308 (C:0.8308, R:0.0104) Ratio=3.12x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 30
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.438 ± 0.652
    Neg distances: 2.492 ± 1.113
    Separation ratio: 5.69x
    Gap: -4.389
    ✅ Excellent global separation!

Epoch 30 Training
----------------------------------------
Batch   0/537: Loss=0.6894 (C:0.6894, R:0.0105)
Batch  25/537: Loss=0.7207 (C:0.7207, R:0.0105)
Batch  50/537: Loss=0.7259 (C:0.7259, R:0.0105)
Batch  75/537: Loss=0.6882 (C:0.6882, R:0.0105)
Batch 100/537: Loss=0.7148 (C:0.7148, R:0.0105)
Batch 125/537: Loss=0.7174 (C:0.7174, R:0.0105)
Batch 150/537: Loss=0.7208 (C:0.7208, R:0.0105)
Batch 175/537: Loss=0.6650 (C:0.6650, R:0.0105)
Batch 200/537: Loss=0.7173 (C:0.7173, R:0.0105)
Batch 225/537: Loss=0.7457 (C:0.7457, R:0.0105)
Batch 250/537: Loss=0.7569 (C:0.7569, R:0.0105)
Batch 275/537: Loss=0.7224 (C:0.7224, R:0.0106)
Batch 300/537: Loss=0.7207 (C:0.7207, R:0.0105)
Batch 325/537: Loss=0.7365 (C:0.7365, R:0.0105)
Batch 350/537: Loss=0.7277 (C:0.7277, R:0.0105)
Batch 375/537: Loss=0.6756 (C:0.6756, R:0.0105)
Batch 400/537: Loss=0.7460 (C:0.7460, R:0.0105)
Batch 425/537: Loss=0.7567 (C:0.7567, R:0.0105)
Batch 450/537: Loss=0.6799 (C:0.6799, R:0.0105)
Batch 475/537: Loss=0.7402 (C:0.7402, R:0.0105)
Batch 500/537: Loss=0.7270 (C:0.7270, R:0.0105)
Batch 525/537: Loss=0.7331 (C:0.7331, R:0.0105)

============================================================
Epoch 30/300 completed in 28.4s
Train: Loss=0.7233 (C:0.7233, R:0.0105) Ratio=4.16x
Val:   Loss=0.8189 (C:0.8189, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.000
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 31
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.429 ± 0.668
    Neg distances: 2.495 ± 1.111
    Separation ratio: 5.81x
    Gap: -4.357
    ✅ Excellent global separation!

Epoch 31 Training
----------------------------------------
Batch   0/537: Loss=0.6760 (C:0.6760, R:0.0106)
Batch  25/537: Loss=0.7031 (C:0.7031, R:0.0105)
Batch  50/537: Loss=0.6968 (C:0.6968, R:0.0105)
Batch  75/537: Loss=0.7268 (C:0.7268, R:0.0105)
Batch 100/537: Loss=0.7132 (C:0.7132, R:0.0105)
Batch 125/537: Loss=0.7389 (C:0.7389, R:0.0105)
Batch 150/537: Loss=0.7043 (C:0.7043, R:0.0105)
Batch 175/537: Loss=0.6851 (C:0.6851, R:0.0105)
Batch 200/537: Loss=0.7494 (C:0.7494, R:0.0106)
Batch 225/537: Loss=0.7108 (C:0.7108, R:0.0105)
Batch 250/537: Loss=0.7278 (C:0.7278, R:0.0105)
Batch 275/537: Loss=0.7386 (C:0.7386, R:0.0105)
Batch 300/537: Loss=0.7194 (C:0.7194, R:0.0105)
Batch 325/537: Loss=0.7337 (C:0.7337, R:0.0105)
Batch 350/537: Loss=0.7416 (C:0.7416, R:0.0105)
Batch 375/537: Loss=0.6951 (C:0.6951, R:0.0105)
Batch 400/537: Loss=0.7799 (C:0.7799, R:0.0105)
Batch 425/537: Loss=0.6993 (C:0.6993, R:0.0105)
Batch 450/537: Loss=0.6981 (C:0.6981, R:0.0105)
Batch 475/537: Loss=0.7075 (C:0.7075, R:0.0105)
Batch 500/537: Loss=0.7584 (C:0.7584, R:0.0105)
Batch 525/537: Loss=0.7401 (C:0.7401, R:0.0105)

============================================================
Epoch 31/300 completed in 27.2s
Train: Loss=0.7139 (C:0.7139, R:0.0105) Ratio=4.09x
Val:   Loss=0.8005 (C:0.8005, R:0.0104) Ratio=3.14x
Reconstruction weight: 0.015
✅ New best model saved (Val Loss: 0.8005)
============================================================

🌍 Updating global dataset at epoch 32
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.415 ± 0.636
    Neg distances: 2.545 ± 1.127
    Separation ratio: 6.13x
    Gap: -4.430
    ✅ Excellent global separation!

Epoch 32 Training
----------------------------------------
Batch   0/537: Loss=0.7246 (C:0.7246, R:0.0105)
Batch  25/537: Loss=0.6479 (C:0.6479, R:0.0105)
Batch  50/537: Loss=0.7165 (C:0.7165, R:0.0105)
Batch  75/537: Loss=0.6826 (C:0.6826, R:0.0106)
Batch 100/537: Loss=0.6647 (C:0.6647, R:0.0105)
Batch 125/537: Loss=0.6665 (C:0.6665, R:0.0105)
Batch 150/537: Loss=0.6839 (C:0.6839, R:0.0105)
Batch 175/537: Loss=0.6801 (C:0.6801, R:0.0105)
Batch 200/537: Loss=0.7022 (C:0.7022, R:0.0105)
Batch 225/537: Loss=0.7323 (C:0.7323, R:0.0105)
Batch 250/537: Loss=0.7146 (C:0.7146, R:0.0105)
Batch 275/537: Loss=0.7108 (C:0.7108, R:0.0105)
Batch 300/537: Loss=0.6758 (C:0.6758, R:0.0105)
Batch 325/537: Loss=0.6849 (C:0.6849, R:0.0105)
Batch 350/537: Loss=0.7060 (C:0.7060, R:0.0105)
Batch 375/537: Loss=0.6968 (C:0.6968, R:0.0105)
Batch 400/537: Loss=0.6850 (C:0.6850, R:0.0105)
Batch 425/537: Loss=0.6914 (C:0.6914, R:0.0105)
Batch 450/537: Loss=0.7158 (C:0.7158, R:0.0105)
Batch 475/537: Loss=0.6858 (C:0.6858, R:0.0105)
Batch 500/537: Loss=0.7061 (C:0.7061, R:0.0105)
Batch 525/537: Loss=0.6616 (C:0.6616, R:0.0105)

============================================================
Epoch 32/300 completed in 27.8s
Train: Loss=0.6982 (C:0.6982, R:0.0105) Ratio=4.25x
Val:   Loss=0.8020 (C:0.8020, R:0.0104) Ratio=3.12x
Reconstruction weight: 0.030
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 33
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.439 ± 0.653
    Neg distances: 2.516 ± 1.123
    Separation ratio: 5.73x
    Gap: -4.400
    ✅ Excellent global separation!

Epoch 33 Training
----------------------------------------
Batch   0/537: Loss=0.7040 (C:0.7040, R:0.0105)
Batch  25/537: Loss=0.6930 (C:0.6930, R:0.0105)
Batch  50/537: Loss=0.6685 (C:0.6685, R:0.0105)
Batch  75/537: Loss=0.7072 (C:0.7072, R:0.0105)
Batch 100/537: Loss=0.6909 (C:0.6909, R:0.0105)
Batch 125/537: Loss=0.7508 (C:0.7508, R:0.0105)
Batch 150/537: Loss=0.7099 (C:0.7099, R:0.0105)
Batch 175/537: Loss=0.7178 (C:0.7178, R:0.0105)
Batch 200/537: Loss=0.7065 (C:0.7065, R:0.0106)
Batch 225/537: Loss=0.7212 (C:0.7212, R:0.0105)
Batch 250/537: Loss=0.7359 (C:0.7359, R:0.0105)
Batch 275/537: Loss=0.7368 (C:0.7368, R:0.0105)
Batch 300/537: Loss=0.7328 (C:0.7328, R:0.0105)
Batch 325/537: Loss=0.7257 (C:0.7257, R:0.0105)
Batch 350/537: Loss=0.7253 (C:0.7253, R:0.0105)
Batch 375/537: Loss=0.6826 (C:0.6826, R:0.0105)
Batch 400/537: Loss=0.6890 (C:0.6890, R:0.0105)
Batch 425/537: Loss=0.6771 (C:0.6771, R:0.0105)
Batch 450/537: Loss=0.7086 (C:0.7086, R:0.0105)
Batch 475/537: Loss=0.7108 (C:0.7108, R:0.0105)
Batch 500/537: Loss=0.7023 (C:0.7023, R:0.0105)
Batch 525/537: Loss=0.6855 (C:0.6855, R:0.0105)

============================================================
Epoch 33/300 completed in 28.0s
Train: Loss=0.7126 (C:0.7126, R:0.0105) Ratio=4.28x
Val:   Loss=0.8031 (C:0.8031, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.045
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 34
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.396 ± 0.630
    Neg distances: 2.531 ± 1.104
    Separation ratio: 6.39x
    Gap: -4.325
    ✅ Excellent global separation!

Epoch 34 Training
----------------------------------------
Batch   0/537: Loss=0.6721 (C:0.6721, R:0.0105)
Batch  25/537: Loss=0.7112 (C:0.7112, R:0.0105)
Batch  50/537: Loss=0.6647 (C:0.6647, R:0.0105)
Batch  75/537: Loss=0.6624 (C:0.6624, R:0.0105)
Batch 100/537: Loss=0.6723 (C:0.6723, R:0.0106)
Batch 125/537: Loss=0.6761 (C:0.6761, R:0.0105)
Batch 150/537: Loss=0.6835 (C:0.6835, R:0.0105)
Batch 175/537: Loss=0.6674 (C:0.6674, R:0.0105)
Batch 200/537: Loss=0.6460 (C:0.6460, R:0.0105)
Batch 225/537: Loss=0.6625 (C:0.6625, R:0.0105)
Batch 250/537: Loss=0.6541 (C:0.6541, R:0.0105)
Batch 275/537: Loss=0.6743 (C:0.6743, R:0.0105)
Batch 300/537: Loss=0.6839 (C:0.6839, R:0.0105)
Batch 325/537: Loss=0.6727 (C:0.6727, R:0.0105)
Batch 350/537: Loss=0.6635 (C:0.6635, R:0.0105)
Batch 375/537: Loss=0.6503 (C:0.6503, R:0.0105)
Batch 400/537: Loss=0.7176 (C:0.7176, R:0.0105)
Batch 425/537: Loss=0.6987 (C:0.6987, R:0.0105)
Batch 450/537: Loss=0.6811 (C:0.6811, R:0.0105)
Batch 475/537: Loss=0.6849 (C:0.6849, R:0.0105)
Batch 500/537: Loss=0.6823 (C:0.6823, R:0.0105)
Batch 525/537: Loss=0.6860 (C:0.6860, R:0.0106)

============================================================
Epoch 34/300 completed in 28.5s
Train: Loss=0.6743 (C:0.6743, R:0.0105) Ratio=4.27x
Val:   Loss=0.7884 (C:0.7884, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.060
✅ New best model saved (Val Loss: 0.7884)
============================================================

🌍 Updating global dataset at epoch 35
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.402 ± 0.646
    Neg distances: 2.533 ± 1.114
    Separation ratio: 6.29x
    Gap: -4.379
    ✅ Excellent global separation!

Epoch 35 Training
----------------------------------------
Batch   0/537: Loss=0.6774 (C:0.6774, R:0.0105)
Batch  25/537: Loss=0.6613 (C:0.6613, R:0.0105)
Batch  50/537: Loss=0.6992 (C:0.6992, R:0.0105)
Batch  75/537: Loss=0.6798 (C:0.6798, R:0.0105)
Batch 100/537: Loss=0.6813 (C:0.6813, R:0.0105)
Batch 125/537: Loss=0.6809 (C:0.6809, R:0.0105)
Batch 150/537: Loss=0.6746 (C:0.6746, R:0.0105)
Batch 175/537: Loss=0.6630 (C:0.6630, R:0.0105)
Batch 200/537: Loss=0.6730 (C:0.6730, R:0.0105)
Batch 225/537: Loss=0.6513 (C:0.6513, R:0.0105)
Batch 250/537: Loss=0.6607 (C:0.6607, R:0.0105)
Batch 275/537: Loss=0.6880 (C:0.6880, R:0.0105)
Batch 300/537: Loss=0.6500 (C:0.6500, R:0.0105)
Batch 325/537: Loss=0.6877 (C:0.6877, R:0.0105)
Batch 350/537: Loss=0.6801 (C:0.6801, R:0.0105)
Batch 375/537: Loss=0.6582 (C:0.6582, R:0.0105)
Batch 400/537: Loss=0.6534 (C:0.6534, R:0.0105)
Batch 425/537: Loss=0.6704 (C:0.6704, R:0.0105)
Batch 450/537: Loss=0.6729 (C:0.6729, R:0.0105)
Batch 475/537: Loss=0.6867 (C:0.6867, R:0.0106)
Batch 500/537: Loss=0.6761 (C:0.6761, R:0.0105)
Batch 525/537: Loss=0.6828 (C:0.6828, R:0.0105)

============================================================
Epoch 35/300 completed in 27.9s
Train: Loss=0.6768 (C:0.6768, R:0.0105) Ratio=4.39x
Val:   Loss=0.7841 (C:0.7841, R:0.0104) Ratio=3.12x
Reconstruction weight: 0.075
✅ New best model saved (Val Loss: 0.7841)
============================================================

🌍 Updating global dataset at epoch 36
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.414 ± 0.660
    Neg distances: 2.513 ± 1.116
    Separation ratio: 6.07x
    Gap: -4.360
    ✅ Excellent global separation!

Epoch 36 Training
----------------------------------------
Batch   0/537: Loss=0.7065 (C:0.7065, R:0.0105)
Batch  25/537: Loss=0.7051 (C:0.7051, R:0.0105)
Batch  50/537: Loss=0.6486 (C:0.6486, R:0.0105)
Batch  75/537: Loss=0.6591 (C:0.6591, R:0.0105)
Batch 100/537: Loss=0.6810 (C:0.6810, R:0.0105)
Batch 125/537: Loss=0.6657 (C:0.6657, R:0.0105)
Batch 150/537: Loss=0.6565 (C:0.6565, R:0.0105)
Batch 175/537: Loss=0.7167 (C:0.7167, R:0.0105)
Batch 200/537: Loss=0.7103 (C:0.7103, R:0.0105)
Batch 225/537: Loss=0.6926 (C:0.6926, R:0.0105)
Batch 250/537: Loss=0.6625 (C:0.6625, R:0.0106)
Batch 275/537: Loss=0.6913 (C:0.6913, R:0.0105)
Batch 300/537: Loss=0.6198 (C:0.6198, R:0.0105)
Batch 325/537: Loss=0.6807 (C:0.6807, R:0.0105)
Batch 350/537: Loss=0.6713 (C:0.6713, R:0.0105)
Batch 375/537: Loss=0.6802 (C:0.6802, R:0.0105)
Batch 400/537: Loss=0.7000 (C:0.7000, R:0.0105)
Batch 425/537: Loss=0.6864 (C:0.6864, R:0.0105)
Batch 450/537: Loss=0.6467 (C:0.6467, R:0.0106)
Batch 475/537: Loss=0.6643 (C:0.6643, R:0.0105)
Batch 500/537: Loss=0.6612 (C:0.6612, R:0.0105)
Batch 525/537: Loss=0.6998 (C:0.6998, R:0.0105)

============================================================
Epoch 36/300 completed in 27.6s
Train: Loss=0.6859 (C:0.6859, R:0.0105) Ratio=4.35x
Val:   Loss=0.8014 (C:0.8014, R:0.0104) Ratio=3.14x
Reconstruction weight: 0.090
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 37
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.407 ± 0.658
    Neg distances: 2.504 ± 1.102
    Separation ratio: 6.15x
    Gap: -4.440
    ✅ Excellent global separation!

Epoch 37 Training
----------------------------------------
Batch   0/537: Loss=0.6642 (C:0.6642, R:0.0105)
Batch  25/537: Loss=0.6817 (C:0.6817, R:0.0105)
Batch  50/537: Loss=0.6319 (C:0.6319, R:0.0105)
Batch  75/537: Loss=0.6808 (C:0.6808, R:0.0105)
Batch 100/537: Loss=0.6788 (C:0.6788, R:0.0105)
Batch 125/537: Loss=0.6563 (C:0.6563, R:0.0105)
Batch 150/537: Loss=0.6656 (C:0.6656, R:0.0105)
Batch 175/537: Loss=0.6878 (C:0.6878, R:0.0105)
Batch 200/537: Loss=0.6604 (C:0.6604, R:0.0105)
Batch 225/537: Loss=0.6996 (C:0.6996, R:0.0105)
Batch 250/537: Loss=0.6599 (C:0.6599, R:0.0105)
Batch 275/537: Loss=0.6857 (C:0.6857, R:0.0105)
Batch 300/537: Loss=0.6944 (C:0.6944, R:0.0105)
Batch 325/537: Loss=0.6875 (C:0.6875, R:0.0105)
Batch 350/537: Loss=0.6935 (C:0.6935, R:0.0105)
Batch 375/537: Loss=0.7129 (C:0.7129, R:0.0105)
Batch 400/537: Loss=0.7289 (C:0.7289, R:0.0105)
Batch 425/537: Loss=0.7230 (C:0.7230, R:0.0105)
Batch 450/537: Loss=0.6700 (C:0.6700, R:0.0105)
Batch 475/537: Loss=0.6933 (C:0.6933, R:0.0105)
Batch 500/537: Loss=0.7095 (C:0.7095, R:0.0105)
Batch 525/537: Loss=0.6847 (C:0.6847, R:0.0105)

============================================================
Epoch 37/300 completed in 27.1s
Train: Loss=0.6767 (C:0.6767, R:0.0105) Ratio=4.30x
Val:   Loss=0.8038 (C:0.8038, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.105
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 38
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.367 ± 0.603
    Neg distances: 2.570 ± 1.106
    Separation ratio: 7.01x
    Gap: -4.410
    ✅ Excellent global separation!

Epoch 38 Training
----------------------------------------
Batch   0/537: Loss=0.6292 (C:0.6292, R:0.0105)
Batch  25/537: Loss=0.6640 (C:0.6640, R:0.0105)
Batch  50/537: Loss=0.6364 (C:0.6364, R:0.0105)
Batch  75/537: Loss=0.6232 (C:0.6232, R:0.0105)
Batch 100/537: Loss=0.6451 (C:0.6451, R:0.0105)
Batch 125/537: Loss=0.6013 (C:0.6013, R:0.0105)
Batch 150/537: Loss=0.6621 (C:0.6621, R:0.0105)
Batch 175/537: Loss=0.6350 (C:0.6350, R:0.0105)
Batch 200/537: Loss=0.6512 (C:0.6512, R:0.0105)
Batch 225/537: Loss=0.6273 (C:0.6273, R:0.0105)
Batch 250/537: Loss=0.6101 (C:0.6101, R:0.0105)
Batch 275/537: Loss=0.6257 (C:0.6257, R:0.0105)
Batch 300/537: Loss=0.6236 (C:0.6236, R:0.0105)
Batch 325/537: Loss=0.6400 (C:0.6400, R:0.0105)
Batch 350/537: Loss=0.6068 (C:0.6068, R:0.0105)
Batch 375/537: Loss=0.6520 (C:0.6520, R:0.0105)
Batch 400/537: Loss=0.6787 (C:0.6787, R:0.0105)
Batch 425/537: Loss=0.6423 (C:0.6423, R:0.0105)
Batch 450/537: Loss=0.6501 (C:0.6501, R:0.0105)
Batch 475/537: Loss=0.6543 (C:0.6543, R:0.0105)
Batch 500/537: Loss=0.6119 (C:0.6119, R:0.0105)
Batch 525/537: Loss=0.6628 (C:0.6628, R:0.0105)

============================================================
Epoch 38/300 completed in 27.3s
Train: Loss=0.6378 (C:0.6378, R:0.0105) Ratio=4.43x
Val:   Loss=0.7484 (C:0.7484, R:0.0104) Ratio=3.13x
Reconstruction weight: 0.120
✅ New best model saved (Val Loss: 0.7484)
============================================================

🌍 Updating global dataset at epoch 39
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.397 ± 0.659
    Neg distances: 2.553 ± 1.118
    Separation ratio: 6.43x
    Gap: -4.424
    ✅ Excellent global separation!

Epoch 39 Training
----------------------------------------
Batch   0/537: Loss=0.6476 (C:0.6476, R:0.0105)
Batch  25/537: Loss=0.6649 (C:0.6649, R:0.0105)
Batch  50/537: Loss=0.6655 (C:0.6655, R:0.0105)
Batch  75/537: Loss=0.6329 (C:0.6329, R:0.0105)
Batch 100/537: Loss=0.6200 (C:0.6200, R:0.0105)
Batch 125/537: Loss=0.5930 (C:0.5930, R:0.0105)
Batch 150/537: Loss=0.6541 (C:0.6541, R:0.0105)
Batch 175/537: Loss=0.6251 (C:0.6251, R:0.0105)
Batch 200/537: Loss=0.6663 (C:0.6663, R:0.0105)
Batch 225/537: Loss=0.6968 (C:0.6968, R:0.0105)
Batch 250/537: Loss=0.6454 (C:0.6454, R:0.0105)
Batch 275/537: Loss=0.6385 (C:0.6385, R:0.0105)
Batch 300/537: Loss=0.6722 (C:0.6722, R:0.0105)
Batch 325/537: Loss=0.6587 (C:0.6587, R:0.0105)
Batch 350/537: Loss=0.7023 (C:0.7023, R:0.0105)
Batch 375/537: Loss=0.6820 (C:0.6820, R:0.0105)
Batch 400/537: Loss=0.6692 (C:0.6692, R:0.0105)
Batch 425/537: Loss=0.6365 (C:0.6365, R:0.0105)
Batch 450/537: Loss=0.6788 (C:0.6788, R:0.0105)
Batch 475/537: Loss=0.6669 (C:0.6669, R:0.0105)
Batch 500/537: Loss=0.6477 (C:0.6477, R:0.0105)
Batch 525/537: Loss=0.6814 (C:0.6814, R:0.0105)

============================================================
Epoch 39/300 completed in 27.8s
Train: Loss=0.6605 (C:0.6605, R:0.0105) Ratio=4.51x
Val:   Loss=0.7836 (C:0.7836, R:0.0104) Ratio=3.14x
Reconstruction weight: 0.135
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 40
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.366 ± 0.610
    Neg distances: 2.561 ± 1.107
    Separation ratio: 6.99x
    Gap: -4.405
    ✅ Excellent global separation!

Epoch 40 Training
----------------------------------------
Batch   0/537: Loss=0.6279 (C:0.6279, R:0.0105)
Batch  25/537: Loss=0.6317 (C:0.6317, R:0.0105)
Batch  50/537: Loss=0.6027 (C:0.6027, R:0.0105)
Batch  75/537: Loss=0.6212 (C:0.6212, R:0.0105)
Batch 100/537: Loss=0.6396 (C:0.6396, R:0.0105)
Batch 125/537: Loss=0.6649 (C:0.6649, R:0.0105)
Batch 150/537: Loss=0.6779 (C:0.6779, R:0.0105)
Batch 175/537: Loss=0.6324 (C:0.6324, R:0.0105)
Batch 200/537: Loss=0.6291 (C:0.6291, R:0.0105)
Batch 225/537: Loss=0.6488 (C:0.6488, R:0.0105)
Batch 250/537: Loss=0.6285 (C:0.6285, R:0.0105)
Batch 275/537: Loss=0.6826 (C:0.6826, R:0.0105)
Batch 300/537: Loss=0.6092 (C:0.6092, R:0.0105)
Batch 325/537: Loss=0.6645 (C:0.6645, R:0.0105)
Batch 350/537: Loss=0.6510 (C:0.6510, R:0.0105)
Batch 375/537: Loss=0.6340 (C:0.6340, R:0.0105)
Batch 400/537: Loss=0.6492 (C:0.6492, R:0.0105)
Batch 425/537: Loss=0.6267 (C:0.6267, R:0.0105)
Batch 450/537: Loss=0.6351 (C:0.6351, R:0.0105)
Batch 475/537: Loss=0.6585 (C:0.6585, R:0.0105)
Batch 500/537: Loss=0.6106 (C:0.6106, R:0.0105)
Batch 525/537: Loss=0.6549 (C:0.6549, R:0.0105)

============================================================
Epoch 40/300 completed in 27.3s
Train: Loss=0.6359 (C:0.6359, R:0.0105) Ratio=4.51x
Val:   Loss=0.7564 (C:0.7564, R:0.0104) Ratio=3.15x
Reconstruction weight: 0.150
No improvement for 2 epochs
Checkpoint saved at epoch 40
============================================================

🌍 Updating global dataset at epoch 41
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.359 ± 0.606
    Neg distances: 2.566 ± 1.096
    Separation ratio: 7.14x
    Gap: -4.412
    ✅ Excellent global separation!

Epoch 41 Training
----------------------------------------
Batch   0/537: Loss=0.5841 (C:0.5841, R:0.0105)
Batch  25/537: Loss=0.6279 (C:0.6279, R:0.0105)
Batch  50/537: Loss=0.5965 (C:0.5965, R:0.0105)
Batch  75/537: Loss=0.5837 (C:0.5837, R:0.0105)
Batch 100/537: Loss=0.6197 (C:0.6197, R:0.0105)
Batch 125/537: Loss=0.6296 (C:0.6296, R:0.0105)
Batch 150/537: Loss=0.6505 (C:0.6505, R:0.0105)
Batch 175/537: Loss=0.5899 (C:0.5899, R:0.0105)
Batch 200/537: Loss=0.6122 (C:0.6122, R:0.0105)
Batch 225/537: Loss=0.6091 (C:0.6091, R:0.0105)
Batch 250/537: Loss=0.6389 (C:0.6389, R:0.0105)
Batch 275/537: Loss=0.6313 (C:0.6313, R:0.0105)
Batch 300/537: Loss=0.6279 (C:0.6279, R:0.0105)
Batch 325/537: Loss=0.6391 (C:0.6391, R:0.0105)
Batch 350/537: Loss=0.5999 (C:0.5999, R:0.0106)
Batch 375/537: Loss=0.5981 (C:0.5981, R:0.0105)
Batch 400/537: Loss=0.6108 (C:0.6108, R:0.0105)
Batch 425/537: Loss=0.6038 (C:0.6038, R:0.0105)
Batch 450/537: Loss=0.6570 (C:0.6570, R:0.0105)
Batch 475/537: Loss=0.6429 (C:0.6429, R:0.0105)
Batch 500/537: Loss=0.6649 (C:0.6649, R:0.0105)
Batch 525/537: Loss=0.6445 (C:0.6445, R:0.0105)

============================================================
Epoch 41/300 completed in 28.1s
Train: Loss=0.6251 (C:0.6251, R:0.0105) Ratio=4.52x
Val:   Loss=0.7472 (C:0.7472, R:0.0104) Ratio=3.13x
Reconstruction weight: 0.165
✅ New best model saved (Val Loss: 0.7472)
============================================================

🌍 Updating global dataset at epoch 42
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.373 ± 0.654
    Neg distances: 2.550 ± 1.110
    Separation ratio: 6.84x
    Gap: -4.378
    ✅ Excellent global separation!

Epoch 42 Training
----------------------------------------
Batch   0/537: Loss=0.6009 (C:0.6009, R:0.0105)
Batch  25/537: Loss=0.6178 (C:0.6178, R:0.0105)
Batch  50/537: Loss=0.6341 (C:0.6341, R:0.0105)
Batch  75/537: Loss=0.6167 (C:0.6167, R:0.0105)
Batch 100/537: Loss=0.6495 (C:0.6495, R:0.0105)
Batch 125/537: Loss=0.6709 (C:0.6709, R:0.0105)
Batch 150/537: Loss=0.6475 (C:0.6475, R:0.0105)
Batch 175/537: Loss=0.6422 (C:0.6422, R:0.0105)
Batch 200/537: Loss=0.6387 (C:0.6387, R:0.0105)
Batch 225/537: Loss=0.6241 (C:0.6241, R:0.0105)
Batch 250/537: Loss=0.6672 (C:0.6672, R:0.0105)
Batch 275/537: Loss=0.6521 (C:0.6521, R:0.0105)
Batch 300/537: Loss=0.6393 (C:0.6393, R:0.0105)
Batch 325/537: Loss=0.6419 (C:0.6419, R:0.0105)
Batch 350/537: Loss=0.6143 (C:0.6143, R:0.0105)
Batch 375/537: Loss=0.6554 (C:0.6554, R:0.0105)
Batch 400/537: Loss=0.6138 (C:0.6138, R:0.0105)
Batch 425/537: Loss=0.6160 (C:0.6160, R:0.0105)
Batch 450/537: Loss=0.6235 (C:0.6235, R:0.0105)
Batch 475/537: Loss=0.6771 (C:0.6771, R:0.0105)
Batch 500/537: Loss=0.6498 (C:0.6498, R:0.0105)
Batch 525/537: Loss=0.6424 (C:0.6424, R:0.0105)

============================================================
Epoch 42/300 completed in 27.3s
Train: Loss=0.6380 (C:0.6380, R:0.0105) Ratio=4.49x
Val:   Loss=0.7601 (C:0.7601, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.180
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 43
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.352 ± 0.600
    Neg distances: 2.548 ± 1.097
    Separation ratio: 7.25x
    Gap: -4.388
    ✅ Excellent global separation!

Epoch 43 Training
----------------------------------------
Batch   0/537: Loss=0.5857 (C:0.5857, R:0.0105)
Batch  25/537: Loss=0.6185 (C:0.6185, R:0.0105)
Batch  50/537: Loss=0.6483 (C:0.6483, R:0.0105)
Batch  75/537: Loss=0.6095 (C:0.6095, R:0.0105)
Batch 100/537: Loss=0.6207 (C:0.6207, R:0.0105)
Batch 125/537: Loss=0.6229 (C:0.6229, R:0.0105)
Batch 150/537: Loss=0.6251 (C:0.6251, R:0.0105)
Batch 175/537: Loss=0.6407 (C:0.6407, R:0.0105)
Batch 200/537: Loss=0.5995 (C:0.5995, R:0.0105)
Batch 225/537: Loss=0.6167 (C:0.6167, R:0.0105)
Batch 250/537: Loss=0.5990 (C:0.5990, R:0.0105)
Batch 275/537: Loss=0.6388 (C:0.6388, R:0.0105)
Batch 300/537: Loss=0.6177 (C:0.6177, R:0.0105)
Batch 325/537: Loss=0.6364 (C:0.6364, R:0.0105)
Batch 350/537: Loss=0.6367 (C:0.6367, R:0.0105)
Batch 375/537: Loss=0.5943 (C:0.5943, R:0.0105)
Batch 400/537: Loss=0.6204 (C:0.6204, R:0.0105)
Batch 425/537: Loss=0.6318 (C:0.6318, R:0.0105)
Batch 450/537: Loss=0.6412 (C:0.6412, R:0.0105)
Batch 475/537: Loss=0.6363 (C:0.6363, R:0.0105)
Batch 500/537: Loss=0.6444 (C:0.6444, R:0.0105)
Batch 525/537: Loss=0.6225 (C:0.6225, R:0.0105)

============================================================
Epoch 43/300 completed in 27.5s
Train: Loss=0.6198 (C:0.6198, R:0.0105) Ratio=4.52x
Val:   Loss=0.7390 (C:0.7390, R:0.0104) Ratio=3.15x
Reconstruction weight: 0.195
✅ New best model saved (Val Loss: 0.7390)
============================================================

🌍 Updating global dataset at epoch 44
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.382 ± 0.632
    Neg distances: 2.555 ± 1.112
    Separation ratio: 6.70x
    Gap: -4.394
    ✅ Excellent global separation!

Epoch 44 Training
----------------------------------------
Batch   0/537: Loss=0.6402 (C:0.6402, R:0.0105)
Batch  25/537: Loss=0.6264 (C:0.6264, R:0.0105)
Batch  50/537: Loss=0.6349 (C:0.6349, R:0.0105)
Batch  75/537: Loss=0.6140 (C:0.6140, R:0.0105)
Batch 100/537: Loss=0.6327 (C:0.6327, R:0.0105)
Batch 125/537: Loss=0.6779 (C:0.6779, R:0.0105)
Batch 150/537: Loss=0.6310 (C:0.6310, R:0.0105)
Batch 175/537: Loss=0.6372 (C:0.6372, R:0.0105)
Batch 200/537: Loss=0.5960 (C:0.5960, R:0.0105)
Batch 225/537: Loss=0.6413 (C:0.6413, R:0.0105)
Batch 250/537: Loss=0.6665 (C:0.6665, R:0.0105)
Batch 275/537: Loss=0.6528 (C:0.6528, R:0.0105)
Batch 300/537: Loss=0.6284 (C:0.6284, R:0.0105)
Batch 325/537: Loss=0.6507 (C:0.6507, R:0.0105)
Batch 350/537: Loss=0.6365 (C:0.6365, R:0.0106)
Batch 375/537: Loss=0.6456 (C:0.6456, R:0.0105)
Batch 400/537: Loss=0.6241 (C:0.6241, R:0.0105)
Batch 425/537: Loss=0.6391 (C:0.6391, R:0.0105)
Batch 450/537: Loss=0.6852 (C:0.6852, R:0.0105)
Batch 475/537: Loss=0.6367 (C:0.6367, R:0.0105)
Batch 500/537: Loss=0.6155 (C:0.6155, R:0.0105)
Batch 525/537: Loss=0.6412 (C:0.6412, R:0.0105)

============================================================
Epoch 44/300 completed in 27.5s
Train: Loss=0.6377 (C:0.6377, R:0.0105) Ratio=4.56x
Val:   Loss=0.7669 (C:0.7669, R:0.0104) Ratio=3.16x
Reconstruction weight: 0.210
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 45
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.370 ± 0.628
    Neg distances: 2.596 ± 1.120
    Separation ratio: 7.02x
    Gap: -4.466
    ✅ Excellent global separation!

Epoch 45 Training
----------------------------------------
Batch   0/537: Loss=0.5775 (C:0.5775, R:0.0105)
Batch  25/537: Loss=0.6394 (C:0.6394, R:0.0105)
Batch  50/537: Loss=0.6363 (C:0.6363, R:0.0106)
Batch  75/537: Loss=0.6128 (C:0.6128, R:0.0105)
Batch 100/537: Loss=0.6210 (C:0.6210, R:0.0105)
Batch 125/537: Loss=0.6291 (C:0.6291, R:0.0105)
Batch 150/537: Loss=0.5748 (C:0.5748, R:0.0105)
Batch 175/537: Loss=0.6756 (C:0.6756, R:0.0105)
Batch 200/537: Loss=0.6102 (C:0.6102, R:0.0105)
Batch 225/537: Loss=0.6217 (C:0.6217, R:0.0104)
Batch 250/537: Loss=0.6230 (C:0.6230, R:0.0105)
Batch 275/537: Loss=0.6128 (C:0.6128, R:0.0105)
Batch 300/537: Loss=0.6144 (C:0.6144, R:0.0105)
Batch 325/537: Loss=0.6144 (C:0.6144, R:0.0105)
Batch 350/537: Loss=0.6528 (C:0.6528, R:0.0105)
Batch 375/537: Loss=0.6437 (C:0.6437, R:0.0105)
Batch 400/537: Loss=0.6227 (C:0.6227, R:0.0105)
Batch 425/537: Loss=0.6192 (C:0.6192, R:0.0105)
Batch 450/537: Loss=0.6271 (C:0.6271, R:0.0105)
Batch 475/537: Loss=0.6457 (C:0.6457, R:0.0105)
Batch 500/537: Loss=0.6569 (C:0.6569, R:0.0105)
Batch 525/537: Loss=0.6329 (C:0.6329, R:0.0105)

============================================================
Epoch 45/300 completed in 27.7s
Train: Loss=0.6234 (C:0.6234, R:0.0105) Ratio=4.62x
Val:   Loss=0.7656 (C:0.7656, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.225
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 46
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.383 ± 0.655
    Neg distances: 2.610 ± 1.130
    Separation ratio: 6.82x
    Gap: -4.509
    ✅ Excellent global separation!

Epoch 46 Training
----------------------------------------
Batch   0/537: Loss=0.6642 (C:0.6642, R:0.0105)
Batch  25/537: Loss=0.6261 (C:0.6261, R:0.0105)
Batch  50/537: Loss=0.5967 (C:0.5967, R:0.0105)
Batch  75/537: Loss=0.6428 (C:0.6428, R:0.0105)
Batch 100/537: Loss=0.5829 (C:0.5829, R:0.0105)
Batch 125/537: Loss=0.6099 (C:0.6099, R:0.0105)
Batch 150/537: Loss=0.6338 (C:0.6338, R:0.0105)
Batch 175/537: Loss=0.5998 (C:0.5998, R:0.0105)
Batch 200/537: Loss=0.6412 (C:0.6412, R:0.0105)
Batch 225/537: Loss=0.6232 (C:0.6232, R:0.0105)
Batch 250/537: Loss=0.6169 (C:0.6169, R:0.0105)
Batch 275/537: Loss=0.6497 (C:0.6497, R:0.0105)
Batch 300/537: Loss=0.6385 (C:0.6385, R:0.0105)
Batch 325/537: Loss=0.6489 (C:0.6489, R:0.0105)
Batch 350/537: Loss=0.6231 (C:0.6231, R:0.0105)
Batch 375/537: Loss=0.6201 (C:0.6201, R:0.0105)
Batch 400/537: Loss=0.6207 (C:0.6207, R:0.0105)
Batch 425/537: Loss=0.6536 (C:0.6536, R:0.0105)
Batch 450/537: Loss=0.6611 (C:0.6611, R:0.0105)
Batch 475/537: Loss=0.6389 (C:0.6389, R:0.0105)
Batch 500/537: Loss=0.6417 (C:0.6417, R:0.0105)
Batch 525/537: Loss=0.6212 (C:0.6212, R:0.0105)

============================================================
Epoch 46/300 completed in 27.4s
Train: Loss=0.6308 (C:0.6308, R:0.0105) Ratio=4.61x
Val:   Loss=0.7698 (C:0.7698, R:0.0104) Ratio=3.13x
Reconstruction weight: 0.240
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 47
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.359 ± 0.634
    Neg distances: 2.634 ± 1.131
    Separation ratio: 7.34x
    Gap: -4.585
    ✅ Excellent global separation!

Epoch 47 Training
----------------------------------------
Batch   0/537: Loss=0.6622 (C:0.6622, R:0.0105)
Batch  25/537: Loss=0.5672 (C:0.5672, R:0.0105)
Batch  50/537: Loss=0.5887 (C:0.5887, R:0.0105)
Batch  75/537: Loss=0.6172 (C:0.6172, R:0.0105)
Batch 100/537: Loss=0.6132 (C:0.6132, R:0.0105)
Batch 125/537: Loss=0.6123 (C:0.6123, R:0.0105)
Batch 150/537: Loss=0.6388 (C:0.6388, R:0.0105)
Batch 175/537: Loss=0.5650 (C:0.5650, R:0.0105)
Batch 200/537: Loss=0.5895 (C:0.5895, R:0.0105)
Batch 225/537: Loss=0.5922 (C:0.5922, R:0.0105)
Batch 250/537: Loss=0.5971 (C:0.5971, R:0.0105)
Batch 275/537: Loss=0.5929 (C:0.5929, R:0.0105)
Batch 300/537: Loss=0.6534 (C:0.6534, R:0.0105)
Batch 325/537: Loss=0.5580 (C:0.5580, R:0.0105)
Batch 350/537: Loss=0.5801 (C:0.5801, R:0.0105)
Batch 375/537: Loss=0.6249 (C:0.6249, R:0.0105)
Batch 400/537: Loss=0.6097 (C:0.6097, R:0.0105)
Batch 425/537: Loss=0.5751 (C:0.5751, R:0.0105)
Batch 450/537: Loss=0.6030 (C:0.6030, R:0.0106)
Batch 475/537: Loss=0.6272 (C:0.6272, R:0.0105)
Batch 500/537: Loss=0.5993 (C:0.5993, R:0.0105)
Batch 525/537: Loss=0.6103 (C:0.6103, R:0.0105)

============================================================
Epoch 47/300 completed in 28.2s
Train: Loss=0.6092 (C:0.6092, R:0.0105) Ratio=4.75x
Val:   Loss=0.7426 (C:0.7426, R:0.0104) Ratio=3.14x
Reconstruction weight: 0.255
No improvement for 4 epochs
============================================================

🌍 Updating global dataset at epoch 48
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.353 ± 0.635
    Neg distances: 2.623 ± 1.123
    Separation ratio: 7.43x
    Gap: -4.377
    ✅ Excellent global separation!

Epoch 48 Training
----------------------------------------
Batch   0/537: Loss=0.5745 (C:0.5745, R:0.0105)
Batch  25/537: Loss=0.5798 (C:0.5798, R:0.0105)
Batch  50/537: Loss=0.5928 (C:0.5928, R:0.0105)
Batch  75/537: Loss=0.6059 (C:0.6059, R:0.0105)
Batch 100/537: Loss=0.6087 (C:0.6087, R:0.0105)
Batch 125/537: Loss=0.6124 (C:0.6124, R:0.0105)
Batch 150/537: Loss=0.5623 (C:0.5623, R:0.0105)
Batch 175/537: Loss=0.5422 (C:0.5422, R:0.0105)
Batch 200/537: Loss=0.5944 (C:0.5944, R:0.0105)
Batch 225/537: Loss=0.5868 (C:0.5868, R:0.0105)
Batch 250/537: Loss=0.6132 (C:0.6132, R:0.0105)
Batch 275/537: Loss=0.5984 (C:0.5984, R:0.0105)
Batch 300/537: Loss=0.5964 (C:0.5964, R:0.0105)
Batch 325/537: Loss=0.5884 (C:0.5884, R:0.0105)
Batch 350/537: Loss=0.6083 (C:0.6083, R:0.0105)
Batch 375/537: Loss=0.5998 (C:0.5998, R:0.0105)
Batch 400/537: Loss=0.5918 (C:0.5918, R:0.0105)
Batch 425/537: Loss=0.6103 (C:0.6103, R:0.0105)
Batch 450/537: Loss=0.5943 (C:0.5943, R:0.0105)
Batch 475/537: Loss=0.5792 (C:0.5792, R:0.0105)
Batch 500/537: Loss=0.6590 (C:0.6590, R:0.0105)
Batch 525/537: Loss=0.5992 (C:0.5992, R:0.0106)

============================================================
Epoch 48/300 completed in 27.3s
Train: Loss=0.6025 (C:0.6025, R:0.0105) Ratio=4.75x
Val:   Loss=0.7425 (C:0.7425, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.270
No improvement for 5 epochs
============================================================

🌍 Updating global dataset at epoch 49
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.350 ± 0.623
    Neg distances: 2.620 ± 1.110
    Separation ratio: 7.50x
    Gap: -4.491
    ✅ Excellent global separation!

Epoch 49 Training
----------------------------------------
Batch   0/537: Loss=0.5727 (C:0.5727, R:0.0105)
Batch  25/537: Loss=0.5705 (C:0.5705, R:0.0105)
Batch  50/537: Loss=0.5815 (C:0.5815, R:0.0105)
Batch  75/537: Loss=0.5973 (C:0.5973, R:0.0105)
Batch 100/537: Loss=0.5352 (C:0.5352, R:0.0106)
Batch 125/537: Loss=0.6080 (C:0.6080, R:0.0105)
Batch 150/537: Loss=0.6091 (C:0.6091, R:0.0105)
Batch 175/537: Loss=0.5789 (C:0.5789, R:0.0105)
Batch 200/537: Loss=0.5988 (C:0.5988, R:0.0105)
Batch 225/537: Loss=0.6041 (C:0.6041, R:0.0105)
Batch 250/537: Loss=0.5806 (C:0.5806, R:0.0105)
Batch 275/537: Loss=0.5591 (C:0.5591, R:0.0105)
Batch 300/537: Loss=0.6093 (C:0.6093, R:0.0105)
Batch 325/537: Loss=0.5824 (C:0.5824, R:0.0106)
Batch 350/537: Loss=0.6108 (C:0.6108, R:0.0105)
Batch 375/537: Loss=0.5773 (C:0.5773, R:0.0105)
Batch 400/537: Loss=0.6269 (C:0.6269, R:0.0105)
Batch 425/537: Loss=0.6134 (C:0.6134, R:0.0105)
Batch 450/537: Loss=0.6165 (C:0.6165, R:0.0105)
Batch 475/537: Loss=0.6149 (C:0.6149, R:0.0106)
Batch 500/537: Loss=0.5800 (C:0.5800, R:0.0105)
Batch 525/537: Loss=0.6024 (C:0.6024, R:0.0105)

============================================================
Epoch 49/300 completed in 28.4s
Train: Loss=0.5990 (C:0.5990, R:0.0105) Ratio=4.77x
Val:   Loss=0.7386 (C:0.7386, R:0.0104) Ratio=3.12x
Reconstruction weight: 0.285
✅ New best model saved (Val Loss: 0.7386)
============================================================

🌍 Updating global dataset at epoch 50
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.341 ± 0.582
    Neg distances: 2.628 ± 1.108
    Separation ratio: 7.72x
    Gap: -4.494
    ✅ Excellent global separation!

Epoch 50 Training
----------------------------------------
Batch   0/537: Loss=0.5417 (C:0.5417, R:0.0105)
Batch  25/537: Loss=0.5638 (C:0.5638, R:0.0105)
Batch  50/537: Loss=0.5673 (C:0.5673, R:0.0105)
Batch  75/537: Loss=0.6215 (C:0.6215, R:0.0105)
Batch 100/537: Loss=0.5701 (C:0.5701, R:0.0105)
Batch 125/537: Loss=0.5441 (C:0.5441, R:0.0105)
Batch 150/537: Loss=0.5820 (C:0.5820, R:0.0106)
Batch 175/537: Loss=0.5808 (C:0.5808, R:0.0105)
Batch 200/537: Loss=0.5844 (C:0.5844, R:0.0105)
Batch 225/537: Loss=0.6090 (C:0.6090, R:0.0105)
Batch 250/537: Loss=0.5985 (C:0.5985, R:0.0105)
Batch 275/537: Loss=0.5703 (C:0.5703, R:0.0105)
Batch 300/537: Loss=0.5750 (C:0.5750, R:0.0105)
Batch 325/537: Loss=0.5873 (C:0.5873, R:0.0105)
Batch 350/537: Loss=0.6190 (C:0.6190, R:0.0105)
Batch 375/537: Loss=0.6004 (C:0.6004, R:0.0105)
Batch 400/537: Loss=0.5935 (C:0.5935, R:0.0105)
Batch 425/537: Loss=0.5816 (C:0.5816, R:0.0105)
Batch 450/537: Loss=0.6089 (C:0.6089, R:0.0105)
Batch 475/537: Loss=0.6287 (C:0.6287, R:0.0105)
Batch 500/537: Loss=0.5917 (C:0.5917, R:0.0105)
Batch 525/537: Loss=0.6177 (C:0.6177, R:0.0105)

============================================================
Epoch 50/300 completed in 28.2s
Train: Loss=0.5893 (C:0.5893, R:0.0105) Ratio=4.79x
Val:   Loss=0.7254 (C:0.7254, R:0.0104) Ratio=3.16x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.7254)
============================================================

🌍 Updating global dataset at epoch 51
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.348 ± 0.630
    Neg distances: 2.645 ± 1.128
    Separation ratio: 7.61x
    Gap: -4.518
    ✅ Excellent global separation!

Epoch 51 Training
----------------------------------------
Batch   0/537: Loss=0.5809 (C:0.5809, R:0.0105)
Batch  25/537: Loss=0.5731 (C:0.5731, R:0.0105)
Batch  50/537: Loss=0.5895 (C:0.5895, R:0.0105)
Batch  75/537: Loss=0.5791 (C:0.5791, R:0.0105)
Batch 100/537: Loss=0.5700 (C:0.5700, R:0.0105)
Batch 125/537: Loss=0.5490 (C:0.5490, R:0.0105)
Batch 150/537: Loss=0.6015 (C:0.6015, R:0.0105)
Batch 175/537: Loss=0.5964 (C:0.5964, R:0.0105)
Batch 200/537: Loss=0.5837 (C:0.5837, R:0.0105)
Batch 225/537: Loss=0.6117 (C:0.6117, R:0.0106)
Batch 250/537: Loss=0.5906 (C:0.5906, R:0.0105)
Batch 275/537: Loss=0.6058 (C:0.6058, R:0.0105)
Batch 300/537: Loss=0.6141 (C:0.6141, R:0.0105)
Batch 325/537: Loss=0.6182 (C:0.6182, R:0.0105)
Batch 350/537: Loss=0.5995 (C:0.5995, R:0.0105)
Batch 375/537: Loss=0.6314 (C:0.6314, R:0.0105)
Batch 400/537: Loss=0.6105 (C:0.6105, R:0.0105)
Batch 425/537: Loss=0.5985 (C:0.5985, R:0.0105)
Batch 450/537: Loss=0.5959 (C:0.5959, R:0.0105)
Batch 475/537: Loss=0.5984 (C:0.5984, R:0.0105)
Batch 500/537: Loss=0.6217 (C:0.6217, R:0.0105)
Batch 525/537: Loss=0.6235 (C:0.6235, R:0.0105)

============================================================
Epoch 51/300 completed in 27.7s
Train: Loss=0.5918 (C:0.5918, R:0.0105) Ratio=4.71x
Val:   Loss=0.7359 (C:0.7359, R:0.0104) Ratio=3.13x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 52
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.340 ± 0.609
    Neg distances: 2.637 ± 1.122
    Separation ratio: 7.76x
    Gap: -4.558
    ✅ Excellent global separation!

Epoch 52 Training
----------------------------------------
Batch   0/537: Loss=0.5329 (C:0.5329, R:0.0106)
Batch  25/537: Loss=0.5697 (C:0.5697, R:0.0105)
Batch  50/537: Loss=0.6112 (C:0.6112, R:0.0105)
Batch  75/537: Loss=0.6106 (C:0.6106, R:0.0105)
Batch 100/537: Loss=0.5847 (C:0.5847, R:0.0105)
Batch 125/537: Loss=0.5462 (C:0.5462, R:0.0105)
Batch 150/537: Loss=0.5960 (C:0.5960, R:0.0105)
Batch 175/537: Loss=0.5750 (C:0.5750, R:0.0104)
Batch 200/537: Loss=0.5830 (C:0.5830, R:0.0105)
Batch 225/537: Loss=0.5808 (C:0.5808, R:0.0105)
Batch 250/537: Loss=0.6127 (C:0.6127, R:0.0105)
Batch 275/537: Loss=0.5987 (C:0.5987, R:0.0105)
Batch 300/537: Loss=0.6129 (C:0.6129, R:0.0105)
Batch 325/537: Loss=0.5513 (C:0.5513, R:0.0105)
Batch 350/537: Loss=0.5963 (C:0.5963, R:0.0105)
Batch 375/537: Loss=0.5863 (C:0.5863, R:0.0105)
Batch 400/537: Loss=0.6121 (C:0.6121, R:0.0105)
Batch 425/537: Loss=0.6224 (C:0.6224, R:0.0105)
Batch 450/537: Loss=0.5753 (C:0.5753, R:0.0105)
Batch 475/537: Loss=0.5989 (C:0.5989, R:0.0105)
Batch 500/537: Loss=0.5998 (C:0.5998, R:0.0105)
Batch 525/537: Loss=0.5530 (C:0.5530, R:0.0105)

============================================================
Epoch 52/300 completed in 27.3s
Train: Loss=0.5854 (C:0.5854, R:0.0105) Ratio=4.87x
Val:   Loss=0.7412 (C:0.7412, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 53
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.332 ± 0.604
    Neg distances: 2.630 ± 1.111
    Separation ratio: 7.93x
    Gap: -4.471
    ✅ Excellent global separation!

Epoch 53 Training
----------------------------------------
Batch   0/537: Loss=0.5799 (C:0.5799, R:0.0105)
Batch  25/537: Loss=0.5333 (C:0.5333, R:0.0105)
Batch  50/537: Loss=0.5573 (C:0.5573, R:0.0106)
Batch  75/537: Loss=0.5772 (C:0.5772, R:0.0105)
Batch 100/537: Loss=0.5640 (C:0.5640, R:0.0105)
Batch 125/537: Loss=0.5755 (C:0.5755, R:0.0105)
Batch 150/537: Loss=0.5712 (C:0.5712, R:0.0105)
Batch 175/537: Loss=0.5768 (C:0.5768, R:0.0105)
Batch 200/537: Loss=0.5804 (C:0.5804, R:0.0105)
Batch 225/537: Loss=0.5546 (C:0.5546, R:0.0106)
Batch 250/537: Loss=0.5310 (C:0.5310, R:0.0105)
Batch 275/537: Loss=0.5517 (C:0.5517, R:0.0105)
Batch 300/537: Loss=0.5784 (C:0.5784, R:0.0105)
Batch 325/537: Loss=0.5942 (C:0.5942, R:0.0105)
Batch 350/537: Loss=0.5971 (C:0.5971, R:0.0105)
Batch 375/537: Loss=0.6098 (C:0.6098, R:0.0105)
Batch 400/537: Loss=0.5636 (C:0.5636, R:0.0105)
Batch 425/537: Loss=0.6245 (C:0.6245, R:0.0105)
Batch 450/537: Loss=0.6122 (C:0.6122, R:0.0105)
Batch 475/537: Loss=0.6006 (C:0.6006, R:0.0105)
Batch 500/537: Loss=0.5942 (C:0.5942, R:0.0105)
Batch 525/537: Loss=0.5802 (C:0.5802, R:0.0106)

============================================================
Epoch 53/300 completed in 28.4s
Train: Loss=0.5785 (C:0.5785, R:0.0105) Ratio=4.84x
Val:   Loss=0.7267 (C:0.7267, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 54
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.333 ± 0.603
    Neg distances: 2.641 ± 1.108
    Separation ratio: 7.94x
    Gap: -4.601
    ✅ Excellent global separation!

Epoch 54 Training
----------------------------------------
Batch   0/537: Loss=0.5880 (C:0.5880, R:0.0105)
Batch  25/537: Loss=0.5912 (C:0.5912, R:0.0105)
Batch  50/537: Loss=0.5602 (C:0.5602, R:0.0105)
Batch  75/537: Loss=0.5524 (C:0.5524, R:0.0105)
Batch 100/537: Loss=0.5619 (C:0.5619, R:0.0105)
Batch 125/537: Loss=0.5655 (C:0.5655, R:0.0105)
Batch 150/537: Loss=0.6087 (C:0.6087, R:0.0105)
Batch 175/537: Loss=0.5901 (C:0.5901, R:0.0105)
Batch 200/537: Loss=0.5644 (C:0.5644, R:0.0105)
Batch 225/537: Loss=0.5509 (C:0.5509, R:0.0105)
Batch 250/537: Loss=0.5442 (C:0.5442, R:0.0105)
Batch 275/537: Loss=0.5893 (C:0.5893, R:0.0105)
Batch 300/537: Loss=0.5320 (C:0.5320, R:0.0105)
Batch 325/537: Loss=0.5662 (C:0.5662, R:0.0105)
Batch 350/537: Loss=0.5559 (C:0.5559, R:0.0105)
Batch 375/537: Loss=0.5808 (C:0.5808, R:0.0105)
Batch 400/537: Loss=0.5952 (C:0.5952, R:0.0105)
Batch 425/537: Loss=0.5795 (C:0.5795, R:0.0105)
Batch 450/537: Loss=0.5403 (C:0.5403, R:0.0105)
Batch 475/537: Loss=0.5638 (C:0.5638, R:0.0105)
Batch 500/537: Loss=0.5777 (C:0.5777, R:0.0105)
Batch 525/537: Loss=0.5745 (C:0.5745, R:0.0105)

============================================================
Epoch 54/300 completed in 27.2s
Train: Loss=0.5752 (C:0.5752, R:0.0105) Ratio=4.94x
Val:   Loss=0.7309 (C:0.7309, R:0.0104) Ratio=3.13x
Reconstruction weight: 0.300
No improvement for 4 epochs
============================================================

🌍 Updating global dataset at epoch 55
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.343 ± 0.605
    Neg distances: 2.623 ± 1.118
    Separation ratio: 7.64x
    Gap: -4.459
    ✅ Excellent global separation!

Epoch 55 Training
----------------------------------------
Batch   0/537: Loss=0.5807 (C:0.5807, R:0.0105)
Batch  25/537: Loss=0.5883 (C:0.5883, R:0.0105)
Batch  50/537: Loss=0.6098 (C:0.6098, R:0.0105)
Batch  75/537: Loss=0.5882 (C:0.5882, R:0.0105)
Batch 100/537: Loss=0.6230 (C:0.6230, R:0.0105)
Batch 125/537: Loss=0.5834 (C:0.5834, R:0.0105)
Batch 150/537: Loss=0.5581 (C:0.5581, R:0.0105)
Batch 175/537: Loss=0.5768 (C:0.5768, R:0.0105)
Batch 200/537: Loss=0.5797 (C:0.5797, R:0.0105)
Batch 225/537: Loss=0.6274 (C:0.6274, R:0.0105)
Batch 250/537: Loss=0.5865 (C:0.5865, R:0.0105)
Batch 275/537: Loss=0.6301 (C:0.6301, R:0.0105)
Batch 300/537: Loss=0.5429 (C:0.5429, R:0.0105)
Batch 325/537: Loss=0.5825 (C:0.5825, R:0.0105)
Batch 350/537: Loss=0.5987 (C:0.5987, R:0.0105)
Batch 375/537: Loss=0.5778 (C:0.5778, R:0.0105)
Batch 400/537: Loss=0.5541 (C:0.5541, R:0.0105)
Batch 425/537: Loss=0.5625 (C:0.5625, R:0.0105)
Batch 450/537: Loss=0.6266 (C:0.6266, R:0.0105)
Batch 475/537: Loss=0.5692 (C:0.5692, R:0.0105)
Batch 500/537: Loss=0.5974 (C:0.5974, R:0.0105)
Batch 525/537: Loss=0.5680 (C:0.5680, R:0.0105)

============================================================
Epoch 55/300 completed in 27.6s
Train: Loss=0.5858 (C:0.5858, R:0.0105) Ratio=4.92x
Val:   Loss=0.7385 (C:0.7385, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
No improvement for 5 epochs
============================================================

🌍 Updating global dataset at epoch 56
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.333 ± 0.611
    Neg distances: 2.676 ± 1.122
    Separation ratio: 8.03x
    Gap: -4.641
    ✅ Excellent global separation!

Epoch 56 Training
----------------------------------------
Batch   0/537: Loss=0.5752 (C:0.5752, R:0.0105)
Batch  25/537: Loss=0.5856 (C:0.5856, R:0.0105)
Batch  50/537: Loss=0.5646 (C:0.5646, R:0.0105)
Batch  75/537: Loss=0.5367 (C:0.5367, R:0.0105)
Batch 100/537: Loss=0.5588 (C:0.5588, R:0.0105)
Batch 125/537: Loss=0.5707 (C:0.5707, R:0.0105)
Batch 150/537: Loss=0.5509 (C:0.5509, R:0.0105)
Batch 175/537: Loss=0.5542 (C:0.5542, R:0.0105)
Batch 200/537: Loss=0.5637 (C:0.5637, R:0.0105)
Batch 225/537: Loss=0.5505 (C:0.5505, R:0.0105)
Batch 250/537: Loss=0.5492 (C:0.5492, R:0.0105)
Batch 275/537: Loss=0.5550 (C:0.5550, R:0.0105)
Batch 300/537: Loss=0.5853 (C:0.5853, R:0.0105)
Batch 325/537: Loss=0.5939 (C:0.5939, R:0.0105)
Batch 350/537: Loss=0.5121 (C:0.5121, R:0.0105)
Batch 375/537: Loss=0.5764 (C:0.5764, R:0.0105)
Batch 400/537: Loss=0.5553 (C:0.5553, R:0.0105)
Batch 425/537: Loss=0.5759 (C:0.5759, R:0.0105)
Batch 450/537: Loss=0.5571 (C:0.5571, R:0.0105)
Batch 475/537: Loss=0.5563 (C:0.5563, R:0.0105)
Batch 500/537: Loss=0.5782 (C:0.5782, R:0.0105)
Batch 525/537: Loss=0.5699 (C:0.5699, R:0.0104)

============================================================
Epoch 56/300 completed in 28.1s
Train: Loss=0.5710 (C:0.5710, R:0.0105) Ratio=5.01x
Val:   Loss=0.7268 (C:0.7268, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.300
No improvement for 6 epochs
============================================================

🌍 Updating global dataset at epoch 57
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.344 ± 0.643
    Neg distances: 2.666 ± 1.140
    Separation ratio: 7.74x
    Gap: -4.562
    ✅ Excellent global separation!

Epoch 57 Training
----------------------------------------
Batch   0/537: Loss=0.5462 (C:0.5462, R:0.0105)
Batch  25/537: Loss=0.6015 (C:0.6015, R:0.0105)
Batch  50/537: Loss=0.5724 (C:0.5724, R:0.0105)
Batch  75/537: Loss=0.5649 (C:0.5649, R:0.0105)
Batch 100/537: Loss=0.6180 (C:0.6180, R:0.0105)
Batch 125/537: Loss=0.5773 (C:0.5773, R:0.0105)
Batch 150/537: Loss=0.5690 (C:0.5690, R:0.0105)
Batch 175/537: Loss=0.5673 (C:0.5673, R:0.0105)
Batch 200/537: Loss=0.5830 (C:0.5830, R:0.0105)
Batch 225/537: Loss=0.5853 (C:0.5853, R:0.0105)
Batch 250/537: Loss=0.5792 (C:0.5792, R:0.0105)
Batch 275/537: Loss=0.5797 (C:0.5797, R:0.0105)
Batch 300/537: Loss=0.5702 (C:0.5702, R:0.0105)
Batch 325/537: Loss=0.6033 (C:0.6033, R:0.0105)
Batch 350/537: Loss=0.5596 (C:0.5596, R:0.0105)
Batch 375/537: Loss=0.5632 (C:0.5632, R:0.0105)
Batch 400/537: Loss=0.5739 (C:0.5739, R:0.0106)
Batch 425/537: Loss=0.5968 (C:0.5968, R:0.0105)
Batch 450/537: Loss=0.6075 (C:0.6075, R:0.0105)
Batch 475/537: Loss=0.5651 (C:0.5651, R:0.0105)
Batch 500/537: Loss=0.5898 (C:0.5898, R:0.0105)
Batch 525/537: Loss=0.6484 (C:0.6484, R:0.0105)

============================================================
Epoch 57/300 completed in 27.6s
Train: Loss=0.5806 (C:0.5806, R:0.0105) Ratio=4.92x
Val:   Loss=0.7323 (C:0.7323, R:0.0104) Ratio=3.13x
Reconstruction weight: 0.300
No improvement for 7 epochs
============================================================

🌍 Updating global dataset at epoch 58
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.319 ± 0.599
    Neg distances: 2.652 ± 1.113
    Separation ratio: 8.32x
    Gap: -4.502
    ✅ Excellent global separation!

Epoch 58 Training
----------------------------------------
Batch   0/537: Loss=0.5363 (C:0.5363, R:0.0105)
Batch  25/537: Loss=0.5560 (C:0.5560, R:0.0105)
Batch  50/537: Loss=0.5627 (C:0.5627, R:0.0105)
Batch  75/537: Loss=0.5482 (C:0.5482, R:0.0105)
Batch 100/537: Loss=0.5716 (C:0.5716, R:0.0105)
Batch 125/537: Loss=0.5685 (C:0.5685, R:0.0105)
Batch 150/537: Loss=0.5430 (C:0.5430, R:0.0105)
Batch 175/537: Loss=0.5489 (C:0.5489, R:0.0105)
Batch 200/537: Loss=0.5126 (C:0.5126, R:0.0106)
Batch 225/537: Loss=0.5686 (C:0.5686, R:0.0105)
Batch 250/537: Loss=0.5579 (C:0.5579, R:0.0106)
Batch 275/537: Loss=0.5501 (C:0.5501, R:0.0105)
Batch 300/537: Loss=0.5387 (C:0.5387, R:0.0105)
Batch 325/537: Loss=0.5434 (C:0.5434, R:0.0105)
Batch 350/537: Loss=0.5604 (C:0.5604, R:0.0105)
Batch 375/537: Loss=0.5706 (C:0.5706, R:0.0105)
Batch 400/537: Loss=0.5562 (C:0.5562, R:0.0105)
Batch 425/537: Loss=0.5545 (C:0.5545, R:0.0105)
Batch 450/537: Loss=0.5203 (C:0.5203, R:0.0105)
Batch 475/537: Loss=0.5707 (C:0.5707, R:0.0105)
Batch 500/537: Loss=0.5267 (C:0.5267, R:0.0105)
Batch 525/537: Loss=0.5489 (C:0.5489, R:0.0105)

============================================================
Epoch 58/300 completed in 27.2s
Train: Loss=0.5593 (C:0.5593, R:0.0105) Ratio=4.99x
Val:   Loss=0.7242 (C:0.7242, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.7242)
============================================================

🌍 Updating global dataset at epoch 59
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.334 ± 0.617
    Neg distances: 2.666 ± 1.123
    Separation ratio: 7.98x
    Gap: -4.527
    ✅ Excellent global separation!

Epoch 59 Training
----------------------------------------
Batch   0/537: Loss=0.5676 (C:0.5676, R:0.0105)
Batch  25/537: Loss=0.5941 (C:0.5941, R:0.0105)
Batch  50/537: Loss=0.5282 (C:0.5282, R:0.0105)
Batch  75/537: Loss=0.5450 (C:0.5450, R:0.0105)
Batch 100/537: Loss=0.5530 (C:0.5530, R:0.0105)
Batch 125/537: Loss=0.5531 (C:0.5531, R:0.0105)
Batch 150/537: Loss=0.5641 (C:0.5641, R:0.0105)
Batch 175/537: Loss=0.5708 (C:0.5708, R:0.0105)
Batch 200/537: Loss=0.5619 (C:0.5619, R:0.0105)
Batch 225/537: Loss=0.5776 (C:0.5776, R:0.0105)
Batch 250/537: Loss=0.5642 (C:0.5642, R:0.0105)
Batch 275/537: Loss=0.5521 (C:0.5521, R:0.0105)
Batch 300/537: Loss=0.5779 (C:0.5779, R:0.0105)
Batch 325/537: Loss=0.5518 (C:0.5518, R:0.0105)
Batch 350/537: Loss=0.5805 (C:0.5805, R:0.0105)
Batch 375/537: Loss=0.5681 (C:0.5681, R:0.0105)
Batch 400/537: Loss=0.5916 (C:0.5916, R:0.0105)
Batch 425/537: Loss=0.5963 (C:0.5963, R:0.0105)
Batch 450/537: Loss=0.5506 (C:0.5506, R:0.0105)
Batch 475/537: Loss=0.5549 (C:0.5549, R:0.0105)
Batch 500/537: Loss=0.5486 (C:0.5486, R:0.0105)
Batch 525/537: Loss=0.5954 (C:0.5954, R:0.0105)

============================================================
Epoch 59/300 completed in 27.6s
Train: Loss=0.5680 (C:0.5680, R:0.0105) Ratio=5.08x
Val:   Loss=0.7219 (C:0.7219, R:0.0104) Ratio=3.14x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.7219)
============================================================

🌍 Updating global dataset at epoch 60
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.330 ± 0.623
    Neg distances: 2.654 ± 1.116
    Separation ratio: 8.05x
    Gap: -4.542
    ✅ Excellent global separation!

Epoch 60 Training
----------------------------------------
Batch   0/537: Loss=0.5603 (C:0.5603, R:0.0105)
Batch  25/537: Loss=0.5528 (C:0.5528, R:0.0105)
Batch  50/537: Loss=0.5570 (C:0.5570, R:0.0106)
Batch  75/537: Loss=0.5174 (C:0.5174, R:0.0105)
Batch 100/537: Loss=0.5957 (C:0.5957, R:0.0105)
Batch 125/537: Loss=0.5881 (C:0.5881, R:0.0105)
Batch 150/537: Loss=0.5242 (C:0.5242, R:0.0105)
Batch 175/537: Loss=0.5222 (C:0.5222, R:0.0105)
Batch 200/537: Loss=0.5830 (C:0.5830, R:0.0105)
Batch 225/537: Loss=0.5249 (C:0.5249, R:0.0105)
Batch 250/537: Loss=0.5598 (C:0.5598, R:0.0105)
Batch 275/537: Loss=0.5421 (C:0.5421, R:0.0105)
Batch 300/537: Loss=0.5873 (C:0.5873, R:0.0105)
Batch 325/537: Loss=0.6012 (C:0.6012, R:0.0105)
Batch 350/537: Loss=0.5806 (C:0.5806, R:0.0105)
Batch 375/537: Loss=0.5613 (C:0.5613, R:0.0105)
Batch 400/537: Loss=0.5777 (C:0.5777, R:0.0105)
Batch 425/537: Loss=0.5841 (C:0.5841, R:0.0105)
Batch 450/537: Loss=0.5909 (C:0.5909, R:0.0105)
Batch 475/537: Loss=0.5501 (C:0.5501, R:0.0105)
Batch 500/537: Loss=0.5895 (C:0.5895, R:0.0105)
Batch 525/537: Loss=0.5667 (C:0.5667, R:0.0105)

============================================================
Epoch 60/300 completed in 27.1s
Train: Loss=0.5631 (C:0.5631, R:0.0105) Ratio=4.96x
Val:   Loss=0.7216 (C:0.7216, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.7216)
Checkpoint saved at epoch 60
============================================================

🌍 Updating global dataset at epoch 61
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.308 ± 0.573
    Neg distances: 2.646 ± 1.102
    Separation ratio: 8.60x
    Gap: -4.519
    ✅ Excellent global separation!

Epoch 61 Training
----------------------------------------
Batch   0/537: Loss=0.5586 (C:0.5586, R:0.0105)
Batch  25/537: Loss=0.5534 (C:0.5534, R:0.0105)
Batch  50/537: Loss=0.5630 (C:0.5630, R:0.0105)
Batch  75/537: Loss=0.5603 (C:0.5603, R:0.0105)
Batch 100/537: Loss=0.5519 (C:0.5519, R:0.0105)
Batch 125/537: Loss=0.5666 (C:0.5666, R:0.0105)
Batch 150/537: Loss=0.5281 (C:0.5281, R:0.0105)
Batch 175/537: Loss=0.5459 (C:0.5459, R:0.0105)
Batch 200/537: Loss=0.5628 (C:0.5628, R:0.0105)
Batch 225/537: Loss=0.5673 (C:0.5673, R:0.0105)
Batch 250/537: Loss=0.5580 (C:0.5580, R:0.0105)
Batch 275/537: Loss=0.5747 (C:0.5747, R:0.0105)
Batch 300/537: Loss=0.5414 (C:0.5414, R:0.0105)
Batch 325/537: Loss=0.5314 (C:0.5314, R:0.0105)
Batch 350/537: Loss=0.5796 (C:0.5796, R:0.0105)
Batch 375/537: Loss=0.5382 (C:0.5382, R:0.0105)
Batch 400/537: Loss=0.5365 (C:0.5365, R:0.0105)
Batch 425/537: Loss=0.5382 (C:0.5382, R:0.0105)
Batch 450/537: Loss=0.5441 (C:0.5441, R:0.0105)
Batch 475/537: Loss=0.5330 (C:0.5330, R:0.0106)
Batch 500/537: Loss=0.5071 (C:0.5071, R:0.0105)
Batch 525/537: Loss=0.5416 (C:0.5416, R:0.0105)

============================================================
Epoch 61/300 completed in 27.7s
Train: Loss=0.5458 (C:0.5458, R:0.0105) Ratio=5.03x
Val:   Loss=0.7105 (C:0.7105, R:0.0104) Ratio=3.12x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.7105)
============================================================

🌍 Updating global dataset at epoch 62
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.312 ± 0.596
    Neg distances: 2.669 ± 1.113
    Separation ratio: 8.56x
    Gap: -4.591
    ✅ Excellent global separation!

Epoch 62 Training
----------------------------------------
Batch   0/537: Loss=0.5817 (C:0.5817, R:0.0105)
Batch  25/537: Loss=0.5250 (C:0.5250, R:0.0105)
Batch  50/537: Loss=0.5418 (C:0.5418, R:0.0105)
Batch  75/537: Loss=0.5263 (C:0.5263, R:0.0105)
Batch 100/537: Loss=0.5349 (C:0.5349, R:0.0105)
Batch 125/537: Loss=0.5017 (C:0.5017, R:0.0105)
Batch 150/537: Loss=0.5608 (C:0.5608, R:0.0105)
Batch 175/537: Loss=0.5177 (C:0.5177, R:0.0105)
Batch 200/537: Loss=0.5311 (C:0.5311, R:0.0105)
Batch 225/537: Loss=0.5019 (C:0.5019, R:0.0105)
Batch 250/537: Loss=0.5361 (C:0.5361, R:0.0105)
Batch 275/537: Loss=0.5724 (C:0.5724, R:0.0105)
Batch 300/537: Loss=0.5898 (C:0.5898, R:0.0105)
Batch 325/537: Loss=0.5733 (C:0.5733, R:0.0105)
Batch 350/537: Loss=0.5201 (C:0.5201, R:0.0105)
Batch 375/537: Loss=0.4954 (C:0.4954, R:0.0105)
Batch 400/537: Loss=0.5570 (C:0.5570, R:0.0105)
Batch 425/537: Loss=0.5197 (C:0.5197, R:0.0105)
Batch 450/537: Loss=0.5876 (C:0.5876, R:0.0105)
Batch 475/537: Loss=0.5637 (C:0.5637, R:0.0105)
Batch 500/537: Loss=0.5601 (C:0.5601, R:0.0105)
Batch 525/537: Loss=0.5188 (C:0.5188, R:0.0105)

============================================================
Epoch 62/300 completed in 27.4s
Train: Loss=0.5468 (C:0.5468, R:0.0105) Ratio=5.13x
Val:   Loss=0.7135 (C:0.7135, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 63
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.322 ± 0.626
    Neg distances: 2.681 ± 1.122
    Separation ratio: 8.31x
    Gap: -4.525
    ✅ Excellent global separation!

Epoch 63 Training
----------------------------------------
Batch   0/537: Loss=0.5334 (C:0.5334, R:0.0105)
Batch  25/537: Loss=0.5357 (C:0.5357, R:0.0105)
Batch  50/537: Loss=0.5391 (C:0.5391, R:0.0105)
Batch  75/537: Loss=0.5430 (C:0.5430, R:0.0105)
Batch 100/537: Loss=0.5448 (C:0.5448, R:0.0105)
Batch 125/537: Loss=0.5273 (C:0.5273, R:0.0105)
Batch 150/537: Loss=0.5664 (C:0.5664, R:0.0105)
Batch 175/537: Loss=0.5543 (C:0.5543, R:0.0105)
Batch 200/537: Loss=0.5116 (C:0.5116, R:0.0105)
Batch 225/537: Loss=0.5484 (C:0.5484, R:0.0105)
Batch 250/537: Loss=0.5607 (C:0.5607, R:0.0105)
Batch 275/537: Loss=0.5451 (C:0.5451, R:0.0105)
Batch 300/537: Loss=0.5548 (C:0.5548, R:0.0105)
Batch 325/537: Loss=0.5251 (C:0.5251, R:0.0105)
Batch 350/537: Loss=0.5488 (C:0.5488, R:0.0105)
Batch 375/537: Loss=0.5780 (C:0.5780, R:0.0105)
Batch 400/537: Loss=0.5476 (C:0.5476, R:0.0105)
Batch 425/537: Loss=0.5763 (C:0.5763, R:0.0105)
Batch 450/537: Loss=0.5705 (C:0.5705, R:0.0105)
Batch 475/537: Loss=0.5394 (C:0.5394, R:0.0105)
Batch 500/537: Loss=0.5726 (C:0.5726, R:0.0105)
Batch 525/537: Loss=0.5663 (C:0.5663, R:0.0105)

============================================================
Epoch 63/300 completed in 28.6s
Train: Loss=0.5528 (C:0.5528, R:0.0105) Ratio=5.06x
Val:   Loss=0.7130 (C:0.7130, R:0.0104) Ratio=3.15x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 64
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.301 ± 0.587
    Neg distances: 2.665 ± 1.110
    Separation ratio: 8.86x
    Gap: -4.661
    ✅ Excellent global separation!

Epoch 64 Training
----------------------------------------
Batch   0/537: Loss=0.5617 (C:0.5617, R:0.0105)
Batch  25/537: Loss=0.5286 (C:0.5286, R:0.0105)
Batch  50/537: Loss=0.5497 (C:0.5497, R:0.0105)
Batch  75/537: Loss=0.5667 (C:0.5667, R:0.0105)
Batch 100/537: Loss=0.4958 (C:0.4958, R:0.0105)
Batch 125/537: Loss=0.5388 (C:0.5388, R:0.0105)
Batch 150/537: Loss=0.5350 (C:0.5350, R:0.0105)
Batch 175/537: Loss=0.5140 (C:0.5140, R:0.0105)
Batch 200/537: Loss=0.5705 (C:0.5705, R:0.0105)
Batch 225/537: Loss=0.5519 (C:0.5519, R:0.0105)
Batch 250/537: Loss=0.5404 (C:0.5404, R:0.0105)
Batch 275/537: Loss=0.5213 (C:0.5213, R:0.0105)
Batch 300/537: Loss=0.5131 (C:0.5131, R:0.0105)
Batch 325/537: Loss=0.5203 (C:0.5203, R:0.0105)
Batch 350/537: Loss=0.5591 (C:0.5591, R:0.0105)
Batch 375/537: Loss=0.5488 (C:0.5488, R:0.0105)
Batch 400/537: Loss=0.5389 (C:0.5389, R:0.0105)
Batch 425/537: Loss=0.5529 (C:0.5529, R:0.0105)
Batch 450/537: Loss=0.5632 (C:0.5632, R:0.0105)
Batch 475/537: Loss=0.5355 (C:0.5355, R:0.0105)
Batch 500/537: Loss=0.5504 (C:0.5504, R:0.0105)
Batch 525/537: Loss=0.5660 (C:0.5660, R:0.0105)

============================================================
Epoch 64/300 completed in 28.1s
Train: Loss=0.5373 (C:0.5373, R:0.0105) Ratio=5.08x
Val:   Loss=0.6991 (C:0.6991, R:0.0104) Ratio=3.19x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.6991)
============================================================

🌍 Updating global dataset at epoch 65
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.294 ± 0.574
    Neg distances: 2.704 ± 1.116
    Separation ratio: 9.19x
    Gap: -4.652
    ✅ Excellent global separation!

Epoch 65 Training
----------------------------------------
Batch   0/537: Loss=0.4938 (C:0.4938, R:0.0105)
Batch  25/537: Loss=0.5324 (C:0.5324, R:0.0105)
Batch  50/537: Loss=0.5185 (C:0.5185, R:0.0105)
Batch  75/537: Loss=0.5354 (C:0.5354, R:0.0105)
Batch 100/537: Loss=0.5366 (C:0.5366, R:0.0105)
Batch 125/537: Loss=0.5236 (C:0.5236, R:0.0105)
Batch 150/537: Loss=0.5525 (C:0.5525, R:0.0105)
Batch 175/537: Loss=0.5160 (C:0.5160, R:0.0105)
Batch 200/537: Loss=0.5263 (C:0.5263, R:0.0105)
Batch 225/537: Loss=0.5121 (C:0.5121, R:0.0105)
Batch 250/537: Loss=0.5386 (C:0.5386, R:0.0105)
Batch 275/537: Loss=0.5721 (C:0.5721, R:0.0105)
Batch 300/537: Loss=0.5221 (C:0.5221, R:0.0105)
Batch 325/537: Loss=0.5184 (C:0.5184, R:0.0105)
Batch 350/537: Loss=0.5363 (C:0.5363, R:0.0105)
Batch 375/537: Loss=0.5424 (C:0.5424, R:0.0105)
Batch 400/537: Loss=0.5554 (C:0.5554, R:0.0105)
Batch 425/537: Loss=0.5285 (C:0.5285, R:0.0105)
Batch 450/537: Loss=0.5179 (C:0.5179, R:0.0105)
Batch 475/537: Loss=0.5611 (C:0.5611, R:0.0105)
Batch 500/537: Loss=0.5390 (C:0.5390, R:0.0105)
Batch 525/537: Loss=0.5180 (C:0.5180, R:0.0105)

============================================================
Epoch 65/300 completed in 28.6s
Train: Loss=0.5278 (C:0.5278, R:0.0105) Ratio=5.07x
Val:   Loss=0.6962 (C:0.6962, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.6962)
============================================================

🌍 Updating global dataset at epoch 66
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.299 ± 0.591
    Neg distances: 2.730 ± 1.126
    Separation ratio: 9.13x
    Gap: -4.634
    ✅ Excellent global separation!

Epoch 66 Training
----------------------------------------
Batch   0/537: Loss=0.5186 (C:0.5186, R:0.0105)
Batch  25/537: Loss=0.5294 (C:0.5294, R:0.0105)
Batch  50/537: Loss=0.5659 (C:0.5659, R:0.0105)
Batch  75/537: Loss=0.5181 (C:0.5181, R:0.0105)
Batch 100/537: Loss=0.5344 (C:0.5344, R:0.0105)
Batch 125/537: Loss=0.5351 (C:0.5351, R:0.0105)
Batch 150/537: Loss=0.5361 (C:0.5361, R:0.0105)
Batch 175/537: Loss=0.5435 (C:0.5435, R:0.0105)
Batch 200/537: Loss=0.5287 (C:0.5287, R:0.0105)
Batch 225/537: Loss=0.5242 (C:0.5242, R:0.0105)
Batch 250/537: Loss=0.5329 (C:0.5329, R:0.0105)
Batch 275/537: Loss=0.5469 (C:0.5469, R:0.0105)
Batch 300/537: Loss=0.5130 (C:0.5130, R:0.0105)
Batch 325/537: Loss=0.5492 (C:0.5492, R:0.0105)
Batch 350/537: Loss=0.5352 (C:0.5352, R:0.0106)
Batch 375/537: Loss=0.5358 (C:0.5358, R:0.0105)
Batch 400/537: Loss=0.5110 (C:0.5110, R:0.0105)
Batch 425/537: Loss=0.5259 (C:0.5259, R:0.0106)
Batch 450/537: Loss=0.5471 (C:0.5471, R:0.0106)
Batch 475/537: Loss=0.5178 (C:0.5178, R:0.0105)
Batch 500/537: Loss=0.5587 (C:0.5587, R:0.0105)
Batch 525/537: Loss=0.5227 (C:0.5227, R:0.0105)

============================================================
Epoch 66/300 completed in 28.9s
Train: Loss=0.5295 (C:0.5295, R:0.0105) Ratio=5.09x
Val:   Loss=0.7003 (C:0.7003, R:0.0104) Ratio=3.13x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 67
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.301 ± 0.585
    Neg distances: 2.728 ± 1.129
    Separation ratio: 9.08x
    Gap: -4.638
    ✅ Excellent global separation!

Epoch 67 Training
----------------------------------------
Batch   0/537: Loss=0.5180 (C:0.5180, R:0.0106)
Batch  25/537: Loss=0.4997 (C:0.4997, R:0.0105)
Batch  50/537: Loss=0.5353 (C:0.5353, R:0.0105)
Batch  75/537: Loss=0.5209 (C:0.5209, R:0.0105)
Batch 100/537: Loss=0.4852 (C:0.4852, R:0.0105)
Batch 125/537: Loss=0.5832 (C:0.5832, R:0.0105)
Batch 150/537: Loss=0.5621 (C:0.5621, R:0.0105)
Batch 175/537: Loss=0.5048 (C:0.5048, R:0.0105)
Batch 200/537: Loss=0.5301 (C:0.5301, R:0.0105)
Batch 225/537: Loss=0.5279 (C:0.5279, R:0.0105)
Batch 250/537: Loss=0.5094 (C:0.5094, R:0.0105)
Batch 275/537: Loss=0.5423 (C:0.5423, R:0.0105)
Batch 300/537: Loss=0.5179 (C:0.5179, R:0.0105)
Batch 325/537: Loss=0.5457 (C:0.5457, R:0.0105)
Batch 350/537: Loss=0.5566 (C:0.5566, R:0.0105)
Batch 375/537: Loss=0.5473 (C:0.5473, R:0.0105)
Batch 400/537: Loss=0.5670 (C:0.5670, R:0.0105)
Batch 425/537: Loss=0.5300 (C:0.5300, R:0.0105)
Batch 450/537: Loss=0.5402 (C:0.5402, R:0.0105)
Batch 475/537: Loss=0.5212 (C:0.5212, R:0.0105)
Batch 500/537: Loss=0.5442 (C:0.5442, R:0.0105)
Batch 525/537: Loss=0.5514 (C:0.5514, R:0.0105)

============================================================
Epoch 67/300 completed in 28.3s
Train: Loss=0.5294 (C:0.5294, R:0.0105) Ratio=5.16x
Val:   Loss=0.7053 (C:0.7053, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 68
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.305 ± 0.596
    Neg distances: 2.728 ± 1.126
    Separation ratio: 8.93x
    Gap: -4.557
    ✅ Excellent global separation!

Epoch 68 Training
----------------------------------------
Batch   0/537: Loss=0.4961 (C:0.4961, R:0.0105)
Batch  25/537: Loss=0.5211 (C:0.5211, R:0.0106)
Batch  50/537: Loss=0.5212 (C:0.5212, R:0.0105)
Batch  75/537: Loss=0.5216 (C:0.5216, R:0.0105)
Batch 100/537: Loss=0.5690 (C:0.5690, R:0.0105)
Batch 125/537: Loss=0.5352 (C:0.5352, R:0.0105)
Batch 150/537: Loss=0.5301 (C:0.5301, R:0.0105)
Batch 175/537: Loss=0.5449 (C:0.5449, R:0.0105)
Batch 200/537: Loss=0.5148 (C:0.5148, R:0.0105)
Batch 225/537: Loss=0.5284 (C:0.5284, R:0.0105)
Batch 250/537: Loss=0.5547 (C:0.5547, R:0.0105)
Batch 275/537: Loss=0.5285 (C:0.5285, R:0.0105)
Batch 300/537: Loss=0.5276 (C:0.5276, R:0.0105)
Batch 325/537: Loss=0.5303 (C:0.5303, R:0.0105)
Batch 350/537: Loss=0.5332 (C:0.5332, R:0.0105)
Batch 375/537: Loss=0.5443 (C:0.5443, R:0.0105)
Batch 400/537: Loss=0.5488 (C:0.5488, R:0.0105)
Batch 425/537: Loss=0.5216 (C:0.5216, R:0.0105)
Batch 450/537: Loss=0.5522 (C:0.5522, R:0.0105)
Batch 475/537: Loss=0.5469 (C:0.5469, R:0.0106)
Batch 500/537: Loss=0.5674 (C:0.5674, R:0.0106)
Batch 525/537: Loss=0.5119 (C:0.5119, R:0.0105)

============================================================
Epoch 68/300 completed in 27.3s
Train: Loss=0.5304 (C:0.5304, R:0.0105) Ratio=5.08x
Val:   Loss=0.7066 (C:0.7066, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 69
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.297 ± 0.589
    Neg distances: 2.709 ± 1.118
    Separation ratio: 9.12x
    Gap: -4.630
    ✅ Excellent global separation!

Epoch 69 Training
----------------------------------------
Batch   0/537: Loss=0.5355 (C:0.5355, R:0.0105)
Batch  25/537: Loss=0.5010 (C:0.5010, R:0.0105)
Batch  50/537: Loss=0.5162 (C:0.5162, R:0.0105)
Batch  75/537: Loss=0.5353 (C:0.5353, R:0.0105)
Batch 100/537: Loss=0.5142 (C:0.5142, R:0.0105)
Batch 125/537: Loss=0.5199 (C:0.5199, R:0.0105)
Batch 150/537: Loss=0.5221 (C:0.5221, R:0.0105)
Batch 175/537: Loss=0.5225 (C:0.5225, R:0.0105)
Batch 200/537: Loss=0.5200 (C:0.5200, R:0.0105)
Batch 225/537: Loss=0.5258 (C:0.5258, R:0.0105)
Batch 250/537: Loss=0.5307 (C:0.5307, R:0.0105)
Batch 275/537: Loss=0.5350 (C:0.5350, R:0.0105)
Batch 300/537: Loss=0.5189 (C:0.5189, R:0.0105)
Batch 325/537: Loss=0.5030 (C:0.5030, R:0.0105)
Batch 350/537: Loss=0.5429 (C:0.5429, R:0.0105)
Batch 375/537: Loss=0.5521 (C:0.5521, R:0.0105)
Batch 400/537: Loss=0.5041 (C:0.5041, R:0.0105)
Batch 425/537: Loss=0.5143 (C:0.5143, R:0.0105)
Batch 450/537: Loss=0.5006 (C:0.5006, R:0.0105)
Batch 475/537: Loss=0.5237 (C:0.5237, R:0.0105)
Batch 500/537: Loss=0.4936 (C:0.4936, R:0.0105)
Batch 525/537: Loss=0.5251 (C:0.5251, R:0.0105)

============================================================
Epoch 69/300 completed in 26.9s
Train: Loss=0.5239 (C:0.5239, R:0.0105) Ratio=5.24x
Val:   Loss=0.7047 (C:0.7047, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
No improvement for 4 epochs
============================================================

🌍 Updating global dataset at epoch 70
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.275 ± 0.551
    Neg distances: 2.738 ± 1.118
    Separation ratio: 9.97x
    Gap: -4.587
    ✅ Excellent global separation!

Epoch 70 Training
----------------------------------------
Batch   0/537: Loss=0.4918 (C:0.4918, R:0.0105)
Batch  25/537: Loss=0.5018 (C:0.5018, R:0.0105)
Batch  50/537: Loss=0.5321 (C:0.5321, R:0.0105)
Batch  75/537: Loss=0.4940 (C:0.4940, R:0.0105)
Batch 100/537: Loss=0.4949 (C:0.4949, R:0.0105)
Batch 125/537: Loss=0.5002 (C:0.5002, R:0.0105)
Batch 150/537: Loss=0.4996 (C:0.4996, R:0.0105)
Batch 175/537: Loss=0.5047 (C:0.5047, R:0.0105)
Batch 200/537: Loss=0.4695 (C:0.4695, R:0.0105)
Batch 225/537: Loss=0.5063 (C:0.5063, R:0.0105)
Batch 250/537: Loss=0.5180 (C:0.5180, R:0.0105)
Batch 275/537: Loss=0.5827 (C:0.5827, R:0.0105)
Batch 300/537: Loss=0.4950 (C:0.4950, R:0.0105)
Batch 325/537: Loss=0.5303 (C:0.5303, R:0.0105)
Batch 350/537: Loss=0.4964 (C:0.4964, R:0.0105)
Batch 375/537: Loss=0.4764 (C:0.4764, R:0.0105)
Batch 400/537: Loss=0.4985 (C:0.4985, R:0.0106)
Batch 425/537: Loss=0.5074 (C:0.5074, R:0.0105)
Batch 450/537: Loss=0.5196 (C:0.5196, R:0.0105)
Batch 475/537: Loss=0.5487 (C:0.5487, R:0.0105)
Batch 500/537: Loss=0.5299 (C:0.5299, R:0.0105)
Batch 525/537: Loss=0.4878 (C:0.4878, R:0.0105)

============================================================
Epoch 70/300 completed in 26.8s
Train: Loss=0.5058 (C:0.5058, R:0.0105) Ratio=5.24x
Val:   Loss=0.6876 (C:0.6876, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.6876)
============================================================

🌍 Updating global dataset at epoch 71
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.302 ± 0.575
    Neg distances: 2.722 ± 1.127
    Separation ratio: 9.00x
    Gap: -4.580
    ✅ Excellent global separation!

Epoch 71 Training
----------------------------------------
Batch   0/537: Loss=0.5315 (C:0.5315, R:0.0105)
Batch  25/537: Loss=0.5124 (C:0.5124, R:0.0105)
Batch  50/537: Loss=0.5416 (C:0.5416, R:0.0105)
Batch  75/537: Loss=0.5460 (C:0.5460, R:0.0105)
Batch 100/537: Loss=0.5432 (C:0.5432, R:0.0106)
Batch 125/537: Loss=0.5393 (C:0.5393, R:0.0105)
Batch 150/537: Loss=0.5306 (C:0.5306, R:0.0105)
Batch 175/537: Loss=0.5419 (C:0.5419, R:0.0105)
Batch 200/537: Loss=0.5132 (C:0.5132, R:0.0105)
Batch 225/537: Loss=0.5260 (C:0.5260, R:0.0105)
Batch 250/537: Loss=0.5317 (C:0.5317, R:0.0105)
Batch 275/537: Loss=0.4956 (C:0.4956, R:0.0105)
Batch 300/537: Loss=0.5434 (C:0.5434, R:0.0105)
Batch 325/537: Loss=0.5572 (C:0.5572, R:0.0105)
Batch 350/537: Loss=0.5117 (C:0.5117, R:0.0105)
Batch 375/537: Loss=0.5736 (C:0.5736, R:0.0106)
Batch 400/537: Loss=0.5448 (C:0.5448, R:0.0105)
Batch 425/537: Loss=0.5307 (C:0.5307, R:0.0105)
Batch 450/537: Loss=0.5605 (C:0.5605, R:0.0105)
Batch 475/537: Loss=0.5587 (C:0.5587, R:0.0106)
Batch 500/537: Loss=0.5317 (C:0.5317, R:0.0105)
Batch 525/537: Loss=0.5296 (C:0.5296, R:0.0105)

============================================================
Epoch 71/300 completed in 27.7s
Train: Loss=0.5260 (C:0.5260, R:0.0105) Ratio=5.18x
Val:   Loss=0.7091 (C:0.7091, R:0.0104) Ratio=3.12x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 72
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.320 ± 0.621
    Neg distances: 2.723 ± 1.139
    Separation ratio: 8.52x
    Gap: -4.621
    ✅ Excellent global separation!

Epoch 72 Training
----------------------------------------
Batch   0/537: Loss=0.5689 (C:0.5689, R:0.0105)
Batch  25/537: Loss=0.5021 (C:0.5021, R:0.0105)
Batch  50/537: Loss=0.5352 (C:0.5352, R:0.0105)
Batch  75/537: Loss=0.5289 (C:0.5289, R:0.0105)
Batch 100/537: Loss=0.5415 (C:0.5415, R:0.0105)
Batch 125/537: Loss=0.4854 (C:0.4854, R:0.0105)
Batch 150/537: Loss=0.5269 (C:0.5269, R:0.0105)
Batch 175/537: Loss=0.5230 (C:0.5230, R:0.0105)
Batch 200/537: Loss=0.5169 (C:0.5169, R:0.0105)
Batch 225/537: Loss=0.5211 (C:0.5211, R:0.0105)
Batch 250/537: Loss=0.5095 (C:0.5095, R:0.0105)
Batch 275/537: Loss=0.5537 (C:0.5537, R:0.0105)
Batch 300/537: Loss=0.5572 (C:0.5572, R:0.0105)
Batch 325/537: Loss=0.5485 (C:0.5485, R:0.0105)
Batch 350/537: Loss=0.5652 (C:0.5652, R:0.0105)
Batch 375/537: Loss=0.4999 (C:0.4999, R:0.0105)
Batch 400/537: Loss=0.5591 (C:0.5591, R:0.0105)
Batch 425/537: Loss=0.5428 (C:0.5428, R:0.0105)
Batch 450/537: Loss=0.5305 (C:0.5305, R:0.0105)
Batch 475/537: Loss=0.5281 (C:0.5281, R:0.0105)
Batch 500/537: Loss=0.5726 (C:0.5726, R:0.0105)
Batch 525/537: Loss=0.5377 (C:0.5377, R:0.0105)

============================================================
Epoch 72/300 completed in 27.4s
Train: Loss=0.5369 (C:0.5369, R:0.0105) Ratio=5.30x
Val:   Loss=0.7130 (C:0.7130, R:0.0104) Ratio=3.13x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 73
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.298 ± 0.593
    Neg distances: 2.722 ± 1.128
    Separation ratio: 9.12x
    Gap: -4.574
    ✅ Excellent global separation!

Epoch 73 Training
----------------------------------------
Batch   0/537: Loss=0.4674 (C:0.4674, R:0.0105)
Batch  25/537: Loss=0.5137 (C:0.5137, R:0.0105)
Batch  50/537: Loss=0.5053 (C:0.5053, R:0.0105)
Batch  75/537: Loss=0.5092 (C:0.5092, R:0.0105)
Batch 100/537: Loss=0.4888 (C:0.4888, R:0.0106)
Batch 125/537: Loss=0.4946 (C:0.4946, R:0.0105)
Batch 150/537: Loss=0.4889 (C:0.4889, R:0.0105)
Batch 175/537: Loss=0.4795 (C:0.4795, R:0.0105)
Batch 200/537: Loss=0.5418 (C:0.5418, R:0.0106)
Batch 225/537: Loss=0.5343 (C:0.5343, R:0.0105)
Batch 250/537: Loss=0.5163 (C:0.5163, R:0.0105)
Batch 275/537: Loss=0.5507 (C:0.5507, R:0.0105)
Batch 300/537: Loss=0.5155 (C:0.5155, R:0.0105)
Batch 325/537: Loss=0.5230 (C:0.5230, R:0.0106)
Batch 350/537: Loss=0.5273 (C:0.5273, R:0.0105)
Batch 375/537: Loss=0.5227 (C:0.5227, R:0.0105)
Batch 400/537: Loss=0.5282 (C:0.5282, R:0.0105)
Batch 425/537: Loss=0.5195 (C:0.5195, R:0.0105)
Batch 450/537: Loss=0.5184 (C:0.5184, R:0.0105)
Batch 475/537: Loss=0.4902 (C:0.4902, R:0.0105)
Batch 500/537: Loss=0.5686 (C:0.5686, R:0.0105)
Batch 525/537: Loss=0.5449 (C:0.5449, R:0.0105)

============================================================
Epoch 73/300 completed in 27.2s
Train: Loss=0.5211 (C:0.5211, R:0.0105) Ratio=5.35x
Val:   Loss=0.7020 (C:0.7020, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 74
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.303 ± 0.587
    Neg distances: 2.717 ± 1.131
    Separation ratio: 8.97x
    Gap: -4.679
    ✅ Excellent global separation!

Epoch 74 Training
----------------------------------------
Batch   0/537: Loss=0.4878 (C:0.4878, R:0.0105)
Batch  25/537: Loss=0.5421 (C:0.5421, R:0.0105)
Batch  50/537: Loss=0.5346 (C:0.5346, R:0.0105)
Batch  75/537: Loss=0.5022 (C:0.5022, R:0.0105)
Batch 100/537: Loss=0.5585 (C:0.5585, R:0.0105)
Batch 125/537: Loss=0.5089 (C:0.5089, R:0.0105)
Batch 150/537: Loss=0.5259 (C:0.5259, R:0.0105)
Batch 175/537: Loss=0.5058 (C:0.5058, R:0.0105)
Batch 200/537: Loss=0.5538 (C:0.5538, R:0.0105)
Batch 225/537: Loss=0.5504 (C:0.5504, R:0.0105)
Batch 250/537: Loss=0.5217 (C:0.5217, R:0.0105)
Batch 275/537: Loss=0.4976 (C:0.4976, R:0.0105)
Batch 300/537: Loss=0.5387 (C:0.5387, R:0.0105)
Batch 325/537: Loss=0.5203 (C:0.5203, R:0.0105)
Batch 350/537: Loss=0.5090 (C:0.5090, R:0.0105)
Batch 375/537: Loss=0.5039 (C:0.5039, R:0.0105)
Batch 400/537: Loss=0.5579 (C:0.5579, R:0.0105)
Batch 425/537: Loss=0.5059 (C:0.5059, R:0.0105)
Batch 450/537: Loss=0.5521 (C:0.5521, R:0.0105)
Batch 475/537: Loss=0.5388 (C:0.5388, R:0.0105)
Batch 500/537: Loss=0.5618 (C:0.5618, R:0.0105)
Batch 525/537: Loss=0.5226 (C:0.5226, R:0.0106)

============================================================
Epoch 74/300 completed in 27.2s
Train: Loss=0.5242 (C:0.5242, R:0.0105) Ratio=5.23x
Val:   Loss=0.7083 (C:0.7083, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
No improvement for 4 epochs
============================================================

🌍 Updating global dataset at epoch 75
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.291 ± 0.588
    Neg distances: 2.729 ± 1.127
    Separation ratio: 9.36x
    Gap: -4.628
    ✅ Excellent global separation!

Epoch 75 Training
----------------------------------------
Batch   0/537: Loss=0.5066 (C:0.5066, R:0.0105)
Batch  25/537: Loss=0.5258 (C:0.5258, R:0.0105)
Batch  50/537: Loss=0.4870 (C:0.4870, R:0.0105)
Batch  75/537: Loss=0.5202 (C:0.5202, R:0.0105)
Batch 100/537: Loss=0.4793 (C:0.4793, R:0.0106)
Batch 125/537: Loss=0.5563 (C:0.5563, R:0.0105)
Batch 150/537: Loss=0.5184 (C:0.5184, R:0.0105)
Batch 175/537: Loss=0.5211 (C:0.5211, R:0.0105)
Batch 200/537: Loss=0.5093 (C:0.5093, R:0.0105)
Batch 225/537: Loss=0.5026 (C:0.5026, R:0.0105)
Batch 250/537: Loss=0.5228 (C:0.5228, R:0.0105)
Batch 275/537: Loss=0.5425 (C:0.5425, R:0.0105)
Batch 300/537: Loss=0.4920 (C:0.4920, R:0.0105)
Batch 325/537: Loss=0.5231 (C:0.5231, R:0.0105)
Batch 350/537: Loss=0.5072 (C:0.5072, R:0.0105)
Batch 375/537: Loss=0.5085 (C:0.5085, R:0.0105)
Batch 400/537: Loss=0.5387 (C:0.5387, R:0.0106)
Batch 425/537: Loss=0.4948 (C:0.4948, R:0.0105)
Batch 450/537: Loss=0.5585 (C:0.5585, R:0.0105)
Batch 475/537: Loss=0.5328 (C:0.5328, R:0.0105)
Batch 500/537: Loss=0.5295 (C:0.5295, R:0.0105)
Batch 525/537: Loss=0.5393 (C:0.5393, R:0.0105)

============================================================
Epoch 75/300 completed in 27.0s
Train: Loss=0.5148 (C:0.5148, R:0.0105) Ratio=5.38x
Val:   Loss=0.6916 (C:0.6916, R:0.0104) Ratio=3.13x
Reconstruction weight: 0.300
No improvement for 5 epochs
============================================================

🌍 Updating global dataset at epoch 76
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.287 ± 0.582
    Neg distances: 2.688 ± 1.103
    Separation ratio: 9.36x
    Gap: -4.648
    ✅ Excellent global separation!

Epoch 76 Training
----------------------------------------
Batch   0/537: Loss=0.5042 (C:0.5042, R:0.0105)
Batch  25/537: Loss=0.5028 (C:0.5028, R:0.0105)
Batch  50/537: Loss=0.4915 (C:0.4915, R:0.0105)
Batch  75/537: Loss=0.5095 (C:0.5095, R:0.0105)
Batch 100/537: Loss=0.5004 (C:0.5004, R:0.0105)
Batch 125/537: Loss=0.5134 (C:0.5134, R:0.0105)
Batch 150/537: Loss=0.4684 (C:0.4684, R:0.0105)
Batch 175/537: Loss=0.5042 (C:0.5042, R:0.0105)
Batch 200/537: Loss=0.4749 (C:0.4749, R:0.0105)
Batch 225/537: Loss=0.4922 (C:0.4922, R:0.0105)
Batch 250/537: Loss=0.4996 (C:0.4996, R:0.0105)
Batch 275/537: Loss=0.4949 (C:0.4949, R:0.0105)
Batch 300/537: Loss=0.5328 (C:0.5328, R:0.0105)
Batch 325/537: Loss=0.5615 (C:0.5615, R:0.0105)
Batch 350/537: Loss=0.5180 (C:0.5180, R:0.0105)
Batch 375/537: Loss=0.5063 (C:0.5063, R:0.0105)
Batch 400/537: Loss=0.5285 (C:0.5285, R:0.0105)
Batch 425/537: Loss=0.4702 (C:0.4702, R:0.0105)
Batch 450/537: Loss=0.4980 (C:0.4980, R:0.0105)
Batch 475/537: Loss=0.5163 (C:0.5163, R:0.0105)
Batch 500/537: Loss=0.5127 (C:0.5127, R:0.0105)
Batch 525/537: Loss=0.4939 (C:0.4939, R:0.0105)

============================================================
Epoch 76/300 completed in 27.1s
Train: Loss=0.5084 (C:0.5084, R:0.0105) Ratio=5.42x
Val:   Loss=0.6977 (C:0.6977, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
No improvement for 6 epochs
============================================================

🌍 Updating global dataset at epoch 77
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.309 ± 0.611
    Neg distances: 2.681 ± 1.125
    Separation ratio: 8.69x
    Gap: -4.526
    ✅ Excellent global separation!

Epoch 77 Training
----------------------------------------
Batch   0/537: Loss=0.4919 (C:0.4919, R:0.0105)
Batch  25/537: Loss=0.5403 (C:0.5403, R:0.0106)
Batch  50/537: Loss=0.5030 (C:0.5030, R:0.0105)
Batch  75/537: Loss=0.4965 (C:0.4965, R:0.0105)
Batch 100/537: Loss=0.5087 (C:0.5087, R:0.0105)
Batch 125/537: Loss=0.4737 (C:0.4737, R:0.0105)
Batch 150/537: Loss=0.4928 (C:0.4928, R:0.0105)
Batch 175/537: Loss=0.4780 (C:0.4780, R:0.0105)
Batch 200/537: Loss=0.4986 (C:0.4986, R:0.0105)
Batch 225/537: Loss=0.5609 (C:0.5609, R:0.0105)
Batch 250/537: Loss=0.4953 (C:0.4953, R:0.0105)
Batch 275/537: Loss=0.5543 (C:0.5543, R:0.0105)
Batch 300/537: Loss=0.5128 (C:0.5128, R:0.0105)
Batch 325/537: Loss=0.5096 (C:0.5096, R:0.0105)
Batch 350/537: Loss=0.5492 (C:0.5492, R:0.0105)
Batch 375/537: Loss=0.5410 (C:0.5410, R:0.0105)
Batch 400/537: Loss=0.5515 (C:0.5515, R:0.0105)
Batch 425/537: Loss=0.4898 (C:0.4898, R:0.0105)
Batch 450/537: Loss=0.5262 (C:0.5262, R:0.0105)
Batch 475/537: Loss=0.5511 (C:0.5511, R:0.0105)
Batch 500/537: Loss=0.5234 (C:0.5234, R:0.0105)
Batch 525/537: Loss=0.5895 (C:0.5895, R:0.0105)

============================================================
Epoch 77/300 completed in 27.3s
Train: Loss=0.5290 (C:0.5290, R:0.0105) Ratio=5.55x
Val:   Loss=0.7053 (C:0.7053, R:0.0104) Ratio=3.14x
Reconstruction weight: 0.300
No improvement for 7 epochs
============================================================

🌍 Updating global dataset at epoch 78
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.267 ± 0.527
    Neg distances: 2.727 ± 1.106
    Separation ratio: 10.20x
    Gap: -4.523
    ✅ Excellent global separation!

Epoch 78 Training
----------------------------------------
Batch   0/537: Loss=0.4595 (C:0.4595, R:0.0105)
Batch  25/537: Loss=0.4846 (C:0.4846, R:0.0105)
Batch  50/537: Loss=0.4776 (C:0.4776, R:0.0105)
Batch  75/537: Loss=0.4721 (C:0.4721, R:0.0105)
Batch 100/537: Loss=0.4616 (C:0.4616, R:0.0105)
Batch 125/537: Loss=0.4587 (C:0.4587, R:0.0105)
Batch 150/537: Loss=0.4860 (C:0.4860, R:0.0105)
Batch 175/537: Loss=0.4864 (C:0.4864, R:0.0105)
Batch 200/537: Loss=0.5279 (C:0.5279, R:0.0105)
Batch 225/537: Loss=0.5032 (C:0.5032, R:0.0105)
Batch 250/537: Loss=0.5059 (C:0.5059, R:0.0105)
Batch 275/537: Loss=0.5000 (C:0.5000, R:0.0105)
Batch 300/537: Loss=0.4407 (C:0.4407, R:0.0105)
Batch 325/537: Loss=0.4846 (C:0.4846, R:0.0105)
Batch 350/537: Loss=0.5069 (C:0.5069, R:0.0105)
Batch 375/537: Loss=0.4981 (C:0.4981, R:0.0105)
Batch 400/537: Loss=0.4726 (C:0.4726, R:0.0105)
Batch 425/537: Loss=0.4897 (C:0.4897, R:0.0105)
Batch 450/537: Loss=0.4897 (C:0.4897, R:0.0105)
Batch 475/537: Loss=0.5470 (C:0.5470, R:0.0105)
Batch 500/537: Loss=0.5028 (C:0.5028, R:0.0105)
Batch 525/537: Loss=0.5034 (C:0.5034, R:0.0105)

============================================================
Epoch 78/300 completed in 27.4s
Train: Loss=0.4916 (C:0.4916, R:0.0105) Ratio=5.38x
Val:   Loss=0.6716 (C:0.6716, R:0.0104) Ratio=3.14x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.6716)
============================================================

🌍 Updating global dataset at epoch 79
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.295 ± 0.592
    Neg distances: 2.717 ± 1.125
    Separation ratio: 9.21x
    Gap: -4.615
    ✅ Excellent global separation!

Epoch 79 Training
----------------------------------------
Batch   0/537: Loss=0.5018 (C:0.5018, R:0.0105)
Batch  25/537: Loss=0.5378 (C:0.5378, R:0.0105)
Batch  50/537: Loss=0.4851 (C:0.4851, R:0.0105)
Batch  75/537: Loss=0.4921 (C:0.4921, R:0.0105)
Batch 100/537: Loss=0.4956 (C:0.4956, R:0.0105)
Batch 125/537: Loss=0.5325 (C:0.5325, R:0.0105)
Batch 150/537: Loss=0.4910 (C:0.4910, R:0.0105)
Batch 175/537: Loss=0.5005 (C:0.5005, R:0.0105)
Batch 200/537: Loss=0.5012 (C:0.5012, R:0.0105)
Batch 225/537: Loss=0.5124 (C:0.5124, R:0.0105)
Batch 250/537: Loss=0.5097 (C:0.5097, R:0.0105)
Batch 275/537: Loss=0.4848 (C:0.4848, R:0.0105)
Batch 300/537: Loss=0.5148 (C:0.5148, R:0.0106)
Batch 325/537: Loss=0.4844 (C:0.4844, R:0.0105)
Batch 350/537: Loss=0.4950 (C:0.4950, R:0.0105)
Batch 375/537: Loss=0.5673 (C:0.5673, R:0.0105)
Batch 400/537: Loss=0.5339 (C:0.5339, R:0.0105)
Batch 425/537: Loss=0.5403 (C:0.5403, R:0.0105)
Batch 450/537: Loss=0.5193 (C:0.5193, R:0.0105)
Batch 475/537: Loss=0.5263 (C:0.5263, R:0.0105)
Batch 500/537: Loss=0.5244 (C:0.5244, R:0.0105)
Batch 525/537: Loss=0.5367 (C:0.5367, R:0.0105)

============================================================
Epoch 79/300 completed in 27.0s
Train: Loss=0.5119 (C:0.5119, R:0.0105) Ratio=5.54x
Val:   Loss=0.6978 (C:0.6978, R:0.0104) Ratio=3.12x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 80
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.279 ± 0.554
    Neg distances: 2.738 ± 1.116
    Separation ratio: 9.80x
    Gap: -4.533
    ✅ Excellent global separation!

Epoch 80 Training
----------------------------------------
Batch   0/537: Loss=0.4981 (C:0.4981, R:0.0105)
Batch  25/537: Loss=0.5098 (C:0.5098, R:0.0105)
Batch  50/537: Loss=0.4949 (C:0.4949, R:0.0105)
Batch  75/537: Loss=0.4771 (C:0.4771, R:0.0105)
Batch 100/537: Loss=0.5270 (C:0.5270, R:0.0105)
Batch 125/537: Loss=0.4819 (C:0.4819, R:0.0105)
Batch 150/537: Loss=0.4858 (C:0.4858, R:0.0105)
Batch 175/537: Loss=0.5296 (C:0.5296, R:0.0105)
Batch 200/537: Loss=0.4731 (C:0.4731, R:0.0105)
Batch 225/537: Loss=0.4977 (C:0.4977, R:0.0105)
Batch 250/537: Loss=0.5062 (C:0.5062, R:0.0105)
Batch 275/537: Loss=0.5045 (C:0.5045, R:0.0105)
Batch 300/537: Loss=0.4756 (C:0.4756, R:0.0105)
Batch 325/537: Loss=0.5490 (C:0.5490, R:0.0105)
Batch 350/537: Loss=0.5331 (C:0.5331, R:0.0106)
Batch 375/537: Loss=0.4619 (C:0.4619, R:0.0106)
Batch 400/537: Loss=0.4750 (C:0.4750, R:0.0105)
Batch 425/537: Loss=0.5299 (C:0.5299, R:0.0105)
Batch 450/537: Loss=0.5156 (C:0.5156, R:0.0105)
Batch 475/537: Loss=0.4920 (C:0.4920, R:0.0105)
Batch 500/537: Loss=0.4630 (C:0.4630, R:0.0105)
Batch 525/537: Loss=0.4810 (C:0.4810, R:0.0105)

============================================================
Epoch 80/300 completed in 27.6s
Train: Loss=0.4974 (C:0.4974, R:0.0105) Ratio=5.50x
Val:   Loss=0.6939 (C:0.6939, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.300
No improvement for 2 epochs
Checkpoint saved at epoch 80
============================================================

🌍 Updating global dataset at epoch 81
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.283 ± 0.580
    Neg distances: 2.786 ± 1.144
    Separation ratio: 9.83x
    Gap: -4.607
    ✅ Excellent global separation!

Epoch 81 Training
----------------------------------------
Batch   0/537: Loss=0.4925 (C:0.4925, R:0.0105)
Batch  25/537: Loss=0.4802 (C:0.4802, R:0.0105)
Batch  50/537: Loss=0.4797 (C:0.4797, R:0.0105)
Batch  75/537: Loss=0.4747 (C:0.4747, R:0.0105)
Batch 100/537: Loss=0.5004 (C:0.5004, R:0.0105)
Batch 125/537: Loss=0.5053 (C:0.5053, R:0.0105)
Batch 150/537: Loss=0.4767 (C:0.4767, R:0.0105)
Batch 175/537: Loss=0.5156 (C:0.5156, R:0.0105)
Batch 200/537: Loss=0.5143 (C:0.5143, R:0.0105)
Batch 225/537: Loss=0.4814 (C:0.4814, R:0.0105)
Batch 250/537: Loss=0.4846 (C:0.4846, R:0.0105)
Batch 275/537: Loss=0.4873 (C:0.4873, R:0.0105)
Batch 300/537: Loss=0.4536 (C:0.4536, R:0.0105)
Batch 325/537: Loss=0.4919 (C:0.4919, R:0.0105)
Batch 350/537: Loss=0.5037 (C:0.5037, R:0.0105)
Batch 375/537: Loss=0.5217 (C:0.5217, R:0.0105)
Batch 400/537: Loss=0.5134 (C:0.5134, R:0.0105)
Batch 425/537: Loss=0.4557 (C:0.4557, R:0.0105)
Batch 450/537: Loss=0.5214 (C:0.5214, R:0.0105)
Batch 475/537: Loss=0.4687 (C:0.4687, R:0.0105)
Batch 500/537: Loss=0.5047 (C:0.5047, R:0.0106)
Batch 525/537: Loss=0.5112 (C:0.5112, R:0.0105)

============================================================
Epoch 81/300 completed in 27.5s
Train: Loss=0.4998 (C:0.4998, R:0.0105) Ratio=5.51x
Val:   Loss=0.6961 (C:0.6961, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 82
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.272 ± 0.558
    Neg distances: 2.807 ± 1.143
    Separation ratio: 10.32x
    Gap: -4.729
    ✅ Excellent global separation!

Epoch 82 Training
----------------------------------------
Batch   0/537: Loss=0.4790 (C:0.4790, R:0.0105)
Batch  25/537: Loss=0.5282 (C:0.5282, R:0.0105)
Batch  50/537: Loss=0.5107 (C:0.5107, R:0.0105)
Batch  75/537: Loss=0.4785 (C:0.4785, R:0.0105)
Batch 100/537: Loss=0.4632 (C:0.4632, R:0.0105)
Batch 125/537: Loss=0.5072 (C:0.5072, R:0.0105)
Batch 150/537: Loss=0.4661 (C:0.4661, R:0.0105)
Batch 175/537: Loss=0.5222 (C:0.5222, R:0.0105)
Batch 200/537: Loss=0.4581 (C:0.4581, R:0.0105)
Batch 225/537: Loss=0.5026 (C:0.5026, R:0.0105)
Batch 250/537: Loss=0.5049 (C:0.5049, R:0.0105)
Batch 275/537: Loss=0.4593 (C:0.4593, R:0.0105)
Batch 300/537: Loss=0.5088 (C:0.5088, R:0.0105)
Batch 325/537: Loss=0.5457 (C:0.5457, R:0.0105)
Batch 350/537: Loss=0.5030 (C:0.5030, R:0.0105)
Batch 375/537: Loss=0.5062 (C:0.5062, R:0.0105)
Batch 400/537: Loss=0.4710 (C:0.4710, R:0.0105)
Batch 425/537: Loss=0.4493 (C:0.4493, R:0.0105)
Batch 450/537: Loss=0.5123 (C:0.5123, R:0.0105)
Batch 475/537: Loss=0.5186 (C:0.5186, R:0.0105)
Batch 500/537: Loss=0.4901 (C:0.4901, R:0.0105)
Batch 525/537: Loss=0.5201 (C:0.5201, R:0.0105)

============================================================
Epoch 82/300 completed in 27.5s
Train: Loss=0.4895 (C:0.4895, R:0.0105) Ratio=5.45x
Val:   Loss=0.6934 (C:0.6934, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 4 epochs
============================================================

🌍 Updating global dataset at epoch 83
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.297 ± 0.586
    Neg distances: 2.763 ± 1.139
    Separation ratio: 9.30x
    Gap: -4.620
    ✅ Excellent global separation!

Epoch 83 Training
----------------------------------------
Batch   0/537: Loss=0.4718 (C:0.4718, R:0.0105)
Batch  25/537: Loss=0.4754 (C:0.4754, R:0.0105)
Batch  50/537: Loss=0.5074 (C:0.5074, R:0.0105)
Batch  75/537: Loss=0.4441 (C:0.4441, R:0.0105)
Batch 100/537: Loss=0.4847 (C:0.4847, R:0.0105)
Batch 125/537: Loss=0.5256 (C:0.5256, R:0.0105)
Batch 150/537: Loss=0.5238 (C:0.5238, R:0.0105)
Batch 175/537: Loss=0.4959 (C:0.4959, R:0.0105)
Batch 200/537: Loss=0.5238 (C:0.5238, R:0.0105)
Batch 225/537: Loss=0.4969 (C:0.4969, R:0.0105)
Batch 250/537: Loss=0.5531 (C:0.5531, R:0.0105)
Batch 275/537: Loss=0.4767 (C:0.4767, R:0.0105)
Batch 300/537: Loss=0.5198 (C:0.5198, R:0.0106)
Batch 325/537: Loss=0.5073 (C:0.5073, R:0.0105)
Batch 350/537: Loss=0.5071 (C:0.5071, R:0.0105)
Batch 375/537: Loss=0.5007 (C:0.5007, R:0.0105)
Batch 400/537: Loss=0.4799 (C:0.4799, R:0.0105)
Batch 425/537: Loss=0.5459 (C:0.5459, R:0.0106)
Batch 450/537: Loss=0.5000 (C:0.5000, R:0.0105)
Batch 475/537: Loss=0.5042 (C:0.5042, R:0.0105)
Batch 500/537: Loss=0.5133 (C:0.5133, R:0.0105)
Batch 525/537: Loss=0.5324 (C:0.5324, R:0.0105)

============================================================
Epoch 83/300 completed in 27.6s
Train: Loss=0.5081 (C:0.5081, R:0.0105) Ratio=5.57x
Val:   Loss=0.6966 (C:0.6966, R:0.0104) Ratio=3.13x
Reconstruction weight: 0.300
No improvement for 5 epochs
============================================================

🌍 Updating global dataset at epoch 84
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.294 ± 0.608
    Neg distances: 2.776 ± 1.143
    Separation ratio: 9.44x
    Gap: -4.733
    ✅ Excellent global separation!

Epoch 84 Training
----------------------------------------
Batch   0/537: Loss=0.4590 (C:0.4590, R:0.0106)
Batch  25/537: Loss=0.4834 (C:0.4834, R:0.0105)
Batch  50/537: Loss=0.4601 (C:0.4601, R:0.0105)
Batch  75/537: Loss=0.5027 (C:0.5027, R:0.0106)
Batch 100/537: Loss=0.4606 (C:0.4606, R:0.0105)
Batch 125/537: Loss=0.4869 (C:0.4869, R:0.0105)
Batch 150/537: Loss=0.4834 (C:0.4834, R:0.0105)
Batch 175/537: Loss=0.4607 (C:0.4607, R:0.0105)
Batch 200/537: Loss=0.5160 (C:0.5160, R:0.0106)
Batch 225/537: Loss=0.5227 (C:0.5227, R:0.0105)
Batch 250/537: Loss=0.4871 (C:0.4871, R:0.0106)
Batch 275/537: Loss=0.5116 (C:0.5116, R:0.0105)
Batch 300/537: Loss=0.4828 (C:0.4828, R:0.0105)
Batch 325/537: Loss=0.5399 (C:0.5399, R:0.0105)
Batch 350/537: Loss=0.5315 (C:0.5315, R:0.0105)
Batch 375/537: Loss=0.5030 (C:0.5030, R:0.0105)
Batch 400/537: Loss=0.5012 (C:0.5012, R:0.0105)
Batch 425/537: Loss=0.5272 (C:0.5272, R:0.0105)
Batch 450/537: Loss=0.4985 (C:0.4985, R:0.0105)
Batch 475/537: Loss=0.5015 (C:0.5015, R:0.0105)
Batch 500/537: Loss=0.4823 (C:0.4823, R:0.0105)
Batch 525/537: Loss=0.5283 (C:0.5283, R:0.0106)

============================================================
Epoch 84/300 completed in 28.5s
Train: Loss=0.5042 (C:0.5042, R:0.0105) Ratio=5.56x
Val:   Loss=0.6910 (C:0.6910, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
No improvement for 6 epochs
============================================================

🌍 Updating global dataset at epoch 85
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.272 ± 0.578
    Neg distances: 2.787 ± 1.133
    Separation ratio: 10.26x
    Gap: -4.743
    ✅ Excellent global separation!

Epoch 85 Training
----------------------------------------
Batch   0/537: Loss=0.4886 (C:0.4886, R:0.0105)
Batch  25/537: Loss=0.5181 (C:0.5181, R:0.0105)
Batch  50/537: Loss=0.4994 (C:0.4994, R:0.0105)
Batch  75/537: Loss=0.4524 (C:0.4524, R:0.0105)
Batch 100/537: Loss=0.5103 (C:0.5103, R:0.0105)
Batch 125/537: Loss=0.4841 (C:0.4841, R:0.0105)
Batch 150/537: Loss=0.4646 (C:0.4646, R:0.0105)
Batch 175/537: Loss=0.4766 (C:0.4766, R:0.0105)
Batch 200/537: Loss=0.4444 (C:0.4444, R:0.0105)
Batch 225/537: Loss=0.4645 (C:0.4645, R:0.0105)
Batch 250/537: Loss=0.4843 (C:0.4843, R:0.0105)
Batch 275/537: Loss=0.4883 (C:0.4883, R:0.0105)
Batch 300/537: Loss=0.4761 (C:0.4761, R:0.0106)
Batch 325/537: Loss=0.4947 (C:0.4947, R:0.0105)
Batch 350/537: Loss=0.4879 (C:0.4879, R:0.0105)
Batch 375/537: Loss=0.4801 (C:0.4801, R:0.0105)
Batch 400/537: Loss=0.4881 (C:0.4881, R:0.0105)
Batch 425/537: Loss=0.5423 (C:0.5423, R:0.0105)
Batch 450/537: Loss=0.4850 (C:0.4850, R:0.0104)
Batch 475/537: Loss=0.4842 (C:0.4842, R:0.0105)
Batch 500/537: Loss=0.4476 (C:0.4476, R:0.0105)
Batch 525/537: Loss=0.5371 (C:0.5371, R:0.0105)

============================================================
Epoch 85/300 completed in 28.3s
Train: Loss=0.4865 (C:0.4865, R:0.0105) Ratio=5.57x
Val:   Loss=0.6751 (C:0.6751, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.300
No improvement for 7 epochs
============================================================

🌍 Updating global dataset at epoch 86
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.282 ± 0.587
    Neg distances: 2.765 ± 1.141
    Separation ratio: 9.80x
    Gap: -4.742
    ✅ Excellent global separation!

Epoch 86 Training
----------------------------------------
Batch   0/537: Loss=0.5344 (C:0.5344, R:0.0105)
Batch  25/537: Loss=0.4783 (C:0.4783, R:0.0106)
Batch  50/537: Loss=0.4447 (C:0.4447, R:0.0105)
Batch  75/537: Loss=0.4776 (C:0.4776, R:0.0105)
Batch 100/537: Loss=0.4774 (C:0.4774, R:0.0105)
Batch 125/537: Loss=0.4958 (C:0.4958, R:0.0105)
Batch 150/537: Loss=0.5100 (C:0.5100, R:0.0105)
Batch 175/537: Loss=0.4473 (C:0.4473, R:0.0105)
Batch 200/537: Loss=0.4663 (C:0.4663, R:0.0105)
Batch 225/537: Loss=0.4749 (C:0.4749, R:0.0105)
Batch 250/537: Loss=0.4943 (C:0.4943, R:0.0105)
Batch 275/537: Loss=0.5007 (C:0.5007, R:0.0105)
Batch 300/537: Loss=0.4860 (C:0.4860, R:0.0105)
Batch 325/537: Loss=0.4858 (C:0.4858, R:0.0105)
Batch 350/537: Loss=0.5011 (C:0.5011, R:0.0105)
Batch 375/537: Loss=0.4877 (C:0.4877, R:0.0105)
Batch 400/537: Loss=0.5384 (C:0.5384, R:0.0106)
Batch 425/537: Loss=0.5033 (C:0.5033, R:0.0105)
Batch 450/537: Loss=0.5043 (C:0.5043, R:0.0105)
Batch 475/537: Loss=0.4826 (C:0.4826, R:0.0105)
Batch 500/537: Loss=0.4977 (C:0.4977, R:0.0105)
Batch 525/537: Loss=0.5176 (C:0.5176, R:0.0105)

============================================================
Epoch 86/300 completed in 28.6s
Train: Loss=0.4951 (C:0.4951, R:0.0105) Ratio=5.60x
Val:   Loss=0.6789 (C:0.6789, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.300
No improvement for 8 epochs

Early stopping triggered after 86 epochs
Best model was at epoch 78 with Val Loss: 0.6716

Global Dataset Training Completed!
Best epoch: 78
Best validation loss: 0.6716
Final separation ratios: Train=5.60x, Val=3.11x
Training completed!
Loading best model from entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin2.0_updatefreq1_max_global_samples5000_20250715_125326/checkpoints/best_model.pt
Starting model evaluation...
========================================
GlobalContrastiveEvaluator initialized on cuda
Starting comprehensive evaluation...
============================================================
Extracting latent representations...
  Processed 1/10 batches
Extracted representations: torch.Size([9824, 75])
Evaluating clustering performance...
Clustering Results:
  Silhouette Score: 0.4644
  Adjusted Rand Score: 0.5337
  Clustering Accuracy: 0.8171
Evaluating classification performance...
  Extracting training representations...
Extracting latent representations...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
Extracted representations: torch.Size([547740, 75])
  Extracting validation representations...
Extracting latent representations...
  Processed 1/9 batches
Extracted representations: torch.Size([9180, 75])
Subsampled training to 50000 samples
  Training on 50000 samples, evaluating on 9180 samples
Classification Results:
  Accuracy: 0.8178
  Per-class F1: [0.8367172837399762, 0.761742892459827, 0.8594657375145179]
Evaluating reconstruction quality...
Reconstruction Results:
  Average MSE: 0.010432
Evaluating separation quality...
Separation Results:
  Positive distances: 0.780 ± 0.929
  Negative distances: 2.374 ± 1.272
  Separation ratio: 3.04x
  Gap: -4.768
  Perfect separation: No

Comprehensive evaluation completed!

============================================================
EVALUATION SUMMARY
============================================================
Clustering Performance:
  Silhouette Score: 0.4644
  Clustering Accuracy: 0.8171
  Adjusted Rand Score: 0.5337

Classification Performance:
  Accuracy: 0.8178

Separation Quality:
  Separation Ratio: 3.04x
  Gap: -4.768
  Perfect Separation: False

Reconstruction Quality:
  Average MSE: 0.010432
============================================================
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin2.0_updatefreq1_max_global_samples5000_20250715_125326/results/evaluation_results_20250715_133313.json
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin2.0_updatefreq1_max_global_samples5000_20250715_125326/results/evaluation_results_20250715_133313.json
Saving final experiment results...
Final results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin2.0_updatefreq1_max_global_samples5000_20250715_125326/final_results.json

============================================================
PIPELINE COMPLETED SUCCESSFULLY!
============================================================
Experiment directory: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin2.0_updatefreq1_max_global_samples5000_20250715_125326
Best model: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin2.0_updatefreq1_max_global_samples5000_20250715_125326/checkpoints/best_model.pt
Final results: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin2.0_updatefreq1_max_global_samples5000_20250715_125326/final_results.json

Key Results:
  Separation ratio: 3.04x
  Perfect separation: False
  Classification accuracy: 0.8178
  Removing previous best: coarse_margin1.0_updatefreq1_max_global_samples5000_20250715_103028
  NEW BEST: 0.8178% (improvement: +-80.85%)
  Saved best experiment: coarse_margin2.0_updatefreq1_max_global_samples5000_20250715_125326

[6/12] Testing: coarse_margin2.0_updatefreq1_max_global_samples10000
  margin: 2.0
  update_frequency: 1
  max_global_samples: 10000
  Reconstruction weight: 0.3 (fixed)
GLOBAL DATASET CONTRASTIVE AUTOENCODER PIPELINE
============================================================
Start time: 2025-07-15 13:33:13.887619
Using device: cuda

Configuration:
  Embedding type: concat
  Batch size: 1020
  Global update frequency: 1 epochs
  Training epochs: 300
Experiment setup completed:
  Experiment directory: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin2.0_updatefreq1_max_global_samples10000_20250715_133313
  Config saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin2.0_updatefreq1_max_global_samples10000_20250715_133313/config.json
Loading data...
========================================
FlexibleEmbedder initialized with type: 'concat'
Output dimension will be: 1536
GlobalDataLoader initialized:
  Embedding type: concat
  Output dimension: 1536
  Sample size: All
Starting data loading pipeline...
============================================================
Loading training data from data/processed/snli_full_standard_SBERT.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 549367 training samples
Loading validation data from data/processed/snli_full_standard_SBERT_validation.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9842 validation samples
Loading test data from data/processed/snli_full_standard_SBERT_test.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9824 test samples
Generating embeddings for training...
Generating concat embeddings on cuda
Processing 549367 samples in batches of 1000
  Processing batch 1/550
  Processing batch 6/550
  Processing batch 11/550
  Processing batch 16/550
  Processing batch 21/550
  Processing batch 26/550
  Processing batch 31/550
  Processing batch 36/550
  Processing batch 41/550
  Processing batch 46/550
  Processing batch 51/550
  Processing batch 56/550
  Processing batch 61/550
  Processing batch 66/550
  Processing batch 71/550
  Processing batch 76/550
  Processing batch 81/550
  Processing batch 86/550
  Processing batch 91/550
  Processing batch 96/550
  Processing batch 101/550
  Processing batch 106/550
  Processing batch 111/550
  Processing batch 116/550
  Processing batch 121/550
  Processing batch 126/550
  Processing batch 131/550
  Processing batch 136/550
  Processing batch 141/550
  Processing batch 146/550
  Processing batch 151/550
  Processing batch 156/550
  Processing batch 161/550
  Processing batch 166/550
  Processing batch 171/550
  Processing batch 176/550
  Processing batch 181/550
  Processing batch 186/550
  Processing batch 191/550
  Processing batch 196/550
  Processing batch 201/550
  Processing batch 206/550
  Processing batch 211/550
  Processing batch 216/550
  Processing batch 221/550
  Processing batch 226/550
  Processing batch 231/550
  Processing batch 236/550
  Processing batch 241/550
  Processing batch 246/550
  Processing batch 251/550
  Processing batch 256/550
  Processing batch 261/550
  Processing batch 266/550
  Processing batch 271/550
  Processing batch 276/550
  Processing batch 281/550
  Processing batch 286/550
  Processing batch 291/550
  Processing batch 296/550
  Processing batch 301/550
  Processing batch 306/550
  Processing batch 311/550
  Processing batch 316/550
  Processing batch 321/550
  Processing batch 326/550
  Processing batch 331/550
  Processing batch 336/550
  Processing batch 341/550
  Processing batch 346/550
  Processing batch 351/550
  Processing batch 356/550
  Processing batch 361/550
  Processing batch 366/550
  Processing batch 371/550
  Processing batch 376/550
  Processing batch 381/550
  Processing batch 386/550
  Processing batch 391/550
  Processing batch 396/550
  Processing batch 401/550
  Processing batch 406/550
  Processing batch 411/550
  Processing batch 416/550
  Processing batch 421/550
  Processing batch 426/550
  Processing batch 431/550
  Processing batch 436/550
  Processing batch 441/550
  Processing batch 446/550
  Processing batch 451/550
  Processing batch 456/550
  Processing batch 461/550
  Processing batch 466/550
  Processing batch 471/550
  Processing batch 476/550
  Processing batch 481/550
  Processing batch 486/550
  Processing batch 491/550
  Processing batch 496/550
  Processing batch 501/550
  Processing batch 506/550
  Processing batch 511/550
  Processing batch 516/550
  Processing batch 521/550
  Processing batch 526/550
  Processing batch 531/550
  Processing batch 536/550
  Processing batch 541/550
  Processing batch 546/550
Generated concat embeddings: torch.Size([549367, 1536])
Generating embeddings for validation...
Generating concat embeddings on cuda
Processing 9842 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9842, 1536])
Generating embeddings for test...
Generating concat embeddings on cuda
Processing 9824 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9824, 1536])
EntailmentDataset created: 549367 samples
  Embedding shape: torch.Size([549367, 1536])
  Class distribution: {'entailment': 183416, 'neutral': 182764, 'contradiction': 183187}
EntailmentDataset created: 9842 samples
  Embedding shape: torch.Size([9842, 1536])
  Class distribution: {'entailment': 3329, 'neutral': 3235, 'contradiction': 3278}
EntailmentDataset created: 9824 samples
  Embedding shape: torch.Size([9824, 1536])
  Class distribution: {'entailment': 3368, 'neutral': 3219, 'contradiction': 3237}

Data loading pipeline completed!
Output embedding dimension: 1536
Updated model input_dim to: 1536
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 537
  Class 2: 183187 samples
  Class 0: 183416 samples
  Class 1: 182764 samples
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 9
  Class 2: 3278 samples
  Class 0: 3329 samples
  Class 1: 3235 samples
DataLoaders created:
  Batch size: 1020
  Balanced sampling: True
  Train batches: 537
  Val batches: 9
  Test batches: 10
Data loading completed!
  Train: 549367 samples, 537 batches
  Val: 9842 samples, 9 batches
  Test: 9824 samples, 10 batches
Creating model and trainer...
========================================
ContrastiveAutoencoder initialized:
  Input dim: 1536
  Latent dim: 75
  Hidden dims: [512, 256]
  Dropout rate: 0.2
  Total parameters: 1,876,555
Model created with 1,876,555 parameters
FullDatasetContrastiveLoss initialized:
  Margin: 2.0
  Update frequency: 1 epochs
  Max global samples: 10000
FullDatasetCombinedLoss initialized:
  Contrastive weight: 1.0
  Base reconstruction weight: 0.0
  Scheduled reconstruction: warmup=30 epochs, max_weight=0.3
Optimizer created (lr=0.0001)
GlobalDatasetTrainer initialized on device: cuda
Model parameters: 1,876,555
Starting training...
========================================
Starting Global Dataset Training...
============================================================

🌍 Updating global dataset at epoch 1
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.087 ± 0.010
    Neg distances: 0.088 ± 0.010
    Separation ratio: 1.00x
    Gap: -0.145
    ❌ Poor global separation

Epoch 1 Training
----------------------------------------
Batch   0/537: Loss=1.9998 (C:1.9998, R:0.0117)
Batch  25/537: Loss=1.9945 (C:1.9945, R:0.0115)
Batch  50/537: Loss=1.9824 (C:1.9824, R:0.0114)
Batch  75/537: Loss=1.9688 (C:1.9688, R:0.0112)
Batch 100/537: Loss=1.9591 (C:1.9591, R:0.0110)
Batch 125/537: Loss=1.9554 (C:1.9554, R:0.0110)
Batch 150/537: Loss=1.9436 (C:1.9436, R:0.0108)
Batch 175/537: Loss=1.9377 (C:1.9377, R:0.0108)
Batch 200/537: Loss=1.9432 (C:1.9432, R:0.0107)
Batch 225/537: Loss=1.9270 (C:1.9270, R:0.0107)
Batch 250/537: Loss=1.9257 (C:1.9257, R:0.0107)
Batch 275/537: Loss=1.9158 (C:1.9158, R:0.0106)
Batch 300/537: Loss=1.9159 (C:1.9159, R:0.0106)
Batch 325/537: Loss=1.9118 (C:1.9118, R:0.0106)
Batch 350/537: Loss=1.9214 (C:1.9214, R:0.0105)
Batch 375/537: Loss=1.9053 (C:1.9053, R:0.0105)
Batch 400/537: Loss=1.9091 (C:1.9091, R:0.0106)
Batch 425/537: Loss=1.9147 (C:1.9147, R:0.0106)
Batch 450/537: Loss=1.9070 (C:1.9070, R:0.0106)
Batch 475/537: Loss=1.9081 (C:1.9081, R:0.0106)
Batch 500/537: Loss=1.8986 (C:1.8986, R:0.0105)
Batch 525/537: Loss=1.8986 (C:1.8986, R:0.0105)

============================================================
Epoch 1/300 completed in 27.6s
Train: Loss=1.9337 (C:1.9337, R:0.0108) Ratio=1.65x
Val:   Loss=1.8916 (C:1.8916, R:0.0105) Ratio=2.14x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.8916)
============================================================

🌍 Updating global dataset at epoch 2
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.665 ± 0.554
    Neg distances: 1.429 ± 0.830
    Separation ratio: 2.15x
    Gap: -3.705
    ✅ Good global separation

Epoch 2 Training
----------------------------------------
Batch   0/537: Loss=1.3881 (C:1.3881, R:0.0105)
Batch  25/537: Loss=1.3876 (C:1.3876, R:0.0105)
Batch  50/537: Loss=1.3825 (C:1.3825, R:0.0105)
Batch  75/537: Loss=1.3923 (C:1.3923, R:0.0105)
Batch 100/537: Loss=1.3570 (C:1.3570, R:0.0105)
Batch 125/537: Loss=1.3973 (C:1.3973, R:0.0105)
Batch 150/537: Loss=1.3651 (C:1.3651, R:0.0105)
Batch 175/537: Loss=1.3801 (C:1.3801, R:0.0105)
Batch 200/537: Loss=1.3831 (C:1.3831, R:0.0105)
Batch 225/537: Loss=1.3742 (C:1.3742, R:0.0106)
Batch 250/537: Loss=1.3755 (C:1.3755, R:0.0105)
Batch 275/537: Loss=1.3056 (C:1.3056, R:0.0105)
Batch 300/537: Loss=1.3723 (C:1.3723, R:0.0105)
Batch 325/537: Loss=1.3119 (C:1.3119, R:0.0105)
Batch 350/537: Loss=1.3928 (C:1.3928, R:0.0105)
Batch 375/537: Loss=1.3575 (C:1.3575, R:0.0105)
Batch 400/537: Loss=1.3625 (C:1.3625, R:0.0105)
Batch 425/537: Loss=1.3898 (C:1.3898, R:0.0105)
Batch 450/537: Loss=1.3707 (C:1.3707, R:0.0105)
Batch 475/537: Loss=1.3413 (C:1.3413, R:0.0105)
Batch 500/537: Loss=1.3778 (C:1.3778, R:0.0105)
Batch 525/537: Loss=1.3741 (C:1.3741, R:0.0105)

============================================================
Epoch 2/300 completed in 27.4s
Train: Loss=1.3643 (C:1.3643, R:0.0105) Ratio=2.16x
Val:   Loss=1.3368 (C:1.3368, R:0.0104) Ratio=2.37x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.3368)
============================================================

🌍 Updating global dataset at epoch 3
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.597 ± 0.560
    Neg distances: 1.500 ± 0.836
    Separation ratio: 2.51x
    Gap: -3.564
    ✅ Good global separation

Epoch 3 Training
----------------------------------------
Batch   0/537: Loss=1.2526 (C:1.2526, R:0.0105)
Batch  25/537: Loss=1.2389 (C:1.2389, R:0.0105)
Batch  50/537: Loss=1.2440 (C:1.2440, R:0.0105)
Batch  75/537: Loss=1.2550 (C:1.2550, R:0.0105)
Batch 100/537: Loss=1.2820 (C:1.2820, R:0.0105)
Batch 125/537: Loss=1.2824 (C:1.2824, R:0.0105)
Batch 150/537: Loss=1.2670 (C:1.2670, R:0.0105)
Batch 175/537: Loss=1.2376 (C:1.2376, R:0.0105)
Batch 200/537: Loss=1.2831 (C:1.2831, R:0.0105)
Batch 225/537: Loss=1.2834 (C:1.2834, R:0.0106)
Batch 250/537: Loss=1.2552 (C:1.2552, R:0.0105)
Batch 275/537: Loss=1.2720 (C:1.2720, R:0.0105)
Batch 300/537: Loss=1.2463 (C:1.2463, R:0.0105)
Batch 325/537: Loss=1.2677 (C:1.2677, R:0.0105)
Batch 350/537: Loss=1.2578 (C:1.2578, R:0.0105)
Batch 375/537: Loss=1.2967 (C:1.2967, R:0.0105)
Batch 400/537: Loss=1.2484 (C:1.2484, R:0.0105)
Batch 425/537: Loss=1.2340 (C:1.2340, R:0.0105)
Batch 450/537: Loss=1.2505 (C:1.2505, R:0.0105)
Batch 475/537: Loss=1.2546 (C:1.2546, R:0.0105)
Batch 500/537: Loss=1.2501 (C:1.2501, R:0.0105)
Batch 525/537: Loss=1.2386 (C:1.2386, R:0.0105)

============================================================
Epoch 3/300 completed in 26.8s
Train: Loss=1.2606 (C:1.2606, R:0.0105) Ratio=2.40x
Val:   Loss=1.2534 (C:1.2534, R:0.0104) Ratio=2.51x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.2534)
============================================================

🌍 Updating global dataset at epoch 4
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.575 ± 0.577
    Neg distances: 1.568 ± 0.854
    Separation ratio: 2.73x
    Gap: -3.651
    ✅ Good global separation

Epoch 4 Training
----------------------------------------
Batch   0/537: Loss=1.2019 (C:1.2019, R:0.0105)
Batch  25/537: Loss=1.1900 (C:1.1900, R:0.0105)
Batch  50/537: Loss=1.2037 (C:1.2037, R:0.0105)
Batch  75/537: Loss=1.2516 (C:1.2516, R:0.0105)
Batch 100/537: Loss=1.2169 (C:1.2169, R:0.0105)
Batch 125/537: Loss=1.1955 (C:1.1955, R:0.0105)
Batch 150/537: Loss=1.2081 (C:1.2081, R:0.0105)
Batch 175/537: Loss=1.2090 (C:1.2090, R:0.0105)
Batch 200/537: Loss=1.2131 (C:1.2131, R:0.0105)
Batch 225/537: Loss=1.2054 (C:1.2054, R:0.0105)
Batch 250/537: Loss=1.1912 (C:1.1912, R:0.0105)
Batch 275/537: Loss=1.2153 (C:1.2153, R:0.0105)
Batch 300/537: Loss=1.2562 (C:1.2562, R:0.0105)
Batch 325/537: Loss=1.1566 (C:1.1566, R:0.0105)
Batch 350/537: Loss=1.1852 (C:1.1852, R:0.0105)
Batch 375/537: Loss=1.1861 (C:1.1861, R:0.0105)
Batch 400/537: Loss=1.2037 (C:1.2037, R:0.0105)
Batch 425/537: Loss=1.2105 (C:1.2105, R:0.0105)
Batch 450/537: Loss=1.2114 (C:1.2114, R:0.0105)
Batch 475/537: Loss=1.1509 (C:1.1509, R:0.0106)
Batch 500/537: Loss=1.2021 (C:1.2021, R:0.0105)
Batch 525/537: Loss=1.2184 (C:1.2184, R:0.0105)

============================================================
Epoch 4/300 completed in 27.3s
Train: Loss=1.2060 (C:1.2060, R:0.0105) Ratio=2.61x
Val:   Loss=1.2070 (C:1.2070, R:0.0104) Ratio=2.61x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.2070)
============================================================

🌍 Updating global dataset at epoch 5
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.568 ± 0.577
    Neg distances: 1.621 ± 0.872
    Separation ratio: 2.85x
    Gap: -3.648
    ✅ Good global separation

Epoch 5 Training
----------------------------------------
Batch   0/537: Loss=1.1527 (C:1.1527, R:0.0105)
Batch  25/537: Loss=1.1173 (C:1.1173, R:0.0105)
Batch  50/537: Loss=1.1903 (C:1.1903, R:0.0105)
Batch  75/537: Loss=1.1765 (C:1.1765, R:0.0105)
Batch 100/537: Loss=1.1779 (C:1.1779, R:0.0105)
Batch 125/537: Loss=1.1757 (C:1.1757, R:0.0105)
Batch 150/537: Loss=1.1508 (C:1.1508, R:0.0105)
Batch 175/537: Loss=1.1159 (C:1.1159, R:0.0105)
Batch 200/537: Loss=1.1319 (C:1.1319, R:0.0105)
Batch 225/537: Loss=1.1586 (C:1.1586, R:0.0105)
Batch 250/537: Loss=1.2034 (C:1.2034, R:0.0105)
Batch 275/537: Loss=1.1436 (C:1.1436, R:0.0105)
Batch 300/537: Loss=1.2081 (C:1.2081, R:0.0105)
Batch 325/537: Loss=1.1848 (C:1.1848, R:0.0105)
Batch 350/537: Loss=1.1867 (C:1.1867, R:0.0105)
Batch 375/537: Loss=1.1746 (C:1.1746, R:0.0105)
Batch 400/537: Loss=1.1822 (C:1.1822, R:0.0105)
Batch 425/537: Loss=1.1831 (C:1.1831, R:0.0105)
Batch 450/537: Loss=1.1649 (C:1.1649, R:0.0105)
Batch 475/537: Loss=1.1465 (C:1.1465, R:0.0105)
Batch 500/537: Loss=1.1712 (C:1.1712, R:0.0105)
Batch 525/537: Loss=1.1704 (C:1.1704, R:0.0105)

============================================================
Epoch 5/300 completed in 27.5s
Train: Loss=1.1710 (C:1.1710, R:0.0105) Ratio=2.71x
Val:   Loss=1.1789 (C:1.1789, R:0.0104) Ratio=2.70x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.1789)
============================================================

🌍 Updating global dataset at epoch 6
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.542 ± 0.568
    Neg distances: 1.686 ± 0.883
    Separation ratio: 3.11x
    Gap: -3.512
    ✅ Excellent global separation!

Epoch 6 Training
----------------------------------------
Batch   0/537: Loss=1.1045 (C:1.1045, R:0.0105)
Batch  25/537: Loss=1.1403 (C:1.1403, R:0.0105)
Batch  50/537: Loss=1.1245 (C:1.1245, R:0.0105)
Batch  75/537: Loss=1.1144 (C:1.1144, R:0.0105)
Batch 100/537: Loss=1.1494 (C:1.1494, R:0.0105)
Batch 125/537: Loss=1.1305 (C:1.1305, R:0.0105)
Batch 150/537: Loss=1.1241 (C:1.1241, R:0.0106)
Batch 175/537: Loss=1.1270 (C:1.1270, R:0.0105)
Batch 200/537: Loss=1.0824 (C:1.0824, R:0.0105)
Batch 225/537: Loss=1.1182 (C:1.1182, R:0.0105)
Batch 250/537: Loss=1.1401 (C:1.1401, R:0.0105)
Batch 275/537: Loss=1.1208 (C:1.1208, R:0.0105)
Batch 300/537: Loss=1.1096 (C:1.1096, R:0.0105)
Batch 325/537: Loss=1.1344 (C:1.1344, R:0.0105)
Batch 350/537: Loss=1.1304 (C:1.1304, R:0.0105)
Batch 375/537: Loss=1.1238 (C:1.1238, R:0.0105)
Batch 400/537: Loss=1.0940 (C:1.0940, R:0.0105)
Batch 425/537: Loss=1.1099 (C:1.1099, R:0.0105)
Batch 450/537: Loss=1.1111 (C:1.1111, R:0.0105)
Batch 475/537: Loss=1.1537 (C:1.1537, R:0.0105)
Batch 500/537: Loss=1.1143 (C:1.1143, R:0.0105)
Batch 525/537: Loss=1.1148 (C:1.1148, R:0.0106)

============================================================
Epoch 6/300 completed in 27.2s
Train: Loss=1.1231 (C:1.1231, R:0.0105) Ratio=2.79x
Val:   Loss=1.1311 (C:1.1311, R:0.0104) Ratio=2.75x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.1311)
============================================================

🌍 Updating global dataset at epoch 7
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.529 ± 0.582
    Neg distances: 1.742 ± 0.892
    Separation ratio: 3.29x
    Gap: -3.497
    ✅ Excellent global separation!

Epoch 7 Training
----------------------------------------
Batch   0/537: Loss=1.1052 (C:1.1052, R:0.0105)
Batch  25/537: Loss=1.0972 (C:1.0972, R:0.0105)
Batch  50/537: Loss=1.0889 (C:1.0889, R:0.0105)
Batch  75/537: Loss=1.0948 (C:1.0948, R:0.0105)
Batch 100/537: Loss=1.0706 (C:1.0706, R:0.0105)
Batch 125/537: Loss=1.0627 (C:1.0627, R:0.0105)
Batch 150/537: Loss=1.0712 (C:1.0712, R:0.0105)
Batch 175/537: Loss=1.0837 (C:1.0837, R:0.0105)
Batch 200/537: Loss=1.0779 (C:1.0779, R:0.0105)
Batch 225/537: Loss=1.0977 (C:1.0977, R:0.0105)
Batch 250/537: Loss=1.1001 (C:1.1001, R:0.0105)
Batch 275/537: Loss=1.0709 (C:1.0709, R:0.0105)
Batch 300/537: Loss=1.0786 (C:1.0786, R:0.0105)
Batch 325/537: Loss=1.0769 (C:1.0769, R:0.0105)
Batch 350/537: Loss=1.0674 (C:1.0674, R:0.0105)
Batch 375/537: Loss=1.0553 (C:1.0553, R:0.0105)
Batch 400/537: Loss=1.0967 (C:1.0967, R:0.0105)
Batch 425/537: Loss=1.0510 (C:1.0510, R:0.0105)
Batch 450/537: Loss=1.0959 (C:1.0959, R:0.0105)
Batch 475/537: Loss=1.0734 (C:1.0734, R:0.0105)
Batch 500/537: Loss=1.0923 (C:1.0923, R:0.0105)
Batch 525/537: Loss=1.0874 (C:1.0874, R:0.0105)

============================================================
Epoch 7/300 completed in 26.6s
Train: Loss=1.0868 (C:1.0868, R:0.0105) Ratio=2.92x
Val:   Loss=1.1029 (C:1.1029, R:0.0104) Ratio=2.81x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.1029)
============================================================

🌍 Updating global dataset at epoch 8
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.514 ± 0.572
    Neg distances: 1.790 ± 0.903
    Separation ratio: 3.48x
    Gap: -3.506
    ✅ Excellent global separation!

Epoch 8 Training
----------------------------------------
Batch   0/537: Loss=1.0423 (C:1.0423, R:0.0105)
Batch  25/537: Loss=1.0581 (C:1.0581, R:0.0105)
Batch  50/537: Loss=1.0568 (C:1.0568, R:0.0105)
Batch  75/537: Loss=1.0638 (C:1.0638, R:0.0105)
Batch 100/537: Loss=1.0769 (C:1.0769, R:0.0105)
Batch 125/537: Loss=1.0808 (C:1.0808, R:0.0105)
Batch 150/537: Loss=1.0408 (C:1.0408, R:0.0105)
Batch 175/537: Loss=1.0207 (C:1.0207, R:0.0105)
Batch 200/537: Loss=1.1221 (C:1.1221, R:0.0105)
Batch 225/537: Loss=1.0803 (C:1.0803, R:0.0105)
Batch 250/537: Loss=1.0562 (C:1.0562, R:0.0106)
Batch 275/537: Loss=1.0543 (C:1.0543, R:0.0105)
Batch 300/537: Loss=1.0642 (C:1.0642, R:0.0105)
Batch 325/537: Loss=1.0508 (C:1.0508, R:0.0105)
Batch 350/537: Loss=1.0635 (C:1.0635, R:0.0105)
Batch 375/537: Loss=1.0218 (C:1.0218, R:0.0105)
Batch 400/537: Loss=1.1059 (C:1.1059, R:0.0105)
Batch 425/537: Loss=1.0705 (C:1.0705, R:0.0105)
Batch 450/537: Loss=1.0637 (C:1.0637, R:0.0105)
Batch 475/537: Loss=1.0969 (C:1.0969, R:0.0105)
Batch 500/537: Loss=1.0899 (C:1.0899, R:0.0105)
Batch 525/537: Loss=1.0854 (C:1.0854, R:0.0105)

============================================================
Epoch 8/300 completed in 27.1s
Train: Loss=1.0568 (C:1.0568, R:0.0105) Ratio=2.97x
Val:   Loss=1.0807 (C:1.0807, R:0.0104) Ratio=2.83x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.0807)
============================================================

🌍 Updating global dataset at epoch 9
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.521 ± 0.606
    Neg distances: 1.866 ± 0.934
    Separation ratio: 3.58x
    Gap: -3.472
    ✅ Excellent global separation!

Epoch 9 Training
----------------------------------------
Batch   0/537: Loss=1.0325 (C:1.0325, R:0.0105)
Batch  25/537: Loss=1.0702 (C:1.0702, R:0.0105)
Batch  50/537: Loss=0.9696 (C:0.9696, R:0.0105)
Batch  75/537: Loss=1.0317 (C:1.0317, R:0.0105)
Batch 100/537: Loss=1.0354 (C:1.0354, R:0.0105)
Batch 125/537: Loss=1.0383 (C:1.0383, R:0.0105)
Batch 150/537: Loss=1.0231 (C:1.0231, R:0.0105)
Batch 175/537: Loss=1.0351 (C:1.0351, R:0.0105)
Batch 200/537: Loss=1.0339 (C:1.0339, R:0.0105)
Batch 225/537: Loss=1.0113 (C:1.0113, R:0.0105)
Batch 250/537: Loss=1.0430 (C:1.0430, R:0.0105)
Batch 275/537: Loss=1.0195 (C:1.0195, R:0.0105)
Batch 300/537: Loss=1.0360 (C:1.0360, R:0.0105)
Batch 325/537: Loss=1.0181 (C:1.0181, R:0.0106)
Batch 350/537: Loss=1.0273 (C:1.0273, R:0.0105)
Batch 375/537: Loss=0.9691 (C:0.9691, R:0.0105)
Batch 400/537: Loss=1.0160 (C:1.0160, R:0.0105)
Batch 425/537: Loss=1.0599 (C:1.0599, R:0.0105)
Batch 450/537: Loss=1.0189 (C:1.0189, R:0.0105)
Batch 475/537: Loss=1.0479 (C:1.0479, R:0.0105)
Batch 500/537: Loss=1.0720 (C:1.0720, R:0.0105)
Batch 525/537: Loss=1.0563 (C:1.0563, R:0.0105)

============================================================
Epoch 9/300 completed in 26.7s
Train: Loss=1.0324 (C:1.0324, R:0.0105) Ratio=3.10x
Val:   Loss=1.0610 (C:1.0610, R:0.0104) Ratio=2.85x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.0610)
============================================================

🌍 Updating global dataset at epoch 10
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.517 ± 0.590
    Neg distances: 1.923 ± 0.950
    Separation ratio: 3.72x
    Gap: -3.588
    ✅ Excellent global separation!

Epoch 10 Training
----------------------------------------
Batch   0/537: Loss=0.9854 (C:0.9854, R:0.0105)
Batch  25/537: Loss=1.0019 (C:1.0019, R:0.0105)
Batch  50/537: Loss=0.9675 (C:0.9675, R:0.0105)
Batch  75/537: Loss=1.0267 (C:1.0267, R:0.0105)
Batch 100/537: Loss=1.0157 (C:1.0157, R:0.0105)
Batch 125/537: Loss=1.0641 (C:1.0641, R:0.0105)
Batch 150/537: Loss=0.9892 (C:0.9892, R:0.0105)
Batch 175/537: Loss=1.0087 (C:1.0087, R:0.0105)
Batch 200/537: Loss=0.9854 (C:0.9854, R:0.0105)
Batch 225/537: Loss=1.0040 (C:1.0040, R:0.0105)
Batch 250/537: Loss=1.0049 (C:1.0049, R:0.0105)
Batch 275/537: Loss=1.0172 (C:1.0172, R:0.0105)
Batch 300/537: Loss=1.0227 (C:1.0227, R:0.0106)
Batch 325/537: Loss=1.0021 (C:1.0021, R:0.0105)
Batch 350/537: Loss=1.0340 (C:1.0340, R:0.0105)
Batch 375/537: Loss=0.9755 (C:0.9755, R:0.0105)
Batch 400/537: Loss=1.0273 (C:1.0273, R:0.0105)
Batch 425/537: Loss=1.0348 (C:1.0348, R:0.0105)
Batch 450/537: Loss=0.9942 (C:0.9942, R:0.0105)
Batch 475/537: Loss=1.0160 (C:1.0160, R:0.0105)
Batch 500/537: Loss=1.0495 (C:1.0495, R:0.0105)
Batch 525/537: Loss=1.0256 (C:1.0256, R:0.0105)

============================================================
Epoch 10/300 completed in 26.7s
Train: Loss=1.0076 (C:1.0076, R:0.0105) Ratio=3.16x
Val:   Loss=1.0426 (C:1.0426, R:0.0104) Ratio=2.88x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.0426)
============================================================

🌍 Updating global dataset at epoch 11
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.519 ± 0.603
    Neg distances: 1.940 ± 0.952
    Separation ratio: 3.74x
    Gap: -3.615
    ✅ Excellent global separation!

Epoch 11 Training
----------------------------------------
Batch   0/537: Loss=1.0001 (C:1.0001, R:0.0105)
Batch  25/537: Loss=0.9531 (C:0.9531, R:0.0105)
Batch  50/537: Loss=1.0043 (C:1.0043, R:0.0105)
Batch  75/537: Loss=1.0057 (C:1.0057, R:0.0105)
Batch 100/537: Loss=0.9696 (C:0.9696, R:0.0106)
Batch 125/537: Loss=0.9791 (C:0.9791, R:0.0106)
Batch 150/537: Loss=0.9931 (C:0.9931, R:0.0105)
Batch 175/537: Loss=0.9618 (C:0.9618, R:0.0106)
Batch 200/537: Loss=0.9793 (C:0.9793, R:0.0105)
Batch 225/537: Loss=1.0010 (C:1.0010, R:0.0105)
Batch 250/537: Loss=0.9549 (C:0.9549, R:0.0105)
Batch 275/537: Loss=0.9589 (C:0.9589, R:0.0106)
Batch 300/537: Loss=0.9602 (C:0.9602, R:0.0105)
Batch 325/537: Loss=0.9996 (C:0.9996, R:0.0105)
Batch 350/537: Loss=1.0285 (C:1.0285, R:0.0105)
Batch 375/537: Loss=1.0058 (C:1.0058, R:0.0105)
Batch 400/537: Loss=0.9872 (C:0.9872, R:0.0105)
Batch 425/537: Loss=0.9634 (C:0.9634, R:0.0105)
Batch 450/537: Loss=0.9855 (C:0.9855, R:0.0106)
Batch 475/537: Loss=0.9615 (C:0.9615, R:0.0105)
Batch 500/537: Loss=0.9683 (C:0.9683, R:0.0105)
Batch 525/537: Loss=1.0147 (C:1.0147, R:0.0105)

============================================================
Epoch 11/300 completed in 27.1s
Train: Loss=0.9941 (C:0.9941, R:0.0105) Ratio=3.28x
Val:   Loss=1.0433 (C:1.0433, R:0.0104) Ratio=2.89x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 12
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.518 ± 0.620
    Neg distances: 2.000 ± 0.976
    Separation ratio: 3.86x
    Gap: -3.699
    ✅ Excellent global separation!

Epoch 12 Training
----------------------------------------
Batch   0/537: Loss=0.9595 (C:0.9595, R:0.0105)
Batch  25/537: Loss=0.9135 (C:0.9135, R:0.0105)
Batch  50/537: Loss=0.9709 (C:0.9709, R:0.0105)
Batch  75/537: Loss=0.9662 (C:0.9662, R:0.0105)
Batch 100/537: Loss=1.0004 (C:1.0004, R:0.0105)
Batch 125/537: Loss=0.9492 (C:0.9492, R:0.0105)
Batch 150/537: Loss=0.9815 (C:0.9815, R:0.0105)
Batch 175/537: Loss=0.9600 (C:0.9600, R:0.0105)
Batch 200/537: Loss=0.9486 (C:0.9486, R:0.0105)
Batch 225/537: Loss=0.9956 (C:0.9956, R:0.0105)
Batch 250/537: Loss=0.9635 (C:0.9635, R:0.0105)
Batch 275/537: Loss=0.9685 (C:0.9685, R:0.0105)
Batch 300/537: Loss=0.9745 (C:0.9745, R:0.0105)
Batch 325/537: Loss=0.9793 (C:0.9793, R:0.0105)
Batch 350/537: Loss=0.9766 (C:0.9766, R:0.0105)
Batch 375/537: Loss=0.9687 (C:0.9687, R:0.0105)
Batch 400/537: Loss=0.9463 (C:0.9463, R:0.0105)
Batch 425/537: Loss=1.0006 (C:1.0006, R:0.0105)
Batch 450/537: Loss=1.0130 (C:1.0130, R:0.0105)
Batch 475/537: Loss=0.9975 (C:0.9975, R:0.0105)
Batch 500/537: Loss=0.9697 (C:0.9697, R:0.0105)
Batch 525/537: Loss=0.9956 (C:0.9956, R:0.0105)

============================================================
Epoch 12/300 completed in 27.3s
Train: Loss=0.9746 (C:0.9746, R:0.0105) Ratio=3.29x
Val:   Loss=1.0096 (C:1.0096, R:0.0104) Ratio=2.95x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.0096)
============================================================

🌍 Updating global dataset at epoch 13
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.512 ± 0.619
    Neg distances: 2.013 ± 0.972
    Separation ratio: 3.93x
    Gap: -3.699
    ✅ Excellent global separation!

Epoch 13 Training
----------------------------------------
Batch   0/537: Loss=0.9370 (C:0.9370, R:0.0105)
Batch  25/537: Loss=0.9503 (C:0.9503, R:0.0105)
Batch  50/537: Loss=0.9382 (C:0.9382, R:0.0105)
Batch  75/537: Loss=0.9606 (C:0.9606, R:0.0105)
Batch 100/537: Loss=0.9472 (C:0.9472, R:0.0105)
Batch 125/537: Loss=0.9430 (C:0.9430, R:0.0105)
Batch 150/537: Loss=0.9599 (C:0.9599, R:0.0105)
Batch 175/537: Loss=0.9908 (C:0.9908, R:0.0105)
Batch 200/537: Loss=0.9632 (C:0.9632, R:0.0105)
Batch 225/537: Loss=0.9658 (C:0.9658, R:0.0105)
Batch 250/537: Loss=0.9908 (C:0.9908, R:0.0105)
Batch 275/537: Loss=0.9823 (C:0.9823, R:0.0105)
Batch 300/537: Loss=0.9288 (C:0.9288, R:0.0105)
Batch 325/537: Loss=0.9639 (C:0.9639, R:0.0105)
Batch 350/537: Loss=0.9377 (C:0.9377, R:0.0105)
Batch 375/537: Loss=0.9868 (C:0.9868, R:0.0105)
Batch 400/537: Loss=0.9170 (C:0.9170, R:0.0105)
Batch 425/537: Loss=0.9509 (C:0.9509, R:0.0105)
Batch 450/537: Loss=0.9800 (C:0.9800, R:0.0105)
Batch 475/537: Loss=0.9759 (C:0.9759, R:0.0105)
Batch 500/537: Loss=0.9452 (C:0.9452, R:0.0105)
Batch 525/537: Loss=0.9606 (C:0.9606, R:0.0105)

============================================================
Epoch 13/300 completed in 26.8s
Train: Loss=0.9590 (C:0.9590, R:0.0105) Ratio=3.33x
Val:   Loss=0.9968 (C:0.9968, R:0.0104) Ratio=2.94x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.9968)
============================================================

🌍 Updating global dataset at epoch 14
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.496 ± 0.614
    Neg distances: 2.080 ± 0.992
    Separation ratio: 4.19x
    Gap: -3.807
    ✅ Excellent global separation!

Epoch 14 Training
----------------------------------------
Batch   0/537: Loss=0.9063 (C:0.9063, R:0.0105)
Batch  25/537: Loss=0.9334 (C:0.9334, R:0.0105)
Batch  50/537: Loss=0.9220 (C:0.9220, R:0.0106)
Batch  75/537: Loss=0.9381 (C:0.9381, R:0.0105)
Batch 100/537: Loss=0.9739 (C:0.9739, R:0.0105)
Batch 125/537: Loss=0.9097 (C:0.9097, R:0.0105)
Batch 150/537: Loss=0.9224 (C:0.9224, R:0.0105)
Batch 175/537: Loss=0.9173 (C:0.9173, R:0.0105)
Batch 200/537: Loss=0.9634 (C:0.9634, R:0.0105)
Batch 225/537: Loss=0.9275 (C:0.9275, R:0.0105)
Batch 250/537: Loss=0.9314 (C:0.9314, R:0.0105)
Batch 275/537: Loss=0.9264 (C:0.9264, R:0.0105)
Batch 300/537: Loss=0.9542 (C:0.9542, R:0.0105)
Batch 325/537: Loss=0.9352 (C:0.9352, R:0.0105)
Batch 350/537: Loss=0.9346 (C:0.9346, R:0.0105)
Batch 375/537: Loss=0.9566 (C:0.9566, R:0.0105)
Batch 400/537: Loss=0.9434 (C:0.9434, R:0.0105)
Batch 425/537: Loss=0.9552 (C:0.9552, R:0.0105)
Batch 450/537: Loss=0.9363 (C:0.9363, R:0.0105)
Batch 475/537: Loss=0.9296 (C:0.9296, R:0.0105)
Batch 500/537: Loss=0.9611 (C:0.9611, R:0.0105)
Batch 525/537: Loss=0.9459 (C:0.9459, R:0.0105)

============================================================
Epoch 14/300 completed in 27.6s
Train: Loss=0.9303 (C:0.9303, R:0.0105) Ratio=3.42x
Val:   Loss=0.9704 (C:0.9704, R:0.0104) Ratio=2.95x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.9704)
============================================================

🌍 Updating global dataset at epoch 15
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.500 ± 0.598
    Neg distances: 2.088 ± 0.994
    Separation ratio: 4.18x
    Gap: -3.798
    ✅ Excellent global separation!

Epoch 15 Training
----------------------------------------
Batch   0/537: Loss=0.9085 (C:0.9085, R:0.0105)
Batch  25/537: Loss=0.8832 (C:0.8832, R:0.0105)
Batch  50/537: Loss=0.9040 (C:0.9040, R:0.0105)
Batch  75/537: Loss=0.9082 (C:0.9082, R:0.0106)
Batch 100/537: Loss=0.9072 (C:0.9072, R:0.0105)
Batch 125/537: Loss=0.9301 (C:0.9301, R:0.0105)
Batch 150/537: Loss=0.9283 (C:0.9283, R:0.0105)
Batch 175/537: Loss=0.9555 (C:0.9555, R:0.0105)
Batch 200/537: Loss=0.9174 (C:0.9174, R:0.0105)
Batch 225/537: Loss=0.9490 (C:0.9490, R:0.0105)
Batch 250/537: Loss=0.9600 (C:0.9600, R:0.0105)
Batch 275/537: Loss=0.8939 (C:0.8939, R:0.0105)
Batch 300/537: Loss=0.9625 (C:0.9625, R:0.0105)
Batch 325/537: Loss=0.9485 (C:0.9485, R:0.0105)
Batch 350/537: Loss=0.9402 (C:0.9402, R:0.0105)
Batch 375/537: Loss=0.9250 (C:0.9250, R:0.0105)
Batch 400/537: Loss=0.9259 (C:0.9259, R:0.0105)
Batch 425/537: Loss=0.9579 (C:0.9579, R:0.0105)
Batch 450/537: Loss=0.9266 (C:0.9266, R:0.0105)
Batch 475/537: Loss=0.9321 (C:0.9321, R:0.0106)
Batch 500/537: Loss=0.9352 (C:0.9352, R:0.0105)
Batch 525/537: Loss=0.9183 (C:0.9183, R:0.0105)

============================================================
Epoch 15/300 completed in 27.4s
Train: Loss=0.9231 (C:0.9231, R:0.0105) Ratio=3.38x
Val:   Loss=0.9811 (C:0.9811, R:0.0104) Ratio=2.97x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 16
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.497 ± 0.625
    Neg distances: 2.129 ± 1.005
    Separation ratio: 4.28x
    Gap: -3.807
    ✅ Excellent global separation!

Epoch 16 Training
----------------------------------------
Batch   0/537: Loss=0.9254 (C:0.9254, R:0.0105)
Batch  25/537: Loss=0.8858 (C:0.8858, R:0.0105)
Batch  50/537: Loss=0.9114 (C:0.9114, R:0.0105)
Batch  75/537: Loss=0.8697 (C:0.8697, R:0.0105)
Batch 100/537: Loss=0.9330 (C:0.9330, R:0.0105)
Batch 125/537: Loss=0.9051 (C:0.9051, R:0.0105)
Batch 150/537: Loss=0.9026 (C:0.9026, R:0.0105)
Batch 175/537: Loss=0.8806 (C:0.8806, R:0.0105)
Batch 200/537: Loss=0.8973 (C:0.8973, R:0.0105)
Batch 225/537: Loss=0.8840 (C:0.8840, R:0.0105)
Batch 250/537: Loss=0.8632 (C:0.8632, R:0.0105)
Batch 275/537: Loss=0.9520 (C:0.9520, R:0.0105)
Batch 300/537: Loss=0.8777 (C:0.8777, R:0.0105)
Batch 325/537: Loss=0.9554 (C:0.9554, R:0.0105)
Batch 350/537: Loss=0.9315 (C:0.9315, R:0.0105)
Batch 375/537: Loss=0.9145 (C:0.9145, R:0.0105)
Batch 400/537: Loss=0.8914 (C:0.8914, R:0.0105)
Batch 425/537: Loss=0.9032 (C:0.9032, R:0.0105)
Batch 450/537: Loss=0.8828 (C:0.8828, R:0.0105)
Batch 475/537: Loss=0.9055 (C:0.9055, R:0.0105)
Batch 500/537: Loss=0.8564 (C:0.8564, R:0.0105)
Batch 525/537: Loss=0.9344 (C:0.9344, R:0.0105)

============================================================
Epoch 16/300 completed in 27.8s
Train: Loss=0.9052 (C:0.9052, R:0.0105) Ratio=3.49x
Val:   Loss=0.9665 (C:0.9665, R:0.0104) Ratio=2.97x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.9665)
============================================================

🌍 Updating global dataset at epoch 17
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.477 ± 0.596
    Neg distances: 2.129 ± 0.992
    Separation ratio: 4.46x
    Gap: -3.843
    ✅ Excellent global separation!

Epoch 17 Training
----------------------------------------
Batch   0/537: Loss=0.8799 (C:0.8799, R:0.0105)
Batch  25/537: Loss=0.9002 (C:0.9002, R:0.0105)
Batch  50/537: Loss=0.9087 (C:0.9087, R:0.0105)
Batch  75/537: Loss=0.8681 (C:0.8681, R:0.0105)
Batch 100/537: Loss=0.8856 (C:0.8856, R:0.0105)
Batch 125/537: Loss=0.8567 (C:0.8567, R:0.0105)
Batch 150/537: Loss=0.8480 (C:0.8480, R:0.0105)
Batch 175/537: Loss=0.9387 (C:0.9387, R:0.0105)
Batch 200/537: Loss=0.8797 (C:0.8797, R:0.0105)
Batch 225/537: Loss=0.8882 (C:0.8882, R:0.0105)
Batch 250/537: Loss=0.8648 (C:0.8648, R:0.0105)
Batch 275/537: Loss=0.8766 (C:0.8766, R:0.0105)
Batch 300/537: Loss=0.8713 (C:0.8713, R:0.0105)
Batch 325/537: Loss=0.9033 (C:0.9033, R:0.0105)
Batch 350/537: Loss=0.9137 (C:0.9137, R:0.0105)
Batch 375/537: Loss=0.8655 (C:0.8655, R:0.0105)
Batch 400/537: Loss=0.8996 (C:0.8996, R:0.0105)
Batch 425/537: Loss=0.9411 (C:0.9411, R:0.0105)
Batch 450/537: Loss=0.8947 (C:0.8947, R:0.0105)
Batch 475/537: Loss=0.8581 (C:0.8581, R:0.0105)
Batch 500/537: Loss=0.9381 (C:0.9381, R:0.0105)
Batch 525/537: Loss=0.8948 (C:0.8948, R:0.0105)

============================================================
Epoch 17/300 completed in 27.7s
Train: Loss=0.8836 (C:0.8836, R:0.0105) Ratio=3.51x
Val:   Loss=0.9441 (C:0.9441, R:0.0104) Ratio=2.96x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.9441)
============================================================

🌍 Updating global dataset at epoch 18
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.490 ± 0.619
    Neg distances: 2.200 ± 1.026
    Separation ratio: 4.49x
    Gap: -3.927
    ✅ Excellent global separation!

Epoch 18 Training
----------------------------------------
Batch   0/537: Loss=0.9019 (C:0.9019, R:0.0105)
Batch  25/537: Loss=0.8735 (C:0.8735, R:0.0105)
Batch  50/537: Loss=0.8782 (C:0.8782, R:0.0105)
Batch  75/537: Loss=0.8672 (C:0.8672, R:0.0105)
Batch 100/537: Loss=0.8617 (C:0.8617, R:0.0105)
Batch 125/537: Loss=0.8836 (C:0.8836, R:0.0105)
Batch 150/537: Loss=0.9045 (C:0.9045, R:0.0105)
Batch 175/537: Loss=0.8362 (C:0.8362, R:0.0105)
Batch 200/537: Loss=0.8927 (C:0.8927, R:0.0105)
Batch 225/537: Loss=0.8873 (C:0.8873, R:0.0105)
Batch 250/537: Loss=0.8789 (C:0.8789, R:0.0105)
Batch 275/537: Loss=0.8812 (C:0.8812, R:0.0105)
Batch 300/537: Loss=0.8839 (C:0.8839, R:0.0105)
Batch 325/537: Loss=0.8770 (C:0.8770, R:0.0105)
Batch 350/537: Loss=0.9212 (C:0.9212, R:0.0105)
Batch 375/537: Loss=0.8758 (C:0.8758, R:0.0105)
Batch 400/537: Loss=0.8418 (C:0.8418, R:0.0105)
Batch 425/537: Loss=0.9190 (C:0.9190, R:0.0105)
Batch 450/537: Loss=0.9052 (C:0.9052, R:0.0105)
Batch 475/537: Loss=0.8892 (C:0.8892, R:0.0105)
Batch 500/537: Loss=0.8953 (C:0.8953, R:0.0105)
Batch 525/537: Loss=0.8785 (C:0.8785, R:0.0105)

============================================================
Epoch 18/300 completed in 27.5s
Train: Loss=0.8752 (C:0.8752, R:0.0105) Ratio=3.54x
Val:   Loss=0.9338 (C:0.9338, R:0.0104) Ratio=2.98x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.9338)
============================================================

🌍 Updating global dataset at epoch 19
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.475 ± 0.615
    Neg distances: 2.232 ± 1.031
    Separation ratio: 4.70x
    Gap: -3.997
    ✅ Excellent global separation!

Epoch 19 Training
----------------------------------------
Batch   0/537: Loss=0.8419 (C:0.8419, R:0.0105)
Batch  25/537: Loss=0.8642 (C:0.8642, R:0.0105)
Batch  50/537: Loss=0.8331 (C:0.8331, R:0.0105)
Batch  75/537: Loss=0.8354 (C:0.8354, R:0.0105)
Batch 100/537: Loss=0.8615 (C:0.8615, R:0.0105)
Batch 125/537: Loss=0.8327 (C:0.8327, R:0.0106)
Batch 150/537: Loss=0.8152 (C:0.8152, R:0.0105)
Batch 175/537: Loss=0.8286 (C:0.8286, R:0.0105)
Batch 200/537: Loss=0.8456 (C:0.8456, R:0.0105)
Batch 225/537: Loss=0.8423 (C:0.8423, R:0.0105)
Batch 250/537: Loss=0.8750 (C:0.8750, R:0.0105)
Batch 275/537: Loss=0.8688 (C:0.8688, R:0.0105)
Batch 300/537: Loss=0.8521 (C:0.8521, R:0.0105)
Batch 325/537: Loss=0.8451 (C:0.8451, R:0.0105)
Batch 350/537: Loss=0.8507 (C:0.8507, R:0.0105)
Batch 375/537: Loss=0.8576 (C:0.8576, R:0.0105)
Batch 400/537: Loss=0.8684 (C:0.8684, R:0.0105)
Batch 425/537: Loss=0.8414 (C:0.8414, R:0.0105)
Batch 450/537: Loss=0.8267 (C:0.8267, R:0.0105)
Batch 475/537: Loss=0.8763 (C:0.8763, R:0.0105)
Batch 500/537: Loss=0.8802 (C:0.8802, R:0.0105)
Batch 525/537: Loss=0.8621 (C:0.8621, R:0.0105)

============================================================
Epoch 19/300 completed in 27.2s
Train: Loss=0.8539 (C:0.8539, R:0.0105) Ratio=3.67x
Val:   Loss=0.9299 (C:0.9299, R:0.0104) Ratio=2.94x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.9299)
============================================================

🌍 Updating global dataset at epoch 20
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.488 ± 0.630
    Neg distances: 2.255 ± 1.044
    Separation ratio: 4.62x
    Gap: -4.191
    ✅ Excellent global separation!

Epoch 20 Training
----------------------------------------
Batch   0/537: Loss=0.8227 (C:0.8227, R:0.0105)
Batch  25/537: Loss=0.8503 (C:0.8503, R:0.0105)
Batch  50/537: Loss=0.8710 (C:0.8710, R:0.0105)
Batch  75/537: Loss=0.8596 (C:0.8596, R:0.0105)
Batch 100/537: Loss=0.8567 (C:0.8567, R:0.0105)
Batch 125/537: Loss=0.8973 (C:0.8973, R:0.0106)
Batch 150/537: Loss=0.8306 (C:0.8306, R:0.0105)
Batch 175/537: Loss=0.8072 (C:0.8072, R:0.0105)
Batch 200/537: Loss=0.8767 (C:0.8767, R:0.0105)
Batch 225/537: Loss=0.8431 (C:0.8431, R:0.0105)
Batch 250/537: Loss=0.8154 (C:0.8154, R:0.0105)
Batch 275/537: Loss=0.8773 (C:0.8773, R:0.0105)
Batch 300/537: Loss=0.8527 (C:0.8527, R:0.0105)
Batch 325/537: Loss=0.8594 (C:0.8594, R:0.0105)
Batch 350/537: Loss=0.8463 (C:0.8463, R:0.0105)
Batch 375/537: Loss=0.8489 (C:0.8489, R:0.0105)
Batch 400/537: Loss=0.8983 (C:0.8983, R:0.0105)
Batch 425/537: Loss=0.8572 (C:0.8572, R:0.0105)
Batch 450/537: Loss=0.8998 (C:0.8998, R:0.0105)
Batch 475/537: Loss=0.8831 (C:0.8831, R:0.0105)
Batch 500/537: Loss=0.8546 (C:0.8546, R:0.0105)
Batch 525/537: Loss=0.8476 (C:0.8476, R:0.0105)

============================================================
Epoch 20/300 completed in 27.1s
Train: Loss=0.8522 (C:0.8522, R:0.0105) Ratio=3.64x
Val:   Loss=0.9198 (C:0.9198, R:0.0104) Ratio=3.00x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.9198)
Checkpoint saved at epoch 20
============================================================

🌍 Updating global dataset at epoch 21
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.494 ± 0.641
    Neg distances: 2.275 ± 1.053
    Separation ratio: 4.61x
    Gap: -4.133
    ✅ Excellent global separation!

Epoch 21 Training
----------------------------------------
Batch   0/537: Loss=0.8225 (C:0.8225, R:0.0106)
Batch  25/537: Loss=0.8385 (C:0.8385, R:0.0105)
Batch  50/537: Loss=0.8250 (C:0.8250, R:0.0105)
Batch  75/537: Loss=0.8498 (C:0.8498, R:0.0105)
Batch 100/537: Loss=0.8201 (C:0.8201, R:0.0105)
Batch 125/537: Loss=0.8238 (C:0.8238, R:0.0105)
Batch 150/537: Loss=0.8250 (C:0.8250, R:0.0105)
Batch 175/537: Loss=0.8380 (C:0.8380, R:0.0105)
Batch 200/537: Loss=0.8240 (C:0.8240, R:0.0105)
Batch 225/537: Loss=0.8544 (C:0.8544, R:0.0105)
Batch 250/537: Loss=0.8184 (C:0.8184, R:0.0105)
Batch 275/537: Loss=0.8591 (C:0.8591, R:0.0105)
Batch 300/537: Loss=0.8717 (C:0.8717, R:0.0105)
Batch 325/537: Loss=0.8453 (C:0.8453, R:0.0105)
Batch 350/537: Loss=0.8353 (C:0.8353, R:0.0106)
Batch 375/537: Loss=0.8166 (C:0.8166, R:0.0105)
Batch 400/537: Loss=0.8224 (C:0.8224, R:0.0105)
Batch 425/537: Loss=0.8336 (C:0.8336, R:0.0105)
Batch 450/537: Loss=0.8720 (C:0.8720, R:0.0106)
Batch 475/537: Loss=0.8250 (C:0.8250, R:0.0106)
Batch 500/537: Loss=0.7958 (C:0.7958, R:0.0105)
Batch 525/537: Loss=0.8749 (C:0.8749, R:0.0105)

============================================================
Epoch 21/300 completed in 27.8s
Train: Loss=0.8455 (C:0.8455, R:0.0105) Ratio=3.77x
Val:   Loss=0.9222 (C:0.9222, R:0.0104) Ratio=3.00x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 22
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.488 ± 0.632
    Neg distances: 2.299 ± 1.060
    Separation ratio: 4.71x
    Gap: -4.072
    ✅ Excellent global separation!

Epoch 22 Training
----------------------------------------
Batch   0/537: Loss=0.8198 (C:0.8198, R:0.0105)
Batch  25/537: Loss=0.7959 (C:0.7959, R:0.0105)
Batch  50/537: Loss=0.7947 (C:0.7947, R:0.0105)
Batch  75/537: Loss=0.8337 (C:0.8337, R:0.0105)
Batch 100/537: Loss=0.8117 (C:0.8117, R:0.0105)
Batch 125/537: Loss=0.8550 (C:0.8550, R:0.0105)
Batch 150/537: Loss=0.8519 (C:0.8519, R:0.0105)
Batch 175/537: Loss=0.8206 (C:0.8206, R:0.0105)
Batch 200/537: Loss=0.8055 (C:0.8055, R:0.0105)
Batch 225/537: Loss=0.8264 (C:0.8264, R:0.0105)
Batch 250/537: Loss=0.8437 (C:0.8437, R:0.0105)
Batch 275/537: Loss=0.8354 (C:0.8354, R:0.0105)
Batch 300/537: Loss=0.8055 (C:0.8055, R:0.0105)
Batch 325/537: Loss=0.8768 (C:0.8768, R:0.0105)
Batch 350/537: Loss=0.8379 (C:0.8379, R:0.0105)
Batch 375/537: Loss=0.7847 (C:0.7847, R:0.0105)
Batch 400/537: Loss=0.8449 (C:0.8449, R:0.0105)
Batch 425/537: Loss=0.8447 (C:0.8447, R:0.0105)
Batch 450/537: Loss=0.8323 (C:0.8323, R:0.0105)
Batch 475/537: Loss=0.8304 (C:0.8304, R:0.0105)
Batch 500/537: Loss=0.8683 (C:0.8683, R:0.0105)
Batch 525/537: Loss=0.8476 (C:0.8476, R:0.0106)

============================================================
Epoch 22/300 completed in 27.5s
Train: Loss=0.8301 (C:0.8301, R:0.0105) Ratio=3.72x
Val:   Loss=0.9117 (C:0.9117, R:0.0104) Ratio=3.02x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.9117)
============================================================

🌍 Updating global dataset at epoch 23
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.468 ± 0.622
    Neg distances: 2.334 ± 1.061
    Separation ratio: 4.99x
    Gap: -4.183
    ✅ Excellent global separation!

Epoch 23 Training
----------------------------------------
Batch   0/537: Loss=0.8366 (C:0.8366, R:0.0105)
Batch  25/537: Loss=0.8301 (C:0.8301, R:0.0105)
Batch  50/537: Loss=0.8001 (C:0.8001, R:0.0105)
Batch  75/537: Loss=0.7789 (C:0.7789, R:0.0105)
Batch 100/537: Loss=0.7666 (C:0.7666, R:0.0105)
Batch 125/537: Loss=0.8032 (C:0.8032, R:0.0105)
Batch 150/537: Loss=0.7743 (C:0.7743, R:0.0105)
Batch 175/537: Loss=0.7891 (C:0.7891, R:0.0105)
Batch 200/537: Loss=0.7749 (C:0.7749, R:0.0105)
Batch 225/537: Loss=0.8368 (C:0.8368, R:0.0105)
Batch 250/537: Loss=0.8140 (C:0.8140, R:0.0105)
Batch 275/537: Loss=0.8091 (C:0.8091, R:0.0105)
Batch 300/537: Loss=0.7652 (C:0.7652, R:0.0106)
Batch 325/537: Loss=0.7797 (C:0.7797, R:0.0105)
Batch 350/537: Loss=0.8056 (C:0.8056, R:0.0105)
Batch 375/537: Loss=0.8017 (C:0.8017, R:0.0105)
Batch 400/537: Loss=0.8105 (C:0.8105, R:0.0106)
Batch 425/537: Loss=0.8195 (C:0.8195, R:0.0105)
Batch 450/537: Loss=0.7896 (C:0.7896, R:0.0105)
Batch 475/537: Loss=0.7893 (C:0.7893, R:0.0105)
Batch 500/537: Loss=0.8042 (C:0.8042, R:0.0105)
Batch 525/537: Loss=0.8685 (C:0.8685, R:0.0105)

============================================================
Epoch 23/300 completed in 27.0s
Train: Loss=0.8065 (C:0.8065, R:0.0105) Ratio=3.83x
Val:   Loss=0.8805 (C:0.8805, R:0.0104) Ratio=3.03x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.8805)
============================================================

🌍 Updating global dataset at epoch 24
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.466 ± 0.629
    Neg distances: 2.368 ± 1.073
    Separation ratio: 5.09x
    Gap: -4.184
    ✅ Excellent global separation!

Epoch 24 Training
----------------------------------------
Batch   0/537: Loss=0.8435 (C:0.8435, R:0.0105)
Batch  25/537: Loss=0.7909 (C:0.7909, R:0.0105)
Batch  50/537: Loss=0.8035 (C:0.8035, R:0.0105)
Batch  75/537: Loss=0.7407 (C:0.7407, R:0.0105)
Batch 100/537: Loss=0.7966 (C:0.7966, R:0.0105)
Batch 125/537: Loss=0.8137 (C:0.8137, R:0.0105)
Batch 150/537: Loss=0.8166 (C:0.8166, R:0.0105)
Batch 175/537: Loss=0.8169 (C:0.8169, R:0.0105)
Batch 200/537: Loss=0.7596 (C:0.7596, R:0.0105)
Batch 225/537: Loss=0.8072 (C:0.8072, R:0.0105)
Batch 250/537: Loss=0.7936 (C:0.7936, R:0.0105)
Batch 275/537: Loss=0.8119 (C:0.8119, R:0.0105)
Batch 300/537: Loss=0.7843 (C:0.7843, R:0.0105)
Batch 325/537: Loss=0.8116 (C:0.8116, R:0.0105)
Batch 350/537: Loss=0.7779 (C:0.7779, R:0.0105)
Batch 375/537: Loss=0.8264 (C:0.8264, R:0.0105)
Batch 400/537: Loss=0.7803 (C:0.7803, R:0.0105)
Batch 425/537: Loss=0.7912 (C:0.7912, R:0.0105)
Batch 450/537: Loss=0.7926 (C:0.7926, R:0.0105)
Batch 475/537: Loss=0.7643 (C:0.7643, R:0.0105)
Batch 500/537: Loss=0.8067 (C:0.8067, R:0.0105)
Batch 525/537: Loss=0.7628 (C:0.7628, R:0.0105)

============================================================
Epoch 24/300 completed in 26.9s
Train: Loss=0.7959 (C:0.7959, R:0.0105) Ratio=3.84x
Val:   Loss=0.8818 (C:0.8818, R:0.0104) Ratio=3.01x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 25
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.468 ± 0.634
    Neg distances: 2.360 ± 1.071
    Separation ratio: 5.04x
    Gap: -4.217
    ✅ Excellent global separation!

Epoch 25 Training
----------------------------------------
Batch   0/537: Loss=0.7744 (C:0.7744, R:0.0105)
Batch  25/537: Loss=0.7554 (C:0.7554, R:0.0105)
Batch  50/537: Loss=0.7869 (C:0.7869, R:0.0105)
Batch  75/537: Loss=0.7936 (C:0.7936, R:0.0105)
Batch 100/537: Loss=0.8025 (C:0.8025, R:0.0105)
Batch 125/537: Loss=0.7812 (C:0.7812, R:0.0105)
Batch 150/537: Loss=0.7707 (C:0.7707, R:0.0105)
Batch 175/537: Loss=0.7714 (C:0.7714, R:0.0105)
Batch 200/537: Loss=0.8001 (C:0.8001, R:0.0105)
Batch 225/537: Loss=0.7891 (C:0.7891, R:0.0105)
Batch 250/537: Loss=0.8045 (C:0.8045, R:0.0105)
Batch 275/537: Loss=0.7875 (C:0.7875, R:0.0105)
Batch 300/537: Loss=0.7901 (C:0.7901, R:0.0105)
Batch 325/537: Loss=0.8201 (C:0.8201, R:0.0105)
Batch 350/537: Loss=0.7372 (C:0.7372, R:0.0106)
Batch 375/537: Loss=0.7898 (C:0.7898, R:0.0105)
Batch 400/537: Loss=0.7877 (C:0.7877, R:0.0105)
Batch 425/537: Loss=0.8131 (C:0.8131, R:0.0105)
Batch 450/537: Loss=0.7773 (C:0.7773, R:0.0105)
Batch 475/537: Loss=0.7544 (C:0.7544, R:0.0105)
Batch 500/537: Loss=0.7921 (C:0.7921, R:0.0105)
Batch 525/537: Loss=0.8176 (C:0.8176, R:0.0105)

============================================================
Epoch 25/300 completed in 26.8s
Train: Loss=0.7902 (C:0.7902, R:0.0105) Ratio=3.88x
Val:   Loss=0.8689 (C:0.8689, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.8689)
============================================================

🌍 Updating global dataset at epoch 26
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.459 ± 0.633
    Neg distances: 2.406 ± 1.081
    Separation ratio: 5.24x
    Gap: -4.350
    ✅ Excellent global separation!

Epoch 26 Training
----------------------------------------
Batch   0/537: Loss=0.7395 (C:0.7395, R:0.0105)
Batch  25/537: Loss=0.7813 (C:0.7813, R:0.0105)
Batch  50/537: Loss=0.7934 (C:0.7934, R:0.0105)
Batch  75/537: Loss=0.7267 (C:0.7267, R:0.0105)
Batch 100/537: Loss=0.7927 (C:0.7927, R:0.0105)
Batch 125/537: Loss=0.8106 (C:0.8106, R:0.0105)
Batch 150/537: Loss=0.7508 (C:0.7508, R:0.0105)
Batch 175/537: Loss=0.7908 (C:0.7908, R:0.0105)
Batch 200/537: Loss=0.7833 (C:0.7833, R:0.0105)
Batch 225/537: Loss=0.7853 (C:0.7853, R:0.0105)
Batch 250/537: Loss=0.7641 (C:0.7641, R:0.0105)
Batch 275/537: Loss=0.7787 (C:0.7787, R:0.0105)
Batch 300/537: Loss=0.7930 (C:0.7930, R:0.0105)
Batch 325/537: Loss=0.8099 (C:0.8099, R:0.0105)
Batch 350/537: Loss=0.7030 (C:0.7030, R:0.0105)
Batch 375/537: Loss=0.7843 (C:0.7843, R:0.0105)
Batch 400/537: Loss=0.7571 (C:0.7571, R:0.0105)
Batch 425/537: Loss=0.7886 (C:0.7886, R:0.0106)
Batch 450/537: Loss=0.7838 (C:0.7838, R:0.0105)
Batch 475/537: Loss=0.8076 (C:0.8076, R:0.0105)
Batch 500/537: Loss=0.7907 (C:0.7907, R:0.0105)
Batch 525/537: Loss=0.8086 (C:0.8086, R:0.0105)

============================================================
Epoch 26/300 completed in 27.1s
Train: Loss=0.7758 (C:0.7758, R:0.0105) Ratio=3.95x
Val:   Loss=0.8491 (C:0.8491, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.8491)
============================================================

🌍 Updating global dataset at epoch 27
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.445 ± 0.610
    Neg distances: 2.389 ± 1.068
    Separation ratio: 5.37x
    Gap: -4.233
    ✅ Excellent global separation!

Epoch 27 Training
----------------------------------------
Batch   0/537: Loss=0.7413 (C:0.7413, R:0.0105)
Batch  25/537: Loss=0.7324 (C:0.7324, R:0.0105)
Batch  50/537: Loss=0.7605 (C:0.7605, R:0.0105)
Batch  75/537: Loss=0.7700 (C:0.7700, R:0.0105)
Batch 100/537: Loss=0.7744 (C:0.7744, R:0.0105)
Batch 125/537: Loss=0.7703 (C:0.7703, R:0.0105)
Batch 150/537: Loss=0.7746 (C:0.7746, R:0.0105)
Batch 175/537: Loss=0.7421 (C:0.7421, R:0.0105)
Batch 200/537: Loss=0.7156 (C:0.7156, R:0.0105)
Batch 225/537: Loss=0.7629 (C:0.7629, R:0.0105)
Batch 250/537: Loss=0.7737 (C:0.7737, R:0.0105)
Batch 275/537: Loss=0.7705 (C:0.7705, R:0.0105)
Batch 300/537: Loss=0.7904 (C:0.7904, R:0.0105)
Batch 325/537: Loss=0.7933 (C:0.7933, R:0.0105)
Batch 350/537: Loss=0.7808 (C:0.7808, R:0.0105)
Batch 375/537: Loss=0.7900 (C:0.7900, R:0.0105)
Batch 400/537: Loss=0.7664 (C:0.7664, R:0.0105)
Batch 425/537: Loss=0.7858 (C:0.7858, R:0.0105)
Batch 450/537: Loss=0.7469 (C:0.7469, R:0.0105)
Batch 475/537: Loss=0.7722 (C:0.7722, R:0.0105)
Batch 500/537: Loss=0.7968 (C:0.7968, R:0.0105)
Batch 525/537: Loss=0.7648 (C:0.7648, R:0.0105)

============================================================
Epoch 27/300 completed in 27.7s
Train: Loss=0.7635 (C:0.7635, R:0.0105) Ratio=3.93x
Val:   Loss=0.8442 (C:0.8442, R:0.0104) Ratio=3.02x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.8442)
============================================================

🌍 Updating global dataset at epoch 28
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.434 ± 0.608
    Neg distances: 2.439 ± 1.078
    Separation ratio: 5.62x
    Gap: -4.354
    ✅ Excellent global separation!

Epoch 28 Training
----------------------------------------
Batch   0/537: Loss=0.7377 (C:0.7377, R:0.0106)
Batch  25/537: Loss=0.7316 (C:0.7316, R:0.0105)
Batch  50/537: Loss=0.7421 (C:0.7421, R:0.0105)
Batch  75/537: Loss=0.7383 (C:0.7383, R:0.0105)
Batch 100/537: Loss=0.7417 (C:0.7417, R:0.0105)
Batch 125/537: Loss=0.7357 (C:0.7357, R:0.0105)
Batch 150/537: Loss=0.7529 (C:0.7529, R:0.0105)
Batch 175/537: Loss=0.7550 (C:0.7550, R:0.0105)
Batch 200/537: Loss=0.7381 (C:0.7381, R:0.0105)
Batch 225/537: Loss=0.7821 (C:0.7821, R:0.0105)
Batch 250/537: Loss=0.7122 (C:0.7122, R:0.0105)
Batch 275/537: Loss=0.7488 (C:0.7488, R:0.0106)
Batch 300/537: Loss=0.7418 (C:0.7418, R:0.0105)
Batch 325/537: Loss=0.6747 (C:0.6747, R:0.0105)
Batch 350/537: Loss=0.7312 (C:0.7312, R:0.0105)
Batch 375/537: Loss=0.7458 (C:0.7458, R:0.0105)
Batch 400/537: Loss=0.7620 (C:0.7620, R:0.0105)
Batch 425/537: Loss=0.6883 (C:0.6883, R:0.0105)
Batch 450/537: Loss=0.7317 (C:0.7317, R:0.0105)
Batch 475/537: Loss=0.7442 (C:0.7442, R:0.0105)
Batch 500/537: Loss=0.7419 (C:0.7419, R:0.0105)
Batch 525/537: Loss=0.7491 (C:0.7491, R:0.0105)

============================================================
Epoch 28/300 completed in 27.6s
Train: Loss=0.7422 (C:0.7422, R:0.0105) Ratio=4.11x
Val:   Loss=0.8278 (C:0.8278, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.8278)
============================================================

🌍 Updating global dataset at epoch 29
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.435 ± 0.633
    Neg distances: 2.442 ± 1.083
    Separation ratio: 5.61x
    Gap: -4.396
    ✅ Excellent global separation!

Epoch 29 Training
----------------------------------------
Batch   0/537: Loss=0.7253 (C:0.7253, R:0.0105)
Batch  25/537: Loss=0.7080 (C:0.7080, R:0.0105)
Batch  50/537: Loss=0.7192 (C:0.7192, R:0.0105)
Batch  75/537: Loss=0.7224 (C:0.7224, R:0.0105)
Batch 100/537: Loss=0.7342 (C:0.7342, R:0.0106)
Batch 125/537: Loss=0.7511 (C:0.7511, R:0.0105)
Batch 150/537: Loss=0.6790 (C:0.6790, R:0.0105)
Batch 175/537: Loss=0.7629 (C:0.7629, R:0.0106)
Batch 200/537: Loss=0.7153 (C:0.7153, R:0.0105)
Batch 225/537: Loss=0.7834 (C:0.7834, R:0.0105)
Batch 250/537: Loss=0.7692 (C:0.7692, R:0.0105)
Batch 275/537: Loss=0.7430 (C:0.7430, R:0.0105)
Batch 300/537: Loss=0.7250 (C:0.7250, R:0.0105)
Batch 325/537: Loss=0.7616 (C:0.7616, R:0.0105)
Batch 350/537: Loss=0.7606 (C:0.7606, R:0.0105)
Batch 375/537: Loss=0.7944 (C:0.7944, R:0.0105)
Batch 400/537: Loss=0.7605 (C:0.7605, R:0.0105)
Batch 425/537: Loss=0.7644 (C:0.7644, R:0.0105)
Batch 450/537: Loss=0.7419 (C:0.7419, R:0.0106)
Batch 475/537: Loss=0.7363 (C:0.7363, R:0.0105)
Batch 500/537: Loss=0.7559 (C:0.7559, R:0.0105)
Batch 525/537: Loss=0.7436 (C:0.7436, R:0.0105)

============================================================
Epoch 29/300 completed in 26.9s
Train: Loss=0.7404 (C:0.7404, R:0.0105) Ratio=3.97x
Val:   Loss=0.8315 (C:0.8315, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 30
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.461 ± 0.646
    Neg distances: 2.427 ± 1.094
    Separation ratio: 5.27x
    Gap: -4.369
    ✅ Excellent global separation!

Epoch 30 Training
----------------------------------------
Batch   0/537: Loss=0.7528 (C:0.7528, R:0.0105)
Batch  25/537: Loss=0.7472 (C:0.7472, R:0.0105)
Batch  50/537: Loss=0.7590 (C:0.7590, R:0.0105)
Batch  75/537: Loss=0.7264 (C:0.7264, R:0.0105)
Batch 100/537: Loss=0.7665 (C:0.7665, R:0.0105)
Batch 125/537: Loss=0.7593 (C:0.7593, R:0.0105)
Batch 150/537: Loss=0.7438 (C:0.7438, R:0.0105)
Batch 175/537: Loss=0.7537 (C:0.7537, R:0.0105)
Batch 200/537: Loss=0.8076 (C:0.8076, R:0.0105)
Batch 225/537: Loss=0.7684 (C:0.7684, R:0.0105)
Batch 250/537: Loss=0.8039 (C:0.8039, R:0.0105)
Batch 275/537: Loss=0.7249 (C:0.7249, R:0.0105)
Batch 300/537: Loss=0.7614 (C:0.7614, R:0.0105)
Batch 325/537: Loss=0.7813 (C:0.7813, R:0.0105)
Batch 350/537: Loss=0.7453 (C:0.7453, R:0.0105)
Batch 375/537: Loss=0.6939 (C:0.6939, R:0.0105)
Batch 400/537: Loss=0.7611 (C:0.7611, R:0.0105)
Batch 425/537: Loss=0.8003 (C:0.8003, R:0.0105)
Batch 450/537: Loss=0.7531 (C:0.7531, R:0.0105)
Batch 475/537: Loss=0.7724 (C:0.7724, R:0.0105)
Batch 500/537: Loss=0.7406 (C:0.7406, R:0.0105)
Batch 525/537: Loss=0.7629 (C:0.7629, R:0.0105)

============================================================
Epoch 30/300 completed in 27.0s
Train: Loss=0.7562 (C:0.7562, R:0.0105) Ratio=4.06x
Val:   Loss=0.8465 (C:0.8465, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.000
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 31
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.428 ± 0.613
    Neg distances: 2.480 ± 1.093
    Separation ratio: 5.79x
    Gap: -4.336
    ✅ Excellent global separation!

Epoch 31 Training
----------------------------------------
Batch   0/537: Loss=0.7182 (C:0.7182, R:0.0105)
Batch  25/537: Loss=0.7048 (C:0.7048, R:0.0105)
Batch  50/537: Loss=0.7602 (C:0.7602, R:0.0105)
Batch  75/537: Loss=0.7055 (C:0.7055, R:0.0105)
Batch 100/537: Loss=0.7195 (C:0.7195, R:0.0105)
Batch 125/537: Loss=0.7105 (C:0.7105, R:0.0105)
Batch 150/537: Loss=0.7153 (C:0.7153, R:0.0105)
Batch 175/537: Loss=0.7005 (C:0.7005, R:0.0105)
Batch 200/537: Loss=0.7541 (C:0.7541, R:0.0105)
Batch 225/537: Loss=0.7277 (C:0.7277, R:0.0105)
Batch 250/537: Loss=0.7085 (C:0.7085, R:0.0106)
Batch 275/537: Loss=0.6819 (C:0.6819, R:0.0105)
Batch 300/537: Loss=0.6815 (C:0.6815, R:0.0105)
Batch 325/537: Loss=0.7549 (C:0.7549, R:0.0105)
Batch 350/537: Loss=0.7332 (C:0.7332, R:0.0105)
Batch 375/537: Loss=0.7481 (C:0.7481, R:0.0105)
Batch 400/537: Loss=0.7361 (C:0.7361, R:0.0105)
Batch 425/537: Loss=0.7068 (C:0.7068, R:0.0105)
Batch 450/537: Loss=0.7058 (C:0.7058, R:0.0105)
Batch 475/537: Loss=0.7032 (C:0.7032, R:0.0105)
Batch 500/537: Loss=0.7551 (C:0.7551, R:0.0105)
Batch 525/537: Loss=0.7655 (C:0.7655, R:0.0105)

============================================================
Epoch 31/300 completed in 27.0s
Train: Loss=0.7237 (C:0.7237, R:0.0105) Ratio=4.11x
Val:   Loss=0.8313 (C:0.8313, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.015
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 32
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.442 ± 0.631
    Neg distances: 2.479 ± 1.103
    Separation ratio: 5.60x
    Gap: -4.424
    ✅ Excellent global separation!

Epoch 32 Training
----------------------------------------
Batch   0/537: Loss=0.7447 (C:0.7447, R:0.0105)
Batch  25/537: Loss=0.7369 (C:0.7369, R:0.0105)
Batch  50/537: Loss=0.7519 (C:0.7519, R:0.0105)
Batch  75/537: Loss=0.7385 (C:0.7385, R:0.0105)
Batch 100/537: Loss=0.7192 (C:0.7192, R:0.0105)
Batch 125/537: Loss=0.7349 (C:0.7349, R:0.0105)
Batch 150/537: Loss=0.7395 (C:0.7395, R:0.0105)
Batch 175/537: Loss=0.7178 (C:0.7178, R:0.0105)
Batch 200/537: Loss=0.7441 (C:0.7441, R:0.0105)
Batch 225/537: Loss=0.7058 (C:0.7058, R:0.0105)
Batch 250/537: Loss=0.7636 (C:0.7636, R:0.0105)
Batch 275/537: Loss=0.7528 (C:0.7528, R:0.0105)
Batch 300/537: Loss=0.7369 (C:0.7369, R:0.0105)
Batch 325/537: Loss=0.7541 (C:0.7541, R:0.0105)
Batch 350/537: Loss=0.7380 (C:0.7380, R:0.0105)
Batch 375/537: Loss=0.7227 (C:0.7227, R:0.0105)
Batch 400/537: Loss=0.7239 (C:0.7239, R:0.0105)
Batch 425/537: Loss=0.7625 (C:0.7625, R:0.0105)
Batch 450/537: Loss=0.7386 (C:0.7386, R:0.0105)
Batch 475/537: Loss=0.7162 (C:0.7162, R:0.0105)
Batch 500/537: Loss=0.7201 (C:0.7201, R:0.0105)
Batch 525/537: Loss=0.7208 (C:0.7208, R:0.0105)

============================================================
Epoch 32/300 completed in 27.0s
Train: Loss=0.7313 (C:0.7313, R:0.0105) Ratio=4.20x
Val:   Loss=0.8315 (C:0.8315, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.030
No improvement for 4 epochs
============================================================

🌍 Updating global dataset at epoch 33
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.426 ± 0.624
    Neg distances: 2.473 ± 1.088
    Separation ratio: 5.80x
    Gap: -4.373
    ✅ Excellent global separation!

Epoch 33 Training
----------------------------------------
Batch   0/537: Loss=0.7633 (C:0.7633, R:0.0105)
Batch  25/537: Loss=0.6700 (C:0.6700, R:0.0105)
Batch  50/537: Loss=0.7166 (C:0.7166, R:0.0105)
Batch  75/537: Loss=0.7012 (C:0.7012, R:0.0105)
Batch 100/537: Loss=0.7455 (C:0.7455, R:0.0105)
Batch 125/537: Loss=0.7523 (C:0.7523, R:0.0105)
Batch 150/537: Loss=0.6613 (C:0.6613, R:0.0105)
Batch 175/537: Loss=0.7478 (C:0.7478, R:0.0105)
Batch 200/537: Loss=0.7245 (C:0.7245, R:0.0105)
Batch 225/537: Loss=0.7034 (C:0.7034, R:0.0105)
Batch 250/537: Loss=0.7191 (C:0.7191, R:0.0105)
Batch 275/537: Loss=0.7141 (C:0.7141, R:0.0105)
Batch 300/537: Loss=0.6699 (C:0.6699, R:0.0105)
Batch 325/537: Loss=0.7022 (C:0.7022, R:0.0105)
Batch 350/537: Loss=0.6795 (C:0.6795, R:0.0105)
Batch 375/537: Loss=0.7566 (C:0.7566, R:0.0105)
Batch 400/537: Loss=0.7180 (C:0.7180, R:0.0105)
Batch 425/537: Loss=0.7015 (C:0.7015, R:0.0105)
Batch 450/537: Loss=0.6727 (C:0.6727, R:0.0105)
Batch 475/537: Loss=0.7286 (C:0.7286, R:0.0105)
Batch 500/537: Loss=0.6946 (C:0.6946, R:0.0105)
Batch 525/537: Loss=0.7151 (C:0.7151, R:0.0105)

============================================================
Epoch 33/300 completed in 26.7s
Train: Loss=0.7147 (C:0.7147, R:0.0105) Ratio=4.23x
Val:   Loss=0.8075 (C:0.8075, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.045
✅ New best model saved (Val Loss: 0.8075)
============================================================

🌍 Updating global dataset at epoch 34
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.426 ± 0.621
    Neg distances: 2.488 ± 1.091
    Separation ratio: 5.84x
    Gap: -4.400
    ✅ Excellent global separation!

Epoch 34 Training
----------------------------------------
Batch   0/537: Loss=0.7169 (C:0.7169, R:0.0105)
Batch  25/537: Loss=0.6749 (C:0.6749, R:0.0105)
Batch  50/537: Loss=0.7269 (C:0.7269, R:0.0105)
Batch  75/537: Loss=0.6845 (C:0.6845, R:0.0105)
Batch 100/537: Loss=0.6995 (C:0.6995, R:0.0105)
Batch 125/537: Loss=0.7616 (C:0.7616, R:0.0105)
Batch 150/537: Loss=0.7360 (C:0.7360, R:0.0105)
Batch 175/537: Loss=0.6693 (C:0.6693, R:0.0105)
Batch 200/537: Loss=0.7395 (C:0.7395, R:0.0105)
Batch 225/537: Loss=0.7096 (C:0.7096, R:0.0105)
Batch 250/537: Loss=0.6889 (C:0.6889, R:0.0105)
Batch 275/537: Loss=0.7130 (C:0.7130, R:0.0105)
Batch 300/537: Loss=0.7108 (C:0.7108, R:0.0105)
Batch 325/537: Loss=0.7084 (C:0.7084, R:0.0105)
Batch 350/537: Loss=0.7286 (C:0.7286, R:0.0105)
Batch 375/537: Loss=0.7012 (C:0.7012, R:0.0105)
Batch 400/537: Loss=0.7188 (C:0.7188, R:0.0105)
Batch 425/537: Loss=0.7104 (C:0.7104, R:0.0105)
Batch 450/537: Loss=0.7154 (C:0.7154, R:0.0105)
Batch 475/537: Loss=0.7685 (C:0.7685, R:0.0105)
Batch 500/537: Loss=0.6987 (C:0.6987, R:0.0105)
Batch 525/537: Loss=0.7524 (C:0.7524, R:0.0106)

============================================================
Epoch 34/300 completed in 26.6s
Train: Loss=0.7090 (C:0.7090, R:0.0105) Ratio=4.16x
Val:   Loss=0.8171 (C:0.8171, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.060
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 35
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.426 ± 0.631
    Neg distances: 2.493 ± 1.096
    Separation ratio: 5.85x
    Gap: -4.446
    ✅ Excellent global separation!

Epoch 35 Training
----------------------------------------
Batch   0/537: Loss=0.6630 (C:0.6630, R:0.0105)
Batch  25/537: Loss=0.7116 (C:0.7116, R:0.0105)
Batch  50/537: Loss=0.7119 (C:0.7119, R:0.0105)
Batch  75/537: Loss=0.7137 (C:0.7137, R:0.0105)
Batch 100/537: Loss=0.7109 (C:0.7109, R:0.0105)
Batch 125/537: Loss=0.7285 (C:0.7285, R:0.0105)
Batch 150/537: Loss=0.7070 (C:0.7070, R:0.0106)
Batch 175/537: Loss=0.6778 (C:0.6778, R:0.0105)
Batch 200/537: Loss=0.7169 (C:0.7169, R:0.0105)
Batch 225/537: Loss=0.7126 (C:0.7126, R:0.0105)
Batch 250/537: Loss=0.6427 (C:0.6427, R:0.0105)
Batch 275/537: Loss=0.7236 (C:0.7236, R:0.0105)
Batch 300/537: Loss=0.7106 (C:0.7106, R:0.0105)
Batch 325/537: Loss=0.7080 (C:0.7080, R:0.0105)
Batch 350/537: Loss=0.6792 (C:0.6792, R:0.0106)
Batch 375/537: Loss=0.6993 (C:0.6993, R:0.0105)
Batch 400/537: Loss=0.7263 (C:0.7263, R:0.0105)
Batch 425/537: Loss=0.7300 (C:0.7300, R:0.0105)
Batch 450/537: Loss=0.6966 (C:0.6966, R:0.0105)
Batch 475/537: Loss=0.6933 (C:0.6933, R:0.0106)
Batch 500/537: Loss=0.6976 (C:0.6976, R:0.0105)
Batch 525/537: Loss=0.7280 (C:0.7280, R:0.0105)

============================================================
Epoch 35/300 completed in 26.5s
Train: Loss=0.7064 (C:0.7064, R:0.0105) Ratio=4.22x
Val:   Loss=0.8139 (C:0.8139, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.075
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 36
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.424 ± 0.640
    Neg distances: 2.516 ± 1.105
    Separation ratio: 5.93x
    Gap: -4.417
    ✅ Excellent global separation!

Epoch 36 Training
----------------------------------------
Batch   0/537: Loss=0.7341 (C:0.7341, R:0.0105)
Batch  25/537: Loss=0.6802 (C:0.6802, R:0.0105)
Batch  50/537: Loss=0.6886 (C:0.6886, R:0.0105)
Batch  75/537: Loss=0.6855 (C:0.6855, R:0.0105)
Batch 100/537: Loss=0.6615 (C:0.6615, R:0.0105)
Batch 125/537: Loss=0.7118 (C:0.7118, R:0.0105)
Batch 150/537: Loss=0.6612 (C:0.6612, R:0.0105)
Batch 175/537: Loss=0.7324 (C:0.7324, R:0.0105)
Batch 200/537: Loss=0.7109 (C:0.7109, R:0.0105)
Batch 225/537: Loss=0.7004 (C:0.7004, R:0.0105)
Batch 250/537: Loss=0.6996 (C:0.6996, R:0.0105)
Batch 275/537: Loss=0.7412 (C:0.7412, R:0.0105)
Batch 300/537: Loss=0.7305 (C:0.7305, R:0.0106)
Batch 325/537: Loss=0.6703 (C:0.6703, R:0.0105)
Batch 350/537: Loss=0.6890 (C:0.6890, R:0.0105)
Batch 375/537: Loss=0.7094 (C:0.7094, R:0.0105)
Batch 400/537: Loss=0.7133 (C:0.7133, R:0.0105)
Batch 425/537: Loss=0.7312 (C:0.7312, R:0.0105)
Batch 450/537: Loss=0.6905 (C:0.6905, R:0.0106)
Batch 475/537: Loss=0.7454 (C:0.7454, R:0.0105)
Batch 500/537: Loss=0.7197 (C:0.7197, R:0.0105)
Batch 525/537: Loss=0.7167 (C:0.7167, R:0.0105)

============================================================
Epoch 36/300 completed in 26.8s
Train: Loss=0.7002 (C:0.7002, R:0.0105) Ratio=4.26x
Val:   Loss=0.8121 (C:0.8121, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.090
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 37
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.417 ± 0.627
    Neg distances: 2.531 ± 1.110
    Separation ratio: 6.06x
    Gap: -4.480
    ✅ Excellent global separation!

Epoch 37 Training
----------------------------------------
Batch   0/537: Loss=0.7097 (C:0.7097, R:0.0105)
Batch  25/537: Loss=0.6799 (C:0.6799, R:0.0105)
Batch  50/537: Loss=0.6932 (C:0.6932, R:0.0105)
Batch  75/537: Loss=0.7053 (C:0.7053, R:0.0105)
Batch 100/537: Loss=0.6558 (C:0.6558, R:0.0105)
Batch 125/537: Loss=0.6724 (C:0.6724, R:0.0105)
Batch 150/537: Loss=0.6943 (C:0.6943, R:0.0106)
Batch 175/537: Loss=0.6700 (C:0.6700, R:0.0105)
Batch 200/537: Loss=0.7171 (C:0.7171, R:0.0105)
Batch 225/537: Loss=0.6965 (C:0.6965, R:0.0105)
Batch 250/537: Loss=0.7265 (C:0.7265, R:0.0105)
Batch 275/537: Loss=0.7024 (C:0.7024, R:0.0106)
Batch 300/537: Loss=0.6930 (C:0.6930, R:0.0105)
Batch 325/537: Loss=0.7293 (C:0.7293, R:0.0105)
Batch 350/537: Loss=0.6783 (C:0.6783, R:0.0105)
Batch 375/537: Loss=0.6883 (C:0.6883, R:0.0105)
Batch 400/537: Loss=0.6973 (C:0.6973, R:0.0105)
Batch 425/537: Loss=0.6986 (C:0.6986, R:0.0105)
Batch 450/537: Loss=0.6986 (C:0.6986, R:0.0105)
Batch 475/537: Loss=0.7240 (C:0.7240, R:0.0105)
Batch 500/537: Loss=0.6712 (C:0.6712, R:0.0105)
Batch 525/537: Loss=0.7002 (C:0.7002, R:0.0105)

============================================================
Epoch 37/300 completed in 26.9s
Train: Loss=0.6921 (C:0.6921, R:0.0105) Ratio=4.32x
Val:   Loss=0.8096 (C:0.8096, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.105
No improvement for 4 epochs
============================================================

🌍 Updating global dataset at epoch 38
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.399 ± 0.610
    Neg distances: 2.550 ± 1.101
    Separation ratio: 6.39x
    Gap: -4.409
    ✅ Excellent global separation!

Epoch 38 Training
----------------------------------------
Batch   0/537: Loss=0.6444 (C:0.6444, R:0.0105)
Batch  25/537: Loss=0.6390 (C:0.6390, R:0.0105)
Batch  50/537: Loss=0.6620 (C:0.6620, R:0.0105)
Batch  75/537: Loss=0.6731 (C:0.6731, R:0.0105)
Batch 100/537: Loss=0.6676 (C:0.6676, R:0.0105)
Batch 125/537: Loss=0.6913 (C:0.6913, R:0.0105)
Batch 150/537: Loss=0.6883 (C:0.6883, R:0.0105)
Batch 175/537: Loss=0.6449 (C:0.6449, R:0.0105)
Batch 200/537: Loss=0.6912 (C:0.6912, R:0.0105)
Batch 225/537: Loss=0.6625 (C:0.6625, R:0.0105)
Batch 250/537: Loss=0.6594 (C:0.6594, R:0.0105)
Batch 275/537: Loss=0.7157 (C:0.7157, R:0.0105)
Batch 300/537: Loss=0.6639 (C:0.6639, R:0.0105)
Batch 325/537: Loss=0.6518 (C:0.6518, R:0.0105)
Batch 350/537: Loss=0.6788 (C:0.6788, R:0.0105)
Batch 375/537: Loss=0.6823 (C:0.6823, R:0.0105)
Batch 400/537: Loss=0.6916 (C:0.6916, R:0.0105)
Batch 425/537: Loss=0.6730 (C:0.6730, R:0.0105)
Batch 450/537: Loss=0.6787 (C:0.6787, R:0.0106)
Batch 475/537: Loss=0.7026 (C:0.7026, R:0.0105)
Batch 500/537: Loss=0.7278 (C:0.7278, R:0.0105)
Batch 525/537: Loss=0.6674 (C:0.6674, R:0.0105)

============================================================
Epoch 38/300 completed in 27.1s
Train: Loss=0.6723 (C:0.6723, R:0.0105) Ratio=4.34x
Val:   Loss=0.7883 (C:0.7883, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.120
✅ New best model saved (Val Loss: 0.7883)
============================================================

🌍 Updating global dataset at epoch 39
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.412 ± 0.623
    Neg distances: 2.532 ± 1.104
    Separation ratio: 6.14x
    Gap: -4.468
    ✅ Excellent global separation!

Epoch 39 Training
----------------------------------------
Batch   0/537: Loss=0.6607 (C:0.6607, R:0.0105)
Batch  25/537: Loss=0.6625 (C:0.6625, R:0.0105)
Batch  50/537: Loss=0.6673 (C:0.6673, R:0.0105)
Batch  75/537: Loss=0.6579 (C:0.6579, R:0.0105)
Batch 100/537: Loss=0.6616 (C:0.6616, R:0.0105)
Batch 125/537: Loss=0.6570 (C:0.6570, R:0.0105)
Batch 150/537: Loss=0.6911 (C:0.6911, R:0.0105)
Batch 175/537: Loss=0.6878 (C:0.6878, R:0.0105)
Batch 200/537: Loss=0.6586 (C:0.6586, R:0.0105)
Batch 225/537: Loss=0.6753 (C:0.6753, R:0.0105)
Batch 250/537: Loss=0.6744 (C:0.6744, R:0.0105)
Batch 275/537: Loss=0.6853 (C:0.6853, R:0.0105)
Batch 300/537: Loss=0.6787 (C:0.6787, R:0.0105)
Batch 325/537: Loss=0.6623 (C:0.6623, R:0.0105)
Batch 350/537: Loss=0.7164 (C:0.7164, R:0.0105)
Batch 375/537: Loss=0.6913 (C:0.6913, R:0.0105)
Batch 400/537: Loss=0.6566 (C:0.6566, R:0.0105)
Batch 425/537: Loss=0.6688 (C:0.6688, R:0.0105)
Batch 450/537: Loss=0.7189 (C:0.7189, R:0.0105)
Batch 475/537: Loss=0.6836 (C:0.6836, R:0.0105)
Batch 500/537: Loss=0.6715 (C:0.6715, R:0.0105)
Batch 525/537: Loss=0.7043 (C:0.7043, R:0.0105)

============================================================
Epoch 39/300 completed in 27.0s
Train: Loss=0.6828 (C:0.6828, R:0.0105) Ratio=4.37x
Val:   Loss=0.8068 (C:0.8068, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.135
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 40
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.411 ± 0.624
    Neg distances: 2.537 ± 1.105
    Separation ratio: 6.18x
    Gap: -4.484
    ✅ Excellent global separation!

Epoch 40 Training
----------------------------------------
Batch   0/537: Loss=0.6774 (C:0.6774, R:0.0105)
Batch  25/537: Loss=0.6749 (C:0.6749, R:0.0105)
Batch  50/537: Loss=0.6656 (C:0.6656, R:0.0105)
Batch  75/537: Loss=0.6588 (C:0.6588, R:0.0105)
Batch 100/537: Loss=0.6303 (C:0.6303, R:0.0105)
Batch 125/537: Loss=0.6839 (C:0.6839, R:0.0106)
Batch 150/537: Loss=0.6244 (C:0.6244, R:0.0105)
Batch 175/537: Loss=0.6543 (C:0.6543, R:0.0105)
Batch 200/537: Loss=0.7006 (C:0.7006, R:0.0105)
Batch 225/537: Loss=0.6807 (C:0.6807, R:0.0105)
Batch 250/537: Loss=0.6657 (C:0.6657, R:0.0105)
Batch 275/537: Loss=0.6967 (C:0.6967, R:0.0105)
Batch 300/537: Loss=0.6601 (C:0.6601, R:0.0105)
Batch 325/537: Loss=0.6571 (C:0.6571, R:0.0105)
Batch 350/537: Loss=0.6676 (C:0.6676, R:0.0105)
Batch 375/537: Loss=0.7158 (C:0.7158, R:0.0105)
Batch 400/537: Loss=0.6907 (C:0.6907, R:0.0105)
Batch 425/537: Loss=0.7302 (C:0.7302, R:0.0105)
Batch 450/537: Loss=0.6405 (C:0.6405, R:0.0105)
Batch 475/537: Loss=0.6900 (C:0.6900, R:0.0105)
Batch 500/537: Loss=0.6592 (C:0.6592, R:0.0105)
Batch 525/537: Loss=0.6791 (C:0.6791, R:0.0105)

============================================================
Epoch 40/300 completed in 27.7s
Train: Loss=0.6776 (C:0.6776, R:0.0105) Ratio=4.44x
Val:   Loss=0.8098 (C:0.8098, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.150
No improvement for 2 epochs
Checkpoint saved at epoch 40
============================================================

🌍 Updating global dataset at epoch 41
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.410 ± 0.626
    Neg distances: 2.559 ± 1.111
    Separation ratio: 6.24x
    Gap: -4.510
    ✅ Excellent global separation!

Epoch 41 Training
----------------------------------------
Batch   0/537: Loss=0.6463 (C:0.6463, R:0.0105)
Batch  25/537: Loss=0.6620 (C:0.6620, R:0.0105)
Batch  50/537: Loss=0.6230 (C:0.6230, R:0.0105)
Batch  75/537: Loss=0.6920 (C:0.6920, R:0.0105)
Batch 100/537: Loss=0.6780 (C:0.6780, R:0.0105)
Batch 125/537: Loss=0.6748 (C:0.6748, R:0.0105)
Batch 150/537: Loss=0.6849 (C:0.6849, R:0.0105)
Batch 175/537: Loss=0.6896 (C:0.6896, R:0.0105)
Batch 200/537: Loss=0.6540 (C:0.6540, R:0.0105)
Batch 225/537: Loss=0.6601 (C:0.6601, R:0.0105)
Batch 250/537: Loss=0.6420 (C:0.6420, R:0.0105)
Batch 275/537: Loss=0.6683 (C:0.6683, R:0.0105)
Batch 300/537: Loss=0.6503 (C:0.6503, R:0.0105)
Batch 325/537: Loss=0.6704 (C:0.6704, R:0.0105)
Batch 350/537: Loss=0.6870 (C:0.6870, R:0.0105)
Batch 375/537: Loss=0.7053 (C:0.7053, R:0.0105)
Batch 400/537: Loss=0.7236 (C:0.7236, R:0.0105)
Batch 425/537: Loss=0.7121 (C:0.7121, R:0.0105)
Batch 450/537: Loss=0.7024 (C:0.7024, R:0.0105)
Batch 475/537: Loss=0.6960 (C:0.6960, R:0.0105)
Batch 500/537: Loss=0.7153 (C:0.7153, R:0.0105)
Batch 525/537: Loss=0.6560 (C:0.6560, R:0.0105)

============================================================
Epoch 41/300 completed in 28.0s
Train: Loss=0.6732 (C:0.6732, R:0.0105) Ratio=4.37x
Val:   Loss=0.7921 (C:0.7921, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.165
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 42
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.398 ± 0.624
    Neg distances: 2.570 ± 1.105
    Separation ratio: 6.47x
    Gap: -4.541
    ✅ Excellent global separation!

Epoch 42 Training
----------------------------------------
Batch   0/537: Loss=0.6309 (C:0.6309, R:0.0105)
Batch  25/537: Loss=0.6366 (C:0.6366, R:0.0106)
Batch  50/537: Loss=0.6613 (C:0.6613, R:0.0105)
Batch  75/537: Loss=0.6702 (C:0.6702, R:0.0105)
Batch 100/537: Loss=0.6308 (C:0.6308, R:0.0105)
Batch 125/537: Loss=0.6446 (C:0.6446, R:0.0105)
Batch 150/537: Loss=0.6839 (C:0.6839, R:0.0105)
Batch 175/537: Loss=0.6829 (C:0.6829, R:0.0105)
Batch 200/537: Loss=0.6707 (C:0.6707, R:0.0105)
Batch 225/537: Loss=0.6625 (C:0.6625, R:0.0105)
Batch 250/537: Loss=0.6792 (C:0.6792, R:0.0105)
Batch 275/537: Loss=0.6763 (C:0.6763, R:0.0105)
Batch 300/537: Loss=0.6218 (C:0.6218, R:0.0105)
Batch 325/537: Loss=0.6847 (C:0.6847, R:0.0105)
Batch 350/537: Loss=0.6605 (C:0.6605, R:0.0106)
Batch 375/537: Loss=0.6622 (C:0.6622, R:0.0105)
Batch 400/537: Loss=0.7039 (C:0.7039, R:0.0105)
Batch 425/537: Loss=0.6920 (C:0.6920, R:0.0105)
Batch 450/537: Loss=0.6599 (C:0.6599, R:0.0105)
Batch 475/537: Loss=0.6836 (C:0.6836, R:0.0105)
Batch 500/537: Loss=0.6147 (C:0.6147, R:0.0105)
Batch 525/537: Loss=0.6887 (C:0.6887, R:0.0105)

============================================================
Epoch 42/300 completed in 27.2s
Train: Loss=0.6604 (C:0.6604, R:0.0105) Ratio=4.44x
Val:   Loss=0.7915 (C:0.7915, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.180
No improvement for 4 epochs
============================================================

🌍 Updating global dataset at epoch 43
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.405 ± 0.625
    Neg distances: 2.583 ± 1.120
    Separation ratio: 6.38x
    Gap: -4.520
    ✅ Excellent global separation!

Epoch 43 Training
----------------------------------------
Batch   0/537: Loss=0.6269 (C:0.6269, R:0.0105)
Batch  25/537: Loss=0.6503 (C:0.6503, R:0.0105)
Batch  50/537: Loss=0.6868 (C:0.6868, R:0.0105)
Batch  75/537: Loss=0.6028 (C:0.6028, R:0.0106)
Batch 100/537: Loss=0.6630 (C:0.6630, R:0.0105)
Batch 125/537: Loss=0.6280 (C:0.6280, R:0.0105)
Batch 150/537: Loss=0.6442 (C:0.6442, R:0.0105)
Batch 175/537: Loss=0.6667 (C:0.6667, R:0.0106)
Batch 200/537: Loss=0.6192 (C:0.6192, R:0.0106)
Batch 225/537: Loss=0.6588 (C:0.6588, R:0.0105)
Batch 250/537: Loss=0.6631 (C:0.6631, R:0.0105)
Batch 275/537: Loss=0.6354 (C:0.6354, R:0.0105)
Batch 300/537: Loss=0.6685 (C:0.6685, R:0.0105)
Batch 325/537: Loss=0.6742 (C:0.6742, R:0.0105)
Batch 350/537: Loss=0.7079 (C:0.7079, R:0.0105)
Batch 375/537: Loss=0.6744 (C:0.6744, R:0.0105)
Batch 400/537: Loss=0.6395 (C:0.6395, R:0.0105)
Batch 425/537: Loss=0.6727 (C:0.6727, R:0.0105)
Batch 450/537: Loss=0.6520 (C:0.6520, R:0.0105)
Batch 475/537: Loss=0.6708 (C:0.6708, R:0.0105)
Batch 500/537: Loss=0.7137 (C:0.7137, R:0.0105)
Batch 525/537: Loss=0.6656 (C:0.6656, R:0.0105)

============================================================
Epoch 43/300 completed in 28.1s
Train: Loss=0.6632 (C:0.6632, R:0.0105) Ratio=4.50x
Val:   Loss=0.7903 (C:0.7903, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.195
No improvement for 5 epochs
============================================================

🌍 Updating global dataset at epoch 44
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.398 ± 0.614
    Neg distances: 2.605 ± 1.124
    Separation ratio: 6.54x
    Gap: -4.511
    ✅ Excellent global separation!

Epoch 44 Training
----------------------------------------
Batch   0/537: Loss=0.6476 (C:0.6476, R:0.0105)
Batch  25/537: Loss=0.6820 (C:0.6820, R:0.0105)
Batch  50/537: Loss=0.6179 (C:0.6179, R:0.0105)
Batch  75/537: Loss=0.6692 (C:0.6692, R:0.0105)
Batch 100/537: Loss=0.6598 (C:0.6598, R:0.0105)
Batch 125/537: Loss=0.6764 (C:0.6764, R:0.0105)
Batch 150/537: Loss=0.6343 (C:0.6343, R:0.0105)
Batch 175/537: Loss=0.6436 (C:0.6436, R:0.0105)
Batch 200/537: Loss=0.6454 (C:0.6454, R:0.0105)
Batch 225/537: Loss=0.6574 (C:0.6574, R:0.0105)
Batch 250/537: Loss=0.6888 (C:0.6888, R:0.0105)
Batch 275/537: Loss=0.6699 (C:0.6699, R:0.0105)
Batch 300/537: Loss=0.6639 (C:0.6639, R:0.0105)
Batch 325/537: Loss=0.6675 (C:0.6675, R:0.0105)
Batch 350/537: Loss=0.6505 (C:0.6505, R:0.0105)
Batch 375/537: Loss=0.6542 (C:0.6542, R:0.0106)
Batch 400/537: Loss=0.6883 (C:0.6883, R:0.0105)
Batch 425/537: Loss=0.6928 (C:0.6928, R:0.0105)
Batch 450/537: Loss=0.6915 (C:0.6915, R:0.0105)
Batch 475/537: Loss=0.6903 (C:0.6903, R:0.0105)
Batch 500/537: Loss=0.6563 (C:0.6563, R:0.0105)
Batch 525/537: Loss=0.6650 (C:0.6650, R:0.0105)

============================================================
Epoch 44/300 completed in 27.8s
Train: Loss=0.6571 (C:0.6571, R:0.0105) Ratio=4.51x
Val:   Loss=0.7891 (C:0.7891, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.210
No improvement for 6 epochs
============================================================

🌍 Updating global dataset at epoch 45
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.356 ± 0.556
    Neg distances: 2.623 ± 1.101
    Separation ratio: 7.37x
    Gap: -4.493
    ✅ Excellent global separation!

Epoch 45 Training
----------------------------------------
Batch   0/537: Loss=0.6401 (C:0.6401, R:0.0105)
Batch  25/537: Loss=0.6145 (C:0.6145, R:0.0105)
Batch  50/537: Loss=0.6103 (C:0.6103, R:0.0105)
Batch  75/537: Loss=0.6157 (C:0.6157, R:0.0105)
Batch 100/537: Loss=0.6019 (C:0.6019, R:0.0105)
Batch 125/537: Loss=0.6084 (C:0.6084, R:0.0105)
Batch 150/537: Loss=0.6251 (C:0.6251, R:0.0105)
Batch 175/537: Loss=0.5964 (C:0.5964, R:0.0105)
Batch 200/537: Loss=0.6042 (C:0.6042, R:0.0105)
Batch 225/537: Loss=0.6141 (C:0.6141, R:0.0105)
Batch 250/537: Loss=0.6199 (C:0.6199, R:0.0105)
Batch 275/537: Loss=0.6008 (C:0.6008, R:0.0105)
Batch 300/537: Loss=0.6178 (C:0.6178, R:0.0105)
Batch 325/537: Loss=0.6304 (C:0.6304, R:0.0105)
Batch 350/537: Loss=0.6284 (C:0.6284, R:0.0105)
Batch 375/537: Loss=0.6430 (C:0.6430, R:0.0105)
Batch 400/537: Loss=0.6115 (C:0.6115, R:0.0105)
Batch 425/537: Loss=0.6259 (C:0.6259, R:0.0105)
Batch 450/537: Loss=0.6096 (C:0.6096, R:0.0106)
Batch 475/537: Loss=0.6362 (C:0.6362, R:0.0105)
Batch 500/537: Loss=0.6155 (C:0.6155, R:0.0105)
Batch 525/537: Loss=0.6330 (C:0.6330, R:0.0105)

============================================================
Epoch 45/300 completed in 27.3s
Train: Loss=0.6194 (C:0.6194, R:0.0105) Ratio=4.51x
Val:   Loss=0.7580 (C:0.7580, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.225
✅ New best model saved (Val Loss: 0.7580)
============================================================

🌍 Updating global dataset at epoch 46
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.378 ± 0.604
    Neg distances: 2.597 ± 1.107
    Separation ratio: 6.87x
    Gap: -4.449
    ✅ Excellent global separation!

Epoch 46 Training
----------------------------------------
Batch   0/537: Loss=0.5996 (C:0.5996, R:0.0105)
Batch  25/537: Loss=0.6427 (C:0.6427, R:0.0105)
Batch  50/537: Loss=0.6340 (C:0.6340, R:0.0105)
Batch  75/537: Loss=0.6277 (C:0.6277, R:0.0105)
Batch 100/537: Loss=0.6352 (C:0.6352, R:0.0105)
Batch 125/537: Loss=0.6231 (C:0.6231, R:0.0105)
Batch 150/537: Loss=0.6125 (C:0.6125, R:0.0105)
Batch 175/537: Loss=0.6138 (C:0.6138, R:0.0105)
Batch 200/537: Loss=0.6707 (C:0.6707, R:0.0105)
Batch 225/537: Loss=0.5982 (C:0.5982, R:0.0105)
Batch 250/537: Loss=0.6459 (C:0.6459, R:0.0105)
Batch 275/537: Loss=0.6531 (C:0.6531, R:0.0105)
Batch 300/537: Loss=0.6693 (C:0.6693, R:0.0105)
Batch 325/537: Loss=0.6308 (C:0.6308, R:0.0105)
Batch 350/537: Loss=0.6298 (C:0.6298, R:0.0105)
Batch 375/537: Loss=0.6707 (C:0.6707, R:0.0105)
Batch 400/537: Loss=0.6178 (C:0.6178, R:0.0105)
Batch 425/537: Loss=0.6465 (C:0.6465, R:0.0105)
Batch 450/537: Loss=0.6781 (C:0.6781, R:0.0105)
Batch 475/537: Loss=0.6389 (C:0.6389, R:0.0105)
Batch 500/537: Loss=0.6436 (C:0.6436, R:0.0105)
Batch 525/537: Loss=0.6215 (C:0.6215, R:0.0105)

============================================================
Epoch 46/300 completed in 27.8s
Train: Loss=0.6358 (C:0.6358, R:0.0105) Ratio=4.59x
Val:   Loss=0.7762 (C:0.7762, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.240
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 47
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.388 ± 0.626
    Neg distances: 2.616 ± 1.122
    Separation ratio: 6.74x
    Gap: -4.550
    ✅ Excellent global separation!

Epoch 47 Training
----------------------------------------
Batch   0/537: Loss=0.6277 (C:0.6277, R:0.0105)
Batch  25/537: Loss=0.6292 (C:0.6292, R:0.0105)
Batch  50/537: Loss=0.6207 (C:0.6207, R:0.0105)
Batch  75/537: Loss=0.6704 (C:0.6704, R:0.0105)
Batch 100/537: Loss=0.6416 (C:0.6416, R:0.0105)
Batch 125/537: Loss=0.6448 (C:0.6448, R:0.0105)
Batch 150/537: Loss=0.6514 (C:0.6514, R:0.0105)
Batch 175/537: Loss=0.6587 (C:0.6587, R:0.0105)
Batch 200/537: Loss=0.6411 (C:0.6411, R:0.0105)
Batch 225/537: Loss=0.6618 (C:0.6618, R:0.0105)
Batch 250/537: Loss=0.6177 (C:0.6177, R:0.0105)
Batch 275/537: Loss=0.6021 (C:0.6021, R:0.0105)
Batch 300/537: Loss=0.6308 (C:0.6308, R:0.0105)
Batch 325/537: Loss=0.6489 (C:0.6489, R:0.0105)
Batch 350/537: Loss=0.6351 (C:0.6351, R:0.0105)
Batch 375/537: Loss=0.6327 (C:0.6327, R:0.0105)
Batch 400/537: Loss=0.6501 (C:0.6501, R:0.0105)
Batch 425/537: Loss=0.6447 (C:0.6447, R:0.0105)
Batch 450/537: Loss=0.5980 (C:0.5980, R:0.0105)
Batch 475/537: Loss=0.6500 (C:0.6500, R:0.0105)
Batch 500/537: Loss=0.6272 (C:0.6272, R:0.0105)
Batch 525/537: Loss=0.6171 (C:0.6171, R:0.0105)

============================================================
Epoch 47/300 completed in 27.2s
Train: Loss=0.6402 (C:0.6402, R:0.0105) Ratio=4.65x
Val:   Loss=0.7888 (C:0.7888, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.255
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 48
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.370 ± 0.602
    Neg distances: 2.584 ± 1.100
    Separation ratio: 6.98x
    Gap: -4.446
    ✅ Excellent global separation!

Epoch 48 Training
----------------------------------------
Batch   0/537: Loss=0.6161 (C:0.6161, R:0.0105)
Batch  25/537: Loss=0.6316 (C:0.6316, R:0.0105)
Batch  50/537: Loss=0.6466 (C:0.6466, R:0.0105)
Batch  75/537: Loss=0.6214 (C:0.6214, R:0.0105)
Batch 100/537: Loss=0.6054 (C:0.6054, R:0.0105)
Batch 125/537: Loss=0.6245 (C:0.6245, R:0.0105)
Batch 150/537: Loss=0.5976 (C:0.5976, R:0.0105)
Batch 175/537: Loss=0.6304 (C:0.6304, R:0.0105)
Batch 200/537: Loss=0.6136 (C:0.6136, R:0.0105)
Batch 225/537: Loss=0.6267 (C:0.6267, R:0.0105)
Batch 250/537: Loss=0.6097 (C:0.6097, R:0.0105)
Batch 275/537: Loss=0.6218 (C:0.6218, R:0.0105)
Batch 300/537: Loss=0.6359 (C:0.6359, R:0.0105)
Batch 325/537: Loss=0.6091 (C:0.6091, R:0.0105)
Batch 350/537: Loss=0.6225 (C:0.6225, R:0.0105)
Batch 375/537: Loss=0.6413 (C:0.6413, R:0.0105)
Batch 400/537: Loss=0.5923 (C:0.5923, R:0.0105)
Batch 425/537: Loss=0.6665 (C:0.6665, R:0.0105)
Batch 450/537: Loss=0.6352 (C:0.6352, R:0.0105)
Batch 475/537: Loss=0.6685 (C:0.6685, R:0.0105)
Batch 500/537: Loss=0.5931 (C:0.5931, R:0.0105)
Batch 525/537: Loss=0.6572 (C:0.6572, R:0.0105)

============================================================
Epoch 48/300 completed in 27.2s
Train: Loss=0.6273 (C:0.6273, R:0.0105) Ratio=4.61x
Val:   Loss=0.7696 (C:0.7696, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.270
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 49
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.368 ± 0.589
    Neg distances: 2.626 ± 1.115
    Separation ratio: 7.13x
    Gap: -4.573
    ✅ Excellent global separation!

Epoch 49 Training
----------------------------------------
Batch   0/537: Loss=0.6286 (C:0.6286, R:0.0105)
Batch  25/537: Loss=0.5999 (C:0.5999, R:0.0105)
Batch  50/537: Loss=0.6155 (C:0.6155, R:0.0105)
Batch  75/537: Loss=0.6488 (C:0.6488, R:0.0105)
Batch 100/537: Loss=0.6187 (C:0.6187, R:0.0105)
Batch 125/537: Loss=0.6188 (C:0.6188, R:0.0105)
Batch 150/537: Loss=0.6154 (C:0.6154, R:0.0105)
Batch 175/537: Loss=0.6156 (C:0.6156, R:0.0105)
Batch 200/537: Loss=0.6313 (C:0.6313, R:0.0105)
Batch 225/537: Loss=0.6084 (C:0.6084, R:0.0105)
Batch 250/537: Loss=0.6004 (C:0.6004, R:0.0105)
Batch 275/537: Loss=0.5829 (C:0.5829, R:0.0105)
Batch 300/537: Loss=0.6230 (C:0.6230, R:0.0105)
Batch 325/537: Loss=0.6502 (C:0.6502, R:0.0105)
Batch 350/537: Loss=0.6196 (C:0.6196, R:0.0105)
Batch 375/537: Loss=0.6398 (C:0.6398, R:0.0105)
Batch 400/537: Loss=0.5791 (C:0.5791, R:0.0105)
Batch 425/537: Loss=0.6447 (C:0.6447, R:0.0105)
Batch 450/537: Loss=0.6138 (C:0.6138, R:0.0105)
Batch 475/537: Loss=0.6454 (C:0.6454, R:0.0106)
Batch 500/537: Loss=0.6046 (C:0.6046, R:0.0105)
Batch 525/537: Loss=0.6546 (C:0.6546, R:0.0105)

============================================================
Epoch 49/300 completed in 27.3s
Train: Loss=0.6215 (C:0.6215, R:0.0105) Ratio=4.64x
Val:   Loss=0.7754 (C:0.7754, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.285
No improvement for 4 epochs
============================================================

🌍 Updating global dataset at epoch 50
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.355 ± 0.579
    Neg distances: 2.625 ± 1.105
    Separation ratio: 7.39x
    Gap: -4.485
    ✅ Excellent global separation!

Epoch 50 Training
----------------------------------------
Batch   0/537: Loss=0.5902 (C:0.5902, R:0.0105)
Batch  25/537: Loss=0.5608 (C:0.5608, R:0.0105)
Batch  50/537: Loss=0.6259 (C:0.6259, R:0.0105)
Batch  75/537: Loss=0.5879 (C:0.5879, R:0.0105)
Batch 100/537: Loss=0.5942 (C:0.5942, R:0.0106)
Batch 125/537: Loss=0.6210 (C:0.6210, R:0.0105)
Batch 150/537: Loss=0.6045 (C:0.6045, R:0.0105)
Batch 175/537: Loss=0.6388 (C:0.6388, R:0.0105)
Batch 200/537: Loss=0.6142 (C:0.6142, R:0.0105)
Batch 225/537: Loss=0.5808 (C:0.5808, R:0.0105)
Batch 250/537: Loss=0.6199 (C:0.6199, R:0.0105)
Batch 275/537: Loss=0.6214 (C:0.6214, R:0.0105)
Batch 300/537: Loss=0.5859 (C:0.5859, R:0.0105)
Batch 325/537: Loss=0.6123 (C:0.6123, R:0.0105)
Batch 350/537: Loss=0.6253 (C:0.6253, R:0.0105)
Batch 375/537: Loss=0.6168 (C:0.6168, R:0.0105)
Batch 400/537: Loss=0.6491 (C:0.6491, R:0.0106)
Batch 425/537: Loss=0.6410 (C:0.6410, R:0.0105)
Batch 450/537: Loss=0.5768 (C:0.5768, R:0.0105)
Batch 475/537: Loss=0.5909 (C:0.5909, R:0.0105)
Batch 500/537: Loss=0.6093 (C:0.6093, R:0.0105)
Batch 525/537: Loss=0.6161 (C:0.6161, R:0.0105)

============================================================
Epoch 50/300 completed in 27.2s
Train: Loss=0.6094 (C:0.6094, R:0.0105) Ratio=4.68x
Val:   Loss=0.7537 (C:0.7537, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.7537)
============================================================

🌍 Updating global dataset at epoch 51
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.366 ± 0.613
    Neg distances: 2.645 ± 1.119
    Separation ratio: 7.22x
    Gap: -4.493
    ✅ Excellent global separation!

Epoch 51 Training
----------------------------------------
Batch   0/537: Loss=0.6294 (C:0.6294, R:0.0105)
Batch  25/537: Loss=0.6198 (C:0.6198, R:0.0105)
Batch  50/537: Loss=0.5863 (C:0.5863, R:0.0105)
Batch  75/537: Loss=0.5977 (C:0.5977, R:0.0105)
Batch 100/537: Loss=0.5912 (C:0.5912, R:0.0105)
Batch 125/537: Loss=0.6073 (C:0.6073, R:0.0105)
Batch 150/537: Loss=0.6111 (C:0.6111, R:0.0105)
Batch 175/537: Loss=0.5839 (C:0.5839, R:0.0105)
Batch 200/537: Loss=0.6089 (C:0.6089, R:0.0105)
Batch 225/537: Loss=0.5943 (C:0.5943, R:0.0105)
Batch 250/537: Loss=0.6084 (C:0.6084, R:0.0105)
Batch 275/537: Loss=0.6103 (C:0.6103, R:0.0105)
Batch 300/537: Loss=0.6460 (C:0.6460, R:0.0105)
Batch 325/537: Loss=0.6224 (C:0.6224, R:0.0105)
Batch 350/537: Loss=0.5800 (C:0.5800, R:0.0105)
Batch 375/537: Loss=0.6700 (C:0.6700, R:0.0105)
Batch 400/537: Loss=0.6390 (C:0.6390, R:0.0105)
Batch 425/537: Loss=0.5944 (C:0.5944, R:0.0105)
Batch 450/537: Loss=0.5985 (C:0.5985, R:0.0105)
Batch 475/537: Loss=0.6631 (C:0.6631, R:0.0105)
Batch 500/537: Loss=0.6092 (C:0.6092, R:0.0105)
Batch 525/537: Loss=0.6260 (C:0.6260, R:0.0105)

============================================================
Epoch 51/300 completed in 27.4s
Train: Loss=0.6169 (C:0.6169, R:0.0105) Ratio=4.65x
Val:   Loss=0.7595 (C:0.7595, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 52
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.373 ± 0.597
    Neg distances: 2.603 ± 1.106
    Separation ratio: 6.97x
    Gap: -4.519
    ✅ Excellent global separation!

Epoch 52 Training
----------------------------------------
Batch   0/537: Loss=0.6324 (C:0.6324, R:0.0105)
Batch  25/537: Loss=0.5909 (C:0.5909, R:0.0105)
Batch  50/537: Loss=0.6336 (C:0.6336, R:0.0105)
Batch  75/537: Loss=0.6029 (C:0.6029, R:0.0105)
Batch 100/537: Loss=0.6091 (C:0.6091, R:0.0105)
Batch 125/537: Loss=0.5848 (C:0.5848, R:0.0105)
Batch 150/537: Loss=0.6023 (C:0.6023, R:0.0105)
Batch 175/537: Loss=0.6232 (C:0.6232, R:0.0106)
Batch 200/537: Loss=0.6422 (C:0.6422, R:0.0105)
Batch 225/537: Loss=0.6190 (C:0.6190, R:0.0105)
Batch 250/537: Loss=0.6352 (C:0.6352, R:0.0105)
Batch 275/537: Loss=0.6170 (C:0.6170, R:0.0105)
Batch 300/537: Loss=0.6268 (C:0.6268, R:0.0105)
Batch 325/537: Loss=0.6280 (C:0.6280, R:0.0105)
Batch 350/537: Loss=0.5708 (C:0.5708, R:0.0105)
Batch 375/537: Loss=0.6024 (C:0.6024, R:0.0105)
Batch 400/537: Loss=0.6043 (C:0.6043, R:0.0105)
Batch 425/537: Loss=0.6363 (C:0.6363, R:0.0105)
Batch 450/537: Loss=0.6070 (C:0.6070, R:0.0105)
Batch 475/537: Loss=0.6268 (C:0.6268, R:0.0105)
Batch 500/537: Loss=0.6247 (C:0.6247, R:0.0105)
Batch 525/537: Loss=0.6286 (C:0.6286, R:0.0105)

============================================================
Epoch 52/300 completed in 28.3s
Train: Loss=0.6216 (C:0.6216, R:0.0105) Ratio=4.77x
Val:   Loss=0.7643 (C:0.7643, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 53
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.362 ± 0.591
    Neg distances: 2.603 ± 1.103
    Separation ratio: 7.18x
    Gap: -4.450
    ✅ Excellent global separation!

Epoch 53 Training
----------------------------------------
Batch   0/537: Loss=0.6274 (C:0.6274, R:0.0105)
Batch  25/537: Loss=0.6136 (C:0.6136, R:0.0105)
Batch  50/537: Loss=0.5708 (C:0.5708, R:0.0105)
Batch  75/537: Loss=0.5917 (C:0.5917, R:0.0105)
Batch 100/537: Loss=0.6180 (C:0.6180, R:0.0105)
Batch 125/537: Loss=0.6067 (C:0.6067, R:0.0105)
Batch 150/537: Loss=0.6278 (C:0.6278, R:0.0105)
Batch 175/537: Loss=0.6246 (C:0.6246, R:0.0105)
Batch 200/537: Loss=0.6155 (C:0.6155, R:0.0105)
Batch 225/537: Loss=0.5949 (C:0.5949, R:0.0105)
Batch 250/537: Loss=0.5995 (C:0.5995, R:0.0105)
Batch 275/537: Loss=0.5979 (C:0.5979, R:0.0105)
Batch 300/537: Loss=0.6303 (C:0.6303, R:0.0105)
Batch 325/537: Loss=0.5999 (C:0.5999, R:0.0105)
Batch 350/537: Loss=0.6382 (C:0.6382, R:0.0105)
Batch 375/537: Loss=0.5980 (C:0.5980, R:0.0105)
Batch 400/537: Loss=0.6155 (C:0.6155, R:0.0105)
Batch 425/537: Loss=0.6190 (C:0.6190, R:0.0105)
Batch 450/537: Loss=0.6599 (C:0.6599, R:0.0105)
Batch 475/537: Loss=0.6137 (C:0.6137, R:0.0105)
Batch 500/537: Loss=0.6003 (C:0.6003, R:0.0105)
Batch 525/537: Loss=0.6254 (C:0.6254, R:0.0105)

============================================================
Epoch 53/300 completed in 27.6s
Train: Loss=0.6119 (C:0.6119, R:0.0105) Ratio=4.73x
Val:   Loss=0.7424 (C:0.7424, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.7424)
============================================================

🌍 Updating global dataset at epoch 54
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.361 ± 0.602
    Neg distances: 2.615 ± 1.107
    Separation ratio: 7.24x
    Gap: -4.557
    ✅ Excellent global separation!

Epoch 54 Training
----------------------------------------
Batch   0/537: Loss=0.5769 (C:0.5769, R:0.0105)
Batch  25/537: Loss=0.5595 (C:0.5595, R:0.0105)
Batch  50/537: Loss=0.6486 (C:0.6486, R:0.0106)
Batch  75/537: Loss=0.6023 (C:0.6023, R:0.0105)
Batch 100/537: Loss=0.5896 (C:0.5896, R:0.0105)
Batch 125/537: Loss=0.6242 (C:0.6242, R:0.0105)
Batch 150/537: Loss=0.6179 (C:0.6179, R:0.0105)
Batch 175/537: Loss=0.5797 (C:0.5797, R:0.0105)
Batch 200/537: Loss=0.5722 (C:0.5722, R:0.0106)
Batch 225/537: Loss=0.5858 (C:0.5858, R:0.0105)
Batch 250/537: Loss=0.6127 (C:0.6127, R:0.0105)
Batch 275/537: Loss=0.6691 (C:0.6691, R:0.0105)
Batch 300/537: Loss=0.5628 (C:0.5628, R:0.0105)
Batch 325/537: Loss=0.6067 (C:0.6067, R:0.0105)
Batch 350/537: Loss=0.5838 (C:0.5838, R:0.0105)
Batch 375/537: Loss=0.6045 (C:0.6045, R:0.0105)
Batch 400/537: Loss=0.6078 (C:0.6078, R:0.0105)
Batch 425/537: Loss=0.6368 (C:0.6368, R:0.0105)
Batch 450/537: Loss=0.6063 (C:0.6063, R:0.0105)
Batch 475/537: Loss=0.5961 (C:0.5961, R:0.0105)
Batch 500/537: Loss=0.6077 (C:0.6077, R:0.0105)
Batch 525/537: Loss=0.6405 (C:0.6405, R:0.0106)

============================================================
Epoch 54/300 completed in 27.3s
Train: Loss=0.6072 (C:0.6072, R:0.0105) Ratio=4.77x
Val:   Loss=0.7534 (C:0.7534, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 55
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.365 ± 0.610
    Neg distances: 2.618 ± 1.113
    Separation ratio: 7.16x
    Gap: -4.617
    ✅ Excellent global separation!

Epoch 55 Training
----------------------------------------
Batch   0/537: Loss=0.6069 (C:0.6069, R:0.0105)
Batch  25/537: Loss=0.5597 (C:0.5597, R:0.0105)
Batch  50/537: Loss=0.5969 (C:0.5969, R:0.0105)
Batch  75/537: Loss=0.5983 (C:0.5983, R:0.0105)
Batch 100/537: Loss=0.6608 (C:0.6608, R:0.0105)
Batch 125/537: Loss=0.5948 (C:0.5948, R:0.0105)
Batch 150/537: Loss=0.6105 (C:0.6105, R:0.0106)
Batch 175/537: Loss=0.5910 (C:0.5910, R:0.0105)
Batch 200/537: Loss=0.6101 (C:0.6101, R:0.0105)
Batch 225/537: Loss=0.5873 (C:0.5873, R:0.0105)
Batch 250/537: Loss=0.6175 (C:0.6175, R:0.0105)
Batch 275/537: Loss=0.5908 (C:0.5908, R:0.0106)
Batch 300/537: Loss=0.6042 (C:0.6042, R:0.0105)
Batch 325/537: Loss=0.5888 (C:0.5888, R:0.0105)
Batch 350/537: Loss=0.6142 (C:0.6142, R:0.0105)
Batch 375/537: Loss=0.6456 (C:0.6456, R:0.0105)
Batch 400/537: Loss=0.5863 (C:0.5863, R:0.0105)
Batch 425/537: Loss=0.6629 (C:0.6629, R:0.0105)
Batch 450/537: Loss=0.6004 (C:0.6004, R:0.0105)
Batch 475/537: Loss=0.6215 (C:0.6215, R:0.0105)
Batch 500/537: Loss=0.6310 (C:0.6310, R:0.0105)
Batch 525/537: Loss=0.6572 (C:0.6572, R:0.0105)

============================================================
Epoch 55/300 completed in 27.5s
Train: Loss=0.6101 (C:0.6101, R:0.0105) Ratio=4.75x
Val:   Loss=0.7606 (C:0.7606, R:0.0104) Ratio=3.02x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 56
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.360 ± 0.583
    Neg distances: 2.646 ± 1.121
    Separation ratio: 7.35x
    Gap: -4.577
    ✅ Excellent global separation!

Epoch 56 Training
----------------------------------------
Batch   0/537: Loss=0.6158 (C:0.6158, R:0.0105)
Batch  25/537: Loss=0.5596 (C:0.5596, R:0.0105)
Batch  50/537: Loss=0.5788 (C:0.5788, R:0.0105)
Batch  75/537: Loss=0.5476 (C:0.5476, R:0.0105)
Batch 100/537: Loss=0.5996 (C:0.5996, R:0.0105)
Batch 125/537: Loss=0.6018 (C:0.6018, R:0.0106)
Batch 150/537: Loss=0.5566 (C:0.5566, R:0.0105)
Batch 175/537: Loss=0.5726 (C:0.5726, R:0.0105)
Batch 200/537: Loss=0.6223 (C:0.6223, R:0.0105)
Batch 225/537: Loss=0.6215 (C:0.6215, R:0.0106)
Batch 250/537: Loss=0.5909 (C:0.5909, R:0.0105)
Batch 275/537: Loss=0.6060 (C:0.6060, R:0.0105)
Batch 300/537: Loss=0.6080 (C:0.6080, R:0.0105)
Batch 325/537: Loss=0.5871 (C:0.5871, R:0.0105)
Batch 350/537: Loss=0.5807 (C:0.5807, R:0.0106)
Batch 375/537: Loss=0.6041 (C:0.6041, R:0.0105)
Batch 400/537: Loss=0.6036 (C:0.6036, R:0.0105)
Batch 425/537: Loss=0.6290 (C:0.6290, R:0.0105)
Batch 450/537: Loss=0.6056 (C:0.6056, R:0.0105)
Batch 475/537: Loss=0.6152 (C:0.6152, R:0.0105)
Batch 500/537: Loss=0.5522 (C:0.5522, R:0.0105)
Batch 525/537: Loss=0.6182 (C:0.6182, R:0.0105)

============================================================
Epoch 56/300 completed in 27.5s
Train: Loss=0.6029 (C:0.6029, R:0.0105) Ratio=4.83x
Val:   Loss=0.7654 (C:0.7654, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 57
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.354 ± 0.593
    Neg distances: 2.631 ± 1.107
    Separation ratio: 7.43x
    Gap: -4.561
    ✅ Excellent global separation!

Epoch 57 Training
----------------------------------------
Batch   0/537: Loss=0.5434 (C:0.5434, R:0.0105)
Batch  25/537: Loss=0.6375 (C:0.6375, R:0.0105)
Batch  50/537: Loss=0.6253 (C:0.6253, R:0.0105)
Batch  75/537: Loss=0.5880 (C:0.5880, R:0.0105)
Batch 100/537: Loss=0.5698 (C:0.5698, R:0.0105)
Batch 125/537: Loss=0.6150 (C:0.6150, R:0.0105)
Batch 150/537: Loss=0.5951 (C:0.5951, R:0.0105)
Batch 175/537: Loss=0.6016 (C:0.6016, R:0.0105)
Batch 200/537: Loss=0.5715 (C:0.5715, R:0.0105)
Batch 225/537: Loss=0.5792 (C:0.5792, R:0.0105)
Batch 250/537: Loss=0.5949 (C:0.5949, R:0.0105)
Batch 275/537: Loss=0.6332 (C:0.6332, R:0.0105)
Batch 300/537: Loss=0.5895 (C:0.5895, R:0.0105)
Batch 325/537: Loss=0.6013 (C:0.6013, R:0.0105)
Batch 350/537: Loss=0.6375 (C:0.6375, R:0.0105)
Batch 375/537: Loss=0.6059 (C:0.6059, R:0.0105)
Batch 400/537: Loss=0.6068 (C:0.6068, R:0.0105)
Batch 425/537: Loss=0.5826 (C:0.5826, R:0.0105)
Batch 450/537: Loss=0.6224 (C:0.6224, R:0.0105)
Batch 475/537: Loss=0.5744 (C:0.5744, R:0.0105)
Batch 500/537: Loss=0.5983 (C:0.5983, R:0.0105)
Batch 525/537: Loss=0.5910 (C:0.5910, R:0.0105)

============================================================
Epoch 57/300 completed in 27.4s
Train: Loss=0.5953 (C:0.5953, R:0.0105) Ratio=4.80x
Val:   Loss=0.7555 (C:0.7555, R:0.0104) Ratio=3.02x
Reconstruction weight: 0.300
No improvement for 4 epochs
============================================================

🌍 Updating global dataset at epoch 58
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.350 ± 0.587
    Neg distances: 2.625 ± 1.104
    Separation ratio: 7.50x
    Gap: -4.596
    ✅ Excellent global separation!

Epoch 58 Training
----------------------------------------
Batch   0/537: Loss=0.6109 (C:0.6109, R:0.0105)
Batch  25/537: Loss=0.5606 (C:0.5606, R:0.0105)
Batch  50/537: Loss=0.5808 (C:0.5808, R:0.0105)
Batch  75/537: Loss=0.5858 (C:0.5858, R:0.0105)
Batch 100/537: Loss=0.5463 (C:0.5463, R:0.0105)
Batch 125/537: Loss=0.5836 (C:0.5836, R:0.0105)
Batch 150/537: Loss=0.6070 (C:0.6070, R:0.0105)
Batch 175/537: Loss=0.5857 (C:0.5857, R:0.0105)
Batch 200/537: Loss=0.5704 (C:0.5704, R:0.0105)
Batch 225/537: Loss=0.5710 (C:0.5710, R:0.0105)
Batch 250/537: Loss=0.6054 (C:0.6054, R:0.0105)
Batch 275/537: Loss=0.6008 (C:0.6008, R:0.0105)
Batch 300/537: Loss=0.6031 (C:0.6031, R:0.0105)
Batch 325/537: Loss=0.5877 (C:0.5877, R:0.0105)
Batch 350/537: Loss=0.5932 (C:0.5932, R:0.0106)
Batch 375/537: Loss=0.5736 (C:0.5736, R:0.0105)
Batch 400/537: Loss=0.5941 (C:0.5941, R:0.0105)
Batch 425/537: Loss=0.6084 (C:0.6084, R:0.0105)
Batch 450/537: Loss=0.5943 (C:0.5943, R:0.0105)
Batch 475/537: Loss=0.6075 (C:0.6075, R:0.0105)
Batch 500/537: Loss=0.6140 (C:0.6140, R:0.0105)
Batch 525/537: Loss=0.6000 (C:0.6000, R:0.0105)

============================================================
Epoch 58/300 completed in 27.1s
Train: Loss=0.5919 (C:0.5919, R:0.0105) Ratio=4.83x
Val:   Loss=0.7517 (C:0.7517, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 5 epochs
============================================================

🌍 Updating global dataset at epoch 59
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.345 ± 0.569
    Neg distances: 2.640 ± 1.104
    Separation ratio: 7.64x
    Gap: -4.593
    ✅ Excellent global separation!

Epoch 59 Training
----------------------------------------
Batch   0/537: Loss=0.5727 (C:0.5727, R:0.0105)
Batch  25/537: Loss=0.5882 (C:0.5882, R:0.0105)
Batch  50/537: Loss=0.5592 (C:0.5592, R:0.0105)
Batch  75/537: Loss=0.6153 (C:0.6153, R:0.0105)
Batch 100/537: Loss=0.5538 (C:0.5538, R:0.0105)
Batch 125/537: Loss=0.5712 (C:0.5712, R:0.0105)
Batch 150/537: Loss=0.5547 (C:0.5547, R:0.0105)
Batch 175/537: Loss=0.5582 (C:0.5582, R:0.0105)
Batch 200/537: Loss=0.5653 (C:0.5653, R:0.0105)
Batch 225/537: Loss=0.5910 (C:0.5910, R:0.0105)
Batch 250/537: Loss=0.5887 (C:0.5887, R:0.0105)
Batch 275/537: Loss=0.5681 (C:0.5681, R:0.0105)
Batch 300/537: Loss=0.5707 (C:0.5707, R:0.0105)
Batch 325/537: Loss=0.5476 (C:0.5476, R:0.0105)
Batch 350/537: Loss=0.5604 (C:0.5604, R:0.0105)
Batch 375/537: Loss=0.6002 (C:0.6002, R:0.0105)
Batch 400/537: Loss=0.6005 (C:0.6005, R:0.0105)
Batch 425/537: Loss=0.5850 (C:0.5850, R:0.0105)
Batch 450/537: Loss=0.5512 (C:0.5512, R:0.0105)
Batch 475/537: Loss=0.6030 (C:0.6030, R:0.0106)
Batch 500/537: Loss=0.6030 (C:0.6030, R:0.0105)
Batch 525/537: Loss=0.6095 (C:0.6095, R:0.0105)

============================================================
Epoch 59/300 completed in 27.3s
Train: Loss=0.5847 (C:0.5847, R:0.0105) Ratio=4.89x
Val:   Loss=0.7527 (C:0.7527, R:0.0104) Ratio=3.02x
Reconstruction weight: 0.300
No improvement for 6 epochs
============================================================

🌍 Updating global dataset at epoch 60
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.341 ± 0.570
    Neg distances: 2.653 ± 1.107
    Separation ratio: 7.77x
    Gap: -4.668
    ✅ Excellent global separation!

Epoch 60 Training
----------------------------------------
Batch   0/537: Loss=0.5721 (C:0.5721, R:0.0105)
Batch  25/537: Loss=0.5917 (C:0.5917, R:0.0105)
Batch  50/537: Loss=0.5570 (C:0.5570, R:0.0105)
Batch  75/537: Loss=0.5580 (C:0.5580, R:0.0105)
Batch 100/537: Loss=0.5892 (C:0.5892, R:0.0105)
Batch 125/537: Loss=0.5480 (C:0.5480, R:0.0105)
Batch 150/537: Loss=0.5593 (C:0.5593, R:0.0105)
Batch 175/537: Loss=0.6039 (C:0.6039, R:0.0105)
Batch 200/537: Loss=0.5321 (C:0.5321, R:0.0105)
Batch 225/537: Loss=0.5829 (C:0.5829, R:0.0105)
Batch 250/537: Loss=0.5764 (C:0.5764, R:0.0105)
Batch 275/537: Loss=0.5482 (C:0.5482, R:0.0105)
Batch 300/537: Loss=0.6024 (C:0.6024, R:0.0105)
Batch 325/537: Loss=0.5535 (C:0.5535, R:0.0105)
Batch 350/537: Loss=0.5846 (C:0.5846, R:0.0105)
Batch 375/537: Loss=0.6111 (C:0.6111, R:0.0105)
Batch 400/537: Loss=0.5779 (C:0.5779, R:0.0105)
Batch 425/537: Loss=0.6108 (C:0.6108, R:0.0105)
Batch 450/537: Loss=0.5609 (C:0.5609, R:0.0105)
Batch 475/537: Loss=0.5995 (C:0.5995, R:0.0105)
Batch 500/537: Loss=0.6009 (C:0.6009, R:0.0105)
Batch 525/537: Loss=0.5709 (C:0.5709, R:0.0105)

============================================================
Epoch 60/300 completed in 27.8s
Train: Loss=0.5806 (C:0.5806, R:0.0105) Ratio=4.96x
Val:   Loss=0.7423 (C:0.7423, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.7423)
Checkpoint saved at epoch 60
============================================================

🌍 Updating global dataset at epoch 61
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.338 ± 0.575
    Neg distances: 2.667 ± 1.109
    Separation ratio: 7.88x
    Gap: -4.523
    ✅ Excellent global separation!

Epoch 61 Training
----------------------------------------
Batch   0/537: Loss=0.5940 (C:0.5940, R:0.0105)
Batch  25/537: Loss=0.5768 (C:0.5768, R:0.0105)
Batch  50/537: Loss=0.6128 (C:0.6128, R:0.0105)
Batch  75/537: Loss=0.5929 (C:0.5929, R:0.0105)
Batch 100/537: Loss=0.5315 (C:0.5315, R:0.0105)
Batch 125/537: Loss=0.5863 (C:0.5863, R:0.0105)
Batch 150/537: Loss=0.6331 (C:0.6331, R:0.0105)
Batch 175/537: Loss=0.5558 (C:0.5558, R:0.0105)
Batch 200/537: Loss=0.5840 (C:0.5840, R:0.0105)
Batch 225/537: Loss=0.5891 (C:0.5891, R:0.0105)
Batch 250/537: Loss=0.5496 (C:0.5496, R:0.0105)
Batch 275/537: Loss=0.5872 (C:0.5872, R:0.0105)
Batch 300/537: Loss=0.5771 (C:0.5771, R:0.0105)
Batch 325/537: Loss=0.5728 (C:0.5728, R:0.0105)
Batch 350/537: Loss=0.5933 (C:0.5933, R:0.0105)
Batch 375/537: Loss=0.5679 (C:0.5679, R:0.0106)
Batch 400/537: Loss=0.5819 (C:0.5819, R:0.0105)
Batch 425/537: Loss=0.5885 (C:0.5885, R:0.0105)
Batch 450/537: Loss=0.5971 (C:0.5971, R:0.0105)
Batch 475/537: Loss=0.5674 (C:0.5674, R:0.0105)
Batch 500/537: Loss=0.5815 (C:0.5815, R:0.0105)
Batch 525/537: Loss=0.5430 (C:0.5430, R:0.0105)

============================================================
Epoch 61/300 completed in 28.2s
Train: Loss=0.5769 (C:0.5769, R:0.0105) Ratio=4.80x
Val:   Loss=0.7353 (C:0.7353, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.7353)
============================================================

🌍 Updating global dataset at epoch 62
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.342 ± 0.584
    Neg distances: 2.678 ± 1.117
    Separation ratio: 7.83x
    Gap: -4.583
    ✅ Excellent global separation!

Epoch 62 Training
----------------------------------------
Batch   0/537: Loss=0.5841 (C:0.5841, R:0.0105)
Batch  25/537: Loss=0.5683 (C:0.5683, R:0.0105)
Batch  50/537: Loss=0.5667 (C:0.5667, R:0.0105)
Batch  75/537: Loss=0.5519 (C:0.5519, R:0.0105)
Batch 100/537: Loss=0.5851 (C:0.5851, R:0.0105)
Batch 125/537: Loss=0.5940 (C:0.5940, R:0.0105)
Batch 150/537: Loss=0.5456 (C:0.5456, R:0.0105)
Batch 175/537: Loss=0.5793 (C:0.5793, R:0.0105)
Batch 200/537: Loss=0.5909 (C:0.5909, R:0.0105)
Batch 225/537: Loss=0.5853 (C:0.5853, R:0.0105)
Batch 250/537: Loss=0.5665 (C:0.5665, R:0.0105)
Batch 275/537: Loss=0.5550 (C:0.5550, R:0.0105)
Batch 300/537: Loss=0.5496 (C:0.5496, R:0.0105)
Batch 325/537: Loss=0.5942 (C:0.5942, R:0.0105)
Batch 350/537: Loss=0.5807 (C:0.5807, R:0.0105)
Batch 375/537: Loss=0.5855 (C:0.5855, R:0.0105)
Batch 400/537: Loss=0.5974 (C:0.5974, R:0.0105)
Batch 425/537: Loss=0.5741 (C:0.5741, R:0.0105)
Batch 450/537: Loss=0.5816 (C:0.5816, R:0.0105)
Batch 475/537: Loss=0.5596 (C:0.5596, R:0.0105)
Batch 500/537: Loss=0.5725 (C:0.5725, R:0.0105)
Batch 525/537: Loss=0.5756 (C:0.5756, R:0.0105)

============================================================
Epoch 62/300 completed in 28.1s
Train: Loss=0.5778 (C:0.5778, R:0.0105) Ratio=4.97x
Val:   Loss=0.7421 (C:0.7421, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 63
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.342 ± 0.585
    Neg distances: 2.682 ± 1.121
    Separation ratio: 7.84x
    Gap: -4.587
    ✅ Excellent global separation!

Epoch 63 Training
----------------------------------------
Batch   0/537: Loss=0.6039 (C:0.6039, R:0.0105)
Batch  25/537: Loss=0.5726 (C:0.5726, R:0.0105)
Batch  50/537: Loss=0.5815 (C:0.5815, R:0.0106)
Batch  75/537: Loss=0.5687 (C:0.5687, R:0.0105)
Batch 100/537: Loss=0.5550 (C:0.5550, R:0.0105)
Batch 125/537: Loss=0.5528 (C:0.5528, R:0.0105)
Batch 150/537: Loss=0.6112 (C:0.6112, R:0.0105)
Batch 175/537: Loss=0.5789 (C:0.5789, R:0.0105)
Batch 200/537: Loss=0.5908 (C:0.5908, R:0.0105)
Batch 225/537: Loss=0.5794 (C:0.5794, R:0.0105)
Batch 250/537: Loss=0.5438 (C:0.5438, R:0.0105)
Batch 275/537: Loss=0.5516 (C:0.5516, R:0.0105)
Batch 300/537: Loss=0.5226 (C:0.5226, R:0.0105)
Batch 325/537: Loss=0.5769 (C:0.5769, R:0.0105)
Batch 350/537: Loss=0.5784 (C:0.5784, R:0.0105)
Batch 375/537: Loss=0.5822 (C:0.5822, R:0.0106)
Batch 400/537: Loss=0.6145 (C:0.6145, R:0.0105)
Batch 425/537: Loss=0.6082 (C:0.6082, R:0.0105)
Batch 450/537: Loss=0.5999 (C:0.5999, R:0.0105)
Batch 475/537: Loss=0.6148 (C:0.6148, R:0.0105)
Batch 500/537: Loss=0.6106 (C:0.6106, R:0.0105)
Batch 525/537: Loss=0.5602 (C:0.5602, R:0.0105)

============================================================
Epoch 63/300 completed in 28.4s
Train: Loss=0.5758 (C:0.5758, R:0.0105) Ratio=4.89x
Val:   Loss=0.7397 (C:0.7397, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 64
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.328 ± 0.572
    Neg distances: 2.672 ± 1.105
    Separation ratio: 8.15x
    Gap: -4.655
    ✅ Excellent global separation!

Epoch 64 Training
----------------------------------------
Batch   0/537: Loss=0.5390 (C:0.5390, R:0.0105)
Batch  25/537: Loss=0.5198 (C:0.5198, R:0.0105)
Batch  50/537: Loss=0.5752 (C:0.5752, R:0.0105)
Batch  75/537: Loss=0.5589 (C:0.5589, R:0.0105)
Batch 100/537: Loss=0.5448 (C:0.5448, R:0.0105)
Batch 125/537: Loss=0.5695 (C:0.5695, R:0.0105)
Batch 150/537: Loss=0.5653 (C:0.5653, R:0.0105)
Batch 175/537: Loss=0.5856 (C:0.5856, R:0.0105)
Batch 200/537: Loss=0.5494 (C:0.5494, R:0.0105)
Batch 225/537: Loss=0.5764 (C:0.5764, R:0.0105)
Batch 250/537: Loss=0.5779 (C:0.5779, R:0.0105)
Batch 275/537: Loss=0.5433 (C:0.5433, R:0.0105)
Batch 300/537: Loss=0.5987 (C:0.5987, R:0.0105)
Batch 325/537: Loss=0.6026 (C:0.6026, R:0.0105)
Batch 350/537: Loss=0.5578 (C:0.5578, R:0.0105)
Batch 375/537: Loss=0.5563 (C:0.5563, R:0.0105)
Batch 400/537: Loss=0.5907 (C:0.5907, R:0.0105)
Batch 425/537: Loss=0.5715 (C:0.5715, R:0.0105)
Batch 450/537: Loss=0.5437 (C:0.5437, R:0.0105)
Batch 475/537: Loss=0.5634 (C:0.5634, R:0.0105)
Batch 500/537: Loss=0.5737 (C:0.5737, R:0.0106)
Batch 525/537: Loss=0.5677 (C:0.5677, R:0.0105)

============================================================
Epoch 64/300 completed in 28.5s
Train: Loss=0.5641 (C:0.5641, R:0.0105) Ratio=4.90x
Val:   Loss=0.7355 (C:0.7355, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 65
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.325 ± 0.576
    Neg distances: 2.669 ± 1.102
    Separation ratio: 8.20x
    Gap: -4.631
    ✅ Excellent global separation!

Epoch 65 Training
----------------------------------------
Batch   0/537: Loss=0.5366 (C:0.5366, R:0.0106)
Batch  25/537: Loss=0.5610 (C:0.5610, R:0.0105)
Batch  50/537: Loss=0.5880 (C:0.5880, R:0.0105)
Batch  75/537: Loss=0.5581 (C:0.5581, R:0.0105)
Batch 100/537: Loss=0.5416 (C:0.5416, R:0.0105)
Batch 125/537: Loss=0.5466 (C:0.5466, R:0.0105)
Batch 150/537: Loss=0.6054 (C:0.6054, R:0.0105)
Batch 175/537: Loss=0.5566 (C:0.5566, R:0.0106)
Batch 200/537: Loss=0.5794 (C:0.5794, R:0.0105)
Batch 225/537: Loss=0.5854 (C:0.5854, R:0.0105)
Batch 250/537: Loss=0.5617 (C:0.5617, R:0.0105)
Batch 275/537: Loss=0.5335 (C:0.5335, R:0.0105)
Batch 300/537: Loss=0.5456 (C:0.5456, R:0.0105)
Batch 325/537: Loss=0.6040 (C:0.6040, R:0.0105)
Batch 350/537: Loss=0.5859 (C:0.5859, R:0.0105)
Batch 375/537: Loss=0.5735 (C:0.5735, R:0.0105)
Batch 400/537: Loss=0.5282 (C:0.5282, R:0.0105)
Batch 425/537: Loss=0.5575 (C:0.5575, R:0.0105)
Batch 450/537: Loss=0.5868 (C:0.5868, R:0.0106)
Batch 475/537: Loss=0.5334 (C:0.5334, R:0.0105)
Batch 500/537: Loss=0.5734 (C:0.5734, R:0.0105)
Batch 525/537: Loss=0.5529 (C:0.5529, R:0.0105)

============================================================
Epoch 65/300 completed in 27.7s
Train: Loss=0.5592 (C:0.5592, R:0.0105) Ratio=4.99x
Val:   Loss=0.7223 (C:0.7223, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.7223)
============================================================

🌍 Updating global dataset at epoch 66
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.324 ± 0.573
    Neg distances: 2.692 ± 1.111
    Separation ratio: 8.31x
    Gap: -4.703
    ✅ Excellent global separation!

Epoch 66 Training
----------------------------------------
Batch   0/537: Loss=0.5602 (C:0.5602, R:0.0105)
Batch  25/537: Loss=0.5173 (C:0.5173, R:0.0105)
Batch  50/537: Loss=0.5683 (C:0.5683, R:0.0106)
Batch  75/537: Loss=0.5414 (C:0.5414, R:0.0105)
Batch 100/537: Loss=0.5107 (C:0.5107, R:0.0105)
Batch 125/537: Loss=0.5712 (C:0.5712, R:0.0105)
Batch 150/537: Loss=0.5497 (C:0.5497, R:0.0105)
Batch 175/537: Loss=0.5586 (C:0.5586, R:0.0105)
Batch 200/537: Loss=0.5566 (C:0.5566, R:0.0105)
Batch 225/537: Loss=0.5625 (C:0.5625, R:0.0105)
Batch 250/537: Loss=0.5884 (C:0.5884, R:0.0105)
Batch 275/537: Loss=0.5687 (C:0.5687, R:0.0106)
Batch 300/537: Loss=0.5699 (C:0.5699, R:0.0105)
Batch 325/537: Loss=0.5435 (C:0.5435, R:0.0105)
Batch 350/537: Loss=0.5622 (C:0.5622, R:0.0105)
Batch 375/537: Loss=0.5701 (C:0.5701, R:0.0105)
Batch 400/537: Loss=0.5468 (C:0.5468, R:0.0105)
Batch 425/537: Loss=0.5359 (C:0.5359, R:0.0105)
Batch 450/537: Loss=0.5857 (C:0.5857, R:0.0105)
Batch 475/537: Loss=0.5587 (C:0.5587, R:0.0105)
Batch 500/537: Loss=0.5531 (C:0.5531, R:0.0105)
Batch 525/537: Loss=0.6153 (C:0.6153, R:0.0105)

============================================================
Epoch 66/300 completed in 28.8s
Train: Loss=0.5572 (C:0.5572, R:0.0105) Ratio=5.02x
Val:   Loss=0.7282 (C:0.7282, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 67
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.335 ± 0.588
    Neg distances: 2.666 ± 1.112
    Separation ratio: 7.96x
    Gap: -4.587
    ✅ Excellent global separation!

Epoch 67 Training
----------------------------------------
Batch   0/537: Loss=0.5224 (C:0.5224, R:0.0105)
Batch  25/537: Loss=0.5379 (C:0.5379, R:0.0105)
Batch  50/537: Loss=0.5398 (C:0.5398, R:0.0105)
Batch  75/537: Loss=0.5538 (C:0.5538, R:0.0105)
Batch 100/537: Loss=0.5570 (C:0.5570, R:0.0105)
Batch 125/537: Loss=0.5434 (C:0.5434, R:0.0105)
Batch 150/537: Loss=0.5552 (C:0.5552, R:0.0105)
Batch 175/537: Loss=0.5689 (C:0.5689, R:0.0105)
Batch 200/537: Loss=0.5374 (C:0.5374, R:0.0105)
Batch 225/537: Loss=0.5505 (C:0.5505, R:0.0105)
Batch 250/537: Loss=0.5446 (C:0.5446, R:0.0105)
Batch 275/537: Loss=0.5473 (C:0.5473, R:0.0105)
Batch 300/537: Loss=0.5575 (C:0.5575, R:0.0105)
Batch 325/537: Loss=0.5570 (C:0.5570, R:0.0105)
Batch 350/537: Loss=0.5934 (C:0.5934, R:0.0105)
Batch 375/537: Loss=0.5718 (C:0.5718, R:0.0105)
Batch 400/537: Loss=0.6016 (C:0.6016, R:0.0105)
Batch 425/537: Loss=0.5735 (C:0.5735, R:0.0105)
Batch 450/537: Loss=0.5567 (C:0.5567, R:0.0106)
Batch 475/537: Loss=0.5661 (C:0.5661, R:0.0105)
Batch 500/537: Loss=0.5700 (C:0.5700, R:0.0105)
Batch 525/537: Loss=0.5677 (C:0.5677, R:0.0105)

============================================================
Epoch 67/300 completed in 28.0s
Train: Loss=0.5640 (C:0.5640, R:0.0105) Ratio=5.10x
Val:   Loss=0.7296 (C:0.7296, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 68
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.334 ± 0.571
    Neg distances: 2.667 ± 1.106
    Separation ratio: 7.99x
    Gap: -4.579
    ✅ Excellent global separation!

Epoch 68 Training
----------------------------------------
Batch   0/537: Loss=0.5669 (C:0.5669, R:0.0105)
Batch  25/537: Loss=0.5779 (C:0.5779, R:0.0105)
Batch  50/537: Loss=0.5616 (C:0.5616, R:0.0105)
Batch  75/537: Loss=0.5517 (C:0.5517, R:0.0105)
Batch 100/537: Loss=0.5550 (C:0.5550, R:0.0105)
Batch 125/537: Loss=0.5571 (C:0.5571, R:0.0105)
Batch 150/537: Loss=0.5574 (C:0.5574, R:0.0105)
Batch 175/537: Loss=0.5548 (C:0.5548, R:0.0105)
Batch 200/537: Loss=0.5581 (C:0.5581, R:0.0105)
Batch 225/537: Loss=0.6029 (C:0.6029, R:0.0105)
Batch 250/537: Loss=0.5821 (C:0.5821, R:0.0105)
Batch 275/537: Loss=0.5825 (C:0.5825, R:0.0105)
Batch 300/537: Loss=0.5689 (C:0.5689, R:0.0105)
Batch 325/537: Loss=0.5506 (C:0.5506, R:0.0105)
Batch 350/537: Loss=0.5714 (C:0.5714, R:0.0105)
Batch 375/537: Loss=0.5678 (C:0.5678, R:0.0105)
Batch 400/537: Loss=0.5949 (C:0.5949, R:0.0105)
Batch 425/537: Loss=0.6003 (C:0.6003, R:0.0106)
Batch 450/537: Loss=0.5602 (C:0.5602, R:0.0105)
Batch 475/537: Loss=0.5924 (C:0.5924, R:0.0105)
Batch 500/537: Loss=0.5586 (C:0.5586, R:0.0106)
Batch 525/537: Loss=0.5628 (C:0.5628, R:0.0105)

============================================================
Epoch 68/300 completed in 28.3s
Train: Loss=0.5620 (C:0.5620, R:0.0105) Ratio=5.05x
Val:   Loss=0.7358 (C:0.7358, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 69
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.325 ± 0.561
    Neg distances: 2.651 ± 1.098
    Separation ratio: 8.17x
    Gap: -4.501
    ✅ Excellent global separation!

Epoch 69 Training
----------------------------------------
Batch   0/537: Loss=0.5570 (C:0.5570, R:0.0105)
Batch  25/537: Loss=0.5497 (C:0.5497, R:0.0105)
Batch  50/537: Loss=0.5670 (C:0.5670, R:0.0105)
Batch  75/537: Loss=0.5686 (C:0.5686, R:0.0105)
Batch 100/537: Loss=0.5857 (C:0.5857, R:0.0105)
Batch 125/537: Loss=0.5644 (C:0.5644, R:0.0105)
Batch 150/537: Loss=0.5822 (C:0.5822, R:0.0105)
Batch 175/537: Loss=0.5609 (C:0.5609, R:0.0105)
Batch 200/537: Loss=0.5953 (C:0.5953, R:0.0105)
Batch 225/537: Loss=0.5896 (C:0.5896, R:0.0105)
Batch 250/537: Loss=0.5387 (C:0.5387, R:0.0105)
Batch 275/537: Loss=0.5412 (C:0.5412, R:0.0106)
Batch 300/537: Loss=0.5544 (C:0.5544, R:0.0105)
Batch 325/537: Loss=0.5030 (C:0.5030, R:0.0105)
Batch 350/537: Loss=0.5709 (C:0.5709, R:0.0105)
Batch 375/537: Loss=0.5600 (C:0.5600, R:0.0105)
Batch 400/537: Loss=0.5345 (C:0.5345, R:0.0106)
Batch 425/537: Loss=0.5691 (C:0.5691, R:0.0105)
Batch 450/537: Loss=0.5725 (C:0.5725, R:0.0105)
Batch 475/537: Loss=0.5826 (C:0.5826, R:0.0105)
Batch 500/537: Loss=0.5603 (C:0.5603, R:0.0105)
Batch 525/537: Loss=0.5653 (C:0.5653, R:0.0105)

============================================================
Epoch 69/300 completed in 27.9s
Train: Loss=0.5583 (C:0.5583, R:0.0105) Ratio=5.01x
Val:   Loss=0.7333 (C:0.7333, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
No improvement for 4 epochs
============================================================

🌍 Updating global dataset at epoch 70
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.327 ± 0.567
    Neg distances: 2.689 ± 1.114
    Separation ratio: 8.23x
    Gap: -4.603
    ✅ Excellent global separation!

Epoch 70 Training
----------------------------------------
Batch   0/537: Loss=0.5321 (C:0.5321, R:0.0105)
Batch  25/537: Loss=0.5164 (C:0.5164, R:0.0105)
Batch  50/537: Loss=0.5574 (C:0.5574, R:0.0105)
Batch  75/537: Loss=0.5476 (C:0.5476, R:0.0105)
Batch 100/537: Loss=0.5625 (C:0.5625, R:0.0105)
Batch 125/537: Loss=0.5326 (C:0.5326, R:0.0105)
Batch 150/537: Loss=0.5664 (C:0.5664, R:0.0106)
Batch 175/537: Loss=0.6021 (C:0.6021, R:0.0105)
Batch 200/537: Loss=0.5632 (C:0.5632, R:0.0105)
Batch 225/537: Loss=0.5508 (C:0.5508, R:0.0105)
Batch 250/537: Loss=0.5437 (C:0.5437, R:0.0105)
Batch 275/537: Loss=0.5129 (C:0.5129, R:0.0105)
Batch 300/537: Loss=0.5748 (C:0.5748, R:0.0105)
Batch 325/537: Loss=0.5880 (C:0.5880, R:0.0105)
Batch 350/537: Loss=0.5535 (C:0.5535, R:0.0105)
Batch 375/537: Loss=0.5782 (C:0.5782, R:0.0105)
Batch 400/537: Loss=0.5929 (C:0.5929, R:0.0105)
Batch 425/537: Loss=0.5532 (C:0.5532, R:0.0105)
Batch 450/537: Loss=0.5759 (C:0.5759, R:0.0105)
Batch 475/537: Loss=0.5699 (C:0.5699, R:0.0105)
Batch 500/537: Loss=0.5468 (C:0.5468, R:0.0105)
Batch 525/537: Loss=0.5500 (C:0.5500, R:0.0105)

============================================================
Epoch 70/300 completed in 28.3s
Train: Loss=0.5545 (C:0.5545, R:0.0105) Ratio=5.03x
Val:   Loss=0.7322 (C:0.7322, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 5 epochs
============================================================

🌍 Updating global dataset at epoch 71
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.325 ± 0.586
    Neg distances: 2.691 ± 1.113
    Separation ratio: 8.28x
    Gap: -4.630
    ✅ Excellent global separation!

Epoch 71 Training
----------------------------------------
Batch   0/537: Loss=0.5115 (C:0.5115, R:0.0105)
Batch  25/537: Loss=0.5484 (C:0.5484, R:0.0105)
Batch  50/537: Loss=0.5482 (C:0.5482, R:0.0105)
Batch  75/537: Loss=0.5412 (C:0.5412, R:0.0105)
Batch 100/537: Loss=0.6029 (C:0.6029, R:0.0105)
Batch 125/537: Loss=0.5483 (C:0.5483, R:0.0105)
Batch 150/537: Loss=0.5366 (C:0.5366, R:0.0105)
Batch 175/537: Loss=0.5326 (C:0.5326, R:0.0106)
Batch 200/537: Loss=0.5361 (C:0.5361, R:0.0105)
Batch 225/537: Loss=0.5471 (C:0.5471, R:0.0105)
Batch 250/537: Loss=0.5416 (C:0.5416, R:0.0105)
Batch 275/537: Loss=0.5356 (C:0.5356, R:0.0105)
Batch 300/537: Loss=0.5801 (C:0.5801, R:0.0105)
Batch 325/537: Loss=0.5336 (C:0.5336, R:0.0105)
Batch 350/537: Loss=0.5476 (C:0.5476, R:0.0105)
Batch 375/537: Loss=0.5603 (C:0.5603, R:0.0105)
Batch 400/537: Loss=0.5697 (C:0.5697, R:0.0105)
Batch 425/537: Loss=0.5422 (C:0.5422, R:0.0105)
Batch 450/537: Loss=0.5653 (C:0.5653, R:0.0105)
Batch 475/537: Loss=0.5515 (C:0.5515, R:0.0105)
Batch 500/537: Loss=0.5058 (C:0.5058, R:0.0105)
Batch 525/537: Loss=0.5701 (C:0.5701, R:0.0106)

============================================================
Epoch 71/300 completed in 27.5s
Train: Loss=0.5515 (C:0.5515, R:0.0105) Ratio=5.09x
Val:   Loss=0.7203 (C:0.7203, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.7203)
============================================================

🌍 Updating global dataset at epoch 72
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.308 ± 0.557
    Neg distances: 2.698 ± 1.106
    Separation ratio: 8.75x
    Gap: -4.610
    ✅ Excellent global separation!

Epoch 72 Training
----------------------------------------
Batch   0/537: Loss=0.5288 (C:0.5288, R:0.0106)
Batch  25/537: Loss=0.5064 (C:0.5064, R:0.0105)
Batch  50/537: Loss=0.5144 (C:0.5144, R:0.0105)
Batch  75/537: Loss=0.5057 (C:0.5057, R:0.0105)
Batch 100/537: Loss=0.5516 (C:0.5516, R:0.0105)
Batch 125/537: Loss=0.5361 (C:0.5361, R:0.0105)
Batch 150/537: Loss=0.5169 (C:0.5169, R:0.0105)
Batch 175/537: Loss=0.4859 (C:0.4859, R:0.0105)
Batch 200/537: Loss=0.4982 (C:0.4982, R:0.0105)
Batch 225/537: Loss=0.5501 (C:0.5501, R:0.0105)
Batch 250/537: Loss=0.5284 (C:0.5284, R:0.0105)
Batch 275/537: Loss=0.5299 (C:0.5299, R:0.0105)
Batch 300/537: Loss=0.5358 (C:0.5358, R:0.0105)
Batch 325/537: Loss=0.5495 (C:0.5495, R:0.0105)
Batch 350/537: Loss=0.5132 (C:0.5132, R:0.0105)
Batch 375/537: Loss=0.5392 (C:0.5392, R:0.0105)
Batch 400/537: Loss=0.5127 (C:0.5127, R:0.0105)
Batch 425/537: Loss=0.5210 (C:0.5210, R:0.0105)
Batch 450/537: Loss=0.5755 (C:0.5755, R:0.0105)
Batch 475/537: Loss=0.5390 (C:0.5390, R:0.0105)
Batch 500/537: Loss=0.5092 (C:0.5092, R:0.0105)
Batch 525/537: Loss=0.5419 (C:0.5419, R:0.0105)

============================================================
Epoch 72/300 completed in 28.4s
Train: Loss=0.5378 (C:0.5378, R:0.0105) Ratio=5.18x
Val:   Loss=0.7111 (C:0.7111, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.7111)
============================================================

🌍 Updating global dataset at epoch 73
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.297 ± 0.544
    Neg distances: 2.707 ± 1.103
    Separation ratio: 9.11x
    Gap: -4.606
    ✅ Excellent global separation!

Epoch 73 Training
----------------------------------------
Batch   0/537: Loss=0.5211 (C:0.5211, R:0.0105)
Batch  25/537: Loss=0.5131 (C:0.5131, R:0.0105)
Batch  50/537: Loss=0.4986 (C:0.4986, R:0.0105)
Batch  75/537: Loss=0.5413 (C:0.5413, R:0.0105)
Batch 100/537: Loss=0.5423 (C:0.5423, R:0.0105)
Batch 125/537: Loss=0.5365 (C:0.5365, R:0.0105)
Batch 150/537: Loss=0.5306 (C:0.5306, R:0.0106)
Batch 175/537: Loss=0.5498 (C:0.5498, R:0.0105)
Batch 200/537: Loss=0.5276 (C:0.5276, R:0.0105)
Batch 225/537: Loss=0.5094 (C:0.5094, R:0.0105)
Batch 250/537: Loss=0.5241 (C:0.5241, R:0.0105)
Batch 275/537: Loss=0.5559 (C:0.5559, R:0.0105)
Batch 300/537: Loss=0.5632 (C:0.5632, R:0.0105)
Batch 325/537: Loss=0.5293 (C:0.5293, R:0.0105)
Batch 350/537: Loss=0.5357 (C:0.5357, R:0.0105)
Batch 375/537: Loss=0.5593 (C:0.5593, R:0.0105)
Batch 400/537: Loss=0.5244 (C:0.5244, R:0.0105)
Batch 425/537: Loss=0.5211 (C:0.5211, R:0.0105)
Batch 450/537: Loss=0.5406 (C:0.5406, R:0.0105)
Batch 475/537: Loss=0.5420 (C:0.5420, R:0.0105)
Batch 500/537: Loss=0.5410 (C:0.5410, R:0.0105)
Batch 525/537: Loss=0.5900 (C:0.5900, R:0.0105)

============================================================
Epoch 73/300 completed in 28.4s
Train: Loss=0.5289 (C:0.5289, R:0.0105) Ratio=5.06x
Val:   Loss=0.7064 (C:0.7064, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.7064)
============================================================

🌍 Updating global dataset at epoch 74
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.308 ± 0.552
    Neg distances: 2.722 ± 1.113
    Separation ratio: 8.84x
    Gap: -4.637
    ✅ Excellent global separation!

Epoch 74 Training
----------------------------------------
Batch   0/537: Loss=0.5313 (C:0.5313, R:0.0105)
Batch  25/537: Loss=0.5591 (C:0.5591, R:0.0105)
Batch  50/537: Loss=0.4959 (C:0.4959, R:0.0105)
Batch  75/537: Loss=0.5230 (C:0.5230, R:0.0105)
Batch 100/537: Loss=0.5128 (C:0.5128, R:0.0105)
Batch 125/537: Loss=0.5280 (C:0.5280, R:0.0105)
Batch 150/537: Loss=0.5310 (C:0.5310, R:0.0105)
Batch 175/537: Loss=0.5282 (C:0.5282, R:0.0105)
Batch 200/537: Loss=0.5442 (C:0.5442, R:0.0105)
Batch 225/537: Loss=0.5609 (C:0.5609, R:0.0105)
Batch 250/537: Loss=0.5401 (C:0.5401, R:0.0105)
Batch 275/537: Loss=0.5227 (C:0.5227, R:0.0105)
Batch 300/537: Loss=0.5200 (C:0.5200, R:0.0105)
Batch 325/537: Loss=0.4996 (C:0.4996, R:0.0105)
Batch 350/537: Loss=0.5483 (C:0.5483, R:0.0105)
Batch 375/537: Loss=0.5633 (C:0.5633, R:0.0105)
Batch 400/537: Loss=0.5216 (C:0.5216, R:0.0105)
Batch 425/537: Loss=0.5496 (C:0.5496, R:0.0105)
Batch 450/537: Loss=0.5195 (C:0.5195, R:0.0105)
Batch 475/537: Loss=0.5170 (C:0.5170, R:0.0105)
Batch 500/537: Loss=0.5755 (C:0.5755, R:0.0105)
Batch 525/537: Loss=0.5517 (C:0.5517, R:0.0105)

============================================================
Epoch 74/300 completed in 27.8s
Train: Loss=0.5340 (C:0.5340, R:0.0105) Ratio=5.19x
Val:   Loss=0.7222 (C:0.7222, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 75
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.306 ± 0.565
    Neg distances: 2.712 ± 1.106
    Separation ratio: 8.87x
    Gap: -4.704
    ✅ Excellent global separation!

Epoch 75 Training
----------------------------------------
Batch   0/537: Loss=0.5059 (C:0.5059, R:0.0105)
Batch  25/537: Loss=0.5443 (C:0.5443, R:0.0105)
Batch  50/537: Loss=0.5265 (C:0.5265, R:0.0105)
Batch  75/537: Loss=0.5038 (C:0.5038, R:0.0105)
Batch 100/537: Loss=0.5265 (C:0.5265, R:0.0105)
Batch 125/537: Loss=0.5091 (C:0.5091, R:0.0105)
Batch 150/537: Loss=0.5406 (C:0.5406, R:0.0105)
Batch 175/537: Loss=0.5262 (C:0.5262, R:0.0105)
Batch 200/537: Loss=0.5423 (C:0.5423, R:0.0105)
Batch 225/537: Loss=0.5015 (C:0.5015, R:0.0105)
Batch 250/537: Loss=0.5304 (C:0.5304, R:0.0105)
Batch 275/537: Loss=0.5276 (C:0.5276, R:0.0105)
Batch 300/537: Loss=0.5057 (C:0.5057, R:0.0105)
Batch 325/537: Loss=0.5106 (C:0.5106, R:0.0105)
Batch 350/537: Loss=0.5087 (C:0.5087, R:0.0105)
Batch 375/537: Loss=0.5508 (C:0.5508, R:0.0105)
Batch 400/537: Loss=0.5265 (C:0.5265, R:0.0105)
Batch 425/537: Loss=0.5214 (C:0.5214, R:0.0105)
Batch 450/537: Loss=0.5394 (C:0.5394, R:0.0106)
Batch 475/537: Loss=0.5416 (C:0.5416, R:0.0105)
Batch 500/537: Loss=0.5484 (C:0.5484, R:0.0105)
Batch 525/537: Loss=0.5522 (C:0.5522, R:0.0105)

============================================================
Epoch 75/300 completed in 28.1s
Train: Loss=0.5297 (C:0.5297, R:0.0105) Ratio=5.23x
Val:   Loss=0.7086 (C:0.7086, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 76
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.311 ± 0.557
    Neg distances: 2.717 ± 1.114
    Separation ratio: 8.73x
    Gap: -4.713
    ✅ Excellent global separation!

Epoch 76 Training
----------------------------------------
Batch   0/537: Loss=0.5630 (C:0.5630, R:0.0105)
Batch  25/537: Loss=0.5415 (C:0.5415, R:0.0105)
Batch  50/537: Loss=0.5031 (C:0.5031, R:0.0105)
Batch  75/537: Loss=0.5189 (C:0.5189, R:0.0105)
Batch 100/537: Loss=0.5237 (C:0.5237, R:0.0105)
Batch 125/537: Loss=0.5632 (C:0.5632, R:0.0105)
Batch 150/537: Loss=0.5296 (C:0.5296, R:0.0106)
Batch 175/537: Loss=0.5241 (C:0.5241, R:0.0105)
Batch 200/537: Loss=0.5101 (C:0.5101, R:0.0105)
Batch 225/537: Loss=0.5243 (C:0.5243, R:0.0106)
Batch 250/537: Loss=0.5488 (C:0.5488, R:0.0105)
Batch 275/537: Loss=0.5539 (C:0.5539, R:0.0105)
Batch 300/537: Loss=0.5223 (C:0.5223, R:0.0105)
Batch 325/537: Loss=0.5455 (C:0.5455, R:0.0105)
Batch 350/537: Loss=0.5360 (C:0.5360, R:0.0105)
Batch 375/537: Loss=0.5271 (C:0.5271, R:0.0105)
Batch 400/537: Loss=0.5666 (C:0.5666, R:0.0105)
Batch 425/537: Loss=0.5069 (C:0.5069, R:0.0105)
Batch 450/537: Loss=0.5181 (C:0.5181, R:0.0105)
Batch 475/537: Loss=0.5461 (C:0.5461, R:0.0106)
Batch 500/537: Loss=0.5354 (C:0.5354, R:0.0105)
Batch 525/537: Loss=0.5406 (C:0.5406, R:0.0105)

============================================================
Epoch 76/300 completed in 27.9s
Train: Loss=0.5344 (C:0.5344, R:0.0105) Ratio=5.21x
Val:   Loss=0.7252 (C:0.7252, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 77
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.295 ± 0.534
    Neg distances: 2.740 ± 1.113
    Separation ratio: 9.28x
    Gap: -4.657
    ✅ Excellent global separation!

Epoch 77 Training
----------------------------------------
Batch   0/537: Loss=0.5153 (C:0.5153, R:0.0106)
Batch  25/537: Loss=0.5087 (C:0.5087, R:0.0105)
Batch  50/537: Loss=0.5095 (C:0.5095, R:0.0105)
Batch  75/537: Loss=0.5511 (C:0.5511, R:0.0105)
Batch 100/537: Loss=0.5244 (C:0.5244, R:0.0105)
Batch 125/537: Loss=0.5004 (C:0.5004, R:0.0105)
Batch 150/537: Loss=0.5515 (C:0.5515, R:0.0105)
Batch 175/537: Loss=0.5068 (C:0.5068, R:0.0105)
Batch 200/537: Loss=0.5343 (C:0.5343, R:0.0105)
Batch 225/537: Loss=0.5397 (C:0.5397, R:0.0105)
Batch 250/537: Loss=0.5504 (C:0.5504, R:0.0105)
Batch 275/537: Loss=0.5098 (C:0.5098, R:0.0105)
Batch 300/537: Loss=0.5168 (C:0.5168, R:0.0105)
Batch 325/537: Loss=0.5169 (C:0.5169, R:0.0105)
Batch 350/537: Loss=0.5021 (C:0.5021, R:0.0105)
Batch 375/537: Loss=0.5166 (C:0.5166, R:0.0105)
Batch 400/537: Loss=0.5432 (C:0.5432, R:0.0105)
Batch 425/537: Loss=0.5279 (C:0.5279, R:0.0105)
Batch 450/537: Loss=0.4888 (C:0.4888, R:0.0105)
Batch 475/537: Loss=0.5052 (C:0.5052, R:0.0105)
Batch 500/537: Loss=0.5094 (C:0.5094, R:0.0104)
Batch 525/537: Loss=0.5117 (C:0.5117, R:0.0105)

============================================================
Epoch 77/300 completed in 27.8s
Train: Loss=0.5192 (C:0.5192, R:0.0105) Ratio=5.22x
Val:   Loss=0.7048 (C:0.7048, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.7048)
============================================================

🌍 Updating global dataset at epoch 78
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.301 ± 0.550
    Neg distances: 2.747 ± 1.120
    Separation ratio: 9.13x
    Gap: -4.689
    ✅ Excellent global separation!

Epoch 78 Training
----------------------------------------
Batch   0/537: Loss=0.5038 (C:0.5038, R:0.0105)
Batch  25/537: Loss=0.4973 (C:0.4973, R:0.0106)
Batch  50/537: Loss=0.5200 (C:0.5200, R:0.0105)
Batch  75/537: Loss=0.4960 (C:0.4960, R:0.0105)
Batch 100/537: Loss=0.5845 (C:0.5845, R:0.0105)
Batch 125/537: Loss=0.4838 (C:0.4838, R:0.0105)
Batch 150/537: Loss=0.5231 (C:0.5231, R:0.0105)
Batch 175/537: Loss=0.4956 (C:0.4956, R:0.0105)
Batch 200/537: Loss=0.5040 (C:0.5040, R:0.0105)
Batch 225/537: Loss=0.5499 (C:0.5499, R:0.0105)
Batch 250/537: Loss=0.4831 (C:0.4831, R:0.0105)
Batch 275/537: Loss=0.5108 (C:0.5108, R:0.0105)
Batch 300/537: Loss=0.5040 (C:0.5040, R:0.0105)
Batch 325/537: Loss=0.5259 (C:0.5259, R:0.0105)
Batch 350/537: Loss=0.5346 (C:0.5346, R:0.0105)
Batch 375/537: Loss=0.5344 (C:0.5344, R:0.0105)
Batch 400/537: Loss=0.5225 (C:0.5225, R:0.0105)
Batch 425/537: Loss=0.5124 (C:0.5124, R:0.0105)
Batch 450/537: Loss=0.5698 (C:0.5698, R:0.0105)
Batch 475/537: Loss=0.5057 (C:0.5057, R:0.0106)
Batch 500/537: Loss=0.5157 (C:0.5157, R:0.0105)
Batch 525/537: Loss=0.5409 (C:0.5409, R:0.0105)

============================================================
Epoch 78/300 completed in 27.6s
Train: Loss=0.5222 (C:0.5222, R:0.0105) Ratio=5.31x
Val:   Loss=0.7070 (C:0.7070, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 79
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.315 ± 0.571
    Neg distances: 2.730 ± 1.123
    Separation ratio: 8.66x
    Gap: -4.716
    ✅ Excellent global separation!

Epoch 79 Training
----------------------------------------
Batch   0/537: Loss=0.5009 (C:0.5009, R:0.0105)
Batch  25/537: Loss=0.5295 (C:0.5295, R:0.0106)
Batch  50/537: Loss=0.5736 (C:0.5736, R:0.0105)
Batch  75/537: Loss=0.5427 (C:0.5427, R:0.0105)
Batch 100/537: Loss=0.5388 (C:0.5388, R:0.0105)
Batch 125/537: Loss=0.5580 (C:0.5580, R:0.0105)
Batch 150/537: Loss=0.5003 (C:0.5003, R:0.0105)
Batch 175/537: Loss=0.5190 (C:0.5190, R:0.0105)
Batch 200/537: Loss=0.5704 (C:0.5704, R:0.0105)
Batch 225/537: Loss=0.5826 (C:0.5826, R:0.0105)
Batch 250/537: Loss=0.5065 (C:0.5065, R:0.0105)
Batch 275/537: Loss=0.5856 (C:0.5856, R:0.0105)
Batch 300/537: Loss=0.5233 (C:0.5233, R:0.0105)
Batch 325/537: Loss=0.5297 (C:0.5297, R:0.0105)
Batch 350/537: Loss=0.5267 (C:0.5267, R:0.0105)
Batch 375/537: Loss=0.5264 (C:0.5264, R:0.0105)
Batch 400/537: Loss=0.5127 (C:0.5127, R:0.0105)
Batch 425/537: Loss=0.5576 (C:0.5576, R:0.0106)
Batch 450/537: Loss=0.5159 (C:0.5159, R:0.0105)
Batch 475/537: Loss=0.5741 (C:0.5741, R:0.0105)
Batch 500/537: Loss=0.5799 (C:0.5799, R:0.0105)
Batch 525/537: Loss=0.5011 (C:0.5011, R:0.0105)

============================================================
Epoch 79/300 completed in 27.7s
Train: Loss=0.5328 (C:0.5328, R:0.0105) Ratio=5.19x
Val:   Loss=0.7148 (C:0.7148, R:0.0104) Ratio=3.03x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 80
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.306 ± 0.548
    Neg distances: 2.714 ± 1.113
    Separation ratio: 8.88x
    Gap: -4.605
    ✅ Excellent global separation!

Epoch 80 Training
----------------------------------------
Batch   0/537: Loss=0.4601 (C:0.4601, R:0.0105)
Batch  25/537: Loss=0.5307 (C:0.5307, R:0.0105)
Batch  50/537: Loss=0.4966 (C:0.4966, R:0.0105)
Batch  75/537: Loss=0.5070 (C:0.5070, R:0.0105)
Batch 100/537: Loss=0.5334 (C:0.5334, R:0.0105)
Batch 125/537: Loss=0.5203 (C:0.5203, R:0.0105)
Batch 150/537: Loss=0.4949 (C:0.4949, R:0.0105)
Batch 175/537: Loss=0.5364 (C:0.5364, R:0.0105)
Batch 200/537: Loss=0.5436 (C:0.5436, R:0.0105)
Batch 225/537: Loss=0.5160 (C:0.5160, R:0.0105)
Batch 250/537: Loss=0.5806 (C:0.5806, R:0.0105)
Batch 275/537: Loss=0.5188 (C:0.5188, R:0.0105)
Batch 300/537: Loss=0.5371 (C:0.5371, R:0.0105)
Batch 325/537: Loss=0.5108 (C:0.5108, R:0.0105)
Batch 350/537: Loss=0.5299 (C:0.5299, R:0.0105)
Batch 375/537: Loss=0.5354 (C:0.5354, R:0.0104)
Batch 400/537: Loss=0.5099 (C:0.5099, R:0.0105)
Batch 425/537: Loss=0.5066 (C:0.5066, R:0.0105)
Batch 450/537: Loss=0.5240 (C:0.5240, R:0.0105)
Batch 475/537: Loss=0.5288 (C:0.5288, R:0.0105)
Batch 500/537: Loss=0.5599 (C:0.5599, R:0.0105)
Batch 525/537: Loss=0.5433 (C:0.5433, R:0.0105)

============================================================
Epoch 80/300 completed in 28.0s
Train: Loss=0.5258 (C:0.5258, R:0.0105) Ratio=5.32x
Val:   Loss=0.7228 (C:0.7228, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 3 epochs
Checkpoint saved at epoch 80
============================================================

🌍 Updating global dataset at epoch 81
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.305 ± 0.569
    Neg distances: 2.734 ± 1.117
    Separation ratio: 8.97x
    Gap: -4.641
    ✅ Excellent global separation!

Epoch 81 Training
----------------------------------------
Batch   0/537: Loss=0.5152 (C:0.5152, R:0.0105)
Batch  25/537: Loss=0.5084 (C:0.5084, R:0.0105)
Batch  50/537: Loss=0.5112 (C:0.5112, R:0.0105)
Batch  75/537: Loss=0.5544 (C:0.5544, R:0.0105)
Batch 100/537: Loss=0.4607 (C:0.4607, R:0.0105)
Batch 125/537: Loss=0.4831 (C:0.4831, R:0.0105)
Batch 150/537: Loss=0.5159 (C:0.5159, R:0.0105)
Batch 175/537: Loss=0.5216 (C:0.5216, R:0.0106)
Batch 200/537: Loss=0.4553 (C:0.4553, R:0.0105)
Batch 225/537: Loss=0.5430 (C:0.5430, R:0.0106)
Batch 250/537: Loss=0.5342 (C:0.5342, R:0.0105)
Batch 275/537: Loss=0.5219 (C:0.5219, R:0.0105)
Batch 300/537: Loss=0.5443 (C:0.5443, R:0.0105)
Batch 325/537: Loss=0.5119 (C:0.5119, R:0.0105)
Batch 350/537: Loss=0.4884 (C:0.4884, R:0.0105)
Batch 375/537: Loss=0.5286 (C:0.5286, R:0.0105)
Batch 400/537: Loss=0.5394 (C:0.5394, R:0.0105)
Batch 425/537: Loss=0.5568 (C:0.5568, R:0.0105)
Batch 450/537: Loss=0.5388 (C:0.5388, R:0.0105)
Batch 475/537: Loss=0.5537 (C:0.5537, R:0.0105)
Batch 500/537: Loss=0.5280 (C:0.5280, R:0.0105)
Batch 525/537: Loss=0.5189 (C:0.5189, R:0.0105)

============================================================
Epoch 81/300 completed in 27.8s
Train: Loss=0.5229 (C:0.5229, R:0.0105) Ratio=5.30x
Val:   Loss=0.7069 (C:0.7069, R:0.0104) Ratio=3.03x
Reconstruction weight: 0.300
No improvement for 4 epochs
============================================================

🌍 Updating global dataset at epoch 82
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.293 ± 0.552
    Neg distances: 2.737 ± 1.110
    Separation ratio: 9.33x
    Gap: -4.683
    ✅ Excellent global separation!

Epoch 82 Training
----------------------------------------
Batch   0/537: Loss=0.5112 (C:0.5112, R:0.0105)
Batch  25/537: Loss=0.5017 (C:0.5017, R:0.0105)
Batch  50/537: Loss=0.5067 (C:0.5067, R:0.0105)
Batch  75/537: Loss=0.5046 (C:0.5046, R:0.0105)
Batch 100/537: Loss=0.5089 (C:0.5089, R:0.0105)
Batch 125/537: Loss=0.5277 (C:0.5277, R:0.0105)
Batch 150/537: Loss=0.5078 (C:0.5078, R:0.0105)
Batch 175/537: Loss=0.4924 (C:0.4924, R:0.0105)
Batch 200/537: Loss=0.4820 (C:0.4820, R:0.0105)
Batch 225/537: Loss=0.5133 (C:0.5133, R:0.0105)
Batch 250/537: Loss=0.5038 (C:0.5038, R:0.0105)
Batch 275/537: Loss=0.4985 (C:0.4985, R:0.0105)
Batch 300/537: Loss=0.5503 (C:0.5503, R:0.0105)
Batch 325/537: Loss=0.4880 (C:0.4880, R:0.0105)
Batch 350/537: Loss=0.5210 (C:0.5210, R:0.0105)
Batch 375/537: Loss=0.5132 (C:0.5132, R:0.0105)
Batch 400/537: Loss=0.5254 (C:0.5254, R:0.0105)
Batch 425/537: Loss=0.4971 (C:0.4971, R:0.0105)
Batch 450/537: Loss=0.4962 (C:0.4962, R:0.0105)
Batch 475/537: Loss=0.5038 (C:0.5038, R:0.0105)
Batch 500/537: Loss=0.5323 (C:0.5323, R:0.0105)
Batch 525/537: Loss=0.4830 (C:0.4830, R:0.0105)

============================================================
Epoch 82/300 completed in 27.7s
Train: Loss=0.5136 (C:0.5136, R:0.0105) Ratio=5.43x
Val:   Loss=0.7073 (C:0.7073, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 5 epochs
============================================================

🌍 Updating global dataset at epoch 83
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.297 ± 0.548
    Neg distances: 2.729 ± 1.109
    Separation ratio: 9.17x
    Gap: -4.633
    ✅ Excellent global separation!

Epoch 83 Training
----------------------------------------
Batch   0/537: Loss=0.4719 (C:0.4719, R:0.0105)
Batch  25/537: Loss=0.4817 (C:0.4817, R:0.0105)
Batch  50/537: Loss=0.4748 (C:0.4748, R:0.0106)
Batch  75/537: Loss=0.5176 (C:0.5176, R:0.0106)
Batch 100/537: Loss=0.4984 (C:0.4984, R:0.0105)
Batch 125/537: Loss=0.5290 (C:0.5290, R:0.0105)
Batch 150/537: Loss=0.5296 (C:0.5296, R:0.0105)
Batch 175/537: Loss=0.5300 (C:0.5300, R:0.0105)
Batch 200/537: Loss=0.5252 (C:0.5252, R:0.0105)
Batch 225/537: Loss=0.5368 (C:0.5368, R:0.0105)
Batch 250/537: Loss=0.5225 (C:0.5225, R:0.0105)
Batch 275/537: Loss=0.5233 (C:0.5233, R:0.0105)
Batch 300/537: Loss=0.4855 (C:0.4855, R:0.0105)
Batch 325/537: Loss=0.5146 (C:0.5146, R:0.0105)
Batch 350/537: Loss=0.5119 (C:0.5119, R:0.0105)
Batch 375/537: Loss=0.5286 (C:0.5286, R:0.0105)
Batch 400/537: Loss=0.5277 (C:0.5277, R:0.0105)
Batch 425/537: Loss=0.5313 (C:0.5313, R:0.0105)
Batch 450/537: Loss=0.5611 (C:0.5611, R:0.0105)
Batch 475/537: Loss=0.5101 (C:0.5101, R:0.0105)
Batch 500/537: Loss=0.5082 (C:0.5082, R:0.0105)
Batch 525/537: Loss=0.5406 (C:0.5406, R:0.0105)

============================================================
Epoch 83/300 completed in 28.4s
Train: Loss=0.5145 (C:0.5145, R:0.0105) Ratio=5.39x
Val:   Loss=0.7114 (C:0.7114, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
No improvement for 6 epochs
============================================================

🌍 Updating global dataset at epoch 84
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.295 ± 0.551
    Neg distances: 2.766 ± 1.126
    Separation ratio: 9.36x
    Gap: -4.718
    ✅ Excellent global separation!

Epoch 84 Training
----------------------------------------
Batch   0/537: Loss=0.5184 (C:0.5184, R:0.0105)
Batch  25/537: Loss=0.4904 (C:0.4904, R:0.0105)
Batch  50/537: Loss=0.5290 (C:0.5290, R:0.0105)
Batch  75/537: Loss=0.5050 (C:0.5050, R:0.0105)
Batch 100/537: Loss=0.5328 (C:0.5328, R:0.0105)
Batch 125/537: Loss=0.5316 (C:0.5316, R:0.0105)
Batch 150/537: Loss=0.5069 (C:0.5069, R:0.0105)
Batch 175/537: Loss=0.5018 (C:0.5018, R:0.0105)
Batch 200/537: Loss=0.5140 (C:0.5140, R:0.0106)
Batch 225/537: Loss=0.5032 (C:0.5032, R:0.0105)
Batch 250/537: Loss=0.5268 (C:0.5268, R:0.0105)
Batch 275/537: Loss=0.5221 (C:0.5221, R:0.0105)
Batch 300/537: Loss=0.5241 (C:0.5241, R:0.0105)
Batch 325/537: Loss=0.5008 (C:0.5008, R:0.0105)
Batch 350/537: Loss=0.5395 (C:0.5395, R:0.0105)
Batch 375/537: Loss=0.5222 (C:0.5222, R:0.0105)
Batch 400/537: Loss=0.5073 (C:0.5073, R:0.0105)
Batch 425/537: Loss=0.5468 (C:0.5468, R:0.0105)
Batch 450/537: Loss=0.5282 (C:0.5282, R:0.0105)
Batch 475/537: Loss=0.4952 (C:0.4952, R:0.0105)
Batch 500/537: Loss=0.5074 (C:0.5074, R:0.0105)
Batch 525/537: Loss=0.5418 (C:0.5418, R:0.0105)

============================================================
Epoch 84/300 completed in 28.3s
Train: Loss=0.5120 (C:0.5120, R:0.0105) Ratio=5.24x
Val:   Loss=0.7068 (C:0.7068, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 7 epochs
============================================================

🌍 Updating global dataset at epoch 85
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.298 ± 0.561
    Neg distances: 2.731 ± 1.112
    Separation ratio: 9.16x
    Gap: -4.671
    ✅ Excellent global separation!

Epoch 85 Training
----------------------------------------
Batch   0/537: Loss=0.5088 (C:0.5088, R:0.0105)
Batch  25/537: Loss=0.5032 (C:0.5032, R:0.0105)
Batch  50/537: Loss=0.4831 (C:0.4831, R:0.0105)
Batch  75/537: Loss=0.5212 (C:0.5212, R:0.0105)
Batch 100/537: Loss=0.5067 (C:0.5067, R:0.0105)
Batch 125/537: Loss=0.4977 (C:0.4977, R:0.0105)
Batch 150/537: Loss=0.4829 (C:0.4829, R:0.0105)
Batch 175/537: Loss=0.5105 (C:0.5105, R:0.0105)
Batch 200/537: Loss=0.5206 (C:0.5206, R:0.0105)
Batch 225/537: Loss=0.5078 (C:0.5078, R:0.0105)
Batch 250/537: Loss=0.5307 (C:0.5307, R:0.0105)
Batch 275/537: Loss=0.5273 (C:0.5273, R:0.0105)
Batch 300/537: Loss=0.5221 (C:0.5221, R:0.0105)
Batch 325/537: Loss=0.5168 (C:0.5168, R:0.0105)
Batch 350/537: Loss=0.5297 (C:0.5297, R:0.0105)
Batch 375/537: Loss=0.5585 (C:0.5585, R:0.0105)
Batch 400/537: Loss=0.5313 (C:0.5313, R:0.0105)
Batch 425/537: Loss=0.5170 (C:0.5170, R:0.0105)
Batch 450/537: Loss=0.4985 (C:0.4985, R:0.0106)
Batch 475/537: Loss=0.5199 (C:0.5199, R:0.0105)
Batch 500/537: Loss=0.5270 (C:0.5270, R:0.0105)
Batch 525/537: Loss=0.5484 (C:0.5484, R:0.0105)

============================================================
Epoch 85/300 completed in 28.8s
Train: Loss=0.5134 (C:0.5134, R:0.0105) Ratio=5.29x
Val:   Loss=0.7057 (C:0.7057, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 8 epochs

Early stopping triggered after 85 epochs
Best model was at epoch 77 with Val Loss: 0.7048

Global Dataset Training Completed!
Best epoch: 77
Best validation loss: 0.7048
Final separation ratios: Train=5.29x, Val=3.07x
Training completed!
Loading best model from entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin2.0_updatefreq1_max_global_samples10000_20250715_133313/checkpoints/best_model.pt
Starting model evaluation...
========================================
GlobalContrastiveEvaluator initialized on cuda
Starting comprehensive evaluation...
============================================================
Extracting latent representations...
  Processed 1/10 batches
Extracted representations: torch.Size([9824, 75])
Evaluating clustering performance...
Clustering Results:
  Silhouette Score: 0.4557
  Adjusted Rand Score: 0.5298
  Clustering Accuracy: 0.8144
Evaluating classification performance...
  Extracting training representations...
Extracting latent representations...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
Extracted representations: torch.Size([547740, 75])
  Extracting validation representations...
Extracting latent representations...
  Processed 1/9 batches
Extracted representations: torch.Size([9180, 75])
Subsampled training to 50000 samples
  Training on 50000 samples, evaluating on 9180 samples
Classification Results:
  Accuracy: 0.8135
  Per-class F1: [0.8313273436175622, 0.7529005957980558, 0.8597731382541509]
Evaluating reconstruction quality...
Reconstruction Results:
  Average MSE: 0.010432
Evaluating separation quality...
Separation Results:
  Positive distances: 0.796 ± 0.921
  Negative distances: 2.388 ± 1.270
  Separation ratio: 3.00x
  Gap: -4.736
  Perfect separation: No

Comprehensive evaluation completed!

============================================================
EVALUATION SUMMARY
============================================================
Clustering Performance:
  Silhouette Score: 0.4557
  Clustering Accuracy: 0.8144
  Adjusted Rand Score: 0.5298

Classification Performance:
  Accuracy: 0.8135

Separation Quality:
  Separation Ratio: 3.00x
  Gap: -4.736
  Perfect Separation: False

Reconstruction Quality:
  Average MSE: 0.010432
============================================================
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin2.0_updatefreq1_max_global_samples10000_20250715_133313/results/evaluation_results_20250715_141232.json
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin2.0_updatefreq1_max_global_samples10000_20250715_133313/results/evaluation_results_20250715_141232.json
Saving final experiment results...
Final results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin2.0_updatefreq1_max_global_samples10000_20250715_133313/final_results.json

============================================================
PIPELINE COMPLETED SUCCESSFULLY!
============================================================
Experiment directory: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin2.0_updatefreq1_max_global_samples10000_20250715_133313
Best model: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin2.0_updatefreq1_max_global_samples10000_20250715_133313/checkpoints/best_model.pt
Final results: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin2.0_updatefreq1_max_global_samples10000_20250715_133313/final_results.json

Key Results:
  Separation ratio: 3.00x
  Perfect separation: False
  Classification accuracy: 0.8135
  Result: 0.8135% (improvement: +-80.86%)
  Cleaning up: coarse_margin2.0_updatefreq1_max_global_samples10000_20250715_133313

[7/12] Testing: coarse_margin2.0_updatefreq3_max_global_samples5000
  margin: 2.0
  update_frequency: 3
  max_global_samples: 5000
  Reconstruction weight: 0.3 (fixed)
GLOBAL DATASET CONTRASTIVE AUTOENCODER PIPELINE
============================================================
Start time: 2025-07-15 14:12:32.601880
Using device: cuda

Configuration:
  Embedding type: concat
  Batch size: 1020
  Global update frequency: 3 epochs
  Training epochs: 300
Experiment setup completed:
  Experiment directory: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin2.0_updatefreq3_max_global_samples5000_20250715_141232
  Config saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin2.0_updatefreq3_max_global_samples5000_20250715_141232/config.json
Loading data...
========================================
FlexibleEmbedder initialized with type: 'concat'
Output dimension will be: 1536
GlobalDataLoader initialized:
  Embedding type: concat
  Output dimension: 1536
  Sample size: All
Starting data loading pipeline...
============================================================
Loading training data from data/processed/snli_full_standard_SBERT.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 549367 training samples
Loading validation data from data/processed/snli_full_standard_SBERT_validation.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9842 validation samples
Loading test data from data/processed/snli_full_standard_SBERT_test.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9824 test samples
Generating embeddings for training...
Generating concat embeddings on cuda
Processing 549367 samples in batches of 1000
  Processing batch 1/550
  Processing batch 6/550
  Processing batch 11/550
  Processing batch 16/550
  Processing batch 21/550
  Processing batch 26/550
  Processing batch 31/550
  Processing batch 36/550
  Processing batch 41/550
  Processing batch 46/550
  Processing batch 51/550
  Processing batch 56/550
  Processing batch 61/550
  Processing batch 66/550
  Processing batch 71/550
  Processing batch 76/550
  Processing batch 81/550
  Processing batch 86/550
  Processing batch 91/550
  Processing batch 96/550
  Processing batch 101/550
  Processing batch 106/550
  Processing batch 111/550
  Processing batch 116/550
  Processing batch 121/550
  Processing batch 126/550
  Processing batch 131/550
  Processing batch 136/550
  Processing batch 141/550
  Processing batch 146/550
  Processing batch 151/550
  Processing batch 156/550
  Processing batch 161/550
  Processing batch 166/550
  Processing batch 171/550
  Processing batch 176/550
  Processing batch 181/550
  Processing batch 186/550
  Processing batch 191/550
  Processing batch 196/550
  Processing batch 201/550
  Processing batch 206/550
  Processing batch 211/550
  Processing batch 216/550
  Processing batch 221/550
  Processing batch 226/550
  Processing batch 231/550
  Processing batch 236/550
  Processing batch 241/550
  Processing batch 246/550
  Processing batch 251/550
  Processing batch 256/550
  Processing batch 261/550
  Processing batch 266/550
  Processing batch 271/550
  Processing batch 276/550
  Processing batch 281/550
  Processing batch 286/550
  Processing batch 291/550
  Processing batch 296/550
  Processing batch 301/550
  Processing batch 306/550
  Processing batch 311/550
  Processing batch 316/550
  Processing batch 321/550
  Processing batch 326/550
  Processing batch 331/550
  Processing batch 336/550
  Processing batch 341/550
  Processing batch 346/550
  Processing batch 351/550
  Processing batch 356/550
  Processing batch 361/550
  Processing batch 366/550
  Processing batch 371/550
  Processing batch 376/550
  Processing batch 381/550
  Processing batch 386/550
  Processing batch 391/550
  Processing batch 396/550
  Processing batch 401/550
  Processing batch 406/550
  Processing batch 411/550
  Processing batch 416/550
  Processing batch 421/550
  Processing batch 426/550
  Processing batch 431/550
  Processing batch 436/550
  Processing batch 441/550
  Processing batch 446/550
  Processing batch 451/550
  Processing batch 456/550
  Processing batch 461/550
  Processing batch 466/550
  Processing batch 471/550
  Processing batch 476/550
  Processing batch 481/550
  Processing batch 486/550
  Processing batch 491/550
  Processing batch 496/550
  Processing batch 501/550
  Processing batch 506/550
  Processing batch 511/550
  Processing batch 516/550
  Processing batch 521/550
  Processing batch 526/550
  Processing batch 531/550
  Processing batch 536/550
  Processing batch 541/550
  Processing batch 546/550
Generated concat embeddings: torch.Size([549367, 1536])
Generating embeddings for validation...
Generating concat embeddings on cuda
Processing 9842 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9842, 1536])
Generating embeddings for test...
Generating concat embeddings on cuda
Processing 9824 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9824, 1536])
EntailmentDataset created: 549367 samples
  Embedding shape: torch.Size([549367, 1536])
  Class distribution: {'entailment': 183416, 'neutral': 182764, 'contradiction': 183187}
EntailmentDataset created: 9842 samples
  Embedding shape: torch.Size([9842, 1536])
  Class distribution: {'entailment': 3329, 'neutral': 3235, 'contradiction': 3278}
EntailmentDataset created: 9824 samples
  Embedding shape: torch.Size([9824, 1536])
  Class distribution: {'entailment': 3368, 'neutral': 3219, 'contradiction': 3237}

Data loading pipeline completed!
Output embedding dimension: 1536
Updated model input_dim to: 1536
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 537
  Class 2: 183187 samples
  Class 0: 183416 samples
  Class 1: 182764 samples
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 9
  Class 2: 3278 samples
  Class 0: 3329 samples
  Class 1: 3235 samples
DataLoaders created:
  Batch size: 1020
  Balanced sampling: True
  Train batches: 537
  Val batches: 9
  Test batches: 10
Data loading completed!
  Train: 549367 samples, 537 batches
  Val: 9842 samples, 9 batches
  Test: 9824 samples, 10 batches
Creating model and trainer...
========================================
ContrastiveAutoencoder initialized:
  Input dim: 1536
  Latent dim: 75
  Hidden dims: [512, 256]
  Dropout rate: 0.2
  Total parameters: 1,876,555
Model created with 1,876,555 parameters
FullDatasetContrastiveLoss initialized:
  Margin: 2.0
  Update frequency: 3 epochs
  Max global samples: 5000
FullDatasetCombinedLoss initialized:
  Contrastive weight: 1.0
  Base reconstruction weight: 0.0
  Scheduled reconstruction: warmup=30 epochs, max_weight=0.3
Optimizer created (lr=0.0001)
GlobalDatasetTrainer initialized on device: cuda
Model parameters: 1,876,555
Starting training...
========================================
Starting Global Dataset Training...
============================================================

🌍 Updating global dataset at epoch 1
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.091 ± 0.010
    Neg distances: 0.091 ± 0.010
    Separation ratio: 1.00x
    Gap: -0.123
    ❌ Poor global separation

Epoch 1 Training
----------------------------------------
Batch   0/537: Loss=1.9999 (C:1.9999, R:0.0117)
Batch  25/537: Loss=1.9961 (C:1.9961, R:0.0114)
Batch  50/537: Loss=1.9831 (C:1.9831, R:0.0113)
Batch  75/537: Loss=1.9684 (C:1.9684, R:0.0112)
Batch 100/537: Loss=1.9692 (C:1.9692, R:0.0110)
Batch 125/537: Loss=1.9642 (C:1.9642, R:0.0110)
Batch 150/537: Loss=1.9634 (C:1.9634, R:0.0109)
Batch 175/537: Loss=1.9468 (C:1.9468, R:0.0107)
Batch 200/537: Loss=1.9331 (C:1.9331, R:0.0107)
Batch 225/537: Loss=1.9197 (C:1.9197, R:0.0107)
Batch 250/537: Loss=1.9298 (C:1.9298, R:0.0107)
Batch 275/537: Loss=1.9209 (C:1.9209, R:0.0106)
Batch 300/537: Loss=1.9106 (C:1.9106, R:0.0106)
Batch 325/537: Loss=1.9275 (C:1.9275, R:0.0106)
Batch 350/537: Loss=1.9143 (C:1.9143, R:0.0106)
Batch 375/537: Loss=1.9161 (C:1.9161, R:0.0106)
Batch 400/537: Loss=1.9017 (C:1.9017, R:0.0106)
Batch 425/537: Loss=1.9133 (C:1.9133, R:0.0105)
Batch 450/537: Loss=1.9133 (C:1.9133, R:0.0106)
Batch 475/537: Loss=1.9071 (C:1.9071, R:0.0105)
Batch 500/537: Loss=1.8965 (C:1.8965, R:0.0105)
Batch 525/537: Loss=1.8958 (C:1.8958, R:0.0105)

============================================================
Epoch 1/300 completed in 28.3s
Train: Loss=1.9353 (C:1.9353, R:0.0108) Ratio=1.63x
Val:   Loss=1.8965 (C:1.8965, R:0.0105) Ratio=2.18x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.8965)
============================================================

Epoch 2 Training
----------------------------------------
Batch   0/537: Loss=1.9100 (C:1.9100, R:0.0105)
Batch  25/537: Loss=1.8990 (C:1.8990, R:0.0105)
Batch  50/537: Loss=1.8883 (C:1.8883, R:0.0105)
Batch  75/537: Loss=1.8896 (C:1.8896, R:0.0105)
Batch 100/537: Loss=1.8801 (C:1.8801, R:0.0105)
Batch 125/537: Loss=1.8880 (C:1.8880, R:0.0105)
Batch 150/537: Loss=1.9060 (C:1.9060, R:0.0105)
Batch 175/537: Loss=1.8930 (C:1.8930, R:0.0105)
Batch 200/537: Loss=1.9012 (C:1.9012, R:0.0105)
Batch 225/537: Loss=1.8831 (C:1.8831, R:0.0105)
Batch 250/537: Loss=1.8890 (C:1.8890, R:0.0105)
Batch 275/537: Loss=1.8991 (C:1.8991, R:0.0105)
Batch 300/537: Loss=1.8969 (C:1.8969, R:0.0105)
Batch 325/537: Loss=1.8915 (C:1.8915, R:0.0105)
Batch 350/537: Loss=1.8941 (C:1.8941, R:0.0106)
Batch 375/537: Loss=1.8850 (C:1.8850, R:0.0105)
Batch 400/537: Loss=1.8877 (C:1.8877, R:0.0105)
Batch 425/537: Loss=1.8879 (C:1.8879, R:0.0105)
Batch 450/537: Loss=1.8784 (C:1.8784, R:0.0105)
Batch 475/537: Loss=1.8882 (C:1.8882, R:0.0105)
Batch 500/537: Loss=1.8948 (C:1.8948, R:0.0105)
Batch 525/537: Loss=1.8954 (C:1.8954, R:0.0105)

============================================================
Epoch 2/300 completed in 21.8s
Train: Loss=1.8941 (C:1.8941, R:0.0105) Ratio=2.21x
Val:   Loss=1.8818 (C:1.8818, R:0.0104) Ratio=2.42x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.8818)
============================================================

Epoch 3 Training
----------------------------------------
Batch   0/537: Loss=1.8762 (C:1.8762, R:0.0105)
Batch  25/537: Loss=1.8860 (C:1.8860, R:0.0105)
Batch  50/537: Loss=1.8985 (C:1.8985, R:0.0105)
Batch  75/537: Loss=1.8917 (C:1.8917, R:0.0105)
Batch 100/537: Loss=1.8874 (C:1.8874, R:0.0105)
Batch 125/537: Loss=1.8770 (C:1.8770, R:0.0105)
Batch 150/537: Loss=1.8904 (C:1.8904, R:0.0105)
Batch 175/537: Loss=1.8823 (C:1.8823, R:0.0105)
Batch 200/537: Loss=1.8937 (C:1.8937, R:0.0105)
Batch 225/537: Loss=1.8784 (C:1.8784, R:0.0105)
Batch 250/537: Loss=1.8747 (C:1.8747, R:0.0105)
Batch 275/537: Loss=1.8782 (C:1.8782, R:0.0105)
Batch 300/537: Loss=1.8819 (C:1.8819, R:0.0106)
Batch 325/537: Loss=1.8835 (C:1.8835, R:0.0105)
Batch 350/537: Loss=1.8944 (C:1.8944, R:0.0105)
Batch 375/537: Loss=1.8744 (C:1.8744, R:0.0105)
Batch 400/537: Loss=1.8861 (C:1.8861, R:0.0105)
Batch 425/537: Loss=1.8784 (C:1.8784, R:0.0105)
Batch 450/537: Loss=1.8753 (C:1.8753, R:0.0106)
Batch 475/537: Loss=1.8837 (C:1.8837, R:0.0106)
Batch 500/537: Loss=1.8737 (C:1.8737, R:0.0106)
Batch 525/537: Loss=1.8628 (C:1.8628, R:0.0105)

============================================================
Epoch 3/300 completed in 22.2s
Train: Loss=1.8809 (C:1.8809, R:0.0105) Ratio=2.45x
Val:   Loss=1.8762 (C:1.8762, R:0.0104) Ratio=2.61x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.8762)
============================================================

🌍 Updating global dataset at epoch 4
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.471 ± 0.566
    Neg distances: 1.353 ± 0.833
    Separation ratio: 2.87x
    Gap: -2.701
    ✅ Good global separation

Epoch 4 Training
----------------------------------------
Batch   0/537: Loss=1.2264 (C:1.2264, R:0.0105)
Batch  25/537: Loss=1.1962 (C:1.1962, R:0.0105)
Batch  50/537: Loss=1.1946 (C:1.1946, R:0.0105)
Batch  75/537: Loss=1.2111 (C:1.2111, R:0.0105)
Batch 100/537: Loss=1.2222 (C:1.2222, R:0.0105)
Batch 125/537: Loss=1.1953 (C:1.1953, R:0.0105)
Batch 150/537: Loss=1.2598 (C:1.2598, R:0.0105)
Batch 175/537: Loss=1.2267 (C:1.2267, R:0.0105)
Batch 200/537: Loss=1.2004 (C:1.2004, R:0.0105)
Batch 225/537: Loss=1.2534 (C:1.2534, R:0.0105)
Batch 250/537: Loss=1.2118 (C:1.2118, R:0.0105)
Batch 275/537: Loss=1.2111 (C:1.2111, R:0.0105)
Batch 300/537: Loss=1.2342 (C:1.2342, R:0.0105)
Batch 325/537: Loss=1.2056 (C:1.2056, R:0.0105)
Batch 350/537: Loss=1.2067 (C:1.2067, R:0.0105)
Batch 375/537: Loss=1.2057 (C:1.2057, R:0.0105)
Batch 400/537: Loss=1.2300 (C:1.2300, R:0.0105)
Batch 425/537: Loss=1.2003 (C:1.2003, R:0.0105)
Batch 450/537: Loss=1.2005 (C:1.2005, R:0.0105)
Batch 475/537: Loss=1.2296 (C:1.2296, R:0.0105)
Batch 500/537: Loss=1.1828 (C:1.1828, R:0.0105)
Batch 525/537: Loss=1.2311 (C:1.2311, R:0.0105)

============================================================
Epoch 4/300 completed in 28.0s
Train: Loss=1.2207 (C:1.2207, R:0.0105) Ratio=2.67x
Val:   Loss=1.2071 (C:1.2071, R:0.0104) Ratio=2.72x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.2071)
============================================================

Epoch 5 Training
----------------------------------------
Batch   0/537: Loss=1.2401 (C:1.2401, R:0.0105)
Batch  25/537: Loss=1.2159 (C:1.2159, R:0.0105)
Batch  50/537: Loss=1.2209 (C:1.2209, R:0.0105)
Batch  75/537: Loss=1.1877 (C:1.1877, R:0.0105)
Batch 100/537: Loss=1.2009 (C:1.2009, R:0.0105)
Batch 125/537: Loss=1.2133 (C:1.2133, R:0.0105)
Batch 150/537: Loss=1.2254 (C:1.2254, R:0.0105)
Batch 175/537: Loss=1.2041 (C:1.2041, R:0.0105)
Batch 200/537: Loss=1.1870 (C:1.1870, R:0.0105)
Batch 225/537: Loss=1.2005 (C:1.2005, R:0.0105)
Batch 250/537: Loss=1.2041 (C:1.2041, R:0.0105)
Batch 275/537: Loss=1.2563 (C:1.2563, R:0.0105)
Batch 300/537: Loss=1.1698 (C:1.1698, R:0.0105)
Batch 325/537: Loss=1.2055 (C:1.2055, R:0.0105)
Batch 350/537: Loss=1.1592 (C:1.1592, R:0.0105)
Batch 375/537: Loss=1.1856 (C:1.1856, R:0.0105)
Batch 400/537: Loss=1.1754 (C:1.1754, R:0.0105)
Batch 425/537: Loss=1.2045 (C:1.2045, R:0.0105)
Batch 450/537: Loss=1.2021 (C:1.2021, R:0.0105)
Batch 475/537: Loss=1.2058 (C:1.2058, R:0.0105)
Batch 500/537: Loss=1.2174 (C:1.2174, R:0.0105)
Batch 525/537: Loss=1.1866 (C:1.1866, R:0.0105)

============================================================
Epoch 5/300 completed in 22.1s
Train: Loss=1.1984 (C:1.1984, R:0.0105) Ratio=2.80x
Val:   Loss=1.2022 (C:1.2022, R:0.0104) Ratio=2.81x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.2022)
============================================================

Epoch 6 Training
----------------------------------------
Batch   0/537: Loss=1.1776 (C:1.1776, R:0.0105)
Batch  25/537: Loss=1.1840 (C:1.1840, R:0.0105)
Batch  50/537: Loss=1.1652 (C:1.1652, R:0.0105)
Batch  75/537: Loss=1.1523 (C:1.1523, R:0.0105)
Batch 100/537: Loss=1.1727 (C:1.1727, R:0.0105)
Batch 125/537: Loss=1.2005 (C:1.2005, R:0.0106)
Batch 150/537: Loss=1.1641 (C:1.1641, R:0.0105)
Batch 175/537: Loss=1.1958 (C:1.1958, R:0.0106)
Batch 200/537: Loss=1.2073 (C:1.2073, R:0.0105)
Batch 225/537: Loss=1.1733 (C:1.1733, R:0.0105)
Batch 250/537: Loss=1.1952 (C:1.1952, R:0.0105)
Batch 275/537: Loss=1.1887 (C:1.1887, R:0.0105)
Batch 300/537: Loss=1.1400 (C:1.1400, R:0.0105)
Batch 325/537: Loss=1.1819 (C:1.1819, R:0.0105)
Batch 350/537: Loss=1.1945 (C:1.1945, R:0.0105)
Batch 375/537: Loss=1.1613 (C:1.1613, R:0.0105)
Batch 400/537: Loss=1.2075 (C:1.2075, R:0.0105)
Batch 425/537: Loss=1.1995 (C:1.1995, R:0.0105)
Batch 450/537: Loss=1.1733 (C:1.1733, R:0.0105)
Batch 475/537: Loss=1.1628 (C:1.1628, R:0.0105)
Batch 500/537: Loss=1.1718 (C:1.1718, R:0.0105)
Batch 525/537: Loss=1.2040 (C:1.2040, R:0.0105)

============================================================
Epoch 6/300 completed in 22.6s
Train: Loss=1.1855 (C:1.1855, R:0.0105) Ratio=2.99x
Val:   Loss=1.1895 (C:1.1895, R:0.0104) Ratio=2.87x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.1895)
============================================================

🌍 Updating global dataset at epoch 7
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.405 ± 0.557
    Neg distances: 1.473 ± 0.855
    Separation ratio: 3.63x
    Gap: -2.722
    ✅ Excellent global separation!

Epoch 7 Training
----------------------------------------
Batch   0/537: Loss=1.0989 (C:1.0989, R:0.0105)
Batch  25/537: Loss=1.1006 (C:1.1006, R:0.0105)
Batch  50/537: Loss=1.0581 (C:1.0581, R:0.0105)
Batch  75/537: Loss=1.0647 (C:1.0647, R:0.0105)
Batch 100/537: Loss=1.0677 (C:1.0677, R:0.0105)
Batch 125/537: Loss=1.0792 (C:1.0792, R:0.0105)
Batch 150/537: Loss=1.0909 (C:1.0909, R:0.0105)
Batch 175/537: Loss=1.0838 (C:1.0838, R:0.0105)
Batch 200/537: Loss=1.0790 (C:1.0790, R:0.0105)
Batch 225/537: Loss=1.0986 (C:1.0986, R:0.0105)
Batch 250/537: Loss=1.0834 (C:1.0834, R:0.0105)
Batch 275/537: Loss=1.0945 (C:1.0945, R:0.0106)
Batch 300/537: Loss=1.0873 (C:1.0873, R:0.0105)
Batch 325/537: Loss=1.0929 (C:1.0929, R:0.0105)
Batch 350/537: Loss=1.0835 (C:1.0835, R:0.0105)
Batch 375/537: Loss=1.1031 (C:1.1031, R:0.0105)
Batch 400/537: Loss=1.1042 (C:1.1042, R:0.0106)
Batch 425/537: Loss=1.0700 (C:1.0700, R:0.0105)
Batch 450/537: Loss=1.0823 (C:1.0823, R:0.0105)
Batch 475/537: Loss=1.1330 (C:1.1330, R:0.0105)
Batch 500/537: Loss=1.0908 (C:1.0908, R:0.0105)
Batch 525/537: Loss=1.0902 (C:1.0902, R:0.0105)

============================================================
Epoch 7/300 completed in 28.4s
Train: Loss=1.0884 (C:1.0884, R:0.0105) Ratio=3.10x
Val:   Loss=1.1023 (C:1.1023, R:0.0104) Ratio=2.91x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.1023)
============================================================

Epoch 8 Training
----------------------------------------
Batch   0/537: Loss=1.0513 (C:1.0513, R:0.0105)
Batch  25/537: Loss=1.0684 (C:1.0684, R:0.0105)
Batch  50/537: Loss=1.1005 (C:1.1005, R:0.0105)
Batch  75/537: Loss=1.0711 (C:1.0711, R:0.0105)
Batch 100/537: Loss=1.0594 (C:1.0594, R:0.0105)
Batch 125/537: Loss=1.0648 (C:1.0648, R:0.0105)
Batch 150/537: Loss=1.0559 (C:1.0559, R:0.0105)
Batch 175/537: Loss=1.0778 (C:1.0778, R:0.0105)
Batch 200/537: Loss=1.0876 (C:1.0876, R:0.0105)
Batch 225/537: Loss=1.1181 (C:1.1181, R:0.0105)
Batch 250/537: Loss=1.0734 (C:1.0734, R:0.0105)
Batch 275/537: Loss=1.0497 (C:1.0497, R:0.0105)
Batch 300/537: Loss=1.0965 (C:1.0965, R:0.0105)
Batch 325/537: Loss=1.0903 (C:1.0903, R:0.0105)
Batch 350/537: Loss=1.0394 (C:1.0394, R:0.0105)
Batch 375/537: Loss=1.0999 (C:1.0999, R:0.0105)
Batch 400/537: Loss=1.0755 (C:1.0755, R:0.0105)
Batch 425/537: Loss=1.0949 (C:1.0949, R:0.0105)
Batch 450/537: Loss=1.0926 (C:1.0926, R:0.0105)
Batch 475/537: Loss=1.1055 (C:1.1055, R:0.0105)
Batch 500/537: Loss=1.0666 (C:1.0666, R:0.0105)
Batch 525/537: Loss=1.0822 (C:1.0822, R:0.0105)

============================================================
Epoch 8/300 completed in 22.6s
Train: Loss=1.0801 (C:1.0801, R:0.0105) Ratio=3.21x
Val:   Loss=1.1191 (C:1.1191, R:0.0104) Ratio=2.84x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

Epoch 9 Training
----------------------------------------
Batch   0/537: Loss=1.0462 (C:1.0462, R:0.0105)
Batch  25/537: Loss=1.0773 (C:1.0773, R:0.0105)
Batch  50/537: Loss=1.0970 (C:1.0970, R:0.0104)
Batch  75/537: Loss=1.0733 (C:1.0733, R:0.0105)
Batch 100/537: Loss=1.1140 (C:1.1140, R:0.0105)
Batch 125/537: Loss=1.0735 (C:1.0735, R:0.0105)
Batch 150/537: Loss=1.0703 (C:1.0703, R:0.0105)
Batch 175/537: Loss=1.1009 (C:1.1009, R:0.0105)
Batch 200/537: Loss=1.0634 (C:1.0634, R:0.0105)
Batch 225/537: Loss=1.1081 (C:1.1081, R:0.0105)
Batch 250/537: Loss=1.0807 (C:1.0807, R:0.0105)
Batch 275/537: Loss=1.0564 (C:1.0564, R:0.0105)
Batch 300/537: Loss=1.0805 (C:1.0805, R:0.0105)
Batch 325/537: Loss=1.0778 (C:1.0778, R:0.0106)
Batch 350/537: Loss=1.1224 (C:1.1224, R:0.0105)
Batch 375/537: Loss=1.0575 (C:1.0575, R:0.0105)
Batch 400/537: Loss=1.0622 (C:1.0622, R:0.0105)
Batch 425/537: Loss=1.1129 (C:1.1129, R:0.0105)
Batch 450/537: Loss=1.0862 (C:1.0862, R:0.0106)
Batch 475/537: Loss=1.1162 (C:1.1162, R:0.0105)
Batch 500/537: Loss=1.1065 (C:1.1065, R:0.0105)
Batch 525/537: Loss=1.0844 (C:1.0844, R:0.0105)

============================================================
Epoch 9/300 completed in 22.5s
Train: Loss=1.0730 (C:1.0730, R:0.0105) Ratio=3.33x
Val:   Loss=1.0981 (C:1.0981, R:0.0104) Ratio=2.93x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.0981)
============================================================

🌍 Updating global dataset at epoch 10
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.358 ± 0.527
    Neg distances: 1.540 ± 0.862
    Separation ratio: 4.31x
    Gap: -2.732
    ✅ Excellent global separation!

Epoch 10 Training
----------------------------------------
Batch   0/537: Loss=1.0049 (C:1.0049, R:0.0105)
Batch  25/537: Loss=0.9908 (C:0.9908, R:0.0105)
Batch  50/537: Loss=1.0059 (C:1.0059, R:0.0105)
Batch  75/537: Loss=1.0408 (C:1.0408, R:0.0105)
Batch 100/537: Loss=1.0633 (C:1.0633, R:0.0105)
Batch 125/537: Loss=0.9858 (C:0.9858, R:0.0105)
Batch 150/537: Loss=1.0061 (C:1.0061, R:0.0105)
Batch 175/537: Loss=0.9842 (C:0.9842, R:0.0105)
Batch 200/537: Loss=1.0215 (C:1.0215, R:0.0105)
Batch 225/537: Loss=1.0006 (C:1.0006, R:0.0105)
Batch 250/537: Loss=1.0206 (C:1.0206, R:0.0105)
Batch 275/537: Loss=0.9826 (C:0.9826, R:0.0105)
Batch 300/537: Loss=0.9883 (C:0.9883, R:0.0105)
Batch 325/537: Loss=1.0223 (C:1.0223, R:0.0105)
Batch 350/537: Loss=1.0141 (C:1.0141, R:0.0105)
Batch 375/537: Loss=1.0127 (C:1.0127, R:0.0105)
Batch 400/537: Loss=1.0249 (C:1.0249, R:0.0105)
Batch 425/537: Loss=1.0007 (C:1.0007, R:0.0105)
Batch 450/537: Loss=1.0507 (C:1.0507, R:0.0105)
Batch 475/537: Loss=1.0202 (C:1.0202, R:0.0105)
Batch 500/537: Loss=1.0379 (C:1.0379, R:0.0105)
Batch 525/537: Loss=1.0264 (C:1.0264, R:0.0105)

============================================================
Epoch 10/300 completed in 28.0s
Train: Loss=1.0160 (C:1.0160, R:0.0105) Ratio=3.41x
Val:   Loss=1.0493 (C:1.0493, R:0.0104) Ratio=2.94x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.0493)
============================================================

Epoch 11 Training
----------------------------------------
Batch   0/537: Loss=1.0177 (C:1.0177, R:0.0105)
Batch  25/537: Loss=0.9845 (C:0.9845, R:0.0105)
Batch  50/537: Loss=0.9922 (C:0.9922, R:0.0105)
Batch  75/537: Loss=0.9990 (C:0.9990, R:0.0105)
Batch 100/537: Loss=1.0143 (C:1.0143, R:0.0105)
Batch 125/537: Loss=0.9883 (C:0.9883, R:0.0105)
Batch 150/537: Loss=1.0150 (C:1.0150, R:0.0105)
Batch 175/537: Loss=1.0041 (C:1.0041, R:0.0105)
Batch 200/537: Loss=0.9887 (C:0.9887, R:0.0105)
Batch 225/537: Loss=1.0453 (C:1.0453, R:0.0105)
Batch 250/537: Loss=0.9929 (C:0.9929, R:0.0105)
Batch 275/537: Loss=1.0166 (C:1.0166, R:0.0105)
Batch 300/537: Loss=1.0003 (C:1.0003, R:0.0105)
Batch 325/537: Loss=1.0217 (C:1.0217, R:0.0105)
Batch 350/537: Loss=1.0181 (C:1.0181, R:0.0105)
Batch 375/537: Loss=1.0455 (C:1.0455, R:0.0105)
Batch 400/537: Loss=1.0296 (C:1.0296, R:0.0105)
Batch 425/537: Loss=1.0117 (C:1.0117, R:0.0105)
Batch 450/537: Loss=0.9998 (C:0.9998, R:0.0105)
Batch 475/537: Loss=1.0053 (C:1.0053, R:0.0105)
Batch 500/537: Loss=1.0171 (C:1.0171, R:0.0105)
Batch 525/537: Loss=1.0127 (C:1.0127, R:0.0105)

============================================================
Epoch 11/300 completed in 22.1s
Train: Loss=1.0092 (C:1.0092, R:0.0105) Ratio=3.48x
Val:   Loss=1.0493 (C:1.0493, R:0.0104) Ratio=2.97x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.0493)
============================================================

Epoch 12 Training
----------------------------------------
Batch   0/537: Loss=0.9941 (C:0.9941, R:0.0105)
Batch  25/537: Loss=0.9739 (C:0.9739, R:0.0105)
Batch  50/537: Loss=0.9839 (C:0.9839, R:0.0105)
Batch  75/537: Loss=1.0142 (C:1.0142, R:0.0105)
Batch 100/537: Loss=1.0232 (C:1.0232, R:0.0105)
Batch 125/537: Loss=0.9871 (C:0.9871, R:0.0105)
Batch 150/537: Loss=1.0036 (C:1.0036, R:0.0105)
Batch 175/537: Loss=0.9852 (C:0.9852, R:0.0105)
Batch 200/537: Loss=0.9662 (C:0.9662, R:0.0106)
Batch 225/537: Loss=1.0333 (C:1.0333, R:0.0105)
Batch 250/537: Loss=0.9684 (C:0.9684, R:0.0105)
Batch 275/537: Loss=0.9854 (C:0.9854, R:0.0106)
Batch 300/537: Loss=1.0165 (C:1.0165, R:0.0105)
Batch 325/537: Loss=0.9994 (C:0.9994, R:0.0106)
Batch 350/537: Loss=1.0242 (C:1.0242, R:0.0105)
Batch 375/537: Loss=0.9911 (C:0.9911, R:0.0105)
Batch 400/537: Loss=1.0025 (C:1.0025, R:0.0106)
Batch 425/537: Loss=0.9948 (C:0.9948, R:0.0105)
Batch 450/537: Loss=0.9949 (C:0.9949, R:0.0105)
Batch 475/537: Loss=1.0133 (C:1.0133, R:0.0105)
Batch 500/537: Loss=1.0147 (C:1.0147, R:0.0105)
Batch 525/537: Loss=1.0116 (C:1.0116, R:0.0105)

============================================================
Epoch 12/300 completed in 21.9s
Train: Loss=1.0067 (C:1.0067, R:0.0105) Ratio=3.62x
Val:   Loss=1.0527 (C:1.0527, R:0.0104) Ratio=3.00x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 13
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.346 ± 0.518
    Neg distances: 1.579 ± 0.872
    Separation ratio: 4.56x
    Gap: -2.789
    ✅ Excellent global separation!

Epoch 13 Training
----------------------------------------
Batch   0/537: Loss=0.9770 (C:0.9770, R:0.0105)
Batch  25/537: Loss=1.0032 (C:1.0032, R:0.0105)
Batch  50/537: Loss=0.9504 (C:0.9504, R:0.0105)
Batch  75/537: Loss=1.0069 (C:1.0069, R:0.0105)
Batch 100/537: Loss=0.9791 (C:0.9791, R:0.0105)
Batch 125/537: Loss=0.9561 (C:0.9561, R:0.0105)
Batch 150/537: Loss=1.0010 (C:1.0010, R:0.0105)
Batch 175/537: Loss=1.0111 (C:1.0111, R:0.0105)
Batch 200/537: Loss=0.9872 (C:0.9872, R:0.0105)
Batch 225/537: Loss=0.9678 (C:0.9678, R:0.0105)
Batch 250/537: Loss=1.0053 (C:1.0053, R:0.0105)
Batch 275/537: Loss=0.9543 (C:0.9543, R:0.0105)
Batch 300/537: Loss=0.9946 (C:0.9946, R:0.0105)
Batch 325/537: Loss=0.9751 (C:0.9751, R:0.0105)
Batch 350/537: Loss=0.9534 (C:0.9534, R:0.0105)
Batch 375/537: Loss=1.0114 (C:1.0114, R:0.0105)
Batch 400/537: Loss=0.9913 (C:0.9913, R:0.0105)
Batch 425/537: Loss=0.9956 (C:0.9956, R:0.0105)
Batch 450/537: Loss=1.0074 (C:1.0074, R:0.0105)
Batch 475/537: Loss=0.9695 (C:0.9695, R:0.0105)
Batch 500/537: Loss=0.9910 (C:0.9910, R:0.0105)
Batch 525/537: Loss=0.9887 (C:0.9887, R:0.0105)

============================================================
Epoch 13/300 completed in 28.1s
Train: Loss=0.9827 (C:0.9827, R:0.0105) Ratio=3.65x
Val:   Loss=1.0361 (C:1.0361, R:0.0104) Ratio=2.97x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.0361)
============================================================

Epoch 14 Training
----------------------------------------
Batch   0/537: Loss=1.0222 (C:1.0222, R:0.0105)
Batch  25/537: Loss=0.9570 (C:0.9570, R:0.0105)
Batch  50/537: Loss=0.9957 (C:0.9957, R:0.0105)
Batch  75/537: Loss=0.9558 (C:0.9558, R:0.0105)
Batch 100/537: Loss=0.9763 (C:0.9763, R:0.0105)
Batch 125/537: Loss=0.9953 (C:0.9953, R:0.0105)
Batch 150/537: Loss=0.9639 (C:0.9639, R:0.0105)
Batch 175/537: Loss=1.0097 (C:1.0097, R:0.0105)
Batch 200/537: Loss=0.9827 (C:0.9827, R:0.0105)
Batch 225/537: Loss=0.9532 (C:0.9532, R:0.0105)
Batch 250/537: Loss=1.0114 (C:1.0114, R:0.0105)
Batch 275/537: Loss=1.0181 (C:1.0181, R:0.0105)
Batch 300/537: Loss=0.9700 (C:0.9700, R:0.0106)
Batch 325/537: Loss=0.9761 (C:0.9761, R:0.0105)
Batch 350/537: Loss=0.9801 (C:0.9801, R:0.0105)
Batch 375/537: Loss=0.9917 (C:0.9917, R:0.0105)
Batch 400/537: Loss=0.9863 (C:0.9863, R:0.0105)
Batch 425/537: Loss=0.9625 (C:0.9625, R:0.0105)
Batch 450/537: Loss=0.9698 (C:0.9698, R:0.0105)
Batch 475/537: Loss=0.9671 (C:0.9671, R:0.0105)
Batch 500/537: Loss=1.0029 (C:1.0029, R:0.0105)
Batch 525/537: Loss=0.9404 (C:0.9404, R:0.0105)

============================================================
Epoch 14/300 completed in 22.7s
Train: Loss=0.9792 (C:0.9792, R:0.0105) Ratio=3.65x
Val:   Loss=1.0328 (C:1.0328, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.0328)
============================================================

Epoch 15 Training
----------------------------------------
Batch   0/537: Loss=0.9502 (C:0.9502, R:0.0105)
Batch  25/537: Loss=0.9781 (C:0.9781, R:0.0106)
Batch  50/537: Loss=0.9458 (C:0.9458, R:0.0105)
Batch  75/537: Loss=0.9692 (C:0.9692, R:0.0105)
Batch 100/537: Loss=0.9465 (C:0.9465, R:0.0105)
Batch 125/537: Loss=0.9703 (C:0.9703, R:0.0105)
Batch 150/537: Loss=0.9572 (C:0.9572, R:0.0105)
Batch 175/537: Loss=0.9718 (C:0.9718, R:0.0105)
Batch 200/537: Loss=0.9646 (C:0.9646, R:0.0105)
Batch 225/537: Loss=0.9989 (C:0.9989, R:0.0105)
Batch 250/537: Loss=0.9519 (C:0.9519, R:0.0105)
Batch 275/537: Loss=0.9666 (C:0.9666, R:0.0105)
Batch 300/537: Loss=0.9810 (C:0.9810, R:0.0105)
Batch 325/537: Loss=0.9381 (C:0.9381, R:0.0105)
Batch 350/537: Loss=0.9273 (C:0.9273, R:0.0105)
Batch 375/537: Loss=0.9921 (C:0.9921, R:0.0105)
Batch 400/537: Loss=0.9698 (C:0.9698, R:0.0105)
Batch 425/537: Loss=0.9623 (C:0.9623, R:0.0105)
Batch 450/537: Loss=0.9670 (C:0.9670, R:0.0105)
Batch 475/537: Loss=0.9585 (C:0.9585, R:0.0105)
Batch 500/537: Loss=0.9414 (C:0.9414, R:0.0105)
Batch 525/537: Loss=1.0060 (C:1.0060, R:0.0105)

============================================================
Epoch 15/300 completed in 22.6s
Train: Loss=0.9748 (C:0.9748, R:0.0105) Ratio=3.82x
Val:   Loss=1.0273 (C:1.0273, R:0.0104) Ratio=3.02x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.0273)
============================================================

🌍 Updating global dataset at epoch 16
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.348 ± 0.529
    Neg distances: 1.621 ± 0.893
    Separation ratio: 4.65x
    Gap: -2.915
    ✅ Excellent global separation!

Epoch 16 Training
----------------------------------------
Batch   0/537: Loss=0.9762 (C:0.9762, R:0.0105)
Batch  25/537: Loss=0.9622 (C:0.9622, R:0.0105)
Batch  50/537: Loss=0.9637 (C:0.9637, R:0.0105)
Batch  75/537: Loss=0.9571 (C:0.9571, R:0.0105)
Batch 100/537: Loss=0.9476 (C:0.9476, R:0.0106)
Batch 125/537: Loss=0.9617 (C:0.9617, R:0.0105)
Batch 150/537: Loss=0.9360 (C:0.9360, R:0.0105)
Batch 175/537: Loss=0.9727 (C:0.9727, R:0.0105)
Batch 200/537: Loss=0.9476 (C:0.9476, R:0.0105)
Batch 225/537: Loss=0.9840 (C:0.9840, R:0.0105)
Batch 250/537: Loss=0.9442 (C:0.9442, R:0.0105)
Batch 275/537: Loss=0.9812 (C:0.9812, R:0.0105)
Batch 300/537: Loss=0.9752 (C:0.9752, R:0.0105)
Batch 325/537: Loss=0.9705 (C:0.9705, R:0.0105)
Batch 350/537: Loss=0.9884 (C:0.9884, R:0.0105)
Batch 375/537: Loss=0.9454 (C:0.9454, R:0.0105)
Batch 400/537: Loss=0.9971 (C:0.9971, R:0.0105)
Batch 425/537: Loss=0.9849 (C:0.9849, R:0.0105)
Batch 450/537: Loss=0.9646 (C:0.9646, R:0.0105)
Batch 475/537: Loss=0.9543 (C:0.9543, R:0.0105)
Batch 500/537: Loss=0.9640 (C:0.9640, R:0.0105)
Batch 525/537: Loss=0.9714 (C:0.9714, R:0.0105)

============================================================
Epoch 16/300 completed in 28.9s
Train: Loss=0.9602 (C:0.9602, R:0.0105) Ratio=3.77x
Val:   Loss=1.0149 (C:1.0149, R:0.0104) Ratio=3.03x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.0149)
============================================================

Epoch 17 Training
----------------------------------------
Batch   0/537: Loss=0.9389 (C:0.9389, R:0.0105)
Batch  25/537: Loss=0.9469 (C:0.9469, R:0.0105)
Batch  50/537: Loss=0.9414 (C:0.9414, R:0.0105)
Batch  75/537: Loss=0.9568 (C:0.9568, R:0.0105)
Batch 100/537: Loss=0.9905 (C:0.9905, R:0.0105)
Batch 125/537: Loss=0.9484 (C:0.9484, R:0.0105)
Batch 150/537: Loss=0.9629 (C:0.9629, R:0.0105)
Batch 175/537: Loss=0.9454 (C:0.9454, R:0.0105)
Batch 200/537: Loss=0.9360 (C:0.9360, R:0.0105)
Batch 225/537: Loss=0.9402 (C:0.9402, R:0.0105)
Batch 250/537: Loss=0.9622 (C:0.9622, R:0.0105)
Batch 275/537: Loss=0.9709 (C:0.9709, R:0.0105)
Batch 300/537: Loss=0.9528 (C:0.9528, R:0.0105)
Batch 325/537: Loss=0.9519 (C:0.9519, R:0.0105)
Batch 350/537: Loss=0.9321 (C:0.9321, R:0.0106)
Batch 375/537: Loss=0.9805 (C:0.9805, R:0.0105)
Batch 400/537: Loss=0.9689 (C:0.9689, R:0.0105)
Batch 425/537: Loss=0.9576 (C:0.9576, R:0.0105)
Batch 450/537: Loss=0.9397 (C:0.9397, R:0.0105)
Batch 475/537: Loss=0.9442 (C:0.9442, R:0.0105)
Batch 500/537: Loss=0.9469 (C:0.9469, R:0.0105)
Batch 525/537: Loss=0.9398 (C:0.9398, R:0.0105)

============================================================
Epoch 17/300 completed in 21.8s
Train: Loss=0.9582 (C:0.9582, R:0.0105) Ratio=3.91x
Val:   Loss=1.0168 (C:1.0168, R:0.0104) Ratio=2.98x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

Epoch 18 Training
----------------------------------------
Batch   0/537: Loss=0.9442 (C:0.9442, R:0.0105)
Batch  25/537: Loss=0.9465 (C:0.9465, R:0.0106)
Batch  50/537: Loss=0.9325 (C:0.9325, R:0.0105)
Batch  75/537: Loss=0.9275 (C:0.9275, R:0.0105)
Batch 100/537: Loss=0.9776 (C:0.9776, R:0.0105)
Batch 125/537: Loss=0.9462 (C:0.9462, R:0.0105)
Batch 150/537: Loss=0.9124 (C:0.9124, R:0.0105)
Batch 175/537: Loss=0.9604 (C:0.9604, R:0.0104)
Batch 200/537: Loss=0.9626 (C:0.9626, R:0.0105)
Batch 225/537: Loss=0.9320 (C:0.9320, R:0.0105)
Batch 250/537: Loss=0.9618 (C:0.9618, R:0.0105)
Batch 275/537: Loss=0.9354 (C:0.9354, R:0.0105)
Batch 300/537: Loss=0.9604 (C:0.9604, R:0.0105)
Batch 325/537: Loss=0.9696 (C:0.9696, R:0.0106)
Batch 350/537: Loss=0.9910 (C:0.9910, R:0.0105)
Batch 375/537: Loss=0.9530 (C:0.9530, R:0.0105)
Batch 400/537: Loss=0.9334 (C:0.9334, R:0.0105)
Batch 425/537: Loss=0.9526 (C:0.9526, R:0.0105)
Batch 450/537: Loss=0.9916 (C:0.9916, R:0.0105)
Batch 475/537: Loss=1.0111 (C:1.0111, R:0.0105)
Batch 500/537: Loss=0.9730 (C:0.9730, R:0.0105)
Batch 525/537: Loss=0.9491 (C:0.9491, R:0.0105)

============================================================
Epoch 18/300 completed in 21.8s
Train: Loss=0.9543 (C:0.9543, R:0.0105) Ratio=3.92x
Val:   Loss=1.0261 (C:1.0261, R:0.0104) Ratio=2.99x
Reconstruction weight: 0.000
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 19
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.317 ± 0.513
    Neg distances: 1.720 ± 0.900
    Separation ratio: 5.42x
    Gap: -2.971
    ✅ Excellent global separation!

Epoch 19 Training
----------------------------------------
Batch   0/537: Loss=0.8722 (C:0.8722, R:0.0105)
Batch  25/537: Loss=0.8781 (C:0.8781, R:0.0105)
Batch  50/537: Loss=0.8896 (C:0.8896, R:0.0105)
Batch  75/537: Loss=0.8934 (C:0.8934, R:0.0105)
Batch 100/537: Loss=0.8788 (C:0.8788, R:0.0105)
Batch 125/537: Loss=0.9167 (C:0.9167, R:0.0105)
Batch 150/537: Loss=0.9107 (C:0.9107, R:0.0105)
Batch 175/537: Loss=0.9076 (C:0.9076, R:0.0105)
Batch 200/537: Loss=0.8848 (C:0.8848, R:0.0105)
Batch 225/537: Loss=0.9039 (C:0.9039, R:0.0105)
Batch 250/537: Loss=0.9203 (C:0.9203, R:0.0105)
Batch 275/537: Loss=0.8660 (C:0.8660, R:0.0105)
Batch 300/537: Loss=0.9541 (C:0.9541, R:0.0105)
Batch 325/537: Loss=0.8775 (C:0.8775, R:0.0105)
Batch 350/537: Loss=0.9004 (C:0.9004, R:0.0105)
Batch 375/537: Loss=0.9121 (C:0.9121, R:0.0105)
Batch 400/537: Loss=0.8908 (C:0.8908, R:0.0105)
Batch 425/537: Loss=0.9000 (C:0.9000, R:0.0105)
Batch 450/537: Loss=0.8875 (C:0.8875, R:0.0105)
Batch 475/537: Loss=0.9351 (C:0.9351, R:0.0105)
Batch 500/537: Loss=0.8967 (C:0.8967, R:0.0105)
Batch 525/537: Loss=0.9245 (C:0.9245, R:0.0105)

============================================================
Epoch 19/300 completed in 27.9s
Train: Loss=0.8997 (C:0.8997, R:0.0105) Ratio=4.02x
Val:   Loss=0.9729 (C:0.9729, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.9729)
============================================================

Epoch 20 Training
----------------------------------------
Batch   0/537: Loss=0.8976 (C:0.8976, R:0.0105)
Batch  25/537: Loss=0.8944 (C:0.8944, R:0.0105)
Batch  50/537: Loss=0.9094 (C:0.9094, R:0.0105)
Batch  75/537: Loss=0.9008 (C:0.9008, R:0.0105)
Batch 100/537: Loss=0.9100 (C:0.9100, R:0.0106)
Batch 125/537: Loss=0.9116 (C:0.9116, R:0.0105)
Batch 150/537: Loss=0.9209 (C:0.9209, R:0.0105)
Batch 175/537: Loss=0.8752 (C:0.8752, R:0.0105)
Batch 200/537: Loss=0.8746 (C:0.8746, R:0.0105)
Batch 225/537: Loss=0.9113 (C:0.9113, R:0.0105)
Batch 250/537: Loss=0.9134 (C:0.9134, R:0.0105)
Batch 275/537: Loss=0.9114 (C:0.9114, R:0.0105)
Batch 300/537: Loss=0.9358 (C:0.9358, R:0.0105)
Batch 325/537: Loss=0.8691 (C:0.8691, R:0.0105)
Batch 350/537: Loss=0.8755 (C:0.8755, R:0.0105)
Batch 375/537: Loss=0.8702 (C:0.8702, R:0.0105)
Batch 400/537: Loss=0.9108 (C:0.9108, R:0.0105)
Batch 425/537: Loss=0.8710 (C:0.8710, R:0.0105)
Batch 450/537: Loss=0.9265 (C:0.9265, R:0.0105)
Batch 475/537: Loss=0.8951 (C:0.8951, R:0.0105)
Batch 500/537: Loss=0.8726 (C:0.8726, R:0.0105)
Batch 525/537: Loss=0.8957 (C:0.8957, R:0.0105)

============================================================
Epoch 20/300 completed in 21.7s
Train: Loss=0.8951 (C:0.8951, R:0.0105) Ratio=3.99x
Val:   Loss=0.9677 (C:0.9677, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.9677)
Checkpoint saved at epoch 20
============================================================

Epoch 21 Training
----------------------------------------
Batch   0/537: Loss=0.8800 (C:0.8800, R:0.0105)
Batch  25/537: Loss=0.9273 (C:0.9273, R:0.0105)
Batch  50/537: Loss=0.9094 (C:0.9094, R:0.0105)
Batch  75/537: Loss=0.8829 (C:0.8829, R:0.0105)
Batch 100/537: Loss=0.9038 (C:0.9038, R:0.0105)
Batch 125/537: Loss=0.8468 (C:0.8468, R:0.0105)
Batch 150/537: Loss=0.8910 (C:0.8910, R:0.0105)
Batch 175/537: Loss=0.8705 (C:0.8705, R:0.0105)
Batch 200/537: Loss=0.8607 (C:0.8607, R:0.0105)
Batch 225/537: Loss=0.8648 (C:0.8648, R:0.0105)
Batch 250/537: Loss=0.9170 (C:0.9170, R:0.0105)
Batch 275/537: Loss=0.9068 (C:0.9068, R:0.0105)
Batch 300/537: Loss=0.9008 (C:0.9008, R:0.0105)
Batch 325/537: Loss=0.8957 (C:0.8957, R:0.0105)
Batch 350/537: Loss=0.8867 (C:0.8867, R:0.0105)
Batch 375/537: Loss=0.8297 (C:0.8297, R:0.0105)
Batch 400/537: Loss=0.8929 (C:0.8929, R:0.0105)
Batch 425/537: Loss=0.9124 (C:0.9124, R:0.0105)
Batch 450/537: Loss=0.8890 (C:0.8890, R:0.0105)
Batch 475/537: Loss=0.8908 (C:0.8908, R:0.0105)
Batch 500/537: Loss=0.9197 (C:0.9197, R:0.0105)
Batch 525/537: Loss=0.8903 (C:0.8903, R:0.0105)

============================================================
Epoch 21/300 completed in 22.0s
Train: Loss=0.8930 (C:0.8930, R:0.0105) Ratio=4.13x
Val:   Loss=0.9667 (C:0.9667, R:0.0104) Ratio=3.01x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.9667)
============================================================

🌍 Updating global dataset at epoch 22
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.324 ± 0.493
    Neg distances: 1.734 ± 0.905
    Separation ratio: 5.36x
    Gap: -3.034
    ✅ Excellent global separation!

Epoch 22 Training
----------------------------------------
Batch   0/537: Loss=0.8657 (C:0.8657, R:0.0105)
Batch  25/537: Loss=0.8912 (C:0.8912, R:0.0106)
Batch  50/537: Loss=0.8423 (C:0.8423, R:0.0105)
Batch  75/537: Loss=0.9101 (C:0.9101, R:0.0105)
Batch 100/537: Loss=0.9107 (C:0.9107, R:0.0105)
Batch 125/537: Loss=0.8762 (C:0.8762, R:0.0105)
Batch 150/537: Loss=0.8891 (C:0.8891, R:0.0105)
Batch 175/537: Loss=0.8809 (C:0.8809, R:0.0105)
Batch 200/537: Loss=0.8825 (C:0.8825, R:0.0105)
Batch 225/537: Loss=0.8954 (C:0.8954, R:0.0105)
Batch 250/537: Loss=0.8690 (C:0.8690, R:0.0105)
Batch 275/537: Loss=0.8821 (C:0.8821, R:0.0105)
Batch 300/537: Loss=0.8928 (C:0.8928, R:0.0105)
Batch 325/537: Loss=0.9194 (C:0.9194, R:0.0106)
Batch 350/537: Loss=0.9180 (C:0.9180, R:0.0105)
Batch 375/537: Loss=0.9234 (C:0.9234, R:0.0105)
Batch 400/537: Loss=0.9143 (C:0.9143, R:0.0105)
Batch 425/537: Loss=0.8947 (C:0.8947, R:0.0105)
Batch 450/537: Loss=0.9194 (C:0.9194, R:0.0105)
Batch 475/537: Loss=0.8676 (C:0.8676, R:0.0105)
Batch 500/537: Loss=0.8805 (C:0.8805, R:0.0105)
Batch 525/537: Loss=0.9145 (C:0.9145, R:0.0105)

============================================================
Epoch 22/300 completed in 27.6s
Train: Loss=0.8923 (C:0.8923, R:0.0105) Ratio=4.06x
Val:   Loss=0.9819 (C:0.9819, R:0.0104) Ratio=2.98x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

Epoch 23 Training
----------------------------------------
Batch   0/537: Loss=0.8946 (C:0.8946, R:0.0105)
Batch  25/537: Loss=0.8845 (C:0.8845, R:0.0105)
Batch  50/537: Loss=0.8657 (C:0.8657, R:0.0105)
Batch  75/537: Loss=0.8901 (C:0.8901, R:0.0105)
Batch 100/537: Loss=0.9132 (C:0.9132, R:0.0105)
Batch 125/537: Loss=0.8786 (C:0.8786, R:0.0105)
Batch 150/537: Loss=0.8764 (C:0.8764, R:0.0105)
Batch 175/537: Loss=0.9054 (C:0.9054, R:0.0105)
Batch 200/537: Loss=0.9324 (C:0.9324, R:0.0105)
Batch 225/537: Loss=0.9406 (C:0.9406, R:0.0105)
Batch 250/537: Loss=0.8835 (C:0.8835, R:0.0105)
Batch 275/537: Loss=0.8862 (C:0.8862, R:0.0105)
Batch 300/537: Loss=0.8845 (C:0.8845, R:0.0105)
Batch 325/537: Loss=0.9277 (C:0.9277, R:0.0105)
Batch 350/537: Loss=0.8624 (C:0.8624, R:0.0105)
Batch 375/537: Loss=0.9023 (C:0.9023, R:0.0105)
Batch 400/537: Loss=0.8778 (C:0.8778, R:0.0105)
Batch 425/537: Loss=0.8789 (C:0.8789, R:0.0105)
Batch 450/537: Loss=0.8761 (C:0.8761, R:0.0105)
Batch 475/537: Loss=0.8664 (C:0.8664, R:0.0105)
Batch 500/537: Loss=0.9187 (C:0.9187, R:0.0105)
Batch 525/537: Loss=0.8656 (C:0.8656, R:0.0105)

============================================================
Epoch 23/300 completed in 21.1s
Train: Loss=0.8909 (C:0.8909, R:0.0105) Ratio=4.11x
Val:   Loss=0.9731 (C:0.9731, R:0.0104) Ratio=3.00x
Reconstruction weight: 0.000
No improvement for 2 epochs
============================================================

Epoch 24 Training
----------------------------------------
Batch   0/537: Loss=0.9019 (C:0.9019, R:0.0105)
Batch  25/537: Loss=0.8464 (C:0.8464, R:0.0105)
Batch  50/537: Loss=0.8831 (C:0.8831, R:0.0105)
Batch  75/537: Loss=0.8897 (C:0.8897, R:0.0105)
Batch 100/537: Loss=0.8885 (C:0.8885, R:0.0105)
Batch 125/537: Loss=0.9244 (C:0.9244, R:0.0105)
Batch 150/537: Loss=0.9104 (C:0.9104, R:0.0105)
Batch 175/537: Loss=0.8835 (C:0.8835, R:0.0105)
Batch 200/537: Loss=0.8772 (C:0.8772, R:0.0105)
Batch 225/537: Loss=0.8944 (C:0.8944, R:0.0105)
Batch 250/537: Loss=0.8624 (C:0.8624, R:0.0105)
Batch 275/537: Loss=0.8989 (C:0.8989, R:0.0105)
Batch 300/537: Loss=0.8832 (C:0.8832, R:0.0105)
Batch 325/537: Loss=0.8855 (C:0.8855, R:0.0105)
Batch 350/537: Loss=0.9067 (C:0.9067, R:0.0105)
Batch 375/537: Loss=0.8919 (C:0.8919, R:0.0106)
Batch 400/537: Loss=0.9096 (C:0.9096, R:0.0105)
Batch 425/537: Loss=0.8766 (C:0.8766, R:0.0105)
Batch 450/537: Loss=0.9059 (C:0.9059, R:0.0105)
Batch 475/537: Loss=0.8788 (C:0.8788, R:0.0105)
Batch 500/537: Loss=0.8926 (C:0.8926, R:0.0105)
Batch 525/537: Loss=0.9154 (C:0.9154, R:0.0105)

============================================================
Epoch 24/300 completed in 21.1s
Train: Loss=0.8870 (C:0.8870, R:0.0105) Ratio=4.20x
Val:   Loss=0.9651 (C:0.9651, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.9651)
============================================================

🌍 Updating global dataset at epoch 25
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.320 ± 0.493
    Neg distances: 1.775 ± 0.901
    Separation ratio: 5.54x
    Gap: -3.051
    ✅ Excellent global separation!

Epoch 25 Training
----------------------------------------
Batch   0/537: Loss=0.8423 (C:0.8423, R:0.0105)
Batch  25/537: Loss=0.8394 (C:0.8394, R:0.0105)
Batch  50/537: Loss=0.8824 (C:0.8824, R:0.0105)
Batch  75/537: Loss=0.8603 (C:0.8603, R:0.0105)
Batch 100/537: Loss=0.8690 (C:0.8690, R:0.0105)
Batch 125/537: Loss=0.8656 (C:0.8656, R:0.0105)
Batch 150/537: Loss=0.8674 (C:0.8674, R:0.0105)
Batch 175/537: Loss=0.8642 (C:0.8642, R:0.0105)
Batch 200/537: Loss=0.8430 (C:0.8430, R:0.0106)
Batch 225/537: Loss=0.8850 (C:0.8850, R:0.0105)
Batch 250/537: Loss=0.8660 (C:0.8660, R:0.0105)
Batch 275/537: Loss=0.8499 (C:0.8499, R:0.0105)
Batch 300/537: Loss=0.8662 (C:0.8662, R:0.0105)
Batch 325/537: Loss=0.8565 (C:0.8565, R:0.0105)
Batch 350/537: Loss=0.8857 (C:0.8857, R:0.0105)
Batch 375/537: Loss=0.8881 (C:0.8881, R:0.0106)
Batch 400/537: Loss=0.8894 (C:0.8894, R:0.0105)
Batch 425/537: Loss=0.8348 (C:0.8348, R:0.0105)
Batch 450/537: Loss=0.8705 (C:0.8705, R:0.0105)
Batch 475/537: Loss=0.8682 (C:0.8682, R:0.0105)
Batch 500/537: Loss=0.8537 (C:0.8537, R:0.0105)
Batch 525/537: Loss=0.8739 (C:0.8739, R:0.0105)

============================================================
Epoch 25/300 completed in 27.7s
Train: Loss=0.8687 (C:0.8687, R:0.0105) Ratio=4.19x
Val:   Loss=0.9594 (C:0.9594, R:0.0104) Ratio=3.03x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.9594)
============================================================

Epoch 26 Training
----------------------------------------
Batch   0/537: Loss=0.8646 (C:0.8646, R:0.0105)
Batch  25/537: Loss=0.8603 (C:0.8603, R:0.0105)
Batch  50/537: Loss=0.8597 (C:0.8597, R:0.0106)
Batch  75/537: Loss=0.8788 (C:0.8788, R:0.0105)
Batch 100/537: Loss=0.8315 (C:0.8315, R:0.0105)
Batch 125/537: Loss=0.8738 (C:0.8738, R:0.0105)
Batch 150/537: Loss=0.8758 (C:0.8758, R:0.0105)
Batch 175/537: Loss=0.8665 (C:0.8665, R:0.0105)
Batch 200/537: Loss=0.8684 (C:0.8684, R:0.0105)
Batch 225/537: Loss=0.8559 (C:0.8559, R:0.0105)
Batch 250/537: Loss=0.8735 (C:0.8735, R:0.0105)
Batch 275/537: Loss=0.8698 (C:0.8698, R:0.0105)
Batch 300/537: Loss=0.8679 (C:0.8679, R:0.0105)
Batch 325/537: Loss=0.8558 (C:0.8558, R:0.0105)
Batch 350/537: Loss=0.8620 (C:0.8620, R:0.0106)
Batch 375/537: Loss=0.8497 (C:0.8497, R:0.0105)
Batch 400/537: Loss=0.8654 (C:0.8654, R:0.0105)
Batch 425/537: Loss=0.8478 (C:0.8478, R:0.0105)
Batch 450/537: Loss=0.8881 (C:0.8881, R:0.0105)
Batch 475/537: Loss=0.8851 (C:0.8851, R:0.0105)
Batch 500/537: Loss=0.8495 (C:0.8495, R:0.0105)
Batch 525/537: Loss=0.8834 (C:0.8834, R:0.0105)

============================================================
Epoch 26/300 completed in 21.0s
Train: Loss=0.8660 (C:0.8660, R:0.0105) Ratio=4.24x
Val:   Loss=0.9524 (C:0.9524, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.9524)
============================================================

Epoch 27 Training
----------------------------------------
Batch   0/537: Loss=0.8510 (C:0.8510, R:0.0105)
Batch  25/537: Loss=0.8513 (C:0.8513, R:0.0105)
Batch  50/537: Loss=0.8502 (C:0.8502, R:0.0105)
Batch  75/537: Loss=0.8330 (C:0.8330, R:0.0105)
Batch 100/537: Loss=0.8511 (C:0.8511, R:0.0105)
Batch 125/537: Loss=0.8467 (C:0.8467, R:0.0105)
Batch 150/537: Loss=0.8726 (C:0.8726, R:0.0105)
Batch 175/537: Loss=0.8686 (C:0.8686, R:0.0106)
Batch 200/537: Loss=0.8600 (C:0.8600, R:0.0106)
Batch 225/537: Loss=0.8645 (C:0.8645, R:0.0105)
Batch 250/537: Loss=0.8474 (C:0.8474, R:0.0105)
Batch 275/537: Loss=0.8628 (C:0.8628, R:0.0105)
Batch 300/537: Loss=0.8235 (C:0.8235, R:0.0105)
Batch 325/537: Loss=0.8703 (C:0.8703, R:0.0105)
Batch 350/537: Loss=0.8645 (C:0.8645, R:0.0105)
Batch 375/537: Loss=0.8609 (C:0.8609, R:0.0105)
Batch 400/537: Loss=0.8661 (C:0.8661, R:0.0105)
Batch 425/537: Loss=0.8627 (C:0.8627, R:0.0105)
Batch 450/537: Loss=0.8892 (C:0.8892, R:0.0105)
Batch 475/537: Loss=0.8677 (C:0.8677, R:0.0105)
Batch 500/537: Loss=0.8422 (C:0.8422, R:0.0105)
Batch 525/537: Loss=0.8586 (C:0.8586, R:0.0105)

============================================================
Epoch 27/300 completed in 21.0s
Train: Loss=0.8600 (C:0.8600, R:0.0105) Ratio=4.37x
Val:   Loss=0.9539 (C:0.9539, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 28
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.303 ± 0.488
    Neg distances: 1.839 ± 0.916
    Separation ratio: 6.07x
    Gap: -3.137
    ✅ Excellent global separation!

Epoch 28 Training
----------------------------------------
Batch   0/537: Loss=0.8440 (C:0.8440, R:0.0105)
Batch  25/537: Loss=0.8329 (C:0.8329, R:0.0105)
Batch  50/537: Loss=0.8043 (C:0.8043, R:0.0105)
Batch  75/537: Loss=0.8414 (C:0.8414, R:0.0105)
Batch 100/537: Loss=0.7989 (C:0.7989, R:0.0105)
Batch 125/537: Loss=0.8108 (C:0.8108, R:0.0105)
Batch 150/537: Loss=0.8658 (C:0.8658, R:0.0105)
Batch 175/537: Loss=0.8436 (C:0.8436, R:0.0105)
Batch 200/537: Loss=0.8642 (C:0.8642, R:0.0105)
Batch 225/537: Loss=0.8265 (C:0.8265, R:0.0105)
Batch 250/537: Loss=0.8200 (C:0.8200, R:0.0105)
Batch 275/537: Loss=0.8341 (C:0.8341, R:0.0105)
Batch 300/537: Loss=0.8263 (C:0.8263, R:0.0105)
Batch 325/537: Loss=0.8286 (C:0.8286, R:0.0105)
Batch 350/537: Loss=0.8375 (C:0.8375, R:0.0106)
Batch 375/537: Loss=0.8248 (C:0.8248, R:0.0105)
Batch 400/537: Loss=0.8379 (C:0.8379, R:0.0105)
Batch 425/537: Loss=0.8285 (C:0.8285, R:0.0105)
Batch 450/537: Loss=0.8537 (C:0.8537, R:0.0105)
Batch 475/537: Loss=0.8186 (C:0.8186, R:0.0105)
Batch 500/537: Loss=0.8415 (C:0.8415, R:0.0106)
Batch 525/537: Loss=0.8729 (C:0.8729, R:0.0105)

============================================================
Epoch 28/300 completed in 27.0s
Train: Loss=0.8316 (C:0.8316, R:0.0105) Ratio=4.33x
Val:   Loss=0.9269 (C:0.9269, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.9269)
============================================================

Epoch 29 Training
----------------------------------------
Batch   0/537: Loss=0.8368 (C:0.8368, R:0.0105)
Batch  25/537: Loss=0.8594 (C:0.8594, R:0.0105)
Batch  50/537: Loss=0.8080 (C:0.8080, R:0.0105)
Batch  75/537: Loss=0.8295 (C:0.8295, R:0.0105)
Batch 100/537: Loss=0.8332 (C:0.8332, R:0.0105)
Batch 125/537: Loss=0.8185 (C:0.8185, R:0.0105)
Batch 150/537: Loss=0.8049 (C:0.8049, R:0.0106)
Batch 175/537: Loss=0.8231 (C:0.8231, R:0.0105)
Batch 200/537: Loss=0.8733 (C:0.8733, R:0.0105)
Batch 225/537: Loss=0.8314 (C:0.8314, R:0.0105)
Batch 250/537: Loss=0.8381 (C:0.8381, R:0.0106)
Batch 275/537: Loss=0.8236 (C:0.8236, R:0.0105)
Batch 300/537: Loss=0.8014 (C:0.8014, R:0.0105)
Batch 325/537: Loss=0.8431 (C:0.8431, R:0.0105)
Batch 350/537: Loss=0.8349 (C:0.8349, R:0.0105)
Batch 375/537: Loss=0.8747 (C:0.8747, R:0.0105)
Batch 400/537: Loss=0.8493 (C:0.8493, R:0.0105)
Batch 425/537: Loss=0.8434 (C:0.8434, R:0.0105)
Batch 450/537: Loss=0.8197 (C:0.8197, R:0.0105)
Batch 475/537: Loss=0.8239 (C:0.8239, R:0.0105)
Batch 500/537: Loss=0.8227 (C:0.8227, R:0.0105)
Batch 525/537: Loss=0.8252 (C:0.8252, R:0.0105)

============================================================
Epoch 29/300 completed in 21.3s
Train: Loss=0.8293 (C:0.8293, R:0.0105) Ratio=4.32x
Val:   Loss=0.9311 (C:0.9311, R:0.0104) Ratio=3.02x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

Epoch 30 Training
----------------------------------------
Batch   0/537: Loss=0.8060 (C:0.8060, R:0.0105)
Batch  25/537: Loss=0.8269 (C:0.8269, R:0.0105)
Batch  50/537: Loss=0.8155 (C:0.8155, R:0.0105)
Batch  75/537: Loss=0.7983 (C:0.7983, R:0.0105)
Batch 100/537: Loss=0.8232 (C:0.8232, R:0.0105)
Batch 125/537: Loss=0.8207 (C:0.8207, R:0.0105)
Batch 150/537: Loss=0.8521 (C:0.8521, R:0.0105)
Batch 175/537: Loss=0.8217 (C:0.8217, R:0.0105)
Batch 200/537: Loss=0.8423 (C:0.8423, R:0.0105)
Batch 225/537: Loss=0.8338 (C:0.8338, R:0.0105)
Batch 250/537: Loss=0.8109 (C:0.8109, R:0.0105)
Batch 275/537: Loss=0.8367 (C:0.8367, R:0.0106)
Batch 300/537: Loss=0.8310 (C:0.8310, R:0.0105)
Batch 325/537: Loss=0.8259 (C:0.8259, R:0.0106)
Batch 350/537: Loss=0.8359 (C:0.8359, R:0.0105)
Batch 375/537: Loss=0.8237 (C:0.8237, R:0.0105)
Batch 400/537: Loss=0.8014 (C:0.8014, R:0.0105)
Batch 425/537: Loss=0.8048 (C:0.8048, R:0.0106)
Batch 450/537: Loss=0.8480 (C:0.8480, R:0.0105)
Batch 475/537: Loss=0.8449 (C:0.8449, R:0.0105)
Batch 500/537: Loss=0.8016 (C:0.8016, R:0.0105)
Batch 525/537: Loss=0.8053 (C:0.8053, R:0.0105)

============================================================
Epoch 30/300 completed in 21.0s
Train: Loss=0.8274 (C:0.8274, R:0.0105) Ratio=4.49x
Val:   Loss=0.9326 (C:0.9326, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.000
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 31
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.318 ± 0.500
    Neg distances: 1.878 ± 0.915
    Separation ratio: 5.90x
    Gap: -3.278
    ✅ Excellent global separation!

Epoch 31 Training
----------------------------------------
Batch   0/537: Loss=0.8029 (C:0.8029, R:0.0105)
Batch  25/537: Loss=0.7917 (C:0.7917, R:0.0105)
Batch  50/537: Loss=0.8140 (C:0.8140, R:0.0105)
Batch  75/537: Loss=0.8273 (C:0.8273, R:0.0105)
Batch 100/537: Loss=0.8091 (C:0.8091, R:0.0105)
Batch 125/537: Loss=0.8550 (C:0.8550, R:0.0105)
Batch 150/537: Loss=0.8051 (C:0.8051, R:0.0105)
Batch 175/537: Loss=0.8280 (C:0.8280, R:0.0105)
Batch 200/537: Loss=0.8241 (C:0.8241, R:0.0106)
Batch 225/537: Loss=0.7971 (C:0.7971, R:0.0105)
Batch 250/537: Loss=0.8091 (C:0.8091, R:0.0105)
Batch 275/537: Loss=0.8193 (C:0.8193, R:0.0105)
Batch 300/537: Loss=0.8394 (C:0.8394, R:0.0105)
Batch 325/537: Loss=0.7916 (C:0.7916, R:0.0105)
Batch 350/537: Loss=0.7996 (C:0.7996, R:0.0105)
Batch 375/537: Loss=0.8025 (C:0.8025, R:0.0105)
Batch 400/537: Loss=0.8229 (C:0.8229, R:0.0105)
Batch 425/537: Loss=0.8321 (C:0.8321, R:0.0105)
Batch 450/537: Loss=0.8022 (C:0.8022, R:0.0105)
Batch 475/537: Loss=0.8153 (C:0.8153, R:0.0105)
Batch 500/537: Loss=0.8167 (C:0.8167, R:0.0106)
Batch 525/537: Loss=0.8294 (C:0.8294, R:0.0105)

============================================================
Epoch 31/300 completed in 26.6s
Train: Loss=0.8192 (C:0.8192, R:0.0105) Ratio=4.45x
Val:   Loss=0.9236 (C:0.9236, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.015
✅ New best model saved (Val Loss: 0.9236)
============================================================

Epoch 32 Training
----------------------------------------
Batch   0/537: Loss=0.8409 (C:0.8409, R:0.0105)
Batch  25/537: Loss=0.8111 (C:0.8111, R:0.0105)
Batch  50/537: Loss=0.7896 (C:0.7896, R:0.0105)
Batch  75/537: Loss=0.7785 (C:0.7785, R:0.0105)
Batch 100/537: Loss=0.8358 (C:0.8358, R:0.0105)
Batch 125/537: Loss=0.8306 (C:0.8306, R:0.0105)
Batch 150/537: Loss=0.8222 (C:0.8222, R:0.0105)
Batch 175/537: Loss=0.7843 (C:0.7843, R:0.0105)
Batch 200/537: Loss=0.8471 (C:0.8471, R:0.0105)
Batch 225/537: Loss=0.8371 (C:0.8371, R:0.0105)
Batch 250/537: Loss=0.8296 (C:0.8296, R:0.0105)
Batch 275/537: Loss=0.7844 (C:0.7844, R:0.0105)
Batch 300/537: Loss=0.8054 (C:0.8054, R:0.0105)
Batch 325/537: Loss=0.8113 (C:0.8113, R:0.0105)
Batch 350/537: Loss=0.8322 (C:0.8322, R:0.0105)
Batch 375/537: Loss=0.8177 (C:0.8177, R:0.0105)
Batch 400/537: Loss=0.8301 (C:0.8301, R:0.0105)
Batch 425/537: Loss=0.8376 (C:0.8376, R:0.0105)
Batch 450/537: Loss=0.8049 (C:0.8049, R:0.0105)
Batch 475/537: Loss=0.8089 (C:0.8089, R:0.0105)
Batch 500/537: Loss=0.8317 (C:0.8317, R:0.0105)
Batch 525/537: Loss=0.8369 (C:0.8369, R:0.0105)

============================================================
Epoch 32/300 completed in 21.2s
Train: Loss=0.8173 (C:0.8173, R:0.0105) Ratio=4.48x
Val:   Loss=0.9243 (C:0.9243, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.030
No improvement for 1 epochs
============================================================

Epoch 33 Training
----------------------------------------
Batch   0/537: Loss=0.8126 (C:0.8126, R:0.0105)
Batch  25/537: Loss=0.8159 (C:0.8159, R:0.0105)
Batch  50/537: Loss=0.7459 (C:0.7459, R:0.0105)
Batch  75/537: Loss=0.8160 (C:0.8160, R:0.0105)
Batch 100/537: Loss=0.7903 (C:0.7903, R:0.0105)
Batch 125/537: Loss=0.8112 (C:0.8112, R:0.0105)
Batch 150/537: Loss=0.7885 (C:0.7885, R:0.0105)
Batch 175/537: Loss=0.8355 (C:0.8355, R:0.0105)
Batch 200/537: Loss=0.8055 (C:0.8055, R:0.0105)
Batch 225/537: Loss=0.8447 (C:0.8447, R:0.0105)
Batch 250/537: Loss=0.8027 (C:0.8027, R:0.0105)
Batch 275/537: Loss=0.8201 (C:0.8201, R:0.0105)
Batch 300/537: Loss=0.8005 (C:0.8005, R:0.0105)
Batch 325/537: Loss=0.8119 (C:0.8119, R:0.0105)
Batch 350/537: Loss=0.8141 (C:0.8141, R:0.0105)
Batch 375/537: Loss=0.7914 (C:0.7914, R:0.0105)
Batch 400/537: Loss=0.8146 (C:0.8146, R:0.0105)
Batch 425/537: Loss=0.8269 (C:0.8269, R:0.0105)
Batch 450/537: Loss=0.8081 (C:0.8081, R:0.0105)
Batch 475/537: Loss=0.8436 (C:0.8436, R:0.0105)
Batch 500/537: Loss=0.8395 (C:0.8395, R:0.0105)
Batch 525/537: Loss=0.8333 (C:0.8333, R:0.0105)

============================================================
Epoch 33/300 completed in 21.3s
Train: Loss=0.8145 (C:0.8145, R:0.0105) Ratio=4.50x
Val:   Loss=0.9195 (C:0.9195, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.045
✅ New best model saved (Val Loss: 0.9195)
============================================================

🌍 Updating global dataset at epoch 34
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.306 ± 0.510
    Neg distances: 1.939 ± 0.922
    Separation ratio: 6.33x
    Gap: -3.370
    ✅ Excellent global separation!

Epoch 34 Training
----------------------------------------
Batch   0/537: Loss=0.8220 (C:0.8220, R:0.0105)
Batch  25/537: Loss=0.8000 (C:0.8000, R:0.0105)
Batch  50/537: Loss=0.7874 (C:0.7874, R:0.0105)
Batch  75/537: Loss=0.7621 (C:0.7621, R:0.0105)
Batch 100/537: Loss=0.8046 (C:0.8046, R:0.0105)
Batch 125/537: Loss=0.8008 (C:0.8008, R:0.0105)
Batch 150/537: Loss=0.7665 (C:0.7665, R:0.0105)
Batch 175/537: Loss=0.7686 (C:0.7686, R:0.0105)
Batch 200/537: Loss=0.7763 (C:0.7763, R:0.0105)
Batch 225/537: Loss=0.7921 (C:0.7921, R:0.0105)
Batch 250/537: Loss=0.8210 (C:0.8210, R:0.0105)
Batch 275/537: Loss=0.8140 (C:0.8140, R:0.0105)
Batch 300/537: Loss=0.7869 (C:0.7869, R:0.0105)
Batch 325/537: Loss=0.7924 (C:0.7924, R:0.0105)
Batch 350/537: Loss=0.8236 (C:0.8236, R:0.0105)
Batch 375/537: Loss=0.8067 (C:0.8067, R:0.0105)
Batch 400/537: Loss=0.7587 (C:0.7587, R:0.0105)
Batch 425/537: Loss=0.7717 (C:0.7717, R:0.0106)
Batch 450/537: Loss=0.7779 (C:0.7779, R:0.0105)
Batch 475/537: Loss=0.7976 (C:0.7976, R:0.0105)
Batch 500/537: Loss=0.7862 (C:0.7862, R:0.0105)
Batch 525/537: Loss=0.7946 (C:0.7946, R:0.0105)

============================================================
Epoch 34/300 completed in 26.8s
Train: Loss=0.7864 (C:0.7864, R:0.0105) Ratio=4.47x
Val:   Loss=0.8962 (C:0.8962, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.060
✅ New best model saved (Val Loss: 0.8962)
============================================================

Epoch 35 Training
----------------------------------------
Batch   0/537: Loss=0.7525 (C:0.7525, R:0.0105)
Batch  25/537: Loss=0.7713 (C:0.7713, R:0.0106)
Batch  50/537: Loss=0.8007 (C:0.8007, R:0.0105)
Batch  75/537: Loss=0.7754 (C:0.7754, R:0.0105)
Batch 100/537: Loss=0.7989 (C:0.7989, R:0.0105)
Batch 125/537: Loss=0.7645 (C:0.7645, R:0.0105)
Batch 150/537: Loss=0.7769 (C:0.7769, R:0.0105)
Batch 175/537: Loss=0.7840 (C:0.7840, R:0.0105)
Batch 200/537: Loss=0.7581 (C:0.7581, R:0.0105)
Batch 225/537: Loss=0.7815 (C:0.7815, R:0.0105)
Batch 250/537: Loss=0.8069 (C:0.8069, R:0.0105)
Batch 275/537: Loss=0.8019 (C:0.8019, R:0.0105)
Batch 300/537: Loss=0.7849 (C:0.7849, R:0.0105)
Batch 325/537: Loss=0.7976 (C:0.7976, R:0.0105)
Batch 350/537: Loss=0.8020 (C:0.8020, R:0.0105)
Batch 375/537: Loss=0.7621 (C:0.7621, R:0.0105)
Batch 400/537: Loss=0.7782 (C:0.7782, R:0.0105)
Batch 425/537: Loss=0.8094 (C:0.8094, R:0.0105)
Batch 450/537: Loss=0.8414 (C:0.8414, R:0.0105)
Batch 475/537: Loss=0.7838 (C:0.7838, R:0.0105)
Batch 500/537: Loss=0.7788 (C:0.7788, R:0.0105)
Batch 525/537: Loss=0.7764 (C:0.7764, R:0.0105)

============================================================
Epoch 35/300 completed in 21.0s
Train: Loss=0.7856 (C:0.7856, R:0.0105) Ratio=4.53x
Val:   Loss=0.9041 (C:0.9041, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.075
No improvement for 1 epochs
============================================================

Epoch 36 Training
----------------------------------------
Batch   0/537: Loss=0.7860 (C:0.7860, R:0.0105)
Batch  25/537: Loss=0.7790 (C:0.7790, R:0.0105)
Batch  50/537: Loss=0.7970 (C:0.7970, R:0.0105)
Batch  75/537: Loss=0.7353 (C:0.7353, R:0.0105)
Batch 100/537: Loss=0.8047 (C:0.8047, R:0.0105)
Batch 125/537: Loss=0.8114 (C:0.8114, R:0.0105)
Batch 150/537: Loss=0.7965 (C:0.7965, R:0.0105)
Batch 175/537: Loss=0.7804 (C:0.7804, R:0.0105)
Batch 200/537: Loss=0.8063 (C:0.8063, R:0.0105)
Batch 225/537: Loss=0.7690 (C:0.7690, R:0.0105)
Batch 250/537: Loss=0.7691 (C:0.7691, R:0.0105)
Batch 275/537: Loss=0.7803 (C:0.7803, R:0.0105)
Batch 300/537: Loss=0.7893 (C:0.7893, R:0.0105)
Batch 325/537: Loss=0.7995 (C:0.7995, R:0.0105)
Batch 350/537: Loss=0.7736 (C:0.7736, R:0.0105)
Batch 375/537: Loss=0.8126 (C:0.8126, R:0.0105)
Batch 400/537: Loss=0.7865 (C:0.7865, R:0.0105)
Batch 425/537: Loss=0.7959 (C:0.7959, R:0.0105)
Batch 450/537: Loss=0.8004 (C:0.8004, R:0.0105)
Batch 475/537: Loss=0.7922 (C:0.7922, R:0.0105)
Batch 500/537: Loss=0.8229 (C:0.8229, R:0.0106)
Batch 525/537: Loss=0.7841 (C:0.7841, R:0.0105)

============================================================
Epoch 36/300 completed in 21.1s
Train: Loss=0.7828 (C:0.7828, R:0.0105) Ratio=4.47x
Val:   Loss=0.9013 (C:0.9013, R:0.0104) Ratio=3.02x
Reconstruction weight: 0.090
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 37
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.311 ± 0.492
    Neg distances: 2.006 ± 0.930
    Separation ratio: 6.45x
    Gap: -3.475
    ✅ Excellent global separation!

Epoch 37 Training
----------------------------------------
Batch   0/537: Loss=0.7768 (C:0.7768, R:0.0105)
Batch  25/537: Loss=0.7427 (C:0.7427, R:0.0105)
Batch  50/537: Loss=0.7541 (C:0.7541, R:0.0105)
Batch  75/537: Loss=0.7593 (C:0.7593, R:0.0105)
Batch 100/537: Loss=0.7253 (C:0.7253, R:0.0105)
Batch 125/537: Loss=0.7955 (C:0.7955, R:0.0105)
Batch 150/537: Loss=0.7950 (C:0.7950, R:0.0106)
Batch 175/537: Loss=0.7932 (C:0.7932, R:0.0105)
Batch 200/537: Loss=0.7667 (C:0.7667, R:0.0105)
Batch 225/537: Loss=0.7717 (C:0.7717, R:0.0105)
Batch 250/537: Loss=0.7883 (C:0.7883, R:0.0105)
Batch 275/537: Loss=0.7464 (C:0.7464, R:0.0105)
Batch 300/537: Loss=0.7745 (C:0.7745, R:0.0105)
Batch 325/537: Loss=0.8040 (C:0.8040, R:0.0105)
Batch 350/537: Loss=0.7582 (C:0.7582, R:0.0105)
Batch 375/537: Loss=0.7645 (C:0.7645, R:0.0105)
Batch 400/537: Loss=0.7583 (C:0.7583, R:0.0105)
Batch 425/537: Loss=0.7966 (C:0.7966, R:0.0105)
Batch 450/537: Loss=0.7860 (C:0.7860, R:0.0105)
Batch 475/537: Loss=0.7676 (C:0.7676, R:0.0105)
Batch 500/537: Loss=0.7766 (C:0.7766, R:0.0105)
Batch 525/537: Loss=0.7503 (C:0.7503, R:0.0105)

============================================================
Epoch 37/300 completed in 26.9s
Train: Loss=0.7605 (C:0.7605, R:0.0105) Ratio=4.48x
Val:   Loss=0.8789 (C:0.8789, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.105
✅ New best model saved (Val Loss: 0.8789)
============================================================

Epoch 38 Training
----------------------------------------
Batch   0/537: Loss=0.7457 (C:0.7457, R:0.0105)
Batch  25/537: Loss=0.7430 (C:0.7430, R:0.0105)
Batch  50/537: Loss=0.7439 (C:0.7439, R:0.0105)
Batch  75/537: Loss=0.7607 (C:0.7607, R:0.0105)
Batch 100/537: Loss=0.7156 (C:0.7156, R:0.0105)
Batch 125/537: Loss=0.7480 (C:0.7480, R:0.0105)
Batch 150/537: Loss=0.7411 (C:0.7411, R:0.0105)
Batch 175/537: Loss=0.7666 (C:0.7666, R:0.0105)
Batch 200/537: Loss=0.7727 (C:0.7727, R:0.0105)
Batch 225/537: Loss=0.7362 (C:0.7362, R:0.0105)
Batch 250/537: Loss=0.7606 (C:0.7606, R:0.0105)
Batch 275/537: Loss=0.7580 (C:0.7580, R:0.0105)
Batch 300/537: Loss=0.7524 (C:0.7524, R:0.0105)
Batch 325/537: Loss=0.7638 (C:0.7638, R:0.0105)
Batch 350/537: Loss=0.7533 (C:0.7533, R:0.0105)
Batch 375/537: Loss=0.7547 (C:0.7547, R:0.0105)
Batch 400/537: Loss=0.7872 (C:0.7872, R:0.0105)
Batch 425/537: Loss=0.7806 (C:0.7806, R:0.0106)
Batch 450/537: Loss=0.7751 (C:0.7751, R:0.0105)
Batch 475/537: Loss=0.7893 (C:0.7893, R:0.0105)
Batch 500/537: Loss=0.7907 (C:0.7907, R:0.0105)
Batch 525/537: Loss=0.7784 (C:0.7784, R:0.0105)

============================================================
Epoch 38/300 completed in 21.1s
Train: Loss=0.7595 (C:0.7595, R:0.0105) Ratio=4.61x
Val:   Loss=0.8731 (C:0.8731, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.120
✅ New best model saved (Val Loss: 0.8731)
============================================================

Epoch 39 Training
----------------------------------------
Batch   0/537: Loss=0.7366 (C:0.7366, R:0.0106)
Batch  25/537: Loss=0.7486 (C:0.7486, R:0.0105)
Batch  50/537: Loss=0.7316 (C:0.7316, R:0.0105)
Batch  75/537: Loss=0.7865 (C:0.7865, R:0.0106)
Batch 100/537: Loss=0.7467 (C:0.7467, R:0.0105)
Batch 125/537: Loss=0.7364 (C:0.7364, R:0.0105)
Batch 150/537: Loss=0.7254 (C:0.7254, R:0.0105)
Batch 175/537: Loss=0.7517 (C:0.7517, R:0.0105)
Batch 200/537: Loss=0.7571 (C:0.7571, R:0.0105)
Batch 225/537: Loss=0.7445 (C:0.7445, R:0.0105)
Batch 250/537: Loss=0.7435 (C:0.7435, R:0.0105)
Batch 275/537: Loss=0.7767 (C:0.7767, R:0.0105)
Batch 300/537: Loss=0.7573 (C:0.7573, R:0.0105)
Batch 325/537: Loss=0.7560 (C:0.7560, R:0.0105)
Batch 350/537: Loss=0.7571 (C:0.7571, R:0.0105)
Batch 375/537: Loss=0.7722 (C:0.7722, R:0.0105)
Batch 400/537: Loss=0.7700 (C:0.7700, R:0.0105)
Batch 425/537: Loss=0.7598 (C:0.7598, R:0.0105)
Batch 450/537: Loss=0.7638 (C:0.7638, R:0.0105)
Batch 475/537: Loss=0.7604 (C:0.7604, R:0.0105)
Batch 500/537: Loss=0.7606 (C:0.7606, R:0.0105)
Batch 525/537: Loss=0.7604 (C:0.7604, R:0.0105)

============================================================
Epoch 39/300 completed in 21.1s
Train: Loss=0.7573 (C:0.7573, R:0.0105) Ratio=4.59x
Val:   Loss=0.8832 (C:0.8832, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.135
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 40
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.308 ± 0.510
    Neg distances: 2.085 ± 0.953
    Separation ratio: 6.78x
    Gap: -3.497
    ✅ Excellent global separation!

Epoch 40 Training
----------------------------------------
Batch   0/537: Loss=0.7426 (C:0.7426, R:0.0105)
Batch  25/537: Loss=0.7359 (C:0.7359, R:0.0105)
Batch  50/537: Loss=0.7369 (C:0.7369, R:0.0105)
Batch  75/537: Loss=0.7350 (C:0.7350, R:0.0105)
Batch 100/537: Loss=0.7588 (C:0.7588, R:0.0105)
Batch 125/537: Loss=0.7095 (C:0.7095, R:0.0105)
Batch 150/537: Loss=0.7503 (C:0.7503, R:0.0105)
Batch 175/537: Loss=0.7258 (C:0.7258, R:0.0105)
Batch 200/537: Loss=0.7144 (C:0.7144, R:0.0105)
Batch 225/537: Loss=0.7306 (C:0.7306, R:0.0105)
Batch 250/537: Loss=0.7431 (C:0.7431, R:0.0105)
Batch 275/537: Loss=0.7401 (C:0.7401, R:0.0105)
Batch 300/537: Loss=0.7708 (C:0.7708, R:0.0105)
Batch 325/537: Loss=0.7273 (C:0.7273, R:0.0105)
Batch 350/537: Loss=0.7437 (C:0.7437, R:0.0105)
Batch 375/537: Loss=0.7440 (C:0.7440, R:0.0105)
Batch 400/537: Loss=0.7218 (C:0.7218, R:0.0105)
Batch 425/537: Loss=0.7521 (C:0.7521, R:0.0105)
Batch 450/537: Loss=0.7361 (C:0.7361, R:0.0105)
Batch 475/537: Loss=0.7384 (C:0.7384, R:0.0105)
Batch 500/537: Loss=0.7282 (C:0.7282, R:0.0105)
Batch 525/537: Loss=0.7270 (C:0.7270, R:0.0105)

============================================================
Epoch 40/300 completed in 27.3s
Train: Loss=0.7345 (C:0.7345, R:0.0105) Ratio=4.61x
Val:   Loss=0.8634 (C:0.8634, R:0.0104) Ratio=3.03x
Reconstruction weight: 0.150
✅ New best model saved (Val Loss: 0.8634)
Checkpoint saved at epoch 40
============================================================

Epoch 41 Training
----------------------------------------
Batch   0/537: Loss=0.7504 (C:0.7504, R:0.0106)
Batch  25/537: Loss=0.7112 (C:0.7112, R:0.0105)
Batch  50/537: Loss=0.7211 (C:0.7211, R:0.0105)
Batch  75/537: Loss=0.7354 (C:0.7354, R:0.0105)
Batch 100/537: Loss=0.7211 (C:0.7211, R:0.0105)
Batch 125/537: Loss=0.7313 (C:0.7313, R:0.0105)
Batch 150/537: Loss=0.7755 (C:0.7755, R:0.0104)
Batch 175/537: Loss=0.7151 (C:0.7151, R:0.0105)
Batch 200/537: Loss=0.7218 (C:0.7218, R:0.0105)
Batch 225/537: Loss=0.7276 (C:0.7276, R:0.0105)
Batch 250/537: Loss=0.7182 (C:0.7182, R:0.0105)
Batch 275/537: Loss=0.7381 (C:0.7381, R:0.0105)
Batch 300/537: Loss=0.7599 (C:0.7599, R:0.0105)
Batch 325/537: Loss=0.7119 (C:0.7119, R:0.0105)
Batch 350/537: Loss=0.7376 (C:0.7376, R:0.0105)
Batch 375/537: Loss=0.7422 (C:0.7422, R:0.0105)
Batch 400/537: Loss=0.7211 (C:0.7211, R:0.0105)
Batch 425/537: Loss=0.7467 (C:0.7467, R:0.0105)
Batch 450/537: Loss=0.7506 (C:0.7506, R:0.0105)
Batch 475/537: Loss=0.7202 (C:0.7202, R:0.0105)
Batch 500/537: Loss=0.7432 (C:0.7432, R:0.0105)
Batch 525/537: Loss=0.7418 (C:0.7418, R:0.0105)

============================================================
Epoch 41/300 completed in 21.3s
Train: Loss=0.7333 (C:0.7333, R:0.0105) Ratio=4.66x
Val:   Loss=0.8587 (C:0.8587, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.165
✅ New best model saved (Val Loss: 0.8587)
============================================================

Epoch 42 Training
----------------------------------------
Batch   0/537: Loss=0.7282 (C:0.7282, R:0.0105)
Batch  25/537: Loss=0.7373 (C:0.7373, R:0.0105)
Batch  50/537: Loss=0.7402 (C:0.7402, R:0.0106)
Batch  75/537: Loss=0.7429 (C:0.7429, R:0.0105)
Batch 100/537: Loss=0.7199 (C:0.7199, R:0.0105)
Batch 125/537: Loss=0.7694 (C:0.7694, R:0.0105)
Batch 150/537: Loss=0.7505 (C:0.7505, R:0.0105)
Batch 175/537: Loss=0.7250 (C:0.7250, R:0.0105)
Batch 200/537: Loss=0.7367 (C:0.7367, R:0.0105)
Batch 225/537: Loss=0.7423 (C:0.7423, R:0.0105)
Batch 250/537: Loss=0.7235 (C:0.7235, R:0.0105)
Batch 275/537: Loss=0.7511 (C:0.7511, R:0.0105)
Batch 300/537: Loss=0.7272 (C:0.7272, R:0.0105)
Batch 325/537: Loss=0.7055 (C:0.7055, R:0.0105)
Batch 350/537: Loss=0.7636 (C:0.7636, R:0.0105)
Batch 375/537: Loss=0.7355 (C:0.7355, R:0.0105)
Batch 400/537: Loss=0.7846 (C:0.7846, R:0.0105)
Batch 425/537: Loss=0.7177 (C:0.7177, R:0.0105)
Batch 450/537: Loss=0.7691 (C:0.7691, R:0.0105)
Batch 475/537: Loss=0.6921 (C:0.6921, R:0.0105)
Batch 500/537: Loss=0.7334 (C:0.7334, R:0.0105)
Batch 525/537: Loss=0.7478 (C:0.7478, R:0.0105)

============================================================
Epoch 42/300 completed in 21.4s
Train: Loss=0.7321 (C:0.7321, R:0.0105) Ratio=4.66x
Val:   Loss=0.8548 (C:0.8548, R:0.0104) Ratio=3.03x
Reconstruction weight: 0.180
✅ New best model saved (Val Loss: 0.8548)
============================================================

🌍 Updating global dataset at epoch 43
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.307 ± 0.486
    Neg distances: 2.144 ± 0.961
    Separation ratio: 6.99x
    Gap: -3.672
    ✅ Excellent global separation!

Epoch 43 Training
----------------------------------------
Batch   0/537: Loss=0.6974 (C:0.6974, R:0.0105)
Batch  25/537: Loss=0.7326 (C:0.7326, R:0.0105)
Batch  50/537: Loss=0.7061 (C:0.7061, R:0.0105)
Batch  75/537: Loss=0.7208 (C:0.7208, R:0.0105)
Batch 100/537: Loss=0.7404 (C:0.7404, R:0.0105)
Batch 125/537: Loss=0.7072 (C:0.7072, R:0.0105)
Batch 150/537: Loss=0.6955 (C:0.6955, R:0.0105)
Batch 175/537: Loss=0.6941 (C:0.6941, R:0.0105)
Batch 200/537: Loss=0.7142 (C:0.7142, R:0.0105)
Batch 225/537: Loss=0.7349 (C:0.7349, R:0.0105)
Batch 250/537: Loss=0.7178 (C:0.7178, R:0.0105)
Batch 275/537: Loss=0.6922 (C:0.6922, R:0.0105)
Batch 300/537: Loss=0.7202 (C:0.7202, R:0.0105)
Batch 325/537: Loss=0.7287 (C:0.7287, R:0.0105)
Batch 350/537: Loss=0.7095 (C:0.7095, R:0.0105)
Batch 375/537: Loss=0.7209 (C:0.7209, R:0.0105)
Batch 400/537: Loss=0.7227 (C:0.7227, R:0.0105)
Batch 425/537: Loss=0.7277 (C:0.7277, R:0.0105)
Batch 450/537: Loss=0.7153 (C:0.7153, R:0.0105)
Batch 475/537: Loss=0.6785 (C:0.6785, R:0.0105)
Batch 500/537: Loss=0.6868 (C:0.6868, R:0.0105)
Batch 525/537: Loss=0.7369 (C:0.7369, R:0.0105)

============================================================
Epoch 43/300 completed in 26.8s
Train: Loss=0.7080 (C:0.7080, R:0.0105) Ratio=4.57x
Val:   Loss=0.8486 (C:0.8486, R:0.0104) Ratio=3.02x
Reconstruction weight: 0.195
✅ New best model saved (Val Loss: 0.8486)
============================================================

Epoch 44 Training
----------------------------------------
Batch   0/537: Loss=0.7152 (C:0.7152, R:0.0105)
Batch  25/537: Loss=0.7026 (C:0.7026, R:0.0105)
Batch  50/537: Loss=0.6973 (C:0.6973, R:0.0105)
Batch  75/537: Loss=0.6898 (C:0.6898, R:0.0105)
Batch 100/537: Loss=0.7361 (C:0.7361, R:0.0105)
Batch 125/537: Loss=0.7211 (C:0.7211, R:0.0105)
Batch 150/537: Loss=0.7034 (C:0.7034, R:0.0105)
Batch 175/537: Loss=0.6918 (C:0.6918, R:0.0105)
Batch 200/537: Loss=0.6914 (C:0.6914, R:0.0105)
Batch 225/537: Loss=0.7299 (C:0.7299, R:0.0105)
Batch 250/537: Loss=0.7540 (C:0.7540, R:0.0105)
Batch 275/537: Loss=0.7469 (C:0.7469, R:0.0105)
Batch 300/537: Loss=0.7302 (C:0.7302, R:0.0105)
Batch 325/537: Loss=0.7028 (C:0.7028, R:0.0105)
Batch 350/537: Loss=0.7236 (C:0.7236, R:0.0105)
Batch 375/537: Loss=0.6823 (C:0.6823, R:0.0105)
Batch 400/537: Loss=0.7678 (C:0.7678, R:0.0105)
Batch 425/537: Loss=0.7112 (C:0.7112, R:0.0105)
Batch 450/537: Loss=0.7147 (C:0.7147, R:0.0105)
Batch 475/537: Loss=0.6844 (C:0.6844, R:0.0105)
Batch 500/537: Loss=0.7285 (C:0.7285, R:0.0105)
Batch 525/537: Loss=0.7172 (C:0.7172, R:0.0105)

============================================================
Epoch 44/300 completed in 20.9s
Train: Loss=0.7063 (C:0.7063, R:0.0105) Ratio=4.61x
Val:   Loss=0.8426 (C:0.8426, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.210
✅ New best model saved (Val Loss: 0.8426)
============================================================

Epoch 45 Training
----------------------------------------
Batch   0/537: Loss=0.7002 (C:0.7002, R:0.0105)
Batch  25/537: Loss=0.6972 (C:0.6972, R:0.0105)
Batch  50/537: Loss=0.7148 (C:0.7148, R:0.0105)
Batch  75/537: Loss=0.6730 (C:0.6730, R:0.0105)
Batch 100/537: Loss=0.7082 (C:0.7082, R:0.0105)
Batch 125/537: Loss=0.6953 (C:0.6953, R:0.0105)
Batch 150/537: Loss=0.7138 (C:0.7138, R:0.0105)
Batch 175/537: Loss=0.7045 (C:0.7045, R:0.0105)
Batch 200/537: Loss=0.6954 (C:0.6954, R:0.0106)
Batch 225/537: Loss=0.7057 (C:0.7057, R:0.0105)
Batch 250/537: Loss=0.6600 (C:0.6600, R:0.0105)
Batch 275/537: Loss=0.7090 (C:0.7090, R:0.0105)
Batch 300/537: Loss=0.6785 (C:0.6785, R:0.0105)
Batch 325/537: Loss=0.6930 (C:0.6930, R:0.0105)
Batch 350/537: Loss=0.6834 (C:0.6834, R:0.0105)
Batch 375/537: Loss=0.7403 (C:0.7403, R:0.0105)
Batch 400/537: Loss=0.7057 (C:0.7057, R:0.0105)
Batch 425/537: Loss=0.7234 (C:0.7234, R:0.0105)
Batch 450/537: Loss=0.6768 (C:0.6768, R:0.0105)
Batch 475/537: Loss=0.7166 (C:0.7166, R:0.0105)
Batch 500/537: Loss=0.6920 (C:0.6920, R:0.0105)
Batch 525/537: Loss=0.7040 (C:0.7040, R:0.0105)

============================================================
Epoch 45/300 completed in 21.1s
Train: Loss=0.7046 (C:0.7046, R:0.0105) Ratio=4.83x
Val:   Loss=0.8410 (C:0.8410, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.225
✅ New best model saved (Val Loss: 0.8410)
============================================================

🌍 Updating global dataset at epoch 46
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.320 ± 0.527
    Neg distances: 2.233 ± 0.993
    Separation ratio: 6.98x
    Gap: -3.724
    ✅ Excellent global separation!

Epoch 46 Training
----------------------------------------
Batch   0/537: Loss=0.6665 (C:0.6665, R:0.0105)
Batch  25/537: Loss=0.6990 (C:0.6990, R:0.0105)
Batch  50/537: Loss=0.7002 (C:0.7002, R:0.0105)
Batch  75/537: Loss=0.7029 (C:0.7029, R:0.0106)
Batch 100/537: Loss=0.7531 (C:0.7531, R:0.0105)
Batch 125/537: Loss=0.6972 (C:0.6972, R:0.0105)
Batch 150/537: Loss=0.6707 (C:0.6707, R:0.0105)
Batch 175/537: Loss=0.6918 (C:0.6918, R:0.0105)
Batch 200/537: Loss=0.6913 (C:0.6913, R:0.0105)
Batch 225/537: Loss=0.6985 (C:0.6985, R:0.0105)
Batch 250/537: Loss=0.6928 (C:0.6928, R:0.0105)
Batch 275/537: Loss=0.6764 (C:0.6764, R:0.0105)
Batch 300/537: Loss=0.6915 (C:0.6915, R:0.0105)
Batch 325/537: Loss=0.6938 (C:0.6938, R:0.0105)
Batch 350/537: Loss=0.6932 (C:0.6932, R:0.0105)
Batch 375/537: Loss=0.6810 (C:0.6810, R:0.0105)
Batch 400/537: Loss=0.6952 (C:0.6952, R:0.0105)
Batch 425/537: Loss=0.7067 (C:0.7067, R:0.0105)
Batch 450/537: Loss=0.6789 (C:0.6789, R:0.0105)
Batch 475/537: Loss=0.6813 (C:0.6813, R:0.0105)
Batch 500/537: Loss=0.7102 (C:0.7102, R:0.0105)
Batch 525/537: Loss=0.7202 (C:0.7202, R:0.0105)

============================================================
Epoch 46/300 completed in 27.4s
Train: Loss=0.6886 (C:0.6886, R:0.0105) Ratio=4.64x
Val:   Loss=0.8177 (C:0.8177, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.240
✅ New best model saved (Val Loss: 0.8177)
============================================================

Epoch 47 Training
----------------------------------------
Batch   0/537: Loss=0.7290 (C:0.7290, R:0.0105)
Batch  25/537: Loss=0.6801 (C:0.6801, R:0.0105)
Batch  50/537: Loss=0.6835 (C:0.6835, R:0.0105)
Batch  75/537: Loss=0.6816 (C:0.6816, R:0.0105)
Batch 100/537: Loss=0.6539 (C:0.6539, R:0.0105)
Batch 125/537: Loss=0.6469 (C:0.6469, R:0.0105)
Batch 150/537: Loss=0.6649 (C:0.6649, R:0.0105)
Batch 175/537: Loss=0.7023 (C:0.7023, R:0.0105)
Batch 200/537: Loss=0.6819 (C:0.6819, R:0.0105)
Batch 225/537: Loss=0.6813 (C:0.6813, R:0.0105)
Batch 250/537: Loss=0.6902 (C:0.6902, R:0.0105)
Batch 275/537: Loss=0.6894 (C:0.6894, R:0.0105)
Batch 300/537: Loss=0.6934 (C:0.6934, R:0.0105)
Batch 325/537: Loss=0.6759 (C:0.6759, R:0.0105)
Batch 350/537: Loss=0.7016 (C:0.7016, R:0.0105)
Batch 375/537: Loss=0.6978 (C:0.6978, R:0.0105)
Batch 400/537: Loss=0.6943 (C:0.6943, R:0.0105)
Batch 425/537: Loss=0.7052 (C:0.7052, R:0.0105)
Batch 450/537: Loss=0.7068 (C:0.7068, R:0.0105)
Batch 475/537: Loss=0.6632 (C:0.6632, R:0.0105)
Batch 500/537: Loss=0.6949 (C:0.6949, R:0.0105)
Batch 525/537: Loss=0.6634 (C:0.6634, R:0.0105)

============================================================
Epoch 47/300 completed in 21.4s
Train: Loss=0.6876 (C:0.6876, R:0.0105) Ratio=4.78x
Val:   Loss=0.8185 (C:0.8185, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.255
No improvement for 1 epochs
============================================================

Epoch 48 Training
----------------------------------------
Batch   0/537: Loss=0.6633 (C:0.6633, R:0.0105)
Batch  25/537: Loss=0.6461 (C:0.6461, R:0.0105)
Batch  50/537: Loss=0.6690 (C:0.6690, R:0.0105)
Batch  75/537: Loss=0.6889 (C:0.6889, R:0.0105)
Batch 100/537: Loss=0.6779 (C:0.6779, R:0.0105)
Batch 125/537: Loss=0.7261 (C:0.7261, R:0.0105)
Batch 150/537: Loss=0.6898 (C:0.6898, R:0.0105)
Batch 175/537: Loss=0.6579 (C:0.6579, R:0.0105)
Batch 200/537: Loss=0.7061 (C:0.7061, R:0.0105)
Batch 225/537: Loss=0.6821 (C:0.6821, R:0.0105)
Batch 250/537: Loss=0.6732 (C:0.6732, R:0.0105)
Batch 275/537: Loss=0.7028 (C:0.7028, R:0.0105)
Batch 300/537: Loss=0.7059 (C:0.7059, R:0.0105)
Batch 325/537: Loss=0.6882 (C:0.6882, R:0.0105)
Batch 350/537: Loss=0.6954 (C:0.6954, R:0.0105)
Batch 375/537: Loss=0.6757 (C:0.6757, R:0.0105)
Batch 400/537: Loss=0.7021 (C:0.7021, R:0.0105)
Batch 425/537: Loss=0.7064 (C:0.7064, R:0.0105)
Batch 450/537: Loss=0.6967 (C:0.6967, R:0.0105)
Batch 475/537: Loss=0.6778 (C:0.6778, R:0.0105)
Batch 500/537: Loss=0.6878 (C:0.6878, R:0.0105)
Batch 525/537: Loss=0.6839 (C:0.6839, R:0.0105)

============================================================
Epoch 48/300 completed in 21.2s
Train: Loss=0.6868 (C:0.6868, R:0.0105) Ratio=4.80x
Val:   Loss=0.8177 (C:0.8177, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.270
✅ New best model saved (Val Loss: 0.8177)
============================================================

🌍 Updating global dataset at epoch 49
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.323 ± 0.551
    Neg distances: 2.286 ± 1.007
    Separation ratio: 7.09x
    Gap: -3.846
    ✅ Excellent global separation!

Epoch 49 Training
----------------------------------------
Batch   0/537: Loss=0.6591 (C:0.6591, R:0.0105)
Batch  25/537: Loss=0.6748 (C:0.6748, R:0.0105)
Batch  50/537: Loss=0.6816 (C:0.6816, R:0.0105)
Batch  75/537: Loss=0.6924 (C:0.6924, R:0.0105)
Batch 100/537: Loss=0.6575 (C:0.6575, R:0.0105)
Batch 125/537: Loss=0.6613 (C:0.6613, R:0.0105)
Batch 150/537: Loss=0.6502 (C:0.6502, R:0.0105)
Batch 175/537: Loss=0.6757 (C:0.6757, R:0.0105)
Batch 200/537: Loss=0.6902 (C:0.6902, R:0.0105)
Batch 225/537: Loss=0.6750 (C:0.6750, R:0.0106)
Batch 250/537: Loss=0.6874 (C:0.6874, R:0.0105)
Batch 275/537: Loss=0.6548 (C:0.6548, R:0.0105)
Batch 300/537: Loss=0.6708 (C:0.6708, R:0.0105)
Batch 325/537: Loss=0.7024 (C:0.7024, R:0.0105)
Batch 350/537: Loss=0.6772 (C:0.6772, R:0.0105)
Batch 375/537: Loss=0.6506 (C:0.6506, R:0.0105)
Batch 400/537: Loss=0.6700 (C:0.6700, R:0.0105)
Batch 425/537: Loss=0.6809 (C:0.6809, R:0.0105)
Batch 450/537: Loss=0.7138 (C:0.7138, R:0.0105)
Batch 475/537: Loss=0.6574 (C:0.6574, R:0.0105)
Batch 500/537: Loss=0.6587 (C:0.6587, R:0.0105)
Batch 525/537: Loss=0.7171 (C:0.7171, R:0.0105)

============================================================
Epoch 49/300 completed in 27.0s
Train: Loss=0.6731 (C:0.6731, R:0.0105) Ratio=4.76x
Val:   Loss=0.8062 (C:0.8062, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.285
✅ New best model saved (Val Loss: 0.8062)
============================================================

Epoch 50 Training
----------------------------------------
Batch   0/537: Loss=0.6797 (C:0.6797, R:0.0105)
Batch  25/537: Loss=0.6802 (C:0.6802, R:0.0105)
Batch  50/537: Loss=0.6804 (C:0.6804, R:0.0105)
Batch  75/537: Loss=0.6903 (C:0.6903, R:0.0105)
Batch 100/537: Loss=0.6739 (C:0.6739, R:0.0105)
Batch 125/537: Loss=0.6764 (C:0.6764, R:0.0105)
Batch 150/537: Loss=0.6633 (C:0.6633, R:0.0105)
Batch 175/537: Loss=0.6512 (C:0.6512, R:0.0105)
Batch 200/537: Loss=0.7281 (C:0.7281, R:0.0105)
Batch 225/537: Loss=0.6764 (C:0.6764, R:0.0105)
Batch 250/537: Loss=0.6809 (C:0.6809, R:0.0105)
Batch 275/537: Loss=0.6816 (C:0.6816, R:0.0105)
Batch 300/537: Loss=0.6750 (C:0.6750, R:0.0105)
Batch 325/537: Loss=0.6403 (C:0.6403, R:0.0106)
Batch 350/537: Loss=0.6694 (C:0.6694, R:0.0105)
Batch 375/537: Loss=0.7139 (C:0.7139, R:0.0105)
Batch 400/537: Loss=0.6370 (C:0.6370, R:0.0105)
Batch 425/537: Loss=0.6708 (C:0.6708, R:0.0105)
Batch 450/537: Loss=0.6664 (C:0.6664, R:0.0105)
Batch 475/537: Loss=0.6632 (C:0.6632, R:0.0105)
Batch 500/537: Loss=0.6541 (C:0.6541, R:0.0105)
Batch 525/537: Loss=0.6795 (C:0.6795, R:0.0105)

============================================================
Epoch 50/300 completed in 21.1s
Train: Loss=0.6716 (C:0.6716, R:0.0105) Ratio=4.82x
Val:   Loss=0.8145 (C:0.8145, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

Epoch 51 Training
----------------------------------------
Batch   0/537: Loss=0.6488 (C:0.6488, R:0.0105)
Batch  25/537: Loss=0.6600 (C:0.6600, R:0.0105)
Batch  50/537: Loss=0.6588 (C:0.6588, R:0.0105)
Batch  75/537: Loss=0.6872 (C:0.6872, R:0.0105)
Batch 100/537: Loss=0.6517 (C:0.6517, R:0.0105)
Batch 125/537: Loss=0.6519 (C:0.6519, R:0.0105)
Batch 150/537: Loss=0.6700 (C:0.6700, R:0.0105)
Batch 175/537: Loss=0.6666 (C:0.6666, R:0.0106)
Batch 200/537: Loss=0.6697 (C:0.6697, R:0.0105)
Batch 225/537: Loss=0.6994 (C:0.6994, R:0.0105)
Batch 250/537: Loss=0.6819 (C:0.6819, R:0.0105)
Batch 275/537: Loss=0.6226 (C:0.6226, R:0.0105)
Batch 300/537: Loss=0.6832 (C:0.6832, R:0.0105)
Batch 325/537: Loss=0.6304 (C:0.6304, R:0.0105)
Batch 350/537: Loss=0.6961 (C:0.6961, R:0.0105)
Batch 375/537: Loss=0.6565 (C:0.6565, R:0.0105)
Batch 400/537: Loss=0.6751 (C:0.6751, R:0.0105)
Batch 425/537: Loss=0.6593 (C:0.6593, R:0.0105)
Batch 450/537: Loss=0.6679 (C:0.6679, R:0.0105)
Batch 475/537: Loss=0.6565 (C:0.6565, R:0.0105)
Batch 500/537: Loss=0.6535 (C:0.6535, R:0.0105)
Batch 525/537: Loss=0.6933 (C:0.6933, R:0.0105)

============================================================
Epoch 51/300 completed in 21.3s
Train: Loss=0.6695 (C:0.6695, R:0.0105) Ratio=4.80x
Val:   Loss=0.7995 (C:0.7995, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.7995)
============================================================

🌍 Updating global dataset at epoch 52
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.335 ± 0.571
    Neg distances: 2.324 ± 1.019
    Separation ratio: 6.94x
    Gap: -3.888
    ✅ Excellent global separation!

Epoch 52 Training
----------------------------------------
Batch   0/537: Loss=0.6841 (C:0.6841, R:0.0105)
Batch  25/537: Loss=0.6595 (C:0.6595, R:0.0105)
Batch  50/537: Loss=0.6665 (C:0.6665, R:0.0105)
Batch  75/537: Loss=0.6518 (C:0.6518, R:0.0105)
Batch 100/537: Loss=0.6593 (C:0.6593, R:0.0105)
Batch 125/537: Loss=0.6678 (C:0.6678, R:0.0105)
Batch 150/537: Loss=0.6167 (C:0.6167, R:0.0105)
Batch 175/537: Loss=0.7130 (C:0.7130, R:0.0105)
Batch 200/537: Loss=0.6776 (C:0.6776, R:0.0105)
Batch 225/537: Loss=0.7012 (C:0.7012, R:0.0106)
Batch 250/537: Loss=0.6809 (C:0.6809, R:0.0106)
Batch 275/537: Loss=0.6485 (C:0.6485, R:0.0105)
Batch 300/537: Loss=0.6570 (C:0.6570, R:0.0105)
Batch 325/537: Loss=0.6622 (C:0.6622, R:0.0105)
Batch 350/537: Loss=0.6473 (C:0.6473, R:0.0105)
Batch 375/537: Loss=0.6600 (C:0.6600, R:0.0105)
Batch 400/537: Loss=0.6362 (C:0.6362, R:0.0105)
Batch 425/537: Loss=0.6622 (C:0.6622, R:0.0105)
Batch 450/537: Loss=0.6649 (C:0.6649, R:0.0105)
Batch 475/537: Loss=0.7029 (C:0.7029, R:0.0105)
Batch 500/537: Loss=0.6473 (C:0.6473, R:0.0106)
Batch 525/537: Loss=0.6706 (C:0.6706, R:0.0105)

============================================================
Epoch 52/300 completed in 26.8s
Train: Loss=0.6629 (C:0.6629, R:0.0105) Ratio=4.80x
Val:   Loss=0.8195 (C:0.8195, R:0.0104) Ratio=3.02x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

Epoch 53 Training
----------------------------------------
Batch   0/537: Loss=0.6318 (C:0.6318, R:0.0105)
Batch  25/537: Loss=0.6323 (C:0.6323, R:0.0105)
Batch  50/537: Loss=0.6838 (C:0.6838, R:0.0105)
Batch  75/537: Loss=0.6695 (C:0.6695, R:0.0105)
Batch 100/537: Loss=0.6484 (C:0.6484, R:0.0105)
Batch 125/537: Loss=0.6506 (C:0.6506, R:0.0105)
Batch 150/537: Loss=0.6320 (C:0.6320, R:0.0105)
Batch 175/537: Loss=0.6267 (C:0.6267, R:0.0105)
Batch 200/537: Loss=0.6828 (C:0.6828, R:0.0105)
Batch 225/537: Loss=0.6760 (C:0.6760, R:0.0106)
Batch 250/537: Loss=0.6155 (C:0.6155, R:0.0105)
Batch 275/537: Loss=0.6475 (C:0.6475, R:0.0106)
Batch 300/537: Loss=0.6684 (C:0.6684, R:0.0105)
Batch 325/537: Loss=0.6638 (C:0.6638, R:0.0105)
Batch 350/537: Loss=0.6466 (C:0.6466, R:0.0105)
Batch 375/537: Loss=0.6942 (C:0.6942, R:0.0105)
Batch 400/537: Loss=0.6963 (C:0.6963, R:0.0105)
Batch 425/537: Loss=0.6431 (C:0.6431, R:0.0105)
Batch 450/537: Loss=0.6407 (C:0.6407, R:0.0105)
Batch 475/537: Loss=0.6397 (C:0.6397, R:0.0105)
Batch 500/537: Loss=0.6686 (C:0.6686, R:0.0105)
Batch 525/537: Loss=0.6424 (C:0.6424, R:0.0105)

============================================================
Epoch 53/300 completed in 20.9s
Train: Loss=0.6599 (C:0.6599, R:0.0105) Ratio=4.89x
Val:   Loss=0.7994 (C:0.7994, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.7994)
============================================================

Epoch 54 Training
----------------------------------------
Batch   0/537: Loss=0.6432 (C:0.6432, R:0.0105)
Batch  25/537: Loss=0.6606 (C:0.6606, R:0.0105)
Batch  50/537: Loss=0.6534 (C:0.6534, R:0.0105)
Batch  75/537: Loss=0.6407 (C:0.6407, R:0.0105)
Batch 100/537: Loss=0.6674 (C:0.6674, R:0.0105)
Batch 125/537: Loss=0.6535 (C:0.6535, R:0.0105)
Batch 150/537: Loss=0.6563 (C:0.6563, R:0.0105)
Batch 175/537: Loss=0.6824 (C:0.6824, R:0.0105)
Batch 200/537: Loss=0.6627 (C:0.6627, R:0.0105)
Batch 225/537: Loss=0.6471 (C:0.6471, R:0.0105)
Batch 250/537: Loss=0.6875 (C:0.6875, R:0.0105)
Batch 275/537: Loss=0.6456 (C:0.6456, R:0.0105)
Batch 300/537: Loss=0.6775 (C:0.6775, R:0.0105)
Batch 325/537: Loss=0.6516 (C:0.6516, R:0.0105)
Batch 350/537: Loss=0.6448 (C:0.6448, R:0.0105)
Batch 375/537: Loss=0.6632 (C:0.6632, R:0.0105)
Batch 400/537: Loss=0.6792 (C:0.6792, R:0.0105)
Batch 425/537: Loss=0.6625 (C:0.6625, R:0.0105)
Batch 450/537: Loss=0.6524 (C:0.6524, R:0.0105)
Batch 475/537: Loss=0.6710 (C:0.6710, R:0.0106)
Batch 500/537: Loss=0.6612 (C:0.6612, R:0.0105)
Batch 525/537: Loss=0.6237 (C:0.6237, R:0.0105)

============================================================
Epoch 54/300 completed in 21.3s
Train: Loss=0.6604 (C:0.6604, R:0.0105) Ratio=4.94x
Val:   Loss=0.8030 (C:0.8030, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 55
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.347 ± 0.584
    Neg distances: 2.374 ± 1.043
    Separation ratio: 6.85x
    Gap: -4.023
    ✅ Excellent global separation!

Epoch 55 Training
----------------------------------------
Batch   0/537: Loss=0.6439 (C:0.6439, R:0.0105)
Batch  25/537: Loss=0.6637 (C:0.6637, R:0.0105)
Batch  50/537: Loss=0.6387 (C:0.6387, R:0.0105)
Batch  75/537: Loss=0.6364 (C:0.6364, R:0.0105)
Batch 100/537: Loss=0.6385 (C:0.6385, R:0.0105)
Batch 125/537: Loss=0.6637 (C:0.6637, R:0.0105)
Batch 150/537: Loss=0.6697 (C:0.6697, R:0.0105)
Batch 175/537: Loss=0.6469 (C:0.6469, R:0.0105)
Batch 200/537: Loss=0.6721 (C:0.6721, R:0.0105)
Batch 225/537: Loss=0.6603 (C:0.6603, R:0.0105)
Batch 250/537: Loss=0.6400 (C:0.6400, R:0.0105)
Batch 275/537: Loss=0.6613 (C:0.6613, R:0.0105)
Batch 300/537: Loss=0.5918 (C:0.5918, R:0.0105)
Batch 325/537: Loss=0.6192 (C:0.6192, R:0.0105)
Batch 350/537: Loss=0.6618 (C:0.6618, R:0.0105)
Batch 375/537: Loss=0.6317 (C:0.6317, R:0.0105)
Batch 400/537: Loss=0.6607 (C:0.6607, R:0.0105)
Batch 425/537: Loss=0.6522 (C:0.6522, R:0.0105)
Batch 450/537: Loss=0.6360 (C:0.6360, R:0.0105)
Batch 475/537: Loss=0.6235 (C:0.6235, R:0.0105)
Batch 500/537: Loss=0.6663 (C:0.6663, R:0.0105)
Batch 525/537: Loss=0.6466 (C:0.6466, R:0.0105)

============================================================
Epoch 55/300 completed in 26.8s
Train: Loss=0.6572 (C:0.6572, R:0.0105) Ratio=5.01x
Val:   Loss=0.7977 (C:0.7977, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.7977)
============================================================

Epoch 56 Training
----------------------------------------
Batch   0/537: Loss=0.6200 (C:0.6200, R:0.0105)
Batch  25/537: Loss=0.6526 (C:0.6526, R:0.0105)
Batch  50/537: Loss=0.6461 (C:0.6461, R:0.0105)
Batch  75/537: Loss=0.6233 (C:0.6233, R:0.0105)
Batch 100/537: Loss=0.6532 (C:0.6532, R:0.0105)
Batch 125/537: Loss=0.6651 (C:0.6651, R:0.0105)
Batch 150/537: Loss=0.5926 (C:0.5926, R:0.0105)
Batch 175/537: Loss=0.6801 (C:0.6801, R:0.0105)
Batch 200/537: Loss=0.6681 (C:0.6681, R:0.0105)
Batch 225/537: Loss=0.6311 (C:0.6311, R:0.0105)
Batch 250/537: Loss=0.7133 (C:0.7133, R:0.0105)
Batch 275/537: Loss=0.6637 (C:0.6637, R:0.0105)
Batch 300/537: Loss=0.6968 (C:0.6968, R:0.0105)
Batch 325/537: Loss=0.6945 (C:0.6945, R:0.0105)
Batch 350/537: Loss=0.6545 (C:0.6545, R:0.0105)
Batch 375/537: Loss=0.6644 (C:0.6644, R:0.0105)
Batch 400/537: Loss=0.6834 (C:0.6834, R:0.0105)
Batch 425/537: Loss=0.6463 (C:0.6463, R:0.0105)
Batch 450/537: Loss=0.6903 (C:0.6903, R:0.0105)
Batch 475/537: Loss=0.6627 (C:0.6627, R:0.0105)
Batch 500/537: Loss=0.6882 (C:0.6882, R:0.0105)
Batch 525/537: Loss=0.6781 (C:0.6781, R:0.0105)

============================================================
Epoch 56/300 completed in 20.9s
Train: Loss=0.6550 (C:0.6550, R:0.0105) Ratio=4.90x
Val:   Loss=0.8011 (C:0.8011, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

Epoch 57 Training
----------------------------------------
Batch   0/537: Loss=0.6415 (C:0.6415, R:0.0105)
Batch  25/537: Loss=0.6702 (C:0.6702, R:0.0105)
Batch  50/537: Loss=0.6185 (C:0.6185, R:0.0105)
Batch  75/537: Loss=0.5970 (C:0.5970, R:0.0105)
Batch 100/537: Loss=0.6741 (C:0.6741, R:0.0105)
Batch 125/537: Loss=0.6503 (C:0.6503, R:0.0105)
Batch 150/537: Loss=0.6471 (C:0.6471, R:0.0105)
Batch 175/537: Loss=0.6627 (C:0.6627, R:0.0105)
Batch 200/537: Loss=0.6398 (C:0.6398, R:0.0105)
Batch 225/537: Loss=0.6557 (C:0.6557, R:0.0105)
Batch 250/537: Loss=0.6254 (C:0.6254, R:0.0105)
Batch 275/537: Loss=0.6331 (C:0.6331, R:0.0105)
Batch 300/537: Loss=0.6078 (C:0.6078, R:0.0105)
Batch 325/537: Loss=0.6708 (C:0.6708, R:0.0105)
Batch 350/537: Loss=0.6595 (C:0.6595, R:0.0105)
Batch 375/537: Loss=0.5994 (C:0.5994, R:0.0105)
Batch 400/537: Loss=0.6400 (C:0.6400, R:0.0105)
Batch 425/537: Loss=0.6440 (C:0.6440, R:0.0105)
Batch 450/537: Loss=0.6836 (C:0.6836, R:0.0105)
Batch 475/537: Loss=0.6638 (C:0.6638, R:0.0105)
Batch 500/537: Loss=0.6758 (C:0.6758, R:0.0105)
Batch 525/537: Loss=0.6962 (C:0.6962, R:0.0105)

============================================================
Epoch 57/300 completed in 20.9s
Train: Loss=0.6525 (C:0.6525, R:0.0105) Ratio=5.05x
Val:   Loss=0.8087 (C:0.8087, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 58
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.315 ± 0.537
    Neg distances: 2.418 ± 1.039
    Separation ratio: 7.69x
    Gap: -4.028
    ✅ Excellent global separation!

Epoch 58 Training
----------------------------------------
Batch   0/537: Loss=0.6223 (C:0.6223, R:0.0105)
Batch  25/537: Loss=0.6010 (C:0.6010, R:0.0105)
Batch  50/537: Loss=0.6146 (C:0.6146, R:0.0105)
Batch  75/537: Loss=0.5820 (C:0.5820, R:0.0105)
Batch 100/537: Loss=0.5969 (C:0.5969, R:0.0105)
Batch 125/537: Loss=0.6151 (C:0.6151, R:0.0105)
Batch 150/537: Loss=0.5863 (C:0.5863, R:0.0105)
Batch 175/537: Loss=0.6025 (C:0.6025, R:0.0105)
Batch 200/537: Loss=0.6269 (C:0.6269, R:0.0105)
Batch 225/537: Loss=0.6172 (C:0.6172, R:0.0105)
Batch 250/537: Loss=0.5975 (C:0.5975, R:0.0105)
Batch 275/537: Loss=0.6358 (C:0.6358, R:0.0105)
Batch 300/537: Loss=0.6122 (C:0.6122, R:0.0105)
Batch 325/537: Loss=0.6155 (C:0.6155, R:0.0105)
Batch 350/537: Loss=0.6398 (C:0.6398, R:0.0105)
Batch 375/537: Loss=0.6438 (C:0.6438, R:0.0105)
Batch 400/537: Loss=0.5832 (C:0.5832, R:0.0105)
Batch 425/537: Loss=0.6237 (C:0.6237, R:0.0105)
Batch 450/537: Loss=0.6234 (C:0.6234, R:0.0105)
Batch 475/537: Loss=0.6110 (C:0.6110, R:0.0105)
Batch 500/537: Loss=0.6150 (C:0.6150, R:0.0105)
Batch 525/537: Loss=0.6512 (C:0.6512, R:0.0105)

============================================================
Epoch 58/300 completed in 26.6s
Train: Loss=0.6168 (C:0.6168, R:0.0105) Ratio=5.03x
Val:   Loss=0.7656 (C:0.7656, R:0.0104) Ratio=3.12x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.7656)
============================================================

Epoch 59 Training
----------------------------------------
Batch   0/537: Loss=0.5863 (C:0.5863, R:0.0105)
Batch  25/537: Loss=0.5940 (C:0.5940, R:0.0105)
Batch  50/537: Loss=0.5806 (C:0.5806, R:0.0105)
Batch  75/537: Loss=0.6321 (C:0.6321, R:0.0105)
Batch 100/537: Loss=0.6244 (C:0.6244, R:0.0105)
Batch 125/537: Loss=0.6392 (C:0.6392, R:0.0105)
Batch 150/537: Loss=0.6088 (C:0.6088, R:0.0105)
Batch 175/537: Loss=0.5888 (C:0.5888, R:0.0105)
Batch 200/537: Loss=0.6303 (C:0.6303, R:0.0105)
Batch 225/537: Loss=0.6150 (C:0.6150, R:0.0105)
Batch 250/537: Loss=0.6451 (C:0.6451, R:0.0105)
Batch 275/537: Loss=0.6208 (C:0.6208, R:0.0105)
Batch 300/537: Loss=0.6016 (C:0.6016, R:0.0105)
Batch 325/537: Loss=0.5854 (C:0.5854, R:0.0105)
Batch 350/537: Loss=0.5831 (C:0.5831, R:0.0105)
Batch 375/537: Loss=0.6314 (C:0.6314, R:0.0106)
Batch 400/537: Loss=0.6094 (C:0.6094, R:0.0105)
Batch 425/537: Loss=0.6353 (C:0.6353, R:0.0105)
Batch 450/537: Loss=0.6030 (C:0.6030, R:0.0105)
Batch 475/537: Loss=0.6101 (C:0.6101, R:0.0105)
Batch 500/537: Loss=0.6068 (C:0.6068, R:0.0105)
Batch 525/537: Loss=0.6564 (C:0.6564, R:0.0105)

============================================================
Epoch 59/300 completed in 21.3s
Train: Loss=0.6147 (C:0.6147, R:0.0105) Ratio=4.94x
Val:   Loss=0.7813 (C:0.7813, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

Epoch 60 Training
----------------------------------------
Batch   0/537: Loss=0.6064 (C:0.6064, R:0.0105)
Batch  25/537: Loss=0.6054 (C:0.6054, R:0.0105)
Batch  50/537: Loss=0.6217 (C:0.6217, R:0.0105)
Batch  75/537: Loss=0.6151 (C:0.6151, R:0.0105)
Batch 100/537: Loss=0.6414 (C:0.6414, R:0.0105)
Batch 125/537: Loss=0.6304 (C:0.6304, R:0.0105)
Batch 150/537: Loss=0.5927 (C:0.5927, R:0.0105)
Batch 175/537: Loss=0.6316 (C:0.6316, R:0.0106)
Batch 200/537: Loss=0.6178 (C:0.6178, R:0.0105)
Batch 225/537: Loss=0.5960 (C:0.5960, R:0.0105)
Batch 250/537: Loss=0.6039 (C:0.6039, R:0.0105)
Batch 275/537: Loss=0.6239 (C:0.6239, R:0.0105)
Batch 300/537: Loss=0.6344 (C:0.6344, R:0.0105)
Batch 325/537: Loss=0.5981 (C:0.5981, R:0.0105)
Batch 350/537: Loss=0.6031 (C:0.6031, R:0.0105)
Batch 375/537: Loss=0.6066 (C:0.6066, R:0.0105)
Batch 400/537: Loss=0.6355 (C:0.6355, R:0.0105)
Batch 425/537: Loss=0.6402 (C:0.6402, R:0.0105)
Batch 450/537: Loss=0.6123 (C:0.6123, R:0.0105)
Batch 475/537: Loss=0.6331 (C:0.6331, R:0.0106)
Batch 500/537: Loss=0.6135 (C:0.6135, R:0.0106)
Batch 525/537: Loss=0.6134 (C:0.6134, R:0.0105)

============================================================
Epoch 60/300 completed in 21.2s
Train: Loss=0.6136 (C:0.6136, R:0.0105) Ratio=4.97x
Val:   Loss=0.7767 (C:0.7767, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 2 epochs
Checkpoint saved at epoch 60
============================================================

🌍 Updating global dataset at epoch 61
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.326 ± 0.562
    Neg distances: 2.441 ± 1.051
    Separation ratio: 7.49x
    Gap: -4.161
    ✅ Excellent global separation!

Epoch 61 Training
----------------------------------------
Batch   0/537: Loss=0.5589 (C:0.5589, R:0.0105)
Batch  25/537: Loss=0.5945 (C:0.5945, R:0.0105)
Batch  50/537: Loss=0.5771 (C:0.5771, R:0.0105)
Batch  75/537: Loss=0.6249 (C:0.6249, R:0.0105)
Batch 100/537: Loss=0.6085 (C:0.6085, R:0.0105)
Batch 125/537: Loss=0.6238 (C:0.6238, R:0.0105)
Batch 150/537: Loss=0.6284 (C:0.6284, R:0.0105)
Batch 175/537: Loss=0.6385 (C:0.6385, R:0.0105)
Batch 200/537: Loss=0.6234 (C:0.6234, R:0.0105)
Batch 225/537: Loss=0.6111 (C:0.6111, R:0.0105)
Batch 250/537: Loss=0.5897 (C:0.5897, R:0.0105)
Batch 275/537: Loss=0.6012 (C:0.6012, R:0.0105)
Batch 300/537: Loss=0.5988 (C:0.5988, R:0.0105)
Batch 325/537: Loss=0.6317 (C:0.6317, R:0.0105)
Batch 350/537: Loss=0.6278 (C:0.6278, R:0.0105)
Batch 375/537: Loss=0.6218 (C:0.6218, R:0.0105)
Batch 400/537: Loss=0.6491 (C:0.6491, R:0.0105)
Batch 425/537: Loss=0.6421 (C:0.6421, R:0.0105)
Batch 450/537: Loss=0.6198 (C:0.6198, R:0.0105)
Batch 475/537: Loss=0.6078 (C:0.6078, R:0.0105)
Batch 500/537: Loss=0.6260 (C:0.6260, R:0.0105)
Batch 525/537: Loss=0.6081 (C:0.6081, R:0.0105)

============================================================
Epoch 61/300 completed in 26.6s
Train: Loss=0.6134 (C:0.6134, R:0.0105) Ratio=5.00x
Val:   Loss=0.7619 (C:0.7619, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.7619)
============================================================

Epoch 62 Training
----------------------------------------
Batch   0/537: Loss=0.6077 (C:0.6077, R:0.0105)
Batch  25/537: Loss=0.6347 (C:0.6347, R:0.0105)
Batch  50/537: Loss=0.6466 (C:0.6466, R:0.0104)
Batch  75/537: Loss=0.5770 (C:0.5770, R:0.0105)
Batch 100/537: Loss=0.6029 (C:0.6029, R:0.0105)
Batch 125/537: Loss=0.6246 (C:0.6246, R:0.0105)
Batch 150/537: Loss=0.5697 (C:0.5697, R:0.0105)
Batch 175/537: Loss=0.5803 (C:0.5803, R:0.0105)
Batch 200/537: Loss=0.6429 (C:0.6429, R:0.0105)
Batch 225/537: Loss=0.5979 (C:0.5979, R:0.0105)
Batch 250/537: Loss=0.6328 (C:0.6328, R:0.0105)
Batch 275/537: Loss=0.6320 (C:0.6320, R:0.0105)
Batch 300/537: Loss=0.6156 (C:0.6156, R:0.0105)
Batch 325/537: Loss=0.6055 (C:0.6055, R:0.0105)
Batch 350/537: Loss=0.6286 (C:0.6286, R:0.0105)
Batch 375/537: Loss=0.6360 (C:0.6360, R:0.0105)
Batch 400/537: Loss=0.5934 (C:0.5934, R:0.0105)
Batch 425/537: Loss=0.6291 (C:0.6291, R:0.0105)
Batch 450/537: Loss=0.6262 (C:0.6262, R:0.0105)
Batch 475/537: Loss=0.6342 (C:0.6342, R:0.0106)
Batch 500/537: Loss=0.6124 (C:0.6124, R:0.0105)
Batch 525/537: Loss=0.6129 (C:0.6129, R:0.0105)

============================================================
Epoch 62/300 completed in 21.1s
Train: Loss=0.6141 (C:0.6141, R:0.0105) Ratio=4.98x
Val:   Loss=0.7771 (C:0.7771, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

Epoch 63 Training
----------------------------------------
Batch   0/537: Loss=0.6044 (C:0.6044, R:0.0105)
Batch  25/537: Loss=0.5754 (C:0.5754, R:0.0105)
Batch  50/537: Loss=0.6212 (C:0.6212, R:0.0105)
Batch  75/537: Loss=0.5973 (C:0.5973, R:0.0105)
Batch 100/537: Loss=0.5960 (C:0.5960, R:0.0105)
Batch 125/537: Loss=0.5785 (C:0.5785, R:0.0105)
Batch 150/537: Loss=0.6078 (C:0.6078, R:0.0105)
Batch 175/537: Loss=0.6052 (C:0.6052, R:0.0106)
Batch 200/537: Loss=0.6005 (C:0.6005, R:0.0105)
Batch 225/537: Loss=0.5873 (C:0.5873, R:0.0105)
Batch 250/537: Loss=0.6113 (C:0.6113, R:0.0105)
Batch 275/537: Loss=0.6074 (C:0.6074, R:0.0105)
Batch 300/537: Loss=0.6242 (C:0.6242, R:0.0105)
Batch 325/537: Loss=0.6464 (C:0.6464, R:0.0105)
Batch 350/537: Loss=0.6160 (C:0.6160, R:0.0105)
Batch 375/537: Loss=0.6203 (C:0.6203, R:0.0105)
Batch 400/537: Loss=0.6111 (C:0.6111, R:0.0105)
Batch 425/537: Loss=0.6373 (C:0.6373, R:0.0105)
Batch 450/537: Loss=0.5963 (C:0.5963, R:0.0105)
Batch 475/537: Loss=0.6280 (C:0.6280, R:0.0105)
Batch 500/537: Loss=0.5850 (C:0.5850, R:0.0105)
Batch 525/537: Loss=0.6344 (C:0.6344, R:0.0105)

============================================================
Epoch 63/300 completed in 21.1s
Train: Loss=0.6112 (C:0.6112, R:0.0105) Ratio=5.16x
Val:   Loss=0.7646 (C:0.7646, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 64
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.328 ± 0.564
    Neg distances: 2.430 ± 1.043
    Separation ratio: 7.41x
    Gap: -4.137
    ✅ Excellent global separation!

Epoch 64 Training
----------------------------------------
Batch   0/537: Loss=0.6183 (C:0.6183, R:0.0105)
Batch  25/537: Loss=0.5784 (C:0.5784, R:0.0105)
Batch  50/537: Loss=0.5891 (C:0.5891, R:0.0105)
Batch  75/537: Loss=0.5896 (C:0.5896, R:0.0105)
Batch 100/537: Loss=0.5822 (C:0.5822, R:0.0105)
Batch 125/537: Loss=0.6047 (C:0.6047, R:0.0105)
Batch 150/537: Loss=0.6512 (C:0.6512, R:0.0105)
Batch 175/537: Loss=0.5733 (C:0.5733, R:0.0105)
Batch 200/537: Loss=0.6264 (C:0.6264, R:0.0105)
Batch 225/537: Loss=0.5882 (C:0.5882, R:0.0105)
Batch 250/537: Loss=0.6092 (C:0.6092, R:0.0105)
Batch 275/537: Loss=0.6340 (C:0.6340, R:0.0105)
Batch 300/537: Loss=0.5840 (C:0.5840, R:0.0105)
Batch 325/537: Loss=0.6078 (C:0.6078, R:0.0105)
Batch 350/537: Loss=0.6124 (C:0.6124, R:0.0105)
Batch 375/537: Loss=0.6431 (C:0.6431, R:0.0105)
Batch 400/537: Loss=0.5516 (C:0.5516, R:0.0105)
Batch 425/537: Loss=0.6144 (C:0.6144, R:0.0105)
Batch 450/537: Loss=0.6119 (C:0.6119, R:0.0105)
Batch 475/537: Loss=0.6052 (C:0.6052, R:0.0105)
Batch 500/537: Loss=0.6075 (C:0.6075, R:0.0105)
Batch 525/537: Loss=0.6154 (C:0.6154, R:0.0105)

============================================================
Epoch 64/300 completed in 26.8s
Train: Loss=0.6071 (C:0.6071, R:0.0105) Ratio=5.16x
Val:   Loss=0.7692 (C:0.7692, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

Epoch 65 Training
----------------------------------------
Batch   0/537: Loss=0.6040 (C:0.6040, R:0.0105)
Batch  25/537: Loss=0.6126 (C:0.6126, R:0.0105)
Batch  50/537: Loss=0.6174 (C:0.6174, R:0.0105)
Batch  75/537: Loss=0.5688 (C:0.5688, R:0.0105)
Batch 100/537: Loss=0.5606 (C:0.5606, R:0.0105)
Batch 125/537: Loss=0.5878 (C:0.5878, R:0.0105)
Batch 150/537: Loss=0.5708 (C:0.5708, R:0.0105)
Batch 175/537: Loss=0.5760 (C:0.5760, R:0.0105)
Batch 200/537: Loss=0.5970 (C:0.5970, R:0.0105)
Batch 225/537: Loss=0.6018 (C:0.6018, R:0.0105)
Batch 250/537: Loss=0.6054 (C:0.6054, R:0.0105)
Batch 275/537: Loss=0.6398 (C:0.6398, R:0.0105)
Batch 300/537: Loss=0.6231 (C:0.6231, R:0.0105)
Batch 325/537: Loss=0.6007 (C:0.6007, R:0.0105)
Batch 350/537: Loss=0.5802 (C:0.5802, R:0.0105)
Batch 375/537: Loss=0.5941 (C:0.5941, R:0.0105)
Batch 400/537: Loss=0.5963 (C:0.5963, R:0.0105)
Batch 425/537: Loss=0.5950 (C:0.5950, R:0.0105)
Batch 450/537: Loss=0.5972 (C:0.5972, R:0.0105)
Batch 475/537: Loss=0.5838 (C:0.5838, R:0.0105)
Batch 500/537: Loss=0.6177 (C:0.6177, R:0.0105)
Batch 525/537: Loss=0.6273 (C:0.6273, R:0.0105)

============================================================
Epoch 65/300 completed in 21.5s
Train: Loss=0.6070 (C:0.6070, R:0.0105) Ratio=5.20x
Val:   Loss=0.7731 (C:0.7731, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 4 epochs
============================================================

Epoch 66 Training
----------------------------------------
Batch   0/537: Loss=0.5859 (C:0.5859, R:0.0105)
Batch  25/537: Loss=0.6371 (C:0.6371, R:0.0105)
Batch  50/537: Loss=0.6150 (C:0.6150, R:0.0105)
Batch  75/537: Loss=0.6291 (C:0.6291, R:0.0105)
Batch 100/537: Loss=0.5999 (C:0.5999, R:0.0105)
Batch 125/537: Loss=0.6098 (C:0.6098, R:0.0105)
Batch 150/537: Loss=0.6486 (C:0.6486, R:0.0105)
Batch 175/537: Loss=0.6206 (C:0.6206, R:0.0105)
Batch 200/537: Loss=0.6027 (C:0.6027, R:0.0105)
Batch 225/537: Loss=0.5629 (C:0.5629, R:0.0105)
Batch 250/537: Loss=0.6032 (C:0.6032, R:0.0105)
Batch 275/537: Loss=0.6320 (C:0.6320, R:0.0105)
Batch 300/537: Loss=0.6210 (C:0.6210, R:0.0105)
Batch 325/537: Loss=0.6050 (C:0.6050, R:0.0105)
Batch 350/537: Loss=0.6178 (C:0.6178, R:0.0105)
Batch 375/537: Loss=0.6150 (C:0.6150, R:0.0105)
Batch 400/537: Loss=0.5920 (C:0.5920, R:0.0105)
Batch 425/537: Loss=0.6044 (C:0.6044, R:0.0105)
Batch 450/537: Loss=0.6213 (C:0.6213, R:0.0105)
Batch 475/537: Loss=0.6073 (C:0.6073, R:0.0105)
Batch 500/537: Loss=0.6114 (C:0.6114, R:0.0105)
Batch 525/537: Loss=0.6517 (C:0.6517, R:0.0105)

============================================================
Epoch 66/300 completed in 21.3s
Train: Loss=0.6053 (C:0.6053, R:0.0105) Ratio=5.04x
Val:   Loss=0.7644 (C:0.7644, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 5 epochs
============================================================

🌍 Updating global dataset at epoch 67
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.304 ± 0.562
    Neg distances: 2.477 ± 1.045
    Separation ratio: 8.14x
    Gap: -4.111
    ✅ Excellent global separation!

Epoch 67 Training
----------------------------------------
Batch   0/537: Loss=0.5575 (C:0.5575, R:0.0105)
Batch  25/537: Loss=0.5599 (C:0.5599, R:0.0105)
Batch  50/537: Loss=0.5581 (C:0.5581, R:0.0105)
Batch  75/537: Loss=0.5552 (C:0.5552, R:0.0105)
Batch 100/537: Loss=0.5802 (C:0.5802, R:0.0105)
Batch 125/537: Loss=0.5710 (C:0.5710, R:0.0105)
Batch 150/537: Loss=0.5978 (C:0.5978, R:0.0105)
Batch 175/537: Loss=0.5520 (C:0.5520, R:0.0105)
Batch 200/537: Loss=0.5972 (C:0.5972, R:0.0105)
Batch 225/537: Loss=0.5766 (C:0.5766, R:0.0105)
Batch 250/537: Loss=0.5557 (C:0.5557, R:0.0105)
Batch 275/537: Loss=0.5905 (C:0.5905, R:0.0105)
Batch 300/537: Loss=0.6079 (C:0.6079, R:0.0105)
Batch 325/537: Loss=0.5951 (C:0.5951, R:0.0105)
Batch 350/537: Loss=0.5729 (C:0.5729, R:0.0105)
Batch 375/537: Loss=0.6080 (C:0.6080, R:0.0105)
Batch 400/537: Loss=0.6027 (C:0.6027, R:0.0105)
Batch 425/537: Loss=0.5650 (C:0.5650, R:0.0105)
Batch 450/537: Loss=0.5763 (C:0.5763, R:0.0105)
Batch 475/537: Loss=0.5751 (C:0.5751, R:0.0105)
Batch 500/537: Loss=0.6001 (C:0.6001, R:0.0105)
Batch 525/537: Loss=0.5990 (C:0.5990, R:0.0105)

============================================================
Epoch 67/300 completed in 27.1s
Train: Loss=0.5795 (C:0.5795, R:0.0105) Ratio=5.13x
Val:   Loss=0.7433 (C:0.7433, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.7433)
============================================================

Epoch 68 Training
----------------------------------------
Batch   0/537: Loss=0.5305 (C:0.5305, R:0.0105)
Batch  25/537: Loss=0.6142 (C:0.6142, R:0.0105)
Batch  50/537: Loss=0.5995 (C:0.5995, R:0.0105)
Batch  75/537: Loss=0.5799 (C:0.5799, R:0.0105)
Batch 100/537: Loss=0.5935 (C:0.5935, R:0.0105)
Batch 125/537: Loss=0.5509 (C:0.5509, R:0.0105)
Batch 150/537: Loss=0.6204 (C:0.6204, R:0.0105)
Batch 175/537: Loss=0.5741 (C:0.5741, R:0.0105)
Batch 200/537: Loss=0.5702 (C:0.5702, R:0.0105)
Batch 225/537: Loss=0.5983 (C:0.5983, R:0.0105)
Batch 250/537: Loss=0.5677 (C:0.5677, R:0.0105)
Batch 275/537: Loss=0.5692 (C:0.5692, R:0.0105)
Batch 300/537: Loss=0.5786 (C:0.5786, R:0.0105)
Batch 325/537: Loss=0.5779 (C:0.5779, R:0.0105)
Batch 350/537: Loss=0.5733 (C:0.5733, R:0.0105)
Batch 375/537: Loss=0.5644 (C:0.5644, R:0.0105)
Batch 400/537: Loss=0.5488 (C:0.5488, R:0.0105)
Batch 425/537: Loss=0.5716 (C:0.5716, R:0.0105)
Batch 450/537: Loss=0.5656 (C:0.5656, R:0.0105)
Batch 475/537: Loss=0.6038 (C:0.6038, R:0.0105)
Batch 500/537: Loss=0.6240 (C:0.6240, R:0.0105)
Batch 525/537: Loss=0.5849 (C:0.5849, R:0.0105)

============================================================
Epoch 68/300 completed in 21.1s
Train: Loss=0.5787 (C:0.5787, R:0.0105) Ratio=5.15x
Val:   Loss=0.7402 (C:0.7402, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.7402)
============================================================

Epoch 69 Training
----------------------------------------
Batch   0/537: Loss=0.5674 (C:0.5674, R:0.0105)
Batch  25/537: Loss=0.5926 (C:0.5926, R:0.0105)
Batch  50/537: Loss=0.5522 (C:0.5522, R:0.0105)
Batch  75/537: Loss=0.5933 (C:0.5933, R:0.0105)
Batch 100/537: Loss=0.5558 (C:0.5558, R:0.0105)
Batch 125/537: Loss=0.5864 (C:0.5864, R:0.0105)
Batch 150/537: Loss=0.5425 (C:0.5425, R:0.0105)
Batch 175/537: Loss=0.5662 (C:0.5662, R:0.0105)
Batch 200/537: Loss=0.5678 (C:0.5678, R:0.0105)
Batch 225/537: Loss=0.5489 (C:0.5489, R:0.0105)
Batch 250/537: Loss=0.5487 (C:0.5487, R:0.0105)
Batch 275/537: Loss=0.5487 (C:0.5487, R:0.0105)
Batch 300/537: Loss=0.5910 (C:0.5910, R:0.0105)
Batch 325/537: Loss=0.5828 (C:0.5828, R:0.0105)
Batch 350/537: Loss=0.5491 (C:0.5491, R:0.0105)
Batch 375/537: Loss=0.5936 (C:0.5936, R:0.0105)
Batch 400/537: Loss=0.5950 (C:0.5950, R:0.0105)
Batch 425/537: Loss=0.5823 (C:0.5823, R:0.0105)
Batch 450/537: Loss=0.6126 (C:0.6126, R:0.0105)
Batch 475/537: Loss=0.6031 (C:0.6031, R:0.0105)
Batch 500/537: Loss=0.5869 (C:0.5869, R:0.0105)
Batch 525/537: Loss=0.6207 (C:0.6207, R:0.0105)

============================================================
Epoch 69/300 completed in 21.2s
Train: Loss=0.5764 (C:0.5764, R:0.0105) Ratio=5.17x
Val:   Loss=0.7418 (C:0.7418, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 70
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.344 ± 0.616
    Neg distances: 2.484 ± 1.071
    Separation ratio: 7.22x
    Gap: -4.241
    ✅ Excellent global separation!

Epoch 70 Training
----------------------------------------
Batch   0/537: Loss=0.5806 (C:0.5806, R:0.0105)
Batch  25/537: Loss=0.5811 (C:0.5811, R:0.0105)
Batch  50/537: Loss=0.5913 (C:0.5913, R:0.0105)
Batch  75/537: Loss=0.6103 (C:0.6103, R:0.0105)
Batch 100/537: Loss=0.5700 (C:0.5700, R:0.0105)
Batch 125/537: Loss=0.6375 (C:0.6375, R:0.0105)
Batch 150/537: Loss=0.5930 (C:0.5930, R:0.0105)
Batch 175/537: Loss=0.5994 (C:0.5994, R:0.0106)
Batch 200/537: Loss=0.6350 (C:0.6350, R:0.0105)
Batch 225/537: Loss=0.6019 (C:0.6019, R:0.0105)
Batch 250/537: Loss=0.5932 (C:0.5932, R:0.0105)
Batch 275/537: Loss=0.6147 (C:0.6147, R:0.0105)
Batch 300/537: Loss=0.6480 (C:0.6480, R:0.0105)
Batch 325/537: Loss=0.5568 (C:0.5568, R:0.0105)
Batch 350/537: Loss=0.5898 (C:0.5898, R:0.0105)
Batch 375/537: Loss=0.6273 (C:0.6273, R:0.0105)
Batch 400/537: Loss=0.6108 (C:0.6108, R:0.0105)
Batch 425/537: Loss=0.5970 (C:0.5970, R:0.0105)
Batch 450/537: Loss=0.6021 (C:0.6021, R:0.0105)
Batch 475/537: Loss=0.6072 (C:0.6072, R:0.0105)
Batch 500/537: Loss=0.6000 (C:0.6000, R:0.0105)
Batch 525/537: Loss=0.5898 (C:0.5898, R:0.0105)

============================================================
Epoch 70/300 completed in 26.9s
Train: Loss=0.6036 (C:0.6036, R:0.0105) Ratio=5.32x
Val:   Loss=0.7622 (C:0.7622, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

Epoch 71 Training
----------------------------------------
Batch   0/537: Loss=0.6230 (C:0.6230, R:0.0105)
Batch  25/537: Loss=0.6054 (C:0.6054, R:0.0105)
Batch  50/537: Loss=0.5964 (C:0.5964, R:0.0105)
Batch  75/537: Loss=0.5773 (C:0.5773, R:0.0105)
Batch 100/537: Loss=0.5658 (C:0.5658, R:0.0105)
Batch 125/537: Loss=0.6057 (C:0.6057, R:0.0105)
Batch 150/537: Loss=0.5908 (C:0.5908, R:0.0105)
Batch 175/537: Loss=0.6046 (C:0.6046, R:0.0105)
Batch 200/537: Loss=0.6080 (C:0.6080, R:0.0105)
Batch 225/537: Loss=0.6288 (C:0.6288, R:0.0105)
Batch 250/537: Loss=0.6197 (C:0.6197, R:0.0105)
Batch 275/537: Loss=0.5912 (C:0.5912, R:0.0105)
Batch 300/537: Loss=0.6248 (C:0.6248, R:0.0105)
Batch 325/537: Loss=0.6308 (C:0.6308, R:0.0105)
Batch 350/537: Loss=0.5693 (C:0.5693, R:0.0105)
Batch 375/537: Loss=0.5986 (C:0.5986, R:0.0105)
Batch 400/537: Loss=0.5980 (C:0.5980, R:0.0105)
Batch 425/537: Loss=0.5993 (C:0.5993, R:0.0105)
Batch 450/537: Loss=0.6241 (C:0.6241, R:0.0106)
Batch 475/537: Loss=0.5891 (C:0.5891, R:0.0105)
Batch 500/537: Loss=0.5996 (C:0.5996, R:0.0105)
Batch 525/537: Loss=0.6052 (C:0.6052, R:0.0105)

============================================================
Epoch 71/300 completed in 21.1s
Train: Loss=0.6018 (C:0.6018, R:0.0105) Ratio=5.29x
Val:   Loss=0.7772 (C:0.7772, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

Epoch 72 Training
----------------------------------------
Batch   0/537: Loss=0.5653 (C:0.5653, R:0.0105)
Batch  25/537: Loss=0.5855 (C:0.5855, R:0.0105)
Batch  50/537: Loss=0.6135 (C:0.6135, R:0.0105)
Batch  75/537: Loss=0.6201 (C:0.6201, R:0.0105)
Batch 100/537: Loss=0.5936 (C:0.5936, R:0.0105)
Batch 125/537: Loss=0.5736 (C:0.5736, R:0.0105)
Batch 150/537: Loss=0.5971 (C:0.5971, R:0.0105)
Batch 175/537: Loss=0.5840 (C:0.5840, R:0.0105)
Batch 200/537: Loss=0.6159 (C:0.6159, R:0.0106)
Batch 225/537: Loss=0.5808 (C:0.5808, R:0.0105)
Batch 250/537: Loss=0.6005 (C:0.6005, R:0.0105)
Batch 275/537: Loss=0.6101 (C:0.6101, R:0.0105)
Batch 300/537: Loss=0.6129 (C:0.6129, R:0.0105)
Batch 325/537: Loss=0.5949 (C:0.5949, R:0.0105)
Batch 350/537: Loss=0.6232 (C:0.6232, R:0.0105)
Batch 375/537: Loss=0.5630 (C:0.5630, R:0.0105)
Batch 400/537: Loss=0.6042 (C:0.6042, R:0.0105)
Batch 425/537: Loss=0.5835 (C:0.5835, R:0.0105)
Batch 450/537: Loss=0.6279 (C:0.6279, R:0.0105)
Batch 475/537: Loss=0.6258 (C:0.6258, R:0.0105)
Batch 500/537: Loss=0.5791 (C:0.5791, R:0.0105)
Batch 525/537: Loss=0.5864 (C:0.5864, R:0.0105)

============================================================
Epoch 72/300 completed in 21.1s
Train: Loss=0.6008 (C:0.6008, R:0.0105) Ratio=5.30x
Val:   Loss=0.7660 (C:0.7660, R:0.0104) Ratio=3.13x
Reconstruction weight: 0.300
No improvement for 4 epochs
============================================================

🌍 Updating global dataset at epoch 73
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.292 ± 0.541
    Neg distances: 2.522 ± 1.052
    Separation ratio: 8.63x
    Gap: -4.190
    ✅ Excellent global separation!

Epoch 73 Training
----------------------------------------
Batch   0/537: Loss=0.5521 (C:0.5521, R:0.0105)
Batch  25/537: Loss=0.5611 (C:0.5611, R:0.0105)
Batch  50/537: Loss=0.5778 (C:0.5778, R:0.0105)
Batch  75/537: Loss=0.6023 (C:0.6023, R:0.0105)
Batch 100/537: Loss=0.5846 (C:0.5846, R:0.0105)
Batch 125/537: Loss=0.5257 (C:0.5257, R:0.0105)
Batch 150/537: Loss=0.5705 (C:0.5705, R:0.0105)
Batch 175/537: Loss=0.5702 (C:0.5702, R:0.0105)
Batch 200/537: Loss=0.5537 (C:0.5537, R:0.0105)
Batch 225/537: Loss=0.5631 (C:0.5631, R:0.0105)
Batch 250/537: Loss=0.5617 (C:0.5617, R:0.0105)
Batch 275/537: Loss=0.5532 (C:0.5532, R:0.0105)
Batch 300/537: Loss=0.5421 (C:0.5421, R:0.0105)
Batch 325/537: Loss=0.5666 (C:0.5666, R:0.0105)
Batch 350/537: Loss=0.5558 (C:0.5558, R:0.0105)
Batch 375/537: Loss=0.5300 (C:0.5300, R:0.0105)
Batch 400/537: Loss=0.5844 (C:0.5844, R:0.0105)
Batch 425/537: Loss=0.5613 (C:0.5613, R:0.0105)
Batch 450/537: Loss=0.5723 (C:0.5723, R:0.0106)
Batch 475/537: Loss=0.5608 (C:0.5608, R:0.0105)
Batch 500/537: Loss=0.5372 (C:0.5372, R:0.0105)
Batch 525/537: Loss=0.5248 (C:0.5248, R:0.0105)

============================================================
Epoch 73/300 completed in 26.7s
Train: Loss=0.5558 (C:0.5558, R:0.0105) Ratio=5.19x
Val:   Loss=0.7395 (C:0.7395, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.7395)
============================================================

Epoch 74 Training
----------------------------------------
Batch   0/537: Loss=0.5738 (C:0.5738, R:0.0105)
Batch  25/537: Loss=0.5451 (C:0.5451, R:0.0105)
Batch  50/537: Loss=0.4856 (C:0.4856, R:0.0105)
Batch  75/537: Loss=0.5510 (C:0.5510, R:0.0105)
Batch 100/537: Loss=0.5141 (C:0.5141, R:0.0105)
Batch 125/537: Loss=0.5738 (C:0.5738, R:0.0105)
Batch 150/537: Loss=0.5648 (C:0.5648, R:0.0105)
Batch 175/537: Loss=0.5800 (C:0.5800, R:0.0105)
Batch 200/537: Loss=0.5934 (C:0.5934, R:0.0105)
Batch 225/537: Loss=0.5737 (C:0.5737, R:0.0105)
Batch 250/537: Loss=0.5575 (C:0.5575, R:0.0105)
Batch 275/537: Loss=0.5356 (C:0.5356, R:0.0105)
Batch 300/537: Loss=0.5478 (C:0.5478, R:0.0105)
Batch 325/537: Loss=0.5556 (C:0.5556, R:0.0105)
Batch 350/537: Loss=0.5620 (C:0.5620, R:0.0105)
Batch 375/537: Loss=0.5861 (C:0.5861, R:0.0105)
Batch 400/537: Loss=0.5600 (C:0.5600, R:0.0105)
Batch 425/537: Loss=0.5938 (C:0.5938, R:0.0105)
Batch 450/537: Loss=0.5637 (C:0.5637, R:0.0105)
Batch 475/537: Loss=0.5749 (C:0.5749, R:0.0105)
Batch 500/537: Loss=0.5813 (C:0.5813, R:0.0105)
Batch 525/537: Loss=0.5465 (C:0.5465, R:0.0105)

============================================================
Epoch 74/300 completed in 21.0s
Train: Loss=0.5566 (C:0.5566, R:0.0105) Ratio=5.25x
Val:   Loss=0.7365 (C:0.7365, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.7365)
============================================================

Epoch 75 Training
----------------------------------------
Batch   0/537: Loss=0.5465 (C:0.5465, R:0.0105)
Batch  25/537: Loss=0.5375 (C:0.5375, R:0.0105)
Batch  50/537: Loss=0.5758 (C:0.5758, R:0.0105)
Batch  75/537: Loss=0.5103 (C:0.5103, R:0.0105)
Batch 100/537: Loss=0.5711 (C:0.5711, R:0.0104)
Batch 125/537: Loss=0.5538 (C:0.5538, R:0.0105)
Batch 150/537: Loss=0.5675 (C:0.5675, R:0.0105)
Batch 175/537: Loss=0.5605 (C:0.5605, R:0.0105)
Batch 200/537: Loss=0.5427 (C:0.5427, R:0.0105)
Batch 225/537: Loss=0.5423 (C:0.5423, R:0.0105)
Batch 250/537: Loss=0.5723 (C:0.5723, R:0.0105)
Batch 275/537: Loss=0.5377 (C:0.5377, R:0.0105)
Batch 300/537: Loss=0.5340 (C:0.5340, R:0.0105)
Batch 325/537: Loss=0.5721 (C:0.5721, R:0.0105)
Batch 350/537: Loss=0.5689 (C:0.5689, R:0.0105)
Batch 375/537: Loss=0.5670 (C:0.5670, R:0.0105)
Batch 400/537: Loss=0.5882 (C:0.5882, R:0.0106)
Batch 425/537: Loss=0.5445 (C:0.5445, R:0.0105)
Batch 450/537: Loss=0.5531 (C:0.5531, R:0.0105)
Batch 475/537: Loss=0.5527 (C:0.5527, R:0.0105)
Batch 500/537: Loss=0.5749 (C:0.5749, R:0.0105)
Batch 525/537: Loss=0.5768 (C:0.5768, R:0.0105)

============================================================
Epoch 75/300 completed in 21.2s
Train: Loss=0.5544 (C:0.5544, R:0.0105) Ratio=5.24x
Val:   Loss=0.7299 (C:0.7299, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.7299)
============================================================

🌍 Updating global dataset at epoch 76
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.318 ± 0.586
    Neg distances: 2.545 ± 1.081
    Separation ratio: 8.01x
    Gap: -4.240
    ✅ Excellent global separation!

Epoch 76 Training
----------------------------------------
Batch   0/537: Loss=0.5586 (C:0.5586, R:0.0105)
Batch  25/537: Loss=0.5583 (C:0.5583, R:0.0105)
Batch  50/537: Loss=0.5390 (C:0.5390, R:0.0105)
Batch  75/537: Loss=0.5702 (C:0.5702, R:0.0105)
Batch 100/537: Loss=0.5781 (C:0.5781, R:0.0105)
Batch 125/537: Loss=0.5753 (C:0.5753, R:0.0105)
Batch 150/537: Loss=0.6136 (C:0.6136, R:0.0105)
Batch 175/537: Loss=0.5642 (C:0.5642, R:0.0105)
Batch 200/537: Loss=0.5618 (C:0.5618, R:0.0105)
Batch 225/537: Loss=0.5495 (C:0.5495, R:0.0105)
Batch 250/537: Loss=0.5466 (C:0.5466, R:0.0105)
Batch 275/537: Loss=0.5594 (C:0.5594, R:0.0105)
Batch 300/537: Loss=0.5666 (C:0.5666, R:0.0105)
Batch 325/537: Loss=0.5820 (C:0.5820, R:0.0105)
Batch 350/537: Loss=0.5979 (C:0.5979, R:0.0105)
Batch 375/537: Loss=0.5917 (C:0.5917, R:0.0105)
Batch 400/537: Loss=0.5821 (C:0.5821, R:0.0105)
Batch 425/537: Loss=0.5911 (C:0.5911, R:0.0106)
Batch 450/537: Loss=0.5809 (C:0.5809, R:0.0105)
Batch 475/537: Loss=0.5743 (C:0.5743, R:0.0105)
Batch 500/537: Loss=0.5838 (C:0.5838, R:0.0105)
Batch 525/537: Loss=0.5880 (C:0.5880, R:0.0105)

============================================================
Epoch 76/300 completed in 27.3s
Train: Loss=0.5696 (C:0.5696, R:0.0105) Ratio=5.28x
Val:   Loss=0.7415 (C:0.7415, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

Epoch 77 Training
----------------------------------------
Batch   0/537: Loss=0.5413 (C:0.5413, R:0.0105)
Batch  25/537: Loss=0.5540 (C:0.5540, R:0.0105)
Batch  50/537: Loss=0.5629 (C:0.5629, R:0.0105)
Batch  75/537: Loss=0.5802 (C:0.5802, R:0.0105)
Batch 100/537: Loss=0.5784 (C:0.5784, R:0.0105)
Batch 125/537: Loss=0.5921 (C:0.5921, R:0.0105)
Batch 150/537: Loss=0.5668 (C:0.5668, R:0.0105)
Batch 175/537: Loss=0.5959 (C:0.5959, R:0.0105)
Batch 200/537: Loss=0.5929 (C:0.5929, R:0.0105)
Batch 225/537: Loss=0.5819 (C:0.5819, R:0.0105)
Batch 250/537: Loss=0.5979 (C:0.5979, R:0.0105)
Batch 275/537: Loss=0.5666 (C:0.5666, R:0.0105)
Batch 300/537: Loss=0.5729 (C:0.5729, R:0.0105)
Batch 325/537: Loss=0.5464 (C:0.5464, R:0.0105)
Batch 350/537: Loss=0.5756 (C:0.5756, R:0.0105)
Batch 375/537: Loss=0.5803 (C:0.5803, R:0.0105)
Batch 400/537: Loss=0.5472 (C:0.5472, R:0.0105)
Batch 425/537: Loss=0.5615 (C:0.5615, R:0.0105)
Batch 450/537: Loss=0.5586 (C:0.5586, R:0.0105)
Batch 475/537: Loss=0.5823 (C:0.5823, R:0.0105)
Batch 500/537: Loss=0.5697 (C:0.5697, R:0.0105)
Batch 525/537: Loss=0.5545 (C:0.5545, R:0.0105)

============================================================
Epoch 77/300 completed in 21.6s
Train: Loss=0.5692 (C:0.5692, R:0.0105) Ratio=5.38x
Val:   Loss=0.7542 (C:0.7542, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

Epoch 78 Training
----------------------------------------
Batch   0/537: Loss=0.5693 (C:0.5693, R:0.0105)
Batch  25/537: Loss=0.5572 (C:0.5572, R:0.0105)
Batch  50/537: Loss=0.5670 (C:0.5670, R:0.0105)
Batch  75/537: Loss=0.5591 (C:0.5591, R:0.0105)
Batch 100/537: Loss=0.5907 (C:0.5907, R:0.0105)
Batch 125/537: Loss=0.5300 (C:0.5300, R:0.0105)
Batch 150/537: Loss=0.5465 (C:0.5465, R:0.0105)
Batch 175/537: Loss=0.5788 (C:0.5788, R:0.0105)
Batch 200/537: Loss=0.5946 (C:0.5946, R:0.0105)
Batch 225/537: Loss=0.5774 (C:0.5774, R:0.0105)
Batch 250/537: Loss=0.5510 (C:0.5510, R:0.0105)
Batch 275/537: Loss=0.5950 (C:0.5950, R:0.0105)
Batch 300/537: Loss=0.5916 (C:0.5916, R:0.0105)
Batch 325/537: Loss=0.5576 (C:0.5576, R:0.0106)
Batch 350/537: Loss=0.6123 (C:0.6123, R:0.0105)
Batch 375/537: Loss=0.5677 (C:0.5677, R:0.0106)
Batch 400/537: Loss=0.5690 (C:0.5690, R:0.0105)
Batch 425/537: Loss=0.5803 (C:0.5803, R:0.0105)
Batch 450/537: Loss=0.5460 (C:0.5460, R:0.0105)
Batch 475/537: Loss=0.5644 (C:0.5644, R:0.0105)
Batch 500/537: Loss=0.5915 (C:0.5915, R:0.0105)
Batch 525/537: Loss=0.5692 (C:0.5692, R:0.0105)

============================================================
Epoch 78/300 completed in 21.4s
Train: Loss=0.5669 (C:0.5669, R:0.0105) Ratio=5.37x
Val:   Loss=0.7393 (C:0.7393, R:0.0104) Ratio=3.12x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 79
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.298 ± 0.576
    Neg distances: 2.613 ± 1.092
    Separation ratio: 8.76x
    Gap: -4.288
    ✅ Excellent global separation!

Epoch 79 Training
----------------------------------------
Batch   0/537: Loss=0.5457 (C:0.5457, R:0.0105)
Batch  25/537: Loss=0.5471 (C:0.5471, R:0.0105)
Batch  50/537: Loss=0.5180 (C:0.5180, R:0.0105)
Batch  75/537: Loss=0.5482 (C:0.5482, R:0.0105)
Batch 100/537: Loss=0.5162 (C:0.5162, R:0.0105)
Batch 125/537: Loss=0.4984 (C:0.4984, R:0.0105)
Batch 150/537: Loss=0.5445 (C:0.5445, R:0.0105)
Batch 175/537: Loss=0.5146 (C:0.5146, R:0.0105)
Batch 200/537: Loss=0.5629 (C:0.5629, R:0.0105)
Batch 225/537: Loss=0.5417 (C:0.5417, R:0.0105)
Batch 250/537: Loss=0.5377 (C:0.5377, R:0.0105)
Batch 275/537: Loss=0.5447 (C:0.5447, R:0.0105)
Batch 300/537: Loss=0.5847 (C:0.5847, R:0.0105)
Batch 325/537: Loss=0.5332 (C:0.5332, R:0.0105)
Batch 350/537: Loss=0.5704 (C:0.5704, R:0.0105)
Batch 375/537: Loss=0.5511 (C:0.5511, R:0.0105)
Batch 400/537: Loss=0.5719 (C:0.5719, R:0.0105)
Batch 425/537: Loss=0.5699 (C:0.5699, R:0.0105)
Batch 450/537: Loss=0.5845 (C:0.5845, R:0.0104)
Batch 475/537: Loss=0.5539 (C:0.5539, R:0.0105)
Batch 500/537: Loss=0.5394 (C:0.5394, R:0.0105)
Batch 525/537: Loss=0.5521 (C:0.5521, R:0.0105)

============================================================
Epoch 79/300 completed in 27.5s
Train: Loss=0.5476 (C:0.5476, R:0.0105) Ratio=5.38x
Val:   Loss=0.7209 (C:0.7209, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.7209)
============================================================

Epoch 80 Training
----------------------------------------
Batch   0/537: Loss=0.5645 (C:0.5645, R:0.0106)
Batch  25/537: Loss=0.5452 (C:0.5452, R:0.0105)
Batch  50/537: Loss=0.5400 (C:0.5400, R:0.0105)
Batch  75/537: Loss=0.5391 (C:0.5391, R:0.0105)
Batch 100/537: Loss=0.5557 (C:0.5557, R:0.0105)
Batch 125/537: Loss=0.5170 (C:0.5170, R:0.0105)
Batch 150/537: Loss=0.5588 (C:0.5588, R:0.0105)
Batch 175/537: Loss=0.5721 (C:0.5721, R:0.0105)
Batch 200/537: Loss=0.4996 (C:0.4996, R:0.0106)
Batch 225/537: Loss=0.5661 (C:0.5661, R:0.0105)
Batch 250/537: Loss=0.5511 (C:0.5511, R:0.0105)
Batch 275/537: Loss=0.5631 (C:0.5631, R:0.0105)
Batch 300/537: Loss=0.5699 (C:0.5699, R:0.0105)
Batch 325/537: Loss=0.5614 (C:0.5614, R:0.0105)
Batch 350/537: Loss=0.5353 (C:0.5353, R:0.0105)
Batch 375/537: Loss=0.5749 (C:0.5749, R:0.0105)
Batch 400/537: Loss=0.5239 (C:0.5239, R:0.0105)
Batch 425/537: Loss=0.5790 (C:0.5790, R:0.0105)
Batch 450/537: Loss=0.5579 (C:0.5579, R:0.0105)
Batch 475/537: Loss=0.5287 (C:0.5287, R:0.0105)
Batch 500/537: Loss=0.5511 (C:0.5511, R:0.0105)
Batch 525/537: Loss=0.5630 (C:0.5630, R:0.0105)

============================================================
Epoch 80/300 completed in 21.7s
Train: Loss=0.5462 (C:0.5462, R:0.0105) Ratio=5.27x
Val:   Loss=0.7240 (C:0.7240, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 1 epochs
Checkpoint saved at epoch 80
============================================================

Epoch 81 Training
----------------------------------------
Batch   0/537: Loss=0.5282 (C:0.5282, R:0.0105)
Batch  25/537: Loss=0.5570 (C:0.5570, R:0.0105)
Batch  50/537: Loss=0.5503 (C:0.5503, R:0.0105)
Batch  75/537: Loss=0.5585 (C:0.5585, R:0.0105)
Batch 100/537: Loss=0.4998 (C:0.4998, R:0.0105)
Batch 125/537: Loss=0.5860 (C:0.5860, R:0.0105)
Batch 150/537: Loss=0.5718 (C:0.5718, R:0.0105)
Batch 175/537: Loss=0.5508 (C:0.5508, R:0.0105)
Batch 200/537: Loss=0.5492 (C:0.5492, R:0.0105)
Batch 225/537: Loss=0.5601 (C:0.5601, R:0.0105)
Batch 250/537: Loss=0.5500 (C:0.5500, R:0.0105)
Batch 275/537: Loss=0.5476 (C:0.5476, R:0.0105)
Batch 300/537: Loss=0.5417 (C:0.5417, R:0.0105)
Batch 325/537: Loss=0.5749 (C:0.5749, R:0.0105)
Batch 350/537: Loss=0.5435 (C:0.5435, R:0.0105)
Batch 375/537: Loss=0.5335 (C:0.5335, R:0.0106)
Batch 400/537: Loss=0.5416 (C:0.5416, R:0.0105)
Batch 425/537: Loss=0.5467 (C:0.5467, R:0.0105)
Batch 450/537: Loss=0.5900 (C:0.5900, R:0.0105)
Batch 475/537: Loss=0.5413 (C:0.5413, R:0.0105)
Batch 500/537: Loss=0.5264 (C:0.5264, R:0.0105)
Batch 525/537: Loss=0.5506 (C:0.5506, R:0.0105)

============================================================
Epoch 81/300 completed in 21.5s
Train: Loss=0.5454 (C:0.5454, R:0.0105) Ratio=5.40x
Val:   Loss=0.7228 (C:0.7228, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 82
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.279 ± 0.531
    Neg distances: 2.630 ± 1.082
    Separation ratio: 9.43x
    Gap: -4.326
    ✅ Excellent global separation!

Epoch 82 Training
----------------------------------------
Batch   0/537: Loss=0.5578 (C:0.5578, R:0.0105)
Batch  25/537: Loss=0.5304 (C:0.5304, R:0.0105)
Batch  50/537: Loss=0.5379 (C:0.5379, R:0.0105)
Batch  75/537: Loss=0.5253 (C:0.5253, R:0.0105)
Batch 100/537: Loss=0.5180 (C:0.5180, R:0.0105)
Batch 125/537: Loss=0.5287 (C:0.5287, R:0.0105)
Batch 150/537: Loss=0.4974 (C:0.4974, R:0.0105)
Batch 175/537: Loss=0.5364 (C:0.5364, R:0.0105)
Batch 200/537: Loss=0.5071 (C:0.5071, R:0.0105)
Batch 225/537: Loss=0.4949 (C:0.4949, R:0.0105)
Batch 250/537: Loss=0.5462 (C:0.5462, R:0.0105)
Batch 275/537: Loss=0.5212 (C:0.5212, R:0.0105)
Batch 300/537: Loss=0.5486 (C:0.5486, R:0.0105)
Batch 325/537: Loss=0.5326 (C:0.5326, R:0.0105)
Batch 350/537: Loss=0.5398 (C:0.5398, R:0.0105)
Batch 375/537: Loss=0.4742 (C:0.4742, R:0.0105)
Batch 400/537: Loss=0.5248 (C:0.5248, R:0.0105)
Batch 425/537: Loss=0.5916 (C:0.5916, R:0.0105)
Batch 450/537: Loss=0.5247 (C:0.5247, R:0.0105)
Batch 475/537: Loss=0.5478 (C:0.5478, R:0.0105)
Batch 500/537: Loss=0.5434 (C:0.5434, R:0.0105)
Batch 525/537: Loss=0.5577 (C:0.5577, R:0.0105)

============================================================
Epoch 82/300 completed in 27.7s
Train: Loss=0.5257 (C:0.5257, R:0.0105) Ratio=5.42x
Val:   Loss=0.7057 (C:0.7057, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.7057)
============================================================

Epoch 83 Training
----------------------------------------
Batch   0/537: Loss=0.5007 (C:0.5007, R:0.0105)
Batch  25/537: Loss=0.5247 (C:0.5247, R:0.0105)
Batch  50/537: Loss=0.5617 (C:0.5617, R:0.0105)
Batch  75/537: Loss=0.4870 (C:0.4870, R:0.0105)
Batch 100/537: Loss=0.5118 (C:0.5118, R:0.0106)
Batch 125/537: Loss=0.5531 (C:0.5531, R:0.0105)
Batch 150/537: Loss=0.4619 (C:0.4619, R:0.0105)
Batch 175/537: Loss=0.5160 (C:0.5160, R:0.0105)
Batch 200/537: Loss=0.5438 (C:0.5438, R:0.0105)
Batch 225/537: Loss=0.5086 (C:0.5086, R:0.0105)
Batch 250/537: Loss=0.5248 (C:0.5248, R:0.0106)
Batch 275/537: Loss=0.5588 (C:0.5588, R:0.0105)
Batch 300/537: Loss=0.5255 (C:0.5255, R:0.0105)
Batch 325/537: Loss=0.5231 (C:0.5231, R:0.0105)
Batch 350/537: Loss=0.5478 (C:0.5478, R:0.0105)
Batch 375/537: Loss=0.5242 (C:0.5242, R:0.0105)
Batch 400/537: Loss=0.5196 (C:0.5196, R:0.0105)
Batch 425/537: Loss=0.4817 (C:0.4817, R:0.0105)
Batch 450/537: Loss=0.5277 (C:0.5277, R:0.0105)
Batch 475/537: Loss=0.5226 (C:0.5226, R:0.0105)
Batch 500/537: Loss=0.5327 (C:0.5327, R:0.0105)
Batch 525/537: Loss=0.5287 (C:0.5287, R:0.0105)

============================================================
Epoch 83/300 completed in 21.4s
Train: Loss=0.5237 (C:0.5237, R:0.0105) Ratio=5.40x
Val:   Loss=0.7085 (C:0.7085, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

Epoch 84 Training
----------------------------------------
Batch   0/537: Loss=0.4955 (C:0.4955, R:0.0105)
Batch  25/537: Loss=0.4976 (C:0.4976, R:0.0106)
Batch  50/537: Loss=0.4935 (C:0.4935, R:0.0105)
Batch  75/537: Loss=0.5053 (C:0.5053, R:0.0105)
Batch 100/537: Loss=0.5517 (C:0.5517, R:0.0105)
Batch 125/537: Loss=0.5241 (C:0.5241, R:0.0106)
Batch 150/537: Loss=0.5398 (C:0.5398, R:0.0105)
Batch 175/537: Loss=0.5581 (C:0.5581, R:0.0105)
Batch 200/537: Loss=0.5200 (C:0.5200, R:0.0105)
Batch 225/537: Loss=0.5133 (C:0.5133, R:0.0105)
Batch 250/537: Loss=0.5248 (C:0.5248, R:0.0105)
Batch 275/537: Loss=0.5215 (C:0.5215, R:0.0105)
Batch 300/537: Loss=0.5143 (C:0.5143, R:0.0105)
Batch 325/537: Loss=0.4883 (C:0.4883, R:0.0105)
Batch 350/537: Loss=0.5035 (C:0.5035, R:0.0104)
Batch 375/537: Loss=0.5098 (C:0.5098, R:0.0105)
Batch 400/537: Loss=0.5203 (C:0.5203, R:0.0105)
Batch 425/537: Loss=0.5182 (C:0.5182, R:0.0105)
Batch 450/537: Loss=0.5166 (C:0.5166, R:0.0105)
Batch 475/537: Loss=0.5256 (C:0.5256, R:0.0105)
Batch 500/537: Loss=0.5375 (C:0.5375, R:0.0105)
Batch 525/537: Loss=0.5079 (C:0.5079, R:0.0105)

============================================================
Epoch 84/300 completed in 21.7s
Train: Loss=0.5236 (C:0.5236, R:0.0105) Ratio=5.56x
Val:   Loss=0.7152 (C:0.7152, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 85
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.296 ± 0.592
    Neg distances: 2.642 ± 1.097
    Separation ratio: 8.94x
    Gap: -4.319
    ✅ Excellent global separation!

Epoch 85 Training
----------------------------------------
Batch   0/537: Loss=0.5475 (C:0.5475, R:0.0105)
Batch  25/537: Loss=0.5333 (C:0.5333, R:0.0105)
Batch  50/537: Loss=0.5144 (C:0.5144, R:0.0106)
Batch  75/537: Loss=0.5708 (C:0.5708, R:0.0105)
Batch 100/537: Loss=0.5448 (C:0.5448, R:0.0105)
Batch 125/537: Loss=0.5081 (C:0.5081, R:0.0105)
Batch 150/537: Loss=0.5003 (C:0.5003, R:0.0105)
Batch 175/537: Loss=0.5260 (C:0.5260, R:0.0105)
Batch 200/537: Loss=0.5743 (C:0.5743, R:0.0105)
Batch 225/537: Loss=0.5075 (C:0.5075, R:0.0105)
Batch 250/537: Loss=0.5091 (C:0.5091, R:0.0105)
Batch 275/537: Loss=0.5089 (C:0.5089, R:0.0105)
Batch 300/537: Loss=0.5789 (C:0.5789, R:0.0105)
Batch 325/537: Loss=0.5212 (C:0.5212, R:0.0105)
Batch 350/537: Loss=0.5177 (C:0.5177, R:0.0105)
Batch 375/537: Loss=0.5615 (C:0.5615, R:0.0105)
Batch 400/537: Loss=0.5696 (C:0.5696, R:0.0105)
Batch 425/537: Loss=0.5573 (C:0.5573, R:0.0105)
Batch 450/537: Loss=0.5359 (C:0.5359, R:0.0105)
Batch 475/537: Loss=0.5834 (C:0.5834, R:0.0105)
Batch 500/537: Loss=0.5584 (C:0.5584, R:0.0105)
Batch 525/537: Loss=0.5640 (C:0.5640, R:0.0105)

============================================================
Epoch 85/300 completed in 27.5s
Train: Loss=0.5312 (C:0.5312, R:0.0105) Ratio=5.48x
Val:   Loss=0.7278 (C:0.7278, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

Epoch 86 Training
----------------------------------------
Batch   0/537: Loss=0.5510 (C:0.5510, R:0.0105)
Batch  25/537: Loss=0.5365 (C:0.5365, R:0.0105)
Batch  50/537: Loss=0.5153 (C:0.5153, R:0.0105)
Batch  75/537: Loss=0.5094 (C:0.5094, R:0.0105)
Batch 100/537: Loss=0.5229 (C:0.5229, R:0.0105)
Batch 125/537: Loss=0.5603 (C:0.5603, R:0.0105)
Batch 150/537: Loss=0.5448 (C:0.5448, R:0.0105)
Batch 175/537: Loss=0.5375 (C:0.5375, R:0.0105)
Batch 200/537: Loss=0.5408 (C:0.5408, R:0.0105)
Batch 225/537: Loss=0.5266 (C:0.5266, R:0.0105)
Batch 250/537: Loss=0.5197 (C:0.5197, R:0.0105)
Batch 275/537: Loss=0.5037 (C:0.5037, R:0.0105)
Batch 300/537: Loss=0.5297 (C:0.5297, R:0.0105)
Batch 325/537: Loss=0.5356 (C:0.5356, R:0.0105)
Batch 350/537: Loss=0.5495 (C:0.5495, R:0.0105)
Batch 375/537: Loss=0.5450 (C:0.5450, R:0.0105)
Batch 400/537: Loss=0.5203 (C:0.5203, R:0.0105)
Batch 425/537: Loss=0.5255 (C:0.5255, R:0.0105)
Batch 450/537: Loss=0.5593 (C:0.5593, R:0.0105)
Batch 475/537: Loss=0.5594 (C:0.5594, R:0.0105)
Batch 500/537: Loss=0.5751 (C:0.5751, R:0.0105)
Batch 525/537: Loss=0.5460 (C:0.5460, R:0.0105)

============================================================
Epoch 86/300 completed in 21.7s
Train: Loss=0.5313 (C:0.5313, R:0.0105) Ratio=5.49x
Val:   Loss=0.7114 (C:0.7114, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.300
No improvement for 4 epochs
============================================================

Epoch 87 Training
----------------------------------------
Batch   0/537: Loss=0.5331 (C:0.5331, R:0.0105)
Batch  25/537: Loss=0.5347 (C:0.5347, R:0.0105)
Batch  50/537: Loss=0.5318 (C:0.5318, R:0.0105)
Batch  75/537: Loss=0.5300 (C:0.5300, R:0.0105)
Batch 100/537: Loss=0.5488 (C:0.5488, R:0.0105)
Batch 125/537: Loss=0.5242 (C:0.5242, R:0.0105)
Batch 150/537: Loss=0.5175 (C:0.5175, R:0.0106)
Batch 175/537: Loss=0.5233 (C:0.5233, R:0.0105)
Batch 200/537: Loss=0.5311 (C:0.5311, R:0.0105)
Batch 225/537: Loss=0.5594 (C:0.5594, R:0.0105)
Batch 250/537: Loss=0.5181 (C:0.5181, R:0.0105)
Batch 275/537: Loss=0.5747 (C:0.5747, R:0.0105)
Batch 300/537: Loss=0.5484 (C:0.5484, R:0.0105)
Batch 325/537: Loss=0.5217 (C:0.5217, R:0.0105)
Batch 350/537: Loss=0.5146 (C:0.5146, R:0.0105)
Batch 375/537: Loss=0.5453 (C:0.5453, R:0.0105)
Batch 400/537: Loss=0.4932 (C:0.4932, R:0.0106)
Batch 425/537: Loss=0.5136 (C:0.5136, R:0.0105)
Batch 450/537: Loss=0.5776 (C:0.5776, R:0.0105)
Batch 475/537: Loss=0.5524 (C:0.5524, R:0.0105)
Batch 500/537: Loss=0.5516 (C:0.5516, R:0.0105)
Batch 525/537: Loss=0.5245 (C:0.5245, R:0.0105)

============================================================
Epoch 87/300 completed in 21.7s
Train: Loss=0.5308 (C:0.5308, R:0.0105) Ratio=5.49x
Val:   Loss=0.7187 (C:0.7187, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
No improvement for 5 epochs
============================================================

🌍 Updating global dataset at epoch 88
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.299 ± 0.584
    Neg distances: 2.650 ± 1.104
    Separation ratio: 8.86x
    Gap: -4.424
    ✅ Excellent global separation!

Epoch 88 Training
----------------------------------------
Batch   0/537: Loss=0.5193 (C:0.5193, R:0.0105)
Batch  25/537: Loss=0.5225 (C:0.5225, R:0.0105)
Batch  50/537: Loss=0.5559 (C:0.5559, R:0.0105)
Batch  75/537: Loss=0.5553 (C:0.5553, R:0.0105)
Batch 100/537: Loss=0.5205 (C:0.5205, R:0.0105)
Batch 125/537: Loss=0.5727 (C:0.5727, R:0.0105)
Batch 150/537: Loss=0.5134 (C:0.5134, R:0.0105)
Batch 175/537: Loss=0.5466 (C:0.5466, R:0.0105)
Batch 200/537: Loss=0.5385 (C:0.5385, R:0.0105)
Batch 225/537: Loss=0.4760 (C:0.4760, R:0.0105)
Batch 250/537: Loss=0.5337 (C:0.5337, R:0.0105)
Batch 275/537: Loss=0.5416 (C:0.5416, R:0.0105)
Batch 300/537: Loss=0.5109 (C:0.5109, R:0.0105)
Batch 325/537: Loss=0.4863 (C:0.4863, R:0.0105)
Batch 350/537: Loss=0.5401 (C:0.5401, R:0.0105)
Batch 375/537: Loss=0.5454 (C:0.5454, R:0.0106)
Batch 400/537: Loss=0.5390 (C:0.5390, R:0.0105)
Batch 425/537: Loss=0.5647 (C:0.5647, R:0.0105)
Batch 450/537: Loss=0.5097 (C:0.5097, R:0.0105)
Batch 475/537: Loss=0.5567 (C:0.5567, R:0.0105)
Batch 500/537: Loss=0.5341 (C:0.5341, R:0.0105)
Batch 525/537: Loss=0.5251 (C:0.5251, R:0.0105)

============================================================
Epoch 88/300 completed in 27.5s
Train: Loss=0.5317 (C:0.5317, R:0.0105) Ratio=5.51x
Val:   Loss=0.7266 (C:0.7266, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.300
No improvement for 6 epochs
============================================================

Epoch 89 Training
----------------------------------------
Batch   0/537: Loss=0.5500 (C:0.5500, R:0.0105)
Batch  25/537: Loss=0.4982 (C:0.4982, R:0.0105)
Batch  50/537: Loss=0.5498 (C:0.5498, R:0.0106)
Batch  75/537: Loss=0.5078 (C:0.5078, R:0.0105)
Batch 100/537: Loss=0.5205 (C:0.5205, R:0.0105)
Batch 125/537: Loss=0.5389 (C:0.5389, R:0.0105)
Batch 150/537: Loss=0.5345 (C:0.5345, R:0.0105)
Batch 175/537: Loss=0.4882 (C:0.4882, R:0.0105)
Batch 200/537: Loss=0.5349 (C:0.5349, R:0.0105)
Batch 225/537: Loss=0.5252 (C:0.5252, R:0.0105)
Batch 250/537: Loss=0.4999 (C:0.4999, R:0.0105)
Batch 275/537: Loss=0.5051 (C:0.5051, R:0.0105)
Batch 300/537: Loss=0.5522 (C:0.5522, R:0.0105)
Batch 325/537: Loss=0.4932 (C:0.4932, R:0.0105)
Batch 350/537: Loss=0.5262 (C:0.5262, R:0.0105)
Batch 375/537: Loss=0.5270 (C:0.5270, R:0.0105)
Batch 400/537: Loss=0.5413 (C:0.5413, R:0.0105)
Batch 425/537: Loss=0.5491 (C:0.5491, R:0.0105)
Batch 450/537: Loss=0.5577 (C:0.5577, R:0.0105)
Batch 475/537: Loss=0.5441 (C:0.5441, R:0.0105)
Batch 500/537: Loss=0.5304 (C:0.5304, R:0.0105)
Batch 525/537: Loss=0.5133 (C:0.5133, R:0.0105)

============================================================
Epoch 89/300 completed in 21.6s
Train: Loss=0.5295 (C:0.5295, R:0.0105) Ratio=5.53x
Val:   Loss=0.7158 (C:0.7158, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
No improvement for 7 epochs
============================================================

Epoch 90 Training
----------------------------------------
Batch   0/537: Loss=0.5493 (C:0.5493, R:0.0105)
Batch  25/537: Loss=0.5253 (C:0.5253, R:0.0105)
Batch  50/537: Loss=0.5506 (C:0.5506, R:0.0105)
Batch  75/537: Loss=0.5045 (C:0.5045, R:0.0105)
Batch 100/537: Loss=0.5490 (C:0.5490, R:0.0105)
Batch 125/537: Loss=0.5239 (C:0.5239, R:0.0105)
Batch 150/537: Loss=0.5375 (C:0.5375, R:0.0105)
Batch 175/537: Loss=0.5355 (C:0.5355, R:0.0105)
Batch 200/537: Loss=0.5192 (C:0.5192, R:0.0105)
Batch 225/537: Loss=0.5433 (C:0.5433, R:0.0105)
Batch 250/537: Loss=0.5528 (C:0.5528, R:0.0105)
Batch 275/537: Loss=0.5501 (C:0.5501, R:0.0105)
Batch 300/537: Loss=0.5063 (C:0.5063, R:0.0105)
Batch 325/537: Loss=0.5360 (C:0.5360, R:0.0105)
Batch 350/537: Loss=0.5233 (C:0.5233, R:0.0105)
Batch 375/537: Loss=0.5063 (C:0.5063, R:0.0105)
Batch 400/537: Loss=0.5631 (C:0.5631, R:0.0105)
Batch 425/537: Loss=0.5637 (C:0.5637, R:0.0105)
Batch 450/537: Loss=0.5745 (C:0.5745, R:0.0105)
Batch 475/537: Loss=0.5347 (C:0.5347, R:0.0105)
Batch 500/537: Loss=0.5578 (C:0.5578, R:0.0105)
Batch 525/537: Loss=0.5274 (C:0.5274, R:0.0105)

============================================================
Epoch 90/300 completed in 21.5s
Train: Loss=0.5300 (C:0.5300, R:0.0105) Ratio=5.51x
Val:   Loss=0.7218 (C:0.7218, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
No improvement for 8 epochs

Early stopping triggered after 90 epochs
Best model was at epoch 82 with Val Loss: 0.7057

Global Dataset Training Completed!
Best epoch: 82
Best validation loss: 0.7057
Final separation ratios: Train=5.51x, Val=3.09x
Training completed!
Loading best model from entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin2.0_updatefreq3_max_global_samples5000_20250715_141232/checkpoints/best_model.pt
Starting model evaluation...
========================================
GlobalContrastiveEvaluator initialized on cuda
Starting comprehensive evaluation...
============================================================
Extracting latent representations...
  Processed 1/10 batches
Extracted representations: torch.Size([9824, 75])
Evaluating clustering performance...
Clustering Results:
  Silhouette Score: 0.4605
  Adjusted Rand Score: 0.5304
  Clustering Accuracy: 0.8133
Evaluating classification performance...
  Extracting training representations...
Extracting latent representations...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
Extracted representations: torch.Size([547740, 75])
  Extracting validation representations...
Extracting latent representations...
  Processed 1/9 batches
Extracted representations: torch.Size([9180, 75])
Subsampled training to 50000 samples
  Training on 50000 samples, evaluating on 9180 samples
Classification Results:
  Accuracy: 0.8120
  Per-class F1: [0.8333051849349772, 0.7435527791126062, 0.8605551969012266]
Evaluating reconstruction quality...
Reconstruction Results:
  Average MSE: 0.010432
Evaluating separation quality...
Separation Results:
  Positive distances: 0.764 ± 0.938
  Negative distances: 2.340 ± 1.245
  Separation ratio: 3.06x
  Gap: -4.427
  Perfect separation: No

Comprehensive evaluation completed!

============================================================
EVALUATION SUMMARY
============================================================
Clustering Performance:
  Silhouette Score: 0.4605
  Clustering Accuracy: 0.8133
  Adjusted Rand Score: 0.5304

Classification Performance:
  Accuracy: 0.8120

Separation Quality:
  Separation Ratio: 3.06x
  Gap: -4.427
  Perfect Separation: False

Reconstruction Quality:
  Average MSE: 0.010432
============================================================
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin2.0_updatefreq3_max_global_samples5000_20250715_141232/results/evaluation_results_20250715_144800.json
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin2.0_updatefreq3_max_global_samples5000_20250715_141232/results/evaluation_results_20250715_144800.json
Saving final experiment results...
Final results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin2.0_updatefreq3_max_global_samples5000_20250715_141232/final_results.json

============================================================
PIPELINE COMPLETED SUCCESSFULLY!
============================================================
Experiment directory: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin2.0_updatefreq3_max_global_samples5000_20250715_141232
Best model: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin2.0_updatefreq3_max_global_samples5000_20250715_141232/checkpoints/best_model.pt
Final results: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin2.0_updatefreq3_max_global_samples5000_20250715_141232/final_results.json

Key Results:
  Separation ratio: 3.06x
  Perfect separation: False
  Classification accuracy: 0.8120
  Result: 0.8120% (improvement: +-80.86%)
  Cleaning up: coarse_margin2.0_updatefreq3_max_global_samples5000_20250715_141232

[8/12] Testing: coarse_margin2.0_updatefreq3_max_global_samples10000
  margin: 2.0
  update_frequency: 3
  max_global_samples: 10000
  Reconstruction weight: 0.3 (fixed)
GLOBAL DATASET CONTRASTIVE AUTOENCODER PIPELINE
============================================================
Start time: 2025-07-15 14:48:00.649344
Using device: cuda

Configuration:
  Embedding type: concat
  Batch size: 1020
  Global update frequency: 3 epochs
  Training epochs: 300
Experiment setup completed:
  Experiment directory: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin2.0_updatefreq3_max_global_samples10000_20250715_144800
  Config saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin2.0_updatefreq3_max_global_samples10000_20250715_144800/config.json
Loading data...
========================================
FlexibleEmbedder initialized with type: 'concat'
Output dimension will be: 1536
GlobalDataLoader initialized:
  Embedding type: concat
  Output dimension: 1536
  Sample size: All
Starting data loading pipeline...
============================================================
Loading training data from data/processed/snli_full_standard_SBERT.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 549367 training samples
Loading validation data from data/processed/snli_full_standard_SBERT_validation.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9842 validation samples
Loading test data from data/processed/snli_full_standard_SBERT_test.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9824 test samples
Generating embeddings for training...
Generating concat embeddings on cuda
Processing 549367 samples in batches of 1000
  Processing batch 1/550
  Processing batch 6/550
  Processing batch 11/550
  Processing batch 16/550
  Processing batch 21/550
  Processing batch 26/550
  Processing batch 31/550
  Processing batch 36/550
  Processing batch 41/550
  Processing batch 46/550
  Processing batch 51/550
  Processing batch 56/550
  Processing batch 61/550
  Processing batch 66/550
  Processing batch 71/550
  Processing batch 76/550
  Processing batch 81/550
  Processing batch 86/550
  Processing batch 91/550
  Processing batch 96/550
  Processing batch 101/550
  Processing batch 106/550
  Processing batch 111/550
  Processing batch 116/550
  Processing batch 121/550
  Processing batch 126/550
  Processing batch 131/550
  Processing batch 136/550
  Processing batch 141/550
  Processing batch 146/550
  Processing batch 151/550
  Processing batch 156/550
  Processing batch 161/550
  Processing batch 166/550
  Processing batch 171/550
  Processing batch 176/550
  Processing batch 181/550
  Processing batch 186/550
  Processing batch 191/550
  Processing batch 196/550
  Processing batch 201/550
  Processing batch 206/550
  Processing batch 211/550
  Processing batch 216/550
  Processing batch 221/550
  Processing batch 226/550
  Processing batch 231/550
  Processing batch 236/550
  Processing batch 241/550
  Processing batch 246/550
  Processing batch 251/550
  Processing batch 256/550
  Processing batch 261/550
  Processing batch 266/550
  Processing batch 271/550
  Processing batch 276/550
  Processing batch 281/550
  Processing batch 286/550
  Processing batch 291/550
  Processing batch 296/550
  Processing batch 301/550
  Processing batch 306/550
  Processing batch 311/550
  Processing batch 316/550
  Processing batch 321/550
  Processing batch 326/550
  Processing batch 331/550
  Processing batch 336/550
  Processing batch 341/550
  Processing batch 346/550
  Processing batch 351/550
  Processing batch 356/550
  Processing batch 361/550
  Processing batch 366/550
  Processing batch 371/550
  Processing batch 376/550
  Processing batch 381/550
  Processing batch 386/550
  Processing batch 391/550
  Processing batch 396/550
  Processing batch 401/550
  Processing batch 406/550
  Processing batch 411/550
  Processing batch 416/550
  Processing batch 421/550
  Processing batch 426/550
  Processing batch 431/550
  Processing batch 436/550
  Processing batch 441/550
  Processing batch 446/550
  Processing batch 451/550
  Processing batch 456/550
  Processing batch 461/550
  Processing batch 466/550
  Processing batch 471/550
  Processing batch 476/550
  Processing batch 481/550
  Processing batch 486/550
  Processing batch 491/550
  Processing batch 496/550
  Processing batch 501/550
  Processing batch 506/550
  Processing batch 511/550
  Processing batch 516/550
  Processing batch 521/550
  Processing batch 526/550
  Processing batch 531/550
  Processing batch 536/550
  Processing batch 541/550
  Processing batch 546/550
Generated concat embeddings: torch.Size([549367, 1536])
Generating embeddings for validation...
Generating concat embeddings on cuda
Processing 9842 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9842, 1536])
Generating embeddings for test...
Generating concat embeddings on cuda
Processing 9824 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9824, 1536])
EntailmentDataset created: 549367 samples
  Embedding shape: torch.Size([549367, 1536])
  Class distribution: {'entailment': 183416, 'neutral': 182764, 'contradiction': 183187}
EntailmentDataset created: 9842 samples
  Embedding shape: torch.Size([9842, 1536])
  Class distribution: {'entailment': 3329, 'neutral': 3235, 'contradiction': 3278}
EntailmentDataset created: 9824 samples
  Embedding shape: torch.Size([9824, 1536])
  Class distribution: {'entailment': 3368, 'neutral': 3219, 'contradiction': 3237}

Data loading pipeline completed!
Output embedding dimension: 1536
Updated model input_dim to: 1536
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 537
  Class 2: 183187 samples
  Class 0: 183416 samples
  Class 1: 182764 samples
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 9
  Class 2: 3278 samples
  Class 0: 3329 samples
  Class 1: 3235 samples
DataLoaders created:
  Batch size: 1020
  Balanced sampling: True
  Train batches: 537
  Val batches: 9
  Test batches: 10
Data loading completed!
  Train: 549367 samples, 537 batches
  Val: 9842 samples, 9 batches
  Test: 9824 samples, 10 batches
Creating model and trainer...
========================================
ContrastiveAutoencoder initialized:
  Input dim: 1536
  Latent dim: 75
  Hidden dims: [512, 256]
  Dropout rate: 0.2
  Total parameters: 1,876,555
Model created with 1,876,555 parameters
FullDatasetContrastiveLoss initialized:
  Margin: 2.0
  Update frequency: 3 epochs
  Max global samples: 10000
FullDatasetCombinedLoss initialized:
  Contrastive weight: 1.0
  Base reconstruction weight: 0.0
  Scheduled reconstruction: warmup=30 epochs, max_weight=0.3
Optimizer created (lr=0.0001)
GlobalDatasetTrainer initialized on device: cuda
Model parameters: 1,876,555
Starting training...
========================================
Starting Global Dataset Training...
============================================================

🌍 Updating global dataset at epoch 1
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.090 ± 0.011
    Neg distances: 0.091 ± 0.011
    Separation ratio: 1.00x
    Gap: -0.142
    ❌ Poor global separation

Epoch 1 Training
----------------------------------------
Batch   0/537: Loss=1.9998 (C:1.9998, R:0.0117)
Batch  25/537: Loss=1.9964 (C:1.9964, R:0.0114)
Batch  50/537: Loss=1.9788 (C:1.9788, R:0.0114)
Batch  75/537: Loss=1.9701 (C:1.9701, R:0.0112)
Batch 100/537: Loss=1.9590 (C:1.9590, R:0.0111)
Batch 125/537: Loss=1.9574 (C:1.9574, R:0.0109)
Batch 150/537: Loss=1.9595 (C:1.9595, R:0.0109)
Batch 175/537: Loss=1.9445 (C:1.9445, R:0.0108)
Batch 200/537: Loss=1.9398 (C:1.9398, R:0.0107)
Batch 225/537: Loss=1.9306 (C:1.9306, R:0.0107)
Batch 250/537: Loss=1.9320 (C:1.9320, R:0.0107)
Batch 275/537: Loss=1.9273 (C:1.9273, R:0.0106)
Batch 300/537: Loss=1.9187 (C:1.9187, R:0.0106)
Batch 325/537: Loss=1.9039 (C:1.9039, R:0.0105)
Batch 350/537: Loss=1.9196 (C:1.9196, R:0.0106)
Batch 375/537: Loss=1.9170 (C:1.9170, R:0.0105)
Batch 400/537: Loss=1.9162 (C:1.9162, R:0.0105)
Batch 425/537: Loss=1.9105 (C:1.9105, R:0.0106)
Batch 450/537: Loss=1.9121 (C:1.9121, R:0.0106)
Batch 475/537: Loss=1.8962 (C:1.8962, R:0.0105)
Batch 500/537: Loss=1.9005 (C:1.9005, R:0.0105)
Batch 525/537: Loss=1.8928 (C:1.8928, R:0.0106)

============================================================
Epoch 1/300 completed in 27.1s
Train: Loss=1.9339 (C:1.9339, R:0.0108) Ratio=1.63x
Val:   Loss=1.9006 (C:1.9006, R:0.0104) Ratio=2.14x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.9006)
============================================================

Epoch 2 Training
----------------------------------------
Batch   0/537: Loss=1.9061 (C:1.9061, R:0.0105)
Batch  25/537: Loss=1.9013 (C:1.9013, R:0.0105)
Batch  50/537: Loss=1.8951 (C:1.8951, R:0.0106)
Batch  75/537: Loss=1.8923 (C:1.8923, R:0.0105)
Batch 100/537: Loss=1.8972 (C:1.8972, R:0.0105)
Batch 125/537: Loss=1.9006 (C:1.9006, R:0.0105)
Batch 150/537: Loss=1.9004 (C:1.9004, R:0.0105)
Batch 175/537: Loss=1.8996 (C:1.8996, R:0.0105)
Batch 200/537: Loss=1.9049 (C:1.9049, R:0.0105)
Batch 225/537: Loss=1.8892 (C:1.8892, R:0.0105)
Batch 250/537: Loss=1.9015 (C:1.9015, R:0.0105)
Batch 275/537: Loss=1.9060 (C:1.9060, R:0.0105)
Batch 300/537: Loss=1.8868 (C:1.8868, R:0.0105)
Batch 325/537: Loss=1.8940 (C:1.8940, R:0.0105)
Batch 350/537: Loss=1.8859 (C:1.8859, R:0.0105)
Batch 375/537: Loss=1.8788 (C:1.8788, R:0.0105)
Batch 400/537: Loss=1.8937 (C:1.8937, R:0.0105)
Batch 425/537: Loss=1.8963 (C:1.8963, R:0.0105)
Batch 450/537: Loss=1.8954 (C:1.8954, R:0.0105)
Batch 475/537: Loss=1.8778 (C:1.8778, R:0.0105)
Batch 500/537: Loss=1.8759 (C:1.8759, R:0.0105)
Batch 525/537: Loss=1.8873 (C:1.8873, R:0.0106)

============================================================
Epoch 2/300 completed in 22.2s
Train: Loss=1.8932 (C:1.8932, R:0.0105) Ratio=2.21x
Val:   Loss=1.8844 (C:1.8844, R:0.0104) Ratio=2.37x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.8844)
============================================================

Epoch 3 Training
----------------------------------------
Batch   0/537: Loss=1.8793 (C:1.8793, R:0.0105)
Batch  25/537: Loss=1.8963 (C:1.8963, R:0.0105)
Batch  50/537: Loss=1.8811 (C:1.8811, R:0.0105)
Batch  75/537: Loss=1.8789 (C:1.8789, R:0.0105)
Batch 100/537: Loss=1.8851 (C:1.8851, R:0.0105)
Batch 125/537: Loss=1.8843 (C:1.8843, R:0.0105)
Batch 150/537: Loss=1.8794 (C:1.8794, R:0.0105)
Batch 175/537: Loss=1.8865 (C:1.8865, R:0.0105)
Batch 200/537: Loss=1.8756 (C:1.8756, R:0.0105)
Batch 225/537: Loss=1.8688 (C:1.8688, R:0.0105)
Batch 250/537: Loss=1.8884 (C:1.8884, R:0.0105)
Batch 275/537: Loss=1.8903 (C:1.8903, R:0.0105)
Batch 300/537: Loss=1.8848 (C:1.8848, R:0.0105)
Batch 325/537: Loss=1.8834 (C:1.8834, R:0.0105)
Batch 350/537: Loss=1.8829 (C:1.8829, R:0.0105)
Batch 375/537: Loss=1.8863 (C:1.8863, R:0.0105)
Batch 400/537: Loss=1.8695 (C:1.8695, R:0.0105)
Batch 425/537: Loss=1.8700 (C:1.8700, R:0.0105)
Batch 450/537: Loss=1.8901 (C:1.8901, R:0.0105)
Batch 475/537: Loss=1.8780 (C:1.8780, R:0.0105)
Batch 500/537: Loss=1.8761 (C:1.8761, R:0.0105)
Batch 525/537: Loss=1.8834 (C:1.8834, R:0.0105)

============================================================
Epoch 3/300 completed in 22.2s
Train: Loss=1.8821 (C:1.8821, R:0.0105) Ratio=2.39x
Val:   Loss=1.8801 (C:1.8801, R:0.0104) Ratio=2.50x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.8801)
============================================================

🌍 Updating global dataset at epoch 4
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.534 ± 0.568
    Neg distances: 1.438 ± 0.828
    Separation ratio: 2.69x
    Gap: -3.211
    ✅ Good global separation

Epoch 4 Training
----------------------------------------
Batch   0/537: Loss=1.2050 (C:1.2050, R:0.0105)
Batch  25/537: Loss=1.2339 (C:1.2339, R:0.0105)
Batch  50/537: Loss=1.2510 (C:1.2510, R:0.0105)
Batch  75/537: Loss=1.2542 (C:1.2542, R:0.0105)
Batch 100/537: Loss=1.2295 (C:1.2295, R:0.0105)
Batch 125/537: Loss=1.2442 (C:1.2442, R:0.0105)
Batch 150/537: Loss=1.2517 (C:1.2517, R:0.0105)
Batch 175/537: Loss=1.2175 (C:1.2175, R:0.0105)
Batch 200/537: Loss=1.2143 (C:1.2143, R:0.0105)
Batch 225/537: Loss=1.2367 (C:1.2367, R:0.0105)
Batch 250/537: Loss=1.2515 (C:1.2515, R:0.0105)
Batch 275/537: Loss=1.2020 (C:1.2020, R:0.0105)
Batch 300/537: Loss=1.2284 (C:1.2284, R:0.0105)
Batch 325/537: Loss=1.2080 (C:1.2080, R:0.0105)
Batch 350/537: Loss=1.2628 (C:1.2628, R:0.0105)
Batch 375/537: Loss=1.2642 (C:1.2642, R:0.0105)
Batch 400/537: Loss=1.2631 (C:1.2631, R:0.0105)
Batch 425/537: Loss=1.2288 (C:1.2288, R:0.0105)
Batch 450/537: Loss=1.2184 (C:1.2184, R:0.0105)
Batch 475/537: Loss=1.2035 (C:1.2035, R:0.0105)
Batch 500/537: Loss=1.2339 (C:1.2339, R:0.0105)
Batch 525/537: Loss=1.2285 (C:1.2285, R:0.0105)

============================================================
Epoch 4/300 completed in 28.9s
Train: Loss=1.2356 (C:1.2356, R:0.0105) Ratio=2.51x
Val:   Loss=1.2235 (C:1.2235, R:0.0104) Ratio=2.62x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.2235)
============================================================

Epoch 5 Training
----------------------------------------
Batch   0/537: Loss=1.2223 (C:1.2223, R:0.0105)
Batch  25/537: Loss=1.2385 (C:1.2385, R:0.0105)
Batch  50/537: Loss=1.1989 (C:1.1989, R:0.0106)
Batch  75/537: Loss=1.2342 (C:1.2342, R:0.0105)
Batch 100/537: Loss=1.2013 (C:1.2013, R:0.0105)
Batch 125/537: Loss=1.2369 (C:1.2369, R:0.0105)
Batch 150/537: Loss=1.2532 (C:1.2532, R:0.0105)
Batch 175/537: Loss=1.2118 (C:1.2118, R:0.0106)
Batch 200/537: Loss=1.2051 (C:1.2051, R:0.0105)
Batch 225/537: Loss=1.1994 (C:1.1994, R:0.0105)
Batch 250/537: Loss=1.1913 (C:1.1913, R:0.0105)
Batch 275/537: Loss=1.1967 (C:1.1967, R:0.0105)
Batch 300/537: Loss=1.1813 (C:1.1813, R:0.0105)
Batch 325/537: Loss=1.2550 (C:1.2550, R:0.0105)
Batch 350/537: Loss=1.1943 (C:1.1943, R:0.0105)
Batch 375/537: Loss=1.1989 (C:1.1989, R:0.0106)
Batch 400/537: Loss=1.2360 (C:1.2360, R:0.0105)
Batch 425/537: Loss=1.2183 (C:1.2183, R:0.0105)
Batch 450/537: Loss=1.2182 (C:1.2182, R:0.0106)
Batch 475/537: Loss=1.2071 (C:1.2071, R:0.0105)
Batch 500/537: Loss=1.2199 (C:1.2199, R:0.0105)
Batch 525/537: Loss=1.2291 (C:1.2291, R:0.0105)

============================================================
Epoch 5/300 completed in 22.9s
Train: Loss=1.2111 (C:1.2111, R:0.0105) Ratio=2.73x
Val:   Loss=1.2208 (C:1.2208, R:0.0104) Ratio=2.68x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.2208)
============================================================

Epoch 6 Training
----------------------------------------
Batch   0/537: Loss=1.2150 (C:1.2150, R:0.0105)
Batch  25/537: Loss=1.2066 (C:1.2066, R:0.0105)
Batch  50/537: Loss=1.2141 (C:1.2141, R:0.0105)
Batch  75/537: Loss=1.1646 (C:1.1646, R:0.0105)
Batch 100/537: Loss=1.1967 (C:1.1967, R:0.0105)
Batch 125/537: Loss=1.2167 (C:1.2167, R:0.0106)
Batch 150/537: Loss=1.2069 (C:1.2069, R:0.0105)
Batch 175/537: Loss=1.2349 (C:1.2349, R:0.0105)
Batch 200/537: Loss=1.1847 (C:1.1847, R:0.0105)
Batch 225/537: Loss=1.1692 (C:1.1692, R:0.0105)
Batch 250/537: Loss=1.1959 (C:1.1959, R:0.0105)
Batch 275/537: Loss=1.1925 (C:1.1925, R:0.0105)
Batch 300/537: Loss=1.1798 (C:1.1798, R:0.0105)
Batch 325/537: Loss=1.2172 (C:1.2172, R:0.0105)
Batch 350/537: Loss=1.1570 (C:1.1570, R:0.0104)
Batch 375/537: Loss=1.2029 (C:1.2029, R:0.0105)
Batch 400/537: Loss=1.2203 (C:1.2203, R:0.0105)
Batch 425/537: Loss=1.2071 (C:1.2071, R:0.0105)
Batch 450/537: Loss=1.2420 (C:1.2420, R:0.0106)
Batch 475/537: Loss=1.2126 (C:1.2126, R:0.0105)
Batch 500/537: Loss=1.1848 (C:1.1848, R:0.0105)
Batch 525/537: Loss=1.1975 (C:1.1975, R:0.0105)

============================================================
Epoch 6/300 completed in 22.8s
Train: Loss=1.2001 (C:1.2001, R:0.0105) Ratio=2.90x
Val:   Loss=1.2179 (C:1.2179, R:0.0104) Ratio=2.76x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.2179)
============================================================

🌍 Updating global dataset at epoch 7
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.467 ± 0.545
    Neg distances: 1.562 ± 0.848
    Separation ratio: 3.34x
    Gap: -3.182
    ✅ Excellent global separation!

Epoch 7 Training
----------------------------------------
Batch   0/537: Loss=1.0905 (C:1.0905, R:0.0105)
Batch  25/537: Loss=1.0864 (C:1.0864, R:0.0105)
Batch  50/537: Loss=1.0951 (C:1.0951, R:0.0105)
Batch  75/537: Loss=1.0767 (C:1.0767, R:0.0105)
Batch 100/537: Loss=1.1010 (C:1.1010, R:0.0105)
Batch 125/537: Loss=1.0967 (C:1.0967, R:0.0104)
Batch 150/537: Loss=1.1132 (C:1.1132, R:0.0106)
Batch 175/537: Loss=1.0982 (C:1.0982, R:0.0105)
Batch 200/537: Loss=1.1145 (C:1.1145, R:0.0106)
Batch 225/537: Loss=1.0892 (C:1.0892, R:0.0105)
Batch 250/537: Loss=1.1030 (C:1.1030, R:0.0105)
Batch 275/537: Loss=1.1078 (C:1.1078, R:0.0105)
Batch 300/537: Loss=1.1200 (C:1.1200, R:0.0105)
Batch 325/537: Loss=1.0755 (C:1.0755, R:0.0105)
Batch 350/537: Loss=1.0912 (C:1.0912, R:0.0105)
Batch 375/537: Loss=1.0900 (C:1.0900, R:0.0105)
Batch 400/537: Loss=1.1496 (C:1.1496, R:0.0105)
Batch 425/537: Loss=1.1337 (C:1.1337, R:0.0105)
Batch 450/537: Loss=1.1365 (C:1.1365, R:0.0105)
Batch 475/537: Loss=1.1204 (C:1.1204, R:0.0105)
Batch 500/537: Loss=1.1526 (C:1.1526, R:0.0105)
Batch 525/537: Loss=1.0848 (C:1.0848, R:0.0106)

============================================================
Epoch 7/300 completed in 29.5s
Train: Loss=1.1032 (C:1.1032, R:0.0105) Ratio=2.99x
Val:   Loss=1.1289 (C:1.1289, R:0.0104) Ratio=2.77x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.1289)
============================================================

Epoch 8 Training
----------------------------------------
Batch   0/537: Loss=1.0690 (C:1.0690, R:0.0105)
Batch  25/537: Loss=1.0712 (C:1.0712, R:0.0105)
Batch  50/537: Loss=1.1036 (C:1.1036, R:0.0105)
Batch  75/537: Loss=1.0981 (C:1.0981, R:0.0105)
Batch 100/537: Loss=1.0608 (C:1.0608, R:0.0105)
Batch 125/537: Loss=1.0746 (C:1.0746, R:0.0105)
Batch 150/537: Loss=1.1039 (C:1.1039, R:0.0105)
Batch 175/537: Loss=1.0768 (C:1.0768, R:0.0105)
Batch 200/537: Loss=1.1018 (C:1.1018, R:0.0105)
Batch 225/537: Loss=1.0904 (C:1.0904, R:0.0105)
Batch 250/537: Loss=1.1013 (C:1.1013, R:0.0105)
Batch 275/537: Loss=1.1084 (C:1.1084, R:0.0105)
Batch 300/537: Loss=1.0605 (C:1.0605, R:0.0105)
Batch 325/537: Loss=1.1062 (C:1.1062, R:0.0105)
Batch 350/537: Loss=1.0724 (C:1.0724, R:0.0105)
Batch 375/537: Loss=1.0727 (C:1.0727, R:0.0105)
Batch 400/537: Loss=1.0789 (C:1.0789, R:0.0105)
Batch 425/537: Loss=1.0607 (C:1.0607, R:0.0105)
Batch 450/537: Loss=1.0799 (C:1.0799, R:0.0105)
Batch 475/537: Loss=1.1180 (C:1.1180, R:0.0105)
Batch 500/537: Loss=1.1128 (C:1.1128, R:0.0105)
Batch 525/537: Loss=1.0921 (C:1.0921, R:0.0105)

============================================================
Epoch 8/300 completed in 22.7s
Train: Loss=1.0927 (C:1.0927, R:0.0105) Ratio=3.14x
Val:   Loss=1.1170 (C:1.1170, R:0.0104) Ratio=2.83x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.1170)
============================================================

Epoch 9 Training
----------------------------------------
Batch   0/537: Loss=1.0853 (C:1.0853, R:0.0106)
Batch  25/537: Loss=1.0837 (C:1.0837, R:0.0105)
Batch  50/537: Loss=1.1030 (C:1.1030, R:0.0105)
Batch  75/537: Loss=1.0643 (C:1.0643, R:0.0105)
Batch 100/537: Loss=1.0858 (C:1.0858, R:0.0105)
Batch 125/537: Loss=1.0773 (C:1.0773, R:0.0105)
Batch 150/537: Loss=1.0638 (C:1.0638, R:0.0105)
Batch 175/537: Loss=1.0962 (C:1.0962, R:0.0105)
Batch 200/537: Loss=1.0703 (C:1.0703, R:0.0105)
Batch 225/537: Loss=1.0396 (C:1.0396, R:0.0105)
Batch 250/537: Loss=1.0829 (C:1.0829, R:0.0105)
Batch 275/537: Loss=1.1034 (C:1.1034, R:0.0105)
Batch 300/537: Loss=1.0874 (C:1.0874, R:0.0105)
Batch 325/537: Loss=1.1134 (C:1.1134, R:0.0105)
Batch 350/537: Loss=1.1126 (C:1.1126, R:0.0105)
Batch 375/537: Loss=1.0738 (C:1.0738, R:0.0105)
Batch 400/537: Loss=1.0699 (C:1.0699, R:0.0105)
Batch 425/537: Loss=1.1309 (C:1.1309, R:0.0105)
Batch 450/537: Loss=1.1115 (C:1.1115, R:0.0105)
Batch 475/537: Loss=1.0773 (C:1.0773, R:0.0105)
Batch 500/537: Loss=1.1227 (C:1.1227, R:0.0105)
Batch 525/537: Loss=1.1134 (C:1.1134, R:0.0105)

============================================================
Epoch 9/300 completed in 21.9s
Train: Loss=1.0850 (C:1.0850, R:0.0105) Ratio=3.16x
Val:   Loss=1.1059 (C:1.1059, R:0.0104) Ratio=2.88x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.1059)
============================================================

🌍 Updating global dataset at epoch 10
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.423 ± 0.535
    Neg distances: 1.618 ± 0.846
    Separation ratio: 3.83x
    Gap: -3.141
    ✅ Excellent global separation!

Epoch 10 Training
----------------------------------------
Batch   0/537: Loss=1.0141 (C:1.0141, R:0.0105)
Batch  25/537: Loss=1.0325 (C:1.0325, R:0.0106)
Batch  50/537: Loss=1.0139 (C:1.0139, R:0.0105)
Batch  75/537: Loss=1.0379 (C:1.0379, R:0.0105)
Batch 100/537: Loss=1.0201 (C:1.0201, R:0.0105)
Batch 125/537: Loss=1.0498 (C:1.0498, R:0.0105)
Batch 150/537: Loss=1.0375 (C:1.0375, R:0.0105)
Batch 175/537: Loss=1.0022 (C:1.0022, R:0.0105)
Batch 200/537: Loss=1.0304 (C:1.0304, R:0.0105)
Batch 225/537: Loss=1.0361 (C:1.0361, R:0.0105)
Batch 250/537: Loss=1.0416 (C:1.0416, R:0.0105)
Batch 275/537: Loss=1.0272 (C:1.0272, R:0.0105)
Batch 300/537: Loss=1.0227 (C:1.0227, R:0.0105)
Batch 325/537: Loss=1.0140 (C:1.0140, R:0.0105)
Batch 350/537: Loss=1.0823 (C:1.0823, R:0.0105)
Batch 375/537: Loss=1.0091 (C:1.0091, R:0.0105)
Batch 400/537: Loss=1.0234 (C:1.0234, R:0.0105)
Batch 425/537: Loss=1.0508 (C:1.0508, R:0.0105)
Batch 450/537: Loss=1.0713 (C:1.0713, R:0.0105)
Batch 475/537: Loss=1.0276 (C:1.0276, R:0.0105)
Batch 500/537: Loss=1.0197 (C:1.0197, R:0.0105)
Batch 525/537: Loss=1.0506 (C:1.0506, R:0.0105)

============================================================
Epoch 10/300 completed in 27.8s
Train: Loss=1.0319 (C:1.0319, R:0.0105) Ratio=3.28x
Val:   Loss=1.0719 (C:1.0719, R:0.0104) Ratio=2.89x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.0719)
============================================================

Epoch 11 Training
----------------------------------------
Batch   0/537: Loss=1.0314 (C:1.0314, R:0.0105)
Batch  25/537: Loss=1.0038 (C:1.0038, R:0.0105)
Batch  50/537: Loss=0.9947 (C:0.9947, R:0.0105)
Batch  75/537: Loss=1.0331 (C:1.0331, R:0.0105)
Batch 100/537: Loss=1.0681 (C:1.0681, R:0.0105)
Batch 125/537: Loss=1.0195 (C:1.0195, R:0.0105)
Batch 150/537: Loss=1.0250 (C:1.0250, R:0.0105)
Batch 175/537: Loss=1.0040 (C:1.0040, R:0.0105)
Batch 200/537: Loss=1.0308 (C:1.0308, R:0.0105)
Batch 225/537: Loss=0.9977 (C:0.9977, R:0.0105)
Batch 250/537: Loss=1.0430 (C:1.0430, R:0.0105)
Batch 275/537: Loss=1.0359 (C:1.0359, R:0.0105)
Batch 300/537: Loss=1.0409 (C:1.0409, R:0.0105)
Batch 325/537: Loss=1.0054 (C:1.0054, R:0.0105)
Batch 350/537: Loss=1.0268 (C:1.0268, R:0.0105)
Batch 375/537: Loss=1.0400 (C:1.0400, R:0.0105)
Batch 400/537: Loss=1.0042 (C:1.0042, R:0.0105)
Batch 425/537: Loss=1.0209 (C:1.0209, R:0.0105)
Batch 450/537: Loss=1.0541 (C:1.0541, R:0.0105)
Batch 475/537: Loss=1.0170 (C:1.0170, R:0.0105)
Batch 500/537: Loss=1.0220 (C:1.0220, R:0.0105)
Batch 525/537: Loss=1.0170 (C:1.0170, R:0.0105)

============================================================
Epoch 11/300 completed in 21.5s
Train: Loss=1.0244 (C:1.0244, R:0.0105) Ratio=3.32x
Val:   Loss=1.0603 (C:1.0603, R:0.0104) Ratio=2.94x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.0603)
============================================================

Epoch 12 Training
----------------------------------------
Batch   0/537: Loss=1.0155 (C:1.0155, R:0.0105)
Batch  25/537: Loss=1.0385 (C:1.0385, R:0.0105)
Batch  50/537: Loss=1.0371 (C:1.0371, R:0.0105)
Batch  75/537: Loss=1.0344 (C:1.0344, R:0.0105)
Batch 100/537: Loss=1.0609 (C:1.0609, R:0.0105)
Batch 125/537: Loss=0.9938 (C:0.9938, R:0.0105)
Batch 150/537: Loss=1.0429 (C:1.0429, R:0.0105)
Batch 175/537: Loss=1.0195 (C:1.0195, R:0.0105)
Batch 200/537: Loss=1.0075 (C:1.0075, R:0.0105)
Batch 225/537: Loss=0.9860 (C:0.9860, R:0.0105)
Batch 250/537: Loss=1.0395 (C:1.0395, R:0.0105)
Batch 275/537: Loss=1.0142 (C:1.0142, R:0.0105)
Batch 300/537: Loss=1.0138 (C:1.0138, R:0.0105)
Batch 325/537: Loss=0.9802 (C:0.9802, R:0.0106)
Batch 350/537: Loss=1.0057 (C:1.0057, R:0.0105)
Batch 375/537: Loss=1.0075 (C:1.0075, R:0.0105)
Batch 400/537: Loss=0.9843 (C:0.9843, R:0.0105)
Batch 425/537: Loss=0.9878 (C:0.9878, R:0.0105)
Batch 450/537: Loss=1.0187 (C:1.0187, R:0.0105)
Batch 475/537: Loss=1.0049 (C:1.0049, R:0.0105)
Batch 500/537: Loss=1.0627 (C:1.0627, R:0.0105)
Batch 525/537: Loss=1.0378 (C:1.0378, R:0.0105)

============================================================
Epoch 12/300 completed in 21.4s
Train: Loss=1.0193 (C:1.0193, R:0.0105) Ratio=3.42x
Val:   Loss=1.0738 (C:1.0738, R:0.0104) Ratio=2.91x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 13
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.393 ± 0.545
    Neg distances: 1.702 ± 0.861
    Separation ratio: 4.33x
    Gap: -3.062
    ✅ Excellent global separation!

Epoch 13 Training
----------------------------------------
Batch   0/537: Loss=0.9440 (C:0.9440, R:0.0105)
Batch  25/537: Loss=0.9383 (C:0.9383, R:0.0105)
Batch  50/537: Loss=0.9677 (C:0.9677, R:0.0105)
Batch  75/537: Loss=0.9189 (C:0.9189, R:0.0105)
Batch 100/537: Loss=0.9680 (C:0.9680, R:0.0105)
Batch 125/537: Loss=0.9374 (C:0.9374, R:0.0105)
Batch 150/537: Loss=0.9652 (C:0.9652, R:0.0105)
Batch 175/537: Loss=0.9358 (C:0.9358, R:0.0105)
Batch 200/537: Loss=0.9922 (C:0.9922, R:0.0105)
Batch 225/537: Loss=1.0077 (C:1.0077, R:0.0105)
Batch 250/537: Loss=0.9703 (C:0.9703, R:0.0105)
Batch 275/537: Loss=0.9818 (C:0.9818, R:0.0105)
Batch 300/537: Loss=0.9918 (C:0.9918, R:0.0105)
Batch 325/537: Loss=0.9590 (C:0.9590, R:0.0105)
Batch 350/537: Loss=1.0008 (C:1.0008, R:0.0105)
Batch 375/537: Loss=0.9604 (C:0.9604, R:0.0105)
Batch 400/537: Loss=0.9574 (C:0.9574, R:0.0105)
Batch 425/537: Loss=0.9805 (C:0.9805, R:0.0105)
Batch 450/537: Loss=0.9948 (C:0.9948, R:0.0105)
Batch 475/537: Loss=0.9903 (C:0.9903, R:0.0105)
Batch 500/537: Loss=0.9897 (C:0.9897, R:0.0105)
Batch 525/537: Loss=0.9712 (C:0.9712, R:0.0105)

============================================================
Epoch 13/300 completed in 27.6s
Train: Loss=0.9704 (C:0.9704, R:0.0105) Ratio=3.47x
Val:   Loss=1.0143 (C:1.0143, R:0.0104) Ratio=2.99x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.0143)
============================================================

Epoch 14 Training
----------------------------------------
Batch   0/537: Loss=0.9572 (C:0.9572, R:0.0105)
Batch  25/537: Loss=0.9620 (C:0.9620, R:0.0105)
Batch  50/537: Loss=0.9105 (C:0.9105, R:0.0105)
Batch  75/537: Loss=0.9403 (C:0.9403, R:0.0105)
Batch 100/537: Loss=0.9883 (C:0.9883, R:0.0105)
Batch 125/537: Loss=0.9577 (C:0.9577, R:0.0105)
Batch 150/537: Loss=0.9811 (C:0.9811, R:0.0105)
Batch 175/537: Loss=0.9723 (C:0.9723, R:0.0105)
Batch 200/537: Loss=0.9565 (C:0.9565, R:0.0105)
Batch 225/537: Loss=0.9481 (C:0.9481, R:0.0105)
Batch 250/537: Loss=0.9587 (C:0.9587, R:0.0106)
Batch 275/537: Loss=0.9564 (C:0.9564, R:0.0105)
Batch 300/537: Loss=0.9936 (C:0.9936, R:0.0105)
Batch 325/537: Loss=0.9419 (C:0.9419, R:0.0105)
Batch 350/537: Loss=0.9933 (C:0.9933, R:0.0105)
Batch 375/537: Loss=0.9894 (C:0.9894, R:0.0105)
Batch 400/537: Loss=0.9901 (C:0.9901, R:0.0105)
Batch 425/537: Loss=0.9590 (C:0.9590, R:0.0105)
Batch 450/537: Loss=0.9439 (C:0.9439, R:0.0105)
Batch 475/537: Loss=0.9594 (C:0.9594, R:0.0105)
Batch 500/537: Loss=0.9551 (C:0.9551, R:0.0105)
Batch 525/537: Loss=0.9674 (C:0.9674, R:0.0105)

============================================================
Epoch 14/300 completed in 21.3s
Train: Loss=0.9651 (C:0.9651, R:0.0105) Ratio=3.66x
Val:   Loss=1.0295 (C:1.0295, R:0.0104) Ratio=2.97x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

Epoch 15 Training
----------------------------------------
Batch   0/537: Loss=0.9645 (C:0.9645, R:0.0105)
Batch  25/537: Loss=0.9672 (C:0.9672, R:0.0105)
Batch  50/537: Loss=0.9454 (C:0.9454, R:0.0105)
Batch  75/537: Loss=0.9875 (C:0.9875, R:0.0105)
Batch 100/537: Loss=0.9339 (C:0.9339, R:0.0105)
Batch 125/537: Loss=0.9564 (C:0.9564, R:0.0106)
Batch 150/537: Loss=0.9552 (C:0.9552, R:0.0105)
Batch 175/537: Loss=0.9786 (C:0.9786, R:0.0105)
Batch 200/537: Loss=0.9872 (C:0.9872, R:0.0105)
Batch 225/537: Loss=0.9522 (C:0.9522, R:0.0105)
Batch 250/537: Loss=0.9416 (C:0.9416, R:0.0105)
Batch 275/537: Loss=0.9429 (C:0.9429, R:0.0106)
Batch 300/537: Loss=0.9392 (C:0.9392, R:0.0105)
Batch 325/537: Loss=0.9692 (C:0.9692, R:0.0105)
Batch 350/537: Loss=0.9683 (C:0.9683, R:0.0105)
Batch 375/537: Loss=0.9589 (C:0.9589, R:0.0105)
Batch 400/537: Loss=0.9318 (C:0.9318, R:0.0105)
Batch 425/537: Loss=0.9673 (C:0.9673, R:0.0105)
Batch 450/537: Loss=0.9442 (C:0.9442, R:0.0105)
Batch 475/537: Loss=0.9580 (C:0.9580, R:0.0105)
Batch 500/537: Loss=0.9724 (C:0.9724, R:0.0105)
Batch 525/537: Loss=0.9337 (C:0.9337, R:0.0105)

============================================================
Epoch 15/300 completed in 21.8s
Train: Loss=0.9605 (C:0.9605, R:0.0105) Ratio=3.65x
Val:   Loss=1.0146 (C:1.0146, R:0.0104) Ratio=2.97x
Reconstruction weight: 0.000
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 16
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.391 ± 0.550
    Neg distances: 1.748 ± 0.880
    Separation ratio: 4.47x
    Gap: -3.002
    ✅ Excellent global separation!

Epoch 16 Training
----------------------------------------
Batch   0/537: Loss=0.9158 (C:0.9158, R:0.0105)
Batch  25/537: Loss=0.9462 (C:0.9462, R:0.0104)
Batch  50/537: Loss=0.9683 (C:0.9683, R:0.0105)
Batch  75/537: Loss=0.9004 (C:0.9004, R:0.0105)
Batch 100/537: Loss=0.9560 (C:0.9560, R:0.0105)
Batch 125/537: Loss=0.9517 (C:0.9517, R:0.0105)
Batch 150/537: Loss=0.9221 (C:0.9221, R:0.0105)
Batch 175/537: Loss=0.9274 (C:0.9274, R:0.0105)
Batch 200/537: Loss=0.9671 (C:0.9671, R:0.0105)
Batch 225/537: Loss=0.9681 (C:0.9681, R:0.0105)
Batch 250/537: Loss=0.9304 (C:0.9304, R:0.0105)
Batch 275/537: Loss=0.9321 (C:0.9321, R:0.0105)
Batch 300/537: Loss=0.9523 (C:0.9523, R:0.0105)
Batch 325/537: Loss=0.9423 (C:0.9423, R:0.0106)
Batch 350/537: Loss=0.9298 (C:0.9298, R:0.0105)
Batch 375/537: Loss=0.9246 (C:0.9246, R:0.0105)
Batch 400/537: Loss=0.9293 (C:0.9293, R:0.0105)
Batch 425/537: Loss=0.9545 (C:0.9545, R:0.0105)
Batch 450/537: Loss=0.9155 (C:0.9155, R:0.0105)
Batch 475/537: Loss=0.9342 (C:0.9342, R:0.0105)
Batch 500/537: Loss=0.9362 (C:0.9362, R:0.0105)
Batch 525/537: Loss=0.9495 (C:0.9495, R:0.0105)

============================================================
Epoch 16/300 completed in 27.2s
Train: Loss=0.9432 (C:0.9432, R:0.0105) Ratio=3.72x
Val:   Loss=1.0069 (C:1.0069, R:0.0104) Ratio=3.01x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.0069)
============================================================

Epoch 17 Training
----------------------------------------
Batch   0/537: Loss=0.9562 (C:0.9562, R:0.0106)
Batch  25/537: Loss=0.9068 (C:0.9068, R:0.0105)
Batch  50/537: Loss=0.9363 (C:0.9363, R:0.0105)
Batch  75/537: Loss=0.9443 (C:0.9443, R:0.0105)
Batch 100/537: Loss=0.9522 (C:0.9522, R:0.0105)
Batch 125/537: Loss=0.9301 (C:0.9301, R:0.0105)
Batch 150/537: Loss=0.9646 (C:0.9646, R:0.0105)
Batch 175/537: Loss=0.9419 (C:0.9419, R:0.0106)
Batch 200/537: Loss=0.9644 (C:0.9644, R:0.0105)
Batch 225/537: Loss=0.9279 (C:0.9279, R:0.0105)
Batch 250/537: Loss=0.9423 (C:0.9423, R:0.0105)
Batch 275/537: Loss=0.9289 (C:0.9289, R:0.0105)
Batch 300/537: Loss=0.9185 (C:0.9185, R:0.0105)
Batch 325/537: Loss=0.9163 (C:0.9163, R:0.0105)
Batch 350/537: Loss=0.9627 (C:0.9627, R:0.0105)
Batch 375/537: Loss=0.9226 (C:0.9226, R:0.0105)
Batch 400/537: Loss=0.9635 (C:0.9635, R:0.0105)
Batch 425/537: Loss=0.9607 (C:0.9607, R:0.0105)
Batch 450/537: Loss=0.9529 (C:0.9529, R:0.0105)
Batch 475/537: Loss=0.9521 (C:0.9521, R:0.0105)
Batch 500/537: Loss=0.9557 (C:0.9557, R:0.0105)
Batch 525/537: Loss=0.9384 (C:0.9384, R:0.0105)

============================================================
Epoch 17/300 completed in 21.7s
Train: Loss=0.9396 (C:0.9396, R:0.0105) Ratio=3.72x
Val:   Loss=1.0028 (C:1.0028, R:0.0104) Ratio=2.97x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.0028)
============================================================

Epoch 18 Training
----------------------------------------
Batch   0/537: Loss=0.9397 (C:0.9397, R:0.0105)
Batch  25/537: Loss=0.9580 (C:0.9580, R:0.0105)
Batch  50/537: Loss=0.9180 (C:0.9180, R:0.0105)
Batch  75/537: Loss=0.9469 (C:0.9469, R:0.0105)
Batch 100/537: Loss=0.9462 (C:0.9462, R:0.0105)
Batch 125/537: Loss=0.9302 (C:0.9302, R:0.0105)
Batch 150/537: Loss=0.9307 (C:0.9307, R:0.0105)
Batch 175/537: Loss=0.9270 (C:0.9270, R:0.0105)
Batch 200/537: Loss=0.9448 (C:0.9448, R:0.0105)
Batch 225/537: Loss=0.9225 (C:0.9225, R:0.0105)
Batch 250/537: Loss=0.9347 (C:0.9347, R:0.0105)
Batch 275/537: Loss=0.9148 (C:0.9148, R:0.0105)
Batch 300/537: Loss=0.9373 (C:0.9373, R:0.0105)
Batch 325/537: Loss=0.9689 (C:0.9689, R:0.0105)
Batch 350/537: Loss=0.9639 (C:0.9639, R:0.0105)
Batch 375/537: Loss=0.9414 (C:0.9414, R:0.0105)
Batch 400/537: Loss=0.9527 (C:0.9527, R:0.0105)
Batch 425/537: Loss=0.9227 (C:0.9227, R:0.0105)
Batch 450/537: Loss=0.9030 (C:0.9030, R:0.0105)
Batch 475/537: Loss=0.9356 (C:0.9356, R:0.0105)
Batch 500/537: Loss=0.9056 (C:0.9056, R:0.0105)
Batch 525/537: Loss=0.9123 (C:0.9123, R:0.0105)

============================================================
Epoch 18/300 completed in 21.6s
Train: Loss=0.9364 (C:0.9364, R:0.0105) Ratio=3.84x
Val:   Loss=0.9999 (C:0.9999, R:0.0104) Ratio=3.01x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.9999)
============================================================

🌍 Updating global dataset at epoch 19
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.375 ± 0.539
    Neg distances: 1.810 ± 0.876
    Separation ratio: 4.83x
    Gap: -3.112
    ✅ Excellent global separation!

Epoch 19 Training
----------------------------------------
Batch   0/537: Loss=0.8972 (C:0.8972, R:0.0105)
Batch  25/537: Loss=0.8924 (C:0.8924, R:0.0105)
Batch  50/537: Loss=0.9344 (C:0.9344, R:0.0106)
Batch  75/537: Loss=0.8695 (C:0.8695, R:0.0105)
Batch 100/537: Loss=0.9000 (C:0.9000, R:0.0105)
Batch 125/537: Loss=0.9042 (C:0.9042, R:0.0105)
Batch 150/537: Loss=0.8882 (C:0.8882, R:0.0105)
Batch 175/537: Loss=0.8997 (C:0.8997, R:0.0105)
Batch 200/537: Loss=0.9139 (C:0.9139, R:0.0105)
Batch 225/537: Loss=0.9055 (C:0.9055, R:0.0105)
Batch 250/537: Loss=0.8932 (C:0.8932, R:0.0105)
Batch 275/537: Loss=0.9082 (C:0.9082, R:0.0105)
Batch 300/537: Loss=0.9243 (C:0.9243, R:0.0105)
Batch 325/537: Loss=0.9011 (C:0.9011, R:0.0105)
Batch 350/537: Loss=0.8990 (C:0.8990, R:0.0106)
Batch 375/537: Loss=0.9084 (C:0.9084, R:0.0105)
Batch 400/537: Loss=0.9084 (C:0.9084, R:0.0105)
Batch 425/537: Loss=0.9080 (C:0.9080, R:0.0105)
Batch 450/537: Loss=0.8795 (C:0.8795, R:0.0105)
Batch 475/537: Loss=0.9381 (C:0.9381, R:0.0105)
Batch 500/537: Loss=0.8984 (C:0.8984, R:0.0105)
Batch 525/537: Loss=0.8852 (C:0.8852, R:0.0105)

============================================================
Epoch 19/300 completed in 26.9s
Train: Loss=0.9006 (C:0.9006, R:0.0105) Ratio=3.83x
Val:   Loss=0.9718 (C:0.9718, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.9718)
============================================================

Epoch 20 Training
----------------------------------------
Batch   0/537: Loss=0.8930 (C:0.8930, R:0.0105)
Batch  25/537: Loss=0.8724 (C:0.8724, R:0.0105)
Batch  50/537: Loss=0.9217 (C:0.9217, R:0.0105)
Batch  75/537: Loss=0.8894 (C:0.8894, R:0.0105)
Batch 100/537: Loss=0.8793 (C:0.8793, R:0.0105)
Batch 125/537: Loss=0.8768 (C:0.8768, R:0.0105)
Batch 150/537: Loss=0.9161 (C:0.9161, R:0.0105)
Batch 175/537: Loss=0.9055 (C:0.9055, R:0.0105)
Batch 200/537: Loss=0.8629 (C:0.8629, R:0.0105)
Batch 225/537: Loss=0.9073 (C:0.9073, R:0.0105)
Batch 250/537: Loss=0.9391 (C:0.9391, R:0.0105)
Batch 275/537: Loss=0.9002 (C:0.9002, R:0.0105)
Batch 300/537: Loss=0.9373 (C:0.9373, R:0.0105)
Batch 325/537: Loss=0.8788 (C:0.8788, R:0.0105)
Batch 350/537: Loss=0.9164 (C:0.9164, R:0.0105)
Batch 375/537: Loss=0.8882 (C:0.8882, R:0.0105)
Batch 400/537: Loss=0.8801 (C:0.8801, R:0.0105)
Batch 425/537: Loss=0.8806 (C:0.8806, R:0.0105)
Batch 450/537: Loss=0.9037 (C:0.9037, R:0.0105)
Batch 475/537: Loss=0.9048 (C:0.9048, R:0.0105)
Batch 500/537: Loss=0.9131 (C:0.9131, R:0.0105)
Batch 525/537: Loss=0.9294 (C:0.9294, R:0.0105)

============================================================
Epoch 20/300 completed in 21.0s
Train: Loss=0.8969 (C:0.8969, R:0.0105) Ratio=3.91x
Val:   Loss=0.9678 (C:0.9678, R:0.0104) Ratio=3.01x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.9678)
Checkpoint saved at epoch 20
============================================================

Epoch 21 Training
----------------------------------------
Batch   0/537: Loss=0.8520 (C:0.8520, R:0.0105)
Batch  25/537: Loss=0.9150 (C:0.9150, R:0.0105)
Batch  50/537: Loss=0.8714 (C:0.8714, R:0.0105)
Batch  75/537: Loss=0.8718 (C:0.8718, R:0.0105)
Batch 100/537: Loss=0.8831 (C:0.8831, R:0.0106)
Batch 125/537: Loss=0.8828 (C:0.8828, R:0.0105)
Batch 150/537: Loss=0.8938 (C:0.8938, R:0.0105)
Batch 175/537: Loss=0.8894 (C:0.8894, R:0.0105)
Batch 200/537: Loss=0.8866 (C:0.8866, R:0.0105)
Batch 225/537: Loss=0.8868 (C:0.8868, R:0.0105)
Batch 250/537: Loss=0.9227 (C:0.9227, R:0.0105)
Batch 275/537: Loss=0.9020 (C:0.9020, R:0.0105)
Batch 300/537: Loss=0.8636 (C:0.8636, R:0.0105)
Batch 325/537: Loss=0.9190 (C:0.9190, R:0.0105)
Batch 350/537: Loss=0.8715 (C:0.8715, R:0.0105)
Batch 375/537: Loss=0.9167 (C:0.9167, R:0.0105)
Batch 400/537: Loss=0.9030 (C:0.9030, R:0.0105)
Batch 425/537: Loss=0.9025 (C:0.9025, R:0.0105)
Batch 450/537: Loss=0.8944 (C:0.8944, R:0.0105)
Batch 475/537: Loss=0.9105 (C:0.9105, R:0.0105)
Batch 500/537: Loss=0.8790 (C:0.8790, R:0.0105)
Batch 525/537: Loss=0.8594 (C:0.8594, R:0.0105)

============================================================
Epoch 21/300 completed in 21.0s
Train: Loss=0.8925 (C:0.8925, R:0.0105) Ratio=3.99x
Val:   Loss=0.9691 (C:0.9691, R:0.0104) Ratio=2.98x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 22
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.344 ± 0.506
    Neg distances: 1.862 ± 0.876
    Separation ratio: 5.41x
    Gap: -3.190
    ✅ Excellent global separation!

Epoch 22 Training
----------------------------------------
Batch   0/537: Loss=0.8279 (C:0.8279, R:0.0105)
Batch  25/537: Loss=0.8685 (C:0.8685, R:0.0105)
Batch  50/537: Loss=0.8417 (C:0.8417, R:0.0105)
Batch  75/537: Loss=0.8534 (C:0.8534, R:0.0105)
Batch 100/537: Loss=0.8473 (C:0.8473, R:0.0105)
Batch 125/537: Loss=0.8749 (C:0.8749, R:0.0106)
Batch 150/537: Loss=0.8495 (C:0.8495, R:0.0105)
Batch 175/537: Loss=0.8441 (C:0.8441, R:0.0105)
Batch 200/537: Loss=0.8262 (C:0.8262, R:0.0105)
Batch 225/537: Loss=0.8183 (C:0.8183, R:0.0105)
Batch 250/537: Loss=0.8660 (C:0.8660, R:0.0105)
Batch 275/537: Loss=0.8608 (C:0.8608, R:0.0105)
Batch 300/537: Loss=0.8427 (C:0.8427, R:0.0105)
Batch 325/537: Loss=0.8683 (C:0.8683, R:0.0105)
Batch 350/537: Loss=0.8714 (C:0.8714, R:0.0105)
Batch 375/537: Loss=0.8618 (C:0.8618, R:0.0105)
Batch 400/537: Loss=0.8434 (C:0.8434, R:0.0105)
Batch 425/537: Loss=0.8762 (C:0.8762, R:0.0105)
Batch 450/537: Loss=0.8504 (C:0.8504, R:0.0105)
Batch 475/537: Loss=0.8568 (C:0.8568, R:0.0105)
Batch 500/537: Loss=0.8560 (C:0.8560, R:0.0105)
Batch 525/537: Loss=0.8532 (C:0.8532, R:0.0105)

============================================================
Epoch 22/300 completed in 26.8s
Train: Loss=0.8554 (C:0.8554, R:0.0105) Ratio=3.94x
Val:   Loss=0.9424 (C:0.9424, R:0.0104) Ratio=3.00x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.9424)
============================================================

Epoch 23 Training
----------------------------------------
Batch   0/537: Loss=0.8461 (C:0.8461, R:0.0105)
Batch  25/537: Loss=0.8407 (C:0.8407, R:0.0105)
Batch  50/537: Loss=0.8543 (C:0.8543, R:0.0105)
Batch  75/537: Loss=0.8577 (C:0.8577, R:0.0106)
Batch 100/537: Loss=0.8264 (C:0.8264, R:0.0105)
Batch 125/537: Loss=0.8526 (C:0.8526, R:0.0105)
Batch 150/537: Loss=0.8266 (C:0.8266, R:0.0105)
Batch 175/537: Loss=0.8451 (C:0.8451, R:0.0105)
Batch 200/537: Loss=0.8484 (C:0.8484, R:0.0105)
Batch 225/537: Loss=0.8702 (C:0.8702, R:0.0105)
Batch 250/537: Loss=0.8581 (C:0.8581, R:0.0105)
Batch 275/537: Loss=0.8434 (C:0.8434, R:0.0105)
Batch 300/537: Loss=0.8368 (C:0.8368, R:0.0105)
Batch 325/537: Loss=0.8288 (C:0.8288, R:0.0105)
Batch 350/537: Loss=0.8343 (C:0.8343, R:0.0105)
Batch 375/537: Loss=0.8388 (C:0.8388, R:0.0105)
Batch 400/537: Loss=0.8464 (C:0.8464, R:0.0105)
Batch 425/537: Loss=0.8665 (C:0.8665, R:0.0105)
Batch 450/537: Loss=0.9021 (C:0.9021, R:0.0105)
Batch 475/537: Loss=0.8626 (C:0.8626, R:0.0105)
Batch 500/537: Loss=0.8742 (C:0.8742, R:0.0105)
Batch 525/537: Loss=0.8526 (C:0.8526, R:0.0106)

============================================================
Epoch 23/300 completed in 20.9s
Train: Loss=0.8505 (C:0.8505, R:0.0105) Ratio=4.06x
Val:   Loss=0.9327 (C:0.9327, R:0.0104) Ratio=3.02x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.9327)
============================================================

Epoch 24 Training
----------------------------------------
Batch   0/537: Loss=0.8330 (C:0.8330, R:0.0105)
Batch  25/537: Loss=0.8595 (C:0.8595, R:0.0105)
Batch  50/537: Loss=0.8563 (C:0.8563, R:0.0105)
Batch  75/537: Loss=0.8687 (C:0.8687, R:0.0105)
Batch 100/537: Loss=0.8679 (C:0.8679, R:0.0105)
Batch 125/537: Loss=0.8387 (C:0.8387, R:0.0105)
Batch 150/537: Loss=0.8402 (C:0.8402, R:0.0105)
Batch 175/537: Loss=0.8225 (C:0.8225, R:0.0105)
Batch 200/537: Loss=0.8925 (C:0.8925, R:0.0105)
Batch 225/537: Loss=0.8264 (C:0.8264, R:0.0105)
Batch 250/537: Loss=0.8573 (C:0.8573, R:0.0106)
Batch 275/537: Loss=0.8088 (C:0.8088, R:0.0105)
Batch 300/537: Loss=0.8668 (C:0.8668, R:0.0105)
Batch 325/537: Loss=0.8365 (C:0.8365, R:0.0105)
Batch 350/537: Loss=0.8768 (C:0.8768, R:0.0105)
Batch 375/537: Loss=0.8571 (C:0.8571, R:0.0105)
Batch 400/537: Loss=0.8553 (C:0.8553, R:0.0105)
Batch 425/537: Loss=0.8523 (C:0.8523, R:0.0105)
Batch 450/537: Loss=0.8285 (C:0.8285, R:0.0105)
Batch 475/537: Loss=0.8573 (C:0.8573, R:0.0105)
Batch 500/537: Loss=0.8331 (C:0.8331, R:0.0105)
Batch 525/537: Loss=0.8572 (C:0.8572, R:0.0106)

============================================================
Epoch 24/300 completed in 21.0s
Train: Loss=0.8475 (C:0.8475, R:0.0105) Ratio=4.06x
Val:   Loss=0.9315 (C:0.9315, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.9315)
============================================================

🌍 Updating global dataset at epoch 25
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.348 ± 0.515
    Neg distances: 1.938 ± 0.897
    Separation ratio: 5.57x
    Gap: -3.299
    ✅ Excellent global separation!

Epoch 25 Training
----------------------------------------
Batch   0/537: Loss=0.8103 (C:0.8103, R:0.0105)
Batch  25/537: Loss=0.8427 (C:0.8427, R:0.0105)
Batch  50/537: Loss=0.8589 (C:0.8589, R:0.0106)
Batch  75/537: Loss=0.8694 (C:0.8694, R:0.0105)
Batch 100/537: Loss=0.8742 (C:0.8742, R:0.0105)
Batch 125/537: Loss=0.8382 (C:0.8382, R:0.0105)
Batch 150/537: Loss=0.8433 (C:0.8433, R:0.0105)
Batch 175/537: Loss=0.8317 (C:0.8317, R:0.0105)
Batch 200/537: Loss=0.8147 (C:0.8147, R:0.0105)
Batch 225/537: Loss=0.8282 (C:0.8282, R:0.0105)
Batch 250/537: Loss=0.8524 (C:0.8524, R:0.0105)
Batch 275/537: Loss=0.8390 (C:0.8390, R:0.0105)
Batch 300/537: Loss=0.8472 (C:0.8472, R:0.0105)
Batch 325/537: Loss=0.8310 (C:0.8310, R:0.0105)
Batch 350/537: Loss=0.8058 (C:0.8058, R:0.0105)
Batch 375/537: Loss=0.8339 (C:0.8339, R:0.0105)
Batch 400/537: Loss=0.8110 (C:0.8110, R:0.0105)
Batch 425/537: Loss=0.8459 (C:0.8459, R:0.0105)
Batch 450/537: Loss=0.8077 (C:0.8077, R:0.0105)
Batch 475/537: Loss=0.8285 (C:0.8285, R:0.0105)
Batch 500/537: Loss=0.8228 (C:0.8228, R:0.0105)
Batch 525/537: Loss=0.8428 (C:0.8428, R:0.0105)

============================================================
Epoch 25/300 completed in 26.8s
Train: Loss=0.8264 (C:0.8264, R:0.0105) Ratio=4.04x
Val:   Loss=0.9205 (C:0.9205, R:0.0104) Ratio=2.99x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.9205)
============================================================

Epoch 26 Training
----------------------------------------
Batch   0/537: Loss=0.8324 (C:0.8324, R:0.0105)
Batch  25/537: Loss=0.8106 (C:0.8106, R:0.0106)
Batch  50/537: Loss=0.8300 (C:0.8300, R:0.0105)
Batch  75/537: Loss=0.8239 (C:0.8239, R:0.0105)
Batch 100/537: Loss=0.8408 (C:0.8408, R:0.0105)
Batch 125/537: Loss=0.8346 (C:0.8346, R:0.0105)
Batch 150/537: Loss=0.8289 (C:0.8289, R:0.0105)
Batch 175/537: Loss=0.8495 (C:0.8495, R:0.0105)
Batch 200/537: Loss=0.8245 (C:0.8245, R:0.0105)
Batch 225/537: Loss=0.8245 (C:0.8245, R:0.0105)
Batch 250/537: Loss=0.8190 (C:0.8190, R:0.0105)
Batch 275/537: Loss=0.7978 (C:0.7978, R:0.0105)
Batch 300/537: Loss=0.8548 (C:0.8548, R:0.0106)
Batch 325/537: Loss=0.8043 (C:0.8043, R:0.0105)
Batch 350/537: Loss=0.8548 (C:0.8548, R:0.0105)
Batch 375/537: Loss=0.8439 (C:0.8439, R:0.0105)
Batch 400/537: Loss=0.8584 (C:0.8584, R:0.0105)
Batch 425/537: Loss=0.8184 (C:0.8184, R:0.0105)
Batch 450/537: Loss=0.8489 (C:0.8489, R:0.0105)
Batch 475/537: Loss=0.8195 (C:0.8195, R:0.0105)
Batch 500/537: Loss=0.8231 (C:0.8231, R:0.0105)
Batch 525/537: Loss=0.8493 (C:0.8493, R:0.0105)

============================================================
Epoch 26/300 completed in 21.2s
Train: Loss=0.8246 (C:0.8246, R:0.0105) Ratio=4.19x
Val:   Loss=0.9078 (C:0.9078, R:0.0104) Ratio=3.03x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.9078)
============================================================

Epoch 27 Training
----------------------------------------
Batch   0/537: Loss=0.8144 (C:0.8144, R:0.0105)
Batch  25/537: Loss=0.8006 (C:0.8006, R:0.0105)
Batch  50/537: Loss=0.8019 (C:0.8019, R:0.0105)
Batch  75/537: Loss=0.7792 (C:0.7792, R:0.0105)
Batch 100/537: Loss=0.8161 (C:0.8161, R:0.0106)
Batch 125/537: Loss=0.8172 (C:0.8172, R:0.0105)
Batch 150/537: Loss=0.7963 (C:0.7963, R:0.0105)
Batch 175/537: Loss=0.8490 (C:0.8490, R:0.0105)
Batch 200/537: Loss=0.8220 (C:0.8220, R:0.0105)
Batch 225/537: Loss=0.8389 (C:0.8389, R:0.0105)
Batch 250/537: Loss=0.8155 (C:0.8155, R:0.0106)
Batch 275/537: Loss=0.8458 (C:0.8458, R:0.0105)
Batch 300/537: Loss=0.7758 (C:0.7758, R:0.0105)
Batch 325/537: Loss=0.8401 (C:0.8401, R:0.0105)
Batch 350/537: Loss=0.8314 (C:0.8314, R:0.0105)
Batch 375/537: Loss=0.8380 (C:0.8380, R:0.0105)
Batch 400/537: Loss=0.8039 (C:0.8039, R:0.0105)
Batch 425/537: Loss=0.7886 (C:0.7886, R:0.0105)
Batch 450/537: Loss=0.8265 (C:0.8265, R:0.0105)
Batch 475/537: Loss=0.8337 (C:0.8337, R:0.0105)
Batch 500/537: Loss=0.7968 (C:0.7968, R:0.0105)
Batch 525/537: Loss=0.8895 (C:0.8895, R:0.0105)

============================================================
Epoch 27/300 completed in 21.4s
Train: Loss=0.8204 (C:0.8204, R:0.0105) Ratio=4.24x
Val:   Loss=0.9158 (C:0.9158, R:0.0104) Ratio=3.03x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 28
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.353 ± 0.542
    Neg distances: 1.974 ± 0.910
    Separation ratio: 5.59x
    Gap: -3.341
    ✅ Excellent global separation!

Epoch 28 Training
----------------------------------------
Batch   0/537: Loss=0.8118 (C:0.8118, R:0.0105)
Batch  25/537: Loss=0.7882 (C:0.7882, R:0.0105)
Batch  50/537: Loss=0.8547 (C:0.8547, R:0.0105)
Batch  75/537: Loss=0.7875 (C:0.7875, R:0.0105)
Batch 100/537: Loss=0.8116 (C:0.8116, R:0.0105)
Batch 125/537: Loss=0.8059 (C:0.8059, R:0.0105)
Batch 150/537: Loss=0.7991 (C:0.7991, R:0.0105)
Batch 175/537: Loss=0.8060 (C:0.8060, R:0.0105)
Batch 200/537: Loss=0.8387 (C:0.8387, R:0.0105)
Batch 225/537: Loss=0.7977 (C:0.7977, R:0.0106)
Batch 250/537: Loss=0.8319 (C:0.8319, R:0.0105)
Batch 275/537: Loss=0.7995 (C:0.7995, R:0.0105)
Batch 300/537: Loss=0.8045 (C:0.8045, R:0.0105)
Batch 325/537: Loss=0.8030 (C:0.8030, R:0.0105)
Batch 350/537: Loss=0.8642 (C:0.8642, R:0.0105)
Batch 375/537: Loss=0.7794 (C:0.7794, R:0.0105)
Batch 400/537: Loss=0.7820 (C:0.7820, R:0.0106)
Batch 425/537: Loss=0.8001 (C:0.8001, R:0.0105)
Batch 450/537: Loss=0.8465 (C:0.8465, R:0.0105)
Batch 475/537: Loss=0.8514 (C:0.8514, R:0.0105)
Batch 500/537: Loss=0.8000 (C:0.8000, R:0.0105)
Batch 525/537: Loss=0.8198 (C:0.8198, R:0.0105)

============================================================
Epoch 28/300 completed in 27.2s
Train: Loss=0.8098 (C:0.8098, R:0.0105) Ratio=4.31x
Val:   Loss=0.8976 (C:0.8976, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 0.8976)
============================================================

Epoch 29 Training
----------------------------------------
Batch   0/537: Loss=0.7846 (C:0.7846, R:0.0105)
Batch  25/537: Loss=0.7969 (C:0.7969, R:0.0105)
Batch  50/537: Loss=0.7789 (C:0.7789, R:0.0105)
Batch  75/537: Loss=0.8388 (C:0.8388, R:0.0105)
Batch 100/537: Loss=0.8264 (C:0.8264, R:0.0105)
Batch 125/537: Loss=0.7860 (C:0.7860, R:0.0105)
Batch 150/537: Loss=0.8048 (C:0.8048, R:0.0105)
Batch 175/537: Loss=0.8450 (C:0.8450, R:0.0105)
Batch 200/537: Loss=0.7600 (C:0.7600, R:0.0106)
Batch 225/537: Loss=0.8326 (C:0.8326, R:0.0105)
Batch 250/537: Loss=0.7992 (C:0.7992, R:0.0105)
Batch 275/537: Loss=0.8061 (C:0.8061, R:0.0105)
Batch 300/537: Loss=0.8745 (C:0.8745, R:0.0105)
Batch 325/537: Loss=0.8053 (C:0.8053, R:0.0105)
Batch 350/537: Loss=0.8131 (C:0.8131, R:0.0105)
Batch 375/537: Loss=0.7965 (C:0.7965, R:0.0105)
Batch 400/537: Loss=0.7939 (C:0.7939, R:0.0105)
Batch 425/537: Loss=0.8065 (C:0.8065, R:0.0105)
Batch 450/537: Loss=0.7913 (C:0.7913, R:0.0105)
Batch 475/537: Loss=0.8094 (C:0.8094, R:0.0105)
Batch 500/537: Loss=0.8010 (C:0.8010, R:0.0105)
Batch 525/537: Loss=0.8367 (C:0.8367, R:0.0105)

============================================================
Epoch 29/300 completed in 21.3s
Train: Loss=0.8077 (C:0.8077, R:0.0105) Ratio=4.21x
Val:   Loss=0.9074 (C:0.9074, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

Epoch 30 Training
----------------------------------------
Batch   0/537: Loss=0.7889 (C:0.7889, R:0.0105)
Batch  25/537: Loss=0.7719 (C:0.7719, R:0.0105)
Batch  50/537: Loss=0.8136 (C:0.8136, R:0.0105)
Batch  75/537: Loss=0.7942 (C:0.7942, R:0.0105)
Batch 100/537: Loss=0.8083 (C:0.8083, R:0.0105)
Batch 125/537: Loss=0.8004 (C:0.8004, R:0.0105)
Batch 150/537: Loss=0.8123 (C:0.8123, R:0.0105)
Batch 175/537: Loss=0.7822 (C:0.7822, R:0.0105)
Batch 200/537: Loss=0.8373 (C:0.8373, R:0.0105)
Batch 225/537: Loss=0.7843 (C:0.7843, R:0.0105)
Batch 250/537: Loss=0.7982 (C:0.7982, R:0.0105)
Batch 275/537: Loss=0.7933 (C:0.7933, R:0.0105)
Batch 300/537: Loss=0.7867 (C:0.7867, R:0.0105)
Batch 325/537: Loss=0.8187 (C:0.8187, R:0.0105)
Batch 350/537: Loss=0.8072 (C:0.8072, R:0.0105)
Batch 375/537: Loss=0.7747 (C:0.7747, R:0.0105)
Batch 400/537: Loss=0.7975 (C:0.7975, R:0.0105)
Batch 425/537: Loss=0.8170 (C:0.8170, R:0.0105)
Batch 450/537: Loss=0.8120 (C:0.8120, R:0.0106)
Batch 475/537: Loss=0.8307 (C:0.8307, R:0.0105)
Batch 500/537: Loss=0.8317 (C:0.8317, R:0.0105)
Batch 525/537: Loss=0.7910 (C:0.7910, R:0.0105)

============================================================
Epoch 30/300 completed in 21.4s
Train: Loss=0.8041 (C:0.8041, R:0.0105) Ratio=4.35x
Val:   Loss=0.9069 (C:0.9069, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.000
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 31
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.323 ± 0.515
    Neg distances: 2.055 ± 0.918
    Separation ratio: 6.36x
    Gap: -3.485
    ✅ Excellent global separation!

Epoch 31 Training
----------------------------------------
Batch   0/537: Loss=0.7402 (C:0.7402, R:0.0104)
Batch  25/537: Loss=0.7404 (C:0.7404, R:0.0105)
Batch  50/537: Loss=0.7159 (C:0.7159, R:0.0105)
Batch  75/537: Loss=0.7492 (C:0.7492, R:0.0105)
Batch 100/537: Loss=0.7610 (C:0.7610, R:0.0105)
Batch 125/537: Loss=0.7885 (C:0.7885, R:0.0105)
Batch 150/537: Loss=0.7587 (C:0.7587, R:0.0105)
Batch 175/537: Loss=0.7814 (C:0.7814, R:0.0105)
Batch 200/537: Loss=0.7391 (C:0.7391, R:0.0105)
Batch 225/537: Loss=0.7400 (C:0.7400, R:0.0105)
Batch 250/537: Loss=0.6988 (C:0.6988, R:0.0105)
Batch 275/537: Loss=0.7687 (C:0.7687, R:0.0105)
Batch 300/537: Loss=0.7422 (C:0.7422, R:0.0105)
Batch 325/537: Loss=0.7570 (C:0.7570, R:0.0105)
Batch 350/537: Loss=0.7394 (C:0.7394, R:0.0106)
Batch 375/537: Loss=0.7452 (C:0.7452, R:0.0105)
Batch 400/537: Loss=0.7414 (C:0.7414, R:0.0105)
Batch 425/537: Loss=0.7634 (C:0.7634, R:0.0105)
Batch 450/537: Loss=0.7481 (C:0.7481, R:0.0105)
Batch 475/537: Loss=0.7797 (C:0.7797, R:0.0105)
Batch 500/537: Loss=0.7873 (C:0.7873, R:0.0105)
Batch 525/537: Loss=0.7612 (C:0.7612, R:0.0105)

============================================================
Epoch 31/300 completed in 27.3s
Train: Loss=0.7576 (C:0.7576, R:0.0105) Ratio=4.42x
Val:   Loss=0.8690 (C:0.8690, R:0.0104) Ratio=3.03x
Reconstruction weight: 0.015
✅ New best model saved (Val Loss: 0.8690)
============================================================

Epoch 32 Training
----------------------------------------
Batch   0/537: Loss=0.7343 (C:0.7343, R:0.0105)
Batch  25/537: Loss=0.7023 (C:0.7023, R:0.0105)
Batch  50/537: Loss=0.7684 (C:0.7684, R:0.0105)
Batch  75/537: Loss=0.7505 (C:0.7505, R:0.0105)
Batch 100/537: Loss=0.7607 (C:0.7607, R:0.0105)
Batch 125/537: Loss=0.7383 (C:0.7383, R:0.0105)
Batch 150/537: Loss=0.7438 (C:0.7438, R:0.0105)
Batch 175/537: Loss=0.7771 (C:0.7771, R:0.0105)
Batch 200/537: Loss=0.7751 (C:0.7751, R:0.0105)
Batch 225/537: Loss=0.7319 (C:0.7319, R:0.0105)
Batch 250/537: Loss=0.7424 (C:0.7424, R:0.0105)
Batch 275/537: Loss=0.7676 (C:0.7676, R:0.0105)
Batch 300/537: Loss=0.7379 (C:0.7379, R:0.0105)
Batch 325/537: Loss=0.7346 (C:0.7346, R:0.0105)
Batch 350/537: Loss=0.7466 (C:0.7466, R:0.0105)
Batch 375/537: Loss=0.7810 (C:0.7810, R:0.0105)
Batch 400/537: Loss=0.7925 (C:0.7925, R:0.0105)
Batch 425/537: Loss=0.7422 (C:0.7422, R:0.0105)
Batch 450/537: Loss=0.7921 (C:0.7921, R:0.0105)
Batch 475/537: Loss=0.7289 (C:0.7289, R:0.0105)
Batch 500/537: Loss=0.7250 (C:0.7250, R:0.0105)
Batch 525/537: Loss=0.7213 (C:0.7213, R:0.0105)

============================================================
Epoch 32/300 completed in 21.8s
Train: Loss=0.7542 (C:0.7542, R:0.0105) Ratio=4.45x
Val:   Loss=0.8586 (C:0.8586, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.030
✅ New best model saved (Val Loss: 0.8586)
============================================================

Epoch 33 Training
----------------------------------------
Batch   0/537: Loss=0.7313 (C:0.7313, R:0.0105)
Batch  25/537: Loss=0.7459 (C:0.7459, R:0.0105)
Batch  50/537: Loss=0.7491 (C:0.7491, R:0.0105)
Batch  75/537: Loss=0.7361 (C:0.7361, R:0.0105)
Batch 100/537: Loss=0.7694 (C:0.7694, R:0.0105)
Batch 125/537: Loss=0.7687 (C:0.7687, R:0.0105)
Batch 150/537: Loss=0.7465 (C:0.7465, R:0.0106)
Batch 175/537: Loss=0.7180 (C:0.7180, R:0.0105)
Batch 200/537: Loss=0.7352 (C:0.7352, R:0.0105)
Batch 225/537: Loss=0.7683 (C:0.7683, R:0.0105)
Batch 250/537: Loss=0.7815 (C:0.7815, R:0.0105)
Batch 275/537: Loss=0.7493 (C:0.7493, R:0.0105)
Batch 300/537: Loss=0.7489 (C:0.7489, R:0.0105)
Batch 325/537: Loss=0.7298 (C:0.7298, R:0.0105)
Batch 350/537: Loss=0.7375 (C:0.7375, R:0.0105)
Batch 375/537: Loss=0.7407 (C:0.7407, R:0.0105)
Batch 400/537: Loss=0.7417 (C:0.7417, R:0.0105)
Batch 425/537: Loss=0.7185 (C:0.7185, R:0.0105)
Batch 450/537: Loss=0.7548 (C:0.7548, R:0.0105)
Batch 475/537: Loss=0.7719 (C:0.7719, R:0.0105)
Batch 500/537: Loss=0.7887 (C:0.7887, R:0.0105)
Batch 525/537: Loss=0.7394 (C:0.7394, R:0.0105)

============================================================
Epoch 33/300 completed in 21.6s
Train: Loss=0.7516 (C:0.7516, R:0.0105) Ratio=4.48x
Val:   Loss=0.8607 (C:0.8607, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.045
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 34
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.340 ± 0.540
    Neg distances: 2.090 ± 0.934
    Separation ratio: 6.14x
    Gap: -3.578
    ✅ Excellent global separation!

Epoch 34 Training
----------------------------------------
Batch   0/537: Loss=0.7401 (C:0.7401, R:0.0105)
Batch  25/537: Loss=0.7201 (C:0.7201, R:0.0105)
Batch  50/537: Loss=0.7536 (C:0.7536, R:0.0105)
Batch  75/537: Loss=0.7483 (C:0.7483, R:0.0105)
Batch 100/537: Loss=0.7685 (C:0.7685, R:0.0105)
Batch 125/537: Loss=0.7557 (C:0.7557, R:0.0105)
Batch 150/537: Loss=0.7553 (C:0.7553, R:0.0105)
Batch 175/537: Loss=0.7840 (C:0.7840, R:0.0105)
Batch 200/537: Loss=0.7436 (C:0.7436, R:0.0105)
Batch 225/537: Loss=0.7689 (C:0.7689, R:0.0105)
Batch 250/537: Loss=0.7223 (C:0.7223, R:0.0105)
Batch 275/537: Loss=0.7446 (C:0.7446, R:0.0105)
Batch 300/537: Loss=0.7487 (C:0.7487, R:0.0105)
Batch 325/537: Loss=0.7474 (C:0.7474, R:0.0105)
Batch 350/537: Loss=0.7409 (C:0.7409, R:0.0105)
Batch 375/537: Loss=0.7272 (C:0.7272, R:0.0105)
Batch 400/537: Loss=0.7634 (C:0.7634, R:0.0105)
Batch 425/537: Loss=0.7586 (C:0.7586, R:0.0105)
Batch 450/537: Loss=0.7473 (C:0.7473, R:0.0105)
Batch 475/537: Loss=0.7650 (C:0.7650, R:0.0105)
Batch 500/537: Loss=0.7029 (C:0.7029, R:0.0105)
Batch 525/537: Loss=0.7468 (C:0.7468, R:0.0105)

============================================================
Epoch 34/300 completed in 27.6s
Train: Loss=0.7509 (C:0.7509, R:0.0105) Ratio=4.48x
Val:   Loss=0.8574 (C:0.8574, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.060
✅ New best model saved (Val Loss: 0.8574)
============================================================

Epoch 35 Training
----------------------------------------
Batch   0/537: Loss=0.7152 (C:0.7152, R:0.0105)
Batch  25/537: Loss=0.7766 (C:0.7766, R:0.0105)
Batch  50/537: Loss=0.7188 (C:0.7188, R:0.0105)
Batch  75/537: Loss=0.7330 (C:0.7330, R:0.0105)
Batch 100/537: Loss=0.7295 (C:0.7295, R:0.0105)
Batch 125/537: Loss=0.7386 (C:0.7386, R:0.0105)
Batch 150/537: Loss=0.7689 (C:0.7689, R:0.0105)
Batch 175/537: Loss=0.7638 (C:0.7638, R:0.0105)
Batch 200/537: Loss=0.7604 (C:0.7604, R:0.0105)
Batch 225/537: Loss=0.7371 (C:0.7371, R:0.0105)
Batch 250/537: Loss=0.7559 (C:0.7559, R:0.0105)
Batch 275/537: Loss=0.7456 (C:0.7456, R:0.0105)
Batch 300/537: Loss=0.7102 (C:0.7102, R:0.0105)
Batch 325/537: Loss=0.7783 (C:0.7783, R:0.0105)
Batch 350/537: Loss=0.7207 (C:0.7207, R:0.0105)
Batch 375/537: Loss=0.7322 (C:0.7322, R:0.0105)
Batch 400/537: Loss=0.7222 (C:0.7222, R:0.0106)
Batch 425/537: Loss=0.8185 (C:0.8185, R:0.0105)
Batch 450/537: Loss=0.7660 (C:0.7660, R:0.0105)
Batch 475/537: Loss=0.7624 (C:0.7624, R:0.0105)
Batch 500/537: Loss=0.7265 (C:0.7265, R:0.0105)
Batch 525/537: Loss=0.7601 (C:0.7601, R:0.0105)

============================================================
Epoch 35/300 completed in 21.9s
Train: Loss=0.7473 (C:0.7473, R:0.0105) Ratio=4.47x
Val:   Loss=0.8629 (C:0.8629, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.075
No improvement for 1 epochs
============================================================

Epoch 36 Training
----------------------------------------
Batch   0/537: Loss=0.7153 (C:0.7153, R:0.0105)
Batch  25/537: Loss=0.7222 (C:0.7222, R:0.0105)
Batch  50/537: Loss=0.7304 (C:0.7304, R:0.0105)
Batch  75/537: Loss=0.7327 (C:0.7327, R:0.0105)
Batch 100/537: Loss=0.7572 (C:0.7572, R:0.0105)
Batch 125/537: Loss=0.7714 (C:0.7714, R:0.0105)
Batch 150/537: Loss=0.7475 (C:0.7475, R:0.0105)
Batch 175/537: Loss=0.7582 (C:0.7582, R:0.0105)
Batch 200/537: Loss=0.7303 (C:0.7303, R:0.0105)
Batch 225/537: Loss=0.7231 (C:0.7231, R:0.0105)
Batch 250/537: Loss=0.7493 (C:0.7493, R:0.0105)
Batch 275/537: Loss=0.7424 (C:0.7424, R:0.0106)
Batch 300/537: Loss=0.7551 (C:0.7551, R:0.0105)
Batch 325/537: Loss=0.7642 (C:0.7642, R:0.0105)
Batch 350/537: Loss=0.7935 (C:0.7935, R:0.0105)
Batch 375/537: Loss=0.7216 (C:0.7216, R:0.0105)
Batch 400/537: Loss=0.7305 (C:0.7305, R:0.0105)
Batch 425/537: Loss=0.7345 (C:0.7345, R:0.0105)
Batch 450/537: Loss=0.7461 (C:0.7461, R:0.0105)
Batch 475/537: Loss=0.7689 (C:0.7689, R:0.0105)
Batch 500/537: Loss=0.7949 (C:0.7949, R:0.0105)
Batch 525/537: Loss=0.7616 (C:0.7616, R:0.0105)

============================================================
Epoch 36/300 completed in 21.1s
Train: Loss=0.7440 (C:0.7440, R:0.0105) Ratio=4.58x
Val:   Loss=0.8559 (C:0.8559, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.090
✅ New best model saved (Val Loss: 0.8559)
============================================================

🌍 Updating global dataset at epoch 37
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.343 ± 0.562
    Neg distances: 2.160 ± 0.960
    Separation ratio: 6.30x
    Gap: -3.657
    ✅ Excellent global separation!

Epoch 37 Training
----------------------------------------
Batch   0/537: Loss=0.7206 (C:0.7206, R:0.0105)
Batch  25/537: Loss=0.7308 (C:0.7308, R:0.0105)
Batch  50/537: Loss=0.7378 (C:0.7378, R:0.0105)
Batch  75/537: Loss=0.7149 (C:0.7149, R:0.0105)
Batch 100/537: Loss=0.7365 (C:0.7365, R:0.0105)
Batch 125/537: Loss=0.6958 (C:0.6958, R:0.0105)
Batch 150/537: Loss=0.7306 (C:0.7306, R:0.0105)
Batch 175/537: Loss=0.6896 (C:0.6896, R:0.0105)
Batch 200/537: Loss=0.7328 (C:0.7328, R:0.0105)
Batch 225/537: Loss=0.6987 (C:0.6987, R:0.0105)
Batch 250/537: Loss=0.7532 (C:0.7532, R:0.0105)
Batch 275/537: Loss=0.7266 (C:0.7266, R:0.0105)
Batch 300/537: Loss=0.7258 (C:0.7258, R:0.0105)
Batch 325/537: Loss=0.7422 (C:0.7422, R:0.0105)
Batch 350/537: Loss=0.7316 (C:0.7316, R:0.0105)
Batch 375/537: Loss=0.7061 (C:0.7061, R:0.0105)
Batch 400/537: Loss=0.7688 (C:0.7688, R:0.0105)
Batch 425/537: Loss=0.7282 (C:0.7282, R:0.0105)
Batch 450/537: Loss=0.7425 (C:0.7425, R:0.0105)
Batch 475/537: Loss=0.7788 (C:0.7788, R:0.0105)
Batch 500/537: Loss=0.7307 (C:0.7307, R:0.0105)
Batch 525/537: Loss=0.7278 (C:0.7278, R:0.0105)

============================================================
Epoch 37/300 completed in 27.4s
Train: Loss=0.7266 (C:0.7266, R:0.0105) Ratio=4.51x
Val:   Loss=0.8470 (C:0.8470, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.105
✅ New best model saved (Val Loss: 0.8470)
============================================================

Epoch 38 Training
----------------------------------------
Batch   0/537: Loss=0.7095 (C:0.7095, R:0.0105)
Batch  25/537: Loss=0.7265 (C:0.7265, R:0.0105)
Batch  50/537: Loss=0.7119 (C:0.7119, R:0.0106)
Batch  75/537: Loss=0.7689 (C:0.7689, R:0.0105)
Batch 100/537: Loss=0.7022 (C:0.7022, R:0.0105)
Batch 125/537: Loss=0.7356 (C:0.7356, R:0.0105)
Batch 150/537: Loss=0.7454 (C:0.7454, R:0.0104)
Batch 175/537: Loss=0.7695 (C:0.7695, R:0.0105)
Batch 200/537: Loss=0.7087 (C:0.7087, R:0.0105)
Batch 225/537: Loss=0.7389 (C:0.7389, R:0.0105)
Batch 250/537: Loss=0.6775 (C:0.6775, R:0.0105)
Batch 275/537: Loss=0.7229 (C:0.7229, R:0.0105)
Batch 300/537: Loss=0.7327 (C:0.7327, R:0.0105)
Batch 325/537: Loss=0.7298 (C:0.7298, R:0.0105)
Batch 350/537: Loss=0.7228 (C:0.7228, R:0.0106)
Batch 375/537: Loss=0.7187 (C:0.7187, R:0.0105)
Batch 400/537: Loss=0.7059 (C:0.7059, R:0.0105)
Batch 425/537: Loss=0.7358 (C:0.7358, R:0.0105)
Batch 450/537: Loss=0.7176 (C:0.7176, R:0.0105)
Batch 475/537: Loss=0.7049 (C:0.7049, R:0.0105)
Batch 500/537: Loss=0.7137 (C:0.7137, R:0.0105)
Batch 525/537: Loss=0.7030 (C:0.7030, R:0.0105)

============================================================
Epoch 38/300 completed in 21.5s
Train: Loss=0.7256 (C:0.7256, R:0.0105) Ratio=4.57x
Val:   Loss=0.8464 (C:0.8464, R:0.0104) Ratio=3.12x
Reconstruction weight: 0.120
✅ New best model saved (Val Loss: 0.8464)
============================================================

Epoch 39 Training
----------------------------------------
Batch   0/537: Loss=0.7188 (C:0.7188, R:0.0105)
Batch  25/537: Loss=0.6957 (C:0.6957, R:0.0105)
Batch  50/537: Loss=0.7342 (C:0.7342, R:0.0105)
Batch  75/537: Loss=0.6798 (C:0.6798, R:0.0105)
Batch 100/537: Loss=0.7033 (C:0.7033, R:0.0106)
Batch 125/537: Loss=0.6896 (C:0.6896, R:0.0105)
Batch 150/537: Loss=0.7217 (C:0.7217, R:0.0105)
Batch 175/537: Loss=0.6889 (C:0.6889, R:0.0105)
Batch 200/537: Loss=0.7405 (C:0.7405, R:0.0105)
Batch 225/537: Loss=0.7202 (C:0.7202, R:0.0105)
Batch 250/537: Loss=0.7139 (C:0.7139, R:0.0105)
Batch 275/537: Loss=0.7106 (C:0.7106, R:0.0105)
Batch 300/537: Loss=0.7002 (C:0.7002, R:0.0105)
Batch 325/537: Loss=0.7016 (C:0.7016, R:0.0105)
Batch 350/537: Loss=0.7155 (C:0.7155, R:0.0105)
Batch 375/537: Loss=0.7110 (C:0.7110, R:0.0104)
Batch 400/537: Loss=0.7377 (C:0.7377, R:0.0105)
Batch 425/537: Loss=0.7259 (C:0.7259, R:0.0105)
Batch 450/537: Loss=0.7763 (C:0.7763, R:0.0105)
Batch 475/537: Loss=0.6887 (C:0.6887, R:0.0105)
Batch 500/537: Loss=0.7168 (C:0.7168, R:0.0105)
Batch 525/537: Loss=0.7136 (C:0.7136, R:0.0105)

============================================================
Epoch 39/300 completed in 21.5s
Train: Loss=0.7217 (C:0.7217, R:0.0105) Ratio=4.63x
Val:   Loss=0.8454 (C:0.8454, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.135
✅ New best model saved (Val Loss: 0.8454)
============================================================

🌍 Updating global dataset at epoch 40
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.327 ± 0.532
    Neg distances: 2.213 ± 0.964
    Separation ratio: 6.77x
    Gap: -3.754
    ✅ Excellent global separation!

Epoch 40 Training
----------------------------------------
Batch   0/537: Loss=0.7368 (C:0.7368, R:0.0105)
Batch  25/537: Loss=0.6821 (C:0.6821, R:0.0105)
Batch  50/537: Loss=0.7170 (C:0.7170, R:0.0105)
Batch  75/537: Loss=0.6920 (C:0.6920, R:0.0105)
Batch 100/537: Loss=0.6845 (C:0.6845, R:0.0105)
Batch 125/537: Loss=0.6776 (C:0.6776, R:0.0105)
Batch 150/537: Loss=0.7221 (C:0.7221, R:0.0105)
Batch 175/537: Loss=0.6914 (C:0.6914, R:0.0105)
Batch 200/537: Loss=0.7119 (C:0.7119, R:0.0105)
Batch 225/537: Loss=0.7081 (C:0.7081, R:0.0105)
Batch 250/537: Loss=0.6785 (C:0.6785, R:0.0105)
Batch 275/537: Loss=0.6658 (C:0.6658, R:0.0105)
Batch 300/537: Loss=0.7019 (C:0.7019, R:0.0105)
Batch 325/537: Loss=0.6282 (C:0.6282, R:0.0105)
Batch 350/537: Loss=0.7125 (C:0.7125, R:0.0105)
Batch 375/537: Loss=0.6835 (C:0.6835, R:0.0105)
Batch 400/537: Loss=0.7546 (C:0.7546, R:0.0105)
Batch 425/537: Loss=0.6884 (C:0.6884, R:0.0106)
Batch 450/537: Loss=0.7206 (C:0.7206, R:0.0105)
Batch 475/537: Loss=0.7173 (C:0.7173, R:0.0105)
Batch 500/537: Loss=0.7287 (C:0.7287, R:0.0105)
Batch 525/537: Loss=0.7376 (C:0.7376, R:0.0105)

============================================================
Epoch 40/300 completed in 27.7s
Train: Loss=0.6932 (C:0.6932, R:0.0105) Ratio=4.54x
Val:   Loss=0.8251 (C:0.8251, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.150
✅ New best model saved (Val Loss: 0.8251)
Checkpoint saved at epoch 40
============================================================

Epoch 41 Training
----------------------------------------
Batch   0/537: Loss=0.6595 (C:0.6595, R:0.0106)
Batch  25/537: Loss=0.6594 (C:0.6594, R:0.0105)
Batch  50/537: Loss=0.7398 (C:0.7398, R:0.0105)
Batch  75/537: Loss=0.7062 (C:0.7062, R:0.0105)
Batch 100/537: Loss=0.6942 (C:0.6942, R:0.0105)
Batch 125/537: Loss=0.7073 (C:0.7073, R:0.0105)
Batch 150/537: Loss=0.7036 (C:0.7036, R:0.0105)
Batch 175/537: Loss=0.6818 (C:0.6818, R:0.0105)
Batch 200/537: Loss=0.6830 (C:0.6830, R:0.0105)
Batch 225/537: Loss=0.7022 (C:0.7022, R:0.0105)
Batch 250/537: Loss=0.6978 (C:0.6978, R:0.0105)
Batch 275/537: Loss=0.6844 (C:0.6844, R:0.0105)
Batch 300/537: Loss=0.6983 (C:0.6983, R:0.0105)
Batch 325/537: Loss=0.6943 (C:0.6943, R:0.0106)
Batch 350/537: Loss=0.6891 (C:0.6891, R:0.0105)
Batch 375/537: Loss=0.6570 (C:0.6570, R:0.0105)
Batch 400/537: Loss=0.6403 (C:0.6403, R:0.0105)
Batch 425/537: Loss=0.7116 (C:0.7116, R:0.0105)
Batch 450/537: Loss=0.7192 (C:0.7192, R:0.0105)
Batch 475/537: Loss=0.7155 (C:0.7155, R:0.0105)
Batch 500/537: Loss=0.7262 (C:0.7262, R:0.0105)
Batch 525/537: Loss=0.7180 (C:0.7180, R:0.0105)

============================================================
Epoch 41/300 completed in 21.4s
Train: Loss=0.6913 (C:0.6913, R:0.0105) Ratio=4.59x
Val:   Loss=0.8132 (C:0.8132, R:0.0104) Ratio=3.13x
Reconstruction weight: 0.165
✅ New best model saved (Val Loss: 0.8132)
============================================================

Epoch 42 Training
----------------------------------------
Batch   0/537: Loss=0.6549 (C:0.6549, R:0.0105)
Batch  25/537: Loss=0.6887 (C:0.6887, R:0.0105)
Batch  50/537: Loss=0.7025 (C:0.7025, R:0.0105)
Batch  75/537: Loss=0.6704 (C:0.6704, R:0.0105)
Batch 100/537: Loss=0.6746 (C:0.6746, R:0.0105)
Batch 125/537: Loss=0.6826 (C:0.6826, R:0.0105)
Batch 150/537: Loss=0.6888 (C:0.6888, R:0.0105)
Batch 175/537: Loss=0.6535 (C:0.6535, R:0.0105)
Batch 200/537: Loss=0.6850 (C:0.6850, R:0.0105)
Batch 225/537: Loss=0.6651 (C:0.6651, R:0.0105)
Batch 250/537: Loss=0.6630 (C:0.6630, R:0.0105)
Batch 275/537: Loss=0.7207 (C:0.7207, R:0.0105)
Batch 300/537: Loss=0.6601 (C:0.6601, R:0.0105)
Batch 325/537: Loss=0.7152 (C:0.7152, R:0.0105)
Batch 350/537: Loss=0.7177 (C:0.7177, R:0.0105)
Batch 375/537: Loss=0.7011 (C:0.7011, R:0.0105)
Batch 400/537: Loss=0.7105 (C:0.7105, R:0.0105)
Batch 425/537: Loss=0.6779 (C:0.6779, R:0.0105)
Batch 450/537: Loss=0.6996 (C:0.6996, R:0.0105)
Batch 475/537: Loss=0.6830 (C:0.6830, R:0.0105)
Batch 500/537: Loss=0.6761 (C:0.6761, R:0.0105)
Batch 525/537: Loss=0.6964 (C:0.6964, R:0.0105)

============================================================
Epoch 42/300 completed in 21.6s
Train: Loss=0.6898 (C:0.6898, R:0.0105) Ratio=4.78x
Val:   Loss=0.8076 (C:0.8076, R:0.0104) Ratio=3.13x
Reconstruction weight: 0.180
✅ New best model saved (Val Loss: 0.8076)
============================================================

🌍 Updating global dataset at epoch 43
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.330 ± 0.571
    Neg distances: 2.268 ± 0.990
    Separation ratio: 6.88x
    Gap: -3.788
    ✅ Excellent global separation!

Epoch 43 Training
----------------------------------------
Batch   0/537: Loss=0.6615 (C:0.6615, R:0.0105)
Batch  25/537: Loss=0.6957 (C:0.6957, R:0.0105)
Batch  50/537: Loss=0.6764 (C:0.6764, R:0.0105)
Batch  75/537: Loss=0.6894 (C:0.6894, R:0.0105)
Batch 100/537: Loss=0.7007 (C:0.7007, R:0.0105)
Batch 125/537: Loss=0.6835 (C:0.6835, R:0.0105)
Batch 150/537: Loss=0.6921 (C:0.6921, R:0.0105)
Batch 175/537: Loss=0.6973 (C:0.6973, R:0.0105)
Batch 200/537: Loss=0.6417 (C:0.6417, R:0.0105)
Batch 225/537: Loss=0.6766 (C:0.6766, R:0.0105)
Batch 250/537: Loss=0.7076 (C:0.7076, R:0.0105)
Batch 275/537: Loss=0.7010 (C:0.7010, R:0.0105)
Batch 300/537: Loss=0.6364 (C:0.6364, R:0.0105)
Batch 325/537: Loss=0.7078 (C:0.7078, R:0.0105)
Batch 350/537: Loss=0.6695 (C:0.6695, R:0.0105)
Batch 375/537: Loss=0.6824 (C:0.6824, R:0.0105)
Batch 400/537: Loss=0.6985 (C:0.6985, R:0.0105)
Batch 425/537: Loss=0.7084 (C:0.7084, R:0.0105)
Batch 450/537: Loss=0.7191 (C:0.7191, R:0.0105)
Batch 475/537: Loss=0.6969 (C:0.6969, R:0.0105)
Batch 500/537: Loss=0.7043 (C:0.7043, R:0.0105)
Batch 525/537: Loss=0.6583 (C:0.6583, R:0.0105)

============================================================
Epoch 43/300 completed in 27.4s
Train: Loss=0.6773 (C:0.6773, R:0.0105) Ratio=4.73x
Val:   Loss=0.8054 (C:0.8054, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.195
✅ New best model saved (Val Loss: 0.8054)
============================================================

Epoch 44 Training
----------------------------------------
Batch   0/537: Loss=0.6759 (C:0.6759, R:0.0105)
Batch  25/537: Loss=0.6467 (C:0.6467, R:0.0105)
Batch  50/537: Loss=0.6279 (C:0.6279, R:0.0105)
Batch  75/537: Loss=0.6656 (C:0.6656, R:0.0105)
Batch 100/537: Loss=0.6553 (C:0.6553, R:0.0105)
Batch 125/537: Loss=0.6478 (C:0.6478, R:0.0105)
Batch 150/537: Loss=0.6988 (C:0.6988, R:0.0105)
Batch 175/537: Loss=0.6574 (C:0.6574, R:0.0105)
Batch 200/537: Loss=0.6948 (C:0.6948, R:0.0105)
Batch 225/537: Loss=0.6646 (C:0.6646, R:0.0105)
Batch 250/537: Loss=0.6547 (C:0.6547, R:0.0105)
Batch 275/537: Loss=0.6529 (C:0.6529, R:0.0105)
Batch 300/537: Loss=0.6577 (C:0.6577, R:0.0105)
Batch 325/537: Loss=0.6876 (C:0.6876, R:0.0105)
Batch 350/537: Loss=0.6625 (C:0.6625, R:0.0105)
Batch 375/537: Loss=0.6914 (C:0.6914, R:0.0105)
Batch 400/537: Loss=0.6766 (C:0.6766, R:0.0105)
Batch 425/537: Loss=0.6759 (C:0.6759, R:0.0105)
Batch 450/537: Loss=0.6402 (C:0.6402, R:0.0105)
Batch 475/537: Loss=0.6671 (C:0.6671, R:0.0105)
Batch 500/537: Loss=0.7065 (C:0.7065, R:0.0105)
Batch 525/537: Loss=0.7026 (C:0.7026, R:0.0105)

============================================================
Epoch 44/300 completed in 21.6s
Train: Loss=0.6743 (C:0.6743, R:0.0105) Ratio=4.74x
Val:   Loss=0.7994 (C:0.7994, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.210
✅ New best model saved (Val Loss: 0.7994)
============================================================

Epoch 45 Training
----------------------------------------
Batch   0/537: Loss=0.6788 (C:0.6788, R:0.0105)
Batch  25/537: Loss=0.6712 (C:0.6712, R:0.0105)
Batch  50/537: Loss=0.6596 (C:0.6596, R:0.0105)
Batch  75/537: Loss=0.6160 (C:0.6160, R:0.0105)
Batch 100/537: Loss=0.6529 (C:0.6529, R:0.0105)
Batch 125/537: Loss=0.6771 (C:0.6771, R:0.0105)
Batch 150/537: Loss=0.6339 (C:0.6339, R:0.0105)
Batch 175/537: Loss=0.6501 (C:0.6501, R:0.0105)
Batch 200/537: Loss=0.6491 (C:0.6491, R:0.0105)
Batch 225/537: Loss=0.6896 (C:0.6896, R:0.0105)
Batch 250/537: Loss=0.6542 (C:0.6542, R:0.0105)
Batch 275/537: Loss=0.6726 (C:0.6726, R:0.0105)
Batch 300/537: Loss=0.6826 (C:0.6826, R:0.0105)
Batch 325/537: Loss=0.6835 (C:0.6835, R:0.0105)
Batch 350/537: Loss=0.6755 (C:0.6755, R:0.0105)
Batch 375/537: Loss=0.6918 (C:0.6918, R:0.0105)
Batch 400/537: Loss=0.6646 (C:0.6646, R:0.0105)
Batch 425/537: Loss=0.6873 (C:0.6873, R:0.0105)
Batch 450/537: Loss=0.7004 (C:0.7004, R:0.0105)
Batch 475/537: Loss=0.7047 (C:0.7047, R:0.0105)
Batch 500/537: Loss=0.6874 (C:0.6874, R:0.0105)
Batch 525/537: Loss=0.6935 (C:0.6935, R:0.0105)

============================================================
Epoch 45/300 completed in 21.5s
Train: Loss=0.6741 (C:0.6741, R:0.0105) Ratio=4.88x
Val:   Loss=0.8098 (C:0.8098, R:0.0104) Ratio=3.12x
Reconstruction weight: 0.225
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 46
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.309 ± 0.532
    Neg distances: 2.312 ± 0.991
    Separation ratio: 7.47x
    Gap: -3.830
    ✅ Excellent global separation!

Epoch 46 Training
----------------------------------------
Batch   0/537: Loss=0.6289 (C:0.6289, R:0.0105)
Batch  25/537: Loss=0.6764 (C:0.6764, R:0.0105)
Batch  50/537: Loss=0.6375 (C:0.6375, R:0.0105)
Batch  75/537: Loss=0.6378 (C:0.6378, R:0.0105)
Batch 100/537: Loss=0.6251 (C:0.6251, R:0.0105)
Batch 125/537: Loss=0.6665 (C:0.6665, R:0.0105)
Batch 150/537: Loss=0.6812 (C:0.6812, R:0.0105)
Batch 175/537: Loss=0.6592 (C:0.6592, R:0.0105)
Batch 200/537: Loss=0.6767 (C:0.6767, R:0.0105)
Batch 225/537: Loss=0.6537 (C:0.6537, R:0.0105)
Batch 250/537: Loss=0.6273 (C:0.6273, R:0.0105)
Batch 275/537: Loss=0.6619 (C:0.6619, R:0.0105)
Batch 300/537: Loss=0.6535 (C:0.6535, R:0.0105)
Batch 325/537: Loss=0.6711 (C:0.6711, R:0.0105)
Batch 350/537: Loss=0.6813 (C:0.6813, R:0.0105)
Batch 375/537: Loss=0.6509 (C:0.6509, R:0.0105)
Batch 400/537: Loss=0.6317 (C:0.6317, R:0.0105)
Batch 425/537: Loss=0.6543 (C:0.6543, R:0.0105)
Batch 450/537: Loss=0.6420 (C:0.6420, R:0.0105)
Batch 475/537: Loss=0.6664 (C:0.6664, R:0.0105)
Batch 500/537: Loss=0.6563 (C:0.6563, R:0.0105)
Batch 525/537: Loss=0.6645 (C:0.6645, R:0.0105)

============================================================
Epoch 46/300 completed in 26.6s
Train: Loss=0.6463 (C:0.6463, R:0.0105) Ratio=4.71x
Val:   Loss=0.7775 (C:0.7775, R:0.0104) Ratio=3.14x
Reconstruction weight: 0.240
✅ New best model saved (Val Loss: 0.7775)
============================================================

Epoch 47 Training
----------------------------------------
Batch   0/537: Loss=0.6093 (C:0.6093, R:0.0105)
Batch  25/537: Loss=0.6529 (C:0.6529, R:0.0105)
Batch  50/537: Loss=0.6418 (C:0.6418, R:0.0105)
Batch  75/537: Loss=0.6605 (C:0.6605, R:0.0105)
Batch 100/537: Loss=0.6436 (C:0.6436, R:0.0106)
Batch 125/537: Loss=0.6660 (C:0.6660, R:0.0105)
Batch 150/537: Loss=0.6362 (C:0.6362, R:0.0105)
Batch 175/537: Loss=0.6130 (C:0.6130, R:0.0105)
Batch 200/537: Loss=0.6354 (C:0.6354, R:0.0105)
Batch 225/537: Loss=0.6926 (C:0.6926, R:0.0105)
Batch 250/537: Loss=0.6368 (C:0.6368, R:0.0105)
Batch 275/537: Loss=0.6091 (C:0.6091, R:0.0105)
Batch 300/537: Loss=0.6637 (C:0.6637, R:0.0105)
Batch 325/537: Loss=0.6488 (C:0.6488, R:0.0105)
Batch 350/537: Loss=0.6405 (C:0.6405, R:0.0105)
Batch 375/537: Loss=0.6333 (C:0.6333, R:0.0105)
Batch 400/537: Loss=0.6287 (C:0.6287, R:0.0105)
Batch 425/537: Loss=0.6440 (C:0.6440, R:0.0105)
Batch 450/537: Loss=0.6139 (C:0.6139, R:0.0105)
Batch 475/537: Loss=0.6415 (C:0.6415, R:0.0105)
Batch 500/537: Loss=0.6339 (C:0.6339, R:0.0105)
Batch 525/537: Loss=0.6216 (C:0.6216, R:0.0105)

============================================================
Epoch 47/300 completed in 21.1s
Train: Loss=0.6431 (C:0.6431, R:0.0105) Ratio=4.90x
Val:   Loss=0.7704 (C:0.7704, R:0.0104) Ratio=3.14x
Reconstruction weight: 0.255
✅ New best model saved (Val Loss: 0.7704)
============================================================

Epoch 48 Training
----------------------------------------
Batch   0/537: Loss=0.6570 (C:0.6570, R:0.0105)
Batch  25/537: Loss=0.6546 (C:0.6546, R:0.0105)
Batch  50/537: Loss=0.5964 (C:0.5964, R:0.0105)
Batch  75/537: Loss=0.6024 (C:0.6024, R:0.0105)
Batch 100/537: Loss=0.5831 (C:0.5831, R:0.0105)
Batch 125/537: Loss=0.6320 (C:0.6320, R:0.0105)
Batch 150/537: Loss=0.6316 (C:0.6316, R:0.0105)
Batch 175/537: Loss=0.6305 (C:0.6305, R:0.0105)
Batch 200/537: Loss=0.6140 (C:0.6140, R:0.0105)
Batch 225/537: Loss=0.6497 (C:0.6497, R:0.0105)
Batch 250/537: Loss=0.6655 (C:0.6655, R:0.0105)
Batch 275/537: Loss=0.6544 (C:0.6544, R:0.0105)
Batch 300/537: Loss=0.6086 (C:0.6086, R:0.0105)
Batch 325/537: Loss=0.6223 (C:0.6223, R:0.0105)
Batch 350/537: Loss=0.6387 (C:0.6387, R:0.0105)
Batch 375/537: Loss=0.6321 (C:0.6321, R:0.0105)
Batch 400/537: Loss=0.6770 (C:0.6770, R:0.0105)
Batch 425/537: Loss=0.6628 (C:0.6628, R:0.0105)
Batch 450/537: Loss=0.6500 (C:0.6500, R:0.0105)
Batch 475/537: Loss=0.6661 (C:0.6661, R:0.0105)
Batch 500/537: Loss=0.6609 (C:0.6609, R:0.0105)
Batch 525/537: Loss=0.6537 (C:0.6537, R:0.0105)

============================================================
Epoch 48/300 completed in 21.5s
Train: Loss=0.6419 (C:0.6419, R:0.0105) Ratio=4.84x
Val:   Loss=0.7752 (C:0.7752, R:0.0104) Ratio=3.14x
Reconstruction weight: 0.270
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 49
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.326 ± 0.570
    Neg distances: 2.357 ± 1.011
    Separation ratio: 7.22x
    Gap: -3.942
    ✅ Excellent global separation!

Epoch 49 Training
----------------------------------------
Batch   0/537: Loss=0.6408 (C:0.6408, R:0.0105)
Batch  25/537: Loss=0.6274 (C:0.6274, R:0.0105)
Batch  50/537: Loss=0.6113 (C:0.6113, R:0.0105)
Batch  75/537: Loss=0.6534 (C:0.6534, R:0.0105)
Batch 100/537: Loss=0.6208 (C:0.6208, R:0.0105)
Batch 125/537: Loss=0.6234 (C:0.6234, R:0.0105)
Batch 150/537: Loss=0.6475 (C:0.6475, R:0.0105)
Batch 175/537: Loss=0.6688 (C:0.6688, R:0.0105)
Batch 200/537: Loss=0.6290 (C:0.6290, R:0.0105)
Batch 225/537: Loss=0.6529 (C:0.6529, R:0.0105)
Batch 250/537: Loss=0.6094 (C:0.6094, R:0.0105)
Batch 275/537: Loss=0.6319 (C:0.6319, R:0.0105)
Batch 300/537: Loss=0.6703 (C:0.6703, R:0.0105)
Batch 325/537: Loss=0.6503 (C:0.6503, R:0.0105)
Batch 350/537: Loss=0.6595 (C:0.6595, R:0.0105)
Batch 375/537: Loss=0.6279 (C:0.6279, R:0.0105)
Batch 400/537: Loss=0.6636 (C:0.6636, R:0.0105)
Batch 425/537: Loss=0.6825 (C:0.6825, R:0.0105)
Batch 450/537: Loss=0.6550 (C:0.6550, R:0.0105)
Batch 475/537: Loss=0.6313 (C:0.6313, R:0.0105)
Batch 500/537: Loss=0.6744 (C:0.6744, R:0.0105)
Batch 525/537: Loss=0.6354 (C:0.6354, R:0.0105)

============================================================
Epoch 49/300 completed in 27.4s
Train: Loss=0.6380 (C:0.6380, R:0.0105) Ratio=4.91x
Val:   Loss=0.7786 (C:0.7786, R:0.0104) Ratio=3.12x
Reconstruction weight: 0.285
No improvement for 2 epochs
============================================================

Epoch 50 Training
----------------------------------------
Batch   0/537: Loss=0.5882 (C:0.5882, R:0.0105)
Batch  25/537: Loss=0.6138 (C:0.6138, R:0.0105)
Batch  50/537: Loss=0.6077 (C:0.6077, R:0.0105)
Batch  75/537: Loss=0.6320 (C:0.6320, R:0.0105)
Batch 100/537: Loss=0.6352 (C:0.6352, R:0.0105)
Batch 125/537: Loss=0.6053 (C:0.6053, R:0.0105)
Batch 150/537: Loss=0.6415 (C:0.6415, R:0.0105)
Batch 175/537: Loss=0.6739 (C:0.6739, R:0.0105)
Batch 200/537: Loss=0.6635 (C:0.6635, R:0.0105)
Batch 225/537: Loss=0.5870 (C:0.5870, R:0.0105)
Batch 250/537: Loss=0.5993 (C:0.5993, R:0.0105)
Batch 275/537: Loss=0.6284 (C:0.6284, R:0.0105)
Batch 300/537: Loss=0.6166 (C:0.6166, R:0.0105)
Batch 325/537: Loss=0.6358 (C:0.6358, R:0.0105)
Batch 350/537: Loss=0.6174 (C:0.6174, R:0.0105)
Batch 375/537: Loss=0.6270 (C:0.6270, R:0.0105)
Batch 400/537: Loss=0.6259 (C:0.6259, R:0.0105)
Batch 425/537: Loss=0.6711 (C:0.6711, R:0.0105)
Batch 450/537: Loss=0.6189 (C:0.6189, R:0.0105)
Batch 475/537: Loss=0.6445 (C:0.6445, R:0.0105)
Batch 500/537: Loss=0.6669 (C:0.6669, R:0.0105)
Batch 525/537: Loss=0.6474 (C:0.6474, R:0.0105)

============================================================
Epoch 50/300 completed in 21.2s
Train: Loss=0.6358 (C:0.6358, R:0.0105) Ratio=4.98x
Val:   Loss=0.7761 (C:0.7761, R:0.0104) Ratio=3.13x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

Epoch 51 Training
----------------------------------------
Batch   0/537: Loss=0.6134 (C:0.6134, R:0.0105)
Batch  25/537: Loss=0.6273 (C:0.6273, R:0.0105)
Batch  50/537: Loss=0.6155 (C:0.6155, R:0.0105)
Batch  75/537: Loss=0.6110 (C:0.6110, R:0.0105)
Batch 100/537: Loss=0.6357 (C:0.6357, R:0.0105)
Batch 125/537: Loss=0.6227 (C:0.6227, R:0.0105)
Batch 150/537: Loss=0.6512 (C:0.6512, R:0.0105)
Batch 175/537: Loss=0.6421 (C:0.6421, R:0.0105)
Batch 200/537: Loss=0.6592 (C:0.6592, R:0.0105)
Batch 225/537: Loss=0.6266 (C:0.6266, R:0.0105)
Batch 250/537: Loss=0.6180 (C:0.6180, R:0.0105)
Batch 275/537: Loss=0.6331 (C:0.6331, R:0.0105)
Batch 300/537: Loss=0.6398 (C:0.6398, R:0.0105)
Batch 325/537: Loss=0.6032 (C:0.6032, R:0.0105)
Batch 350/537: Loss=0.6518 (C:0.6518, R:0.0105)
Batch 375/537: Loss=0.6431 (C:0.6431, R:0.0105)
Batch 400/537: Loss=0.6209 (C:0.6209, R:0.0105)
Batch 425/537: Loss=0.6224 (C:0.6224, R:0.0105)
Batch 450/537: Loss=0.6617 (C:0.6617, R:0.0106)
Batch 475/537: Loss=0.6212 (C:0.6212, R:0.0105)
Batch 500/537: Loss=0.6817 (C:0.6817, R:0.0105)
Batch 525/537: Loss=0.6520 (C:0.6520, R:0.0105)

============================================================
Epoch 51/300 completed in 21.5s
Train: Loss=0.6321 (C:0.6321, R:0.0105) Ratio=4.91x
Val:   Loss=0.7670 (C:0.7670, R:0.0104) Ratio=3.14x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.7670)
============================================================

🌍 Updating global dataset at epoch 52
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.308 ± 0.551
    Neg distances: 2.410 ± 1.018
    Separation ratio: 7.82x
    Gap: -3.976
    ✅ Excellent global separation!

Epoch 52 Training
----------------------------------------
Batch   0/537: Loss=0.6004 (C:0.6004, R:0.0105)
Batch  25/537: Loss=0.5913 (C:0.5913, R:0.0105)
Batch  50/537: Loss=0.6173 (C:0.6173, R:0.0105)
Batch  75/537: Loss=0.5894 (C:0.5894, R:0.0105)
Batch 100/537: Loss=0.6207 (C:0.6207, R:0.0105)
Batch 125/537: Loss=0.6108 (C:0.6108, R:0.0105)
Batch 150/537: Loss=0.5956 (C:0.5956, R:0.0105)
Batch 175/537: Loss=0.6111 (C:0.6111, R:0.0105)
Batch 200/537: Loss=0.5966 (C:0.5966, R:0.0105)
Batch 225/537: Loss=0.6009 (C:0.6009, R:0.0105)
Batch 250/537: Loss=0.6157 (C:0.6157, R:0.0105)
Batch 275/537: Loss=0.6366 (C:0.6366, R:0.0105)
Batch 300/537: Loss=0.5963 (C:0.5963, R:0.0105)
Batch 325/537: Loss=0.5949 (C:0.5949, R:0.0105)
Batch 350/537: Loss=0.5867 (C:0.5867, R:0.0105)
Batch 375/537: Loss=0.5911 (C:0.5911, R:0.0105)
Batch 400/537: Loss=0.5980 (C:0.5980, R:0.0105)
Batch 425/537: Loss=0.6285 (C:0.6285, R:0.0105)
Batch 450/537: Loss=0.6449 (C:0.6449, R:0.0105)
Batch 475/537: Loss=0.6083 (C:0.6083, R:0.0105)
Batch 500/537: Loss=0.6052 (C:0.6052, R:0.0105)
Batch 525/537: Loss=0.6092 (C:0.6092, R:0.0105)

============================================================
Epoch 52/300 completed in 27.0s
Train: Loss=0.6082 (C:0.6082, R:0.0105) Ratio=5.03x
Val:   Loss=0.7442 (C:0.7442, R:0.0104) Ratio=3.15x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.7442)
============================================================

Epoch 53 Training
----------------------------------------
Batch   0/537: Loss=0.5632 (C:0.5632, R:0.0105)
Batch  25/537: Loss=0.6067 (C:0.6067, R:0.0105)
Batch  50/537: Loss=0.5972 (C:0.5972, R:0.0105)
Batch  75/537: Loss=0.6395 (C:0.6395, R:0.0105)
Batch 100/537: Loss=0.5928 (C:0.5928, R:0.0105)
Batch 125/537: Loss=0.5650 (C:0.5650, R:0.0106)
Batch 150/537: Loss=0.6118 (C:0.6118, R:0.0105)
Batch 175/537: Loss=0.5640 (C:0.5640, R:0.0106)
Batch 200/537: Loss=0.6033 (C:0.6033, R:0.0105)
Batch 225/537: Loss=0.5954 (C:0.5954, R:0.0105)
Batch 250/537: Loss=0.5917 (C:0.5917, R:0.0105)
Batch 275/537: Loss=0.6005 (C:0.6005, R:0.0105)
Batch 300/537: Loss=0.6217 (C:0.6217, R:0.0105)
Batch 325/537: Loss=0.6052 (C:0.6052, R:0.0105)
Batch 350/537: Loss=0.6353 (C:0.6353, R:0.0105)
Batch 375/537: Loss=0.5937 (C:0.5937, R:0.0105)
Batch 400/537: Loss=0.5665 (C:0.5665, R:0.0105)
Batch 425/537: Loss=0.6012 (C:0.6012, R:0.0105)
Batch 450/537: Loss=0.6164 (C:0.6164, R:0.0105)
Batch 475/537: Loss=0.6312 (C:0.6312, R:0.0105)
Batch 500/537: Loss=0.6166 (C:0.6166, R:0.0105)
Batch 525/537: Loss=0.6298 (C:0.6298, R:0.0105)

============================================================
Epoch 53/300 completed in 21.1s
Train: Loss=0.6060 (C:0.6060, R:0.0105) Ratio=5.07x
Val:   Loss=0.7526 (C:0.7526, R:0.0104) Ratio=3.12x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

Epoch 54 Training
----------------------------------------
Batch   0/537: Loss=0.6153 (C:0.6153, R:0.0105)
Batch  25/537: Loss=0.6053 (C:0.6053, R:0.0105)
Batch  50/537: Loss=0.5916 (C:0.5916, R:0.0105)
Batch  75/537: Loss=0.5435 (C:0.5435, R:0.0105)
Batch 100/537: Loss=0.5879 (C:0.5879, R:0.0105)
Batch 125/537: Loss=0.6107 (C:0.6107, R:0.0105)
Batch 150/537: Loss=0.5648 (C:0.5648, R:0.0105)
Batch 175/537: Loss=0.6019 (C:0.6019, R:0.0105)
Batch 200/537: Loss=0.6057 (C:0.6057, R:0.0105)
Batch 225/537: Loss=0.6340 (C:0.6340, R:0.0105)
Batch 250/537: Loss=0.6235 (C:0.6235, R:0.0105)
Batch 275/537: Loss=0.6011 (C:0.6011, R:0.0105)
Batch 300/537: Loss=0.6274 (C:0.6274, R:0.0105)
Batch 325/537: Loss=0.6114 (C:0.6114, R:0.0105)
Batch 350/537: Loss=0.6118 (C:0.6118, R:0.0105)
Batch 375/537: Loss=0.5940 (C:0.5940, R:0.0105)
Batch 400/537: Loss=0.6019 (C:0.6019, R:0.0105)
Batch 425/537: Loss=0.5908 (C:0.5908, R:0.0106)
Batch 450/537: Loss=0.5981 (C:0.5981, R:0.0106)
Batch 475/537: Loss=0.6133 (C:0.6133, R:0.0105)
Batch 500/537: Loss=0.6379 (C:0.6379, R:0.0105)
Batch 525/537: Loss=0.5814 (C:0.5814, R:0.0105)

============================================================
Epoch 54/300 completed in 22.0s
Train: Loss=0.6065 (C:0.6065, R:0.0105) Ratio=5.04x
Val:   Loss=0.7494 (C:0.7494, R:0.0104) Ratio=3.15x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 55
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.310 ± 0.562
    Neg distances: 2.456 ± 1.041
    Separation ratio: 7.92x
    Gap: -4.112
    ✅ Excellent global separation!

Epoch 55 Training
----------------------------------------
Batch   0/537: Loss=0.6218 (C:0.6218, R:0.0105)
Batch  25/537: Loss=0.5984 (C:0.5984, R:0.0105)
Batch  50/537: Loss=0.6361 (C:0.6361, R:0.0105)
Batch  75/537: Loss=0.6101 (C:0.6101, R:0.0105)
Batch 100/537: Loss=0.6128 (C:0.6128, R:0.0105)
Batch 125/537: Loss=0.5647 (C:0.5647, R:0.0106)
Batch 150/537: Loss=0.5875 (C:0.5875, R:0.0105)
Batch 175/537: Loss=0.5681 (C:0.5681, R:0.0105)
Batch 200/537: Loss=0.5866 (C:0.5866, R:0.0106)
Batch 225/537: Loss=0.5810 (C:0.5810, R:0.0105)
Batch 250/537: Loss=0.6214 (C:0.6214, R:0.0105)
Batch 275/537: Loss=0.6023 (C:0.6023, R:0.0105)
Batch 300/537: Loss=0.5992 (C:0.5992, R:0.0105)
Batch 325/537: Loss=0.5943 (C:0.5943, R:0.0105)
Batch 350/537: Loss=0.6408 (C:0.6408, R:0.0105)
Batch 375/537: Loss=0.5816 (C:0.5816, R:0.0105)
Batch 400/537: Loss=0.6194 (C:0.6194, R:0.0105)
Batch 425/537: Loss=0.5889 (C:0.5889, R:0.0105)
Batch 450/537: Loss=0.6064 (C:0.6064, R:0.0105)
Batch 475/537: Loss=0.5746 (C:0.5746, R:0.0105)
Batch 500/537: Loss=0.5939 (C:0.5939, R:0.0105)
Batch 525/537: Loss=0.6028 (C:0.6028, R:0.0105)

============================================================
Epoch 55/300 completed in 29.8s
Train: Loss=0.5968 (C:0.5968, R:0.0105) Ratio=4.96x
Val:   Loss=0.7468 (C:0.7468, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

Epoch 56 Training
----------------------------------------
Batch   0/537: Loss=0.5857 (C:0.5857, R:0.0105)
Batch  25/537: Loss=0.5618 (C:0.5618, R:0.0105)
Batch  50/537: Loss=0.5957 (C:0.5957, R:0.0105)
Batch  75/537: Loss=0.6102 (C:0.6102, R:0.0105)
Batch 100/537: Loss=0.6179 (C:0.6179, R:0.0105)
Batch 125/537: Loss=0.6242 (C:0.6242, R:0.0105)
Batch 150/537: Loss=0.6161 (C:0.6161, R:0.0106)
Batch 175/537: Loss=0.5624 (C:0.5624, R:0.0105)
Batch 200/537: Loss=0.5986 (C:0.5986, R:0.0105)
Batch 225/537: Loss=0.5875 (C:0.5875, R:0.0105)
Batch 250/537: Loss=0.6453 (C:0.6453, R:0.0105)
Batch 275/537: Loss=0.6040 (C:0.6040, R:0.0105)
Batch 300/537: Loss=0.5788 (C:0.5788, R:0.0105)
Batch 325/537: Loss=0.6101 (C:0.6101, R:0.0105)
Batch 350/537: Loss=0.5819 (C:0.5819, R:0.0105)
Batch 375/537: Loss=0.5542 (C:0.5542, R:0.0105)
Batch 400/537: Loss=0.5717 (C:0.5717, R:0.0105)
Batch 425/537: Loss=0.6069 (C:0.6069, R:0.0105)
Batch 450/537: Loss=0.5849 (C:0.5849, R:0.0105)
Batch 475/537: Loss=0.5934 (C:0.5934, R:0.0105)
Batch 500/537: Loss=0.5588 (C:0.5588, R:0.0105)
Batch 525/537: Loss=0.5922 (C:0.5922, R:0.0105)

============================================================
Epoch 56/300 completed in 23.0s
Train: Loss=0.5960 (C:0.5960, R:0.0105) Ratio=5.08x
Val:   Loss=0.7541 (C:0.7541, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.300
No improvement for 4 epochs
============================================================

Epoch 57 Training
----------------------------------------
Batch   0/537: Loss=0.5788 (C:0.5788, R:0.0105)
Batch  25/537: Loss=0.5860 (C:0.5860, R:0.0106)
Batch  50/537: Loss=0.5890 (C:0.5890, R:0.0105)
Batch  75/537: Loss=0.5840 (C:0.5840, R:0.0105)
Batch 100/537: Loss=0.6012 (C:0.6012, R:0.0105)
Batch 125/537: Loss=0.5736 (C:0.5736, R:0.0105)
Batch 150/537: Loss=0.5848 (C:0.5848, R:0.0105)
Batch 175/537: Loss=0.6056 (C:0.6056, R:0.0105)
Batch 200/537: Loss=0.6109 (C:0.6109, R:0.0105)
Batch 225/537: Loss=0.6415 (C:0.6415, R:0.0105)
Batch 250/537: Loss=0.6268 (C:0.6268, R:0.0105)
Batch 275/537: Loss=0.5854 (C:0.5854, R:0.0105)
Batch 300/537: Loss=0.5928 (C:0.5928, R:0.0105)
Batch 325/537: Loss=0.6012 (C:0.6012, R:0.0105)
Batch 350/537: Loss=0.6047 (C:0.6047, R:0.0105)
Batch 375/537: Loss=0.6032 (C:0.6032, R:0.0105)
Batch 400/537: Loss=0.5978 (C:0.5978, R:0.0105)
Batch 425/537: Loss=0.5806 (C:0.5806, R:0.0106)
Batch 450/537: Loss=0.6073 (C:0.6073, R:0.0105)
Batch 475/537: Loss=0.5955 (C:0.5955, R:0.0105)
Batch 500/537: Loss=0.5958 (C:0.5958, R:0.0105)
Batch 525/537: Loss=0.5904 (C:0.5904, R:0.0105)

============================================================
Epoch 57/300 completed in 22.4s
Train: Loss=0.5947 (C:0.5947, R:0.0105) Ratio=5.03x
Val:   Loss=0.7333 (C:0.7333, R:0.0104) Ratio=3.12x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.7333)
============================================================

🌍 Updating global dataset at epoch 58
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.305 ± 0.552
    Neg distances: 2.472 ± 1.038
    Separation ratio: 8.12x
    Gap: -4.100
    ✅ Excellent global separation!

Epoch 58 Training
----------------------------------------
Batch   0/537: Loss=0.5918 (C:0.5918, R:0.0105)
Batch  25/537: Loss=0.5916 (C:0.5916, R:0.0105)
Batch  50/537: Loss=0.5914 (C:0.5914, R:0.0105)
Batch  75/537: Loss=0.6189 (C:0.6189, R:0.0105)
Batch 100/537: Loss=0.5702 (C:0.5702, R:0.0105)
Batch 125/537: Loss=0.5673 (C:0.5673, R:0.0105)
Batch 150/537: Loss=0.5828 (C:0.5828, R:0.0105)
Batch 175/537: Loss=0.5623 (C:0.5623, R:0.0105)
Batch 200/537: Loss=0.6338 (C:0.6338, R:0.0105)
Batch 225/537: Loss=0.5562 (C:0.5562, R:0.0105)
Batch 250/537: Loss=0.5849 (C:0.5849, R:0.0105)
Batch 275/537: Loss=0.5697 (C:0.5697, R:0.0105)
Batch 300/537: Loss=0.5790 (C:0.5790, R:0.0105)
Batch 325/537: Loss=0.6001 (C:0.6001, R:0.0105)
Batch 350/537: Loss=0.6422 (C:0.6422, R:0.0105)
Batch 375/537: Loss=0.5687 (C:0.5687, R:0.0105)
Batch 400/537: Loss=0.5959 (C:0.5959, R:0.0105)
Batch 425/537: Loss=0.5717 (C:0.5717, R:0.0105)
Batch 450/537: Loss=0.5618 (C:0.5618, R:0.0105)
Batch 475/537: Loss=0.5938 (C:0.5938, R:0.0105)
Batch 500/537: Loss=0.5714 (C:0.5714, R:0.0105)
Batch 525/537: Loss=0.5750 (C:0.5750, R:0.0105)

============================================================
Epoch 58/300 completed in 30.0s
Train: Loss=0.5797 (C:0.5797, R:0.0105) Ratio=5.02x
Val:   Loss=0.7340 (C:0.7340, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

Epoch 59 Training
----------------------------------------
Batch   0/537: Loss=0.5700 (C:0.5700, R:0.0105)
Batch  25/537: Loss=0.5956 (C:0.5956, R:0.0105)
Batch  50/537: Loss=0.5663 (C:0.5663, R:0.0105)
Batch  75/537: Loss=0.5458 (C:0.5458, R:0.0105)
Batch 100/537: Loss=0.5586 (C:0.5586, R:0.0105)
Batch 125/537: Loss=0.5855 (C:0.5855, R:0.0105)
Batch 150/537: Loss=0.6006 (C:0.6006, R:0.0105)
Batch 175/537: Loss=0.5387 (C:0.5387, R:0.0105)
Batch 200/537: Loss=0.6107 (C:0.6107, R:0.0105)
Batch 225/537: Loss=0.5845 (C:0.5845, R:0.0105)
Batch 250/537: Loss=0.5977 (C:0.5977, R:0.0105)
Batch 275/537: Loss=0.5415 (C:0.5415, R:0.0105)
Batch 300/537: Loss=0.6048 (C:0.6048, R:0.0105)
Batch 325/537: Loss=0.6018 (C:0.6018, R:0.0105)
Batch 350/537: Loss=0.6284 (C:0.6284, R:0.0105)
Batch 375/537: Loss=0.5810 (C:0.5810, R:0.0105)
Batch 400/537: Loss=0.5836 (C:0.5836, R:0.0105)
Batch 425/537: Loss=0.5943 (C:0.5943, R:0.0105)
Batch 450/537: Loss=0.5708 (C:0.5708, R:0.0105)
Batch 475/537: Loss=0.5966 (C:0.5966, R:0.0105)
Batch 500/537: Loss=0.6018 (C:0.6018, R:0.0105)
Batch 525/537: Loss=0.5782 (C:0.5782, R:0.0105)

============================================================
Epoch 59/300 completed in 22.8s
Train: Loss=0.5795 (C:0.5795, R:0.0105) Ratio=5.01x
Val:   Loss=0.7409 (C:0.7409, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

Epoch 60 Training
----------------------------------------
Batch   0/537: Loss=0.5612 (C:0.5612, R:0.0105)
Batch  25/537: Loss=0.5763 (C:0.5763, R:0.0105)
Batch  50/537: Loss=0.5860 (C:0.5860, R:0.0105)
Batch  75/537: Loss=0.5661 (C:0.5661, R:0.0105)
Batch 100/537: Loss=0.5732 (C:0.5732, R:0.0105)
Batch 125/537: Loss=0.5998 (C:0.5998, R:0.0105)
Batch 150/537: Loss=0.5429 (C:0.5429, R:0.0105)
Batch 175/537: Loss=0.5776 (C:0.5776, R:0.0106)
Batch 200/537: Loss=0.6080 (C:0.6080, R:0.0105)
Batch 225/537: Loss=0.5793 (C:0.5793, R:0.0105)
Batch 250/537: Loss=0.6064 (C:0.6064, R:0.0104)
Batch 275/537: Loss=0.5802 (C:0.5802, R:0.0105)
Batch 300/537: Loss=0.5756 (C:0.5756, R:0.0105)
Batch 325/537: Loss=0.5918 (C:0.5918, R:0.0105)
Batch 350/537: Loss=0.5744 (C:0.5744, R:0.0105)
Batch 375/537: Loss=0.6165 (C:0.6165, R:0.0105)
Batch 400/537: Loss=0.6116 (C:0.6116, R:0.0105)
Batch 425/537: Loss=0.5870 (C:0.5870, R:0.0105)
Batch 450/537: Loss=0.6132 (C:0.6132, R:0.0105)
Batch 475/537: Loss=0.5912 (C:0.5912, R:0.0105)
Batch 500/537: Loss=0.5316 (C:0.5316, R:0.0105)
Batch 525/537: Loss=0.5487 (C:0.5487, R:0.0105)

============================================================
Epoch 60/300 completed in 22.5s
Train: Loss=0.5773 (C:0.5773, R:0.0105) Ratio=5.07x
Val:   Loss=0.7367 (C:0.7367, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.300
No improvement for 3 epochs
Checkpoint saved at epoch 60
============================================================

🌍 Updating global dataset at epoch 61
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.306 ± 0.557
    Neg distances: 2.498 ± 1.045
    Separation ratio: 8.16x
    Gap: -4.126
    ✅ Excellent global separation!

Epoch 61 Training
----------------------------------------
Batch   0/537: Loss=0.5710 (C:0.5710, R:0.0105)
Batch  25/537: Loss=0.5547 (C:0.5547, R:0.0105)
Batch  50/537: Loss=0.5767 (C:0.5767, R:0.0105)
Batch  75/537: Loss=0.5910 (C:0.5910, R:0.0106)
Batch 100/537: Loss=0.5106 (C:0.5106, R:0.0105)
Batch 125/537: Loss=0.5540 (C:0.5540, R:0.0105)
Batch 150/537: Loss=0.5433 (C:0.5433, R:0.0105)
Batch 175/537: Loss=0.5740 (C:0.5740, R:0.0105)
Batch 200/537: Loss=0.5956 (C:0.5956, R:0.0105)
Batch 225/537: Loss=0.5910 (C:0.5910, R:0.0105)
Batch 250/537: Loss=0.5692 (C:0.5692, R:0.0105)
Batch 275/537: Loss=0.5866 (C:0.5866, R:0.0105)
Batch 300/537: Loss=0.6001 (C:0.6001, R:0.0105)
Batch 325/537: Loss=0.5746 (C:0.5746, R:0.0105)
Batch 350/537: Loss=0.5309 (C:0.5309, R:0.0105)
Batch 375/537: Loss=0.5951 (C:0.5951, R:0.0105)
Batch 400/537: Loss=0.5469 (C:0.5469, R:0.0105)
Batch 425/537: Loss=0.5932 (C:0.5932, R:0.0105)
Batch 450/537: Loss=0.5523 (C:0.5523, R:0.0105)
Batch 475/537: Loss=0.6115 (C:0.6115, R:0.0105)
Batch 500/537: Loss=0.5639 (C:0.5639, R:0.0105)
Batch 525/537: Loss=0.5613 (C:0.5613, R:0.0105)

============================================================
Epoch 61/300 completed in 28.7s
Train: Loss=0.5737 (C:0.5737, R:0.0105) Ratio=5.23x
Val:   Loss=0.7298 (C:0.7298, R:0.0104) Ratio=3.12x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.7298)
============================================================

Epoch 62 Training
----------------------------------------
Batch   0/537: Loss=0.5801 (C:0.5801, R:0.0105)
Batch  25/537: Loss=0.6115 (C:0.6115, R:0.0105)
Batch  50/537: Loss=0.5631 (C:0.5631, R:0.0105)
Batch  75/537: Loss=0.5259 (C:0.5259, R:0.0105)
Batch 100/537: Loss=0.5504 (C:0.5504, R:0.0105)
Batch 125/537: Loss=0.5977 (C:0.5977, R:0.0105)
Batch 150/537: Loss=0.5725 (C:0.5725, R:0.0105)
Batch 175/537: Loss=0.5683 (C:0.5683, R:0.0105)
Batch 200/537: Loss=0.5641 (C:0.5641, R:0.0105)
Batch 225/537: Loss=0.5630 (C:0.5630, R:0.0105)
Batch 250/537: Loss=0.5725 (C:0.5725, R:0.0105)
Batch 275/537: Loss=0.5759 (C:0.5759, R:0.0105)
Batch 300/537: Loss=0.5488 (C:0.5488, R:0.0105)
Batch 325/537: Loss=0.5922 (C:0.5922, R:0.0105)
Batch 350/537: Loss=0.6201 (C:0.6201, R:0.0105)
Batch 375/537: Loss=0.5898 (C:0.5898, R:0.0105)
Batch 400/537: Loss=0.5614 (C:0.5614, R:0.0105)
Batch 425/537: Loss=0.5848 (C:0.5848, R:0.0105)
Batch 450/537: Loss=0.5911 (C:0.5911, R:0.0105)
Batch 475/537: Loss=0.5818 (C:0.5818, R:0.0105)
Batch 500/537: Loss=0.5717 (C:0.5717, R:0.0105)
Batch 525/537: Loss=0.5971 (C:0.5971, R:0.0105)

============================================================
Epoch 62/300 completed in 21.4s
Train: Loss=0.5727 (C:0.5727, R:0.0105) Ratio=5.16x
Val:   Loss=0.7346 (C:0.7346, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

Epoch 63 Training
----------------------------------------
Batch   0/537: Loss=0.5299 (C:0.5299, R:0.0105)
Batch  25/537: Loss=0.5431 (C:0.5431, R:0.0105)
Batch  50/537: Loss=0.5949 (C:0.5949, R:0.0105)
Batch  75/537: Loss=0.5750 (C:0.5750, R:0.0105)
Batch 100/537: Loss=0.5485 (C:0.5485, R:0.0105)
Batch 125/537: Loss=0.5630 (C:0.5630, R:0.0105)
Batch 150/537: Loss=0.5862 (C:0.5862, R:0.0105)
Batch 175/537: Loss=0.5912 (C:0.5912, R:0.0105)
Batch 200/537: Loss=0.5988 (C:0.5988, R:0.0105)
Batch 225/537: Loss=0.5722 (C:0.5722, R:0.0105)
Batch 250/537: Loss=0.5700 (C:0.5700, R:0.0105)
Batch 275/537: Loss=0.5572 (C:0.5572, R:0.0105)
Batch 300/537: Loss=0.5660 (C:0.5660, R:0.0105)
Batch 325/537: Loss=0.5881 (C:0.5881, R:0.0105)
Batch 350/537: Loss=0.5666 (C:0.5666, R:0.0105)
Batch 375/537: Loss=0.5841 (C:0.5841, R:0.0105)
Batch 400/537: Loss=0.5277 (C:0.5277, R:0.0105)
Batch 425/537: Loss=0.5694 (C:0.5694, R:0.0105)
Batch 450/537: Loss=0.5730 (C:0.5730, R:0.0105)
Batch 475/537: Loss=0.5633 (C:0.5633, R:0.0105)
Batch 500/537: Loss=0.5547 (C:0.5547, R:0.0105)
Batch 525/537: Loss=0.5994 (C:0.5994, R:0.0105)

============================================================
Epoch 63/300 completed in 21.5s
Train: Loss=0.5702 (C:0.5702, R:0.0105) Ratio=5.26x
Val:   Loss=0.7263 (C:0.7263, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.7263)
============================================================

🌍 Updating global dataset at epoch 64
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.313 ± 0.572
    Neg distances: 2.528 ± 1.069
    Separation ratio: 8.08x
    Gap: -4.252
    ✅ Excellent global separation!

Epoch 64 Training
----------------------------------------
Batch   0/537: Loss=0.5656 (C:0.5656, R:0.0105)
Batch  25/537: Loss=0.5494 (C:0.5494, R:0.0105)
Batch  50/537: Loss=0.5907 (C:0.5907, R:0.0105)
Batch  75/537: Loss=0.5610 (C:0.5610, R:0.0105)
Batch 100/537: Loss=0.5620 (C:0.5620, R:0.0105)
Batch 125/537: Loss=0.5720 (C:0.5720, R:0.0105)
Batch 150/537: Loss=0.5680 (C:0.5680, R:0.0105)
Batch 175/537: Loss=0.5958 (C:0.5958, R:0.0105)
Batch 200/537: Loss=0.5558 (C:0.5558, R:0.0105)
Batch 225/537: Loss=0.6006 (C:0.6006, R:0.0105)
Batch 250/537: Loss=0.5853 (C:0.5853, R:0.0105)
Batch 275/537: Loss=0.5769 (C:0.5769, R:0.0105)
Batch 300/537: Loss=0.5830 (C:0.5830, R:0.0105)
Batch 325/537: Loss=0.5996 (C:0.5996, R:0.0105)
Batch 350/537: Loss=0.5754 (C:0.5754, R:0.0105)
Batch 375/537: Loss=0.6288 (C:0.6288, R:0.0105)
Batch 400/537: Loss=0.5520 (C:0.5520, R:0.0105)
Batch 425/537: Loss=0.5450 (C:0.5450, R:0.0105)
Batch 450/537: Loss=0.5563 (C:0.5563, R:0.0105)
Batch 475/537: Loss=0.5845 (C:0.5845, R:0.0105)
Batch 500/537: Loss=0.6184 (C:0.6184, R:0.0105)
Batch 525/537: Loss=0.5600 (C:0.5600, R:0.0105)

============================================================
Epoch 64/300 completed in 27.9s
Train: Loss=0.5722 (C:0.5722, R:0.0105) Ratio=5.15x
Val:   Loss=0.7369 (C:0.7369, R:0.0104) Ratio=3.15x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

Epoch 65 Training
----------------------------------------
Batch   0/537: Loss=0.5727 (C:0.5727, R:0.0105)
Batch  25/537: Loss=0.5633 (C:0.5633, R:0.0105)
Batch  50/537: Loss=0.5907 (C:0.5907, R:0.0105)
Batch  75/537: Loss=0.5772 (C:0.5772, R:0.0105)
Batch 100/537: Loss=0.6028 (C:0.6028, R:0.0105)
Batch 125/537: Loss=0.5792 (C:0.5792, R:0.0105)
Batch 150/537: Loss=0.5969 (C:0.5969, R:0.0105)
Batch 175/537: Loss=0.5585 (C:0.5585, R:0.0105)
Batch 200/537: Loss=0.5690 (C:0.5690, R:0.0105)
Batch 225/537: Loss=0.5439 (C:0.5439, R:0.0105)
Batch 250/537: Loss=0.5628 (C:0.5628, R:0.0105)
Batch 275/537: Loss=0.5549 (C:0.5549, R:0.0105)
Batch 300/537: Loss=0.5616 (C:0.5616, R:0.0105)
Batch 325/537: Loss=0.5832 (C:0.5832, R:0.0105)
Batch 350/537: Loss=0.5523 (C:0.5523, R:0.0105)
Batch 375/537: Loss=0.5830 (C:0.5830, R:0.0105)
Batch 400/537: Loss=0.5518 (C:0.5518, R:0.0105)
Batch 425/537: Loss=0.5655 (C:0.5655, R:0.0105)
Batch 450/537: Loss=0.5710 (C:0.5710, R:0.0106)
Batch 475/537: Loss=0.5991 (C:0.5991, R:0.0105)
Batch 500/537: Loss=0.5561 (C:0.5561, R:0.0105)
Batch 525/537: Loss=0.5762 (C:0.5762, R:0.0105)

============================================================
Epoch 65/300 completed in 21.1s
Train: Loss=0.5723 (C:0.5723, R:0.0105) Ratio=5.23x
Val:   Loss=0.7362 (C:0.7362, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

Epoch 66 Training
----------------------------------------
Batch   0/537: Loss=0.5790 (C:0.5790, R:0.0105)
Batch  25/537: Loss=0.5671 (C:0.5671, R:0.0105)
Batch  50/537: Loss=0.5288 (C:0.5288, R:0.0105)
Batch  75/537: Loss=0.5598 (C:0.5598, R:0.0105)
Batch 100/537: Loss=0.5851 (C:0.5851, R:0.0105)
Batch 125/537: Loss=0.5533 (C:0.5533, R:0.0105)
Batch 150/537: Loss=0.5716 (C:0.5716, R:0.0105)
Batch 175/537: Loss=0.5465 (C:0.5465, R:0.0105)
Batch 200/537: Loss=0.5689 (C:0.5689, R:0.0105)
Batch 225/537: Loss=0.5365 (C:0.5365, R:0.0105)
Batch 250/537: Loss=0.5936 (C:0.5936, R:0.0105)
Batch 275/537: Loss=0.5454 (C:0.5454, R:0.0105)
Batch 300/537: Loss=0.5588 (C:0.5588, R:0.0105)
Batch 325/537: Loss=0.5516 (C:0.5516, R:0.0105)
Batch 350/537: Loss=0.5728 (C:0.5728, R:0.0105)
Batch 375/537: Loss=0.6104 (C:0.6104, R:0.0105)
Batch 400/537: Loss=0.5492 (C:0.5492, R:0.0105)
Batch 425/537: Loss=0.5663 (C:0.5663, R:0.0105)
Batch 450/537: Loss=0.5310 (C:0.5310, R:0.0105)
Batch 475/537: Loss=0.5478 (C:0.5478, R:0.0105)
Batch 500/537: Loss=0.5783 (C:0.5783, R:0.0105)
Batch 525/537: Loss=0.6117 (C:0.6117, R:0.0105)

============================================================
Epoch 66/300 completed in 21.4s
Train: Loss=0.5684 (C:0.5684, R:0.0105) Ratio=5.36x
Val:   Loss=0.7349 (C:0.7349, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 67
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.306 ± 0.574
    Neg distances: 2.581 ± 1.080
    Separation ratio: 8.45x
    Gap: -4.302
    ✅ Excellent global separation!

Epoch 67 Training
----------------------------------------
Batch   0/537: Loss=0.5672 (C:0.5672, R:0.0105)
Batch  25/537: Loss=0.5607 (C:0.5607, R:0.0105)
Batch  50/537: Loss=0.4900 (C:0.4900, R:0.0106)
Batch  75/537: Loss=0.5776 (C:0.5776, R:0.0105)
Batch 100/537: Loss=0.5349 (C:0.5349, R:0.0105)
Batch 125/537: Loss=0.5494 (C:0.5494, R:0.0105)
Batch 150/537: Loss=0.5378 (C:0.5378, R:0.0105)
Batch 175/537: Loss=0.5632 (C:0.5632, R:0.0105)
Batch 200/537: Loss=0.5578 (C:0.5578, R:0.0105)
Batch 225/537: Loss=0.5450 (C:0.5450, R:0.0105)
Batch 250/537: Loss=0.5485 (C:0.5485, R:0.0105)
Batch 275/537: Loss=0.5620 (C:0.5620, R:0.0105)
Batch 300/537: Loss=0.5743 (C:0.5743, R:0.0105)
Batch 325/537: Loss=0.5939 (C:0.5939, R:0.0105)
Batch 350/537: Loss=0.5419 (C:0.5419, R:0.0105)
Batch 375/537: Loss=0.6028 (C:0.6028, R:0.0105)
Batch 400/537: Loss=0.5384 (C:0.5384, R:0.0105)
Batch 425/537: Loss=0.5792 (C:0.5792, R:0.0105)
Batch 450/537: Loss=0.5758 (C:0.5758, R:0.0105)
Batch 475/537: Loss=0.5879 (C:0.5879, R:0.0105)
Batch 500/537: Loss=0.5547 (C:0.5547, R:0.0105)
Batch 525/537: Loss=0.5343 (C:0.5343, R:0.0105)

============================================================
Epoch 67/300 completed in 27.5s
Train: Loss=0.5581 (C:0.5581, R:0.0105) Ratio=5.21x
Val:   Loss=0.7272 (C:0.7272, R:0.0104) Ratio=3.12x
Reconstruction weight: 0.300
No improvement for 4 epochs
============================================================

Epoch 68 Training
----------------------------------------
Batch   0/537: Loss=0.5912 (C:0.5912, R:0.0105)
Batch  25/537: Loss=0.5350 (C:0.5350, R:0.0105)
Batch  50/537: Loss=0.5506 (C:0.5506, R:0.0105)
Batch  75/537: Loss=0.5520 (C:0.5520, R:0.0105)
Batch 100/537: Loss=0.5638 (C:0.5638, R:0.0105)
Batch 125/537: Loss=0.5687 (C:0.5687, R:0.0105)
Batch 150/537: Loss=0.5553 (C:0.5553, R:0.0105)
Batch 175/537: Loss=0.5701 (C:0.5701, R:0.0105)
Batch 200/537: Loss=0.5832 (C:0.5832, R:0.0105)
Batch 225/537: Loss=0.5455 (C:0.5455, R:0.0105)
Batch 250/537: Loss=0.5709 (C:0.5709, R:0.0105)
Batch 275/537: Loss=0.5707 (C:0.5707, R:0.0105)
Batch 300/537: Loss=0.5490 (C:0.5490, R:0.0105)
Batch 325/537: Loss=0.5773 (C:0.5773, R:0.0105)
Batch 350/537: Loss=0.5607 (C:0.5607, R:0.0105)
Batch 375/537: Loss=0.5729 (C:0.5729, R:0.0105)
Batch 400/537: Loss=0.5667 (C:0.5667, R:0.0105)
Batch 425/537: Loss=0.5225 (C:0.5225, R:0.0105)
Batch 450/537: Loss=0.5675 (C:0.5675, R:0.0105)
Batch 475/537: Loss=0.6024 (C:0.6024, R:0.0105)
Batch 500/537: Loss=0.5892 (C:0.5892, R:0.0105)
Batch 525/537: Loss=0.5595 (C:0.5595, R:0.0105)

============================================================
Epoch 68/300 completed in 21.7s
Train: Loss=0.5558 (C:0.5558, R:0.0105) Ratio=5.26x
Val:   Loss=0.7315 (C:0.7315, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.300
No improvement for 5 epochs
============================================================

Epoch 69 Training
----------------------------------------
Batch   0/537: Loss=0.5421 (C:0.5421, R:0.0105)
Batch  25/537: Loss=0.5791 (C:0.5791, R:0.0106)
Batch  50/537: Loss=0.5719 (C:0.5719, R:0.0105)
Batch  75/537: Loss=0.5422 (C:0.5422, R:0.0105)
Batch 100/537: Loss=0.5575 (C:0.5575, R:0.0105)
Batch 125/537: Loss=0.5589 (C:0.5589, R:0.0105)
Batch 150/537: Loss=0.5297 (C:0.5297, R:0.0105)
Batch 175/537: Loss=0.5282 (C:0.5282, R:0.0105)
Batch 200/537: Loss=0.5471 (C:0.5471, R:0.0105)
Batch 225/537: Loss=0.5492 (C:0.5492, R:0.0105)
Batch 250/537: Loss=0.5502 (C:0.5502, R:0.0105)
Batch 275/537: Loss=0.5849 (C:0.5849, R:0.0105)
Batch 300/537: Loss=0.5744 (C:0.5744, R:0.0105)
Batch 325/537: Loss=0.5457 (C:0.5457, R:0.0105)
Batch 350/537: Loss=0.5518 (C:0.5518, R:0.0105)
Batch 375/537: Loss=0.5447 (C:0.5447, R:0.0105)
Batch 400/537: Loss=0.5559 (C:0.5559, R:0.0105)
Batch 425/537: Loss=0.5627 (C:0.5627, R:0.0105)
Batch 450/537: Loss=0.5873 (C:0.5873, R:0.0105)
Batch 475/537: Loss=0.5772 (C:0.5772, R:0.0105)
Batch 500/537: Loss=0.5528 (C:0.5528, R:0.0105)
Batch 525/537: Loss=0.5408 (C:0.5408, R:0.0105)

============================================================
Epoch 69/300 completed in 21.9s
Train: Loss=0.5542 (C:0.5542, R:0.0105) Ratio=5.28x
Val:   Loss=0.7319 (C:0.7319, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.300
No improvement for 6 epochs
============================================================

🌍 Updating global dataset at epoch 70
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.302 ± 0.562
    Neg distances: 2.563 ± 1.066
    Separation ratio: 8.49x
    Gap: -4.267
    ✅ Excellent global separation!

Epoch 70 Training
----------------------------------------
Batch   0/537: Loss=0.5401 (C:0.5401, R:0.0105)
Batch  25/537: Loss=0.5403 (C:0.5403, R:0.0105)
Batch  50/537: Loss=0.5389 (C:0.5389, R:0.0105)
Batch  75/537: Loss=0.5479 (C:0.5479, R:0.0105)
Batch 100/537: Loss=0.5500 (C:0.5500, R:0.0105)
Batch 125/537: Loss=0.5311 (C:0.5311, R:0.0105)
Batch 150/537: Loss=0.5577 (C:0.5577, R:0.0105)
Batch 175/537: Loss=0.5422 (C:0.5422, R:0.0105)
Batch 200/537: Loss=0.5788 (C:0.5788, R:0.0105)
Batch 225/537: Loss=0.5475 (C:0.5475, R:0.0105)
Batch 250/537: Loss=0.5391 (C:0.5391, R:0.0105)
Batch 275/537: Loss=0.5597 (C:0.5597, R:0.0105)
Batch 300/537: Loss=0.5646 (C:0.5646, R:0.0105)
Batch 325/537: Loss=0.5451 (C:0.5451, R:0.0105)
Batch 350/537: Loss=0.5136 (C:0.5136, R:0.0105)
Batch 375/537: Loss=0.5560 (C:0.5560, R:0.0105)
Batch 400/537: Loss=0.5686 (C:0.5686, R:0.0105)
Batch 425/537: Loss=0.5192 (C:0.5192, R:0.0105)
Batch 450/537: Loss=0.5419 (C:0.5419, R:0.0105)
Batch 475/537: Loss=0.5394 (C:0.5394, R:0.0105)
Batch 500/537: Loss=0.5820 (C:0.5820, R:0.0106)
Batch 525/537: Loss=0.5592 (C:0.5592, R:0.0106)

============================================================
Epoch 70/300 completed in 27.4s
Train: Loss=0.5493 (C:0.5493, R:0.0105) Ratio=5.32x
Val:   Loss=0.7111 (C:0.7111, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.7111)
============================================================

Epoch 71 Training
----------------------------------------
Batch   0/537: Loss=0.5650 (C:0.5650, R:0.0105)
Batch  25/537: Loss=0.5322 (C:0.5322, R:0.0105)
Batch  50/537: Loss=0.5877 (C:0.5877, R:0.0105)
Batch  75/537: Loss=0.5295 (C:0.5295, R:0.0105)
Batch 100/537: Loss=0.5468 (C:0.5468, R:0.0105)
Batch 125/537: Loss=0.5930 (C:0.5930, R:0.0105)
Batch 150/537: Loss=0.5172 (C:0.5172, R:0.0105)
Batch 175/537: Loss=0.5159 (C:0.5159, R:0.0105)
Batch 200/537: Loss=0.5211 (C:0.5211, R:0.0105)
Batch 225/537: Loss=0.5805 (C:0.5805, R:0.0106)
Batch 250/537: Loss=0.5389 (C:0.5389, R:0.0106)
Batch 275/537: Loss=0.5748 (C:0.5748, R:0.0105)
Batch 300/537: Loss=0.5609 (C:0.5609, R:0.0105)
Batch 325/537: Loss=0.6015 (C:0.6015, R:0.0105)
Batch 350/537: Loss=0.5795 (C:0.5795, R:0.0105)
Batch 375/537: Loss=0.5456 (C:0.5456, R:0.0105)
Batch 400/537: Loss=0.5781 (C:0.5781, R:0.0105)
Batch 425/537: Loss=0.5318 (C:0.5318, R:0.0105)
Batch 450/537: Loss=0.5540 (C:0.5540, R:0.0105)
Batch 475/537: Loss=0.5461 (C:0.5461, R:0.0105)
Batch 500/537: Loss=0.5343 (C:0.5343, R:0.0105)
Batch 525/537: Loss=0.5293 (C:0.5293, R:0.0105)

============================================================
Epoch 71/300 completed in 21.2s
Train: Loss=0.5480 (C:0.5480, R:0.0105) Ratio=5.27x
Val:   Loss=0.7324 (C:0.7324, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

Epoch 72 Training
----------------------------------------
Batch   0/537: Loss=0.5205 (C:0.5205, R:0.0105)
Batch  25/537: Loss=0.5572 (C:0.5572, R:0.0105)
Batch  50/537: Loss=0.5725 (C:0.5725, R:0.0105)
Batch  75/537: Loss=0.5096 (C:0.5096, R:0.0105)
Batch 100/537: Loss=0.5533 (C:0.5533, R:0.0105)
Batch 125/537: Loss=0.5370 (C:0.5370, R:0.0105)
Batch 150/537: Loss=0.5299 (C:0.5299, R:0.0105)
Batch 175/537: Loss=0.5430 (C:0.5430, R:0.0105)
Batch 200/537: Loss=0.5822 (C:0.5822, R:0.0105)
Batch 225/537: Loss=0.5439 (C:0.5439, R:0.0105)
Batch 250/537: Loss=0.5599 (C:0.5599, R:0.0105)
Batch 275/537: Loss=0.5667 (C:0.5667, R:0.0105)
Batch 300/537: Loss=0.5469 (C:0.5469, R:0.0105)
Batch 325/537: Loss=0.5662 (C:0.5662, R:0.0105)
Batch 350/537: Loss=0.5317 (C:0.5317, R:0.0105)
Batch 375/537: Loss=0.4999 (C:0.4999, R:0.0105)
Batch 400/537: Loss=0.5594 (C:0.5594, R:0.0105)
Batch 425/537: Loss=0.5767 (C:0.5767, R:0.0105)
Batch 450/537: Loss=0.5691 (C:0.5691, R:0.0105)
Batch 475/537: Loss=0.5330 (C:0.5330, R:0.0105)
Batch 500/537: Loss=0.5505 (C:0.5505, R:0.0105)
Batch 525/537: Loss=0.5913 (C:0.5913, R:0.0105)

============================================================
Epoch 72/300 completed in 21.8s
Train: Loss=0.5457 (C:0.5457, R:0.0105) Ratio=5.27x
Val:   Loss=0.7217 (C:0.7217, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 73
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.308 ± 0.589
    Neg distances: 2.593 ± 1.088
    Separation ratio: 8.43x
    Gap: -4.263
    ✅ Excellent global separation!

Epoch 73 Training
----------------------------------------
Batch   0/537: Loss=0.5273 (C:0.5273, R:0.0105)
Batch  25/537: Loss=0.5672 (C:0.5672, R:0.0105)
Batch  50/537: Loss=0.5446 (C:0.5446, R:0.0105)
Batch  75/537: Loss=0.5066 (C:0.5066, R:0.0105)
Batch 100/537: Loss=0.4945 (C:0.4945, R:0.0105)
Batch 125/537: Loss=0.4993 (C:0.4993, R:0.0105)
Batch 150/537: Loss=0.5115 (C:0.5115, R:0.0106)
Batch 175/537: Loss=0.5528 (C:0.5528, R:0.0106)
Batch 200/537: Loss=0.5543 (C:0.5543, R:0.0105)
Batch 225/537: Loss=0.5742 (C:0.5742, R:0.0105)
Batch 250/537: Loss=0.5290 (C:0.5290, R:0.0105)
Batch 275/537: Loss=0.5263 (C:0.5263, R:0.0105)
Batch 300/537: Loss=0.5621 (C:0.5621, R:0.0105)
Batch 325/537: Loss=0.5727 (C:0.5727, R:0.0105)
Batch 350/537: Loss=0.5530 (C:0.5530, R:0.0105)
Batch 375/537: Loss=0.5538 (C:0.5538, R:0.0105)
Batch 400/537: Loss=0.5642 (C:0.5642, R:0.0105)
Batch 425/537: Loss=0.5592 (C:0.5592, R:0.0105)
Batch 450/537: Loss=0.5633 (C:0.5633, R:0.0105)
Batch 475/537: Loss=0.5313 (C:0.5313, R:0.0105)
Batch 500/537: Loss=0.5469 (C:0.5469, R:0.0105)
Batch 525/537: Loss=0.5684 (C:0.5684, R:0.0105)

============================================================
Epoch 73/300 completed in 28.2s
Train: Loss=0.5505 (C:0.5505, R:0.0105) Ratio=5.51x
Val:   Loss=0.7276 (C:0.7276, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

Epoch 74 Training
----------------------------------------
Batch   0/537: Loss=0.5774 (C:0.5774, R:0.0105)
Batch  25/537: Loss=0.6127 (C:0.6127, R:0.0105)
Batch  50/537: Loss=0.5555 (C:0.5555, R:0.0105)
Batch  75/537: Loss=0.5025 (C:0.5025, R:0.0105)
Batch 100/537: Loss=0.5259 (C:0.5259, R:0.0105)
Batch 125/537: Loss=0.5787 (C:0.5787, R:0.0105)
Batch 150/537: Loss=0.5647 (C:0.5647, R:0.0105)
Batch 175/537: Loss=0.5263 (C:0.5263, R:0.0105)
Batch 200/537: Loss=0.5182 (C:0.5182, R:0.0105)
Batch 225/537: Loss=0.5571 (C:0.5571, R:0.0105)
Batch 250/537: Loss=0.5391 (C:0.5391, R:0.0105)
Batch 275/537: Loss=0.5338 (C:0.5338, R:0.0105)
Batch 300/537: Loss=0.5665 (C:0.5665, R:0.0105)
Batch 325/537: Loss=0.5507 (C:0.5507, R:0.0105)
Batch 350/537: Loss=0.5543 (C:0.5543, R:0.0105)
Batch 375/537: Loss=0.5073 (C:0.5073, R:0.0106)
Batch 400/537: Loss=0.5330 (C:0.5330, R:0.0105)
Batch 425/537: Loss=0.5475 (C:0.5475, R:0.0106)
Batch 450/537: Loss=0.5574 (C:0.5574, R:0.0105)
Batch 475/537: Loss=0.5572 (C:0.5572, R:0.0105)
Batch 500/537: Loss=0.5390 (C:0.5390, R:0.0105)
Batch 525/537: Loss=0.5502 (C:0.5502, R:0.0105)

============================================================
Epoch 74/300 completed in 21.8s
Train: Loss=0.5499 (C:0.5499, R:0.0105) Ratio=5.44x
Val:   Loss=0.7236 (C:0.7236, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.300
No improvement for 4 epochs
============================================================

Epoch 75 Training
----------------------------------------
Batch   0/537: Loss=0.5370 (C:0.5370, R:0.0105)
Batch  25/537: Loss=0.5008 (C:0.5008, R:0.0105)
Batch  50/537: Loss=0.5460 (C:0.5460, R:0.0105)
Batch  75/537: Loss=0.5583 (C:0.5583, R:0.0105)
Batch 100/537: Loss=0.5467 (C:0.5467, R:0.0105)
Batch 125/537: Loss=0.5478 (C:0.5478, R:0.0105)
Batch 150/537: Loss=0.5403 (C:0.5403, R:0.0105)
Batch 175/537: Loss=0.5416 (C:0.5416, R:0.0105)
Batch 200/537: Loss=0.5597 (C:0.5597, R:0.0105)
Batch 225/537: Loss=0.5111 (C:0.5111, R:0.0106)
Batch 250/537: Loss=0.5499 (C:0.5499, R:0.0105)
Batch 275/537: Loss=0.5798 (C:0.5798, R:0.0105)
Batch 300/537: Loss=0.5155 (C:0.5155, R:0.0105)
Batch 325/537: Loss=0.6061 (C:0.6061, R:0.0105)
Batch 350/537: Loss=0.5723 (C:0.5723, R:0.0105)
Batch 375/537: Loss=0.5826 (C:0.5826, R:0.0105)
Batch 400/537: Loss=0.5654 (C:0.5654, R:0.0105)
Batch 425/537: Loss=0.5283 (C:0.5283, R:0.0105)
Batch 450/537: Loss=0.5659 (C:0.5659, R:0.0105)
Batch 475/537: Loss=0.5488 (C:0.5488, R:0.0106)
Batch 500/537: Loss=0.5279 (C:0.5279, R:0.0105)
Batch 525/537: Loss=0.5485 (C:0.5485, R:0.0106)

============================================================
Epoch 75/300 completed in 21.5s
Train: Loss=0.5473 (C:0.5473, R:0.0105) Ratio=5.46x
Val:   Loss=0.7239 (C:0.7239, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.300
No improvement for 5 epochs
============================================================

🌍 Updating global dataset at epoch 76
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.291 ± 0.576
    Neg distances: 2.627 ± 1.087
    Separation ratio: 9.04x
    Gap: -4.379
    ✅ Excellent global separation!

Epoch 76 Training
----------------------------------------
Batch   0/537: Loss=0.5350 (C:0.5350, R:0.0105)
Batch  25/537: Loss=0.5134 (C:0.5134, R:0.0106)
Batch  50/537: Loss=0.5661 (C:0.5661, R:0.0106)
Batch  75/537: Loss=0.5128 (C:0.5128, R:0.0105)
Batch 100/537: Loss=0.5392 (C:0.5392, R:0.0105)
Batch 125/537: Loss=0.5170 (C:0.5170, R:0.0105)
Batch 150/537: Loss=0.5388 (C:0.5388, R:0.0105)
Batch 175/537: Loss=0.5326 (C:0.5326, R:0.0105)
Batch 200/537: Loss=0.5270 (C:0.5270, R:0.0105)
Batch 225/537: Loss=0.4968 (C:0.4968, R:0.0105)
Batch 250/537: Loss=0.5238 (C:0.5238, R:0.0105)
Batch 275/537: Loss=0.5442 (C:0.5442, R:0.0105)
Batch 300/537: Loss=0.5124 (C:0.5124, R:0.0105)
Batch 325/537: Loss=0.5297 (C:0.5297, R:0.0105)
Batch 350/537: Loss=0.5244 (C:0.5244, R:0.0105)
Batch 375/537: Loss=0.5114 (C:0.5114, R:0.0105)
Batch 400/537: Loss=0.5369 (C:0.5369, R:0.0105)
Batch 425/537: Loss=0.5401 (C:0.5401, R:0.0105)
Batch 450/537: Loss=0.5144 (C:0.5144, R:0.0105)
Batch 475/537: Loss=0.5444 (C:0.5444, R:0.0105)
Batch 500/537: Loss=0.5727 (C:0.5727, R:0.0105)
Batch 525/537: Loss=0.5248 (C:0.5248, R:0.0105)

============================================================
Epoch 76/300 completed in 27.5s
Train: Loss=0.5299 (C:0.5299, R:0.0105) Ratio=5.45x
Val:   Loss=0.7206 (C:0.7206, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 6 epochs
============================================================

Epoch 77 Training
----------------------------------------
Batch   0/537: Loss=0.4912 (C:0.4912, R:0.0106)
Batch  25/537: Loss=0.5148 (C:0.5148, R:0.0105)
Batch  50/537: Loss=0.4884 (C:0.4884, R:0.0105)
Batch  75/537: Loss=0.4876 (C:0.4876, R:0.0106)
Batch 100/537: Loss=0.5429 (C:0.5429, R:0.0105)
Batch 125/537: Loss=0.5161 (C:0.5161, R:0.0105)
Batch 150/537: Loss=0.5069 (C:0.5069, R:0.0105)
Batch 175/537: Loss=0.5429 (C:0.5429, R:0.0105)
Batch 200/537: Loss=0.5187 (C:0.5187, R:0.0105)
Batch 225/537: Loss=0.5052 (C:0.5052, R:0.0105)
Batch 250/537: Loss=0.5492 (C:0.5492, R:0.0105)
Batch 275/537: Loss=0.5272 (C:0.5272, R:0.0105)
Batch 300/537: Loss=0.5629 (C:0.5629, R:0.0105)
Batch 325/537: Loss=0.5300 (C:0.5300, R:0.0105)
Batch 350/537: Loss=0.5177 (C:0.5177, R:0.0105)
Batch 375/537: Loss=0.5540 (C:0.5540, R:0.0105)
Batch 400/537: Loss=0.5178 (C:0.5178, R:0.0105)
Batch 425/537: Loss=0.5630 (C:0.5630, R:0.0105)
Batch 450/537: Loss=0.5642 (C:0.5642, R:0.0105)
Batch 475/537: Loss=0.5060 (C:0.5060, R:0.0105)
Batch 500/537: Loss=0.5953 (C:0.5953, R:0.0105)
Batch 525/537: Loss=0.5223 (C:0.5223, R:0.0105)

============================================================
Epoch 77/300 completed in 21.8s
Train: Loss=0.5297 (C:0.5297, R:0.0105) Ratio=5.51x
Val:   Loss=0.7007 (C:0.7007, R:0.0104) Ratio=3.12x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.7007)
============================================================

Epoch 78 Training
----------------------------------------
Batch   0/537: Loss=0.5061 (C:0.5061, R:0.0105)
Batch  25/537: Loss=0.5489 (C:0.5489, R:0.0105)
Batch  50/537: Loss=0.5305 (C:0.5305, R:0.0105)
Batch  75/537: Loss=0.4954 (C:0.4954, R:0.0105)
Batch 100/537: Loss=0.5128 (C:0.5128, R:0.0105)
Batch 125/537: Loss=0.5449 (C:0.5449, R:0.0105)
Batch 150/537: Loss=0.5362 (C:0.5362, R:0.0105)
Batch 175/537: Loss=0.5310 (C:0.5310, R:0.0105)
Batch 200/537: Loss=0.5011 (C:0.5011, R:0.0105)
Batch 225/537: Loss=0.5267 (C:0.5267, R:0.0105)
Batch 250/537: Loss=0.5327 (C:0.5327, R:0.0105)
Batch 275/537: Loss=0.5407 (C:0.5407, R:0.0105)
Batch 300/537: Loss=0.5473 (C:0.5473, R:0.0105)
Batch 325/537: Loss=0.5127 (C:0.5127, R:0.0105)
Batch 350/537: Loss=0.5622 (C:0.5622, R:0.0105)
Batch 375/537: Loss=0.5464 (C:0.5464, R:0.0105)
Batch 400/537: Loss=0.5127 (C:0.5127, R:0.0105)
Batch 425/537: Loss=0.5180 (C:0.5180, R:0.0105)
Batch 450/537: Loss=0.5104 (C:0.5104, R:0.0106)
Batch 475/537: Loss=0.5288 (C:0.5288, R:0.0105)
Batch 500/537: Loss=0.5543 (C:0.5543, R:0.0105)
Batch 525/537: Loss=0.5144 (C:0.5144, R:0.0105)

============================================================
Epoch 78/300 completed in 21.3s
Train: Loss=0.5277 (C:0.5277, R:0.0105) Ratio=5.56x
Val:   Loss=0.7085 (C:0.7085, R:0.0104) Ratio=3.13x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 79
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.279 ± 0.546
    Neg distances: 2.613 ± 1.074
    Separation ratio: 9.37x
    Gap: -4.264
    ✅ Excellent global separation!

Epoch 79 Training
----------------------------------------
Batch   0/537: Loss=0.5169 (C:0.5169, R:0.0105)
Batch  25/537: Loss=0.5021 (C:0.5021, R:0.0105)
Batch  50/537: Loss=0.4776 (C:0.4776, R:0.0105)
Batch  75/537: Loss=0.4978 (C:0.4978, R:0.0105)
Batch 100/537: Loss=0.5429 (C:0.5429, R:0.0105)
Batch 125/537: Loss=0.4986 (C:0.4986, R:0.0105)
Batch 150/537: Loss=0.5485 (C:0.5485, R:0.0105)
Batch 175/537: Loss=0.5202 (C:0.5202, R:0.0105)
Batch 200/537: Loss=0.5118 (C:0.5118, R:0.0105)
Batch 225/537: Loss=0.4984 (C:0.4984, R:0.0105)
Batch 250/537: Loss=0.4895 (C:0.4895, R:0.0105)
Batch 275/537: Loss=0.4970 (C:0.4970, R:0.0105)
Batch 300/537: Loss=0.5223 (C:0.5223, R:0.0105)
Batch 325/537: Loss=0.5420 (C:0.5420, R:0.0105)
Batch 350/537: Loss=0.4766 (C:0.4766, R:0.0105)
Batch 375/537: Loss=0.5416 (C:0.5416, R:0.0105)
Batch 400/537: Loss=0.5361 (C:0.5361, R:0.0105)
Batch 425/537: Loss=0.5013 (C:0.5013, R:0.0105)
Batch 450/537: Loss=0.5033 (C:0.5033, R:0.0105)
Batch 475/537: Loss=0.5095 (C:0.5095, R:0.0105)
Batch 500/537: Loss=0.5407 (C:0.5407, R:0.0105)
Batch 525/537: Loss=0.5376 (C:0.5376, R:0.0105)

============================================================
Epoch 79/300 completed in 27.7s
Train: Loss=0.5191 (C:0.5191, R:0.0105) Ratio=5.55x
Val:   Loss=0.6936 (C:0.6936, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.6936)
============================================================

Epoch 80 Training
----------------------------------------
Batch   0/537: Loss=0.5000 (C:0.5000, R:0.0105)
Batch  25/537: Loss=0.5039 (C:0.5039, R:0.0105)
Batch  50/537: Loss=0.5169 (C:0.5169, R:0.0105)
Batch  75/537: Loss=0.5243 (C:0.5243, R:0.0105)
Batch 100/537: Loss=0.5361 (C:0.5361, R:0.0105)
Batch 125/537: Loss=0.5345 (C:0.5345, R:0.0105)
Batch 150/537: Loss=0.5425 (C:0.5425, R:0.0105)
Batch 175/537: Loss=0.5260 (C:0.5260, R:0.0105)
Batch 200/537: Loss=0.5210 (C:0.5210, R:0.0105)
Batch 225/537: Loss=0.5093 (C:0.5093, R:0.0105)
Batch 250/537: Loss=0.5053 (C:0.5053, R:0.0105)
Batch 275/537: Loss=0.4767 (C:0.4767, R:0.0105)
Batch 300/537: Loss=0.5119 (C:0.5119, R:0.0105)
Batch 325/537: Loss=0.5210 (C:0.5210, R:0.0105)
Batch 350/537: Loss=0.5510 (C:0.5510, R:0.0105)
Batch 375/537: Loss=0.5112 (C:0.5112, R:0.0105)
Batch 400/537: Loss=0.5443 (C:0.5443, R:0.0105)
Batch 425/537: Loss=0.5255 (C:0.5255, R:0.0105)
Batch 450/537: Loss=0.5372 (C:0.5372, R:0.0105)
Batch 475/537: Loss=0.4813 (C:0.4813, R:0.0106)
Batch 500/537: Loss=0.5675 (C:0.5675, R:0.0105)
Batch 525/537: Loss=0.5122 (C:0.5122, R:0.0105)

============================================================
Epoch 80/300 completed in 21.4s
Train: Loss=0.5158 (C:0.5158, R:0.0105) Ratio=5.53x
Val:   Loss=0.6999 (C:0.6999, R:0.0104) Ratio=3.12x
Reconstruction weight: 0.300
No improvement for 1 epochs
Checkpoint saved at epoch 80
============================================================

Epoch 81 Training
----------------------------------------
Batch   0/537: Loss=0.5042 (C:0.5042, R:0.0105)
Batch  25/537: Loss=0.5205 (C:0.5205, R:0.0105)
Batch  50/537: Loss=0.5183 (C:0.5183, R:0.0105)
Batch  75/537: Loss=0.5302 (C:0.5302, R:0.0105)
Batch 100/537: Loss=0.5045 (C:0.5045, R:0.0105)
Batch 125/537: Loss=0.4895 (C:0.4895, R:0.0105)
Batch 150/537: Loss=0.5128 (C:0.5128, R:0.0105)
Batch 175/537: Loss=0.5090 (C:0.5090, R:0.0105)
Batch 200/537: Loss=0.4881 (C:0.4881, R:0.0105)
Batch 225/537: Loss=0.5437 (C:0.5437, R:0.0105)
Batch 250/537: Loss=0.5050 (C:0.5050, R:0.0106)
Batch 275/537: Loss=0.5157 (C:0.5157, R:0.0106)
Batch 300/537: Loss=0.5918 (C:0.5918, R:0.0105)
Batch 325/537: Loss=0.4819 (C:0.4819, R:0.0105)
Batch 350/537: Loss=0.5189 (C:0.5189, R:0.0105)
Batch 375/537: Loss=0.5149 (C:0.5149, R:0.0105)
Batch 400/537: Loss=0.5017 (C:0.5017, R:0.0105)
Batch 425/537: Loss=0.5135 (C:0.5135, R:0.0105)
Batch 450/537: Loss=0.5175 (C:0.5175, R:0.0105)
Batch 475/537: Loss=0.5487 (C:0.5487, R:0.0105)
Batch 500/537: Loss=0.5102 (C:0.5102, R:0.0105)
Batch 525/537: Loss=0.4873 (C:0.4873, R:0.0105)

============================================================
Epoch 81/300 completed in 21.5s
Train: Loss=0.5142 (C:0.5142, R:0.0105) Ratio=5.61x
Val:   Loss=0.7136 (C:0.7136, R:0.0104) Ratio=3.12x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 82
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.282 ± 0.556
    Neg distances: 2.615 ± 1.076
    Separation ratio: 9.26x
    Gap: -4.294
    ✅ Excellent global separation!

Epoch 82 Training
----------------------------------------
Batch   0/537: Loss=0.5036 (C:0.5036, R:0.0105)
Batch  25/537: Loss=0.5027 (C:0.5027, R:0.0105)
Batch  50/537: Loss=0.5181 (C:0.5181, R:0.0105)
Batch  75/537: Loss=0.5274 (C:0.5274, R:0.0105)
Batch 100/537: Loss=0.5513 (C:0.5513, R:0.0105)
Batch 125/537: Loss=0.4773 (C:0.4773, R:0.0105)
Batch 150/537: Loss=0.5195 (C:0.5195, R:0.0105)
Batch 175/537: Loss=0.5082 (C:0.5082, R:0.0105)
Batch 200/537: Loss=0.5110 (C:0.5110, R:0.0105)
Batch 225/537: Loss=0.4671 (C:0.4671, R:0.0105)
Batch 250/537: Loss=0.5034 (C:0.5034, R:0.0105)
Batch 275/537: Loss=0.5142 (C:0.5142, R:0.0105)
Batch 300/537: Loss=0.4891 (C:0.4891, R:0.0105)
Batch 325/537: Loss=0.4948 (C:0.4948, R:0.0105)
Batch 350/537: Loss=0.5370 (C:0.5370, R:0.0106)
Batch 375/537: Loss=0.5001 (C:0.5001, R:0.0105)
Batch 400/537: Loss=0.5438 (C:0.5438, R:0.0105)
Batch 425/537: Loss=0.5025 (C:0.5025, R:0.0105)
Batch 450/537: Loss=0.5334 (C:0.5334, R:0.0105)
Batch 475/537: Loss=0.4992 (C:0.4992, R:0.0105)
Batch 500/537: Loss=0.5324 (C:0.5324, R:0.0105)
Batch 525/537: Loss=0.5653 (C:0.5653, R:0.0105)

============================================================
Epoch 82/300 completed in 27.5s
Train: Loss=0.5166 (C:0.5166, R:0.0105) Ratio=5.62x
Val:   Loss=0.6923 (C:0.6923, R:0.0104) Ratio=3.14x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 0.6923)
============================================================

Epoch 83 Training
----------------------------------------
Batch   0/537: Loss=0.5266 (C:0.5266, R:0.0105)
Batch  25/537: Loss=0.4841 (C:0.4841, R:0.0105)
Batch  50/537: Loss=0.5291 (C:0.5291, R:0.0105)
Batch  75/537: Loss=0.5617 (C:0.5617, R:0.0105)
Batch 100/537: Loss=0.4979 (C:0.4979, R:0.0105)
Batch 125/537: Loss=0.5169 (C:0.5169, R:0.0105)
Batch 150/537: Loss=0.5339 (C:0.5339, R:0.0105)
Batch 175/537: Loss=0.4988 (C:0.4988, R:0.0105)
Batch 200/537: Loss=0.5504 (C:0.5504, R:0.0105)
Batch 225/537: Loss=0.5185 (C:0.5185, R:0.0105)
Batch 250/537: Loss=0.4973 (C:0.4973, R:0.0105)
Batch 275/537: Loss=0.5197 (C:0.5197, R:0.0105)
Batch 300/537: Loss=0.4890 (C:0.4890, R:0.0105)
Batch 325/537: Loss=0.4872 (C:0.4872, R:0.0105)
Batch 350/537: Loss=0.5017 (C:0.5017, R:0.0105)
Batch 375/537: Loss=0.5401 (C:0.5401, R:0.0105)
Batch 400/537: Loss=0.4836 (C:0.4836, R:0.0105)
Batch 425/537: Loss=0.5061 (C:0.5061, R:0.0105)
Batch 450/537: Loss=0.4972 (C:0.4972, R:0.0105)
Batch 475/537: Loss=0.5008 (C:0.5008, R:0.0105)
Batch 500/537: Loss=0.5198 (C:0.5198, R:0.0105)
Batch 525/537: Loss=0.5146 (C:0.5146, R:0.0105)

============================================================
Epoch 83/300 completed in 21.5s
Train: Loss=0.5163 (C:0.5163, R:0.0105) Ratio=5.58x
Val:   Loss=0.6940 (C:0.6940, R:0.0104) Ratio=3.13x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

Epoch 84 Training
----------------------------------------
Batch   0/537: Loss=0.4921 (C:0.4921, R:0.0105)
Batch  25/537: Loss=0.5180 (C:0.5180, R:0.0105)
Batch  50/537: Loss=0.4880 (C:0.4880, R:0.0105)
Batch  75/537: Loss=0.4923 (C:0.4923, R:0.0105)
Batch 100/537: Loss=0.5111 (C:0.5111, R:0.0105)
Batch 125/537: Loss=0.5256 (C:0.5256, R:0.0105)
Batch 150/537: Loss=0.5360 (C:0.5360, R:0.0105)
Batch 175/537: Loss=0.4950 (C:0.4950, R:0.0105)
Batch 200/537: Loss=0.4943 (C:0.4943, R:0.0105)
Batch 225/537: Loss=0.5360 (C:0.5360, R:0.0105)
Batch 250/537: Loss=0.5260 (C:0.5260, R:0.0105)
Batch 275/537: Loss=0.5262 (C:0.5262, R:0.0105)
Batch 300/537: Loss=0.4874 (C:0.4874, R:0.0105)
Batch 325/537: Loss=0.5193 (C:0.5193, R:0.0105)
Batch 350/537: Loss=0.5328 (C:0.5328, R:0.0106)
Batch 375/537: Loss=0.5216 (C:0.5216, R:0.0105)
Batch 400/537: Loss=0.5314 (C:0.5314, R:0.0105)
Batch 425/537: Loss=0.5264 (C:0.5264, R:0.0105)
Batch 450/537: Loss=0.5417 (C:0.5417, R:0.0105)
Batch 475/537: Loss=0.5056 (C:0.5056, R:0.0105)
Batch 500/537: Loss=0.5026 (C:0.5026, R:0.0105)
Batch 525/537: Loss=0.4760 (C:0.4760, R:0.0105)

============================================================
Epoch 84/300 completed in 21.8s
Train: Loss=0.5141 (C:0.5141, R:0.0105) Ratio=5.65x
Val:   Loss=0.7077 (C:0.7077, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 85
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.279 ± 0.566
    Neg distances: 2.652 ± 1.086
    Separation ratio: 9.52x
    Gap: -4.425
    ✅ Excellent global separation!

Epoch 85 Training
----------------------------------------
Batch   0/537: Loss=0.5014 (C:0.5014, R:0.0105)
Batch  25/537: Loss=0.5147 (C:0.5147, R:0.0105)
Batch  50/537: Loss=0.5034 (C:0.5034, R:0.0105)
Batch  75/537: Loss=0.4865 (C:0.4865, R:0.0105)
Batch 100/537: Loss=0.5170 (C:0.5170, R:0.0105)
Batch 125/537: Loss=0.4747 (C:0.4747, R:0.0105)
Batch 150/537: Loss=0.5247 (C:0.5247, R:0.0105)
Batch 175/537: Loss=0.4811 (C:0.4811, R:0.0105)
Batch 200/537: Loss=0.5456 (C:0.5456, R:0.0105)
Batch 225/537: Loss=0.5402 (C:0.5402, R:0.0105)
Batch 250/537: Loss=0.4700 (C:0.4700, R:0.0105)
Batch 275/537: Loss=0.5333 (C:0.5333, R:0.0105)
Batch 300/537: Loss=0.5038 (C:0.5038, R:0.0105)
Batch 325/537: Loss=0.4981 (C:0.4981, R:0.0105)
Batch 350/537: Loss=0.5253 (C:0.5253, R:0.0105)
Batch 375/537: Loss=0.4852 (C:0.4852, R:0.0105)
Batch 400/537: Loss=0.5269 (C:0.5269, R:0.0105)
Batch 425/537: Loss=0.4918 (C:0.4918, R:0.0105)
Batch 450/537: Loss=0.5231 (C:0.5231, R:0.0105)
Batch 475/537: Loss=0.5334 (C:0.5334, R:0.0106)
Batch 500/537: Loss=0.5224 (C:0.5224, R:0.0105)
Batch 525/537: Loss=0.5476 (C:0.5476, R:0.0105)

============================================================
Epoch 85/300 completed in 27.5s
Train: Loss=0.5071 (C:0.5071, R:0.0105) Ratio=5.58x
Val:   Loss=0.7031 (C:0.7031, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

Epoch 86 Training
----------------------------------------
Batch   0/537: Loss=0.5241 (C:0.5241, R:0.0105)
Batch  25/537: Loss=0.4647 (C:0.4647, R:0.0105)
Batch  50/537: Loss=0.4832 (C:0.4832, R:0.0105)
Batch  75/537: Loss=0.4827 (C:0.4827, R:0.0105)
Batch 100/537: Loss=0.5167 (C:0.5167, R:0.0105)
Batch 125/537: Loss=0.4701 (C:0.4701, R:0.0105)
Batch 150/537: Loss=0.5087 (C:0.5087, R:0.0105)
Batch 175/537: Loss=0.4713 (C:0.4713, R:0.0105)
Batch 200/537: Loss=0.4987 (C:0.4987, R:0.0105)
Batch 225/537: Loss=0.5365 (C:0.5365, R:0.0105)
Batch 250/537: Loss=0.5417 (C:0.5417, R:0.0105)
Batch 275/537: Loss=0.5062 (C:0.5062, R:0.0105)
Batch 300/537: Loss=0.5126 (C:0.5126, R:0.0106)
Batch 325/537: Loss=0.5423 (C:0.5423, R:0.0105)
Batch 350/537: Loss=0.5051 (C:0.5051, R:0.0105)
Batch 375/537: Loss=0.5429 (C:0.5429, R:0.0105)
Batch 400/537: Loss=0.5132 (C:0.5132, R:0.0105)
Batch 425/537: Loss=0.5118 (C:0.5118, R:0.0105)
Batch 450/537: Loss=0.4951 (C:0.4951, R:0.0105)
Batch 475/537: Loss=0.5361 (C:0.5361, R:0.0105)
Batch 500/537: Loss=0.5520 (C:0.5520, R:0.0105)
Batch 525/537: Loss=0.5003 (C:0.5003, R:0.0105)

============================================================
Epoch 86/300 completed in 21.7s
Train: Loss=0.5058 (C:0.5058, R:0.0105) Ratio=5.60x
Val:   Loss=0.6987 (C:0.6987, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.300
No improvement for 4 epochs
============================================================

Epoch 87 Training
----------------------------------------
Batch   0/537: Loss=0.4974 (C:0.4974, R:0.0105)
Batch  25/537: Loss=0.5229 (C:0.5229, R:0.0105)
Batch  50/537: Loss=0.5247 (C:0.5247, R:0.0105)
Batch  75/537: Loss=0.4919 (C:0.4919, R:0.0105)
Batch 100/537: Loss=0.4869 (C:0.4869, R:0.0105)
Batch 125/537: Loss=0.4888 (C:0.4888, R:0.0105)
Batch 150/537: Loss=0.5206 (C:0.5206, R:0.0105)
Batch 175/537: Loss=0.5080 (C:0.5080, R:0.0105)
Batch 200/537: Loss=0.4999 (C:0.4999, R:0.0105)
Batch 225/537: Loss=0.5307 (C:0.5307, R:0.0105)
Batch 250/537: Loss=0.5314 (C:0.5314, R:0.0105)
Batch 275/537: Loss=0.4957 (C:0.4957, R:0.0105)
Batch 300/537: Loss=0.4615 (C:0.4615, R:0.0105)
Batch 325/537: Loss=0.4865 (C:0.4865, R:0.0106)
Batch 350/537: Loss=0.5092 (C:0.5092, R:0.0105)
Batch 375/537: Loss=0.4967 (C:0.4967, R:0.0105)
Batch 400/537: Loss=0.5206 (C:0.5206, R:0.0105)
Batch 425/537: Loss=0.5312 (C:0.5312, R:0.0105)
Batch 450/537: Loss=0.4814 (C:0.4814, R:0.0105)
Batch 475/537: Loss=0.5020 (C:0.5020, R:0.0105)
Batch 500/537: Loss=0.5101 (C:0.5101, R:0.0105)
Batch 525/537: Loss=0.5547 (C:0.5547, R:0.0105)

============================================================
Epoch 87/300 completed in 21.7s
Train: Loss=0.5071 (C:0.5071, R:0.0105) Ratio=5.63x
Val:   Loss=0.6936 (C:0.6936, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.300
No improvement for 5 epochs
============================================================

🌍 Updating global dataset at epoch 88
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.295 ± 0.573
    Neg distances: 2.668 ± 1.101
    Separation ratio: 9.06x
    Gap: -4.565
    ✅ Excellent global separation!

Epoch 88 Training
----------------------------------------
Batch   0/537: Loss=0.4810 (C:0.4810, R:0.0105)
Batch  25/537: Loss=0.5185 (C:0.5185, R:0.0105)
Batch  50/537: Loss=0.4821 (C:0.4821, R:0.0105)
Batch  75/537: Loss=0.4736 (C:0.4736, R:0.0105)
Batch 100/537: Loss=0.5232 (C:0.5232, R:0.0105)
Batch 125/537: Loss=0.5236 (C:0.5236, R:0.0105)
Batch 150/537: Loss=0.4985 (C:0.4985, R:0.0105)
Batch 175/537: Loss=0.5275 (C:0.5275, R:0.0105)
Batch 200/537: Loss=0.5386 (C:0.5386, R:0.0105)
Batch 225/537: Loss=0.5014 (C:0.5014, R:0.0105)
Batch 250/537: Loss=0.5317 (C:0.5317, R:0.0105)
Batch 275/537: Loss=0.5642 (C:0.5642, R:0.0105)
Batch 300/537: Loss=0.5233 (C:0.5233, R:0.0105)
Batch 325/537: Loss=0.5091 (C:0.5091, R:0.0105)
Batch 350/537: Loss=0.5513 (C:0.5513, R:0.0105)
Batch 375/537: Loss=0.5390 (C:0.5390, R:0.0105)
Batch 400/537: Loss=0.5375 (C:0.5375, R:0.0105)
Batch 425/537: Loss=0.4676 (C:0.4676, R:0.0105)
Batch 450/537: Loss=0.5272 (C:0.5272, R:0.0105)
Batch 475/537: Loss=0.4760 (C:0.4760, R:0.0105)
Batch 500/537: Loss=0.5221 (C:0.5221, R:0.0105)
Batch 525/537: Loss=0.4911 (C:0.4911, R:0.0105)

============================================================
Epoch 88/300 completed in 27.4s
Train: Loss=0.5153 (C:0.5153, R:0.0105) Ratio=5.67x
Val:   Loss=0.7058 (C:0.7058, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
No improvement for 6 epochs
============================================================

Epoch 89 Training
----------------------------------------
Batch   0/537: Loss=0.5244 (C:0.5244, R:0.0105)
Batch  25/537: Loss=0.5176 (C:0.5176, R:0.0105)
Batch  50/537: Loss=0.5031 (C:0.5031, R:0.0105)
Batch  75/537: Loss=0.4905 (C:0.4905, R:0.0105)
Batch 100/537: Loss=0.4883 (C:0.4883, R:0.0105)
Batch 125/537: Loss=0.4993 (C:0.4993, R:0.0105)
Batch 150/537: Loss=0.4841 (C:0.4841, R:0.0105)
Batch 175/537: Loss=0.4886 (C:0.4886, R:0.0105)
Batch 200/537: Loss=0.4861 (C:0.4861, R:0.0105)
Batch 225/537: Loss=0.5071 (C:0.5071, R:0.0105)
Batch 250/537: Loss=0.4907 (C:0.4907, R:0.0105)
Batch 275/537: Loss=0.5265 (C:0.5265, R:0.0105)
Batch 300/537: Loss=0.5289 (C:0.5289, R:0.0106)
Batch 325/537: Loss=0.4922 (C:0.4922, R:0.0105)
Batch 350/537: Loss=0.5232 (C:0.5232, R:0.0105)
Batch 375/537: Loss=0.5201 (C:0.5201, R:0.0105)
Batch 400/537: Loss=0.5214 (C:0.5214, R:0.0105)
Batch 425/537: Loss=0.5473 (C:0.5473, R:0.0105)
Batch 450/537: Loss=0.4641 (C:0.4641, R:0.0105)
Batch 475/537: Loss=0.5145 (C:0.5145, R:0.0105)
Batch 500/537: Loss=0.5332 (C:0.5332, R:0.0105)
Batch 525/537: Loss=0.5184 (C:0.5184, R:0.0105)

============================================================
Epoch 89/300 completed in 21.8s
Train: Loss=0.5150 (C:0.5150, R:0.0105) Ratio=5.76x
Val:   Loss=0.7052 (C:0.7052, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 7 epochs
============================================================

Epoch 90 Training
----------------------------------------
Batch   0/537: Loss=0.4998 (C:0.4998, R:0.0105)
Batch  25/537: Loss=0.5024 (C:0.5024, R:0.0106)
Batch  50/537: Loss=0.4619 (C:0.4619, R:0.0105)
Batch  75/537: Loss=0.5222 (C:0.5222, R:0.0105)
Batch 100/537: Loss=0.4964 (C:0.4964, R:0.0106)
Batch 125/537: Loss=0.4688 (C:0.4688, R:0.0105)
Batch 150/537: Loss=0.5077 (C:0.5077, R:0.0105)
Batch 175/537: Loss=0.4801 (C:0.4801, R:0.0105)
Batch 200/537: Loss=0.5041 (C:0.5041, R:0.0105)
Batch 225/537: Loss=0.5018 (C:0.5018, R:0.0105)
Batch 250/537: Loss=0.5082 (C:0.5082, R:0.0105)
Batch 275/537: Loss=0.5358 (C:0.5358, R:0.0105)
Batch 300/537: Loss=0.4844 (C:0.4844, R:0.0105)
Batch 325/537: Loss=0.4607 (C:0.4607, R:0.0105)
Batch 350/537: Loss=0.4967 (C:0.4967, R:0.0105)
Batch 375/537: Loss=0.5494 (C:0.5494, R:0.0105)
Batch 400/537: Loss=0.5310 (C:0.5310, R:0.0105)
Batch 425/537: Loss=0.5248 (C:0.5248, R:0.0105)
Batch 450/537: Loss=0.5092 (C:0.5092, R:0.0105)
Batch 475/537: Loss=0.5307 (C:0.5307, R:0.0105)
Batch 500/537: Loss=0.4929 (C:0.4929, R:0.0104)
Batch 525/537: Loss=0.5001 (C:0.5001, R:0.0105)

============================================================
Epoch 90/300 completed in 21.4s
Train: Loss=0.5133 (C:0.5133, R:0.0105) Ratio=5.73x
Val:   Loss=0.7083 (C:0.7083, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
No improvement for 8 epochs

Early stopping triggered after 90 epochs
Best model was at epoch 82 with Val Loss: 0.6923

Global Dataset Training Completed!
Best epoch: 82
Best validation loss: 0.6923
Final separation ratios: Train=5.73x, Val=3.09x
Training completed!
Loading best model from entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin2.0_updatefreq3_max_global_samples10000_20250715_144800/checkpoints/best_model.pt
Starting model evaluation...
========================================
GlobalContrastiveEvaluator initialized on cuda
Starting comprehensive evaluation...
============================================================
Extracting latent representations...
  Processed 1/10 batches
Extracted representations: torch.Size([9824, 75])
Evaluating clustering performance...
Clustering Results:
  Silhouette Score: 0.4560
  Adjusted Rand Score: 0.5226
  Clustering Accuracy: 0.8096
Evaluating classification performance...
  Extracting training representations...
Extracting latent representations...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
Extracted representations: torch.Size([547740, 75])
  Extracting validation representations...
Extracting latent representations...
  Processed 1/9 batches
Extracted representations: torch.Size([9180, 75])
Subsampled training to 50000 samples
  Training on 50000 samples, evaluating on 9180 samples
Classification Results:
  Accuracy: 0.8155
  Per-class F1: [0.8391655450874831, 0.749879826950809, 0.8589473684210528]
Evaluating reconstruction quality...
Reconstruction Results:
  Average MSE: 0.010432
Evaluating separation quality...
Separation Results:
  Positive distances: 0.770 ± 0.947
  Negative distances: 2.326 ± 1.243
  Separation ratio: 3.02x
  Gap: -4.386
  Perfect separation: No

Comprehensive evaluation completed!

============================================================
EVALUATION SUMMARY
============================================================
Clustering Performance:
  Silhouette Score: 0.4560
  Clustering Accuracy: 0.8096
  Adjusted Rand Score: 0.5226

Classification Performance:
  Accuracy: 0.8155

Separation Quality:
  Separation Ratio: 3.02x
  Gap: -4.386
  Perfect Separation: False

Reconstruction Quality:
  Average MSE: 0.010432
============================================================
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin2.0_updatefreq3_max_global_samples10000_20250715_144800/results/evaluation_results_20250715_152349.json
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin2.0_updatefreq3_max_global_samples10000_20250715_144800/results/evaluation_results_20250715_152349.json
Saving final experiment results...
Final results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin2.0_updatefreq3_max_global_samples10000_20250715_144800/final_results.json

============================================================
PIPELINE COMPLETED SUCCESSFULLY!
============================================================
Experiment directory: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin2.0_updatefreq3_max_global_samples10000_20250715_144800
Best model: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin2.0_updatefreq3_max_global_samples10000_20250715_144800/checkpoints/best_model.pt
Final results: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin2.0_updatefreq3_max_global_samples10000_20250715_144800/final_results.json

Key Results:
  Separation ratio: 3.02x
  Perfect separation: False
  Classification accuracy: 0.8155
  Result: 0.8155% (improvement: +-80.85%)
  Cleaning up: coarse_margin2.0_updatefreq3_max_global_samples10000_20250715_144800

[9/12] Testing: coarse_margin3.0_updatefreq1_max_global_samples5000
  margin: 3.0
  update_frequency: 1
  max_global_samples: 5000
  Reconstruction weight: 0.3 (fixed)
GLOBAL DATASET CONTRASTIVE AUTOENCODER PIPELINE
============================================================
Start time: 2025-07-15 15:23:50.048872
Using device: cuda

Configuration:
  Embedding type: concat
  Batch size: 1020
  Global update frequency: 1 epochs
  Training epochs: 300
Experiment setup completed:
  Experiment directory: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin3.0_updatefreq1_max_global_samples5000_20250715_152350
  Config saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin3.0_updatefreq1_max_global_samples5000_20250715_152350/config.json
Loading data...
========================================
FlexibleEmbedder initialized with type: 'concat'
Output dimension will be: 1536
GlobalDataLoader initialized:
  Embedding type: concat
  Output dimension: 1536
  Sample size: All
Starting data loading pipeline...
============================================================
Loading training data from data/processed/snli_full_standard_SBERT.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 549367 training samples
Loading validation data from data/processed/snli_full_standard_SBERT_validation.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9842 validation samples
Loading test data from data/processed/snli_full_standard_SBERT_test.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9824 test samples
Generating embeddings for training...
Generating concat embeddings on cuda
Processing 549367 samples in batches of 1000
  Processing batch 1/550
  Processing batch 6/550
  Processing batch 11/550
  Processing batch 16/550
  Processing batch 21/550
  Processing batch 26/550
  Processing batch 31/550
  Processing batch 36/550
  Processing batch 41/550
  Processing batch 46/550
  Processing batch 51/550
  Processing batch 56/550
  Processing batch 61/550
  Processing batch 66/550
  Processing batch 71/550
  Processing batch 76/550
  Processing batch 81/550
  Processing batch 86/550
  Processing batch 91/550
  Processing batch 96/550
  Processing batch 101/550
  Processing batch 106/550
  Processing batch 111/550
  Processing batch 116/550
  Processing batch 121/550
  Processing batch 126/550
  Processing batch 131/550
  Processing batch 136/550
  Processing batch 141/550
  Processing batch 146/550
  Processing batch 151/550
  Processing batch 156/550
  Processing batch 161/550
  Processing batch 166/550
  Processing batch 171/550
  Processing batch 176/550
  Processing batch 181/550
  Processing batch 186/550
  Processing batch 191/550
  Processing batch 196/550
  Processing batch 201/550
  Processing batch 206/550
  Processing batch 211/550
  Processing batch 216/550
  Processing batch 221/550
  Processing batch 226/550
  Processing batch 231/550
  Processing batch 236/550
  Processing batch 241/550
  Processing batch 246/550
  Processing batch 251/550
  Processing batch 256/550
  Processing batch 261/550
  Processing batch 266/550
  Processing batch 271/550
  Processing batch 276/550
  Processing batch 281/550
  Processing batch 286/550
  Processing batch 291/550
  Processing batch 296/550
  Processing batch 301/550
  Processing batch 306/550
  Processing batch 311/550
  Processing batch 316/550
  Processing batch 321/550
  Processing batch 326/550
  Processing batch 331/550
  Processing batch 336/550
  Processing batch 341/550
  Processing batch 346/550
  Processing batch 351/550
  Processing batch 356/550
  Processing batch 361/550
  Processing batch 366/550
  Processing batch 371/550
  Processing batch 376/550
  Processing batch 381/550
  Processing batch 386/550
  Processing batch 391/550
  Processing batch 396/550
  Processing batch 401/550
  Processing batch 406/550
  Processing batch 411/550
  Processing batch 416/550
  Processing batch 421/550
  Processing batch 426/550
  Processing batch 431/550
  Processing batch 436/550
  Processing batch 441/550
  Processing batch 446/550
  Processing batch 451/550
  Processing batch 456/550
  Processing batch 461/550
  Processing batch 466/550
  Processing batch 471/550
  Processing batch 476/550
  Processing batch 481/550
  Processing batch 486/550
  Processing batch 491/550
  Processing batch 496/550
  Processing batch 501/550
  Processing batch 506/550
  Processing batch 511/550
  Processing batch 516/550
  Processing batch 521/550
  Processing batch 526/550
  Processing batch 531/550
  Processing batch 536/550
  Processing batch 541/550
  Processing batch 546/550
Generated concat embeddings: torch.Size([549367, 1536])
Generating embeddings for validation...
Generating concat embeddings on cuda
Processing 9842 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9842, 1536])
Generating embeddings for test...
Generating concat embeddings on cuda
Processing 9824 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9824, 1536])
EntailmentDataset created: 549367 samples
  Embedding shape: torch.Size([549367, 1536])
  Class distribution: {'entailment': 183416, 'neutral': 182764, 'contradiction': 183187}
EntailmentDataset created: 9842 samples
  Embedding shape: torch.Size([9842, 1536])
  Class distribution: {'entailment': 3329, 'neutral': 3235, 'contradiction': 3278}
EntailmentDataset created: 9824 samples
  Embedding shape: torch.Size([9824, 1536])
  Class distribution: {'entailment': 3368, 'neutral': 3219, 'contradiction': 3237}

Data loading pipeline completed!
Output embedding dimension: 1536
Updated model input_dim to: 1536
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 537
  Class 2: 183187 samples
  Class 0: 183416 samples
  Class 1: 182764 samples
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 9
  Class 2: 3278 samples
  Class 0: 3329 samples
  Class 1: 3235 samples
DataLoaders created:
  Batch size: 1020
  Balanced sampling: True
  Train batches: 537
  Val batches: 9
  Test batches: 10
Data loading completed!
  Train: 549367 samples, 537 batches
  Val: 9842 samples, 9 batches
  Test: 9824 samples, 10 batches
Creating model and trainer...
========================================
ContrastiveAutoencoder initialized:
  Input dim: 1536
  Latent dim: 75
  Hidden dims: [512, 256]
  Dropout rate: 0.2
  Total parameters: 1,876,555
Model created with 1,876,555 parameters
FullDatasetContrastiveLoss initialized:
  Margin: 3.0
  Update frequency: 1 epochs
  Max global samples: 5000
FullDatasetCombinedLoss initialized:
  Contrastive weight: 1.0
  Base reconstruction weight: 0.0
  Scheduled reconstruction: warmup=30 epochs, max_weight=0.3
Optimizer created (lr=0.0001)
GlobalDatasetTrainer initialized on device: cuda
Model parameters: 1,876,555
Starting training...
========================================
Starting Global Dataset Training...
============================================================

🌍 Updating global dataset at epoch 1
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.095 ± 0.011
    Neg distances: 0.096 ± 0.011
    Separation ratio: 1.00x
    Gap: -0.129
    ❌ Poor global separation

Epoch 1 Training
----------------------------------------
Batch   0/537: Loss=2.9998 (C:2.9998, R:0.0116)
Batch  25/537: Loss=2.9959 (C:2.9959, R:0.0114)
Batch  50/537: Loss=2.9747 (C:2.9747, R:0.0113)
Batch  75/537: Loss=2.9548 (C:2.9548, R:0.0112)
Batch 100/537: Loss=2.9514 (C:2.9514, R:0.0110)
Batch 125/537: Loss=2.9450 (C:2.9450, R:0.0109)
Batch 150/537: Loss=2.9349 (C:2.9349, R:0.0108)
Batch 175/537: Loss=2.9213 (C:2.9213, R:0.0108)
Batch 200/537: Loss=2.9155 (C:2.9155, R:0.0107)
Batch 225/537: Loss=2.9049 (C:2.9049, R:0.0107)
Batch 250/537: Loss=2.8860 (C:2.8860, R:0.0107)
Batch 275/537: Loss=2.8947 (C:2.8947, R:0.0106)
Batch 300/537: Loss=2.8810 (C:2.8810, R:0.0106)
Batch 325/537: Loss=2.8679 (C:2.8679, R:0.0105)
Batch 350/537: Loss=2.8536 (C:2.8536, R:0.0106)
Batch 375/537: Loss=2.8743 (C:2.8743, R:0.0106)
Batch 400/537: Loss=2.8737 (C:2.8737, R:0.0105)
Batch 425/537: Loss=2.8593 (C:2.8593, R:0.0106)
Batch 450/537: Loss=2.8647 (C:2.8647, R:0.0105)
Batch 475/537: Loss=2.8603 (C:2.8603, R:0.0106)
Batch 500/537: Loss=2.8703 (C:2.8703, R:0.0105)
Batch 525/537: Loss=2.8626 (C:2.8626, R:0.0105)

============================================================
Epoch 1/300 completed in 27.4s
Train: Loss=2.9031 (C:2.9031, R:0.0108) Ratio=1.60x
Val:   Loss=2.8433 (C:2.8433, R:0.0104) Ratio=2.12x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 2.8433)
============================================================

🌍 Updating global dataset at epoch 2
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.955 ± 0.809
    Neg distances: 2.092 ± 1.225
    Separation ratio: 2.19x
    Gap: -5.091
    ✅ Good global separation

Epoch 2 Training
----------------------------------------
Batch   0/537: Loss=2.0730 (C:2.0730, R:0.0106)
Batch  25/537: Loss=2.0422 (C:2.0422, R:0.0105)
Batch  50/537: Loss=2.0981 (C:2.0981, R:0.0105)
Batch  75/537: Loss=2.0771 (C:2.0771, R:0.0105)
Batch 100/537: Loss=2.0436 (C:2.0436, R:0.0105)
Batch 125/537: Loss=2.0599 (C:2.0599, R:0.0105)
Batch 150/537: Loss=2.0311 (C:2.0311, R:0.0105)
Batch 175/537: Loss=2.0373 (C:2.0373, R:0.0105)
Batch 200/537: Loss=2.0585 (C:2.0585, R:0.0105)
Batch 225/537: Loss=2.0425 (C:2.0425, R:0.0105)
Batch 250/537: Loss=2.0553 (C:2.0553, R:0.0105)
Batch 275/537: Loss=2.0597 (C:2.0597, R:0.0105)
Batch 300/537: Loss=2.0007 (C:2.0007, R:0.0105)
Batch 325/537: Loss=2.0430 (C:2.0430, R:0.0105)
Batch 350/537: Loss=1.9787 (C:1.9787, R:0.0105)
Batch 375/537: Loss=2.0602 (C:2.0602, R:0.0105)
Batch 400/537: Loss=2.0362 (C:2.0362, R:0.0105)
Batch 425/537: Loss=2.0672 (C:2.0672, R:0.0106)
Batch 450/537: Loss=2.0520 (C:2.0520, R:0.0105)
Batch 475/537: Loss=2.0305 (C:2.0305, R:0.0105)
Batch 500/537: Loss=2.0148 (C:2.0148, R:0.0105)
Batch 525/537: Loss=1.9919 (C:1.9919, R:0.0105)

============================================================
Epoch 2/300 completed in 27.4s
Train: Loss=2.0420 (C:2.0420, R:0.0105) Ratio=2.16x
Val:   Loss=1.9949 (C:1.9949, R:0.0104) Ratio=2.35x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.9949)
============================================================

🌍 Updating global dataset at epoch 3
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.899 ± 0.837
    Neg distances: 2.207 ± 1.245
    Separation ratio: 2.45x
    Gap: -5.167
    ✅ Good global separation

Epoch 3 Training
----------------------------------------
Batch   0/537: Loss=1.9337 (C:1.9337, R:0.0105)
Batch  25/537: Loss=1.8920 (C:1.8920, R:0.0105)
Batch  50/537: Loss=1.9092 (C:1.9092, R:0.0105)
Batch  75/537: Loss=1.9223 (C:1.9223, R:0.0106)
Batch 100/537: Loss=1.9131 (C:1.9131, R:0.0105)
Batch 125/537: Loss=1.9359 (C:1.9359, R:0.0105)
Batch 150/537: Loss=1.8544 (C:1.8544, R:0.0105)
Batch 175/537: Loss=1.8891 (C:1.8891, R:0.0105)
Batch 200/537: Loss=1.9408 (C:1.9408, R:0.0105)
Batch 225/537: Loss=1.8989 (C:1.8989, R:0.0105)
Batch 250/537: Loss=1.8627 (C:1.8627, R:0.0105)
Batch 275/537: Loss=1.8880 (C:1.8880, R:0.0105)
Batch 300/537: Loss=1.9444 (C:1.9444, R:0.0105)
Batch 325/537: Loss=1.9282 (C:1.9282, R:0.0105)
Batch 350/537: Loss=1.8926 (C:1.8926, R:0.0105)
Batch 375/537: Loss=1.8551 (C:1.8551, R:0.0105)
Batch 400/537: Loss=1.9311 (C:1.9311, R:0.0105)
Batch 425/537: Loss=1.9013 (C:1.9013, R:0.0105)
Batch 450/537: Loss=1.8999 (C:1.8999, R:0.0105)
Batch 475/537: Loss=1.8705 (C:1.8705, R:0.0105)
Batch 500/537: Loss=1.9161 (C:1.9161, R:0.0105)
Batch 525/537: Loss=1.9469 (C:1.9469, R:0.0105)

============================================================
Epoch 3/300 completed in 27.8s
Train: Loss=1.9100 (C:1.9100, R:0.0105) Ratio=2.42x
Val:   Loss=1.8865 (C:1.8865, R:0.0104) Ratio=2.50x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.8865)
============================================================

🌍 Updating global dataset at epoch 4
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.840 ± 0.833
    Neg distances: 2.289 ± 1.261
    Separation ratio: 2.73x
    Gap: -5.046
    ✅ Good global separation

Epoch 4 Training
----------------------------------------
Batch   0/537: Loss=1.7961 (C:1.7961, R:0.0105)
Batch  25/537: Loss=1.8303 (C:1.8303, R:0.0105)
Batch  50/537: Loss=1.8219 (C:1.8219, R:0.0105)
Batch  75/537: Loss=1.8085 (C:1.8085, R:0.0105)
Batch 100/537: Loss=1.7983 (C:1.7983, R:0.0105)
Batch 125/537: Loss=1.8071 (C:1.8071, R:0.0105)
Batch 150/537: Loss=1.8288 (C:1.8288, R:0.0105)
Batch 175/537: Loss=1.8381 (C:1.8381, R:0.0105)
Batch 200/537: Loss=1.8321 (C:1.8321, R:0.0105)
Batch 225/537: Loss=1.8298 (C:1.8298, R:0.0105)
Batch 250/537: Loss=1.8375 (C:1.8375, R:0.0105)
Batch 275/537: Loss=1.8466 (C:1.8466, R:0.0105)
Batch 300/537: Loss=1.8082 (C:1.8082, R:0.0106)
Batch 325/537: Loss=1.7744 (C:1.7744, R:0.0105)
Batch 350/537: Loss=1.7868 (C:1.7868, R:0.0105)
Batch 375/537: Loss=1.7816 (C:1.7816, R:0.0105)
Batch 400/537: Loss=1.8267 (C:1.8267, R:0.0105)
Batch 425/537: Loss=1.7920 (C:1.7920, R:0.0105)
Batch 450/537: Loss=1.8209 (C:1.8209, R:0.0105)
Batch 475/537: Loss=1.8297 (C:1.8297, R:0.0105)
Batch 500/537: Loss=1.8378 (C:1.8378, R:0.0105)
Batch 525/537: Loss=1.8108 (C:1.8108, R:0.0105)

============================================================
Epoch 4/300 completed in 27.2s
Train: Loss=1.8176 (C:1.8176, R:0.0105) Ratio=2.57x
Val:   Loss=1.8126 (C:1.8126, R:0.0104) Ratio=2.62x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.8126)
============================================================

🌍 Updating global dataset at epoch 5
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.842 ± 0.849
    Neg distances: 2.348 ± 1.275
    Separation ratio: 2.79x
    Gap: -4.902
    ✅ Good global separation

Epoch 5 Training
----------------------------------------
Batch   0/537: Loss=1.8096 (C:1.8096, R:0.0105)
Batch  25/537: Loss=1.7619 (C:1.7619, R:0.0105)
Batch  50/537: Loss=1.7864 (C:1.7864, R:0.0105)
Batch  75/537: Loss=1.7654 (C:1.7654, R:0.0105)
Batch 100/537: Loss=1.8192 (C:1.8192, R:0.0105)
Batch 125/537: Loss=1.8463 (C:1.8463, R:0.0105)
Batch 150/537: Loss=1.7449 (C:1.7449, R:0.0105)
Batch 175/537: Loss=1.7940 (C:1.7940, R:0.0105)
Batch 200/537: Loss=1.7526 (C:1.7526, R:0.0105)
Batch 225/537: Loss=1.7406 (C:1.7406, R:0.0105)
Batch 250/537: Loss=1.7856 (C:1.7856, R:0.0105)
Batch 275/537: Loss=1.7655 (C:1.7655, R:0.0105)
Batch 300/537: Loss=1.7842 (C:1.7842, R:0.0105)
Batch 325/537: Loss=1.8099 (C:1.8099, R:0.0105)
Batch 350/537: Loss=1.8259 (C:1.8259, R:0.0105)
Batch 375/537: Loss=1.8234 (C:1.8234, R:0.0105)
Batch 400/537: Loss=1.7568 (C:1.7568, R:0.0105)
Batch 425/537: Loss=1.7213 (C:1.7213, R:0.0105)
Batch 450/537: Loss=1.7542 (C:1.7542, R:0.0105)
Batch 475/537: Loss=1.8306 (C:1.8306, R:0.0105)
Batch 500/537: Loss=1.7927 (C:1.7927, R:0.0105)
Batch 525/537: Loss=1.7542 (C:1.7542, R:0.0105)

============================================================
Epoch 5/300 completed in 28.0s
Train: Loss=1.7821 (C:1.7821, R:0.0105) Ratio=2.71x
Val:   Loss=1.7714 (C:1.7714, R:0.0104) Ratio=2.70x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.7714)
============================================================

🌍 Updating global dataset at epoch 6
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.813 ± 0.860
    Neg distances: 2.469 ± 1.307
    Separation ratio: 3.04x
    Gap: -5.105
    ✅ Excellent global separation!

Epoch 6 Training
----------------------------------------
Batch   0/537: Loss=1.7548 (C:1.7548, R:0.0105)
Batch  25/537: Loss=1.7379 (C:1.7379, R:0.0105)
Batch  50/537: Loss=1.7343 (C:1.7343, R:0.0105)
Batch  75/537: Loss=1.7336 (C:1.7336, R:0.0105)
Batch 100/537: Loss=1.6695 (C:1.6695, R:0.0105)
Batch 125/537: Loss=1.6757 (C:1.6757, R:0.0105)
Batch 150/537: Loss=1.7250 (C:1.7250, R:0.0105)
Batch 175/537: Loss=1.7686 (C:1.7686, R:0.0106)
Batch 200/537: Loss=1.7545 (C:1.7545, R:0.0105)
Batch 225/537: Loss=1.6959 (C:1.6959, R:0.0105)
Batch 250/537: Loss=1.7345 (C:1.7345, R:0.0105)
Batch 275/537: Loss=1.6972 (C:1.6972, R:0.0105)
Batch 300/537: Loss=1.7036 (C:1.7036, R:0.0106)
Batch 325/537: Loss=1.6490 (C:1.6490, R:0.0105)
Batch 350/537: Loss=1.7132 (C:1.7132, R:0.0105)
Batch 375/537: Loss=1.7074 (C:1.7074, R:0.0106)
Batch 400/537: Loss=1.7283 (C:1.7283, R:0.0105)
Batch 425/537: Loss=1.7701 (C:1.7701, R:0.0105)
Batch 450/537: Loss=1.7116 (C:1.7116, R:0.0105)
Batch 475/537: Loss=1.6903 (C:1.6903, R:0.0105)
Batch 500/537: Loss=1.6640 (C:1.6640, R:0.0105)
Batch 525/537: Loss=1.7430 (C:1.7430, R:0.0105)

============================================================
Epoch 6/300 completed in 27.0s
Train: Loss=1.7070 (C:1.7070, R:0.0105) Ratio=2.75x
Val:   Loss=1.7098 (C:1.7098, R:0.0104) Ratio=2.74x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.7098)
============================================================

🌍 Updating global dataset at epoch 7
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.788 ± 0.871
    Neg distances: 2.549 ± 1.321
    Separation ratio: 3.24x
    Gap: -5.096
    ✅ Excellent global separation!

Epoch 7 Training
----------------------------------------
Batch   0/537: Loss=1.6266 (C:1.6266, R:0.0105)
Batch  25/537: Loss=1.6514 (C:1.6514, R:0.0105)
Batch  50/537: Loss=1.6101 (C:1.6101, R:0.0105)
Batch  75/537: Loss=1.6460 (C:1.6460, R:0.0105)
Batch 100/537: Loss=1.6991 (C:1.6991, R:0.0105)
Batch 125/537: Loss=1.6904 (C:1.6904, R:0.0105)
Batch 150/537: Loss=1.6110 (C:1.6110, R:0.0105)
Batch 175/537: Loss=1.6535 (C:1.6535, R:0.0105)
Batch 200/537: Loss=1.6315 (C:1.6315, R:0.0105)
Batch 225/537: Loss=1.6586 (C:1.6586, R:0.0105)
Batch 250/537: Loss=1.6059 (C:1.6059, R:0.0105)
Batch 275/537: Loss=1.6282 (C:1.6282, R:0.0105)
Batch 300/537: Loss=1.6725 (C:1.6725, R:0.0105)
Batch 325/537: Loss=1.6183 (C:1.6183, R:0.0105)
Batch 350/537: Loss=1.6431 (C:1.6431, R:0.0105)
Batch 375/537: Loss=1.6413 (C:1.6413, R:0.0105)
Batch 400/537: Loss=1.6186 (C:1.6186, R:0.0105)
Batch 425/537: Loss=1.6939 (C:1.6939, R:0.0105)
Batch 450/537: Loss=1.6597 (C:1.6597, R:0.0105)
Batch 475/537: Loss=1.6627 (C:1.6627, R:0.0105)
Batch 500/537: Loss=1.5928 (C:1.5928, R:0.0105)
Batch 525/537: Loss=1.6800 (C:1.6800, R:0.0105)

============================================================
Epoch 7/300 completed in 28.3s
Train: Loss=1.6552 (C:1.6552, R:0.0105) Ratio=2.92x
Val:   Loss=1.6685 (C:1.6685, R:0.0104) Ratio=2.81x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.6685)
============================================================

🌍 Updating global dataset at epoch 8
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.752 ± 0.840
    Neg distances: 2.650 ± 1.337
    Separation ratio: 3.53x
    Gap: -5.065
    ✅ Excellent global separation!

Epoch 8 Training
----------------------------------------
Batch   0/537: Loss=1.6272 (C:1.6272, R:0.0105)
Batch  25/537: Loss=1.5656 (C:1.5656, R:0.0105)
Batch  50/537: Loss=1.6054 (C:1.6054, R:0.0105)
Batch  75/537: Loss=1.5725 (C:1.5725, R:0.0105)
Batch 100/537: Loss=1.5912 (C:1.5912, R:0.0105)
Batch 125/537: Loss=1.5886 (C:1.5886, R:0.0105)
Batch 150/537: Loss=1.5580 (C:1.5580, R:0.0105)
Batch 175/537: Loss=1.5613 (C:1.5613, R:0.0105)
Batch 200/537: Loss=1.6183 (C:1.6183, R:0.0105)
Batch 225/537: Loss=1.5522 (C:1.5522, R:0.0106)
Batch 250/537: Loss=1.5467 (C:1.5467, R:0.0105)
Batch 275/537: Loss=1.5976 (C:1.5976, R:0.0105)
Batch 300/537: Loss=1.6048 (C:1.6048, R:0.0105)
Batch 325/537: Loss=1.5353 (C:1.5353, R:0.0105)
Batch 350/537: Loss=1.5894 (C:1.5894, R:0.0105)
Batch 375/537: Loss=1.5589 (C:1.5589, R:0.0105)
Batch 400/537: Loss=1.6803 (C:1.6803, R:0.0105)
Batch 425/537: Loss=1.6435 (C:1.6435, R:0.0105)
Batch 450/537: Loss=1.6353 (C:1.6353, R:0.0106)
Batch 475/537: Loss=1.6132 (C:1.6132, R:0.0105)
Batch 500/537: Loss=1.5889 (C:1.5889, R:0.0105)
Batch 525/537: Loss=1.5953 (C:1.5953, R:0.0105)

============================================================
Epoch 8/300 completed in 30.2s
Train: Loss=1.5887 (C:1.5887, R:0.0105) Ratio=2.95x
Val:   Loss=1.6017 (C:1.6017, R:0.0104) Ratio=2.81x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.6017)
============================================================

🌍 Updating global dataset at epoch 9
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.779 ± 0.899
    Neg distances: 2.723 ± 1.374
    Separation ratio: 3.49x
    Gap: -5.204
    ✅ Excellent global separation!

Epoch 9 Training
----------------------------------------
Batch   0/537: Loss=1.5663 (C:1.5663, R:0.0105)
Batch  25/537: Loss=1.5828 (C:1.5828, R:0.0105)
Batch  50/537: Loss=1.5893 (C:1.5893, R:0.0105)
Batch  75/537: Loss=1.6173 (C:1.6173, R:0.0105)
Batch 100/537: Loss=1.5960 (C:1.5960, R:0.0105)
Batch 125/537: Loss=1.5747 (C:1.5747, R:0.0105)
Batch 150/537: Loss=1.5741 (C:1.5741, R:0.0105)
Batch 175/537: Loss=1.5312 (C:1.5312, R:0.0105)
Batch 200/537: Loss=1.5516 (C:1.5516, R:0.0105)
Batch 225/537: Loss=1.5712 (C:1.5712, R:0.0105)
Batch 250/537: Loss=1.6287 (C:1.6287, R:0.0106)
Batch 275/537: Loss=1.5520 (C:1.5520, R:0.0105)
Batch 300/537: Loss=1.5725 (C:1.5725, R:0.0105)
Batch 325/537: Loss=1.6136 (C:1.6136, R:0.0105)
Batch 350/537: Loss=1.5877 (C:1.5877, R:0.0105)
Batch 375/537: Loss=1.6426 (C:1.6426, R:0.0105)
Batch 400/537: Loss=1.5514 (C:1.5514, R:0.0105)
Batch 425/537: Loss=1.5592 (C:1.5592, R:0.0105)
Batch 450/537: Loss=1.5647 (C:1.5647, R:0.0106)
Batch 475/537: Loss=1.5632 (C:1.5632, R:0.0105)
Batch 500/537: Loss=1.5915 (C:1.5915, R:0.0105)
Batch 525/537: Loss=1.5572 (C:1.5572, R:0.0105)

============================================================
Epoch 9/300 completed in 29.5s
Train: Loss=1.5750 (C:1.5750, R:0.0105) Ratio=3.00x
Val:   Loss=1.5907 (C:1.5907, R:0.0104) Ratio=2.88x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.5907)
============================================================

🌍 Updating global dataset at epoch 10
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.790 ± 0.896
    Neg distances: 2.736 ± 1.376
    Separation ratio: 3.46x
    Gap: -5.186
    ✅ Excellent global separation!

Epoch 10 Training
----------------------------------------
Batch   0/537: Loss=1.5700 (C:1.5700, R:0.0105)
Batch  25/537: Loss=1.6187 (C:1.6187, R:0.0105)
Batch  50/537: Loss=1.5883 (C:1.5883, R:0.0105)
Batch  75/537: Loss=1.5684 (C:1.5684, R:0.0105)
Batch 100/537: Loss=1.5461 (C:1.5461, R:0.0105)
Batch 125/537: Loss=1.5446 (C:1.5446, R:0.0105)
Batch 150/537: Loss=1.6055 (C:1.6055, R:0.0105)
Batch 175/537: Loss=1.5334 (C:1.5334, R:0.0105)
Batch 200/537: Loss=1.5600 (C:1.5600, R:0.0105)
Batch 225/537: Loss=1.5457 (C:1.5457, R:0.0105)
Batch 250/537: Loss=1.5278 (C:1.5278, R:0.0105)
Batch 275/537: Loss=1.5778 (C:1.5778, R:0.0105)
Batch 300/537: Loss=1.5556 (C:1.5556, R:0.0105)
Batch 325/537: Loss=1.5437 (C:1.5437, R:0.0105)
Batch 350/537: Loss=1.5550 (C:1.5550, R:0.0105)
Batch 375/537: Loss=1.5194 (C:1.5194, R:0.0105)
Batch 400/537: Loss=1.5830 (C:1.5830, R:0.0105)
Batch 425/537: Loss=1.5965 (C:1.5965, R:0.0105)
Batch 450/537: Loss=1.5601 (C:1.5601, R:0.0105)
Batch 475/537: Loss=1.5790 (C:1.5790, R:0.0105)
Batch 500/537: Loss=1.6530 (C:1.6530, R:0.0105)
Batch 525/537: Loss=1.5707 (C:1.5707, R:0.0105)

============================================================
Epoch 10/300 completed in 30.1s
Train: Loss=1.5654 (C:1.5654, R:0.0105) Ratio=3.10x
Val:   Loss=1.6118 (C:1.6118, R:0.0104) Ratio=2.86x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 11
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.767 ± 0.884
    Neg distances: 2.834 ± 1.399
    Separation ratio: 3.69x
    Gap: -5.265
    ✅ Excellent global separation!

Epoch 11 Training
----------------------------------------
Batch   0/537: Loss=1.4909 (C:1.4909, R:0.0105)
Batch  25/537: Loss=1.4965 (C:1.4965, R:0.0105)
Batch  50/537: Loss=1.5074 (C:1.5074, R:0.0105)
Batch  75/537: Loss=1.5232 (C:1.5232, R:0.0105)
Batch 100/537: Loss=1.5146 (C:1.5146, R:0.0105)
Batch 125/537: Loss=1.5099 (C:1.5099, R:0.0105)
Batch 150/537: Loss=1.4873 (C:1.4873, R:0.0105)
Batch 175/537: Loss=1.4913 (C:1.4913, R:0.0105)
Batch 200/537: Loss=1.5705 (C:1.5705, R:0.0105)
Batch 225/537: Loss=1.4737 (C:1.4737, R:0.0105)
Batch 250/537: Loss=1.5233 (C:1.5233, R:0.0105)
Batch 275/537: Loss=1.4902 (C:1.4902, R:0.0105)
Batch 300/537: Loss=1.4944 (C:1.4944, R:0.0105)
Batch 325/537: Loss=1.4656 (C:1.4656, R:0.0105)
Batch 350/537: Loss=1.5083 (C:1.5083, R:0.0105)
Batch 375/537: Loss=1.4947 (C:1.4947, R:0.0105)
Batch 400/537: Loss=1.5210 (C:1.5210, R:0.0105)
Batch 425/537: Loss=1.5101 (C:1.5101, R:0.0105)
Batch 450/537: Loss=1.4994 (C:1.4994, R:0.0105)
Batch 475/537: Loss=1.5244 (C:1.5244, R:0.0104)
Batch 500/537: Loss=1.4997 (C:1.4997, R:0.0105)
Batch 525/537: Loss=1.5200 (C:1.5200, R:0.0105)

============================================================
Epoch 11/300 completed in 29.0s
Train: Loss=1.5142 (C:1.5142, R:0.0105) Ratio=3.17x
Val:   Loss=1.5487 (C:1.5487, R:0.0104) Ratio=2.92x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.5487)
============================================================

🌍 Updating global dataset at epoch 12
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.759 ± 0.874
    Neg distances: 2.892 ± 1.416
    Separation ratio: 3.81x
    Gap: -5.327
    ✅ Excellent global separation!

Epoch 12 Training
----------------------------------------
Batch   0/537: Loss=1.4994 (C:1.4994, R:0.0105)
Batch  25/537: Loss=1.4867 (C:1.4867, R:0.0105)
Batch  50/537: Loss=1.4808 (C:1.4808, R:0.0105)
Batch  75/537: Loss=1.5067 (C:1.5067, R:0.0105)
Batch 100/537: Loss=1.5201 (C:1.5201, R:0.0105)
Batch 125/537: Loss=1.4668 (C:1.4668, R:0.0105)
Batch 150/537: Loss=1.4790 (C:1.4790, R:0.0106)
Batch 175/537: Loss=1.4668 (C:1.4668, R:0.0105)
Batch 200/537: Loss=1.4338 (C:1.4338, R:0.0105)
Batch 225/537: Loss=1.5215 (C:1.5215, R:0.0105)
Batch 250/537: Loss=1.4628 (C:1.4628, R:0.0105)
Batch 275/537: Loss=1.4865 (C:1.4865, R:0.0106)
Batch 300/537: Loss=1.4878 (C:1.4878, R:0.0105)
Batch 325/537: Loss=1.4707 (C:1.4707, R:0.0105)
Batch 350/537: Loss=1.4320 (C:1.4320, R:0.0105)
Batch 375/537: Loss=1.4412 (C:1.4412, R:0.0105)
Batch 400/537: Loss=1.4968 (C:1.4968, R:0.0105)
Batch 425/537: Loss=1.4766 (C:1.4766, R:0.0105)
Batch 450/537: Loss=1.4675 (C:1.4675, R:0.0105)
Batch 475/537: Loss=1.5148 (C:1.5148, R:0.0105)
Batch 500/537: Loss=1.4281 (C:1.4281, R:0.0105)
Batch 525/537: Loss=1.4717 (C:1.4717, R:0.0105)

============================================================
Epoch 12/300 completed in 28.7s
Train: Loss=1.4840 (C:1.4840, R:0.0105) Ratio=3.29x
Val:   Loss=1.5418 (C:1.5418, R:0.0104) Ratio=2.92x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.5418)
============================================================

🌍 Updating global dataset at epoch 13
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.797 ± 0.911
    Neg distances: 2.957 ± 1.462
    Separation ratio: 3.71x
    Gap: -5.482
    ✅ Excellent global separation!

Epoch 13 Training
----------------------------------------
Batch   0/537: Loss=1.4733 (C:1.4733, R:0.0105)
Batch  25/537: Loss=1.5218 (C:1.5218, R:0.0105)
Batch  50/537: Loss=1.4854 (C:1.4854, R:0.0105)
Batch  75/537: Loss=1.4734 (C:1.4734, R:0.0105)
Batch 100/537: Loss=1.4610 (C:1.4610, R:0.0105)
Batch 125/537: Loss=1.5175 (C:1.5175, R:0.0105)
Batch 150/537: Loss=1.5253 (C:1.5253, R:0.0105)
Batch 175/537: Loss=1.4402 (C:1.4402, R:0.0106)
Batch 200/537: Loss=1.5072 (C:1.5072, R:0.0105)
Batch 225/537: Loss=1.4701 (C:1.4701, R:0.0105)
Batch 250/537: Loss=1.4477 (C:1.4477, R:0.0105)
Batch 275/537: Loss=1.4476 (C:1.4476, R:0.0105)
Batch 300/537: Loss=1.5091 (C:1.5091, R:0.0105)
Batch 325/537: Loss=1.4720 (C:1.4720, R:0.0105)
Batch 350/537: Loss=1.4461 (C:1.4461, R:0.0105)
Batch 375/537: Loss=1.4954 (C:1.4954, R:0.0105)
Batch 400/537: Loss=1.5166 (C:1.5166, R:0.0105)
Batch 425/537: Loss=1.4736 (C:1.4736, R:0.0105)
Batch 450/537: Loss=1.4764 (C:1.4764, R:0.0105)
Batch 475/537: Loss=1.4973 (C:1.4973, R:0.0105)
Batch 500/537: Loss=1.4833 (C:1.4833, R:0.0105)
Batch 525/537: Loss=1.4968 (C:1.4968, R:0.0105)

============================================================
Epoch 13/300 completed in 27.5s
Train: Loss=1.4867 (C:1.4867, R:0.0105) Ratio=3.26x
Val:   Loss=1.5391 (C:1.5391, R:0.0104) Ratio=2.89x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.5391)
============================================================

🌍 Updating global dataset at epoch 14
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.756 ± 0.896
    Neg distances: 3.051 ± 1.464
    Separation ratio: 4.04x
    Gap: -5.492
    ✅ Excellent global separation!

Epoch 14 Training
----------------------------------------
Batch   0/537: Loss=1.3821 (C:1.3821, R:0.0105)
Batch  25/537: Loss=1.3396 (C:1.3396, R:0.0105)
Batch  50/537: Loss=1.4340 (C:1.4340, R:0.0105)
Batch  75/537: Loss=1.3882 (C:1.3882, R:0.0105)
Batch 100/537: Loss=1.4387 (C:1.4387, R:0.0105)
Batch 125/537: Loss=1.4416 (C:1.4416, R:0.0105)
Batch 150/537: Loss=1.4661 (C:1.4661, R:0.0105)
Batch 175/537: Loss=1.4018 (C:1.4018, R:0.0105)
Batch 200/537: Loss=1.4947 (C:1.4947, R:0.0105)
Batch 225/537: Loss=1.4195 (C:1.4195, R:0.0105)
Batch 250/537: Loss=1.4134 (C:1.4134, R:0.0105)
Batch 275/537: Loss=1.4294 (C:1.4294, R:0.0106)
Batch 300/537: Loss=1.4417 (C:1.4417, R:0.0105)
Batch 325/537: Loss=1.3939 (C:1.3939, R:0.0105)
Batch 350/537: Loss=1.4150 (C:1.4150, R:0.0105)
Batch 375/537: Loss=1.4725 (C:1.4725, R:0.0105)
Batch 400/537: Loss=1.4405 (C:1.4405, R:0.0105)
Batch 425/537: Loss=1.4494 (C:1.4494, R:0.0105)
Batch 450/537: Loss=1.4111 (C:1.4111, R:0.0105)
Batch 475/537: Loss=1.4401 (C:1.4401, R:0.0105)
Batch 500/537: Loss=1.4204 (C:1.4204, R:0.0105)
Batch 525/537: Loss=1.4327 (C:1.4327, R:0.0106)

============================================================
Epoch 14/300 completed in 27.5s
Train: Loss=1.4220 (C:1.4220, R:0.0105) Ratio=3.32x
Val:   Loss=1.4746 (C:1.4746, R:0.0104) Ratio=2.96x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.4746)
============================================================

🌍 Updating global dataset at epoch 15
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.773 ± 0.903
    Neg distances: 3.095 ± 1.491
    Separation ratio: 4.01x
    Gap: -5.703
    ✅ Excellent global separation!

Epoch 15 Training
----------------------------------------
Batch   0/537: Loss=1.4124 (C:1.4124, R:0.0105)
Batch  25/537: Loss=1.3995 (C:1.3995, R:0.0106)
Batch  50/537: Loss=1.4219 (C:1.4219, R:0.0106)
Batch  75/537: Loss=1.4113 (C:1.4113, R:0.0105)
Batch 100/537: Loss=1.3824 (C:1.3824, R:0.0105)
Batch 125/537: Loss=1.3919 (C:1.3919, R:0.0105)
Batch 150/537: Loss=1.4157 (C:1.4157, R:0.0105)
Batch 175/537: Loss=1.4521 (C:1.4521, R:0.0105)
Batch 200/537: Loss=1.4552 (C:1.4552, R:0.0105)
Batch 225/537: Loss=1.3937 (C:1.3937, R:0.0105)
Batch 250/537: Loss=1.4121 (C:1.4121, R:0.0105)
Batch 275/537: Loss=1.4749 (C:1.4749, R:0.0105)
Batch 300/537: Loss=1.4326 (C:1.4326, R:0.0105)
Batch 325/537: Loss=1.4529 (C:1.4529, R:0.0105)
Batch 350/537: Loss=1.4095 (C:1.4095, R:0.0105)
Batch 375/537: Loss=1.4231 (C:1.4231, R:0.0105)
Batch 400/537: Loss=1.4303 (C:1.4303, R:0.0105)
Batch 425/537: Loss=1.4190 (C:1.4190, R:0.0105)
Batch 450/537: Loss=1.3907 (C:1.3907, R:0.0105)
Batch 475/537: Loss=1.4773 (C:1.4773, R:0.0105)
Batch 500/537: Loss=1.4234 (C:1.4234, R:0.0105)
Batch 525/537: Loss=1.3765 (C:1.3765, R:0.0105)

============================================================
Epoch 15/300 completed in 27.3s
Train: Loss=1.4185 (C:1.4185, R:0.0105) Ratio=3.39x
Val:   Loss=1.4806 (C:1.4806, R:0.0104) Ratio=2.91x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 16
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.783 ± 0.942
    Neg distances: 3.132 ± 1.500
    Separation ratio: 4.00x
    Gap: -5.734
    ✅ Excellent global separation!

Epoch 16 Training
----------------------------------------
Batch   0/537: Loss=1.4338 (C:1.4338, R:0.0105)
Batch  25/537: Loss=1.3859 (C:1.3859, R:0.0105)
Batch  50/537: Loss=1.3909 (C:1.3909, R:0.0105)
Batch  75/537: Loss=1.3533 (C:1.3533, R:0.0105)
Batch 100/537: Loss=1.4044 (C:1.4044, R:0.0105)
Batch 125/537: Loss=1.3952 (C:1.3952, R:0.0105)
Batch 150/537: Loss=1.4267 (C:1.4267, R:0.0105)
Batch 175/537: Loss=1.4027 (C:1.4027, R:0.0105)
Batch 200/537: Loss=1.3589 (C:1.3589, R:0.0105)
Batch 225/537: Loss=1.3915 (C:1.3915, R:0.0105)
Batch 250/537: Loss=1.3622 (C:1.3622, R:0.0105)
Batch 275/537: Loss=1.4275 (C:1.4275, R:0.0105)
Batch 300/537: Loss=1.3955 (C:1.3955, R:0.0105)
Batch 325/537: Loss=1.3976 (C:1.3976, R:0.0105)
Batch 350/537: Loss=1.4495 (C:1.4495, R:0.0105)
Batch 375/537: Loss=1.3898 (C:1.3898, R:0.0105)
Batch 400/537: Loss=1.4091 (C:1.4091, R:0.0105)
Batch 425/537: Loss=1.4217 (C:1.4217, R:0.0105)
Batch 450/537: Loss=1.3964 (C:1.3964, R:0.0105)
Batch 475/537: Loss=1.3589 (C:1.3589, R:0.0105)
Batch 500/537: Loss=1.4196 (C:1.4196, R:0.0105)
Batch 525/537: Loss=1.4101 (C:1.4101, R:0.0105)

============================================================
Epoch 16/300 completed in 28.0s
Train: Loss=1.4034 (C:1.4034, R:0.0105) Ratio=3.42x
Val:   Loss=1.4779 (C:1.4779, R:0.0104) Ratio=2.97x
Reconstruction weight: 0.000
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 17
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.761 ± 0.900
    Neg distances: 3.189 ± 1.513
    Separation ratio: 4.19x
    Gap: -5.918
    ✅ Excellent global separation!

Epoch 17 Training
----------------------------------------
Batch   0/537: Loss=1.4204 (C:1.4204, R:0.0105)
Batch  25/537: Loss=1.3317 (C:1.3317, R:0.0105)
Batch  50/537: Loss=1.4078 (C:1.4078, R:0.0105)
Batch  75/537: Loss=1.3510 (C:1.3510, R:0.0105)
Batch 100/537: Loss=1.3325 (C:1.3325, R:0.0105)
Batch 125/537: Loss=1.4131 (C:1.4131, R:0.0105)
Batch 150/537: Loss=1.3401 (C:1.3401, R:0.0105)
Batch 175/537: Loss=1.3612 (C:1.3612, R:0.0105)
Batch 200/537: Loss=1.3752 (C:1.3752, R:0.0105)
Batch 225/537: Loss=1.3769 (C:1.3769, R:0.0105)
Batch 250/537: Loss=1.3745 (C:1.3745, R:0.0105)
Batch 275/537: Loss=1.3424 (C:1.3424, R:0.0105)
Batch 300/537: Loss=1.3756 (C:1.3756, R:0.0105)
Batch 325/537: Loss=1.3580 (C:1.3580, R:0.0105)
Batch 350/537: Loss=1.3972 (C:1.3972, R:0.0105)
Batch 375/537: Loss=1.3783 (C:1.3783, R:0.0105)
Batch 400/537: Loss=1.3461 (C:1.3461, R:0.0105)
Batch 425/537: Loss=1.3473 (C:1.3473, R:0.0105)
Batch 450/537: Loss=1.2928 (C:1.2928, R:0.0105)
Batch 475/537: Loss=1.2985 (C:1.2985, R:0.0105)
Batch 500/537: Loss=1.4108 (C:1.4108, R:0.0105)
Batch 525/537: Loss=1.3754 (C:1.3754, R:0.0105)

============================================================
Epoch 17/300 completed in 27.7s
Train: Loss=1.3669 (C:1.3669, R:0.0105) Ratio=3.48x
Val:   Loss=1.4391 (C:1.4391, R:0.0104) Ratio=2.98x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.4391)
============================================================

🌍 Updating global dataset at epoch 18
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.734 ± 0.922
    Neg distances: 3.282 ± 1.530
    Separation ratio: 4.47x
    Gap: -6.118
    ✅ Excellent global separation!

Epoch 18 Training
----------------------------------------
Batch   0/537: Loss=1.2802 (C:1.2802, R:0.0105)
Batch  25/537: Loss=1.3266 (C:1.3266, R:0.0106)
Batch  50/537: Loss=1.3193 (C:1.3193, R:0.0105)
Batch  75/537: Loss=1.3254 (C:1.3254, R:0.0105)
Batch 100/537: Loss=1.3932 (C:1.3932, R:0.0106)
Batch 125/537: Loss=1.2854 (C:1.2854, R:0.0105)
Batch 150/537: Loss=1.3278 (C:1.3278, R:0.0105)
Batch 175/537: Loss=1.3443 (C:1.3443, R:0.0105)
Batch 200/537: Loss=1.3050 (C:1.3050, R:0.0105)
Batch 225/537: Loss=1.2959 (C:1.2959, R:0.0105)
Batch 250/537: Loss=1.3009 (C:1.3009, R:0.0105)
Batch 275/537: Loss=1.3455 (C:1.3455, R:0.0105)
Batch 300/537: Loss=1.3396 (C:1.3396, R:0.0105)
Batch 325/537: Loss=1.2993 (C:1.2993, R:0.0105)
Batch 350/537: Loss=1.3648 (C:1.3648, R:0.0105)
Batch 375/537: Loss=1.3090 (C:1.3090, R:0.0105)
Batch 400/537: Loss=1.3950 (C:1.3950, R:0.0105)
Batch 425/537: Loss=1.3239 (C:1.3239, R:0.0105)
Batch 450/537: Loss=1.3652 (C:1.3652, R:0.0105)
Batch 475/537: Loss=1.2631 (C:1.2631, R:0.0105)
Batch 500/537: Loss=1.3406 (C:1.3406, R:0.0105)
Batch 525/537: Loss=1.3208 (C:1.3208, R:0.0105)

============================================================
Epoch 18/300 completed in 27.4s
Train: Loss=1.3220 (C:1.3220, R:0.0105) Ratio=3.49x
Val:   Loss=1.3958 (C:1.3958, R:0.0104) Ratio=3.00x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.3958)
============================================================

🌍 Updating global dataset at epoch 19
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.773 ± 0.929
    Neg distances: 3.275 ± 1.546
    Separation ratio: 4.24x
    Gap: -6.145
    ✅ Excellent global separation!

Epoch 19 Training
----------------------------------------
Batch   0/537: Loss=1.3283 (C:1.3283, R:0.0105)
Batch  25/537: Loss=1.3238 (C:1.3238, R:0.0105)
Batch  50/537: Loss=1.3365 (C:1.3365, R:0.0106)
Batch  75/537: Loss=1.2462 (C:1.2462, R:0.0105)
Batch 100/537: Loss=1.3613 (C:1.3613, R:0.0105)
Batch 125/537: Loss=1.3348 (C:1.3348, R:0.0105)
Batch 150/537: Loss=1.3590 (C:1.3590, R:0.0105)
Batch 175/537: Loss=1.3164 (C:1.3164, R:0.0105)
Batch 200/537: Loss=1.3568 (C:1.3568, R:0.0105)
Batch 225/537: Loss=1.2972 (C:1.2972, R:0.0105)
Batch 250/537: Loss=1.3510 (C:1.3510, R:0.0105)
Batch 275/537: Loss=1.3663 (C:1.3663, R:0.0105)
Batch 300/537: Loss=1.3605 (C:1.3605, R:0.0105)
Batch 325/537: Loss=1.3581 (C:1.3581, R:0.0105)
Batch 350/537: Loss=1.3202 (C:1.3202, R:0.0105)
Batch 375/537: Loss=1.3265 (C:1.3265, R:0.0105)
Batch 400/537: Loss=1.3461 (C:1.3461, R:0.0105)
Batch 425/537: Loss=1.3186 (C:1.3186, R:0.0105)
Batch 450/537: Loss=1.3311 (C:1.3311, R:0.0105)
Batch 475/537: Loss=1.3183 (C:1.3183, R:0.0105)
Batch 500/537: Loss=1.4073 (C:1.4073, R:0.0105)
Batch 525/537: Loss=1.3599 (C:1.3599, R:0.0105)

============================================================
Epoch 19/300 completed in 27.3s
Train: Loss=1.3370 (C:1.3370, R:0.0105) Ratio=3.55x
Val:   Loss=1.4301 (C:1.4301, R:0.0104) Ratio=2.99x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 20
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.736 ± 0.892
    Neg distances: 3.374 ± 1.562
    Separation ratio: 4.59x
    Gap: -6.012
    ✅ Excellent global separation!

Epoch 20 Training
----------------------------------------
Batch   0/537: Loss=1.2840 (C:1.2840, R:0.0105)
Batch  25/537: Loss=1.2427 (C:1.2427, R:0.0105)
Batch  50/537: Loss=1.3203 (C:1.3203, R:0.0105)
Batch  75/537: Loss=1.2887 (C:1.2887, R:0.0105)
Batch 100/537: Loss=1.2641 (C:1.2641, R:0.0105)
Batch 125/537: Loss=1.2355 (C:1.2355, R:0.0105)
Batch 150/537: Loss=1.2311 (C:1.2311, R:0.0105)
Batch 175/537: Loss=1.3253 (C:1.3253, R:0.0105)
Batch 200/537: Loss=1.3182 (C:1.3182, R:0.0105)
Batch 225/537: Loss=1.2967 (C:1.2967, R:0.0105)
Batch 250/537: Loss=1.2666 (C:1.2666, R:0.0105)
Batch 275/537: Loss=1.2520 (C:1.2520, R:0.0105)
Batch 300/537: Loss=1.2354 (C:1.2354, R:0.0105)
Batch 325/537: Loss=1.2790 (C:1.2790, R:0.0105)
Batch 350/537: Loss=1.3286 (C:1.3286, R:0.0105)
Batch 375/537: Loss=1.2942 (C:1.2942, R:0.0105)
Batch 400/537: Loss=1.2931 (C:1.2931, R:0.0105)
Batch 425/537: Loss=1.2666 (C:1.2666, R:0.0105)
Batch 450/537: Loss=1.3160 (C:1.3160, R:0.0105)
Batch 475/537: Loss=1.3462 (C:1.3462, R:0.0105)
Batch 500/537: Loss=1.2276 (C:1.2276, R:0.0105)
Batch 525/537: Loss=1.3620 (C:1.3620, R:0.0105)

============================================================
Epoch 20/300 completed in 27.4s
Train: Loss=1.2880 (C:1.2880, R:0.0105) Ratio=3.60x
Val:   Loss=1.3824 (C:1.3824, R:0.0104) Ratio=3.03x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.3824)
Checkpoint saved at epoch 20
============================================================

🌍 Updating global dataset at epoch 21
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.737 ± 0.937
    Neg distances: 3.452 ± 1.599
    Separation ratio: 4.68x
    Gap: -6.381
    ✅ Excellent global separation!

Epoch 21 Training
----------------------------------------
Batch   0/537: Loss=1.2606 (C:1.2606, R:0.0105)
Batch  25/537: Loss=1.2277 (C:1.2277, R:0.0105)
Batch  50/537: Loss=1.2715 (C:1.2715, R:0.0105)
Batch  75/537: Loss=1.2715 (C:1.2715, R:0.0105)
Batch 100/537: Loss=1.2640 (C:1.2640, R:0.0106)
Batch 125/537: Loss=1.2229 (C:1.2229, R:0.0105)
Batch 150/537: Loss=1.2682 (C:1.2682, R:0.0105)
Batch 175/537: Loss=1.2807 (C:1.2807, R:0.0105)
Batch 200/537: Loss=1.2382 (C:1.2382, R:0.0105)
Batch 225/537: Loss=1.2804 (C:1.2804, R:0.0105)
Batch 250/537: Loss=1.2565 (C:1.2565, R:0.0105)
Batch 275/537: Loss=1.2653 (C:1.2653, R:0.0105)
Batch 300/537: Loss=1.2670 (C:1.2670, R:0.0105)
Batch 325/537: Loss=1.2557 (C:1.2557, R:0.0105)
Batch 350/537: Loss=1.2286 (C:1.2286, R:0.0106)
Batch 375/537: Loss=1.2540 (C:1.2540, R:0.0105)
Batch 400/537: Loss=1.2365 (C:1.2365, R:0.0105)
Batch 425/537: Loss=1.2274 (C:1.2274, R:0.0105)
Batch 450/537: Loss=1.2275 (C:1.2275, R:0.0105)
Batch 475/537: Loss=1.2830 (C:1.2830, R:0.0105)
Batch 500/537: Loss=1.2797 (C:1.2797, R:0.0105)
Batch 525/537: Loss=1.2947 (C:1.2947, R:0.0105)

============================================================
Epoch 21/300 completed in 27.9s
Train: Loss=1.2686 (C:1.2686, R:0.0105) Ratio=3.69x
Val:   Loss=1.3769 (C:1.3769, R:0.0104) Ratio=3.00x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.3769)
============================================================

🌍 Updating global dataset at epoch 22
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.734 ± 0.964
    Neg distances: 3.519 ± 1.613
    Separation ratio: 4.80x
    Gap: -6.327
    ✅ Excellent global separation!

Epoch 22 Training
----------------------------------------
Batch   0/537: Loss=1.2557 (C:1.2557, R:0.0105)
Batch  25/537: Loss=1.2534 (C:1.2534, R:0.0105)
Batch  50/537: Loss=1.2523 (C:1.2523, R:0.0105)
Batch  75/537: Loss=1.2246 (C:1.2246, R:0.0105)
Batch 100/537: Loss=1.2618 (C:1.2618, R:0.0105)
Batch 125/537: Loss=1.2578 (C:1.2578, R:0.0105)
Batch 150/537: Loss=1.2796 (C:1.2796, R:0.0105)
Batch 175/537: Loss=1.2277 (C:1.2277, R:0.0105)
Batch 200/537: Loss=1.2257 (C:1.2257, R:0.0105)
Batch 225/537: Loss=1.1953 (C:1.1953, R:0.0105)
Batch 250/537: Loss=1.2965 (C:1.2965, R:0.0105)
Batch 275/537: Loss=1.2038 (C:1.2038, R:0.0105)
Batch 300/537: Loss=1.2670 (C:1.2670, R:0.0105)
Batch 325/537: Loss=1.2939 (C:1.2939, R:0.0105)
Batch 350/537: Loss=1.2255 (C:1.2255, R:0.0105)
Batch 375/537: Loss=1.3555 (C:1.3555, R:0.0105)
Batch 400/537: Loss=1.2574 (C:1.2574, R:0.0105)
Batch 425/537: Loss=1.2564 (C:1.2564, R:0.0105)
Batch 450/537: Loss=1.2278 (C:1.2278, R:0.0105)
Batch 475/537: Loss=1.2681 (C:1.2681, R:0.0105)
Batch 500/537: Loss=1.3039 (C:1.3039, R:0.0105)
Batch 525/537: Loss=1.2878 (C:1.2878, R:0.0106)

============================================================
Epoch 22/300 completed in 27.1s
Train: Loss=1.2500 (C:1.2500, R:0.0105) Ratio=3.64x
Val:   Loss=1.3430 (C:1.3430, R:0.0104) Ratio=2.99x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.3430)
============================================================

🌍 Updating global dataset at epoch 23
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.758 ± 1.003
    Neg distances: 3.522 ± 1.622
    Separation ratio: 4.65x
    Gap: -6.397
    ✅ Excellent global separation!

Epoch 23 Training
----------------------------------------
Batch   0/537: Loss=1.2591 (C:1.2591, R:0.0105)
Batch  25/537: Loss=1.2574 (C:1.2574, R:0.0105)
Batch  50/537: Loss=1.2061 (C:1.2061, R:0.0105)
Batch  75/537: Loss=1.2684 (C:1.2684, R:0.0105)
Batch 100/537: Loss=1.2167 (C:1.2167, R:0.0105)
Batch 125/537: Loss=1.2434 (C:1.2434, R:0.0105)
Batch 150/537: Loss=1.2528 (C:1.2528, R:0.0105)
Batch 175/537: Loss=1.3136 (C:1.3136, R:0.0105)
Batch 200/537: Loss=1.2584 (C:1.2584, R:0.0105)
Batch 225/537: Loss=1.2360 (C:1.2360, R:0.0106)
Batch 250/537: Loss=1.2414 (C:1.2414, R:0.0105)
Batch 275/537: Loss=1.2590 (C:1.2590, R:0.0105)
Batch 300/537: Loss=1.2277 (C:1.2277, R:0.0105)
Batch 325/537: Loss=1.2574 (C:1.2574, R:0.0105)
Batch 350/537: Loss=1.2434 (C:1.2434, R:0.0105)
Batch 375/537: Loss=1.2786 (C:1.2786, R:0.0105)
Batch 400/537: Loss=1.2504 (C:1.2504, R:0.0105)
Batch 425/537: Loss=1.2859 (C:1.2859, R:0.0105)
Batch 450/537: Loss=1.2960 (C:1.2960, R:0.0105)
Batch 475/537: Loss=1.3041 (C:1.3041, R:0.0105)
Batch 500/537: Loss=1.2538 (C:1.2538, R:0.0106)
Batch 525/537: Loss=1.2946 (C:1.2946, R:0.0105)

============================================================
Epoch 23/300 completed in 27.8s
Train: Loss=1.2571 (C:1.2571, R:0.0105) Ratio=3.73x
Val:   Loss=1.3704 (C:1.3704, R:0.0104) Ratio=2.99x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 24
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.726 ± 0.930
    Neg distances: 3.517 ± 1.606
    Separation ratio: 4.85x
    Gap: -6.436
    ✅ Excellent global separation!

Epoch 24 Training
----------------------------------------
Batch   0/537: Loss=1.2142 (C:1.2142, R:0.0105)
Batch  25/537: Loss=1.2519 (C:1.2519, R:0.0105)
Batch  50/537: Loss=1.2154 (C:1.2154, R:0.0105)
Batch  75/537: Loss=1.2442 (C:1.2442, R:0.0106)
Batch 100/537: Loss=1.2431 (C:1.2431, R:0.0105)
Batch 125/537: Loss=1.2352 (C:1.2352, R:0.0105)
Batch 150/537: Loss=1.2102 (C:1.2102, R:0.0105)
Batch 175/537: Loss=1.2332 (C:1.2332, R:0.0105)
Batch 200/537: Loss=1.2591 (C:1.2591, R:0.0105)
Batch 225/537: Loss=1.2846 (C:1.2846, R:0.0105)
Batch 250/537: Loss=1.2031 (C:1.2031, R:0.0105)
Batch 275/537: Loss=1.2128 (C:1.2128, R:0.0105)
Batch 300/537: Loss=1.2044 (C:1.2044, R:0.0105)
Batch 325/537: Loss=1.2640 (C:1.2640, R:0.0105)
Batch 350/537: Loss=1.2453 (C:1.2453, R:0.0105)
Batch 375/537: Loss=1.2147 (C:1.2147, R:0.0105)
Batch 400/537: Loss=1.2449 (C:1.2449, R:0.0105)
Batch 425/537: Loss=1.2403 (C:1.2403, R:0.0105)
Batch 450/537: Loss=1.2798 (C:1.2798, R:0.0106)
Batch 475/537: Loss=1.2504 (C:1.2504, R:0.0105)
Batch 500/537: Loss=1.2158 (C:1.2158, R:0.0105)
Batch 525/537: Loss=1.2787 (C:1.2787, R:0.0105)

============================================================
Epoch 24/300 completed in 28.3s
Train: Loss=1.2282 (C:1.2282, R:0.0105) Ratio=3.71x
Val:   Loss=1.3501 (C:1.3501, R:0.0104) Ratio=2.98x
Reconstruction weight: 0.000
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 25
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.690 ± 0.913
    Neg distances: 3.564 ± 1.605
    Separation ratio: 5.17x
    Gap: -6.343
    ✅ Excellent global separation!

Epoch 25 Training
----------------------------------------
Batch   0/537: Loss=1.1728 (C:1.1728, R:0.0105)
Batch  25/537: Loss=1.1322 (C:1.1322, R:0.0105)
Batch  50/537: Loss=1.1883 (C:1.1883, R:0.0105)
Batch  75/537: Loss=1.2220 (C:1.2220, R:0.0105)
Batch 100/537: Loss=1.2042 (C:1.2042, R:0.0105)
Batch 125/537: Loss=1.1313 (C:1.1313, R:0.0105)
Batch 150/537: Loss=1.1604 (C:1.1604, R:0.0105)
Batch 175/537: Loss=1.2063 (C:1.2063, R:0.0105)
Batch 200/537: Loss=1.2184 (C:1.2184, R:0.0105)
Batch 225/537: Loss=1.2226 (C:1.2226, R:0.0105)
Batch 250/537: Loss=1.1652 (C:1.1652, R:0.0105)
Batch 275/537: Loss=1.1724 (C:1.1724, R:0.0105)
Batch 300/537: Loss=1.1311 (C:1.1311, R:0.0105)
Batch 325/537: Loss=1.1611 (C:1.1611, R:0.0105)
Batch 350/537: Loss=1.1758 (C:1.1758, R:0.0105)
Batch 375/537: Loss=1.2000 (C:1.2000, R:0.0105)
Batch 400/537: Loss=1.2402 (C:1.2402, R:0.0105)
Batch 425/537: Loss=1.1210 (C:1.1210, R:0.0105)
Batch 450/537: Loss=1.1678 (C:1.1678, R:0.0105)
Batch 475/537: Loss=1.1375 (C:1.1375, R:0.0105)
Batch 500/537: Loss=1.2090 (C:1.2090, R:0.0105)
Batch 525/537: Loss=1.2386 (C:1.2386, R:0.0105)

============================================================
Epoch 25/300 completed in 27.7s
Train: Loss=1.1877 (C:1.1877, R:0.0105) Ratio=3.87x
Val:   Loss=1.2914 (C:1.2914, R:0.0104) Ratio=3.02x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.2914)
============================================================

🌍 Updating global dataset at epoch 26
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.681 ± 0.889
    Neg distances: 3.571 ± 1.597
    Separation ratio: 5.24x
    Gap: -6.266
    ✅ Excellent global separation!

Epoch 26 Training
----------------------------------------
Batch   0/537: Loss=1.1861 (C:1.1861, R:0.0105)
Batch  25/537: Loss=1.1572 (C:1.1572, R:0.0105)
Batch  50/537: Loss=1.1193 (C:1.1193, R:0.0105)
Batch  75/537: Loss=1.1775 (C:1.1775, R:0.0105)
Batch 100/537: Loss=1.2404 (C:1.2404, R:0.0105)
Batch 125/537: Loss=1.1815 (C:1.1815, R:0.0105)
Batch 150/537: Loss=1.2142 (C:1.2142, R:0.0105)
Batch 175/537: Loss=1.1633 (C:1.1633, R:0.0105)
Batch 200/537: Loss=1.2235 (C:1.2235, R:0.0105)
Batch 225/537: Loss=1.1922 (C:1.1922, R:0.0105)
Batch 250/537: Loss=1.1797 (C:1.1797, R:0.0105)
Batch 275/537: Loss=1.1356 (C:1.1356, R:0.0105)
Batch 300/537: Loss=1.2047 (C:1.2047, R:0.0105)
Batch 325/537: Loss=1.1670 (C:1.1670, R:0.0105)
Batch 350/537: Loss=1.1736 (C:1.1736, R:0.0105)
Batch 375/537: Loss=1.1792 (C:1.1792, R:0.0105)
Batch 400/537: Loss=1.2207 (C:1.2207, R:0.0105)
Batch 425/537: Loss=1.2337 (C:1.2337, R:0.0105)
Batch 450/537: Loss=1.1371 (C:1.1371, R:0.0105)
Batch 475/537: Loss=1.1294 (C:1.1294, R:0.0105)
Batch 500/537: Loss=1.1681 (C:1.1681, R:0.0105)
Batch 525/537: Loss=1.2123 (C:1.2123, R:0.0105)

============================================================
Epoch 26/300 completed in 27.0s
Train: Loss=1.1736 (C:1.1736, R:0.0105) Ratio=3.78x
Val:   Loss=1.3014 (C:1.3014, R:0.0104) Ratio=2.99x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 27
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.716 ± 0.968
    Neg distances: 3.607 ± 1.630
    Separation ratio: 5.04x
    Gap: -6.789
    ✅ Excellent global separation!

Epoch 27 Training
----------------------------------------
Batch   0/537: Loss=1.1459 (C:1.1459, R:0.0105)
Batch  25/537: Loss=1.2220 (C:1.2220, R:0.0105)
Batch  50/537: Loss=1.1745 (C:1.1745, R:0.0105)
Batch  75/537: Loss=1.1487 (C:1.1487, R:0.0105)
Batch 100/537: Loss=1.1500 (C:1.1500, R:0.0105)
Batch 125/537: Loss=1.1793 (C:1.1793, R:0.0105)
Batch 150/537: Loss=1.2370 (C:1.2370, R:0.0105)
Batch 175/537: Loss=1.1925 (C:1.1925, R:0.0105)
Batch 200/537: Loss=1.2004 (C:1.2004, R:0.0105)
Batch 225/537: Loss=1.1808 (C:1.1808, R:0.0105)
Batch 250/537: Loss=1.1677 (C:1.1677, R:0.0105)
Batch 275/537: Loss=1.1844 (C:1.1844, R:0.0105)
Batch 300/537: Loss=1.1910 (C:1.1910, R:0.0105)
Batch 325/537: Loss=1.2138 (C:1.2138, R:0.0105)
Batch 350/537: Loss=1.1999 (C:1.1999, R:0.0105)
Batch 375/537: Loss=1.1939 (C:1.1939, R:0.0105)
Batch 400/537: Loss=1.2030 (C:1.2030, R:0.0105)
Batch 425/537: Loss=1.2434 (C:1.2434, R:0.0105)
Batch 450/537: Loss=1.1602 (C:1.1602, R:0.0105)
Batch 475/537: Loss=1.2791 (C:1.2791, R:0.0106)
Batch 500/537: Loss=1.2188 (C:1.2188, R:0.0105)
Batch 525/537: Loss=1.2354 (C:1.2354, R:0.0105)

============================================================
Epoch 27/300 completed in 27.7s
Train: Loss=1.1876 (C:1.1876, R:0.0105) Ratio=3.85x
Val:   Loss=1.3200 (C:1.3200, R:0.0104) Ratio=3.00x
Reconstruction weight: 0.000
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 28
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.709 ± 0.917
    Neg distances: 3.603 ± 1.627
    Separation ratio: 5.08x
    Gap: -6.543
    ✅ Excellent global separation!

Epoch 28 Training
----------------------------------------
Batch   0/537: Loss=1.1940 (C:1.1940, R:0.0105)
Batch  25/537: Loss=1.1393 (C:1.1393, R:0.0105)
Batch  50/537: Loss=1.1860 (C:1.1860, R:0.0105)
Batch  75/537: Loss=1.2050 (C:1.2050, R:0.0105)
Batch 100/537: Loss=1.1226 (C:1.1226, R:0.0105)
Batch 125/537: Loss=1.1526 (C:1.1526, R:0.0105)
Batch 150/537: Loss=1.1955 (C:1.1955, R:0.0105)
Batch 175/537: Loss=1.1404 (C:1.1404, R:0.0105)
Batch 200/537: Loss=1.1621 (C:1.1621, R:0.0106)
Batch 225/537: Loss=1.1366 (C:1.1366, R:0.0105)
Batch 250/537: Loss=1.1525 (C:1.1525, R:0.0105)
Batch 275/537: Loss=1.2138 (C:1.2138, R:0.0105)
Batch 300/537: Loss=1.1779 (C:1.1779, R:0.0105)
Batch 325/537: Loss=1.1556 (C:1.1556, R:0.0105)
Batch 350/537: Loss=1.2317 (C:1.2317, R:0.0105)
Batch 375/537: Loss=1.1998 (C:1.1998, R:0.0105)
Batch 400/537: Loss=1.2086 (C:1.2086, R:0.0105)
Batch 425/537: Loss=1.2155 (C:1.2155, R:0.0105)
Batch 450/537: Loss=1.1826 (C:1.1826, R:0.0105)
Batch 475/537: Loss=1.2217 (C:1.2217, R:0.0105)
Batch 500/537: Loss=1.1937 (C:1.1937, R:0.0105)
Batch 525/537: Loss=1.1721 (C:1.1721, R:0.0105)

============================================================
Epoch 28/300 completed in 27.4s
Train: Loss=1.1770 (C:1.1770, R:0.0105) Ratio=3.86x
Val:   Loss=1.2983 (C:1.2983, R:0.0104) Ratio=3.01x
Reconstruction weight: 0.000
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 29
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.700 ± 0.933
    Neg distances: 3.623 ± 1.629
    Separation ratio: 5.18x
    Gap: -6.731
    ✅ Excellent global separation!

Epoch 29 Training
----------------------------------------
Batch   0/537: Loss=1.1674 (C:1.1674, R:0.0105)
Batch  25/537: Loss=1.1390 (C:1.1390, R:0.0105)
Batch  50/537: Loss=1.1181 (C:1.1181, R:0.0105)
Batch  75/537: Loss=1.1628 (C:1.1628, R:0.0105)
Batch 100/537: Loss=1.1644 (C:1.1644, R:0.0105)
Batch 125/537: Loss=1.1729 (C:1.1729, R:0.0105)
Batch 150/537: Loss=1.1528 (C:1.1528, R:0.0105)
Batch 175/537: Loss=1.1696 (C:1.1696, R:0.0105)
Batch 200/537: Loss=1.1582 (C:1.1582, R:0.0105)
Batch 225/537: Loss=1.0972 (C:1.0972, R:0.0105)
Batch 250/537: Loss=1.1852 (C:1.1852, R:0.0105)
Batch 275/537: Loss=1.1638 (C:1.1638, R:0.0105)
Batch 300/537: Loss=1.1719 (C:1.1719, R:0.0105)
Batch 325/537: Loss=1.1982 (C:1.1982, R:0.0105)
Batch 350/537: Loss=1.2147 (C:1.2147, R:0.0105)
Batch 375/537: Loss=1.1182 (C:1.1182, R:0.0105)
Batch 400/537: Loss=1.2510 (C:1.2510, R:0.0105)
Batch 425/537: Loss=1.2191 (C:1.2191, R:0.0105)
Batch 450/537: Loss=1.1906 (C:1.1906, R:0.0105)
Batch 475/537: Loss=1.1633 (C:1.1633, R:0.0105)
Batch 500/537: Loss=1.1773 (C:1.1773, R:0.0105)
Batch 525/537: Loss=1.2014 (C:1.2014, R:0.0105)

============================================================
Epoch 29/300 completed in 27.0s
Train: Loss=1.1628 (C:1.1628, R:0.0105) Ratio=3.88x
Val:   Loss=1.2934 (C:1.2934, R:0.0104) Ratio=3.02x
Reconstruction weight: 0.000
No improvement for 4 epochs
============================================================

🌍 Updating global dataset at epoch 30
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.682 ± 0.927
    Neg distances: 3.638 ± 1.617
    Separation ratio: 5.33x
    Gap: -6.555
    ✅ Excellent global separation!

Epoch 30 Training
----------------------------------------
Batch   0/537: Loss=1.0929 (C:1.0929, R:0.0105)
Batch  25/537: Loss=1.1399 (C:1.1399, R:0.0105)
Batch  50/537: Loss=1.1651 (C:1.1651, R:0.0105)
Batch  75/537: Loss=1.1075 (C:1.1075, R:0.0105)
Batch 100/537: Loss=1.1133 (C:1.1133, R:0.0105)
Batch 125/537: Loss=1.1182 (C:1.1182, R:0.0105)
Batch 150/537: Loss=1.1476 (C:1.1476, R:0.0105)
Batch 175/537: Loss=1.1350 (C:1.1350, R:0.0105)
Batch 200/537: Loss=1.1542 (C:1.1542, R:0.0105)
Batch 225/537: Loss=1.1644 (C:1.1644, R:0.0105)
Batch 250/537: Loss=1.1191 (C:1.1191, R:0.0105)
Batch 275/537: Loss=1.1319 (C:1.1319, R:0.0105)
Batch 300/537: Loss=1.1341 (C:1.1341, R:0.0105)
Batch 325/537: Loss=1.1253 (C:1.1253, R:0.0105)
Batch 350/537: Loss=1.1451 (C:1.1451, R:0.0105)
Batch 375/537: Loss=1.1562 (C:1.1562, R:0.0105)
Batch 400/537: Loss=1.1416 (C:1.1416, R:0.0106)
Batch 425/537: Loss=1.1736 (C:1.1736, R:0.0105)
Batch 450/537: Loss=1.1898 (C:1.1898, R:0.0105)
Batch 475/537: Loss=1.1785 (C:1.1785, R:0.0105)
Batch 500/537: Loss=1.1457 (C:1.1457, R:0.0105)
Batch 525/537: Loss=1.1385 (C:1.1385, R:0.0105)

============================================================
Epoch 30/300 completed in 27.0s
Train: Loss=1.1365 (C:1.1365, R:0.0105) Ratio=3.95x
Val:   Loss=1.2798 (C:1.2798, R:0.0104) Ratio=3.01x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.2798)
============================================================

🌍 Updating global dataset at epoch 31
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.697 ± 0.971
    Neg distances: 3.751 ± 1.668
    Separation ratio: 5.38x
    Gap: -6.723
    ✅ Excellent global separation!

Epoch 31 Training
----------------------------------------
Batch   0/537: Loss=1.2089 (C:1.2089, R:0.0105)
Batch  25/537: Loss=1.0712 (C:1.0712, R:0.0105)
Batch  50/537: Loss=1.1067 (C:1.1067, R:0.0105)
Batch  75/537: Loss=1.1661 (C:1.1661, R:0.0105)
Batch 100/537: Loss=1.0997 (C:1.0997, R:0.0105)
Batch 125/537: Loss=1.1256 (C:1.1256, R:0.0105)
Batch 150/537: Loss=1.1625 (C:1.1625, R:0.0105)
Batch 175/537: Loss=1.1059 (C:1.1059, R:0.0105)
Batch 200/537: Loss=1.1642 (C:1.1642, R:0.0106)
Batch 225/537: Loss=1.1443 (C:1.1443, R:0.0105)
Batch 250/537: Loss=1.1383 (C:1.1383, R:0.0105)
Batch 275/537: Loss=1.1541 (C:1.1541, R:0.0105)
Batch 300/537: Loss=1.1591 (C:1.1591, R:0.0105)
Batch 325/537: Loss=1.1496 (C:1.1496, R:0.0105)
Batch 350/537: Loss=1.1037 (C:1.1037, R:0.0105)
Batch 375/537: Loss=1.1671 (C:1.1671, R:0.0105)
Batch 400/537: Loss=1.1282 (C:1.1282, R:0.0105)
Batch 425/537: Loss=1.1539 (C:1.1539, R:0.0105)
Batch 450/537: Loss=1.1299 (C:1.1299, R:0.0105)
Batch 475/537: Loss=1.0756 (C:1.0756, R:0.0105)
Batch 500/537: Loss=1.1208 (C:1.1208, R:0.0105)
Batch 525/537: Loss=1.0882 (C:1.0882, R:0.0105)

============================================================
Epoch 31/300 completed in 27.0s
Train: Loss=1.1340 (C:1.1340, R:0.0105) Ratio=4.04x
Val:   Loss=1.2752 (C:1.2752, R:0.0104) Ratio=3.00x
Reconstruction weight: 0.015
✅ New best model saved (Val Loss: 1.2752)
============================================================

🌍 Updating global dataset at epoch 32
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.683 ± 0.937
    Neg distances: 3.746 ± 1.666
    Separation ratio: 5.48x
    Gap: -6.633
    ✅ Excellent global separation!

Epoch 32 Training
----------------------------------------
Batch   0/537: Loss=1.1222 (C:1.1222, R:0.0105)
Batch  25/537: Loss=1.0900 (C:1.0900, R:0.0105)
Batch  50/537: Loss=1.1187 (C:1.1187, R:0.0105)
Batch  75/537: Loss=1.1565 (C:1.1565, R:0.0105)
Batch 100/537: Loss=1.1474 (C:1.1474, R:0.0105)
Batch 125/537: Loss=1.0791 (C:1.0791, R:0.0106)
Batch 150/537: Loss=1.1083 (C:1.1083, R:0.0105)
Batch 175/537: Loss=1.0691 (C:1.0691, R:0.0105)
Batch 200/537: Loss=1.1052 (C:1.1052, R:0.0105)
Batch 225/537: Loss=1.1626 (C:1.1626, R:0.0105)
Batch 250/537: Loss=1.1478 (C:1.1478, R:0.0105)
Batch 275/537: Loss=1.0906 (C:1.0906, R:0.0105)
Batch 300/537: Loss=1.1247 (C:1.1247, R:0.0105)
Batch 325/537: Loss=1.1987 (C:1.1987, R:0.0104)
Batch 350/537: Loss=1.1051 (C:1.1051, R:0.0105)
Batch 375/537: Loss=1.1713 (C:1.1713, R:0.0105)
Batch 400/537: Loss=1.0872 (C:1.0872, R:0.0105)
Batch 425/537: Loss=1.1299 (C:1.1299, R:0.0105)
Batch 450/537: Loss=1.1046 (C:1.1046, R:0.0105)
Batch 475/537: Loss=1.1131 (C:1.1131, R:0.0105)
Batch 500/537: Loss=1.1415 (C:1.1415, R:0.0105)
Batch 525/537: Loss=1.1387 (C:1.1387, R:0.0105)

============================================================
Epoch 32/300 completed in 27.0s
Train: Loss=1.1189 (C:1.1189, R:0.0105) Ratio=4.06x
Val:   Loss=1.2886 (C:1.2886, R:0.0104) Ratio=2.99x
Reconstruction weight: 0.030
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 33
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.666 ± 0.905
    Neg distances: 3.707 ± 1.631
    Separation ratio: 5.57x
    Gap: -6.599
    ✅ Excellent global separation!

Epoch 33 Training
----------------------------------------
Batch   0/537: Loss=1.0721 (C:1.0721, R:0.0105)
Batch  25/537: Loss=1.0705 (C:1.0705, R:0.0105)
Batch  50/537: Loss=1.0768 (C:1.0768, R:0.0105)
Batch  75/537: Loss=1.0375 (C:1.0375, R:0.0105)
Batch 100/537: Loss=1.0566 (C:1.0566, R:0.0106)
Batch 125/537: Loss=1.0280 (C:1.0280, R:0.0105)
Batch 150/537: Loss=1.0882 (C:1.0882, R:0.0105)
Batch 175/537: Loss=1.0398 (C:1.0398, R:0.0105)
Batch 200/537: Loss=1.0892 (C:1.0892, R:0.0105)
Batch 225/537: Loss=1.1021 (C:1.1021, R:0.0105)
Batch 250/537: Loss=1.0790 (C:1.0790, R:0.0105)
Batch 275/537: Loss=1.0821 (C:1.0821, R:0.0105)
Batch 300/537: Loss=1.0451 (C:1.0451, R:0.0105)
Batch 325/537: Loss=1.0642 (C:1.0642, R:0.0105)
Batch 350/537: Loss=1.1240 (C:1.1240, R:0.0105)
Batch 375/537: Loss=1.1314 (C:1.1314, R:0.0105)
Batch 400/537: Loss=1.1037 (C:1.1037, R:0.0105)
Batch 425/537: Loss=1.1133 (C:1.1133, R:0.0105)
Batch 450/537: Loss=1.0665 (C:1.0665, R:0.0105)
Batch 475/537: Loss=1.0844 (C:1.0844, R:0.0105)
Batch 500/537: Loss=1.0899 (C:1.0899, R:0.0105)
Batch 525/537: Loss=1.1358 (C:1.1358, R:0.0105)

============================================================
Epoch 33/300 completed in 26.9s
Train: Loss=1.1029 (C:1.1029, R:0.0105) Ratio=4.16x
Val:   Loss=1.2678 (C:1.2678, R:0.0104) Ratio=2.99x
Reconstruction weight: 0.045
✅ New best model saved (Val Loss: 1.2678)
============================================================

🌍 Updating global dataset at epoch 34
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.640 ± 0.876
    Neg distances: 3.754 ± 1.644
    Separation ratio: 5.86x
    Gap: -6.845
    ✅ Excellent global separation!

Epoch 34 Training
----------------------------------------
Batch   0/537: Loss=1.0463 (C:1.0463, R:0.0105)
Batch  25/537: Loss=1.0523 (C:1.0523, R:0.0105)
Batch  50/537: Loss=1.0206 (C:1.0206, R:0.0105)
Batch  75/537: Loss=1.0589 (C:1.0589, R:0.0105)
Batch 100/537: Loss=1.1033 (C:1.1033, R:0.0105)
Batch 125/537: Loss=1.0617 (C:1.0617, R:0.0105)
Batch 150/537: Loss=1.0753 (C:1.0753, R:0.0105)
Batch 175/537: Loss=1.0999 (C:1.0999, R:0.0105)
Batch 200/537: Loss=1.0485 (C:1.0485, R:0.0105)
Batch 225/537: Loss=1.0217 (C:1.0217, R:0.0105)
Batch 250/537: Loss=1.1108 (C:1.1108, R:0.0105)
Batch 275/537: Loss=1.0659 (C:1.0659, R:0.0105)
Batch 300/537: Loss=1.0986 (C:1.0986, R:0.0105)
Batch 325/537: Loss=1.0892 (C:1.0892, R:0.0105)
Batch 350/537: Loss=1.1042 (C:1.1042, R:0.0105)
Batch 375/537: Loss=1.0633 (C:1.0633, R:0.0105)
Batch 400/537: Loss=1.1043 (C:1.1043, R:0.0105)
Batch 425/537: Loss=1.0570 (C:1.0570, R:0.0105)
Batch 450/537: Loss=1.0896 (C:1.0896, R:0.0105)
Batch 475/537: Loss=1.1064 (C:1.1064, R:0.0105)
Batch 500/537: Loss=1.1118 (C:1.1118, R:0.0105)
Batch 525/537: Loss=1.0979 (C:1.0979, R:0.0105)

============================================================
Epoch 34/300 completed in 26.6s
Train: Loss=1.0782 (C:1.0782, R:0.0105) Ratio=4.09x
Val:   Loss=1.2426 (C:1.2426, R:0.0104) Ratio=2.99x
Reconstruction weight: 0.060
✅ New best model saved (Val Loss: 1.2426)
============================================================

🌍 Updating global dataset at epoch 35
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.654 ± 0.923
    Neg distances: 3.755 ± 1.652
    Separation ratio: 5.75x
    Gap: -6.735
    ✅ Excellent global separation!

Epoch 35 Training
----------------------------------------
Batch   0/537: Loss=1.0997 (C:1.0997, R:0.0105)
Batch  25/537: Loss=1.0304 (C:1.0304, R:0.0105)
Batch  50/537: Loss=1.0189 (C:1.0189, R:0.0105)
Batch  75/537: Loss=1.0640 (C:1.0640, R:0.0105)
Batch 100/537: Loss=1.0753 (C:1.0753, R:0.0105)
Batch 125/537: Loss=1.0685 (C:1.0685, R:0.0105)
Batch 150/537: Loss=1.0469 (C:1.0469, R:0.0105)
Batch 175/537: Loss=1.0620 (C:1.0620, R:0.0105)
Batch 200/537: Loss=1.0860 (C:1.0860, R:0.0105)
Batch 225/537: Loss=1.0242 (C:1.0242, R:0.0105)
Batch 250/537: Loss=1.0768 (C:1.0768, R:0.0105)
Batch 275/537: Loss=1.0646 (C:1.0646, R:0.0105)
Batch 300/537: Loss=1.0804 (C:1.0804, R:0.0105)
Batch 325/537: Loss=1.0900 (C:1.0900, R:0.0106)
Batch 350/537: Loss=1.0863 (C:1.0863, R:0.0105)
Batch 375/537: Loss=1.0349 (C:1.0349, R:0.0105)
Batch 400/537: Loss=1.0804 (C:1.0804, R:0.0105)
Batch 425/537: Loss=1.0675 (C:1.0675, R:0.0105)
Batch 450/537: Loss=1.0957 (C:1.0957, R:0.0105)
Batch 475/537: Loss=1.0992 (C:1.0992, R:0.0105)
Batch 500/537: Loss=1.1037 (C:1.1037, R:0.0105)
Batch 525/537: Loss=1.0898 (C:1.0898, R:0.0105)

============================================================
Epoch 35/300 completed in 27.1s
Train: Loss=1.0806 (C:1.0806, R:0.0105) Ratio=4.19x
Val:   Loss=1.2486 (C:1.2486, R:0.0104) Ratio=2.99x
Reconstruction weight: 0.075
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 36
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.650 ± 0.891
    Neg distances: 3.783 ± 1.657
    Separation ratio: 5.82x
    Gap: -6.802
    ✅ Excellent global separation!

Epoch 36 Training
----------------------------------------
Batch   0/537: Loss=1.0573 (C:1.0573, R:0.0105)
Batch  25/537: Loss=1.0390 (C:1.0390, R:0.0105)
Batch  50/537: Loss=1.0311 (C:1.0311, R:0.0105)
Batch  75/537: Loss=1.1122 (C:1.1122, R:0.0105)
Batch 100/537: Loss=1.0367 (C:1.0367, R:0.0106)
Batch 125/537: Loss=1.1078 (C:1.1078, R:0.0105)
Batch 150/537: Loss=1.0468 (C:1.0468, R:0.0105)
Batch 175/537: Loss=1.0630 (C:1.0630, R:0.0105)
Batch 200/537: Loss=1.1395 (C:1.1395, R:0.0105)
Batch 225/537: Loss=1.1170 (C:1.1170, R:0.0105)
Batch 250/537: Loss=1.1242 (C:1.1242, R:0.0105)
Batch 275/537: Loss=1.1219 (C:1.1219, R:0.0105)
Batch 300/537: Loss=1.0884 (C:1.0884, R:0.0105)
Batch 325/537: Loss=1.0308 (C:1.0308, R:0.0105)
Batch 350/537: Loss=1.1340 (C:1.1340, R:0.0105)
Batch 375/537: Loss=1.0587 (C:1.0587, R:0.0105)
Batch 400/537: Loss=1.0363 (C:1.0363, R:0.0105)
Batch 425/537: Loss=1.0974 (C:1.0974, R:0.0105)
Batch 450/537: Loss=1.0795 (C:1.0795, R:0.0105)
Batch 475/537: Loss=1.1243 (C:1.1243, R:0.0105)
Batch 500/537: Loss=1.0181 (C:1.0181, R:0.0105)
Batch 525/537: Loss=1.0230 (C:1.0230, R:0.0105)

============================================================
Epoch 36/300 completed in 26.7s
Train: Loss=1.0726 (C:1.0726, R:0.0105) Ratio=4.09x
Val:   Loss=1.2313 (C:1.2313, R:0.0104) Ratio=3.00x
Reconstruction weight: 0.090
✅ New best model saved (Val Loss: 1.2313)
============================================================

🌍 Updating global dataset at epoch 37
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.674 ± 0.966
    Neg distances: 3.823 ± 1.683
    Separation ratio: 5.68x
    Gap: -6.779
    ✅ Excellent global separation!

Epoch 37 Training
----------------------------------------
Batch   0/537: Loss=1.1173 (C:1.1173, R:0.0105)
Batch  25/537: Loss=1.1230 (C:1.1230, R:0.0105)
Batch  50/537: Loss=1.0692 (C:1.0692, R:0.0105)
Batch  75/537: Loss=1.0424 (C:1.0424, R:0.0105)
Batch 100/537: Loss=1.0698 (C:1.0698, R:0.0105)
Batch 125/537: Loss=1.0260 (C:1.0260, R:0.0105)
Batch 150/537: Loss=1.0766 (C:1.0766, R:0.0105)
Batch 175/537: Loss=1.0454 (C:1.0454, R:0.0105)
Batch 200/537: Loss=1.0657 (C:1.0657, R:0.0105)
Batch 225/537: Loss=1.0848 (C:1.0848, R:0.0105)
Batch 250/537: Loss=1.0757 (C:1.0757, R:0.0105)
Batch 275/537: Loss=1.0800 (C:1.0800, R:0.0105)
Batch 300/537: Loss=1.0798 (C:1.0798, R:0.0105)
Batch 325/537: Loss=1.0500 (C:1.0500, R:0.0105)
Batch 350/537: Loss=1.0864 (C:1.0864, R:0.0105)
Batch 375/537: Loss=1.1238 (C:1.1238, R:0.0105)
Batch 400/537: Loss=1.0204 (C:1.0204, R:0.0105)
Batch 425/537: Loss=1.0546 (C:1.0546, R:0.0105)
Batch 450/537: Loss=1.0815 (C:1.0815, R:0.0105)
Batch 475/537: Loss=1.0769 (C:1.0769, R:0.0105)
Batch 500/537: Loss=1.0915 (C:1.0915, R:0.0105)
Batch 525/537: Loss=1.1124 (C:1.1124, R:0.0105)

============================================================
Epoch 37/300 completed in 26.6s
Train: Loss=1.0815 (C:1.0815, R:0.0105) Ratio=4.21x
Val:   Loss=1.2500 (C:1.2500, R:0.0104) Ratio=3.01x
Reconstruction weight: 0.105
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 38
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.652 ± 0.929
    Neg distances: 3.782 ± 1.656
    Separation ratio: 5.80x
    Gap: -7.107
    ✅ Excellent global separation!

Epoch 38 Training
----------------------------------------
Batch   0/537: Loss=1.0498 (C:1.0498, R:0.0105)
Batch  25/537: Loss=1.0125 (C:1.0125, R:0.0105)
Batch  50/537: Loss=1.0281 (C:1.0281, R:0.0105)
Batch  75/537: Loss=1.0754 (C:1.0754, R:0.0105)
Batch 100/537: Loss=1.0676 (C:1.0676, R:0.0105)
Batch 125/537: Loss=1.0433 (C:1.0433, R:0.0105)
Batch 150/537: Loss=1.0115 (C:1.0115, R:0.0105)
Batch 175/537: Loss=1.0459 (C:1.0459, R:0.0105)
Batch 200/537: Loss=1.0825 (C:1.0825, R:0.0105)
Batch 225/537: Loss=1.0696 (C:1.0696, R:0.0105)
Batch 250/537: Loss=1.0998 (C:1.0998, R:0.0105)
Batch 275/537: Loss=1.0464 (C:1.0464, R:0.0105)
Batch 300/537: Loss=1.0855 (C:1.0855, R:0.0106)
Batch 325/537: Loss=1.0552 (C:1.0552, R:0.0105)
Batch 350/537: Loss=1.0660 (C:1.0660, R:0.0105)
Batch 375/537: Loss=1.0456 (C:1.0456, R:0.0105)
Batch 400/537: Loss=1.0542 (C:1.0542, R:0.0105)
Batch 425/537: Loss=1.1373 (C:1.1373, R:0.0105)
Batch 450/537: Loss=1.0639 (C:1.0639, R:0.0105)
Batch 475/537: Loss=1.1013 (C:1.1013, R:0.0105)
Batch 500/537: Loss=1.1034 (C:1.1034, R:0.0105)
Batch 525/537: Loss=1.0943 (C:1.0943, R:0.0105)

============================================================
Epoch 38/300 completed in 26.7s
Train: Loss=1.0646 (C:1.0646, R:0.0105) Ratio=4.25x
Val:   Loss=1.2278 (C:1.2278, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.120
✅ New best model saved (Val Loss: 1.2278)
============================================================

🌍 Updating global dataset at epoch 39
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.630 ± 0.921
    Neg distances: 3.818 ± 1.661
    Separation ratio: 6.06x
    Gap: -6.731
    ✅ Excellent global separation!

Epoch 39 Training
----------------------------------------
Batch   0/537: Loss=1.0213 (C:1.0213, R:0.0105)
Batch  25/537: Loss=0.9948 (C:0.9948, R:0.0105)
Batch  50/537: Loss=1.0547 (C:1.0547, R:0.0105)
Batch  75/537: Loss=1.0888 (C:1.0888, R:0.0105)
Batch 100/537: Loss=1.1212 (C:1.1212, R:0.0105)
Batch 125/537: Loss=1.0653 (C:1.0653, R:0.0105)
Batch 150/537: Loss=1.0141 (C:1.0141, R:0.0105)
Batch 175/537: Loss=1.0724 (C:1.0724, R:0.0105)
Batch 200/537: Loss=1.0175 (C:1.0175, R:0.0105)
Batch 225/537: Loss=1.0500 (C:1.0500, R:0.0105)
Batch 250/537: Loss=1.0255 (C:1.0255, R:0.0105)
Batch 275/537: Loss=0.9757 (C:0.9757, R:0.0105)
Batch 300/537: Loss=1.0959 (C:1.0959, R:0.0105)
Batch 325/537: Loss=1.0304 (C:1.0304, R:0.0105)
Batch 350/537: Loss=1.0322 (C:1.0322, R:0.0105)
Batch 375/537: Loss=1.0693 (C:1.0693, R:0.0105)
Batch 400/537: Loss=1.0658 (C:1.0658, R:0.0105)
Batch 425/537: Loss=1.0590 (C:1.0590, R:0.0105)
Batch 450/537: Loss=1.1191 (C:1.1191, R:0.0105)
Batch 475/537: Loss=1.1095 (C:1.1095, R:0.0105)
Batch 500/537: Loss=1.0458 (C:1.0458, R:0.0105)
Batch 525/537: Loss=1.1090 (C:1.1090, R:0.0105)

============================================================
Epoch 39/300 completed in 27.5s
Train: Loss=1.0447 (C:1.0447, R:0.0105) Ratio=4.18x
Val:   Loss=1.2212 (C:1.2212, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.135
✅ New best model saved (Val Loss: 1.2212)
============================================================

🌍 Updating global dataset at epoch 40
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.651 ± 0.959
    Neg distances: 3.827 ± 1.683
    Separation ratio: 5.88x
    Gap: -6.767
    ✅ Excellent global separation!

Epoch 40 Training
----------------------------------------
Batch   0/537: Loss=0.9910 (C:0.9910, R:0.0105)
Batch  25/537: Loss=1.0575 (C:1.0575, R:0.0105)
Batch  50/537: Loss=1.0366 (C:1.0366, R:0.0105)
Batch  75/537: Loss=1.0468 (C:1.0468, R:0.0105)
Batch 100/537: Loss=1.0935 (C:1.0935, R:0.0105)
Batch 125/537: Loss=1.0377 (C:1.0377, R:0.0105)
Batch 150/537: Loss=1.0432 (C:1.0432, R:0.0105)
Batch 175/537: Loss=1.0501 (C:1.0501, R:0.0105)
Batch 200/537: Loss=1.0498 (C:1.0498, R:0.0105)
Batch 225/537: Loss=1.0316 (C:1.0316, R:0.0105)
Batch 250/537: Loss=1.1507 (C:1.1507, R:0.0105)
Batch 275/537: Loss=1.0378 (C:1.0378, R:0.0105)
Batch 300/537: Loss=1.0971 (C:1.0971, R:0.0105)
Batch 325/537: Loss=1.0199 (C:1.0199, R:0.0105)
Batch 350/537: Loss=1.0451 (C:1.0451, R:0.0105)
Batch 375/537: Loss=1.0586 (C:1.0586, R:0.0105)
Batch 400/537: Loss=1.0247 (C:1.0247, R:0.0105)
Batch 425/537: Loss=1.0576 (C:1.0576, R:0.0105)
Batch 450/537: Loss=1.0528 (C:1.0528, R:0.0105)
Batch 475/537: Loss=1.0986 (C:1.0986, R:0.0105)
Batch 500/537: Loss=1.0762 (C:1.0762, R:0.0105)
Batch 525/537: Loss=1.1117 (C:1.1117, R:0.0105)

============================================================
Epoch 40/300 completed in 27.1s
Train: Loss=1.0553 (C:1.0553, R:0.0105) Ratio=4.28x
Val:   Loss=1.2312 (C:1.2312, R:0.0104) Ratio=3.03x
Reconstruction weight: 0.150
No improvement for 1 epochs
Checkpoint saved at epoch 40
============================================================

🌍 Updating global dataset at epoch 41
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.639 ± 0.940
    Neg distances: 3.803 ± 1.667
    Separation ratio: 5.95x
    Gap: -6.734
    ✅ Excellent global separation!

Epoch 41 Training
----------------------------------------
Batch   0/537: Loss=1.0344 (C:1.0344, R:0.0105)
Batch  25/537: Loss=1.0358 (C:1.0358, R:0.0105)
Batch  50/537: Loss=1.0347 (C:1.0347, R:0.0105)
Batch  75/537: Loss=1.0187 (C:1.0187, R:0.0105)
Batch 100/537: Loss=0.9587 (C:0.9587, R:0.0105)
Batch 125/537: Loss=1.0521 (C:1.0521, R:0.0105)
Batch 150/537: Loss=1.0001 (C:1.0001, R:0.0105)
Batch 175/537: Loss=1.1042 (C:1.1042, R:0.0105)
Batch 200/537: Loss=1.0560 (C:1.0560, R:0.0105)
Batch 225/537: Loss=1.0657 (C:1.0657, R:0.0105)
Batch 250/537: Loss=1.0129 (C:1.0129, R:0.0105)
Batch 275/537: Loss=1.0559 (C:1.0559, R:0.0105)
Batch 300/537: Loss=1.0313 (C:1.0313, R:0.0105)
Batch 325/537: Loss=1.0469 (C:1.0469, R:0.0105)
Batch 350/537: Loss=1.0375 (C:1.0375, R:0.0105)
Batch 375/537: Loss=1.1021 (C:1.1021, R:0.0105)
Batch 400/537: Loss=1.0603 (C:1.0603, R:0.0105)
Batch 425/537: Loss=1.0970 (C:1.0970, R:0.0105)
Batch 450/537: Loss=1.0403 (C:1.0403, R:0.0105)
Batch 475/537: Loss=1.0456 (C:1.0456, R:0.0105)
Batch 500/537: Loss=1.0249 (C:1.0249, R:0.0105)
Batch 525/537: Loss=1.1042 (C:1.1042, R:0.0105)

============================================================
Epoch 41/300 completed in 27.1s
Train: Loss=1.0437 (C:1.0437, R:0.0105) Ratio=4.27x
Val:   Loss=1.2166 (C:1.2166, R:0.0104) Ratio=3.03x
Reconstruction weight: 0.165
✅ New best model saved (Val Loss: 1.2166)
============================================================

🌍 Updating global dataset at epoch 42
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.618 ± 0.922
    Neg distances: 3.826 ± 1.657
    Separation ratio: 6.19x
    Gap: -6.754
    ✅ Excellent global separation!

Epoch 42 Training
----------------------------------------
Batch   0/537: Loss=1.0059 (C:1.0059, R:0.0105)
Batch  25/537: Loss=0.9873 (C:0.9873, R:0.0105)
Batch  50/537: Loss=0.9837 (C:0.9837, R:0.0105)
Batch  75/537: Loss=1.0256 (C:1.0256, R:0.0105)
Batch 100/537: Loss=1.0118 (C:1.0118, R:0.0105)
Batch 125/537: Loss=0.9647 (C:0.9647, R:0.0105)
Batch 150/537: Loss=0.9462 (C:0.9462, R:0.0105)
Batch 175/537: Loss=0.9865 (C:0.9865, R:0.0105)
Batch 200/537: Loss=1.0173 (C:1.0173, R:0.0105)
Batch 225/537: Loss=1.0193 (C:1.0193, R:0.0105)
Batch 250/537: Loss=1.0420 (C:1.0420, R:0.0105)
Batch 275/537: Loss=1.0613 (C:1.0613, R:0.0106)
Batch 300/537: Loss=1.0230 (C:1.0230, R:0.0105)
Batch 325/537: Loss=1.0421 (C:1.0421, R:0.0105)
Batch 350/537: Loss=1.0193 (C:1.0193, R:0.0105)
Batch 375/537: Loss=0.9755 (C:0.9755, R:0.0105)
Batch 400/537: Loss=0.9981 (C:0.9981, R:0.0105)
Batch 425/537: Loss=1.0304 (C:1.0304, R:0.0105)
Batch 450/537: Loss=1.0590 (C:1.0590, R:0.0105)
Batch 475/537: Loss=1.0154 (C:1.0154, R:0.0106)
Batch 500/537: Loss=1.0776 (C:1.0776, R:0.0105)
Batch 525/537: Loss=1.0469 (C:1.0469, R:0.0105)

============================================================
Epoch 42/300 completed in 27.1s
Train: Loss=1.0209 (C:1.0209, R:0.0105) Ratio=4.35x
Val:   Loss=1.2030 (C:1.2030, R:0.0104) Ratio=3.03x
Reconstruction weight: 0.180
✅ New best model saved (Val Loss: 1.2030)
============================================================

🌍 Updating global dataset at epoch 43
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.594 ± 0.893
    Neg distances: 3.884 ± 1.663
    Separation ratio: 6.54x
    Gap: -6.910
    ✅ Excellent global separation!

Epoch 43 Training
----------------------------------------
Batch   0/537: Loss=0.9557 (C:0.9557, R:0.0105)
Batch  25/537: Loss=0.9984 (C:0.9984, R:0.0105)
Batch  50/537: Loss=0.9820 (C:0.9820, R:0.0105)
Batch  75/537: Loss=1.0030 (C:1.0030, R:0.0105)
Batch 100/537: Loss=0.9927 (C:0.9927, R:0.0105)
Batch 125/537: Loss=0.9959 (C:0.9959, R:0.0105)
Batch 150/537: Loss=0.9826 (C:0.9826, R:0.0105)
Batch 175/537: Loss=1.0752 (C:1.0752, R:0.0105)
Batch 200/537: Loss=1.0018 (C:1.0018, R:0.0105)
Batch 225/537: Loss=1.0443 (C:1.0443, R:0.0105)
Batch 250/537: Loss=1.0130 (C:1.0130, R:0.0105)
Batch 275/537: Loss=0.9937 (C:0.9937, R:0.0105)
Batch 300/537: Loss=0.9869 (C:0.9869, R:0.0105)
Batch 325/537: Loss=0.9657 (C:0.9657, R:0.0105)
Batch 350/537: Loss=0.9133 (C:0.9133, R:0.0105)
Batch 375/537: Loss=1.0555 (C:1.0555, R:0.0105)
Batch 400/537: Loss=0.9511 (C:0.9511, R:0.0105)
Batch 425/537: Loss=0.9690 (C:0.9690, R:0.0105)
Batch 450/537: Loss=0.9617 (C:0.9617, R:0.0105)
Batch 475/537: Loss=1.0104 (C:1.0104, R:0.0105)
Batch 500/537: Loss=1.0016 (C:1.0016, R:0.0105)
Batch 525/537: Loss=0.9875 (C:0.9875, R:0.0106)

============================================================
Epoch 43/300 completed in 26.8s
Train: Loss=0.9951 (C:0.9951, R:0.0105) Ratio=4.36x
Val:   Loss=1.1788 (C:1.1788, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.195
✅ New best model saved (Val Loss: 1.1788)
============================================================

🌍 Updating global dataset at epoch 44
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.592 ± 0.897
    Neg distances: 3.859 ± 1.656
    Separation ratio: 6.52x
    Gap: -6.794
    ✅ Excellent global separation!

Epoch 44 Training
----------------------------------------
Batch   0/537: Loss=0.9647 (C:0.9647, R:0.0105)
Batch  25/537: Loss=0.9651 (C:0.9651, R:0.0105)
Batch  50/537: Loss=0.9746 (C:0.9746, R:0.0105)
Batch  75/537: Loss=0.9987 (C:0.9987, R:0.0105)
Batch 100/537: Loss=0.9594 (C:0.9594, R:0.0106)
Batch 125/537: Loss=0.9460 (C:0.9460, R:0.0105)
Batch 150/537: Loss=0.9836 (C:0.9836, R:0.0105)
Batch 175/537: Loss=0.9860 (C:0.9860, R:0.0105)
Batch 200/537: Loss=0.9627 (C:0.9627, R:0.0105)
Batch 225/537: Loss=1.0024 (C:1.0024, R:0.0105)
Batch 250/537: Loss=0.9919 (C:0.9919, R:0.0105)
Batch 275/537: Loss=0.9892 (C:0.9892, R:0.0105)
Batch 300/537: Loss=0.9305 (C:0.9305, R:0.0105)
Batch 325/537: Loss=1.0142 (C:1.0142, R:0.0105)
Batch 350/537: Loss=0.9067 (C:0.9067, R:0.0105)
Batch 375/537: Loss=0.9759 (C:0.9759, R:0.0105)
Batch 400/537: Loss=0.9979 (C:0.9979, R:0.0105)
Batch 425/537: Loss=1.0145 (C:1.0145, R:0.0105)
Batch 450/537: Loss=0.9506 (C:0.9506, R:0.0105)
Batch 475/537: Loss=0.9856 (C:0.9856, R:0.0105)
Batch 500/537: Loss=0.9462 (C:0.9462, R:0.0105)
Batch 525/537: Loss=0.9619 (C:0.9619, R:0.0105)

============================================================
Epoch 44/300 completed in 26.7s
Train: Loss=0.9899 (C:0.9899, R:0.0105) Ratio=4.44x
Val:   Loss=1.1929 (C:1.1929, R:0.0104) Ratio=3.00x
Reconstruction weight: 0.210
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 45
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.589 ± 0.894
    Neg distances: 3.888 ± 1.669
    Separation ratio: 6.60x
    Gap: -6.829
    ✅ Excellent global separation!

Epoch 45 Training
----------------------------------------
Batch   0/537: Loss=0.9478 (C:0.9478, R:0.0105)
Batch  25/537: Loss=0.9180 (C:0.9180, R:0.0105)
Batch  50/537: Loss=1.0000 (C:1.0000, R:0.0105)
Batch  75/537: Loss=0.9839 (C:0.9839, R:0.0105)
Batch 100/537: Loss=0.9664 (C:0.9664, R:0.0105)
Batch 125/537: Loss=0.9366 (C:0.9366, R:0.0105)
Batch 150/537: Loss=1.0530 (C:1.0530, R:0.0106)
Batch 175/537: Loss=0.9670 (C:0.9670, R:0.0105)
Batch 200/537: Loss=0.9854 (C:0.9854, R:0.0105)
Batch 225/537: Loss=1.0523 (C:1.0523, R:0.0105)
Batch 250/537: Loss=0.9676 (C:0.9676, R:0.0105)
Batch 275/537: Loss=0.9967 (C:0.9967, R:0.0105)
Batch 300/537: Loss=0.9809 (C:0.9809, R:0.0106)
Batch 325/537: Loss=0.9609 (C:0.9609, R:0.0105)
Batch 350/537: Loss=1.0114 (C:1.0114, R:0.0105)
Batch 375/537: Loss=1.0263 (C:1.0263, R:0.0105)
Batch 400/537: Loss=0.9713 (C:0.9713, R:0.0105)
Batch 425/537: Loss=0.9752 (C:0.9752, R:0.0105)
Batch 450/537: Loss=1.0112 (C:1.0112, R:0.0106)
Batch 475/537: Loss=0.9675 (C:0.9675, R:0.0105)
Batch 500/537: Loss=1.0270 (C:1.0270, R:0.0105)
Batch 525/537: Loss=0.9691 (C:0.9691, R:0.0105)

============================================================
Epoch 45/300 completed in 27.2s
Train: Loss=0.9827 (C:0.9827, R:0.0105) Ratio=4.46x
Val:   Loss=1.1831 (C:1.1831, R:0.0104) Ratio=3.02x
Reconstruction weight: 0.225
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 46
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.571 ± 0.880
    Neg distances: 3.917 ± 1.658
    Separation ratio: 6.86x
    Gap: -6.774
    ✅ Excellent global separation!

Epoch 46 Training
----------------------------------------
Batch   0/537: Loss=0.9590 (C:0.9590, R:0.0105)
Batch  25/537: Loss=1.0082 (C:1.0082, R:0.0105)
Batch  50/537: Loss=0.9337 (C:0.9337, R:0.0105)
Batch  75/537: Loss=0.9938 (C:0.9938, R:0.0105)
Batch 100/537: Loss=0.9373 (C:0.9373, R:0.0105)
Batch 125/537: Loss=1.0221 (C:1.0221, R:0.0105)
Batch 150/537: Loss=0.9500 (C:0.9500, R:0.0105)
Batch 175/537: Loss=0.9671 (C:0.9671, R:0.0105)
Batch 200/537: Loss=0.9604 (C:0.9604, R:0.0105)
Batch 225/537: Loss=0.9560 (C:0.9560, R:0.0105)
Batch 250/537: Loss=1.0271 (C:1.0271, R:0.0105)
Batch 275/537: Loss=0.9753 (C:0.9753, R:0.0105)
Batch 300/537: Loss=0.9395 (C:0.9395, R:0.0105)
Batch 325/537: Loss=0.9619 (C:0.9619, R:0.0105)
Batch 350/537: Loss=0.9334 (C:0.9334, R:0.0105)
Batch 375/537: Loss=0.9218 (C:0.9218, R:0.0105)
Batch 400/537: Loss=0.9606 (C:0.9606, R:0.0105)
Batch 425/537: Loss=0.9486 (C:0.9486, R:0.0105)
Batch 450/537: Loss=1.0233 (C:1.0233, R:0.0105)
Batch 475/537: Loss=0.9477 (C:0.9477, R:0.0105)
Batch 500/537: Loss=0.9685 (C:0.9685, R:0.0105)
Batch 525/537: Loss=0.9229 (C:0.9229, R:0.0105)

============================================================
Epoch 46/300 completed in 27.0s
Train: Loss=0.9654 (C:0.9654, R:0.0105) Ratio=4.41x
Val:   Loss=1.1644 (C:1.1644, R:0.0104) Ratio=3.03x
Reconstruction weight: 0.240
✅ New best model saved (Val Loss: 1.1644)
============================================================

🌍 Updating global dataset at epoch 47
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.607 ± 0.930
    Neg distances: 3.922 ± 1.690
    Separation ratio: 6.46x
    Gap: -6.785
    ✅ Excellent global separation!

Epoch 47 Training
----------------------------------------
Batch   0/537: Loss=0.9795 (C:0.9795, R:0.0105)
Batch  25/537: Loss=0.9807 (C:0.9807, R:0.0105)
Batch  50/537: Loss=0.9420 (C:0.9420, R:0.0105)
Batch  75/537: Loss=0.9065 (C:0.9065, R:0.0105)
Batch 100/537: Loss=0.9791 (C:0.9791, R:0.0105)
Batch 125/537: Loss=1.0159 (C:1.0159, R:0.0105)
Batch 150/537: Loss=0.9548 (C:0.9548, R:0.0105)
Batch 175/537: Loss=1.0009 (C:1.0009, R:0.0105)
Batch 200/537: Loss=1.0024 (C:1.0024, R:0.0105)
Batch 225/537: Loss=1.0051 (C:1.0051, R:0.0105)
Batch 250/537: Loss=0.9813 (C:0.9813, R:0.0105)
Batch 275/537: Loss=0.9922 (C:0.9922, R:0.0105)
Batch 300/537: Loss=0.9666 (C:0.9666, R:0.0105)
Batch 325/537: Loss=0.9767 (C:0.9767, R:0.0105)
Batch 350/537: Loss=0.9746 (C:0.9746, R:0.0105)
Batch 375/537: Loss=0.9851 (C:0.9851, R:0.0105)
Batch 400/537: Loss=1.0130 (C:1.0130, R:0.0105)
Batch 425/537: Loss=1.0395 (C:1.0395, R:0.0105)
Batch 450/537: Loss=0.9585 (C:0.9585, R:0.0105)
Batch 475/537: Loss=0.9397 (C:0.9397, R:0.0105)
Batch 500/537: Loss=0.9622 (C:0.9622, R:0.0105)
Batch 525/537: Loss=0.9938 (C:0.9938, R:0.0105)

============================================================
Epoch 47/300 completed in 27.5s
Train: Loss=0.9868 (C:0.9868, R:0.0105) Ratio=4.56x
Val:   Loss=1.1956 (C:1.1956, R:0.0104) Ratio=3.01x
Reconstruction weight: 0.255
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 48
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.570 ± 0.865
    Neg distances: 3.941 ± 1.663
    Separation ratio: 6.92x
    Gap: -6.988
    ✅ Excellent global separation!

Epoch 48 Training
----------------------------------------
Batch   0/537: Loss=0.9576 (C:0.9576, R:0.0105)
Batch  25/537: Loss=0.9754 (C:0.9754, R:0.0105)
Batch  50/537: Loss=0.9120 (C:0.9120, R:0.0105)
Batch  75/537: Loss=0.9196 (C:0.9196, R:0.0105)
Batch 100/537: Loss=0.9269 (C:0.9269, R:0.0105)
Batch 125/537: Loss=0.9708 (C:0.9708, R:0.0105)
Batch 150/537: Loss=0.9370 (C:0.9370, R:0.0105)
Batch 175/537: Loss=0.9652 (C:0.9652, R:0.0105)
Batch 200/537: Loss=0.9369 (C:0.9369, R:0.0105)
Batch 225/537: Loss=0.9349 (C:0.9349, R:0.0105)
Batch 250/537: Loss=0.9249 (C:0.9249, R:0.0105)
Batch 275/537: Loss=0.9377 (C:0.9377, R:0.0105)
Batch 300/537: Loss=0.9931 (C:0.9931, R:0.0106)
Batch 325/537: Loss=0.9273 (C:0.9273, R:0.0105)
Batch 350/537: Loss=1.0087 (C:1.0087, R:0.0105)
Batch 375/537: Loss=0.9619 (C:0.9619, R:0.0105)
Batch 400/537: Loss=0.9600 (C:0.9600, R:0.0105)
Batch 425/537: Loss=0.9692 (C:0.9692, R:0.0105)
Batch 450/537: Loss=0.9432 (C:0.9432, R:0.0105)
Batch 475/537: Loss=0.9324 (C:0.9324, R:0.0105)
Batch 500/537: Loss=0.9166 (C:0.9166, R:0.0105)
Batch 525/537: Loss=0.9550 (C:0.9550, R:0.0105)

============================================================
Epoch 48/300 completed in 27.0s
Train: Loss=0.9535 (C:0.9535, R:0.0105) Ratio=4.48x
Val:   Loss=1.1474 (C:1.1474, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.270
✅ New best model saved (Val Loss: 1.1474)
============================================================

🌍 Updating global dataset at epoch 49
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.605 ± 0.953
    Neg distances: 3.916 ± 1.684
    Separation ratio: 6.47x
    Gap: -6.897
    ✅ Excellent global separation!

Epoch 49 Training
----------------------------------------
Batch   0/537: Loss=0.9918 (C:0.9918, R:0.0105)
Batch  25/537: Loss=0.9517 (C:0.9517, R:0.0105)
Batch  50/537: Loss=1.0247 (C:1.0247, R:0.0105)
Batch  75/537: Loss=1.0099 (C:1.0099, R:0.0106)
Batch 100/537: Loss=0.9575 (C:0.9575, R:0.0105)
Batch 125/537: Loss=0.9611 (C:0.9611, R:0.0105)
Batch 150/537: Loss=0.9594 (C:0.9594, R:0.0106)
Batch 175/537: Loss=1.0625 (C:1.0625, R:0.0105)
Batch 200/537: Loss=1.0054 (C:1.0054, R:0.0105)
Batch 225/537: Loss=1.0067 (C:1.0067, R:0.0105)
Batch 250/537: Loss=1.0017 (C:1.0017, R:0.0105)
Batch 275/537: Loss=0.9864 (C:0.9864, R:0.0105)
Batch 300/537: Loss=0.9583 (C:0.9583, R:0.0105)
Batch 325/537: Loss=0.9270 (C:0.9270, R:0.0105)
Batch 350/537: Loss=0.9605 (C:0.9605, R:0.0105)
Batch 375/537: Loss=0.9985 (C:0.9985, R:0.0105)
Batch 400/537: Loss=0.9512 (C:0.9512, R:0.0105)
Batch 425/537: Loss=0.9856 (C:0.9856, R:0.0105)
Batch 450/537: Loss=0.9688 (C:0.9688, R:0.0105)
Batch 475/537: Loss=0.9550 (C:0.9550, R:0.0105)
Batch 500/537: Loss=0.9952 (C:0.9952, R:0.0105)
Batch 525/537: Loss=1.0500 (C:1.0500, R:0.0105)

============================================================
Epoch 49/300 completed in 27.4s
Train: Loss=0.9797 (C:0.9797, R:0.0105) Ratio=4.48x
Val:   Loss=1.1816 (C:1.1816, R:0.0104) Ratio=3.03x
Reconstruction weight: 0.285
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 50
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.591 ± 0.890
    Neg distances: 3.914 ± 1.678
    Separation ratio: 6.62x
    Gap: -6.888
    ✅ Excellent global separation!

Epoch 50 Training
----------------------------------------
Batch   0/537: Loss=0.9637 (C:0.9637, R:0.0105)
Batch  25/537: Loss=0.9591 (C:0.9591, R:0.0106)
Batch  50/537: Loss=0.9786 (C:0.9786, R:0.0105)
Batch  75/537: Loss=0.9913 (C:0.9913, R:0.0105)
Batch 100/537: Loss=0.9653 (C:0.9653, R:0.0105)
Batch 125/537: Loss=0.9727 (C:0.9727, R:0.0105)
Batch 150/537: Loss=0.9493 (C:0.9493, R:0.0105)
Batch 175/537: Loss=0.9182 (C:0.9182, R:0.0105)
Batch 200/537: Loss=0.9594 (C:0.9594, R:0.0105)
Batch 225/537: Loss=0.9484 (C:0.9484, R:0.0105)
Batch 250/537: Loss=0.9756 (C:0.9756, R:0.0105)
Batch 275/537: Loss=0.9455 (C:0.9455, R:0.0105)
Batch 300/537: Loss=1.0059 (C:1.0059, R:0.0105)
Batch 325/537: Loss=0.9491 (C:0.9491, R:0.0105)
Batch 350/537: Loss=1.0160 (C:1.0160, R:0.0105)
Batch 375/537: Loss=0.9734 (C:0.9734, R:0.0105)
Batch 400/537: Loss=0.9567 (C:0.9567, R:0.0105)
Batch 425/537: Loss=1.0037 (C:1.0037, R:0.0105)
Batch 450/537: Loss=0.9316 (C:0.9316, R:0.0105)
Batch 475/537: Loss=1.0057 (C:1.0057, R:0.0105)
Batch 500/537: Loss=0.9413 (C:0.9413, R:0.0105)
Batch 525/537: Loss=0.9846 (C:0.9846, R:0.0105)

============================================================
Epoch 50/300 completed in 27.1s
Train: Loss=0.9680 (C:0.9680, R:0.0105) Ratio=4.58x
Val:   Loss=1.1862 (C:1.1862, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 51
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.584 ± 0.897
    Neg distances: 3.985 ± 1.705
    Separation ratio: 6.83x
    Gap: -6.959
    ✅ Excellent global separation!

Epoch 51 Training
----------------------------------------
Batch   0/537: Loss=0.9824 (C:0.9824, R:0.0105)
Batch  25/537: Loss=0.9470 (C:0.9470, R:0.0105)
Batch  50/537: Loss=0.9711 (C:0.9711, R:0.0105)
Batch  75/537: Loss=0.9260 (C:0.9260, R:0.0105)
Batch 100/537: Loss=0.9579 (C:0.9579, R:0.0105)
Batch 125/537: Loss=0.9303 (C:0.9303, R:0.0105)
Batch 150/537: Loss=0.9047 (C:0.9047, R:0.0105)
Batch 175/537: Loss=0.9341 (C:0.9341, R:0.0106)
Batch 200/537: Loss=0.9420 (C:0.9420, R:0.0105)
Batch 225/537: Loss=0.9080 (C:0.9080, R:0.0105)
Batch 250/537: Loss=0.9310 (C:0.9310, R:0.0105)
Batch 275/537: Loss=0.9901 (C:0.9901, R:0.0105)
Batch 300/537: Loss=0.9781 (C:0.9781, R:0.0105)
Batch 325/537: Loss=0.9605 (C:0.9605, R:0.0105)
Batch 350/537: Loss=0.9823 (C:0.9823, R:0.0105)
Batch 375/537: Loss=1.0195 (C:1.0195, R:0.0105)
Batch 400/537: Loss=0.9829 (C:0.9829, R:0.0105)
Batch 425/537: Loss=0.9254 (C:0.9254, R:0.0106)
Batch 450/537: Loss=0.9583 (C:0.9583, R:0.0105)
Batch 475/537: Loss=0.9553 (C:0.9553, R:0.0105)
Batch 500/537: Loss=0.9371 (C:0.9371, R:0.0105)
Batch 525/537: Loss=0.9840 (C:0.9840, R:0.0105)

============================================================
Epoch 51/300 completed in 27.6s
Train: Loss=0.9574 (C:0.9574, R:0.0105) Ratio=4.52x
Val:   Loss=1.1703 (C:1.1703, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 52
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.589 ± 0.926
    Neg distances: 3.958 ± 1.690
    Separation ratio: 6.72x
    Gap: -6.952
    ✅ Excellent global separation!

Epoch 52 Training
----------------------------------------
Batch   0/537: Loss=0.9108 (C:0.9108, R:0.0105)
Batch  25/537: Loss=0.9576 (C:0.9576, R:0.0105)
Batch  50/537: Loss=0.9724 (C:0.9724, R:0.0105)
Batch  75/537: Loss=0.9084 (C:0.9084, R:0.0105)
Batch 100/537: Loss=0.9531 (C:0.9531, R:0.0105)
Batch 125/537: Loss=0.9714 (C:0.9714, R:0.0105)
Batch 150/537: Loss=0.9466 (C:0.9466, R:0.0105)
Batch 175/537: Loss=0.9765 (C:0.9765, R:0.0105)
Batch 200/537: Loss=1.0149 (C:1.0149, R:0.0105)
Batch 225/537: Loss=1.0027 (C:1.0027, R:0.0105)
Batch 250/537: Loss=0.9782 (C:0.9782, R:0.0105)
Batch 275/537: Loss=0.9909 (C:0.9909, R:0.0105)
Batch 300/537: Loss=0.9197 (C:0.9197, R:0.0105)
Batch 325/537: Loss=0.9494 (C:0.9494, R:0.0105)
Batch 350/537: Loss=0.9339 (C:0.9339, R:0.0105)
Batch 375/537: Loss=0.9183 (C:0.9183, R:0.0105)
Batch 400/537: Loss=0.9741 (C:0.9741, R:0.0105)
Batch 425/537: Loss=0.9971 (C:0.9971, R:0.0105)
Batch 450/537: Loss=0.9132 (C:0.9132, R:0.0105)
Batch 475/537: Loss=0.9394 (C:0.9394, R:0.0105)
Batch 500/537: Loss=1.0382 (C:1.0382, R:0.0105)
Batch 525/537: Loss=0.9903 (C:0.9903, R:0.0105)

============================================================
Epoch 52/300 completed in 28.5s
Train: Loss=0.9552 (C:0.9552, R:0.0105) Ratio=4.55x
Val:   Loss=1.1712 (C:1.1712, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.300
No improvement for 4 epochs
============================================================

🌍 Updating global dataset at epoch 53
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.587 ± 0.950
    Neg distances: 3.982 ± 1.690
    Separation ratio: 6.78x
    Gap: -6.934
    ✅ Excellent global separation!

Epoch 53 Training
----------------------------------------
Batch   0/537: Loss=0.9276 (C:0.9276, R:0.0105)
Batch  25/537: Loss=0.9636 (C:0.9636, R:0.0105)
Batch  50/537: Loss=0.9668 (C:0.9668, R:0.0105)
Batch  75/537: Loss=0.9260 (C:0.9260, R:0.0105)
Batch 100/537: Loss=0.9607 (C:0.9607, R:0.0105)
Batch 125/537: Loss=0.9971 (C:0.9971, R:0.0105)
Batch 150/537: Loss=1.0120 (C:1.0120, R:0.0105)
Batch 175/537: Loss=0.9867 (C:0.9867, R:0.0105)
Batch 200/537: Loss=0.9486 (C:0.9486, R:0.0105)
Batch 225/537: Loss=0.8928 (C:0.8928, R:0.0105)
Batch 250/537: Loss=0.9288 (C:0.9288, R:0.0105)
Batch 275/537: Loss=0.9565 (C:0.9565, R:0.0106)
Batch 300/537: Loss=0.9626 (C:0.9626, R:0.0105)
Batch 325/537: Loss=1.0015 (C:1.0015, R:0.0105)
Batch 350/537: Loss=0.9741 (C:0.9741, R:0.0105)
Batch 375/537: Loss=0.9528 (C:0.9528, R:0.0105)
Batch 400/537: Loss=0.9980 (C:0.9980, R:0.0105)
Batch 425/537: Loss=0.9872 (C:0.9872, R:0.0105)
Batch 450/537: Loss=0.9386 (C:0.9386, R:0.0105)
Batch 475/537: Loss=0.9170 (C:0.9170, R:0.0105)
Batch 500/537: Loss=0.9562 (C:0.9562, R:0.0105)
Batch 525/537: Loss=0.8989 (C:0.8989, R:0.0105)

============================================================
Epoch 53/300 completed in 27.7s
Train: Loss=0.9489 (C:0.9489, R:0.0105) Ratio=4.54x
Val:   Loss=1.1673 (C:1.1673, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.300
No improvement for 5 epochs
============================================================

🌍 Updating global dataset at epoch 54
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.578 ± 0.957
    Neg distances: 3.953 ± 1.681
    Separation ratio: 6.84x
    Gap: -7.039
    ✅ Excellent global separation!

Epoch 54 Training
----------------------------------------
Batch   0/537: Loss=0.9553 (C:0.9553, R:0.0105)
Batch  25/537: Loss=0.8859 (C:0.8859, R:0.0105)
Batch  50/537: Loss=0.9574 (C:0.9574, R:0.0105)
Batch  75/537: Loss=0.9472 (C:0.9472, R:0.0105)
Batch 100/537: Loss=1.0524 (C:1.0524, R:0.0105)
Batch 125/537: Loss=0.9668 (C:0.9668, R:0.0105)
Batch 150/537: Loss=0.9394 (C:0.9394, R:0.0106)
Batch 175/537: Loss=0.9347 (C:0.9347, R:0.0105)
Batch 200/537: Loss=0.9058 (C:0.9058, R:0.0105)
Batch 225/537: Loss=0.9642 (C:0.9642, R:0.0106)
Batch 250/537: Loss=0.9618 (C:0.9618, R:0.0105)
Batch 275/537: Loss=0.9181 (C:0.9181, R:0.0105)
Batch 300/537: Loss=0.9389 (C:0.9389, R:0.0105)
Batch 325/537: Loss=0.9365 (C:0.9365, R:0.0105)
Batch 350/537: Loss=0.9517 (C:0.9517, R:0.0106)
Batch 375/537: Loss=0.9441 (C:0.9441, R:0.0105)
Batch 400/537: Loss=0.9176 (C:0.9176, R:0.0105)
Batch 425/537: Loss=0.9045 (C:0.9045, R:0.0105)
Batch 450/537: Loss=0.9365 (C:0.9365, R:0.0105)
Batch 475/537: Loss=0.9482 (C:0.9482, R:0.0105)
Batch 500/537: Loss=0.9560 (C:0.9560, R:0.0105)
Batch 525/537: Loss=0.9219 (C:0.9219, R:0.0105)

============================================================
Epoch 54/300 completed in 28.0s
Train: Loss=0.9413 (C:0.9413, R:0.0105) Ratio=4.65x
Val:   Loss=1.1581 (C:1.1581, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
No improvement for 6 epochs
============================================================

🌍 Updating global dataset at epoch 55
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.548 ± 0.882
    Neg distances: 3.969 ± 1.678
    Separation ratio: 7.24x
    Gap: -7.001
    ✅ Excellent global separation!

Epoch 55 Training
----------------------------------------
Batch   0/537: Loss=0.8780 (C:0.8780, R:0.0105)
Batch  25/537: Loss=0.9283 (C:0.9283, R:0.0105)
Batch  50/537: Loss=0.8589 (C:0.8589, R:0.0105)
Batch  75/537: Loss=0.9417 (C:0.9417, R:0.0105)
Batch 100/537: Loss=0.8567 (C:0.8567, R:0.0105)
Batch 125/537: Loss=0.9070 (C:0.9070, R:0.0105)
Batch 150/537: Loss=0.9456 (C:0.9456, R:0.0105)
Batch 175/537: Loss=0.8911 (C:0.8911, R:0.0105)
Batch 200/537: Loss=0.8756 (C:0.8756, R:0.0105)
Batch 225/537: Loss=0.8648 (C:0.8648, R:0.0106)
Batch 250/537: Loss=0.8431 (C:0.8431, R:0.0105)
Batch 275/537: Loss=0.9617 (C:0.9617, R:0.0105)
Batch 300/537: Loss=0.8903 (C:0.8903, R:0.0105)
Batch 325/537: Loss=0.9218 (C:0.9218, R:0.0105)
Batch 350/537: Loss=0.9301 (C:0.9301, R:0.0105)
Batch 375/537: Loss=0.9389 (C:0.9389, R:0.0105)
Batch 400/537: Loss=0.8836 (C:0.8836, R:0.0105)
Batch 425/537: Loss=0.9435 (C:0.9435, R:0.0105)
Batch 450/537: Loss=0.8745 (C:0.8745, R:0.0105)
Batch 475/537: Loss=0.9158 (C:0.9158, R:0.0105)
Batch 500/537: Loss=0.9611 (C:0.9611, R:0.0105)
Batch 525/537: Loss=0.9432 (C:0.9432, R:0.0105)

============================================================
Epoch 55/300 completed in 27.7s
Train: Loss=0.9192 (C:0.9192, R:0.0105) Ratio=4.76x
Val:   Loss=1.1652 (C:1.1652, R:0.0104) Ratio=3.02x
Reconstruction weight: 0.300
No improvement for 7 epochs
============================================================

🌍 Updating global dataset at epoch 56
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.568 ± 0.916
    Neg distances: 4.010 ± 1.701
    Separation ratio: 7.05x
    Gap: -7.029
    ✅ Excellent global separation!

Epoch 56 Training
----------------------------------------
Batch   0/537: Loss=0.9475 (C:0.9475, R:0.0105)
Batch  25/537: Loss=0.9179 (C:0.9179, R:0.0105)
Batch  50/537: Loss=0.9114 (C:0.9114, R:0.0105)
Batch  75/537: Loss=0.8917 (C:0.8917, R:0.0105)
Batch 100/537: Loss=0.9599 (C:0.9599, R:0.0105)
Batch 125/537: Loss=0.9256 (C:0.9256, R:0.0105)
Batch 150/537: Loss=0.9153 (C:0.9153, R:0.0105)
Batch 175/537: Loss=0.9319 (C:0.9319, R:0.0105)
Batch 200/537: Loss=0.9092 (C:0.9092, R:0.0105)
Batch 225/537: Loss=0.9177 (C:0.9177, R:0.0106)
Batch 250/537: Loss=0.8938 (C:0.8938, R:0.0105)
Batch 275/537: Loss=0.9703 (C:0.9703, R:0.0105)
Batch 300/537: Loss=0.9298 (C:0.9298, R:0.0105)
Batch 325/537: Loss=0.9184 (C:0.9184, R:0.0105)
Batch 350/537: Loss=0.9234 (C:0.9234, R:0.0105)
Batch 375/537: Loss=0.9593 (C:0.9593, R:0.0105)
Batch 400/537: Loss=0.9257 (C:0.9257, R:0.0105)
Batch 425/537: Loss=0.9263 (C:0.9263, R:0.0105)
Batch 450/537: Loss=0.9282 (C:0.9282, R:0.0105)
Batch 475/537: Loss=0.9499 (C:0.9499, R:0.0105)
Batch 500/537: Loss=0.9220 (C:0.9220, R:0.0105)
Batch 525/537: Loss=0.9481 (C:0.9481, R:0.0105)

============================================================
Epoch 56/300 completed in 27.9s
Train: Loss=0.9291 (C:0.9291, R:0.0105) Ratio=4.66x
Val:   Loss=1.1643 (C:1.1643, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
No improvement for 8 epochs

Early stopping triggered after 56 epochs
Best model was at epoch 48 with Val Loss: 1.1474

Global Dataset Training Completed!
Best epoch: 48
Best validation loss: 1.1474
Final separation ratios: Train=4.66x, Val=3.05x
Training completed!
Loading best model from entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin3.0_updatefreq1_max_global_samples5000_20250715_152350/checkpoints/best_model.pt
Starting model evaluation...
========================================
GlobalContrastiveEvaluator initialized on cuda
Starting comprehensive evaluation...
============================================================
Extracting latent representations...
  Processed 1/10 batches
Extracted representations: torch.Size([9824, 75])
Evaluating clustering performance...
Clustering Results:
  Silhouette Score: 0.4574
  Adjusted Rand Score: 0.5422
  Clustering Accuracy: 0.8199
Evaluating classification performance...
  Extracting training representations...
Extracting latent representations...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
Extracted representations: torch.Size([547740, 75])
  Extracting validation representations...
Extracting latent representations...
  Processed 1/9 batches
Extracted representations: torch.Size([9180, 75])
Subsampled training to 50000 samples
  Training on 50000 samples, evaluating on 9180 samples
Classification Results:
  Accuracy: 0.8151
  Per-class F1: [0.8358862144420132, 0.7509047993705744, 0.8621372031662269]
Evaluating reconstruction quality...
Reconstruction Results:
  Average MSE: 0.010432
Evaluating separation quality...
Separation Results:
  Positive distances: 1.164 ± 1.318
  Negative distances: 3.520 ± 1.853
  Separation ratio: 3.02x
  Gap: -7.019
  Perfect separation: No

Comprehensive evaluation completed!

============================================================
EVALUATION SUMMARY
============================================================
Clustering Performance:
  Silhouette Score: 0.4574
  Clustering Accuracy: 0.8199
  Adjusted Rand Score: 0.5422

Classification Performance:
  Accuracy: 0.8151

Separation Quality:
  Separation Ratio: 3.02x
  Gap: -7.019
  Perfect Separation: False

Reconstruction Quality:
  Average MSE: 0.010432
============================================================
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin3.0_updatefreq1_max_global_samples5000_20250715_152350/results/evaluation_results_20250715_154951.json
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin3.0_updatefreq1_max_global_samples5000_20250715_152350/results/evaluation_results_20250715_154951.json
Saving final experiment results...
Final results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin3.0_updatefreq1_max_global_samples5000_20250715_152350/final_results.json

============================================================
PIPELINE COMPLETED SUCCESSFULLY!
============================================================
Experiment directory: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin3.0_updatefreq1_max_global_samples5000_20250715_152350
Best model: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin3.0_updatefreq1_max_global_samples5000_20250715_152350/checkpoints/best_model.pt
Final results: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin3.0_updatefreq1_max_global_samples5000_20250715_152350/final_results.json

Key Results:
  Separation ratio: 3.02x
  Perfect separation: False
  Classification accuracy: 0.8151
  Result: 0.8151% (improvement: +-80.85%)
  Cleaning up: coarse_margin3.0_updatefreq1_max_global_samples5000_20250715_152350

[10/12] Testing: coarse_margin3.0_updatefreq1_max_global_samples10000
  margin: 3.0
  update_frequency: 1
  max_global_samples: 10000
  Reconstruction weight: 0.3 (fixed)
GLOBAL DATASET CONTRASTIVE AUTOENCODER PIPELINE
============================================================
Start time: 2025-07-15 15:49:51.662937
Using device: cuda

Configuration:
  Embedding type: concat
  Batch size: 1020
  Global update frequency: 1 epochs
  Training epochs: 300
Experiment setup completed:
  Experiment directory: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin3.0_updatefreq1_max_global_samples10000_20250715_154951
  Config saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin3.0_updatefreq1_max_global_samples10000_20250715_154951/config.json
Loading data...
========================================
FlexibleEmbedder initialized with type: 'concat'
Output dimension will be: 1536
GlobalDataLoader initialized:
  Embedding type: concat
  Output dimension: 1536
  Sample size: All
Starting data loading pipeline...
============================================================
Loading training data from data/processed/snli_full_standard_SBERT.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 549367 training samples
Loading validation data from data/processed/snli_full_standard_SBERT_validation.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9842 validation samples
Loading test data from data/processed/snli_full_standard_SBERT_test.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9824 test samples
Generating embeddings for training...
Generating concat embeddings on cuda
Processing 549367 samples in batches of 1000
  Processing batch 1/550
  Processing batch 6/550
  Processing batch 11/550
  Processing batch 16/550
  Processing batch 21/550
  Processing batch 26/550
  Processing batch 31/550
  Processing batch 36/550
  Processing batch 41/550
  Processing batch 46/550
  Processing batch 51/550
  Processing batch 56/550
  Processing batch 61/550
  Processing batch 66/550
  Processing batch 71/550
  Processing batch 76/550
  Processing batch 81/550
  Processing batch 86/550
  Processing batch 91/550
  Processing batch 96/550
  Processing batch 101/550
  Processing batch 106/550
  Processing batch 111/550
  Processing batch 116/550
  Processing batch 121/550
  Processing batch 126/550
  Processing batch 131/550
  Processing batch 136/550
  Processing batch 141/550
  Processing batch 146/550
  Processing batch 151/550
  Processing batch 156/550
  Processing batch 161/550
  Processing batch 166/550
  Processing batch 171/550
  Processing batch 176/550
  Processing batch 181/550
  Processing batch 186/550
  Processing batch 191/550
  Processing batch 196/550
  Processing batch 201/550
  Processing batch 206/550
  Processing batch 211/550
  Processing batch 216/550
  Processing batch 221/550
  Processing batch 226/550
  Processing batch 231/550
  Processing batch 236/550
  Processing batch 241/550
  Processing batch 246/550
  Processing batch 251/550
  Processing batch 256/550
  Processing batch 261/550
  Processing batch 266/550
  Processing batch 271/550
  Processing batch 276/550
  Processing batch 281/550
  Processing batch 286/550
  Processing batch 291/550
  Processing batch 296/550
  Processing batch 301/550
  Processing batch 306/550
  Processing batch 311/550
  Processing batch 316/550
  Processing batch 321/550
  Processing batch 326/550
  Processing batch 331/550
  Processing batch 336/550
  Processing batch 341/550
  Processing batch 346/550
  Processing batch 351/550
  Processing batch 356/550
  Processing batch 361/550
  Processing batch 366/550
  Processing batch 371/550
  Processing batch 376/550
  Processing batch 381/550
  Processing batch 386/550
  Processing batch 391/550
  Processing batch 396/550
  Processing batch 401/550
  Processing batch 406/550
  Processing batch 411/550
  Processing batch 416/550
  Processing batch 421/550
  Processing batch 426/550
  Processing batch 431/550
  Processing batch 436/550
  Processing batch 441/550
  Processing batch 446/550
  Processing batch 451/550
  Processing batch 456/550
  Processing batch 461/550
  Processing batch 466/550
  Processing batch 471/550
  Processing batch 476/550
  Processing batch 481/550
  Processing batch 486/550
  Processing batch 491/550
  Processing batch 496/550
  Processing batch 501/550
  Processing batch 506/550
  Processing batch 511/550
  Processing batch 516/550
  Processing batch 521/550
  Processing batch 526/550
  Processing batch 531/550
  Processing batch 536/550
  Processing batch 541/550
  Processing batch 546/550
Generated concat embeddings: torch.Size([549367, 1536])
Generating embeddings for validation...
Generating concat embeddings on cuda
Processing 9842 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9842, 1536])
Generating embeddings for test...
Generating concat embeddings on cuda
Processing 9824 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9824, 1536])
EntailmentDataset created: 549367 samples
  Embedding shape: torch.Size([549367, 1536])
  Class distribution: {'entailment': 183416, 'neutral': 182764, 'contradiction': 183187}
EntailmentDataset created: 9842 samples
  Embedding shape: torch.Size([9842, 1536])
  Class distribution: {'entailment': 3329, 'neutral': 3235, 'contradiction': 3278}
EntailmentDataset created: 9824 samples
  Embedding shape: torch.Size([9824, 1536])
  Class distribution: {'entailment': 3368, 'neutral': 3219, 'contradiction': 3237}

Data loading pipeline completed!
Output embedding dimension: 1536
Updated model input_dim to: 1536
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 537
  Class 2: 183187 samples
  Class 0: 183416 samples
  Class 1: 182764 samples
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 9
  Class 2: 3278 samples
  Class 0: 3329 samples
  Class 1: 3235 samples
DataLoaders created:
  Batch size: 1020
  Balanced sampling: True
  Train batches: 537
  Val batches: 9
  Test batches: 10
Data loading completed!
  Train: 549367 samples, 537 batches
  Val: 9842 samples, 9 batches
  Test: 9824 samples, 10 batches
Creating model and trainer...
========================================
ContrastiveAutoencoder initialized:
  Input dim: 1536
  Latent dim: 75
  Hidden dims: [512, 256]
  Dropout rate: 0.2
  Total parameters: 1,876,555
Model created with 1,876,555 parameters
FullDatasetContrastiveLoss initialized:
  Margin: 3.0
  Update frequency: 1 epochs
  Max global samples: 10000
FullDatasetCombinedLoss initialized:
  Contrastive weight: 1.0
  Base reconstruction weight: 0.0
  Scheduled reconstruction: warmup=30 epochs, max_weight=0.3
Optimizer created (lr=0.0001)
GlobalDatasetTrainer initialized on device: cuda
Model parameters: 1,876,555
Starting training...
========================================
Starting Global Dataset Training...
============================================================

🌍 Updating global dataset at epoch 1
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.091 ± 0.011
    Neg distances: 0.092 ± 0.011
    Separation ratio: 1.00x
    Gap: -0.148
    ❌ Poor global separation

Epoch 1 Training
----------------------------------------
Batch   0/537: Loss=2.9998 (C:2.9998, R:0.0116)
Batch  25/537: Loss=2.9956 (C:2.9956, R:0.0114)
Batch  50/537: Loss=2.9756 (C:2.9756, R:0.0113)
Batch  75/537: Loss=2.9573 (C:2.9573, R:0.0112)
Batch 100/537: Loss=2.9611 (C:2.9611, R:0.0110)
Batch 125/537: Loss=2.9388 (C:2.9388, R:0.0109)
Batch 150/537: Loss=2.9333 (C:2.9333, R:0.0109)
Batch 175/537: Loss=2.9064 (C:2.9064, R:0.0108)
Batch 200/537: Loss=2.9128 (C:2.9128, R:0.0108)
Batch 225/537: Loss=2.9103 (C:2.9103, R:0.0107)
Batch 250/537: Loss=2.8913 (C:2.8913, R:0.0107)
Batch 275/537: Loss=2.8918 (C:2.8918, R:0.0106)
Batch 300/537: Loss=2.8968 (C:2.8968, R:0.0106)
Batch 325/537: Loss=2.8775 (C:2.8775, R:0.0106)
Batch 350/537: Loss=2.8578 (C:2.8578, R:0.0106)
Batch 375/537: Loss=2.8765 (C:2.8765, R:0.0106)
Batch 400/537: Loss=2.8696 (C:2.8696, R:0.0106)
Batch 425/537: Loss=2.8677 (C:2.8677, R:0.0106)
Batch 450/537: Loss=2.8764 (C:2.8764, R:0.0105)
Batch 475/537: Loss=2.8696 (C:2.8696, R:0.0105)
Batch 500/537: Loss=2.8364 (C:2.8364, R:0.0105)
Batch 525/537: Loss=2.8722 (C:2.8722, R:0.0105)

============================================================
Epoch 1/300 completed in 27.3s
Train: Loss=2.9042 (C:2.9042, R:0.0108) Ratio=1.60x
Val:   Loss=2.8479 (C:2.8479, R:0.0104) Ratio=2.10x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 2.8479)
============================================================

🌍 Updating global dataset at epoch 2
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 1.011 ± 0.862
    Neg distances: 2.171 ± 1.275
    Separation ratio: 2.15x
    Gap: -5.812
    ✅ Good global separation

Epoch 2 Training
----------------------------------------
Batch   0/537: Loss=2.0553 (C:2.0553, R:0.0105)
Batch  25/537: Loss=2.0382 (C:2.0382, R:0.0105)
Batch  50/537: Loss=2.0554 (C:2.0554, R:0.0105)
Batch  75/537: Loss=2.0700 (C:2.0700, R:0.0105)
Batch 100/537: Loss=2.0337 (C:2.0337, R:0.0105)
Batch 125/537: Loss=2.0505 (C:2.0505, R:0.0105)
Batch 150/537: Loss=2.1367 (C:2.1367, R:0.0105)
Batch 175/537: Loss=2.0645 (C:2.0645, R:0.0105)
Batch 200/537: Loss=2.0211 (C:2.0211, R:0.0105)
Batch 225/537: Loss=2.0475 (C:2.0475, R:0.0105)
Batch 250/537: Loss=2.0967 (C:2.0967, R:0.0105)
Batch 275/537: Loss=2.0634 (C:2.0634, R:0.0105)
Batch 300/537: Loss=2.0333 (C:2.0333, R:0.0105)
Batch 325/537: Loss=2.0279 (C:2.0279, R:0.0105)
Batch 350/537: Loss=2.0304 (C:2.0304, R:0.0105)
Batch 375/537: Loss=2.0149 (C:2.0149, R:0.0105)
Batch 400/537: Loss=1.9916 (C:1.9916, R:0.0105)
Batch 425/537: Loss=2.0172 (C:2.0172, R:0.0105)
Batch 450/537: Loss=2.0506 (C:2.0506, R:0.0105)
Batch 475/537: Loss=2.0449 (C:2.0449, R:0.0105)
Batch 500/537: Loss=2.0231 (C:2.0231, R:0.0105)
Batch 525/537: Loss=2.0154 (C:2.0154, R:0.0105)

============================================================
Epoch 2/300 completed in 26.9s
Train: Loss=2.0505 (C:2.0505, R:0.0105) Ratio=2.19x
Val:   Loss=2.0186 (C:2.0186, R:0.0104) Ratio=2.37x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 2.0186)
============================================================

🌍 Updating global dataset at epoch 3
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.900 ± 0.849
    Neg distances: 2.249 ± 1.260
    Separation ratio: 2.50x
    Gap: -5.473
    ✅ Good global separation

Epoch 3 Training
----------------------------------------
Batch   0/537: Loss=1.9095 (C:1.9095, R:0.0105)
Batch  25/537: Loss=1.8892 (C:1.8892, R:0.0105)
Batch  50/537: Loss=1.9132 (C:1.9132, R:0.0105)
Batch  75/537: Loss=1.8712 (C:1.8712, R:0.0105)
Batch 100/537: Loss=1.8647 (C:1.8647, R:0.0105)
Batch 125/537: Loss=1.9201 (C:1.9201, R:0.0105)
Batch 150/537: Loss=1.8652 (C:1.8652, R:0.0105)
Batch 175/537: Loss=1.9314 (C:1.9314, R:0.0105)
Batch 200/537: Loss=1.8413 (C:1.8413, R:0.0105)
Batch 225/537: Loss=1.9025 (C:1.9025, R:0.0105)
Batch 250/537: Loss=1.9384 (C:1.9384, R:0.0105)
Batch 275/537: Loss=1.8649 (C:1.8649, R:0.0105)
Batch 300/537: Loss=1.9209 (C:1.9209, R:0.0105)
Batch 325/537: Loss=1.8661 (C:1.8661, R:0.0105)
Batch 350/537: Loss=1.8407 (C:1.8407, R:0.0105)
Batch 375/537: Loss=1.8552 (C:1.8552, R:0.0105)
Batch 400/537: Loss=1.8476 (C:1.8476, R:0.0105)
Batch 425/537: Loss=1.8618 (C:1.8618, R:0.0105)
Batch 450/537: Loss=1.8865 (C:1.8865, R:0.0105)
Batch 475/537: Loss=1.8929 (C:1.8929, R:0.0105)
Batch 500/537: Loss=1.8863 (C:1.8863, R:0.0105)
Batch 525/537: Loss=1.8663 (C:1.8663, R:0.0105)

============================================================
Epoch 3/300 completed in 27.0s
Train: Loss=1.8967 (C:1.8967, R:0.0105) Ratio=2.44x
Val:   Loss=1.8722 (C:1.8722, R:0.0104) Ratio=2.51x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.8722)
============================================================

🌍 Updating global dataset at epoch 4
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.869 ± 0.862
    Neg distances: 2.362 ± 1.293
    Separation ratio: 2.72x
    Gap: -5.706
    ✅ Good global separation

Epoch 4 Training
----------------------------------------
Batch   0/537: Loss=1.8415 (C:1.8415, R:0.0106)
Batch  25/537: Loss=1.8722 (C:1.8722, R:0.0105)
Batch  50/537: Loss=1.8152 (C:1.8152, R:0.0105)
Batch  75/537: Loss=1.7811 (C:1.7811, R:0.0105)
Batch 100/537: Loss=1.7851 (C:1.7851, R:0.0105)
Batch 125/537: Loss=1.8251 (C:1.8251, R:0.0105)
Batch 150/537: Loss=1.8337 (C:1.8337, R:0.0105)
Batch 175/537: Loss=1.7897 (C:1.7897, R:0.0105)
Batch 200/537: Loss=1.8348 (C:1.8348, R:0.0105)
Batch 225/537: Loss=1.8422 (C:1.8422, R:0.0105)
Batch 250/537: Loss=1.7986 (C:1.7986, R:0.0105)
Batch 275/537: Loss=1.8472 (C:1.8472, R:0.0105)
Batch 300/537: Loss=1.7878 (C:1.7878, R:0.0105)
Batch 325/537: Loss=1.8372 (C:1.8372, R:0.0105)
Batch 350/537: Loss=1.8267 (C:1.8267, R:0.0105)
Batch 375/537: Loss=1.7944 (C:1.7944, R:0.0105)
Batch 400/537: Loss=1.8496 (C:1.8496, R:0.0105)
Batch 425/537: Loss=1.7620 (C:1.7620, R:0.0105)
Batch 450/537: Loss=1.8793 (C:1.8793, R:0.0105)
Batch 475/537: Loss=1.8345 (C:1.8345, R:0.0105)
Batch 500/537: Loss=1.8352 (C:1.8352, R:0.0105)
Batch 525/537: Loss=1.8089 (C:1.8089, R:0.0105)

============================================================
Epoch 4/300 completed in 26.9s
Train: Loss=1.8166 (C:1.8166, R:0.0105) Ratio=2.54x
Val:   Loss=1.8122 (C:1.8122, R:0.0104) Ratio=2.59x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.8122)
============================================================

🌍 Updating global dataset at epoch 5
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.837 ± 0.853
    Neg distances: 2.416 ± 1.294
    Separation ratio: 2.89x
    Gap: -5.419
    ✅ Good global separation

Epoch 5 Training
----------------------------------------
Batch   0/537: Loss=1.7721 (C:1.7721, R:0.0105)
Batch  25/537: Loss=1.7623 (C:1.7623, R:0.0105)
Batch  50/537: Loss=1.7540 (C:1.7540, R:0.0105)
Batch  75/537: Loss=1.7784 (C:1.7784, R:0.0105)
Batch 100/537: Loss=1.7261 (C:1.7261, R:0.0105)
Batch 125/537: Loss=1.7841 (C:1.7841, R:0.0105)
Batch 150/537: Loss=1.7668 (C:1.7668, R:0.0105)
Batch 175/537: Loss=1.6937 (C:1.6937, R:0.0105)
Batch 200/537: Loss=1.7575 (C:1.7575, R:0.0106)
Batch 225/537: Loss=1.7278 (C:1.7278, R:0.0105)
Batch 250/537: Loss=1.7417 (C:1.7417, R:0.0105)
Batch 275/537: Loss=1.7735 (C:1.7735, R:0.0104)
Batch 300/537: Loss=1.7485 (C:1.7485, R:0.0105)
Batch 325/537: Loss=1.7534 (C:1.7534, R:0.0105)
Batch 350/537: Loss=1.7328 (C:1.7328, R:0.0105)
Batch 375/537: Loss=1.7310 (C:1.7310, R:0.0105)
Batch 400/537: Loss=1.7434 (C:1.7434, R:0.0105)
Batch 425/537: Loss=1.7620 (C:1.7620, R:0.0105)
Batch 450/537: Loss=1.7209 (C:1.7209, R:0.0105)
Batch 475/537: Loss=1.7801 (C:1.7801, R:0.0105)
Batch 500/537: Loss=1.7700 (C:1.7700, R:0.0105)
Batch 525/537: Loss=1.7543 (C:1.7543, R:0.0105)

============================================================
Epoch 5/300 completed in 27.9s
Train: Loss=1.7589 (C:1.7589, R:0.0105) Ratio=2.67x
Val:   Loss=1.7515 (C:1.7515, R:0.0104) Ratio=2.66x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.7515)
============================================================

🌍 Updating global dataset at epoch 6
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.838 ± 0.861
    Neg distances: 2.482 ± 1.320
    Separation ratio: 2.96x
    Gap: -5.680
    ✅ Good global separation

Epoch 6 Training
----------------------------------------
Batch   0/537: Loss=1.7215 (C:1.7215, R:0.0105)
Batch  25/537: Loss=1.6977 (C:1.6977, R:0.0105)
Batch  50/537: Loss=1.7243 (C:1.7243, R:0.0105)
Batch  75/537: Loss=1.6781 (C:1.6781, R:0.0105)
Batch 100/537: Loss=1.6834 (C:1.6834, R:0.0105)
Batch 125/537: Loss=1.6946 (C:1.6946, R:0.0105)
Batch 150/537: Loss=1.6999 (C:1.6999, R:0.0105)
Batch 175/537: Loss=1.7321 (C:1.7321, R:0.0105)
Batch 200/537: Loss=1.7029 (C:1.7029, R:0.0105)
Batch 225/537: Loss=1.7134 (C:1.7134, R:0.0105)
Batch 250/537: Loss=1.7048 (C:1.7048, R:0.0105)
Batch 275/537: Loss=1.7210 (C:1.7210, R:0.0105)
Batch 300/537: Loss=1.7460 (C:1.7460, R:0.0105)
Batch 325/537: Loss=1.7469 (C:1.7469, R:0.0105)
Batch 350/537: Loss=1.7639 (C:1.7639, R:0.0105)
Batch 375/537: Loss=1.6961 (C:1.6961, R:0.0105)
Batch 400/537: Loss=1.7589 (C:1.7589, R:0.0105)
Batch 425/537: Loss=1.7527 (C:1.7527, R:0.0105)
Batch 450/537: Loss=1.7569 (C:1.7569, R:0.0105)
Batch 475/537: Loss=1.7794 (C:1.7794, R:0.0105)
Batch 500/537: Loss=1.7200 (C:1.7200, R:0.0105)
Batch 525/537: Loss=1.7399 (C:1.7399, R:0.0105)

============================================================
Epoch 6/300 completed in 27.5s
Train: Loss=1.7257 (C:1.7257, R:0.0105) Ratio=2.73x
Val:   Loss=1.7375 (C:1.7375, R:0.0104) Ratio=2.69x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.7375)
============================================================

🌍 Updating global dataset at epoch 7
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.820 ± 0.864
    Neg distances: 2.566 ± 1.338
    Separation ratio: 3.13x
    Gap: -5.699
    ✅ Excellent global separation!

Epoch 7 Training
----------------------------------------
Batch   0/537: Loss=1.6301 (C:1.6301, R:0.0105)
Batch  25/537: Loss=1.6055 (C:1.6055, R:0.0105)
Batch  50/537: Loss=1.6501 (C:1.6501, R:0.0105)
Batch  75/537: Loss=1.6962 (C:1.6962, R:0.0105)
Batch 100/537: Loss=1.6826 (C:1.6826, R:0.0105)
Batch 125/537: Loss=1.7019 (C:1.7019, R:0.0105)
Batch 150/537: Loss=1.6720 (C:1.6720, R:0.0105)
Batch 175/537: Loss=1.7074 (C:1.7074, R:0.0105)
Batch 200/537: Loss=1.6634 (C:1.6634, R:0.0105)
Batch 225/537: Loss=1.5940 (C:1.5940, R:0.0105)
Batch 250/537: Loss=1.6508 (C:1.6508, R:0.0105)
Batch 275/537: Loss=1.6623 (C:1.6623, R:0.0106)
Batch 300/537: Loss=1.6548 (C:1.6548, R:0.0105)
Batch 325/537: Loss=1.6537 (C:1.6537, R:0.0105)
Batch 350/537: Loss=1.6688 (C:1.6688, R:0.0105)
Batch 375/537: Loss=1.6656 (C:1.6656, R:0.0105)
Batch 400/537: Loss=1.6745 (C:1.6745, R:0.0105)
Batch 425/537: Loss=1.6691 (C:1.6691, R:0.0105)
Batch 450/537: Loss=1.6328 (C:1.6328, R:0.0105)
Batch 475/537: Loss=1.6223 (C:1.6223, R:0.0105)
Batch 500/537: Loss=1.7192 (C:1.7192, R:0.0105)
Batch 525/537: Loss=1.7129 (C:1.7129, R:0.0105)

============================================================
Epoch 7/300 completed in 27.5s
Train: Loss=1.6734 (C:1.6734, R:0.0105) Ratio=2.87x
Val:   Loss=1.6957 (C:1.6957, R:0.0104) Ratio=2.73x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.6957)
============================================================

🌍 Updating global dataset at epoch 8
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.818 ± 0.867
    Neg distances: 2.640 ± 1.366
    Separation ratio: 3.23x
    Gap: -6.412
    ✅ Excellent global separation!

Epoch 8 Training
----------------------------------------
Batch   0/537: Loss=1.6657 (C:1.6657, R:0.0105)
Batch  25/537: Loss=1.6282 (C:1.6282, R:0.0105)
Batch  50/537: Loss=1.6288 (C:1.6288, R:0.0105)
Batch  75/537: Loss=1.5580 (C:1.5580, R:0.0105)
Batch 100/537: Loss=1.6147 (C:1.6147, R:0.0105)
Batch 125/537: Loss=1.5629 (C:1.5629, R:0.0105)
Batch 150/537: Loss=1.6130 (C:1.6130, R:0.0105)
Batch 175/537: Loss=1.6111 (C:1.6111, R:0.0105)
Batch 200/537: Loss=1.6168 (C:1.6168, R:0.0105)
Batch 225/537: Loss=1.6200 (C:1.6200, R:0.0105)
Batch 250/537: Loss=1.6606 (C:1.6606, R:0.0105)
Batch 275/537: Loss=1.6253 (C:1.6253, R:0.0105)
Batch 300/537: Loss=1.6565 (C:1.6565, R:0.0105)
Batch 325/537: Loss=1.6457 (C:1.6457, R:0.0105)
Batch 350/537: Loss=1.6596 (C:1.6596, R:0.0105)
Batch 375/537: Loss=1.6302 (C:1.6302, R:0.0105)
Batch 400/537: Loss=1.6188 (C:1.6188, R:0.0105)
Batch 425/537: Loss=1.6115 (C:1.6115, R:0.0105)
Batch 450/537: Loss=1.6219 (C:1.6219, R:0.0105)
Batch 475/537: Loss=1.6187 (C:1.6187, R:0.0105)
Batch 500/537: Loss=1.6177 (C:1.6177, R:0.0105)
Batch 525/537: Loss=1.6788 (C:1.6788, R:0.0105)

============================================================
Epoch 8/300 completed in 27.6s
Train: Loss=1.6391 (C:1.6391, R:0.0105) Ratio=2.94x
Val:   Loss=1.6780 (C:1.6780, R:0.0104) Ratio=2.75x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.6780)
============================================================

🌍 Updating global dataset at epoch 9
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.808 ± 0.857
    Neg distances: 2.657 ± 1.364
    Separation ratio: 3.29x
    Gap: -5.682
    ✅ Excellent global separation!

Epoch 9 Training
----------------------------------------
Batch   0/537: Loss=1.6083 (C:1.6083, R:0.0105)
Batch  25/537: Loss=1.6283 (C:1.6283, R:0.0105)
Batch  50/537: Loss=1.6109 (C:1.6109, R:0.0105)
Batch  75/537: Loss=1.5658 (C:1.5658, R:0.0105)
Batch 100/537: Loss=1.6026 (C:1.6026, R:0.0105)
Batch 125/537: Loss=1.6346 (C:1.6346, R:0.0105)
Batch 150/537: Loss=1.6189 (C:1.6189, R:0.0105)
Batch 175/537: Loss=1.5857 (C:1.5857, R:0.0105)
Batch 200/537: Loss=1.6434 (C:1.6434, R:0.0105)
Batch 225/537: Loss=1.6357 (C:1.6357, R:0.0105)
Batch 250/537: Loss=1.6471 (C:1.6471, R:0.0105)
Batch 275/537: Loss=1.6529 (C:1.6529, R:0.0105)
Batch 300/537: Loss=1.6285 (C:1.6285, R:0.0105)
Batch 325/537: Loss=1.5935 (C:1.5935, R:0.0105)
Batch 350/537: Loss=1.6125 (C:1.6125, R:0.0105)
Batch 375/537: Loss=1.6187 (C:1.6187, R:0.0105)
Batch 400/537: Loss=1.6415 (C:1.6415, R:0.0105)
Batch 425/537: Loss=1.6299 (C:1.6299, R:0.0105)
Batch 450/537: Loss=1.5896 (C:1.5896, R:0.0105)
Batch 475/537: Loss=1.5522 (C:1.5522, R:0.0105)
Batch 500/537: Loss=1.6081 (C:1.6081, R:0.0104)
Batch 525/537: Loss=1.5963 (C:1.5963, R:0.0106)

============================================================
Epoch 9/300 completed in 26.7s
Train: Loss=1.6150 (C:1.6150, R:0.0105) Ratio=3.02x
Val:   Loss=1.6597 (C:1.6597, R:0.0104) Ratio=2.76x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.6597)
============================================================

🌍 Updating global dataset at epoch 10
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.800 ± 0.859
    Neg distances: 2.760 ± 1.394
    Separation ratio: 3.45x
    Gap: -5.892
    ✅ Excellent global separation!

Epoch 10 Training
----------------------------------------
Batch   0/537: Loss=1.5923 (C:1.5923, R:0.0105)
Batch  25/537: Loss=1.5853 (C:1.5853, R:0.0105)
Batch  50/537: Loss=1.5834 (C:1.5834, R:0.0105)
Batch  75/537: Loss=1.5142 (C:1.5142, R:0.0105)
Batch 100/537: Loss=1.6000 (C:1.6000, R:0.0105)
Batch 125/537: Loss=1.5535 (C:1.5535, R:0.0105)
Batch 150/537: Loss=1.5958 (C:1.5958, R:0.0105)
Batch 175/537: Loss=1.5792 (C:1.5792, R:0.0105)
Batch 200/537: Loss=1.5735 (C:1.5735, R:0.0105)
Batch 225/537: Loss=1.5596 (C:1.5596, R:0.0105)
Batch 250/537: Loss=1.5696 (C:1.5696, R:0.0105)
Batch 275/537: Loss=1.5862 (C:1.5862, R:0.0105)
Batch 300/537: Loss=1.6197 (C:1.6197, R:0.0105)
Batch 325/537: Loss=1.5698 (C:1.5698, R:0.0105)
Batch 350/537: Loss=1.5672 (C:1.5672, R:0.0105)
Batch 375/537: Loss=1.6001 (C:1.6001, R:0.0105)
Batch 400/537: Loss=1.6219 (C:1.6219, R:0.0105)
Batch 425/537: Loss=1.5316 (C:1.5316, R:0.0106)
Batch 450/537: Loss=1.5284 (C:1.5284, R:0.0105)
Batch 475/537: Loss=1.5643 (C:1.5643, R:0.0105)
Batch 500/537: Loss=1.5968 (C:1.5968, R:0.0105)
Batch 525/537: Loss=1.5764 (C:1.5764, R:0.0105)

============================================================
Epoch 10/300 completed in 27.0s
Train: Loss=1.5711 (C:1.5711, R:0.0105) Ratio=3.07x
Val:   Loss=1.6165 (C:1.6165, R:0.0104) Ratio=2.80x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.6165)
============================================================

🌍 Updating global dataset at epoch 11
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.788 ± 0.876
    Neg distances: 2.859 ± 1.416
    Separation ratio: 3.63x
    Gap: -5.962
    ✅ Excellent global separation!

Epoch 11 Training
----------------------------------------
Batch   0/537: Loss=1.5367 (C:1.5367, R:0.0105)
Batch  25/537: Loss=1.5113 (C:1.5113, R:0.0105)
Batch  50/537: Loss=1.5395 (C:1.5395, R:0.0105)
Batch  75/537: Loss=1.5406 (C:1.5406, R:0.0105)
Batch 100/537: Loss=1.5400 (C:1.5400, R:0.0105)
Batch 125/537: Loss=1.5382 (C:1.5382, R:0.0105)
Batch 150/537: Loss=1.5535 (C:1.5535, R:0.0105)
Batch 175/537: Loss=1.5463 (C:1.5463, R:0.0105)
Batch 200/537: Loss=1.5343 (C:1.5343, R:0.0105)
Batch 225/537: Loss=1.5466 (C:1.5466, R:0.0106)
Batch 250/537: Loss=1.5348 (C:1.5348, R:0.0105)
Batch 275/537: Loss=1.5244 (C:1.5244, R:0.0105)
Batch 300/537: Loss=1.4635 (C:1.4635, R:0.0105)
Batch 325/537: Loss=1.5010 (C:1.5010, R:0.0105)
Batch 350/537: Loss=1.5316 (C:1.5316, R:0.0105)
Batch 375/537: Loss=1.5231 (C:1.5231, R:0.0105)
Batch 400/537: Loss=1.5543 (C:1.5543, R:0.0105)
Batch 425/537: Loss=1.5244 (C:1.5244, R:0.0105)
Batch 450/537: Loss=1.5518 (C:1.5518, R:0.0105)
Batch 475/537: Loss=1.5012 (C:1.5012, R:0.0105)
Batch 500/537: Loss=1.5202 (C:1.5202, R:0.0105)
Batch 525/537: Loss=1.5402 (C:1.5402, R:0.0105)

============================================================
Epoch 11/300 completed in 26.8s
Train: Loss=1.5254 (C:1.5254, R:0.0105) Ratio=3.13x
Val:   Loss=1.5657 (C:1.5657, R:0.0104) Ratio=2.87x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.5657)
============================================================

🌍 Updating global dataset at epoch 12
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.776 ± 0.858
    Neg distances: 2.909 ± 1.429
    Separation ratio: 3.75x
    Gap: -6.114
    ✅ Excellent global separation!

Epoch 12 Training
----------------------------------------
Batch   0/537: Loss=1.4731 (C:1.4731, R:0.0105)
Batch  25/537: Loss=1.5391 (C:1.5391, R:0.0105)
Batch  50/537: Loss=1.4709 (C:1.4709, R:0.0105)
Batch  75/537: Loss=1.4413 (C:1.4413, R:0.0105)
Batch 100/537: Loss=1.5083 (C:1.5083, R:0.0105)
Batch 125/537: Loss=1.4414 (C:1.4414, R:0.0105)
Batch 150/537: Loss=1.5831 (C:1.5831, R:0.0105)
Batch 175/537: Loss=1.5164 (C:1.5164, R:0.0105)
Batch 200/537: Loss=1.5326 (C:1.5326, R:0.0105)
Batch 225/537: Loss=1.4958 (C:1.4958, R:0.0105)
Batch 250/537: Loss=1.5242 (C:1.5242, R:0.0105)
Batch 275/537: Loss=1.4880 (C:1.4880, R:0.0105)
Batch 300/537: Loss=1.5420 (C:1.5420, R:0.0105)
Batch 325/537: Loss=1.5364 (C:1.5364, R:0.0105)
Batch 350/537: Loss=1.4645 (C:1.4645, R:0.0105)
Batch 375/537: Loss=1.4683 (C:1.4683, R:0.0105)
Batch 400/537: Loss=1.4840 (C:1.4840, R:0.0106)
Batch 425/537: Loss=1.4307 (C:1.4307, R:0.0105)
Batch 450/537: Loss=1.5328 (C:1.5328, R:0.0105)
Batch 475/537: Loss=1.5140 (C:1.5140, R:0.0105)
Batch 500/537: Loss=1.4870 (C:1.4870, R:0.0105)
Batch 525/537: Loss=1.5019 (C:1.5019, R:0.0105)

============================================================
Epoch 12/300 completed in 26.9s
Train: Loss=1.4941 (C:1.4941, R:0.0105) Ratio=3.18x
Val:   Loss=1.5521 (C:1.5521, R:0.0104) Ratio=2.86x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.5521)
============================================================

🌍 Updating global dataset at epoch 13
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.788 ± 0.885
    Neg distances: 2.943 ± 1.443
    Separation ratio: 3.74x
    Gap: -6.019
    ✅ Excellent global separation!

Epoch 13 Training
----------------------------------------
Batch   0/537: Loss=1.4263 (C:1.4263, R:0.0105)
Batch  25/537: Loss=1.4624 (C:1.4624, R:0.0105)
Batch  50/537: Loss=1.4289 (C:1.4289, R:0.0105)
Batch  75/537: Loss=1.4607 (C:1.4607, R:0.0105)
Batch 100/537: Loss=1.4708 (C:1.4708, R:0.0105)
Batch 125/537: Loss=1.5197 (C:1.5197, R:0.0105)
Batch 150/537: Loss=1.5006 (C:1.5006, R:0.0105)
Batch 175/537: Loss=1.4456 (C:1.4456, R:0.0105)
Batch 200/537: Loss=1.4404 (C:1.4404, R:0.0106)
Batch 225/537: Loss=1.5149 (C:1.5149, R:0.0105)
Batch 250/537: Loss=1.4829 (C:1.4829, R:0.0105)
Batch 275/537: Loss=1.4242 (C:1.4242, R:0.0105)
Batch 300/537: Loss=1.4614 (C:1.4614, R:0.0105)
Batch 325/537: Loss=1.4617 (C:1.4617, R:0.0105)
Batch 350/537: Loss=1.4929 (C:1.4929, R:0.0105)
Batch 375/537: Loss=1.4537 (C:1.4537, R:0.0105)
Batch 400/537: Loss=1.5301 (C:1.5301, R:0.0105)
Batch 425/537: Loss=1.5088 (C:1.5088, R:0.0105)
Batch 450/537: Loss=1.4576 (C:1.4576, R:0.0105)
Batch 475/537: Loss=1.5254 (C:1.5254, R:0.0105)
Batch 500/537: Loss=1.5162 (C:1.5162, R:0.0105)
Batch 525/537: Loss=1.4697 (C:1.4697, R:0.0105)

============================================================
Epoch 13/300 completed in 26.9s
Train: Loss=1.4799 (C:1.4799, R:0.0105) Ratio=3.29x
Val:   Loss=1.5505 (C:1.5505, R:0.0104) Ratio=2.85x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.5505)
============================================================

🌍 Updating global dataset at epoch 14
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.787 ± 0.905
    Neg distances: 3.017 ± 1.466
    Separation ratio: 3.84x
    Gap: -6.008
    ✅ Excellent global separation!

Epoch 14 Training
----------------------------------------
Batch   0/537: Loss=1.4443 (C:1.4443, R:0.0105)
Batch  25/537: Loss=1.4196 (C:1.4196, R:0.0105)
Batch  50/537: Loss=1.4403 (C:1.4403, R:0.0105)
Batch  75/537: Loss=1.4311 (C:1.4311, R:0.0105)
Batch 100/537: Loss=1.4507 (C:1.4507, R:0.0106)
Batch 125/537: Loss=1.4301 (C:1.4301, R:0.0105)
Batch 150/537: Loss=1.4909 (C:1.4909, R:0.0105)
Batch 175/537: Loss=1.4063 (C:1.4063, R:0.0105)
Batch 200/537: Loss=1.3486 (C:1.3486, R:0.0105)
Batch 225/537: Loss=1.3852 (C:1.3852, R:0.0105)
Batch 250/537: Loss=1.4449 (C:1.4449, R:0.0105)
Batch 275/537: Loss=1.4507 (C:1.4507, R:0.0105)
Batch 300/537: Loss=1.4611 (C:1.4611, R:0.0105)
Batch 325/537: Loss=1.4415 (C:1.4415, R:0.0105)
Batch 350/537: Loss=1.4661 (C:1.4661, R:0.0105)
Batch 375/537: Loss=1.4245 (C:1.4245, R:0.0105)
Batch 400/537: Loss=1.5126 (C:1.5126, R:0.0106)
Batch 425/537: Loss=1.4746 (C:1.4746, R:0.0105)
Batch 450/537: Loss=1.4069 (C:1.4069, R:0.0105)
Batch 475/537: Loss=1.4904 (C:1.4904, R:0.0105)
Batch 500/537: Loss=1.4787 (C:1.4787, R:0.0105)
Batch 525/537: Loss=1.4434 (C:1.4434, R:0.0105)

============================================================
Epoch 14/300 completed in 26.9s
Train: Loss=1.4485 (C:1.4485, R:0.0105) Ratio=3.35x
Val:   Loss=1.5239 (C:1.5239, R:0.0104) Ratio=2.90x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.5239)
============================================================

🌍 Updating global dataset at epoch 15
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.771 ± 0.892
    Neg distances: 3.082 ± 1.485
    Separation ratio: 4.00x
    Gap: -6.247
    ✅ Excellent global separation!

Epoch 15 Training
----------------------------------------
Batch   0/537: Loss=1.4425 (C:1.4425, R:0.0105)
Batch  25/537: Loss=1.3769 (C:1.3769, R:0.0105)
Batch  50/537: Loss=1.4061 (C:1.4061, R:0.0105)
Batch  75/537: Loss=1.3583 (C:1.3583, R:0.0105)
Batch 100/537: Loss=1.3744 (C:1.3744, R:0.0105)
Batch 125/537: Loss=1.4252 (C:1.4252, R:0.0105)
Batch 150/537: Loss=1.3787 (C:1.3787, R:0.0105)
Batch 175/537: Loss=1.4120 (C:1.4120, R:0.0105)
Batch 200/537: Loss=1.4354 (C:1.4354, R:0.0105)
Batch 225/537: Loss=1.3762 (C:1.3762, R:0.0105)
Batch 250/537: Loss=1.4311 (C:1.4311, R:0.0105)
Batch 275/537: Loss=1.4092 (C:1.4092, R:0.0105)
Batch 300/537: Loss=1.4195 (C:1.4195, R:0.0105)
Batch 325/537: Loss=1.4077 (C:1.4077, R:0.0105)
Batch 350/537: Loss=1.4382 (C:1.4382, R:0.0105)
Batch 375/537: Loss=1.4414 (C:1.4414, R:0.0105)
Batch 400/537: Loss=1.4181 (C:1.4181, R:0.0105)
Batch 425/537: Loss=1.4139 (C:1.4139, R:0.0105)
Batch 450/537: Loss=1.4327 (C:1.4327, R:0.0106)
Batch 475/537: Loss=1.4462 (C:1.4462, R:0.0105)
Batch 500/537: Loss=1.3931 (C:1.3931, R:0.0105)
Batch 525/537: Loss=1.3205 (C:1.3205, R:0.0105)

============================================================
Epoch 15/300 completed in 27.2s
Train: Loss=1.4143 (C:1.4143, R:0.0105) Ratio=3.41x
Val:   Loss=1.4965 (C:1.4965, R:0.0104) Ratio=2.94x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.4965)
============================================================

🌍 Updating global dataset at epoch 16
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.752 ± 0.903
    Neg distances: 3.130 ± 1.488
    Separation ratio: 4.16x
    Gap: -6.056
    ✅ Excellent global separation!

Epoch 16 Training
----------------------------------------
Batch   0/537: Loss=1.3918 (C:1.3918, R:0.0105)
Batch  25/537: Loss=1.3842 (C:1.3842, R:0.0105)
Batch  50/537: Loss=1.3263 (C:1.3263, R:0.0105)
Batch  75/537: Loss=1.3391 (C:1.3391, R:0.0105)
Batch 100/537: Loss=1.3975 (C:1.3975, R:0.0105)
Batch 125/537: Loss=1.4049 (C:1.4049, R:0.0105)
Batch 150/537: Loss=1.3578 (C:1.3578, R:0.0105)
Batch 175/537: Loss=1.3324 (C:1.3324, R:0.0105)
Batch 200/537: Loss=1.3828 (C:1.3828, R:0.0105)
Batch 225/537: Loss=1.4381 (C:1.4381, R:0.0106)
Batch 250/537: Loss=1.3514 (C:1.3514, R:0.0105)
Batch 275/537: Loss=1.3416 (C:1.3416, R:0.0105)
Batch 300/537: Loss=1.4213 (C:1.4213, R:0.0105)
Batch 325/537: Loss=1.3793 (C:1.3793, R:0.0105)
Batch 350/537: Loss=1.3930 (C:1.3930, R:0.0105)
Batch 375/537: Loss=1.4252 (C:1.4252, R:0.0105)
Batch 400/537: Loss=1.4060 (C:1.4060, R:0.0105)
Batch 425/537: Loss=1.4415 (C:1.4415, R:0.0105)
Batch 450/537: Loss=1.3579 (C:1.3579, R:0.0106)
Batch 475/537: Loss=1.4271 (C:1.4271, R:0.0105)
Batch 500/537: Loss=1.4651 (C:1.4651, R:0.0105)
Batch 525/537: Loss=1.4169 (C:1.4169, R:0.0105)

============================================================
Epoch 16/300 completed in 27.1s
Train: Loss=1.3847 (C:1.3847, R:0.0105) Ratio=3.43x
Val:   Loss=1.4650 (C:1.4650, R:0.0104) Ratio=2.96x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.4650)
============================================================

🌍 Updating global dataset at epoch 17
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.743 ± 0.903
    Neg distances: 3.132 ± 1.484
    Separation ratio: 4.22x
    Gap: -5.907
    ✅ Excellent global separation!

Epoch 17 Training
----------------------------------------
Batch   0/537: Loss=1.3623 (C:1.3623, R:0.0105)
Batch  25/537: Loss=1.3706 (C:1.3706, R:0.0106)
Batch  50/537: Loss=1.3458 (C:1.3458, R:0.0105)
Batch  75/537: Loss=1.3388 (C:1.3388, R:0.0105)
Batch 100/537: Loss=1.3124 (C:1.3124, R:0.0105)
Batch 125/537: Loss=1.3643 (C:1.3643, R:0.0105)
Batch 150/537: Loss=1.3495 (C:1.3495, R:0.0105)
Batch 175/537: Loss=1.3073 (C:1.3073, R:0.0105)
Batch 200/537: Loss=1.4036 (C:1.4036, R:0.0106)
Batch 225/537: Loss=1.3610 (C:1.3610, R:0.0105)
Batch 250/537: Loss=1.3824 (C:1.3824, R:0.0105)
Batch 275/537: Loss=1.4094 (C:1.4094, R:0.0105)
Batch 300/537: Loss=1.3412 (C:1.3412, R:0.0106)
Batch 325/537: Loss=1.3874 (C:1.3874, R:0.0105)
Batch 350/537: Loss=1.3239 (C:1.3239, R:0.0105)
Batch 375/537: Loss=1.3813 (C:1.3813, R:0.0105)
Batch 400/537: Loss=1.3648 (C:1.3648, R:0.0105)
Batch 425/537: Loss=1.3119 (C:1.3119, R:0.0105)
Batch 450/537: Loss=1.3412 (C:1.3412, R:0.0105)
Batch 475/537: Loss=1.3471 (C:1.3471, R:0.0105)
Batch 500/537: Loss=1.4027 (C:1.4027, R:0.0105)
Batch 525/537: Loss=1.3738 (C:1.3738, R:0.0105)

============================================================
Epoch 17/300 completed in 27.0s
Train: Loss=1.3654 (C:1.3654, R:0.0105) Ratio=3.57x
Val:   Loss=1.4441 (C:1.4441, R:0.0104) Ratio=2.98x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.4441)
============================================================

🌍 Updating global dataset at epoch 18
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.764 ± 0.932
    Neg distances: 3.226 ± 1.529
    Separation ratio: 4.23x
    Gap: -5.969
    ✅ Excellent global separation!

Epoch 18 Training
----------------------------------------
Batch   0/537: Loss=1.3665 (C:1.3665, R:0.0105)
Batch  25/537: Loss=1.3144 (C:1.3144, R:0.0105)
Batch  50/537: Loss=1.3797 (C:1.3797, R:0.0105)
Batch  75/537: Loss=1.3011 (C:1.3011, R:0.0105)
Batch 100/537: Loss=1.3253 (C:1.3253, R:0.0106)
Batch 125/537: Loss=1.3076 (C:1.3076, R:0.0105)
Batch 150/537: Loss=1.3902 (C:1.3902, R:0.0105)
Batch 175/537: Loss=1.3437 (C:1.3437, R:0.0105)
Batch 200/537: Loss=1.3477 (C:1.3477, R:0.0105)
Batch 225/537: Loss=1.3172 (C:1.3172, R:0.0105)
Batch 250/537: Loss=1.3478 (C:1.3478, R:0.0106)
Batch 275/537: Loss=1.3447 (C:1.3447, R:0.0105)
Batch 300/537: Loss=1.3103 (C:1.3103, R:0.0105)
Batch 325/537: Loss=1.3441 (C:1.3441, R:0.0105)
Batch 350/537: Loss=1.3658 (C:1.3658, R:0.0105)
Batch 375/537: Loss=1.3691 (C:1.3691, R:0.0105)
Batch 400/537: Loss=1.3635 (C:1.3635, R:0.0105)
Batch 425/537: Loss=1.4341 (C:1.4341, R:0.0105)
Batch 450/537: Loss=1.4013 (C:1.4013, R:0.0105)
Batch 475/537: Loss=1.3558 (C:1.3558, R:0.0105)
Batch 500/537: Loss=1.3917 (C:1.3917, R:0.0105)
Batch 525/537: Loss=1.3441 (C:1.3441, R:0.0105)

============================================================
Epoch 18/300 completed in 27.0s
Train: Loss=1.3520 (C:1.3520, R:0.0105) Ratio=3.58x
Val:   Loss=1.4455 (C:1.4455, R:0.0104) Ratio=2.98x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 19
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.743 ± 0.913
    Neg distances: 3.247 ± 1.524
    Separation ratio: 4.37x
    Gap: -5.963
    ✅ Excellent global separation!

Epoch 19 Training
----------------------------------------
Batch   0/537: Loss=1.2882 (C:1.2882, R:0.0105)
Batch  25/537: Loss=1.3284 (C:1.3284, R:0.0106)
Batch  50/537: Loss=1.2980 (C:1.2980, R:0.0105)
Batch  75/537: Loss=1.4537 (C:1.4537, R:0.0105)
Batch 100/537: Loss=1.3955 (C:1.3955, R:0.0105)
Batch 125/537: Loss=1.3201 (C:1.3201, R:0.0105)
Batch 150/537: Loss=1.3096 (C:1.3096, R:0.0105)
Batch 175/537: Loss=1.2864 (C:1.2864, R:0.0105)
Batch 200/537: Loss=1.3182 (C:1.3182, R:0.0105)
Batch 225/537: Loss=1.3013 (C:1.3013, R:0.0105)
Batch 250/537: Loss=1.3832 (C:1.3832, R:0.0105)
Batch 275/537: Loss=1.3037 (C:1.3037, R:0.0105)
Batch 300/537: Loss=1.2814 (C:1.2814, R:0.0105)
Batch 325/537: Loss=1.2829 (C:1.2829, R:0.0105)
Batch 350/537: Loss=1.3623 (C:1.3623, R:0.0105)
Batch 375/537: Loss=1.3108 (C:1.3108, R:0.0105)
Batch 400/537: Loss=1.3384 (C:1.3384, R:0.0105)
Batch 425/537: Loss=1.3660 (C:1.3660, R:0.0105)
Batch 450/537: Loss=1.3124 (C:1.3124, R:0.0105)
Batch 475/537: Loss=1.3285 (C:1.3285, R:0.0105)
Batch 500/537: Loss=1.3962 (C:1.3962, R:0.0106)
Batch 525/537: Loss=1.3393 (C:1.3393, R:0.0105)

============================================================
Epoch 19/300 completed in 27.0s
Train: Loss=1.3205 (C:1.3205, R:0.0105) Ratio=3.62x
Val:   Loss=1.4060 (C:1.4060, R:0.0104) Ratio=2.99x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.4060)
============================================================

🌍 Updating global dataset at epoch 20
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.741 ± 0.941
    Neg distances: 3.336 ± 1.560
    Separation ratio: 4.50x
    Gap: -6.112
    ✅ Excellent global separation!

Epoch 20 Training
----------------------------------------
Batch   0/537: Loss=1.2762 (C:1.2762, R:0.0105)
Batch  25/537: Loss=1.2720 (C:1.2720, R:0.0106)
Batch  50/537: Loss=1.2286 (C:1.2286, R:0.0105)
Batch  75/537: Loss=1.3149 (C:1.3149, R:0.0105)
Batch 100/537: Loss=1.3036 (C:1.3036, R:0.0105)
Batch 125/537: Loss=1.2846 (C:1.2846, R:0.0105)
Batch 150/537: Loss=1.3584 (C:1.3584, R:0.0105)
Batch 175/537: Loss=1.2956 (C:1.2956, R:0.0105)
Batch 200/537: Loss=1.2198 (C:1.2198, R:0.0105)
Batch 225/537: Loss=1.3327 (C:1.3327, R:0.0105)
Batch 250/537: Loss=1.3439 (C:1.3439, R:0.0105)
Batch 275/537: Loss=1.3117 (C:1.3117, R:0.0105)
Batch 300/537: Loss=1.2494 (C:1.2494, R:0.0105)
Batch 325/537: Loss=1.3115 (C:1.3115, R:0.0105)
Batch 350/537: Loss=1.2719 (C:1.2719, R:0.0105)
Batch 375/537: Loss=1.3652 (C:1.3652, R:0.0105)
Batch 400/537: Loss=1.2644 (C:1.2644, R:0.0105)
Batch 425/537: Loss=1.2733 (C:1.2733, R:0.0105)
Batch 450/537: Loss=1.2902 (C:1.2902, R:0.0105)
Batch 475/537: Loss=1.3852 (C:1.3852, R:0.0105)
Batch 500/537: Loss=1.2775 (C:1.2775, R:0.0105)
Batch 525/537: Loss=1.3213 (C:1.3213, R:0.0105)

============================================================
Epoch 20/300 completed in 27.9s
Train: Loss=1.2958 (C:1.2958, R:0.0105) Ratio=3.65x
Val:   Loss=1.4043 (C:1.4043, R:0.0104) Ratio=2.98x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.4043)
Checkpoint saved at epoch 20
============================================================

🌍 Updating global dataset at epoch 21
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.697 ± 0.907
    Neg distances: 3.407 ± 1.563
    Separation ratio: 4.89x
    Gap: -6.082
    ✅ Excellent global separation!

Epoch 21 Training
----------------------------------------
Batch   0/537: Loss=1.2373 (C:1.2373, R:0.0105)
Batch  25/537: Loss=1.3017 (C:1.3017, R:0.0105)
Batch  50/537: Loss=1.2770 (C:1.2770, R:0.0105)
Batch  75/537: Loss=1.2922 (C:1.2922, R:0.0105)
Batch 100/537: Loss=1.2314 (C:1.2314, R:0.0105)
Batch 125/537: Loss=1.2381 (C:1.2381, R:0.0105)
Batch 150/537: Loss=1.3035 (C:1.3035, R:0.0105)
Batch 175/537: Loss=1.2814 (C:1.2814, R:0.0105)
Batch 200/537: Loss=1.2368 (C:1.2368, R:0.0105)
Batch 225/537: Loss=1.3232 (C:1.3232, R:0.0105)
Batch 250/537: Loss=1.2335 (C:1.2335, R:0.0105)
Batch 275/537: Loss=1.2587 (C:1.2587, R:0.0106)
Batch 300/537: Loss=1.2571 (C:1.2571, R:0.0105)
Batch 325/537: Loss=1.2350 (C:1.2350, R:0.0105)
Batch 350/537: Loss=1.2044 (C:1.2044, R:0.0106)
Batch 375/537: Loss=1.2553 (C:1.2553, R:0.0105)
Batch 400/537: Loss=1.2105 (C:1.2105, R:0.0105)
Batch 425/537: Loss=1.3466 (C:1.3466, R:0.0105)
Batch 450/537: Loss=1.2494 (C:1.2494, R:0.0105)
Batch 475/537: Loss=1.2767 (C:1.2767, R:0.0105)
Batch 500/537: Loss=1.2881 (C:1.2881, R:0.0105)
Batch 525/537: Loss=1.2547 (C:1.2547, R:0.0105)

============================================================
Epoch 21/300 completed in 27.2s
Train: Loss=1.2460 (C:1.2460, R:0.0105) Ratio=3.65x
Val:   Loss=1.3542 (C:1.3542, R:0.0104) Ratio=3.02x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.3542)
============================================================

🌍 Updating global dataset at epoch 22
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.730 ± 0.970
    Neg distances: 3.423 ± 1.579
    Separation ratio: 4.69x
    Gap: -6.110
    ✅ Excellent global separation!

Epoch 22 Training
----------------------------------------
Batch   0/537: Loss=1.2399 (C:1.2399, R:0.0105)
Batch  25/537: Loss=1.3119 (C:1.3119, R:0.0105)
Batch  50/537: Loss=1.2345 (C:1.2345, R:0.0105)
Batch  75/537: Loss=1.2375 (C:1.2375, R:0.0105)
Batch 100/537: Loss=1.2534 (C:1.2534, R:0.0105)
Batch 125/537: Loss=1.2144 (C:1.2144, R:0.0105)
Batch 150/537: Loss=1.2884 (C:1.2884, R:0.0105)
Batch 175/537: Loss=1.1880 (C:1.1880, R:0.0105)
Batch 200/537: Loss=1.3035 (C:1.3035, R:0.0105)
Batch 225/537: Loss=1.1870 (C:1.1870, R:0.0105)
Batch 250/537: Loss=1.2394 (C:1.2394, R:0.0105)
Batch 275/537: Loss=1.2243 (C:1.2243, R:0.0105)
Batch 300/537: Loss=1.2385 (C:1.2385, R:0.0105)
Batch 325/537: Loss=1.2294 (C:1.2294, R:0.0105)
Batch 350/537: Loss=1.2601 (C:1.2601, R:0.0105)
Batch 375/537: Loss=1.2693 (C:1.2693, R:0.0105)
Batch 400/537: Loss=1.2460 (C:1.2460, R:0.0105)
Batch 425/537: Loss=1.1804 (C:1.1804, R:0.0105)
Batch 450/537: Loss=1.2309 (C:1.2309, R:0.0105)
Batch 475/537: Loss=1.2012 (C:1.2012, R:0.0105)
Batch 500/537: Loss=1.3125 (C:1.3125, R:0.0105)
Batch 525/537: Loss=1.2664 (C:1.2664, R:0.0105)

============================================================
Epoch 22/300 completed in 27.8s
Train: Loss=1.2525 (C:1.2525, R:0.0105) Ratio=3.81x
Val:   Loss=1.3536 (C:1.3536, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.3536)
============================================================

🌍 Updating global dataset at epoch 23
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.707 ± 0.936
    Neg distances: 3.477 ± 1.588
    Separation ratio: 4.92x
    Gap: -6.177
    ✅ Excellent global separation!

Epoch 23 Training
----------------------------------------
Batch   0/537: Loss=1.1797 (C:1.1797, R:0.0105)
Batch  25/537: Loss=1.1901 (C:1.1901, R:0.0105)
Batch  50/537: Loss=1.2511 (C:1.2511, R:0.0105)
Batch  75/537: Loss=1.2628 (C:1.2628, R:0.0105)
Batch 100/537: Loss=1.2154 (C:1.2154, R:0.0105)
Batch 125/537: Loss=1.1493 (C:1.1493, R:0.0105)
Batch 150/537: Loss=1.2599 (C:1.2599, R:0.0105)
Batch 175/537: Loss=1.2225 (C:1.2225, R:0.0105)
Batch 200/537: Loss=1.1907 (C:1.1907, R:0.0106)
Batch 225/537: Loss=1.1752 (C:1.1752, R:0.0105)
Batch 250/537: Loss=1.2291 (C:1.2291, R:0.0105)
Batch 275/537: Loss=1.2505 (C:1.2505, R:0.0105)
Batch 300/537: Loss=1.2193 (C:1.2193, R:0.0105)
Batch 325/537: Loss=1.1749 (C:1.1749, R:0.0105)
Batch 350/537: Loss=1.2003 (C:1.2003, R:0.0105)
Batch 375/537: Loss=1.2653 (C:1.2653, R:0.0105)
Batch 400/537: Loss=1.2579 (C:1.2579, R:0.0106)
Batch 425/537: Loss=1.2240 (C:1.2240, R:0.0105)
Batch 450/537: Loss=1.2180 (C:1.2180, R:0.0105)
Batch 475/537: Loss=1.2455 (C:1.2455, R:0.0105)
Batch 500/537: Loss=1.2588 (C:1.2588, R:0.0105)
Batch 525/537: Loss=1.2202 (C:1.2202, R:0.0106)

============================================================
Epoch 23/300 completed in 27.4s
Train: Loss=1.2195 (C:1.2195, R:0.0105) Ratio=3.79x
Val:   Loss=1.3248 (C:1.3248, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.3248)
============================================================

🌍 Updating global dataset at epoch 24
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.702 ± 0.938
    Neg distances: 3.510 ± 1.593
    Separation ratio: 5.00x
    Gap: -6.275
    ✅ Excellent global separation!

Epoch 24 Training
----------------------------------------
Batch   0/537: Loss=1.1528 (C:1.1528, R:0.0105)
Batch  25/537: Loss=1.2239 (C:1.2239, R:0.0105)
Batch  50/537: Loss=1.1808 (C:1.1808, R:0.0105)
Batch  75/537: Loss=1.1871 (C:1.1871, R:0.0105)
Batch 100/537: Loss=1.2359 (C:1.2359, R:0.0105)
Batch 125/537: Loss=1.2032 (C:1.2032, R:0.0105)
Batch 150/537: Loss=1.1586 (C:1.1586, R:0.0105)
Batch 175/537: Loss=1.2139 (C:1.2139, R:0.0105)
Batch 200/537: Loss=1.1407 (C:1.1407, R:0.0105)
Batch 225/537: Loss=1.1547 (C:1.1547, R:0.0105)
Batch 250/537: Loss=1.1534 (C:1.1534, R:0.0105)
Batch 275/537: Loss=1.2334 (C:1.2334, R:0.0105)
Batch 300/537: Loss=1.1836 (C:1.1836, R:0.0105)
Batch 325/537: Loss=1.1777 (C:1.1777, R:0.0105)
Batch 350/537: Loss=1.2094 (C:1.2094, R:0.0105)
Batch 375/537: Loss=1.2551 (C:1.2551, R:0.0105)
Batch 400/537: Loss=1.2529 (C:1.2529, R:0.0105)
Batch 425/537: Loss=1.2175 (C:1.2175, R:0.0105)
Batch 450/537: Loss=1.1828 (C:1.1828, R:0.0105)
Batch 475/537: Loss=1.2177 (C:1.2177, R:0.0105)
Batch 500/537: Loss=1.2164 (C:1.2164, R:0.0105)
Batch 525/537: Loss=1.2159 (C:1.2159, R:0.0105)

============================================================
Epoch 24/300 completed in 27.8s
Train: Loss=1.1970 (C:1.1970, R:0.0105) Ratio=3.86x
Val:   Loss=1.3180 (C:1.3180, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.3180)
============================================================

🌍 Updating global dataset at epoch 25
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.687 ± 0.920
    Neg distances: 3.559 ± 1.599
    Separation ratio: 5.18x
    Gap: -6.325
    ✅ Excellent global separation!

Epoch 25 Training
----------------------------------------
Batch   0/537: Loss=1.2301 (C:1.2301, R:0.0105)
Batch  25/537: Loss=1.1944 (C:1.1944, R:0.0105)
Batch  50/537: Loss=1.1637 (C:1.1637, R:0.0105)
Batch  75/537: Loss=1.1261 (C:1.1261, R:0.0105)
Batch 100/537: Loss=1.1203 (C:1.1203, R:0.0105)
Batch 125/537: Loss=1.2263 (C:1.2263, R:0.0105)
Batch 150/537: Loss=1.1481 (C:1.1481, R:0.0105)
Batch 175/537: Loss=1.2509 (C:1.2509, R:0.0105)
Batch 200/537: Loss=1.1886 (C:1.1886, R:0.0105)
Batch 225/537: Loss=1.1418 (C:1.1418, R:0.0105)
Batch 250/537: Loss=1.1930 (C:1.1930, R:0.0105)
Batch 275/537: Loss=1.2091 (C:1.2091, R:0.0105)
Batch 300/537: Loss=1.1782 (C:1.1782, R:0.0105)
Batch 325/537: Loss=1.0795 (C:1.0795, R:0.0105)
Batch 350/537: Loss=1.1983 (C:1.1983, R:0.0105)
Batch 375/537: Loss=1.1738 (C:1.1738, R:0.0105)
Batch 400/537: Loss=1.1511 (C:1.1511, R:0.0105)
Batch 425/537: Loss=1.1806 (C:1.1806, R:0.0105)
Batch 450/537: Loss=1.1539 (C:1.1539, R:0.0105)
Batch 475/537: Loss=1.1571 (C:1.1571, R:0.0105)
Batch 500/537: Loss=1.1765 (C:1.1765, R:0.0105)
Batch 525/537: Loss=1.2165 (C:1.2165, R:0.0105)

============================================================
Epoch 25/300 completed in 27.6s
Train: Loss=1.1707 (C:1.1707, R:0.0105) Ratio=3.88x
Val:   Loss=1.2856 (C:1.2856, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.2856)
============================================================

🌍 Updating global dataset at epoch 26
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.661 ± 0.907
    Neg distances: 3.612 ± 1.611
    Separation ratio: 5.47x
    Gap: -6.409
    ✅ Excellent global separation!

Epoch 26 Training
----------------------------------------
Batch   0/537: Loss=1.1266 (C:1.1266, R:0.0106)
Batch  25/537: Loss=1.1888 (C:1.1888, R:0.0105)
Batch  50/537: Loss=1.1232 (C:1.1232, R:0.0105)
Batch  75/537: Loss=1.1077 (C:1.1077, R:0.0105)
Batch 100/537: Loss=1.1147 (C:1.1147, R:0.0105)
Batch 125/537: Loss=1.1090 (C:1.1090, R:0.0105)
Batch 150/537: Loss=1.1276 (C:1.1276, R:0.0105)
Batch 175/537: Loss=1.1140 (C:1.1140, R:0.0105)
Batch 200/537: Loss=1.1203 (C:1.1203, R:0.0105)
Batch 225/537: Loss=1.1250 (C:1.1250, R:0.0105)
Batch 250/537: Loss=1.1080 (C:1.1080, R:0.0105)
Batch 275/537: Loss=1.1853 (C:1.1853, R:0.0105)
Batch 300/537: Loss=1.1108 (C:1.1108, R:0.0105)
Batch 325/537: Loss=1.1670 (C:1.1670, R:0.0105)
Batch 350/537: Loss=1.1438 (C:1.1438, R:0.0106)
Batch 375/537: Loss=1.1266 (C:1.1266, R:0.0105)
Batch 400/537: Loss=1.1386 (C:1.1386, R:0.0105)
Batch 425/537: Loss=1.1779 (C:1.1779, R:0.0105)
Batch 450/537: Loss=1.1836 (C:1.1836, R:0.0105)
Batch 475/537: Loss=1.1600 (C:1.1600, R:0.0105)
Batch 500/537: Loss=1.1265 (C:1.1265, R:0.0106)
Batch 525/537: Loss=1.1406 (C:1.1406, R:0.0106)

============================================================
Epoch 26/300 completed in 28.0s
Train: Loss=1.1405 (C:1.1405, R:0.0105) Ratio=3.96x
Val:   Loss=1.2660 (C:1.2660, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.2660)
============================================================

🌍 Updating global dataset at epoch 27
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.681 ± 0.967
    Neg distances: 3.638 ± 1.633
    Separation ratio: 5.34x
    Gap: -6.423
    ✅ Excellent global separation!

Epoch 27 Training
----------------------------------------
Batch   0/537: Loss=1.1408 (C:1.1408, R:0.0105)
Batch  25/537: Loss=1.1159 (C:1.1159, R:0.0105)
Batch  50/537: Loss=1.1592 (C:1.1592, R:0.0105)
Batch  75/537: Loss=1.1776 (C:1.1776, R:0.0105)
Batch 100/537: Loss=1.1336 (C:1.1336, R:0.0105)
Batch 125/537: Loss=1.1717 (C:1.1717, R:0.0105)
Batch 150/537: Loss=1.1613 (C:1.1613, R:0.0106)
Batch 175/537: Loss=1.1975 (C:1.1975, R:0.0106)
Batch 200/537: Loss=1.1319 (C:1.1319, R:0.0105)
Batch 225/537: Loss=1.0565 (C:1.0565, R:0.0105)
Batch 250/537: Loss=1.1526 (C:1.1526, R:0.0105)
Batch 275/537: Loss=1.1601 (C:1.1601, R:0.0105)
Batch 300/537: Loss=1.1402 (C:1.1402, R:0.0105)
Batch 325/537: Loss=1.1571 (C:1.1571, R:0.0105)
Batch 350/537: Loss=1.1426 (C:1.1426, R:0.0105)
Batch 375/537: Loss=1.1533 (C:1.1533, R:0.0105)
Batch 400/537: Loss=1.1580 (C:1.1580, R:0.0105)
Batch 425/537: Loss=1.2109 (C:1.2109, R:0.0105)
Batch 450/537: Loss=1.1528 (C:1.1528, R:0.0105)
Batch 475/537: Loss=1.1605 (C:1.1605, R:0.0105)
Batch 500/537: Loss=1.1387 (C:1.1387, R:0.0106)
Batch 525/537: Loss=1.1460 (C:1.1460, R:0.0105)

============================================================
Epoch 27/300 completed in 27.5s
Train: Loss=1.1437 (C:1.1437, R:0.0105) Ratio=3.97x
Val:   Loss=1.2931 (C:1.2931, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 28
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.686 ± 0.959
    Neg distances: 3.607 ± 1.622
    Separation ratio: 5.26x
    Gap: -6.333
    ✅ Excellent global separation!

Epoch 28 Training
----------------------------------------
Batch   0/537: Loss=1.1098 (C:1.1098, R:0.0105)
Batch  25/537: Loss=1.1304 (C:1.1304, R:0.0105)
Batch  50/537: Loss=1.1347 (C:1.1347, R:0.0104)
Batch  75/537: Loss=1.1459 (C:1.1459, R:0.0105)
Batch 100/537: Loss=1.1190 (C:1.1190, R:0.0105)
Batch 125/537: Loss=1.1006 (C:1.1006, R:0.0105)
Batch 150/537: Loss=1.1103 (C:1.1103, R:0.0105)
Batch 175/537: Loss=1.1509 (C:1.1509, R:0.0105)
Batch 200/537: Loss=1.1349 (C:1.1349, R:0.0105)
Batch 225/537: Loss=1.1517 (C:1.1517, R:0.0105)
Batch 250/537: Loss=1.1968 (C:1.1968, R:0.0105)
Batch 275/537: Loss=1.1726 (C:1.1726, R:0.0105)
Batch 300/537: Loss=1.2370 (C:1.2370, R:0.0105)
Batch 325/537: Loss=1.1515 (C:1.1515, R:0.0105)
Batch 350/537: Loss=1.1126 (C:1.1126, R:0.0105)
Batch 375/537: Loss=1.1343 (C:1.1343, R:0.0105)
Batch 400/537: Loss=1.1170 (C:1.1170, R:0.0105)
Batch 425/537: Loss=1.1334 (C:1.1334, R:0.0105)
Batch 450/537: Loss=1.1681 (C:1.1681, R:0.0106)
Batch 475/537: Loss=1.1359 (C:1.1359, R:0.0105)
Batch 500/537: Loss=1.1515 (C:1.1515, R:0.0105)
Batch 525/537: Loss=1.1431 (C:1.1431, R:0.0105)

============================================================
Epoch 28/300 completed in 27.6s
Train: Loss=1.1443 (C:1.1443, R:0.0105) Ratio=4.06x
Val:   Loss=1.2886 (C:1.2886, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.000
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 29
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.668 ± 0.949
    Neg distances: 3.644 ± 1.627
    Separation ratio: 5.46x
    Gap: -6.554
    ✅ Excellent global separation!

Epoch 29 Training
----------------------------------------
Batch   0/537: Loss=1.1525 (C:1.1525, R:0.0105)
Batch  25/537: Loss=1.1152 (C:1.1152, R:0.0105)
Batch  50/537: Loss=1.1280 (C:1.1280, R:0.0105)
Batch  75/537: Loss=1.1330 (C:1.1330, R:0.0105)
Batch 100/537: Loss=1.1416 (C:1.1416, R:0.0105)
Batch 125/537: Loss=1.1387 (C:1.1387, R:0.0105)
Batch 150/537: Loss=1.1350 (C:1.1350, R:0.0105)
Batch 175/537: Loss=1.1306 (C:1.1306, R:0.0105)
Batch 200/537: Loss=1.1124 (C:1.1124, R:0.0105)
Batch 225/537: Loss=1.1353 (C:1.1353, R:0.0105)
Batch 250/537: Loss=1.0898 (C:1.0898, R:0.0105)
Batch 275/537: Loss=1.0919 (C:1.0919, R:0.0105)
Batch 300/537: Loss=1.1682 (C:1.1682, R:0.0106)
Batch 325/537: Loss=1.1089 (C:1.1089, R:0.0105)
Batch 350/537: Loss=1.1229 (C:1.1229, R:0.0105)
Batch 375/537: Loss=1.1681 (C:1.1681, R:0.0105)
Batch 400/537: Loss=1.1249 (C:1.1249, R:0.0105)
Batch 425/537: Loss=1.0859 (C:1.0859, R:0.0105)
Batch 450/537: Loss=1.1284 (C:1.1284, R:0.0105)
Batch 475/537: Loss=1.1058 (C:1.1058, R:0.0105)
Batch 500/537: Loss=1.0825 (C:1.0825, R:0.0105)
Batch 525/537: Loss=1.0720 (C:1.0720, R:0.0105)

============================================================
Epoch 29/300 completed in 27.2s
Train: Loss=1.1201 (C:1.1201, R:0.0105) Ratio=4.06x
Val:   Loss=1.2559 (C:1.2559, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.2559)
============================================================

🌍 Updating global dataset at epoch 30
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.672 ± 0.957
    Neg distances: 3.698 ± 1.653
    Separation ratio: 5.51x
    Gap: -6.553
    ✅ Excellent global separation!

Epoch 30 Training
----------------------------------------
Batch   0/537: Loss=1.0883 (C:1.0883, R:0.0105)
Batch  25/537: Loss=1.0705 (C:1.0705, R:0.0105)
Batch  50/537: Loss=1.0907 (C:1.0907, R:0.0105)
Batch  75/537: Loss=1.1276 (C:1.1276, R:0.0105)
Batch 100/537: Loss=1.0541 (C:1.0541, R:0.0105)
Batch 125/537: Loss=1.1257 (C:1.1257, R:0.0105)
Batch 150/537: Loss=1.1017 (C:1.1017, R:0.0105)
Batch 175/537: Loss=1.1274 (C:1.1274, R:0.0105)
Batch 200/537: Loss=1.1152 (C:1.1152, R:0.0105)
Batch 225/537: Loss=1.1566 (C:1.1566, R:0.0105)
Batch 250/537: Loss=1.1019 (C:1.1019, R:0.0105)
Batch 275/537: Loss=1.0666 (C:1.0666, R:0.0105)
Batch 300/537: Loss=1.2013 (C:1.2013, R:0.0105)
Batch 325/537: Loss=1.1216 (C:1.1216, R:0.0106)
Batch 350/537: Loss=1.1279 (C:1.1279, R:0.0105)
Batch 375/537: Loss=1.1561 (C:1.1561, R:0.0105)
Batch 400/537: Loss=1.1294 (C:1.1294, R:0.0105)
Batch 425/537: Loss=1.1031 (C:1.1031, R:0.0105)
Batch 450/537: Loss=1.1074 (C:1.1074, R:0.0105)
Batch 475/537: Loss=1.0979 (C:1.0979, R:0.0105)
Batch 500/537: Loss=1.1125 (C:1.1125, R:0.0105)
Batch 525/537: Loss=1.1338 (C:1.1338, R:0.0105)

============================================================
Epoch 30/300 completed in 27.6s
Train: Loss=1.1126 (C:1.1126, R:0.0105) Ratio=4.14x
Val:   Loss=1.2493 (C:1.2493, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.2493)
============================================================

🌍 Updating global dataset at epoch 31
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.643 ± 0.956
    Neg distances: 3.724 ± 1.646
    Separation ratio: 5.79x
    Gap: -6.573
    ✅ Excellent global separation!

Epoch 31 Training
----------------------------------------
Batch   0/537: Loss=1.1516 (C:1.1516, R:0.0105)
Batch  25/537: Loss=1.0565 (C:1.0565, R:0.0105)
Batch  50/537: Loss=1.0976 (C:1.0976, R:0.0105)
Batch  75/537: Loss=1.0326 (C:1.0326, R:0.0105)
Batch 100/537: Loss=1.0368 (C:1.0368, R:0.0105)
Batch 125/537: Loss=1.0746 (C:1.0746, R:0.0105)
Batch 150/537: Loss=1.0938 (C:1.0938, R:0.0105)
Batch 175/537: Loss=1.0998 (C:1.0998, R:0.0106)
Batch 200/537: Loss=1.1396 (C:1.1396, R:0.0105)
Batch 225/537: Loss=1.1216 (C:1.1216, R:0.0105)
Batch 250/537: Loss=1.0936 (C:1.0936, R:0.0105)
Batch 275/537: Loss=1.0330 (C:1.0330, R:0.0105)
Batch 300/537: Loss=1.1326 (C:1.1326, R:0.0105)
Batch 325/537: Loss=1.1118 (C:1.1118, R:0.0105)
Batch 350/537: Loss=1.1033 (C:1.1033, R:0.0105)
Batch 375/537: Loss=1.0815 (C:1.0815, R:0.0105)
Batch 400/537: Loss=1.0496 (C:1.0496, R:0.0105)
Batch 425/537: Loss=1.1271 (C:1.1271, R:0.0105)
Batch 450/537: Loss=1.0607 (C:1.0607, R:0.0105)
Batch 475/537: Loss=1.0815 (C:1.0815, R:0.0105)
Batch 500/537: Loss=1.0980 (C:1.0980, R:0.0105)
Batch 525/537: Loss=1.0926 (C:1.0926, R:0.0105)

============================================================
Epoch 31/300 completed in 27.6s
Train: Loss=1.0835 (C:1.0835, R:0.0105) Ratio=4.07x
Val:   Loss=1.2275 (C:1.2275, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.015
✅ New best model saved (Val Loss: 1.2275)
============================================================

🌍 Updating global dataset at epoch 32
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.627 ± 0.934
    Neg distances: 3.769 ± 1.654
    Separation ratio: 6.01x
    Gap: -6.487
    ✅ Excellent global separation!

Epoch 32 Training
----------------------------------------
Batch   0/537: Loss=1.0316 (C:1.0316, R:0.0105)
Batch  25/537: Loss=1.0820 (C:1.0820, R:0.0105)
Batch  50/537: Loss=1.1100 (C:1.1100, R:0.0106)
Batch  75/537: Loss=1.0803 (C:1.0803, R:0.0105)
Batch 100/537: Loss=1.0340 (C:1.0340, R:0.0105)
Batch 125/537: Loss=1.0655 (C:1.0655, R:0.0105)
Batch 150/537: Loss=1.0546 (C:1.0546, R:0.0105)
Batch 175/537: Loss=1.0180 (C:1.0180, R:0.0105)
Batch 200/537: Loss=1.1291 (C:1.1291, R:0.0105)
Batch 225/537: Loss=1.0653 (C:1.0653, R:0.0105)
Batch 250/537: Loss=1.1170 (C:1.1170, R:0.0105)
Batch 275/537: Loss=1.0529 (C:1.0529, R:0.0105)
Batch 300/537: Loss=1.0749 (C:1.0749, R:0.0105)
Batch 325/537: Loss=1.0557 (C:1.0557, R:0.0105)
Batch 350/537: Loss=1.0418 (C:1.0418, R:0.0106)
Batch 375/537: Loss=1.0726 (C:1.0726, R:0.0105)
Batch 400/537: Loss=1.0563 (C:1.0563, R:0.0105)
Batch 425/537: Loss=1.0562 (C:1.0562, R:0.0105)
Batch 450/537: Loss=1.0181 (C:1.0181, R:0.0105)
Batch 475/537: Loss=1.0530 (C:1.0530, R:0.0105)
Batch 500/537: Loss=1.0593 (C:1.0593, R:0.0105)
Batch 525/537: Loss=1.0698 (C:1.0698, R:0.0105)

============================================================
Epoch 32/300 completed in 27.7s
Train: Loss=1.0624 (C:1.0624, R:0.0105) Ratio=4.16x
Val:   Loss=1.2205 (C:1.2205, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.030
✅ New best model saved (Val Loss: 1.2205)
============================================================

🌍 Updating global dataset at epoch 33
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.658 ± 0.996
    Neg distances: 3.783 ± 1.670
    Separation ratio: 5.74x
    Gap: -6.534
    ✅ Excellent global separation!

Epoch 33 Training
----------------------------------------
Batch   0/537: Loss=1.1002 (C:1.1002, R:0.0105)
Batch  25/537: Loss=1.0443 (C:1.0443, R:0.0105)
Batch  50/537: Loss=1.1110 (C:1.1110, R:0.0105)
Batch  75/537: Loss=1.0320 (C:1.0320, R:0.0105)
Batch 100/537: Loss=1.0664 (C:1.0664, R:0.0105)
Batch 125/537: Loss=1.0731 (C:1.0731, R:0.0105)
Batch 150/537: Loss=1.0445 (C:1.0445, R:0.0105)
Batch 175/537: Loss=1.0936 (C:1.0936, R:0.0105)
Batch 200/537: Loss=1.0740 (C:1.0740, R:0.0105)
Batch 225/537: Loss=1.0778 (C:1.0778, R:0.0105)
Batch 250/537: Loss=1.0583 (C:1.0583, R:0.0105)
Batch 275/537: Loss=1.1088 (C:1.1088, R:0.0105)
Batch 300/537: Loss=1.1456 (C:1.1456, R:0.0105)
Batch 325/537: Loss=1.0730 (C:1.0730, R:0.0105)
Batch 350/537: Loss=1.0899 (C:1.0899, R:0.0105)
Batch 375/537: Loss=1.0686 (C:1.0686, R:0.0105)
Batch 400/537: Loss=1.1120 (C:1.1120, R:0.0105)
Batch 425/537: Loss=1.0539 (C:1.0539, R:0.0105)
Batch 450/537: Loss=1.0973 (C:1.0973, R:0.0105)
Batch 475/537: Loss=1.0990 (C:1.0990, R:0.0105)
Batch 500/537: Loss=1.0182 (C:1.0182, R:0.0106)
Batch 525/537: Loss=1.0539 (C:1.0539, R:0.0105)

============================================================
Epoch 33/300 completed in 26.9s
Train: Loss=1.0773 (C:1.0773, R:0.0105) Ratio=4.19x
Val:   Loss=1.2341 (C:1.2341, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.045
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 34
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.632 ± 0.939
    Neg distances: 3.742 ± 1.647
    Separation ratio: 5.92x
    Gap: -6.417
    ✅ Excellent global separation!

Epoch 34 Training
----------------------------------------
Batch   0/537: Loss=1.0946 (C:1.0946, R:0.0104)
Batch  25/537: Loss=1.0379 (C:1.0379, R:0.0105)
Batch  50/537: Loss=1.0711 (C:1.0711, R:0.0105)
Batch  75/537: Loss=1.0553 (C:1.0553, R:0.0105)
Batch 100/537: Loss=1.0647 (C:1.0647, R:0.0105)
Batch 125/537: Loss=1.0392 (C:1.0392, R:0.0105)
Batch 150/537: Loss=1.0407 (C:1.0407, R:0.0105)
Batch 175/537: Loss=1.1126 (C:1.1126, R:0.0105)
Batch 200/537: Loss=1.0746 (C:1.0746, R:0.0106)
Batch 225/537: Loss=1.0584 (C:1.0584, R:0.0105)
Batch 250/537: Loss=1.1072 (C:1.1072, R:0.0105)
Batch 275/537: Loss=1.0253 (C:1.0253, R:0.0105)
Batch 300/537: Loss=1.0211 (C:1.0211, R:0.0105)
Batch 325/537: Loss=1.0874 (C:1.0874, R:0.0105)
Batch 350/537: Loss=1.0566 (C:1.0566, R:0.0105)
Batch 375/537: Loss=1.0978 (C:1.0978, R:0.0105)
Batch 400/537: Loss=1.0245 (C:1.0245, R:0.0105)
Batch 425/537: Loss=1.1037 (C:1.1037, R:0.0105)
Batch 450/537: Loss=1.1555 (C:1.1555, R:0.0105)
Batch 475/537: Loss=1.0571 (C:1.0571, R:0.0105)
Batch 500/537: Loss=0.9322 (C:0.9322, R:0.0105)
Batch 525/537: Loss=1.0827 (C:1.0827, R:0.0105)

============================================================
Epoch 34/300 completed in 26.9s
Train: Loss=1.0607 (C:1.0607, R:0.0105) Ratio=4.23x
Val:   Loss=1.2169 (C:1.2169, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.060
✅ New best model saved (Val Loss: 1.2169)
============================================================

🌍 Updating global dataset at epoch 35
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.605 ± 0.933
    Neg distances: 3.766 ± 1.640
    Separation ratio: 6.23x
    Gap: -6.480
    ✅ Excellent global separation!

Epoch 35 Training
----------------------------------------
Batch   0/537: Loss=1.0003 (C:1.0003, R:0.0105)
Batch  25/537: Loss=1.0119 (C:1.0119, R:0.0105)
Batch  50/537: Loss=1.0753 (C:1.0753, R:0.0105)
Batch  75/537: Loss=1.0335 (C:1.0335, R:0.0105)
Batch 100/537: Loss=0.9995 (C:0.9995, R:0.0105)
Batch 125/537: Loss=1.0354 (C:1.0354, R:0.0105)
Batch 150/537: Loss=0.9941 (C:0.9941, R:0.0106)
Batch 175/537: Loss=1.0423 (C:1.0423, R:0.0105)
Batch 200/537: Loss=1.0821 (C:1.0821, R:0.0105)
Batch 225/537: Loss=0.9455 (C:0.9455, R:0.0105)
Batch 250/537: Loss=1.0692 (C:1.0692, R:0.0105)
Batch 275/537: Loss=1.0073 (C:1.0073, R:0.0106)
Batch 300/537: Loss=1.0299 (C:1.0299, R:0.0105)
Batch 325/537: Loss=1.0350 (C:1.0350, R:0.0105)
Batch 350/537: Loss=1.0015 (C:1.0015, R:0.0105)
Batch 375/537: Loss=0.9489 (C:0.9489, R:0.0106)
Batch 400/537: Loss=1.0370 (C:1.0370, R:0.0105)
Batch 425/537: Loss=1.1031 (C:1.1031, R:0.0105)
Batch 450/537: Loss=0.9798 (C:0.9798, R:0.0105)
Batch 475/537: Loss=1.0435 (C:1.0435, R:0.0105)
Batch 500/537: Loss=1.0879 (C:1.0879, R:0.0105)
Batch 525/537: Loss=1.0544 (C:1.0544, R:0.0105)

============================================================
Epoch 35/300 completed in 26.9s
Train: Loss=1.0303 (C:1.0303, R:0.0105) Ratio=4.25x
Val:   Loss=1.2142 (C:1.2142, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.075
✅ New best model saved (Val Loss: 1.2142)
============================================================

🌍 Updating global dataset at epoch 36
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.609 ± 0.927
    Neg distances: 3.786 ± 1.643
    Separation ratio: 6.22x
    Gap: -6.512
    ✅ Excellent global separation!

Epoch 36 Training
----------------------------------------
Batch   0/537: Loss=0.9728 (C:0.9728, R:0.0105)
Batch  25/537: Loss=0.9907 (C:0.9907, R:0.0105)
Batch  50/537: Loss=0.9925 (C:0.9925, R:0.0105)
Batch  75/537: Loss=0.9962 (C:0.9962, R:0.0105)
Batch 100/537: Loss=1.0554 (C:1.0554, R:0.0105)
Batch 125/537: Loss=0.9341 (C:0.9341, R:0.0105)
Batch 150/537: Loss=1.0337 (C:1.0337, R:0.0106)
Batch 175/537: Loss=1.0339 (C:1.0339, R:0.0105)
Batch 200/537: Loss=1.0445 (C:1.0445, R:0.0105)
Batch 225/537: Loss=1.0146 (C:1.0146, R:0.0105)
Batch 250/537: Loss=1.0257 (C:1.0257, R:0.0105)
Batch 275/537: Loss=1.0085 (C:1.0085, R:0.0106)
Batch 300/537: Loss=1.0447 (C:1.0447, R:0.0105)
Batch 325/537: Loss=1.0324 (C:1.0324, R:0.0106)
Batch 350/537: Loss=1.0311 (C:1.0311, R:0.0105)
Batch 375/537: Loss=1.0279 (C:1.0279, R:0.0105)
Batch 400/537: Loss=1.0545 (C:1.0545, R:0.0105)
Batch 425/537: Loss=0.9967 (C:0.9967, R:0.0105)
Batch 450/537: Loss=1.0789 (C:1.0789, R:0.0105)
Batch 475/537: Loss=1.1096 (C:1.1096, R:0.0105)
Batch 500/537: Loss=1.0009 (C:1.0009, R:0.0105)
Batch 525/537: Loss=1.0672 (C:1.0672, R:0.0105)

============================================================
Epoch 36/300 completed in 26.9s
Train: Loss=1.0258 (C:1.0258, R:0.0105) Ratio=4.29x
Val:   Loss=1.1840 (C:1.1840, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.090
✅ New best model saved (Val Loss: 1.1840)
============================================================

🌍 Updating global dataset at epoch 37
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.602 ± 0.916
    Neg distances: 3.766 ± 1.635
    Separation ratio: 6.26x
    Gap: -6.619
    ✅ Excellent global separation!

Epoch 37 Training
----------------------------------------
Batch   0/537: Loss=0.9532 (C:0.9532, R:0.0105)
Batch  25/537: Loss=0.9330 (C:0.9330, R:0.0105)
Batch  50/537: Loss=1.0262 (C:1.0262, R:0.0105)
Batch  75/537: Loss=0.9574 (C:0.9574, R:0.0105)
Batch 100/537: Loss=0.9992 (C:0.9992, R:0.0105)
Batch 125/537: Loss=1.0458 (C:1.0458, R:0.0105)
Batch 150/537: Loss=1.0760 (C:1.0760, R:0.0105)
Batch 175/537: Loss=1.0542 (C:1.0542, R:0.0106)
Batch 200/537: Loss=1.0494 (C:1.0494, R:0.0105)
Batch 225/537: Loss=1.0313 (C:1.0313, R:0.0105)
Batch 250/537: Loss=0.9802 (C:0.9802, R:0.0105)
Batch 275/537: Loss=1.0476 (C:1.0476, R:0.0105)
Batch 300/537: Loss=1.0263 (C:1.0263, R:0.0105)
Batch 325/537: Loss=1.0247 (C:1.0247, R:0.0105)
Batch 350/537: Loss=0.9924 (C:0.9924, R:0.0105)
Batch 375/537: Loss=0.9970 (C:0.9970, R:0.0105)
Batch 400/537: Loss=0.9784 (C:0.9784, R:0.0105)
Batch 425/537: Loss=1.0466 (C:1.0466, R:0.0105)
Batch 450/537: Loss=1.0455 (C:1.0455, R:0.0105)
Batch 475/537: Loss=1.0343 (C:1.0343, R:0.0105)
Batch 500/537: Loss=1.0175 (C:1.0175, R:0.0105)
Batch 525/537: Loss=1.0550 (C:1.0550, R:0.0105)

============================================================
Epoch 37/300 completed in 27.2s
Train: Loss=1.0161 (C:1.0161, R:0.0105) Ratio=4.27x
Val:   Loss=1.2053 (C:1.2053, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.105
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 38
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.603 ± 0.922
    Neg distances: 3.795 ± 1.652
    Separation ratio: 6.30x
    Gap: -6.570
    ✅ Excellent global separation!

Epoch 38 Training
----------------------------------------
Batch   0/537: Loss=0.9926 (C:0.9926, R:0.0105)
Batch  25/537: Loss=0.9796 (C:0.9796, R:0.0105)
Batch  50/537: Loss=0.9916 (C:0.9916, R:0.0106)
Batch  75/537: Loss=1.0380 (C:1.0380, R:0.0105)
Batch 100/537: Loss=1.0221 (C:1.0221, R:0.0105)
Batch 125/537: Loss=1.0079 (C:1.0079, R:0.0105)
Batch 150/537: Loss=0.9478 (C:0.9478, R:0.0106)
Batch 175/537: Loss=1.0516 (C:1.0516, R:0.0105)
Batch 200/537: Loss=1.0652 (C:1.0652, R:0.0105)
Batch 225/537: Loss=1.0020 (C:1.0020, R:0.0105)
Batch 250/537: Loss=1.1017 (C:1.1017, R:0.0105)
Batch 275/537: Loss=1.0103 (C:1.0103, R:0.0105)
Batch 300/537: Loss=0.9828 (C:0.9828, R:0.0105)
Batch 325/537: Loss=1.0127 (C:1.0127, R:0.0105)
Batch 350/537: Loss=1.0376 (C:1.0376, R:0.0106)
Batch 375/537: Loss=1.0631 (C:1.0631, R:0.0105)
Batch 400/537: Loss=1.0464 (C:1.0464, R:0.0105)
Batch 425/537: Loss=1.0330 (C:1.0330, R:0.0105)
Batch 450/537: Loss=1.0219 (C:1.0219, R:0.0105)
Batch 475/537: Loss=1.0582 (C:1.0582, R:0.0105)
Batch 500/537: Loss=1.0478 (C:1.0478, R:0.0106)
Batch 525/537: Loss=1.0184 (C:1.0184, R:0.0105)

============================================================
Epoch 38/300 completed in 28.0s
Train: Loss=1.0130 (C:1.0130, R:0.0105) Ratio=4.35x
Val:   Loss=1.1828 (C:1.1828, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.120
✅ New best model saved (Val Loss: 1.1828)
============================================================

🌍 Updating global dataset at epoch 39
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.586 ± 0.911
    Neg distances: 3.794 ± 1.643
    Separation ratio: 6.48x
    Gap: -6.544
    ✅ Excellent global separation!

Epoch 39 Training
----------------------------------------
Batch   0/537: Loss=0.9818 (C:0.9818, R:0.0105)
Batch  25/537: Loss=1.0404 (C:1.0404, R:0.0106)
Batch  50/537: Loss=0.9894 (C:0.9894, R:0.0105)
Batch  75/537: Loss=0.9663 (C:0.9663, R:0.0105)
Batch 100/537: Loss=0.9995 (C:0.9995, R:0.0105)
Batch 125/537: Loss=0.9726 (C:0.9726, R:0.0105)
Batch 150/537: Loss=1.0085 (C:1.0085, R:0.0105)
Batch 175/537: Loss=1.0040 (C:1.0040, R:0.0105)
Batch 200/537: Loss=1.0065 (C:1.0065, R:0.0105)
Batch 225/537: Loss=0.9827 (C:0.9827, R:0.0105)
Batch 250/537: Loss=1.0378 (C:1.0378, R:0.0105)
Batch 275/537: Loss=0.9892 (C:0.9892, R:0.0105)
Batch 300/537: Loss=0.9697 (C:0.9697, R:0.0105)
Batch 325/537: Loss=0.9830 (C:0.9830, R:0.0105)
Batch 350/537: Loss=0.9588 (C:0.9588, R:0.0105)
Batch 375/537: Loss=0.9865 (C:0.9865, R:0.0105)
Batch 400/537: Loss=1.0187 (C:1.0187, R:0.0105)
Batch 425/537: Loss=1.0289 (C:1.0289, R:0.0105)
Batch 450/537: Loss=0.9925 (C:0.9925, R:0.0105)
Batch 475/537: Loss=1.0145 (C:1.0145, R:0.0105)
Batch 500/537: Loss=1.0512 (C:1.0512, R:0.0105)
Batch 525/537: Loss=1.0048 (C:1.0048, R:0.0105)

============================================================
Epoch 39/300 completed in 27.6s
Train: Loss=0.9975 (C:0.9975, R:0.0105) Ratio=4.37x
Val:   Loss=1.1582 (C:1.1582, R:0.0104) Ratio=3.16x
Reconstruction weight: 0.135
✅ New best model saved (Val Loss: 1.1582)
============================================================

🌍 Updating global dataset at epoch 40
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.567 ± 0.895
    Neg distances: 3.826 ± 1.644
    Separation ratio: 6.75x
    Gap: -6.567
    ✅ Excellent global separation!

Epoch 40 Training
----------------------------------------
Batch   0/537: Loss=0.9232 (C:0.9232, R:0.0105)
Batch  25/537: Loss=1.0736 (C:1.0736, R:0.0105)
Batch  50/537: Loss=0.9498 (C:0.9498, R:0.0105)
Batch  75/537: Loss=0.9125 (C:0.9125, R:0.0105)
Batch 100/537: Loss=0.9560 (C:0.9560, R:0.0105)
Batch 125/537: Loss=1.0115 (C:1.0115, R:0.0106)
Batch 150/537: Loss=0.9830 (C:0.9830, R:0.0105)
Batch 175/537: Loss=1.0179 (C:1.0179, R:0.0105)
Batch 200/537: Loss=0.9579 (C:0.9579, R:0.0105)
Batch 225/537: Loss=0.9276 (C:0.9276, R:0.0105)
Batch 250/537: Loss=0.9646 (C:0.9646, R:0.0105)
Batch 275/537: Loss=0.9229 (C:0.9229, R:0.0105)
Batch 300/537: Loss=0.9933 (C:0.9933, R:0.0105)
Batch 325/537: Loss=0.9890 (C:0.9890, R:0.0105)
Batch 350/537: Loss=0.9607 (C:0.9607, R:0.0105)
Batch 375/537: Loss=0.9036 (C:0.9036, R:0.0105)
Batch 400/537: Loss=0.9291 (C:0.9291, R:0.0105)
Batch 425/537: Loss=0.9557 (C:0.9557, R:0.0105)
Batch 450/537: Loss=0.9754 (C:0.9754, R:0.0105)
Batch 475/537: Loss=0.9832 (C:0.9832, R:0.0105)
Batch 500/537: Loss=0.9809 (C:0.9809, R:0.0105)
Batch 525/537: Loss=1.0285 (C:1.0285, R:0.0105)

============================================================
Epoch 40/300 completed in 27.8s
Train: Loss=0.9784 (C:0.9784, R:0.0105) Ratio=4.53x
Val:   Loss=1.1606 (C:1.1606, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.150
No improvement for 1 epochs
Checkpoint saved at epoch 40
============================================================

🌍 Updating global dataset at epoch 41
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.579 ± 0.914
    Neg distances: 3.868 ± 1.665
    Separation ratio: 6.68x
    Gap: -6.574
    ✅ Excellent global separation!

Epoch 41 Training
----------------------------------------
Batch   0/537: Loss=0.8907 (C:0.8907, R:0.0106)
Batch  25/537: Loss=1.0038 (C:1.0038, R:0.0105)
Batch  50/537: Loss=0.9114 (C:0.9114, R:0.0105)
Batch  75/537: Loss=0.8879 (C:0.8879, R:0.0105)
Batch 100/537: Loss=0.9897 (C:0.9897, R:0.0106)
Batch 125/537: Loss=0.9743 (C:0.9743, R:0.0105)
Batch 150/537: Loss=0.9696 (C:0.9696, R:0.0105)
Batch 175/537: Loss=0.9637 (C:0.9637, R:0.0105)
Batch 200/537: Loss=0.9778 (C:0.9778, R:0.0105)
Batch 225/537: Loss=1.0059 (C:1.0059, R:0.0105)
Batch 250/537: Loss=1.0066 (C:1.0066, R:0.0105)
Batch 275/537: Loss=0.9837 (C:0.9837, R:0.0105)
Batch 300/537: Loss=0.9570 (C:0.9570, R:0.0105)
Batch 325/537: Loss=0.9444 (C:0.9444, R:0.0105)
Batch 350/537: Loss=0.9282 (C:0.9282, R:0.0105)
Batch 375/537: Loss=1.0260 (C:1.0260, R:0.0106)
Batch 400/537: Loss=0.9703 (C:0.9703, R:0.0105)
Batch 425/537: Loss=1.0024 (C:1.0024, R:0.0105)
Batch 450/537: Loss=0.9583 (C:0.9583, R:0.0105)
Batch 475/537: Loss=0.9838 (C:0.9838, R:0.0105)
Batch 500/537: Loss=0.9661 (C:0.9661, R:0.0105)
Batch 525/537: Loss=1.0033 (C:1.0033, R:0.0105)

============================================================
Epoch 41/300 completed in 27.5s
Train: Loss=0.9793 (C:0.9793, R:0.0105) Ratio=4.52x
Val:   Loss=1.1631 (C:1.1631, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.165
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 42
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.597 ± 0.948
    Neg distances: 3.856 ± 1.672
    Separation ratio: 6.45x
    Gap: -6.585
    ✅ Excellent global separation!

Epoch 42 Training
----------------------------------------
Batch   0/537: Loss=0.9610 (C:0.9610, R:0.0105)
Batch  25/537: Loss=1.0439 (C:1.0439, R:0.0105)
Batch  50/537: Loss=1.0207 (C:1.0207, R:0.0105)
Batch  75/537: Loss=0.9695 (C:0.9695, R:0.0106)
Batch 100/537: Loss=1.0110 (C:1.0110, R:0.0105)
Batch 125/537: Loss=0.9932 (C:0.9932, R:0.0105)
Batch 150/537: Loss=0.9873 (C:0.9873, R:0.0105)
Batch 175/537: Loss=1.0220 (C:1.0220, R:0.0105)
Batch 200/537: Loss=1.0230 (C:1.0230, R:0.0105)
Batch 225/537: Loss=0.9824 (C:0.9824, R:0.0105)
Batch 250/537: Loss=1.0192 (C:1.0192, R:0.0105)
Batch 275/537: Loss=1.0130 (C:1.0130, R:0.0105)
Batch 300/537: Loss=0.9827 (C:0.9827, R:0.0105)
Batch 325/537: Loss=1.0199 (C:1.0199, R:0.0105)
Batch 350/537: Loss=1.0351 (C:1.0351, R:0.0105)
Batch 375/537: Loss=1.0366 (C:1.0366, R:0.0105)
Batch 400/537: Loss=1.0212 (C:1.0212, R:0.0105)
Batch 425/537: Loss=1.0504 (C:1.0504, R:0.0105)
Batch 450/537: Loss=0.9886 (C:0.9886, R:0.0105)
Batch 475/537: Loss=1.0381 (C:1.0381, R:0.0105)
Batch 500/537: Loss=1.0328 (C:1.0328, R:0.0106)
Batch 525/537: Loss=1.0729 (C:1.0729, R:0.0105)

============================================================
Epoch 42/300 completed in 27.7s
Train: Loss=0.9904 (C:0.9904, R:0.0105) Ratio=4.38x
Val:   Loss=1.1769 (C:1.1769, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.180
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 43
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.563 ± 0.904
    Neg distances: 3.883 ± 1.655
    Separation ratio: 6.90x
    Gap: -6.562
    ✅ Excellent global separation!

Epoch 43 Training
----------------------------------------
Batch   0/537: Loss=0.9330 (C:0.9330, R:0.0105)
Batch  25/537: Loss=0.9074 (C:0.9074, R:0.0105)
Batch  50/537: Loss=0.9605 (C:0.9605, R:0.0105)
Batch  75/537: Loss=1.0148 (C:1.0148, R:0.0105)
Batch 100/537: Loss=0.9196 (C:0.9196, R:0.0105)
Batch 125/537: Loss=0.9411 (C:0.9411, R:0.0105)
Batch 150/537: Loss=0.9970 (C:0.9970, R:0.0105)
Batch 175/537: Loss=0.9284 (C:0.9284, R:0.0105)
Batch 200/537: Loss=0.9548 (C:0.9548, R:0.0105)
Batch 225/537: Loss=0.9756 (C:0.9756, R:0.0105)
Batch 250/537: Loss=0.9801 (C:0.9801, R:0.0105)
Batch 275/537: Loss=0.9648 (C:0.9648, R:0.0105)
Batch 300/537: Loss=0.9218 (C:0.9218, R:0.0105)
Batch 325/537: Loss=1.0164 (C:1.0164, R:0.0105)
Batch 350/537: Loss=0.9616 (C:0.9616, R:0.0106)
Batch 375/537: Loss=0.9586 (C:0.9586, R:0.0105)
Batch 400/537: Loss=0.9501 (C:0.9501, R:0.0105)
Batch 425/537: Loss=0.9162 (C:0.9162, R:0.0105)
Batch 450/537: Loss=0.9381 (C:0.9381, R:0.0105)
Batch 475/537: Loss=0.9688 (C:0.9688, R:0.0105)
Batch 500/537: Loss=0.9636 (C:0.9636, R:0.0105)
Batch 525/537: Loss=0.9307 (C:0.9307, R:0.0105)

============================================================
Epoch 43/300 completed in 27.3s
Train: Loss=0.9587 (C:0.9587, R:0.0105) Ratio=4.56x
Val:   Loss=1.1494 (C:1.1494, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.195
✅ New best model saved (Val Loss: 1.1494)
============================================================

🌍 Updating global dataset at epoch 44
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.553 ± 0.901
    Neg distances: 3.900 ± 1.654
    Separation ratio: 7.06x
    Gap: -6.756
    ✅ Excellent global separation!

Epoch 44 Training
----------------------------------------
Batch   0/537: Loss=0.9353 (C:0.9353, R:0.0105)
Batch  25/537: Loss=0.9436 (C:0.9436, R:0.0105)
Batch  50/537: Loss=0.9008 (C:0.9008, R:0.0105)
Batch  75/537: Loss=0.9259 (C:0.9259, R:0.0105)
Batch 100/537: Loss=0.9290 (C:0.9290, R:0.0105)
Batch 125/537: Loss=0.9788 (C:0.9788, R:0.0105)
Batch 150/537: Loss=0.9325 (C:0.9325, R:0.0105)
Batch 175/537: Loss=0.9615 (C:0.9615, R:0.0105)
Batch 200/537: Loss=0.9302 (C:0.9302, R:0.0105)
Batch 225/537: Loss=1.0032 (C:1.0032, R:0.0105)
Batch 250/537: Loss=0.9651 (C:0.9651, R:0.0105)
Batch 275/537: Loss=0.9920 (C:0.9920, R:0.0105)
Batch 300/537: Loss=0.9699 (C:0.9699, R:0.0105)
Batch 325/537: Loss=1.0020 (C:1.0020, R:0.0105)
Batch 350/537: Loss=0.9671 (C:0.9671, R:0.0105)
Batch 375/537: Loss=0.9653 (C:0.9653, R:0.0105)
Batch 400/537: Loss=0.9307 (C:0.9307, R:0.0106)
Batch 425/537: Loss=0.9418 (C:0.9418, R:0.0105)
Batch 450/537: Loss=0.9392 (C:0.9392, R:0.0105)
Batch 475/537: Loss=0.9163 (C:0.9163, R:0.0105)
Batch 500/537: Loss=0.9543 (C:0.9543, R:0.0105)
Batch 525/537: Loss=0.9746 (C:0.9746, R:0.0105)

============================================================
Epoch 44/300 completed in 27.9s
Train: Loss=0.9469 (C:0.9469, R:0.0105) Ratio=4.53x
Val:   Loss=1.1329 (C:1.1329, R:0.0104) Ratio=3.12x
Reconstruction weight: 0.210
✅ New best model saved (Val Loss: 1.1329)
============================================================

🌍 Updating global dataset at epoch 45
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.555 ± 0.885
    Neg distances: 3.871 ± 1.649
    Separation ratio: 6.98x
    Gap: -6.773
    ✅ Excellent global separation!

Epoch 45 Training
----------------------------------------
Batch   0/537: Loss=0.9545 (C:0.9545, R:0.0106)
Batch  25/537: Loss=0.9539 (C:0.9539, R:0.0105)
Batch  50/537: Loss=0.8840 (C:0.8840, R:0.0105)
Batch  75/537: Loss=1.0058 (C:1.0058, R:0.0105)
Batch 100/537: Loss=0.9708 (C:0.9708, R:0.0105)
Batch 125/537: Loss=0.9275 (C:0.9275, R:0.0105)
Batch 150/537: Loss=0.9252 (C:0.9252, R:0.0105)
Batch 175/537: Loss=0.9399 (C:0.9399, R:0.0105)
Batch 200/537: Loss=0.9464 (C:0.9464, R:0.0105)
Batch 225/537: Loss=0.9604 (C:0.9604, R:0.0105)
Batch 250/537: Loss=0.9445 (C:0.9445, R:0.0105)
Batch 275/537: Loss=0.9551 (C:0.9551, R:0.0105)
Batch 300/537: Loss=0.9819 (C:0.9819, R:0.0105)
Batch 325/537: Loss=0.9123 (C:0.9123, R:0.0106)
Batch 350/537: Loss=0.9775 (C:0.9775, R:0.0105)
Batch 375/537: Loss=0.9246 (C:0.9246, R:0.0105)
Batch 400/537: Loss=0.9365 (C:0.9365, R:0.0105)
Batch 425/537: Loss=0.9999 (C:0.9999, R:0.0105)
Batch 450/537: Loss=0.9599 (C:0.9599, R:0.0105)
Batch 475/537: Loss=0.9783 (C:0.9783, R:0.0105)
Batch 500/537: Loss=1.0181 (C:1.0181, R:0.0105)
Batch 525/537: Loss=0.9887 (C:0.9887, R:0.0105)

============================================================
Epoch 45/300 completed in 28.3s
Train: Loss=0.9469 (C:0.9469, R:0.0105) Ratio=4.49x
Val:   Loss=1.1553 (C:1.1553, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.225
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 46
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.551 ± 0.892
    Neg distances: 3.890 ± 1.656
    Separation ratio: 7.06x
    Gap: -6.625
    ✅ Excellent global separation!

Epoch 46 Training
----------------------------------------
Batch   0/537: Loss=0.9047 (C:0.9047, R:0.0105)
Batch  25/537: Loss=0.8954 (C:0.8954, R:0.0105)
Batch  50/537: Loss=0.9205 (C:0.9205, R:0.0105)
Batch  75/537: Loss=0.9668 (C:0.9668, R:0.0105)
Batch 100/537: Loss=0.9092 (C:0.9092, R:0.0105)
Batch 125/537: Loss=0.9213 (C:0.9213, R:0.0106)
Batch 150/537: Loss=0.9821 (C:0.9821, R:0.0105)
Batch 175/537: Loss=0.9154 (C:0.9154, R:0.0105)
Batch 200/537: Loss=0.9316 (C:0.9316, R:0.0105)
Batch 225/537: Loss=0.9550 (C:0.9550, R:0.0105)
Batch 250/537: Loss=0.9052 (C:0.9052, R:0.0105)
Batch 275/537: Loss=0.9039 (C:0.9039, R:0.0105)
Batch 300/537: Loss=0.9050 (C:0.9050, R:0.0105)
Batch 325/537: Loss=0.9079 (C:0.9079, R:0.0105)
Batch 350/537: Loss=0.9317 (C:0.9317, R:0.0105)
Batch 375/537: Loss=0.9890 (C:0.9890, R:0.0105)
Batch 400/537: Loss=0.9502 (C:0.9502, R:0.0105)
Batch 425/537: Loss=0.9213 (C:0.9213, R:0.0106)
Batch 450/537: Loss=0.9029 (C:0.9029, R:0.0105)
Batch 475/537: Loss=0.9737 (C:0.9737, R:0.0105)
Batch 500/537: Loss=0.9505 (C:0.9505, R:0.0105)
Batch 525/537: Loss=0.9872 (C:0.9872, R:0.0105)

============================================================
Epoch 46/300 completed in 28.0s
Train: Loss=0.9388 (C:0.9388, R:0.0105) Ratio=4.59x
Val:   Loss=1.1408 (C:1.1408, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.240
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 47
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.564 ± 0.932
    Neg distances: 3.869 ± 1.660
    Separation ratio: 6.86x
    Gap: -6.682
    ✅ Excellent global separation!

Epoch 47 Training
----------------------------------------
Batch   0/537: Loss=0.9590 (C:0.9590, R:0.0105)
Batch  25/537: Loss=0.9135 (C:0.9135, R:0.0105)
Batch  50/537: Loss=0.8894 (C:0.8894, R:0.0105)
Batch  75/537: Loss=0.9258 (C:0.9258, R:0.0105)
Batch 100/537: Loss=0.8443 (C:0.8443, R:0.0105)
Batch 125/537: Loss=0.9114 (C:0.9114, R:0.0105)
Batch 150/537: Loss=0.9727 (C:0.9727, R:0.0105)
Batch 175/537: Loss=0.9047 (C:0.9047, R:0.0105)
Batch 200/537: Loss=0.9557 (C:0.9557, R:0.0105)
Batch 225/537: Loss=0.9305 (C:0.9305, R:0.0105)
Batch 250/537: Loss=0.9132 (C:0.9132, R:0.0105)
Batch 275/537: Loss=0.9812 (C:0.9812, R:0.0105)
Batch 300/537: Loss=0.9513 (C:0.9513, R:0.0105)
Batch 325/537: Loss=0.9905 (C:0.9905, R:0.0105)
Batch 350/537: Loss=0.9382 (C:0.9382, R:0.0105)
Batch 375/537: Loss=0.9541 (C:0.9541, R:0.0105)
Batch 400/537: Loss=0.9228 (C:0.9228, R:0.0105)
Batch 425/537: Loss=0.9423 (C:0.9423, R:0.0105)
Batch 450/537: Loss=0.8958 (C:0.8958, R:0.0105)
Batch 475/537: Loss=0.9339 (C:0.9339, R:0.0105)
Batch 500/537: Loss=0.9931 (C:0.9931, R:0.0105)
Batch 525/537: Loss=0.9699 (C:0.9699, R:0.0105)

============================================================
Epoch 47/300 completed in 27.9s
Train: Loss=0.9494 (C:0.9494, R:0.0105) Ratio=4.73x
Val:   Loss=1.1577 (C:1.1577, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.255
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 48
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.549 ± 0.885
    Neg distances: 3.877 ± 1.650
    Separation ratio: 7.06x
    Gap: -6.613
    ✅ Excellent global separation!

Epoch 48 Training
----------------------------------------
Batch   0/537: Loss=0.9036 (C:0.9036, R:0.0105)
Batch  25/537: Loss=0.9428 (C:0.9428, R:0.0105)
Batch  50/537: Loss=0.9447 (C:0.9447, R:0.0105)
Batch  75/537: Loss=0.9104 (C:0.9104, R:0.0106)
Batch 100/537: Loss=0.9238 (C:0.9238, R:0.0105)
Batch 125/537: Loss=0.9450 (C:0.9450, R:0.0105)
Batch 150/537: Loss=0.9357 (C:0.9357, R:0.0105)
Batch 175/537: Loss=0.9162 (C:0.9162, R:0.0105)
Batch 200/537: Loss=0.9558 (C:0.9558, R:0.0105)
Batch 225/537: Loss=0.9232 (C:0.9232, R:0.0105)
Batch 250/537: Loss=0.9338 (C:0.9338, R:0.0105)
Batch 275/537: Loss=0.9195 (C:0.9195, R:0.0105)
Batch 300/537: Loss=0.9147 (C:0.9147, R:0.0105)
Batch 325/537: Loss=0.9460 (C:0.9460, R:0.0105)
Batch 350/537: Loss=0.9051 (C:0.9051, R:0.0105)
Batch 375/537: Loss=0.9435 (C:0.9435, R:0.0106)
Batch 400/537: Loss=0.9869 (C:0.9869, R:0.0105)
Batch 425/537: Loss=0.8975 (C:0.8975, R:0.0105)
Batch 450/537: Loss=0.9997 (C:0.9997, R:0.0105)
Batch 475/537: Loss=0.9974 (C:0.9974, R:0.0105)
Batch 500/537: Loss=0.9235 (C:0.9235, R:0.0105)
Batch 525/537: Loss=0.9902 (C:0.9902, R:0.0105)

============================================================
Epoch 48/300 completed in 27.4s
Train: Loss=0.9328 (C:0.9328, R:0.0105) Ratio=4.53x
Val:   Loss=1.1421 (C:1.1421, R:0.0104) Ratio=3.12x
Reconstruction weight: 0.270
No improvement for 4 epochs
============================================================

🌍 Updating global dataset at epoch 49
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.537 ± 0.903
    Neg distances: 3.890 ± 1.648
    Separation ratio: 7.25x
    Gap: -6.670
    ✅ Excellent global separation!

Epoch 49 Training
----------------------------------------
Batch   0/537: Loss=0.9392 (C:0.9392, R:0.0105)
Batch  25/537: Loss=0.8415 (C:0.8415, R:0.0105)
Batch  50/537: Loss=0.9224 (C:0.9224, R:0.0105)
Batch  75/537: Loss=0.9999 (C:0.9999, R:0.0105)
Batch 100/537: Loss=0.9321 (C:0.9321, R:0.0105)
Batch 125/537: Loss=0.8791 (C:0.8791, R:0.0105)
Batch 150/537: Loss=0.9152 (C:0.9152, R:0.0105)
Batch 175/537: Loss=0.9192 (C:0.9192, R:0.0105)
Batch 200/537: Loss=0.9050 (C:0.9050, R:0.0105)
Batch 225/537: Loss=0.8982 (C:0.8982, R:0.0105)
Batch 250/537: Loss=0.8536 (C:0.8536, R:0.0105)
Batch 275/537: Loss=0.9419 (C:0.9419, R:0.0105)
Batch 300/537: Loss=0.8733 (C:0.8733, R:0.0105)
Batch 325/537: Loss=0.9394 (C:0.9394, R:0.0105)
Batch 350/537: Loss=0.8873 (C:0.8873, R:0.0105)
Batch 375/537: Loss=0.9245 (C:0.9245, R:0.0105)
Batch 400/537: Loss=0.9113 (C:0.9113, R:0.0105)
Batch 425/537: Loss=0.9575 (C:0.9575, R:0.0105)
Batch 450/537: Loss=0.8753 (C:0.8753, R:0.0105)
Batch 475/537: Loss=0.9138 (C:0.9138, R:0.0105)
Batch 500/537: Loss=0.9161 (C:0.9161, R:0.0105)
Batch 525/537: Loss=0.9043 (C:0.9043, R:0.0105)

============================================================
Epoch 49/300 completed in 26.9s
Train: Loss=0.9208 (C:0.9208, R:0.0105) Ratio=4.73x
Val:   Loss=1.1412 (C:1.1412, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.285
No improvement for 5 epochs
============================================================

🌍 Updating global dataset at epoch 50
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.540 ± 0.879
    Neg distances: 3.911 ± 1.659
    Separation ratio: 7.24x
    Gap: -6.642
    ✅ Excellent global separation!

Epoch 50 Training
----------------------------------------
Batch   0/537: Loss=0.8638 (C:0.8638, R:0.0105)
Batch  25/537: Loss=0.8676 (C:0.8676, R:0.0105)
Batch  50/537: Loss=0.9429 (C:0.9429, R:0.0105)
Batch  75/537: Loss=0.9524 (C:0.9524, R:0.0105)
Batch 100/537: Loss=0.9335 (C:0.9335, R:0.0105)
Batch 125/537: Loss=0.9069 (C:0.9069, R:0.0105)
Batch 150/537: Loss=0.9104 (C:0.9104, R:0.0105)
Batch 175/537: Loss=0.9562 (C:0.9562, R:0.0105)
Batch 200/537: Loss=0.9732 (C:0.9732, R:0.0105)
Batch 225/537: Loss=0.9378 (C:0.9378, R:0.0106)
Batch 250/537: Loss=0.9129 (C:0.9129, R:0.0105)
Batch 275/537: Loss=0.8976 (C:0.8976, R:0.0105)
Batch 300/537: Loss=0.8818 (C:0.8818, R:0.0105)
Batch 325/537: Loss=0.8674 (C:0.8674, R:0.0105)
Batch 350/537: Loss=0.9184 (C:0.9184, R:0.0105)
Batch 375/537: Loss=0.9622 (C:0.9622, R:0.0105)
Batch 400/537: Loss=0.9780 (C:0.9780, R:0.0105)
Batch 425/537: Loss=0.9551 (C:0.9551, R:0.0106)
Batch 450/537: Loss=0.9158 (C:0.9158, R:0.0105)
Batch 475/537: Loss=0.9024 (C:0.9024, R:0.0105)
Batch 500/537: Loss=0.9897 (C:0.9897, R:0.0105)
Batch 525/537: Loss=0.9939 (C:0.9939, R:0.0105)

============================================================
Epoch 50/300 completed in 26.8s
Train: Loss=0.9232 (C:0.9232, R:0.0105) Ratio=4.72x
Val:   Loss=1.1376 (C:1.1376, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.300
No improvement for 6 epochs
============================================================

🌍 Updating global dataset at epoch 51
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.529 ± 0.890
    Neg distances: 3.917 ± 1.660
    Separation ratio: 7.41x
    Gap: -6.749
    ✅ Excellent global separation!

Epoch 51 Training
----------------------------------------
Batch   0/537: Loss=0.9091 (C:0.9091, R:0.0105)
Batch  25/537: Loss=0.8505 (C:0.8505, R:0.0105)
Batch  50/537: Loss=0.9214 (C:0.9214, R:0.0105)
Batch  75/537: Loss=0.9159 (C:0.9159, R:0.0105)
Batch 100/537: Loss=0.9335 (C:0.9335, R:0.0105)
Batch 125/537: Loss=0.8436 (C:0.8436, R:0.0105)
Batch 150/537: Loss=0.9555 (C:0.9555, R:0.0105)
Batch 175/537: Loss=0.9187 (C:0.9187, R:0.0105)
Batch 200/537: Loss=0.9521 (C:0.9521, R:0.0105)
Batch 225/537: Loss=0.8283 (C:0.8283, R:0.0105)
Batch 250/537: Loss=0.8923 (C:0.8923, R:0.0105)
Batch 275/537: Loss=0.9400 (C:0.9400, R:0.0105)
Batch 300/537: Loss=0.9243 (C:0.9243, R:0.0105)
Batch 325/537: Loss=0.8829 (C:0.8829, R:0.0105)
Batch 350/537: Loss=0.9648 (C:0.9648, R:0.0105)
Batch 375/537: Loss=0.9770 (C:0.9770, R:0.0105)
Batch 400/537: Loss=0.9061 (C:0.9061, R:0.0106)
Batch 425/537: Loss=0.9647 (C:0.9647, R:0.0105)
Batch 450/537: Loss=0.9092 (C:0.9092, R:0.0105)
Batch 475/537: Loss=0.9148 (C:0.9148, R:0.0105)
Batch 500/537: Loss=0.8990 (C:0.8990, R:0.0105)
Batch 525/537: Loss=0.9305 (C:0.9305, R:0.0105)

============================================================
Epoch 51/300 completed in 27.0s
Train: Loss=0.9076 (C:0.9076, R:0.0105) Ratio=4.67x
Val:   Loss=1.1122 (C:1.1122, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.1122)
============================================================

🌍 Updating global dataset at epoch 52
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.526 ± 0.887
    Neg distances: 3.929 ± 1.655
    Separation ratio: 7.47x
    Gap: -6.760
    ✅ Excellent global separation!

Epoch 52 Training
----------------------------------------
Batch   0/537: Loss=0.8785 (C:0.8785, R:0.0105)
Batch  25/537: Loss=0.9558 (C:0.9558, R:0.0105)
Batch  50/537: Loss=0.8640 (C:0.8640, R:0.0105)
Batch  75/537: Loss=0.9383 (C:0.9383, R:0.0105)
Batch 100/537: Loss=0.8576 (C:0.8576, R:0.0105)
Batch 125/537: Loss=0.8736 (C:0.8736, R:0.0105)
Batch 150/537: Loss=0.9114 (C:0.9114, R:0.0105)
Batch 175/537: Loss=0.8765 (C:0.8765, R:0.0105)
Batch 200/537: Loss=0.9133 (C:0.9133, R:0.0105)
Batch 225/537: Loss=0.8632 (C:0.8632, R:0.0105)
Batch 250/537: Loss=0.9359 (C:0.9359, R:0.0105)
Batch 275/537: Loss=0.9160 (C:0.9160, R:0.0105)
Batch 300/537: Loss=0.9043 (C:0.9043, R:0.0105)
Batch 325/537: Loss=0.9518 (C:0.9518, R:0.0105)
Batch 350/537: Loss=0.9248 (C:0.9248, R:0.0105)
Batch 375/537: Loss=0.9044 (C:0.9044, R:0.0105)
Batch 400/537: Loss=0.9204 (C:0.9204, R:0.0105)
Batch 425/537: Loss=0.8558 (C:0.8558, R:0.0105)
Batch 450/537: Loss=0.8901 (C:0.8901, R:0.0105)
Batch 475/537: Loss=0.9395 (C:0.9395, R:0.0106)
Batch 500/537: Loss=0.9033 (C:0.9033, R:0.0105)
Batch 525/537: Loss=0.8945 (C:0.8945, R:0.0105)

============================================================
Epoch 52/300 completed in 27.3s
Train: Loss=0.8989 (C:0.8989, R:0.0105) Ratio=4.65x
Val:   Loss=1.1112 (C:1.1112, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.1112)
============================================================

🌍 Updating global dataset at epoch 53
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.519 ± 0.876
    Neg distances: 3.952 ± 1.661
    Separation ratio: 7.61x
    Gap: -6.749
    ✅ Excellent global separation!

Epoch 53 Training
----------------------------------------
Batch   0/537: Loss=0.8346 (C:0.8346, R:0.0105)
Batch  25/537: Loss=0.8887 (C:0.8887, R:0.0105)
Batch  50/537: Loss=0.8707 (C:0.8707, R:0.0105)
Batch  75/537: Loss=0.8373 (C:0.8373, R:0.0105)
Batch 100/537: Loss=0.8774 (C:0.8774, R:0.0105)
Batch 125/537: Loss=0.9108 (C:0.9108, R:0.0105)
Batch 150/537: Loss=0.9335 (C:0.9335, R:0.0105)
Batch 175/537: Loss=0.8640 (C:0.8640, R:0.0105)
Batch 200/537: Loss=0.8749 (C:0.8749, R:0.0105)
Batch 225/537: Loss=0.8523 (C:0.8523, R:0.0105)
Batch 250/537: Loss=0.9315 (C:0.9315, R:0.0105)
Batch 275/537: Loss=0.8676 (C:0.8676, R:0.0105)
Batch 300/537: Loss=0.9189 (C:0.9189, R:0.0105)
Batch 325/537: Loss=0.8937 (C:0.8937, R:0.0105)
Batch 350/537: Loss=0.8991 (C:0.8991, R:0.0105)
Batch 375/537: Loss=0.8987 (C:0.8987, R:0.0105)
Batch 400/537: Loss=0.8968 (C:0.8968, R:0.0105)
Batch 425/537: Loss=0.9385 (C:0.9385, R:0.0105)
Batch 450/537: Loss=0.8754 (C:0.8754, R:0.0105)
Batch 475/537: Loss=0.8946 (C:0.8946, R:0.0105)
Batch 500/537: Loss=0.9287 (C:0.9287, R:0.0105)
Batch 525/537: Loss=0.8983 (C:0.8983, R:0.0105)

============================================================
Epoch 53/300 completed in 27.2s
Train: Loss=0.8925 (C:0.8925, R:0.0105) Ratio=4.75x
Val:   Loss=1.1256 (C:1.1256, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 54
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.520 ± 0.878
    Neg distances: 3.960 ± 1.667
    Separation ratio: 7.61x
    Gap: -6.783
    ✅ Excellent global separation!

Epoch 54 Training
----------------------------------------
Batch   0/537: Loss=0.8998 (C:0.8998, R:0.0105)
Batch  25/537: Loss=0.8585 (C:0.8585, R:0.0106)
Batch  50/537: Loss=0.9257 (C:0.9257, R:0.0105)
Batch  75/537: Loss=0.9277 (C:0.9277, R:0.0105)
Batch 100/537: Loss=0.8732 (C:0.8732, R:0.0105)
Batch 125/537: Loss=0.8568 (C:0.8568, R:0.0105)
Batch 150/537: Loss=0.8743 (C:0.8743, R:0.0105)
Batch 175/537: Loss=0.8700 (C:0.8700, R:0.0105)
Batch 200/537: Loss=0.8681 (C:0.8681, R:0.0105)
Batch 225/537: Loss=0.8668 (C:0.8668, R:0.0105)
Batch 250/537: Loss=0.8878 (C:0.8878, R:0.0105)
Batch 275/537: Loss=0.8907 (C:0.8907, R:0.0105)
Batch 300/537: Loss=0.8913 (C:0.8913, R:0.0105)
Batch 325/537: Loss=0.8353 (C:0.8353, R:0.0105)
Batch 350/537: Loss=0.9065 (C:0.9065, R:0.0105)
Batch 375/537: Loss=0.8648 (C:0.8648, R:0.0105)
Batch 400/537: Loss=0.9030 (C:0.9030, R:0.0105)
Batch 425/537: Loss=0.9544 (C:0.9544, R:0.0105)
Batch 450/537: Loss=0.9227 (C:0.9227, R:0.0105)
Batch 475/537: Loss=0.8876 (C:0.8876, R:0.0105)
Batch 500/537: Loss=0.8839 (C:0.8839, R:0.0105)
Batch 525/537: Loss=0.9352 (C:0.9352, R:0.0105)

============================================================
Epoch 54/300 completed in 27.0s
Train: Loss=0.8946 (C:0.8946, R:0.0105) Ratio=4.81x
Val:   Loss=1.1012 (C:1.1012, R:0.0104) Ratio=3.15x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.1012)
============================================================

🌍 Updating global dataset at epoch 55
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.532 ± 0.913
    Neg distances: 3.965 ± 1.678
    Separation ratio: 7.46x
    Gap: -6.737
    ✅ Excellent global separation!

Epoch 55 Training
----------------------------------------
Batch   0/537: Loss=0.8318 (C:0.8318, R:0.0105)
Batch  25/537: Loss=0.9140 (C:0.9140, R:0.0105)
Batch  50/537: Loss=0.9066 (C:0.9066, R:0.0105)
Batch  75/537: Loss=0.9088 (C:0.9088, R:0.0105)
Batch 100/537: Loss=0.8878 (C:0.8878, R:0.0105)
Batch 125/537: Loss=0.8943 (C:0.8943, R:0.0105)
Batch 150/537: Loss=0.8630 (C:0.8630, R:0.0105)
Batch 175/537: Loss=0.8924 (C:0.8924, R:0.0105)
Batch 200/537: Loss=0.9106 (C:0.9106, R:0.0105)
Batch 225/537: Loss=0.8110 (C:0.8110, R:0.0105)
Batch 250/537: Loss=0.8632 (C:0.8632, R:0.0105)
Batch 275/537: Loss=0.8895 (C:0.8895, R:0.0105)
Batch 300/537: Loss=0.9065 (C:0.9065, R:0.0105)
Batch 325/537: Loss=0.9401 (C:0.9401, R:0.0105)
Batch 350/537: Loss=0.8796 (C:0.8796, R:0.0106)
Batch 375/537: Loss=0.8734 (C:0.8734, R:0.0105)
Batch 400/537: Loss=0.7847 (C:0.7847, R:0.0105)
Batch 425/537: Loss=0.8964 (C:0.8964, R:0.0105)
Batch 450/537: Loss=0.9224 (C:0.9224, R:0.0105)
Batch 475/537: Loss=0.8849 (C:0.8849, R:0.0105)
Batch 500/537: Loss=0.9543 (C:0.9543, R:0.0105)
Batch 525/537: Loss=0.9090 (C:0.9090, R:0.0105)

============================================================
Epoch 55/300 completed in 27.3s
Train: Loss=0.8986 (C:0.8986, R:0.0105) Ratio=4.83x
Val:   Loss=1.1256 (C:1.1256, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 56
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.520 ± 0.903
    Neg distances: 4.010 ± 1.683
    Separation ratio: 7.71x
    Gap: -6.771
    ✅ Excellent global separation!

Epoch 56 Training
----------------------------------------
Batch   0/537: Loss=0.8325 (C:0.8325, R:0.0105)
Batch  25/537: Loss=0.8970 (C:0.8970, R:0.0105)
Batch  50/537: Loss=0.8883 (C:0.8883, R:0.0105)
Batch  75/537: Loss=0.8908 (C:0.8908, R:0.0105)
Batch 100/537: Loss=0.8758 (C:0.8758, R:0.0105)
Batch 125/537: Loss=0.8633 (C:0.8633, R:0.0105)
Batch 150/537: Loss=0.8443 (C:0.8443, R:0.0105)
Batch 175/537: Loss=0.9263 (C:0.9263, R:0.0105)
Batch 200/537: Loss=0.8831 (C:0.8831, R:0.0105)
Batch 225/537: Loss=0.9155 (C:0.9155, R:0.0105)
Batch 250/537: Loss=0.9131 (C:0.9131, R:0.0105)
Batch 275/537: Loss=0.8996 (C:0.8996, R:0.0105)
Batch 300/537: Loss=0.8911 (C:0.8911, R:0.0105)
Batch 325/537: Loss=0.8561 (C:0.8561, R:0.0105)
Batch 350/537: Loss=0.9152 (C:0.9152, R:0.0105)
Batch 375/537: Loss=0.8881 (C:0.8881, R:0.0105)
Batch 400/537: Loss=0.8811 (C:0.8811, R:0.0105)
Batch 425/537: Loss=0.8908 (C:0.8908, R:0.0105)
Batch 450/537: Loss=0.8373 (C:0.8373, R:0.0104)
Batch 475/537: Loss=0.8656 (C:0.8656, R:0.0105)
Batch 500/537: Loss=0.8747 (C:0.8747, R:0.0105)
Batch 525/537: Loss=0.8962 (C:0.8962, R:0.0105)

============================================================
Epoch 56/300 completed in 28.3s
Train: Loss=0.8817 (C:0.8817, R:0.0105) Ratio=4.87x
Val:   Loss=1.1136 (C:1.1136, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 57
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.525 ± 0.908
    Neg distances: 3.973 ± 1.670
    Separation ratio: 7.57x
    Gap: -6.754
    ✅ Excellent global separation!

Epoch 57 Training
----------------------------------------
Batch   0/537: Loss=0.8278 (C:0.8278, R:0.0105)
Batch  25/537: Loss=0.9344 (C:0.9344, R:0.0105)
Batch  50/537: Loss=0.8614 (C:0.8614, R:0.0105)
Batch  75/537: Loss=0.9531 (C:0.9531, R:0.0105)
Batch 100/537: Loss=0.9455 (C:0.9455, R:0.0105)
Batch 125/537: Loss=0.8794 (C:0.8794, R:0.0105)
Batch 150/537: Loss=0.8902 (C:0.8902, R:0.0105)
Batch 175/537: Loss=0.9880 (C:0.9880, R:0.0105)
Batch 200/537: Loss=0.8803 (C:0.8803, R:0.0105)
Batch 225/537: Loss=0.8533 (C:0.8533, R:0.0105)
Batch 250/537: Loss=0.9001 (C:0.9001, R:0.0105)
Batch 275/537: Loss=0.8897 (C:0.8897, R:0.0106)
Batch 300/537: Loss=0.9018 (C:0.9018, R:0.0105)
Batch 325/537: Loss=0.8661 (C:0.8661, R:0.0105)
Batch 350/537: Loss=0.9539 (C:0.9539, R:0.0105)
Batch 375/537: Loss=0.8714 (C:0.8714, R:0.0105)
Batch 400/537: Loss=0.8432 (C:0.8432, R:0.0105)
Batch 425/537: Loss=0.9467 (C:0.9467, R:0.0105)
Batch 450/537: Loss=0.9429 (C:0.9429, R:0.0105)
Batch 475/537: Loss=0.9244 (C:0.9244, R:0.0105)
Batch 500/537: Loss=0.9288 (C:0.9288, R:0.0105)
Batch 525/537: Loss=0.8858 (C:0.8858, R:0.0105)

============================================================
Epoch 57/300 completed in 27.5s
Train: Loss=0.8851 (C:0.8851, R:0.0105) Ratio=4.72x
Val:   Loss=1.1291 (C:1.1291, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 58
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.516 ± 0.869
    Neg distances: 3.953 ± 1.661
    Separation ratio: 7.66x
    Gap: -6.707
    ✅ Excellent global separation!

Epoch 58 Training
----------------------------------------
Batch   0/537: Loss=0.8533 (C:0.8533, R:0.0105)
Batch  25/537: Loss=0.9166 (C:0.9166, R:0.0105)
Batch  50/537: Loss=0.8816 (C:0.8816, R:0.0105)
Batch  75/537: Loss=0.8517 (C:0.8517, R:0.0105)
Batch 100/537: Loss=0.8636 (C:0.8636, R:0.0105)
Batch 125/537: Loss=0.8568 (C:0.8568, R:0.0105)
Batch 150/537: Loss=0.8787 (C:0.8787, R:0.0105)
Batch 175/537: Loss=0.8391 (C:0.8391, R:0.0105)
Batch 200/537: Loss=0.9134 (C:0.9134, R:0.0105)
Batch 225/537: Loss=0.8598 (C:0.8598, R:0.0105)
Batch 250/537: Loss=0.8400 (C:0.8400, R:0.0105)
Batch 275/537: Loss=0.8589 (C:0.8589, R:0.0105)
Batch 300/537: Loss=0.9239 (C:0.9239, R:0.0105)
Batch 325/537: Loss=0.8280 (C:0.8280, R:0.0105)
Batch 350/537: Loss=0.8415 (C:0.8415, R:0.0105)
Batch 375/537: Loss=0.8489 (C:0.8489, R:0.0105)
Batch 400/537: Loss=0.8635 (C:0.8635, R:0.0106)
Batch 425/537: Loss=0.9192 (C:0.9192, R:0.0105)
Batch 450/537: Loss=0.8988 (C:0.8988, R:0.0105)
Batch 475/537: Loss=0.8922 (C:0.8922, R:0.0105)
Batch 500/537: Loss=0.8301 (C:0.8301, R:0.0105)
Batch 525/537: Loss=0.8985 (C:0.8985, R:0.0105)

============================================================
Epoch 58/300 completed in 28.7s
Train: Loss=0.8792 (C:0.8792, R:0.0105) Ratio=4.93x
Val:   Loss=1.1232 (C:1.1232, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
No improvement for 4 epochs
============================================================

🌍 Updating global dataset at epoch 59
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.501 ± 0.867
    Neg distances: 3.979 ± 1.662
    Separation ratio: 7.94x
    Gap: -6.803
    ✅ Excellent global separation!

Epoch 59 Training
----------------------------------------
Batch   0/537: Loss=0.8479 (C:0.8479, R:0.0105)
Batch  25/537: Loss=0.9035 (C:0.9035, R:0.0105)
Batch  50/537: Loss=0.8134 (C:0.8134, R:0.0105)
Batch  75/537: Loss=0.8279 (C:0.8279, R:0.0105)
Batch 100/537: Loss=0.8335 (C:0.8335, R:0.0105)
Batch 125/537: Loss=0.9146 (C:0.9146, R:0.0105)
Batch 150/537: Loss=0.8485 (C:0.8485, R:0.0105)
Batch 175/537: Loss=0.8145 (C:0.8145, R:0.0105)
Batch 200/537: Loss=0.8722 (C:0.8722, R:0.0105)
Batch 225/537: Loss=0.7986 (C:0.7986, R:0.0105)
Batch 250/537: Loss=0.8359 (C:0.8359, R:0.0105)
Batch 275/537: Loss=0.8928 (C:0.8928, R:0.0105)
Batch 300/537: Loss=0.8994 (C:0.8994, R:0.0106)
Batch 325/537: Loss=0.8332 (C:0.8332, R:0.0105)
Batch 350/537: Loss=0.8486 (C:0.8486, R:0.0105)
Batch 375/537: Loss=0.8769 (C:0.8769, R:0.0105)
Batch 400/537: Loss=0.8772 (C:0.8772, R:0.0105)
Batch 425/537: Loss=0.7812 (C:0.7812, R:0.0105)
Batch 450/537: Loss=0.9151 (C:0.9151, R:0.0105)
Batch 475/537: Loss=0.8872 (C:0.8872, R:0.0105)
Batch 500/537: Loss=0.8377 (C:0.8377, R:0.0105)
Batch 525/537: Loss=0.9482 (C:0.9482, R:0.0105)

============================================================
Epoch 59/300 completed in 27.5s
Train: Loss=0.8648 (C:0.8648, R:0.0105) Ratio=4.91x
Val:   Loss=1.0964 (C:1.0964, R:0.0104) Ratio=3.13x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.0964)
============================================================

🌍 Updating global dataset at epoch 60
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.507 ± 0.878
    Neg distances: 4.003 ± 1.678
    Separation ratio: 7.89x
    Gap: -6.726
    ✅ Excellent global separation!

Epoch 60 Training
----------------------------------------
Batch   0/537: Loss=0.8856 (C:0.8856, R:0.0106)
Batch  25/537: Loss=0.8841 (C:0.8841, R:0.0105)
Batch  50/537: Loss=0.8334 (C:0.8334, R:0.0105)
Batch  75/537: Loss=0.8482 (C:0.8482, R:0.0105)
Batch 100/537: Loss=0.8541 (C:0.8541, R:0.0105)
Batch 125/537: Loss=0.9171 (C:0.9171, R:0.0105)
Batch 150/537: Loss=0.8879 (C:0.8879, R:0.0105)
Batch 175/537: Loss=0.9070 (C:0.9070, R:0.0105)
Batch 200/537: Loss=0.8379 (C:0.8379, R:0.0106)
Batch 225/537: Loss=0.8317 (C:0.8317, R:0.0105)
Batch 250/537: Loss=0.8491 (C:0.8491, R:0.0105)
Batch 275/537: Loss=0.8522 (C:0.8522, R:0.0106)
Batch 300/537: Loss=0.8645 (C:0.8645, R:0.0105)
Batch 325/537: Loss=0.8771 (C:0.8771, R:0.0105)
Batch 350/537: Loss=0.9153 (C:0.9153, R:0.0105)
Batch 375/537: Loss=0.9109 (C:0.9109, R:0.0105)
Batch 400/537: Loss=0.8348 (C:0.8348, R:0.0105)
Batch 425/537: Loss=0.8860 (C:0.8860, R:0.0105)
Batch 450/537: Loss=0.8460 (C:0.8460, R:0.0105)
Batch 475/537: Loss=0.9129 (C:0.9129, R:0.0105)
Batch 500/537: Loss=0.8510 (C:0.8510, R:0.0105)
Batch 525/537: Loss=0.9254 (C:0.9254, R:0.0105)

============================================================
Epoch 60/300 completed in 28.0s
Train: Loss=0.8659 (C:0.8659, R:0.0105) Ratio=4.83x
Val:   Loss=1.1157 (C:1.1157, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 1 epochs
Checkpoint saved at epoch 60
============================================================

🌍 Updating global dataset at epoch 61
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.507 ± 0.910
    Neg distances: 4.039 ± 1.689
    Separation ratio: 7.96x
    Gap: -6.772
    ✅ Excellent global separation!

Epoch 61 Training
----------------------------------------
Batch   0/537: Loss=0.8385 (C:0.8385, R:0.0105)
Batch  25/537: Loss=0.8527 (C:0.8527, R:0.0105)
Batch  50/537: Loss=0.8254 (C:0.8254, R:0.0105)
Batch  75/537: Loss=0.8672 (C:0.8672, R:0.0105)
Batch 100/537: Loss=0.9004 (C:0.9004, R:0.0105)
Batch 125/537: Loss=0.8818 (C:0.8818, R:0.0105)
Batch 150/537: Loss=0.8671 (C:0.8671, R:0.0105)
Batch 175/537: Loss=0.8747 (C:0.8747, R:0.0105)
Batch 200/537: Loss=0.8448 (C:0.8448, R:0.0105)
Batch 225/537: Loss=0.8795 (C:0.8795, R:0.0105)
Batch 250/537: Loss=0.8246 (C:0.8246, R:0.0105)
Batch 275/537: Loss=0.8528 (C:0.8528, R:0.0105)
Batch 300/537: Loss=0.8407 (C:0.8407, R:0.0105)
Batch 325/537: Loss=0.8600 (C:0.8600, R:0.0105)
Batch 350/537: Loss=0.8799 (C:0.8799, R:0.0105)
Batch 375/537: Loss=0.8344 (C:0.8344, R:0.0105)
Batch 400/537: Loss=0.8593 (C:0.8593, R:0.0105)
Batch 425/537: Loss=0.8385 (C:0.8385, R:0.0105)
Batch 450/537: Loss=0.8292 (C:0.8292, R:0.0105)
Batch 475/537: Loss=0.8287 (C:0.8287, R:0.0105)
Batch 500/537: Loss=0.8488 (C:0.8488, R:0.0105)
Batch 525/537: Loss=0.8207 (C:0.8207, R:0.0105)

============================================================
Epoch 61/300 completed in 27.6s
Train: Loss=0.8598 (C:0.8598, R:0.0105) Ratio=4.95x
Val:   Loss=1.0983 (C:1.0983, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 62
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.510 ± 0.895
    Neg distances: 4.029 ± 1.682
    Separation ratio: 7.90x
    Gap: -6.827
    ✅ Excellent global separation!

Epoch 62 Training
----------------------------------------
Batch   0/537: Loss=0.7645 (C:0.7645, R:0.0106)
Batch  25/537: Loss=0.8757 (C:0.8757, R:0.0105)
Batch  50/537: Loss=0.8012 (C:0.8012, R:0.0105)
Batch  75/537: Loss=0.8552 (C:0.8552, R:0.0105)
Batch 100/537: Loss=0.8124 (C:0.8124, R:0.0105)
Batch 125/537: Loss=0.8342 (C:0.8342, R:0.0105)
Batch 150/537: Loss=0.9506 (C:0.9506, R:0.0105)
Batch 175/537: Loss=0.8725 (C:0.8725, R:0.0105)
Batch 200/537: Loss=0.8178 (C:0.8178, R:0.0105)
Batch 225/537: Loss=0.9191 (C:0.9191, R:0.0105)
Batch 250/537: Loss=0.8799 (C:0.8799, R:0.0105)
Batch 275/537: Loss=0.9230 (C:0.9230, R:0.0105)
Batch 300/537: Loss=0.9611 (C:0.9611, R:0.0105)
Batch 325/537: Loss=0.8458 (C:0.8458, R:0.0105)
Batch 350/537: Loss=0.8659 (C:0.8659, R:0.0105)
Batch 375/537: Loss=0.8881 (C:0.8881, R:0.0105)
Batch 400/537: Loss=0.8478 (C:0.8478, R:0.0105)
Batch 425/537: Loss=0.8596 (C:0.8596, R:0.0105)
Batch 450/537: Loss=0.8643 (C:0.8643, R:0.0105)
Batch 475/537: Loss=0.8725 (C:0.8725, R:0.0105)
Batch 500/537: Loss=0.8723 (C:0.8723, R:0.0105)
Batch 525/537: Loss=0.8390 (C:0.8390, R:0.0105)

============================================================
Epoch 62/300 completed in 27.2s
Train: Loss=0.8592 (C:0.8592, R:0.0105) Ratio=4.99x
Val:   Loss=1.1086 (C:1.1086, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 63
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.498 ± 0.877
    Neg distances: 4.011 ± 1.670
    Separation ratio: 8.05x
    Gap: -6.802
    ✅ Excellent global separation!

Epoch 63 Training
----------------------------------------
Batch   0/537: Loss=0.7858 (C:0.7858, R:0.0105)
Batch  25/537: Loss=0.8613 (C:0.8613, R:0.0105)
Batch  50/537: Loss=0.8373 (C:0.8373, R:0.0105)
Batch  75/537: Loss=0.8559 (C:0.8559, R:0.0105)
Batch 100/537: Loss=0.7824 (C:0.7824, R:0.0105)
Batch 125/537: Loss=0.8448 (C:0.8448, R:0.0105)
Batch 150/537: Loss=0.8424 (C:0.8424, R:0.0105)
Batch 175/537: Loss=0.8678 (C:0.8678, R:0.0105)
Batch 200/537: Loss=0.7884 (C:0.7884, R:0.0105)
Batch 225/537: Loss=0.8642 (C:0.8642, R:0.0105)
Batch 250/537: Loss=0.8890 (C:0.8890, R:0.0105)
Batch 275/537: Loss=0.8895 (C:0.8895, R:0.0105)
Batch 300/537: Loss=0.8452 (C:0.8452, R:0.0105)
Batch 325/537: Loss=0.8842 (C:0.8842, R:0.0105)
Batch 350/537: Loss=0.8382 (C:0.8382, R:0.0105)
Batch 375/537: Loss=0.8565 (C:0.8565, R:0.0105)
Batch 400/537: Loss=0.8514 (C:0.8514, R:0.0105)
Batch 425/537: Loss=0.8887 (C:0.8887, R:0.0105)
Batch 450/537: Loss=0.7925 (C:0.7925, R:0.0105)
Batch 475/537: Loss=0.9050 (C:0.9050, R:0.0105)
Batch 500/537: Loss=0.8343 (C:0.8343, R:0.0105)
Batch 525/537: Loss=0.8914 (C:0.8914, R:0.0105)

============================================================
Epoch 63/300 completed in 27.3s
Train: Loss=0.8487 (C:0.8487, R:0.0105) Ratio=4.98x
Val:   Loss=1.0943 (C:1.0943, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.0943)
============================================================

🌍 Updating global dataset at epoch 64
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.487 ± 0.854
    Neg distances: 4.048 ± 1.675
    Separation ratio: 8.30x
    Gap: -6.923
    ✅ Excellent global separation!

Epoch 64 Training
----------------------------------------
Batch   0/537: Loss=0.8011 (C:0.8011, R:0.0105)
Batch  25/537: Loss=0.8166 (C:0.8166, R:0.0105)
Batch  50/537: Loss=0.7852 (C:0.7852, R:0.0106)
Batch  75/537: Loss=0.8802 (C:0.8802, R:0.0105)
Batch 100/537: Loss=0.8404 (C:0.8404, R:0.0105)
Batch 125/537: Loss=0.8063 (C:0.8063, R:0.0105)
Batch 150/537: Loss=0.8452 (C:0.8452, R:0.0105)
Batch 175/537: Loss=0.8205 (C:0.8205, R:0.0105)
Batch 200/537: Loss=0.8566 (C:0.8566, R:0.0105)
Batch 225/537: Loss=0.8251 (C:0.8251, R:0.0105)
Batch 250/537: Loss=0.8301 (C:0.8301, R:0.0105)
Batch 275/537: Loss=0.8118 (C:0.8118, R:0.0104)
Batch 300/537: Loss=0.8299 (C:0.8299, R:0.0105)
Batch 325/537: Loss=0.7776 (C:0.7776, R:0.0105)
Batch 350/537: Loss=0.8184 (C:0.8184, R:0.0105)
Batch 375/537: Loss=0.8408 (C:0.8408, R:0.0105)
Batch 400/537: Loss=0.8163 (C:0.8163, R:0.0105)
Batch 425/537: Loss=0.8107 (C:0.8107, R:0.0105)
Batch 450/537: Loss=0.8574 (C:0.8574, R:0.0105)
Batch 475/537: Loss=0.8795 (C:0.8795, R:0.0106)
Batch 500/537: Loss=0.8692 (C:0.8692, R:0.0105)
Batch 525/537: Loss=0.8246 (C:0.8246, R:0.0105)

============================================================
Epoch 64/300 completed in 27.1s
Train: Loss=0.8351 (C:0.8351, R:0.0105) Ratio=5.06x
Val:   Loss=1.1051 (C:1.1051, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 65
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.499 ± 0.880
    Neg distances: 4.008 ± 1.669
    Separation ratio: 8.04x
    Gap: -6.882
    ✅ Excellent global separation!

Epoch 65 Training
----------------------------------------
Batch   0/537: Loss=0.8127 (C:0.8127, R:0.0105)
Batch  25/537: Loss=0.8580 (C:0.8580, R:0.0105)
Batch  50/537: Loss=0.8217 (C:0.8217, R:0.0105)
Batch  75/537: Loss=0.8027 (C:0.8027, R:0.0105)
Batch 100/537: Loss=0.8760 (C:0.8760, R:0.0105)
Batch 125/537: Loss=0.7931 (C:0.7931, R:0.0105)
Batch 150/537: Loss=0.8363 (C:0.8363, R:0.0105)
Batch 175/537: Loss=0.8495 (C:0.8495, R:0.0105)
Batch 200/537: Loss=0.8252 (C:0.8252, R:0.0105)
Batch 225/537: Loss=0.8922 (C:0.8922, R:0.0106)
Batch 250/537: Loss=0.8279 (C:0.8279, R:0.0105)
Batch 275/537: Loss=0.8677 (C:0.8677, R:0.0105)
Batch 300/537: Loss=0.8194 (C:0.8194, R:0.0105)
Batch 325/537: Loss=0.9078 (C:0.9078, R:0.0105)
Batch 350/537: Loss=0.8525 (C:0.8525, R:0.0105)
Batch 375/537: Loss=0.8255 (C:0.8255, R:0.0105)
Batch 400/537: Loss=0.8327 (C:0.8327, R:0.0105)
Batch 425/537: Loss=0.8293 (C:0.8293, R:0.0105)
Batch 450/537: Loss=0.8274 (C:0.8274, R:0.0106)
Batch 475/537: Loss=0.8595 (C:0.8595, R:0.0105)
Batch 500/537: Loss=0.7754 (C:0.7754, R:0.0105)
Batch 525/537: Loss=0.8620 (C:0.8620, R:0.0105)

============================================================
Epoch 65/300 completed in 26.7s
Train: Loss=0.8460 (C:0.8460, R:0.0105) Ratio=5.06x
Val:   Loss=1.0851 (C:1.0851, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.0851)
============================================================

🌍 Updating global dataset at epoch 66
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.482 ± 0.845
    Neg distances: 4.023 ± 1.668
    Separation ratio: 8.34x
    Gap: -6.807
    ✅ Excellent global separation!

Epoch 66 Training
----------------------------------------
Batch   0/537: Loss=0.8806 (C:0.8806, R:0.0105)
Batch  25/537: Loss=0.8497 (C:0.8497, R:0.0105)
Batch  50/537: Loss=0.7886 (C:0.7886, R:0.0105)
Batch  75/537: Loss=0.7941 (C:0.7941, R:0.0105)
Batch 100/537: Loss=0.7961 (C:0.7961, R:0.0105)
Batch 125/537: Loss=0.8112 (C:0.8112, R:0.0105)
Batch 150/537: Loss=0.8587 (C:0.8587, R:0.0105)
Batch 175/537: Loss=0.8072 (C:0.8072, R:0.0105)
Batch 200/537: Loss=0.8259 (C:0.8259, R:0.0105)
Batch 225/537: Loss=0.8452 (C:0.8452, R:0.0106)
Batch 250/537: Loss=0.8471 (C:0.8471, R:0.0105)
Batch 275/537: Loss=0.8255 (C:0.8255, R:0.0105)
Batch 300/537: Loss=0.8978 (C:0.8978, R:0.0106)
Batch 325/537: Loss=0.8261 (C:0.8261, R:0.0105)
Batch 350/537: Loss=0.8067 (C:0.8067, R:0.0105)
Batch 375/537: Loss=0.7941 (C:0.7941, R:0.0105)
Batch 400/537: Loss=0.8662 (C:0.8662, R:0.0105)
Batch 425/537: Loss=0.8906 (C:0.8906, R:0.0105)
Batch 450/537: Loss=0.7979 (C:0.7979, R:0.0105)
Batch 475/537: Loss=0.8406 (C:0.8406, R:0.0105)
Batch 500/537: Loss=0.8653 (C:0.8653, R:0.0105)
Batch 525/537: Loss=0.8191 (C:0.8191, R:0.0105)

============================================================
Epoch 66/300 completed in 26.6s
Train: Loss=0.8319 (C:0.8319, R:0.0105) Ratio=5.07x
Val:   Loss=1.0749 (C:1.0749, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.0749)
============================================================

🌍 Updating global dataset at epoch 67
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.483 ± 0.872
    Neg distances: 4.009 ± 1.658
    Separation ratio: 8.30x
    Gap: -6.935
    ✅ Excellent global separation!

Epoch 67 Training
----------------------------------------
Batch   0/537: Loss=0.8054 (C:0.8054, R:0.0105)
Batch  25/537: Loss=0.7981 (C:0.7981, R:0.0106)
Batch  50/537: Loss=0.8249 (C:0.8249, R:0.0105)
Batch  75/537: Loss=0.8199 (C:0.8199, R:0.0105)
Batch 100/537: Loss=0.7834 (C:0.7834, R:0.0105)
Batch 125/537: Loss=0.7950 (C:0.7950, R:0.0105)
Batch 150/537: Loss=0.8320 (C:0.8320, R:0.0105)
Batch 175/537: Loss=0.8533 (C:0.8533, R:0.0105)
Batch 200/537: Loss=0.8793 (C:0.8793, R:0.0105)
Batch 225/537: Loss=0.8488 (C:0.8488, R:0.0105)
Batch 250/537: Loss=0.8760 (C:0.8760, R:0.0105)
Batch 275/537: Loss=0.8214 (C:0.8214, R:0.0105)
Batch 300/537: Loss=0.8582 (C:0.8582, R:0.0105)
Batch 325/537: Loss=0.8495 (C:0.8495, R:0.0105)
Batch 350/537: Loss=0.8302 (C:0.8302, R:0.0105)
Batch 375/537: Loss=0.8381 (C:0.8381, R:0.0105)
Batch 400/537: Loss=0.8885 (C:0.8885, R:0.0105)
Batch 425/537: Loss=0.8225 (C:0.8225, R:0.0106)
Batch 450/537: Loss=0.8070 (C:0.8070, R:0.0105)
Batch 475/537: Loss=0.8245 (C:0.8245, R:0.0105)
Batch 500/537: Loss=0.8295 (C:0.8295, R:0.0105)
Batch 525/537: Loss=0.8317 (C:0.8317, R:0.0105)

============================================================
Epoch 67/300 completed in 27.2s
Train: Loss=0.8303 (C:0.8303, R:0.0105) Ratio=5.02x
Val:   Loss=1.0894 (C:1.0894, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 68
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.476 ± 0.865
    Neg distances: 4.053 ± 1.672
    Separation ratio: 8.51x
    Gap: -6.936
    ✅ Excellent global separation!

Epoch 68 Training
----------------------------------------
Batch   0/537: Loss=0.7710 (C:0.7710, R:0.0105)
Batch  25/537: Loss=0.7990 (C:0.7990, R:0.0105)
Batch  50/537: Loss=0.8115 (C:0.8115, R:0.0105)
Batch  75/537: Loss=0.8201 (C:0.8201, R:0.0105)
Batch 100/537: Loss=0.8401 (C:0.8401, R:0.0105)
Batch 125/537: Loss=0.8584 (C:0.8584, R:0.0105)
Batch 150/537: Loss=0.8340 (C:0.8340, R:0.0105)
Batch 175/537: Loss=0.8308 (C:0.8308, R:0.0105)
Batch 200/537: Loss=0.7636 (C:0.7636, R:0.0105)
Batch 225/537: Loss=0.8565 (C:0.8565, R:0.0105)
Batch 250/537: Loss=0.8248 (C:0.8248, R:0.0105)
Batch 275/537: Loss=0.8177 (C:0.8177, R:0.0105)
Batch 300/537: Loss=0.8190 (C:0.8190, R:0.0105)
Batch 325/537: Loss=0.8264 (C:0.8264, R:0.0105)
Batch 350/537: Loss=0.8323 (C:0.8323, R:0.0105)
Batch 375/537: Loss=0.8141 (C:0.8141, R:0.0105)
Batch 400/537: Loss=0.7923 (C:0.7923, R:0.0105)
Batch 425/537: Loss=0.7980 (C:0.7980, R:0.0105)
Batch 450/537: Loss=0.8762 (C:0.8762, R:0.0105)
Batch 475/537: Loss=0.8126 (C:0.8126, R:0.0105)
Batch 500/537: Loss=0.8476 (C:0.8476, R:0.0105)
Batch 525/537: Loss=0.8624 (C:0.8624, R:0.0105)

============================================================
Epoch 68/300 completed in 27.1s
Train: Loss=0.8194 (C:0.8194, R:0.0105) Ratio=5.02x
Val:   Loss=1.0770 (C:1.0770, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 69
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.488 ± 0.862
    Neg distances: 4.036 ± 1.671
    Separation ratio: 8.28x
    Gap: -6.864
    ✅ Excellent global separation!

Epoch 69 Training
----------------------------------------
Batch   0/537: Loss=0.8276 (C:0.8276, R:0.0106)
Batch  25/537: Loss=0.8329 (C:0.8329, R:0.0105)
Batch  50/537: Loss=0.7609 (C:0.7609, R:0.0105)
Batch  75/537: Loss=0.8045 (C:0.8045, R:0.0105)
Batch 100/537: Loss=0.8355 (C:0.8355, R:0.0105)
Batch 125/537: Loss=0.8030 (C:0.8030, R:0.0105)
Batch 150/537: Loss=0.8754 (C:0.8754, R:0.0105)
Batch 175/537: Loss=0.8640 (C:0.8640, R:0.0105)
Batch 200/537: Loss=0.8122 (C:0.8122, R:0.0105)
Batch 225/537: Loss=0.8833 (C:0.8833, R:0.0105)
Batch 250/537: Loss=0.7988 (C:0.7988, R:0.0105)
Batch 275/537: Loss=0.8317 (C:0.8317, R:0.0105)
Batch 300/537: Loss=0.9314 (C:0.9314, R:0.0105)
Batch 325/537: Loss=0.8189 (C:0.8189, R:0.0105)
Batch 350/537: Loss=0.8415 (C:0.8415, R:0.0105)
Batch 375/537: Loss=0.8899 (C:0.8899, R:0.0105)
Batch 400/537: Loss=0.9037 (C:0.9037, R:0.0105)
Batch 425/537: Loss=0.8476 (C:0.8476, R:0.0105)
Batch 450/537: Loss=0.8253 (C:0.8253, R:0.0105)
Batch 475/537: Loss=0.8555 (C:0.8555, R:0.0105)
Batch 500/537: Loss=0.8307 (C:0.8307, R:0.0105)
Batch 525/537: Loss=0.8611 (C:0.8611, R:0.0105)

============================================================
Epoch 69/300 completed in 28.0s
Train: Loss=0.8283 (C:0.8283, R:0.0105) Ratio=4.98x
Val:   Loss=1.0925 (C:1.0925, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 70
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.476 ± 0.843
    Neg distances: 4.039 ± 1.670
    Separation ratio: 8.48x
    Gap: -6.888
    ✅ Excellent global separation!

Epoch 70 Training
----------------------------------------
Batch   0/537: Loss=0.8435 (C:0.8435, R:0.0105)
Batch  25/537: Loss=0.8046 (C:0.8046, R:0.0105)
Batch  50/537: Loss=0.8057 (C:0.8057, R:0.0105)
Batch  75/537: Loss=0.8152 (C:0.8152, R:0.0106)
Batch 100/537: Loss=0.8052 (C:0.8052, R:0.0105)
Batch 125/537: Loss=0.8284 (C:0.8284, R:0.0105)
Batch 150/537: Loss=0.8007 (C:0.8007, R:0.0105)
Batch 175/537: Loss=0.7818 (C:0.7818, R:0.0105)
Batch 200/537: Loss=0.8082 (C:0.8082, R:0.0105)
Batch 225/537: Loss=0.8103 (C:0.8103, R:0.0105)
Batch 250/537: Loss=0.7846 (C:0.7846, R:0.0105)
Batch 275/537: Loss=0.8462 (C:0.8462, R:0.0105)
Batch 300/537: Loss=0.8325 (C:0.8325, R:0.0105)
Batch 325/537: Loss=0.7768 (C:0.7768, R:0.0105)
Batch 350/537: Loss=0.8058 (C:0.8058, R:0.0105)
Batch 375/537: Loss=0.7885 (C:0.7885, R:0.0104)
Batch 400/537: Loss=0.8337 (C:0.8337, R:0.0105)
Batch 425/537: Loss=0.8209 (C:0.8209, R:0.0105)
Batch 450/537: Loss=0.8591 (C:0.8591, R:0.0106)
Batch 475/537: Loss=0.8337 (C:0.8337, R:0.0105)
Batch 500/537: Loss=0.8280 (C:0.8280, R:0.0105)
Batch 525/537: Loss=0.8389 (C:0.8389, R:0.0105)

============================================================
Epoch 70/300 completed in 27.4s
Train: Loss=0.8200 (C:0.8200, R:0.0105) Ratio=5.15x
Val:   Loss=1.0717 (C:1.0717, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.0717)
============================================================

🌍 Updating global dataset at epoch 71
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.480 ± 0.864
    Neg distances: 4.005 ± 1.658
    Separation ratio: 8.34x
    Gap: -6.852
    ✅ Excellent global separation!

Epoch 71 Training
----------------------------------------
Batch   0/537: Loss=0.8158 (C:0.8158, R:0.0105)
Batch  25/537: Loss=0.7746 (C:0.7746, R:0.0105)
Batch  50/537: Loss=0.7547 (C:0.7547, R:0.0105)
Batch  75/537: Loss=0.8597 (C:0.8597, R:0.0105)
Batch 100/537: Loss=0.8524 (C:0.8524, R:0.0105)
Batch 125/537: Loss=0.7926 (C:0.7926, R:0.0105)
Batch 150/537: Loss=0.8355 (C:0.8355, R:0.0105)
Batch 175/537: Loss=0.9098 (C:0.9098, R:0.0105)
Batch 200/537: Loss=0.7886 (C:0.7886, R:0.0105)
Batch 225/537: Loss=0.8340 (C:0.8340, R:0.0105)
Batch 250/537: Loss=0.7935 (C:0.7935, R:0.0105)
Batch 275/537: Loss=0.8091 (C:0.8091, R:0.0105)
Batch 300/537: Loss=0.8381 (C:0.8381, R:0.0105)
Batch 325/537: Loss=0.8233 (C:0.8233, R:0.0105)
Batch 350/537: Loss=0.8222 (C:0.8222, R:0.0105)
Batch 375/537: Loss=0.7825 (C:0.7825, R:0.0105)
Batch 400/537: Loss=0.8563 (C:0.8563, R:0.0105)
Batch 425/537: Loss=0.8991 (C:0.8991, R:0.0105)
Batch 450/537: Loss=0.7925 (C:0.7925, R:0.0105)
Batch 475/537: Loss=0.8479 (C:0.8479, R:0.0105)
Batch 500/537: Loss=0.8499 (C:0.8499, R:0.0105)
Batch 525/537: Loss=0.8019 (C:0.8019, R:0.0105)

============================================================
Epoch 71/300 completed in 28.3s
Train: Loss=0.8227 (C:0.8227, R:0.0105) Ratio=5.11x
Val:   Loss=1.0839 (C:1.0839, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 72
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.468 ± 0.848
    Neg distances: 4.058 ± 1.668
    Separation ratio: 8.66x
    Gap: -6.826
    ✅ Excellent global separation!

Epoch 72 Training
----------------------------------------
Batch   0/537: Loss=0.7697 (C:0.7697, R:0.0105)
Batch  25/537: Loss=0.7978 (C:0.7978, R:0.0105)
Batch  50/537: Loss=0.7878 (C:0.7878, R:0.0105)
Batch  75/537: Loss=0.8166 (C:0.8166, R:0.0105)
Batch 100/537: Loss=0.7835 (C:0.7835, R:0.0105)
Batch 125/537: Loss=0.7618 (C:0.7618, R:0.0105)
Batch 150/537: Loss=0.7915 (C:0.7915, R:0.0105)
Batch 175/537: Loss=0.8151 (C:0.8151, R:0.0105)
Batch 200/537: Loss=0.8004 (C:0.8004, R:0.0105)
Batch 225/537: Loss=0.7722 (C:0.7722, R:0.0105)
Batch 250/537: Loss=0.7985 (C:0.7985, R:0.0105)
Batch 275/537: Loss=0.7965 (C:0.7965, R:0.0105)
Batch 300/537: Loss=0.7863 (C:0.7863, R:0.0105)
Batch 325/537: Loss=0.8289 (C:0.8289, R:0.0105)
Batch 350/537: Loss=0.8244 (C:0.8244, R:0.0105)
Batch 375/537: Loss=0.8086 (C:0.8086, R:0.0105)
Batch 400/537: Loss=0.8403 (C:0.8403, R:0.0104)
Batch 425/537: Loss=0.7791 (C:0.7791, R:0.0105)
Batch 450/537: Loss=0.7575 (C:0.7575, R:0.0105)
Batch 475/537: Loss=0.8452 (C:0.8452, R:0.0105)
Batch 500/537: Loss=0.7802 (C:0.7802, R:0.0105)
Batch 525/537: Loss=0.7840 (C:0.7840, R:0.0105)

============================================================
Epoch 72/300 completed in 27.6s
Train: Loss=0.8094 (C:0.8094, R:0.0105) Ratio=5.22x
Val:   Loss=1.0747 (C:1.0747, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 73
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.484 ± 0.887
    Neg distances: 4.048 ± 1.676
    Separation ratio: 8.37x
    Gap: -6.846
    ✅ Excellent global separation!

Epoch 73 Training
----------------------------------------
Batch   0/537: Loss=0.7903 (C:0.7903, R:0.0105)
Batch  25/537: Loss=0.7571 (C:0.7571, R:0.0105)
Batch  50/537: Loss=0.8686 (C:0.8686, R:0.0105)
Batch  75/537: Loss=0.8915 (C:0.8915, R:0.0105)
Batch 100/537: Loss=0.7893 (C:0.7893, R:0.0105)
Batch 125/537: Loss=0.7642 (C:0.7642, R:0.0105)
Batch 150/537: Loss=0.8671 (C:0.8671, R:0.0104)
Batch 175/537: Loss=0.8502 (C:0.8502, R:0.0105)
Batch 200/537: Loss=0.7681 (C:0.7681, R:0.0105)
Batch 225/537: Loss=0.8127 (C:0.8127, R:0.0105)
Batch 250/537: Loss=0.8468 (C:0.8468, R:0.0105)
Batch 275/537: Loss=0.8150 (C:0.8150, R:0.0105)
Batch 300/537: Loss=0.7814 (C:0.7814, R:0.0105)
Batch 325/537: Loss=0.7784 (C:0.7784, R:0.0105)
Batch 350/537: Loss=0.7975 (C:0.7975, R:0.0105)
Batch 375/537: Loss=0.7955 (C:0.7955, R:0.0105)
Batch 400/537: Loss=0.8530 (C:0.8530, R:0.0105)
Batch 425/537: Loss=0.8114 (C:0.8114, R:0.0105)
Batch 450/537: Loss=0.8422 (C:0.8422, R:0.0105)
Batch 475/537: Loss=0.8449 (C:0.8449, R:0.0105)
Batch 500/537: Loss=0.8542 (C:0.8542, R:0.0105)
Batch 525/537: Loss=0.8519 (C:0.8519, R:0.0105)

============================================================
Epoch 73/300 completed in 28.0s
Train: Loss=0.8200 (C:0.8200, R:0.0105) Ratio=5.19x
Val:   Loss=1.0846 (C:1.0846, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 74
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.463 ± 0.840
    Neg distances: 4.068 ± 1.674
    Separation ratio: 8.79x
    Gap: -6.878
    ✅ Excellent global separation!

Epoch 74 Training
----------------------------------------
Batch   0/537: Loss=0.7761 (C:0.7761, R:0.0105)
Batch  25/537: Loss=0.8275 (C:0.8275, R:0.0105)
Batch  50/537: Loss=0.7860 (C:0.7860, R:0.0105)
Batch  75/537: Loss=0.7653 (C:0.7653, R:0.0105)
Batch 100/537: Loss=0.8255 (C:0.8255, R:0.0105)
Batch 125/537: Loss=0.8512 (C:0.8512, R:0.0105)
Batch 150/537: Loss=0.7561 (C:0.7561, R:0.0105)
Batch 175/537: Loss=0.7701 (C:0.7701, R:0.0105)
Batch 200/537: Loss=0.8508 (C:0.8508, R:0.0105)
Batch 225/537: Loss=0.7871 (C:0.7871, R:0.0106)
Batch 250/537: Loss=0.8034 (C:0.8034, R:0.0105)
Batch 275/537: Loss=0.8060 (C:0.8060, R:0.0106)
Batch 300/537: Loss=0.8013 (C:0.8013, R:0.0105)
Batch 325/537: Loss=0.7505 (C:0.7505, R:0.0105)
Batch 350/537: Loss=0.8342 (C:0.8342, R:0.0105)
Batch 375/537: Loss=0.7649 (C:0.7649, R:0.0105)
Batch 400/537: Loss=0.8085 (C:0.8085, R:0.0105)
Batch 425/537: Loss=0.8069 (C:0.8069, R:0.0106)
Batch 450/537: Loss=0.8204 (C:0.8204, R:0.0106)
Batch 475/537: Loss=0.7725 (C:0.7725, R:0.0105)
Batch 500/537: Loss=0.7832 (C:0.7832, R:0.0105)
Batch 525/537: Loss=0.8342 (C:0.8342, R:0.0105)

============================================================
Epoch 74/300 completed in 27.2s
Train: Loss=0.8018 (C:0.8018, R:0.0105) Ratio=5.15x
Val:   Loss=1.0820 (C:1.0820, R:0.0104) Ratio=2.99x
Reconstruction weight: 0.300
No improvement for 4 epochs
============================================================

🌍 Updating global dataset at epoch 75
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.448 ± 0.817
    Neg distances: 4.048 ± 1.648
    Separation ratio: 9.03x
    Gap: -6.878
    ✅ Excellent global separation!

Epoch 75 Training
----------------------------------------
Batch   0/537: Loss=0.7899 (C:0.7899, R:0.0105)
Batch  25/537: Loss=0.8033 (C:0.8033, R:0.0105)
Batch  50/537: Loss=0.8059 (C:0.8059, R:0.0105)
Batch  75/537: Loss=0.8395 (C:0.8395, R:0.0105)
Batch 100/537: Loss=0.7917 (C:0.7917, R:0.0105)
Batch 125/537: Loss=0.8241 (C:0.8241, R:0.0105)
Batch 150/537: Loss=0.8029 (C:0.8029, R:0.0105)
Batch 175/537: Loss=0.8432 (C:0.8432, R:0.0105)
Batch 200/537: Loss=0.7345 (C:0.7345, R:0.0105)
Batch 225/537: Loss=0.7948 (C:0.7948, R:0.0105)
Batch 250/537: Loss=0.7854 (C:0.7854, R:0.0105)
Batch 275/537: Loss=0.7416 (C:0.7416, R:0.0105)
Batch 300/537: Loss=0.8242 (C:0.8242, R:0.0105)
Batch 325/537: Loss=0.8331 (C:0.8331, R:0.0106)
Batch 350/537: Loss=0.7832 (C:0.7832, R:0.0105)
Batch 375/537: Loss=0.8014 (C:0.8014, R:0.0105)
Batch 400/537: Loss=0.8051 (C:0.8051, R:0.0106)
Batch 425/537: Loss=0.8042 (C:0.8042, R:0.0106)
Batch 450/537: Loss=0.7256 (C:0.7256, R:0.0105)
Batch 475/537: Loss=0.7902 (C:0.7902, R:0.0105)
Batch 500/537: Loss=0.8289 (C:0.8289, R:0.0105)
Batch 525/537: Loss=0.7981 (C:0.7981, R:0.0105)

============================================================
Epoch 75/300 completed in 26.7s
Train: Loss=0.7882 (C:0.7882, R:0.0105) Ratio=5.15x
Val:   Loss=1.0591 (C:1.0591, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.0591)
============================================================

🌍 Updating global dataset at epoch 76
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.457 ± 0.862
    Neg distances: 4.031 ± 1.650
    Separation ratio: 8.82x
    Gap: -6.944
    ✅ Excellent global separation!

Epoch 76 Training
----------------------------------------
Batch   0/537: Loss=0.7995 (C:0.7995, R:0.0105)
Batch  25/537: Loss=0.7452 (C:0.7452, R:0.0105)
Batch  50/537: Loss=0.7342 (C:0.7342, R:0.0105)
Batch  75/537: Loss=0.8243 (C:0.8243, R:0.0105)
Batch 100/537: Loss=0.7580 (C:0.7580, R:0.0105)
Batch 125/537: Loss=0.8253 (C:0.8253, R:0.0105)
Batch 150/537: Loss=0.7468 (C:0.7468, R:0.0105)
Batch 175/537: Loss=0.7523 (C:0.7523, R:0.0106)
Batch 200/537: Loss=0.8168 (C:0.8168, R:0.0105)
Batch 225/537: Loss=0.8428 (C:0.8428, R:0.0105)
Batch 250/537: Loss=0.8300 (C:0.8300, R:0.0106)
Batch 275/537: Loss=0.8098 (C:0.8098, R:0.0105)
Batch 300/537: Loss=0.8107 (C:0.8107, R:0.0105)
Batch 325/537: Loss=0.7814 (C:0.7814, R:0.0105)
Batch 350/537: Loss=0.7811 (C:0.7811, R:0.0105)
Batch 375/537: Loss=0.7539 (C:0.7539, R:0.0105)
Batch 400/537: Loss=0.8224 (C:0.8224, R:0.0105)
Batch 425/537: Loss=0.7775 (C:0.7775, R:0.0105)
Batch 450/537: Loss=0.7521 (C:0.7521, R:0.0105)
Batch 475/537: Loss=0.8124 (C:0.8124, R:0.0105)
Batch 500/537: Loss=0.7971 (C:0.7971, R:0.0105)
Batch 525/537: Loss=0.7398 (C:0.7398, R:0.0105)

============================================================
Epoch 76/300 completed in 27.0s
Train: Loss=0.7958 (C:0.7958, R:0.0105) Ratio=5.39x
Val:   Loss=1.0676 (C:1.0676, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 77
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.443 ± 0.827
    Neg distances: 4.059 ± 1.654
    Separation ratio: 9.17x
    Gap: -6.803
    ✅ Excellent global separation!

Epoch 77 Training
----------------------------------------
Batch   0/537: Loss=0.7736 (C:0.7736, R:0.0106)
Batch  25/537: Loss=0.7978 (C:0.7978, R:0.0105)
Batch  50/537: Loss=0.7555 (C:0.7555, R:0.0105)
Batch  75/537: Loss=0.8506 (C:0.8506, R:0.0105)
Batch 100/537: Loss=0.7711 (C:0.7711, R:0.0105)
Batch 125/537: Loss=0.7519 (C:0.7519, R:0.0105)
Batch 150/537: Loss=0.8125 (C:0.8125, R:0.0105)
Batch 175/537: Loss=0.8098 (C:0.8098, R:0.0105)
Batch 200/537: Loss=0.7483 (C:0.7483, R:0.0105)
Batch 225/537: Loss=0.7774 (C:0.7774, R:0.0105)
Batch 250/537: Loss=0.7771 (C:0.7771, R:0.0105)
Batch 275/537: Loss=0.7704 (C:0.7704, R:0.0105)
Batch 300/537: Loss=0.8093 (C:0.8093, R:0.0105)
Batch 325/537: Loss=0.7525 (C:0.7525, R:0.0105)
Batch 350/537: Loss=0.7691 (C:0.7691, R:0.0105)
Batch 375/537: Loss=0.7549 (C:0.7549, R:0.0105)
Batch 400/537: Loss=0.8155 (C:0.8155, R:0.0105)
Batch 425/537: Loss=0.7782 (C:0.7782, R:0.0105)
Batch 450/537: Loss=0.8018 (C:0.8018, R:0.0105)
Batch 475/537: Loss=0.7576 (C:0.7576, R:0.0105)
Batch 500/537: Loss=0.8223 (C:0.8223, R:0.0106)
Batch 525/537: Loss=0.7677 (C:0.7677, R:0.0105)

============================================================
Epoch 77/300 completed in 28.6s
Train: Loss=0.7784 (C:0.7784, R:0.0105) Ratio=5.22x
Val:   Loss=1.0493 (C:1.0493, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.0493)
============================================================

🌍 Updating global dataset at epoch 78
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.440 ± 0.810
    Neg distances: 4.060 ± 1.650
    Separation ratio: 9.23x
    Gap: -6.868
    ✅ Excellent global separation!

Epoch 78 Training
----------------------------------------
Batch   0/537: Loss=0.7419 (C:0.7419, R:0.0105)
Batch  25/537: Loss=0.7539 (C:0.7539, R:0.0105)
Batch  50/537: Loss=0.7801 (C:0.7801, R:0.0105)
Batch  75/537: Loss=0.7659 (C:0.7659, R:0.0105)
Batch 100/537: Loss=0.7419 (C:0.7419, R:0.0105)
Batch 125/537: Loss=0.7151 (C:0.7151, R:0.0105)
Batch 150/537: Loss=0.7688 (C:0.7688, R:0.0105)
Batch 175/537: Loss=0.8130 (C:0.8130, R:0.0105)
Batch 200/537: Loss=0.7313 (C:0.7313, R:0.0105)
Batch 225/537: Loss=0.7411 (C:0.7411, R:0.0105)
Batch 250/537: Loss=0.7734 (C:0.7734, R:0.0105)
Batch 275/537: Loss=0.7654 (C:0.7654, R:0.0105)
Batch 300/537: Loss=0.7571 (C:0.7571, R:0.0105)
Batch 325/537: Loss=0.8019 (C:0.8019, R:0.0105)
Batch 350/537: Loss=0.7386 (C:0.7386, R:0.0105)
Batch 375/537: Loss=0.8280 (C:0.8280, R:0.0105)
Batch 400/537: Loss=0.7434 (C:0.7434, R:0.0105)
Batch 425/537: Loss=0.8062 (C:0.8062, R:0.0105)
Batch 450/537: Loss=0.7511 (C:0.7511, R:0.0105)
Batch 475/537: Loss=0.7753 (C:0.7753, R:0.0105)
Batch 500/537: Loss=0.7208 (C:0.7208, R:0.0105)
Batch 525/537: Loss=0.7185 (C:0.7185, R:0.0105)

============================================================
Epoch 78/300 completed in 27.7s
Train: Loss=0.7756 (C:0.7756, R:0.0105) Ratio=5.38x
Val:   Loss=1.0709 (C:1.0709, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 79
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.442 ± 0.825
    Neg distances: 4.072 ± 1.661
    Separation ratio: 9.22x
    Gap: -6.909
    ✅ Excellent global separation!

Epoch 79 Training
----------------------------------------
Batch   0/537: Loss=0.7293 (C:0.7293, R:0.0105)
Batch  25/537: Loss=0.7344 (C:0.7344, R:0.0105)
Batch  50/537: Loss=0.7620 (C:0.7620, R:0.0105)
Batch  75/537: Loss=0.7493 (C:0.7493, R:0.0105)
Batch 100/537: Loss=0.8028 (C:0.8028, R:0.0105)
Batch 125/537: Loss=0.8210 (C:0.8210, R:0.0105)
Batch 150/537: Loss=0.7646 (C:0.7646, R:0.0105)
Batch 175/537: Loss=0.7871 (C:0.7871, R:0.0105)
Batch 200/537: Loss=0.7368 (C:0.7368, R:0.0105)
Batch 225/537: Loss=0.7752 (C:0.7752, R:0.0105)
Batch 250/537: Loss=0.7678 (C:0.7678, R:0.0105)
Batch 275/537: Loss=0.8008 (C:0.8008, R:0.0105)
Batch 300/537: Loss=0.8424 (C:0.8424, R:0.0105)
Batch 325/537: Loss=0.7706 (C:0.7706, R:0.0105)
Batch 350/537: Loss=0.7476 (C:0.7476, R:0.0105)
Batch 375/537: Loss=0.7837 (C:0.7837, R:0.0105)
Batch 400/537: Loss=0.8004 (C:0.8004, R:0.0105)
Batch 425/537: Loss=0.7385 (C:0.7385, R:0.0105)
Batch 450/537: Loss=0.7796 (C:0.7796, R:0.0105)
Batch 475/537: Loss=0.7622 (C:0.7622, R:0.0104)
Batch 500/537: Loss=0.7668 (C:0.7668, R:0.0105)
Batch 525/537: Loss=0.7725 (C:0.7725, R:0.0105)

============================================================
Epoch 79/300 completed in 27.0s
Train: Loss=0.7750 (C:0.7750, R:0.0105) Ratio=5.31x
Val:   Loss=1.0540 (C:1.0540, R:0.0104) Ratio=3.03x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 80
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.440 ± 0.838
    Neg distances: 4.103 ± 1.667
    Separation ratio: 9.33x
    Gap: -6.862
    ✅ Excellent global separation!

Epoch 80 Training
----------------------------------------
Batch   0/537: Loss=0.7531 (C:0.7531, R:0.0105)
Batch  25/537: Loss=0.7475 (C:0.7475, R:0.0105)
Batch  50/537: Loss=0.7984 (C:0.7984, R:0.0105)
Batch  75/537: Loss=0.8475 (C:0.8475, R:0.0105)
Batch 100/537: Loss=0.7832 (C:0.7832, R:0.0105)
Batch 125/537: Loss=0.8550 (C:0.8550, R:0.0105)
Batch 150/537: Loss=0.7334 (C:0.7334, R:0.0105)
Batch 175/537: Loss=0.7584 (C:0.7584, R:0.0105)
Batch 200/537: Loss=0.7273 (C:0.7273, R:0.0106)
Batch 225/537: Loss=0.7770 (C:0.7770, R:0.0105)
Batch 250/537: Loss=0.7648 (C:0.7648, R:0.0105)
Batch 275/537: Loss=0.8023 (C:0.8023, R:0.0105)
Batch 300/537: Loss=0.8026 (C:0.8026, R:0.0105)
Batch 325/537: Loss=0.7762 (C:0.7762, R:0.0105)
Batch 350/537: Loss=0.7694 (C:0.7694, R:0.0105)
Batch 375/537: Loss=0.8121 (C:0.8121, R:0.0105)
Batch 400/537: Loss=0.8281 (C:0.8281, R:0.0105)
Batch 425/537: Loss=0.7701 (C:0.7701, R:0.0105)
Batch 450/537: Loss=0.7430 (C:0.7430, R:0.0105)
Batch 475/537: Loss=0.7941 (C:0.7941, R:0.0105)
Batch 500/537: Loss=0.7620 (C:0.7620, R:0.0105)
Batch 525/537: Loss=0.7783 (C:0.7783, R:0.0105)

============================================================
Epoch 80/300 completed in 27.7s
Train: Loss=0.7723 (C:0.7723, R:0.0105) Ratio=5.26x
Val:   Loss=1.0514 (C:1.0514, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
No improvement for 3 epochs
Checkpoint saved at epoch 80
============================================================

🌍 Updating global dataset at epoch 81
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.486 ± 0.900
    Neg distances: 4.096 ± 1.694
    Separation ratio: 8.42x
    Gap: -6.976
    ✅ Excellent global separation!

Epoch 81 Training
----------------------------------------
Batch   0/537: Loss=0.7847 (C:0.7847, R:0.0105)
Batch  25/537: Loss=0.8006 (C:0.8006, R:0.0105)
Batch  50/537: Loss=0.8271 (C:0.8271, R:0.0105)
Batch  75/537: Loss=0.7629 (C:0.7629, R:0.0105)
Batch 100/537: Loss=0.7624 (C:0.7624, R:0.0105)
Batch 125/537: Loss=0.8203 (C:0.8203, R:0.0105)
Batch 150/537: Loss=0.7396 (C:0.7396, R:0.0105)
Batch 175/537: Loss=0.7926 (C:0.7926, R:0.0105)
Batch 200/537: Loss=0.8202 (C:0.8202, R:0.0105)
Batch 225/537: Loss=0.8428 (C:0.8428, R:0.0106)
Batch 250/537: Loss=0.8214 (C:0.8214, R:0.0105)
Batch 275/537: Loss=0.7618 (C:0.7618, R:0.0105)
Batch 300/537: Loss=0.7653 (C:0.7653, R:0.0105)
Batch 325/537: Loss=0.8325 (C:0.8325, R:0.0105)
Batch 350/537: Loss=0.7765 (C:0.7765, R:0.0105)
Batch 375/537: Loss=0.7848 (C:0.7848, R:0.0106)
Batch 400/537: Loss=0.8233 (C:0.8233, R:0.0105)
Batch 425/537: Loss=0.7469 (C:0.7469, R:0.0105)
Batch 450/537: Loss=0.7976 (C:0.7976, R:0.0105)
Batch 475/537: Loss=0.8250 (C:0.8250, R:0.0106)
Batch 500/537: Loss=0.7564 (C:0.7564, R:0.0105)
Batch 525/537: Loss=0.8252 (C:0.8252, R:0.0105)

============================================================
Epoch 81/300 completed in 27.5s
Train: Loss=0.8048 (C:0.8048, R:0.0105) Ratio=5.46x
Val:   Loss=1.0743 (C:1.0743, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
No improvement for 4 epochs
============================================================

🌍 Updating global dataset at epoch 82
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.426 ± 0.802
    Neg distances: 4.135 ± 1.675
    Separation ratio: 9.70x
    Gap: -6.900
    ✅ Excellent global separation!

Epoch 82 Training
----------------------------------------
Batch   0/537: Loss=0.7670 (C:0.7670, R:0.0105)
Batch  25/537: Loss=0.7511 (C:0.7511, R:0.0105)
Batch  50/537: Loss=0.7880 (C:0.7880, R:0.0105)
Batch  75/537: Loss=0.7337 (C:0.7337, R:0.0105)
Batch 100/537: Loss=0.7561 (C:0.7561, R:0.0105)
Batch 125/537: Loss=0.7808 (C:0.7808, R:0.0105)
Batch 150/537: Loss=0.7708 (C:0.7708, R:0.0105)
Batch 175/537: Loss=0.7190 (C:0.7190, R:0.0105)
Batch 200/537: Loss=0.8258 (C:0.8258, R:0.0105)
Batch 225/537: Loss=0.7459 (C:0.7459, R:0.0105)
Batch 250/537: Loss=0.7039 (C:0.7039, R:0.0105)
Batch 275/537: Loss=0.7648 (C:0.7648, R:0.0105)
Batch 300/537: Loss=0.7238 (C:0.7238, R:0.0105)
Batch 325/537: Loss=0.7781 (C:0.7781, R:0.0105)
Batch 350/537: Loss=0.7553 (C:0.7553, R:0.0105)
Batch 375/537: Loss=0.7462 (C:0.7462, R:0.0105)
Batch 400/537: Loss=0.7955 (C:0.7955, R:0.0105)
Batch 425/537: Loss=0.7322 (C:0.7322, R:0.0105)
Batch 450/537: Loss=0.7373 (C:0.7373, R:0.0105)
Batch 475/537: Loss=0.7520 (C:0.7520, R:0.0105)
Batch 500/537: Loss=0.8213 (C:0.8213, R:0.0105)
Batch 525/537: Loss=0.7880 (C:0.7880, R:0.0105)

============================================================
Epoch 82/300 completed in 27.3s
Train: Loss=0.7569 (C:0.7569, R:0.0105) Ratio=5.29x
Val:   Loss=1.0571 (C:1.0571, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 5 epochs
============================================================

🌍 Updating global dataset at epoch 83
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.424 ± 0.826
    Neg distances: 4.100 ± 1.660
    Separation ratio: 9.67x
    Gap: -7.001
    ✅ Excellent global separation!

Epoch 83 Training
----------------------------------------
Batch   0/537: Loss=0.7576 (C:0.7576, R:0.0105)
Batch  25/537: Loss=0.6874 (C:0.6874, R:0.0105)
Batch  50/537: Loss=0.7250 (C:0.7250, R:0.0105)
Batch  75/537: Loss=0.7413 (C:0.7413, R:0.0105)
Batch 100/537: Loss=0.7784 (C:0.7784, R:0.0105)
Batch 125/537: Loss=0.7537 (C:0.7537, R:0.0105)
Batch 150/537: Loss=0.7492 (C:0.7492, R:0.0105)
Batch 175/537: Loss=0.7551 (C:0.7551, R:0.0105)
Batch 200/537: Loss=0.7485 (C:0.7485, R:0.0105)
Batch 225/537: Loss=0.7369 (C:0.7369, R:0.0105)
Batch 250/537: Loss=0.7731 (C:0.7731, R:0.0105)
Batch 275/537: Loss=0.7502 (C:0.7502, R:0.0105)
Batch 300/537: Loss=0.7704 (C:0.7704, R:0.0105)
Batch 325/537: Loss=0.7983 (C:0.7983, R:0.0105)
Batch 350/537: Loss=0.7279 (C:0.7279, R:0.0105)
Batch 375/537: Loss=0.7950 (C:0.7950, R:0.0106)
Batch 400/537: Loss=0.7943 (C:0.7943, R:0.0105)
Batch 425/537: Loss=0.7589 (C:0.7589, R:0.0105)
Batch 450/537: Loss=0.7903 (C:0.7903, R:0.0105)
Batch 475/537: Loss=0.7441 (C:0.7441, R:0.0105)
Batch 500/537: Loss=0.7928 (C:0.7928, R:0.0106)
Batch 525/537: Loss=0.7281 (C:0.7281, R:0.0105)

============================================================
Epoch 83/300 completed in 27.2s
Train: Loss=0.7548 (C:0.7548, R:0.0105) Ratio=5.32x
Val:   Loss=1.0433 (C:1.0433, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.0433)
============================================================

🌍 Updating global dataset at epoch 84
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.428 ± 0.819
    Neg distances: 4.121 ± 1.671
    Separation ratio: 9.63x
    Gap: -6.882
    ✅ Excellent global separation!

Epoch 84 Training
----------------------------------------
Batch   0/537: Loss=0.7573 (C:0.7573, R:0.0105)
Batch  25/537: Loss=0.7887 (C:0.7887, R:0.0105)
Batch  50/537: Loss=0.7233 (C:0.7233, R:0.0105)
Batch  75/537: Loss=0.7183 (C:0.7183, R:0.0105)
Batch 100/537: Loss=0.7085 (C:0.7085, R:0.0105)
Batch 125/537: Loss=0.7191 (C:0.7191, R:0.0105)
Batch 150/537: Loss=0.7174 (C:0.7174, R:0.0105)
Batch 175/537: Loss=0.7842 (C:0.7842, R:0.0105)
Batch 200/537: Loss=0.7613 (C:0.7613, R:0.0105)
Batch 225/537: Loss=0.7919 (C:0.7919, R:0.0105)
Batch 250/537: Loss=0.7585 (C:0.7585, R:0.0105)
Batch 275/537: Loss=0.7972 (C:0.7972, R:0.0105)
Batch 300/537: Loss=0.7861 (C:0.7861, R:0.0105)
Batch 325/537: Loss=0.7894 (C:0.7894, R:0.0105)
Batch 350/537: Loss=0.8219 (C:0.8219, R:0.0105)
Batch 375/537: Loss=0.7965 (C:0.7965, R:0.0105)
Batch 400/537: Loss=0.7475 (C:0.7475, R:0.0105)
Batch 425/537: Loss=0.7204 (C:0.7204, R:0.0105)
Batch 450/537: Loss=0.7745 (C:0.7745, R:0.0105)
Batch 475/537: Loss=0.7692 (C:0.7692, R:0.0105)
Batch 500/537: Loss=0.7590 (C:0.7590, R:0.0105)
Batch 525/537: Loss=0.7648 (C:0.7648, R:0.0105)

============================================================
Epoch 84/300 completed in 27.4s
Train: Loss=0.7568 (C:0.7568, R:0.0105) Ratio=5.40x
Val:   Loss=1.0538 (C:1.0538, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 85
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.431 ± 0.817
    Neg distances: 4.125 ± 1.672
    Separation ratio: 9.58x
    Gap: -7.084
    ✅ Excellent global separation!

Epoch 85 Training
----------------------------------------
Batch   0/537: Loss=0.7288 (C:0.7288, R:0.0105)
Batch  25/537: Loss=0.7631 (C:0.7631, R:0.0105)
Batch  50/537: Loss=0.7459 (C:0.7459, R:0.0105)
Batch  75/537: Loss=0.7253 (C:0.7253, R:0.0105)
Batch 100/537: Loss=0.7064 (C:0.7064, R:0.0105)
Batch 125/537: Loss=0.7338 (C:0.7338, R:0.0105)
Batch 150/537: Loss=0.7433 (C:0.7433, R:0.0105)
Batch 175/537: Loss=0.7309 (C:0.7309, R:0.0105)
Batch 200/537: Loss=0.7567 (C:0.7567, R:0.0105)
Batch 225/537: Loss=0.7781 (C:0.7781, R:0.0105)
Batch 250/537: Loss=0.8006 (C:0.8006, R:0.0105)
Batch 275/537: Loss=0.7743 (C:0.7743, R:0.0105)
Batch 300/537: Loss=0.8203 (C:0.8203, R:0.0105)
Batch 325/537: Loss=0.7444 (C:0.7444, R:0.0105)
Batch 350/537: Loss=0.7679 (C:0.7679, R:0.0106)
Batch 375/537: Loss=0.7673 (C:0.7673, R:0.0105)
Batch 400/537: Loss=0.7178 (C:0.7178, R:0.0105)
Batch 425/537: Loss=0.7155 (C:0.7155, R:0.0105)
Batch 450/537: Loss=0.7825 (C:0.7825, R:0.0105)
Batch 475/537: Loss=0.7446 (C:0.7446, R:0.0106)
Batch 500/537: Loss=0.7065 (C:0.7065, R:0.0105)
Batch 525/537: Loss=0.7149 (C:0.7149, R:0.0105)

============================================================
Epoch 85/300 completed in 26.7s
Train: Loss=0.7537 (C:0.7537, R:0.0105) Ratio=5.43x
Val:   Loss=1.0606 (C:1.0606, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 86
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.441 ± 0.847
    Neg distances: 4.099 ± 1.673
    Separation ratio: 9.30x
    Gap: -7.069
    ✅ Excellent global separation!

Epoch 86 Training
----------------------------------------
Batch   0/537: Loss=0.7425 (C:0.7425, R:0.0105)
Batch  25/537: Loss=0.7697 (C:0.7697, R:0.0105)
Batch  50/537: Loss=0.7253 (C:0.7253, R:0.0105)
Batch  75/537: Loss=0.8197 (C:0.8197, R:0.0105)
Batch 100/537: Loss=0.7864 (C:0.7864, R:0.0105)
Batch 125/537: Loss=0.7511 (C:0.7511, R:0.0105)
Batch 150/537: Loss=0.8077 (C:0.8077, R:0.0105)
Batch 175/537: Loss=0.7655 (C:0.7655, R:0.0105)
Batch 200/537: Loss=0.7078 (C:0.7078, R:0.0105)
Batch 225/537: Loss=0.7564 (C:0.7564, R:0.0105)
Batch 250/537: Loss=0.7764 (C:0.7764, R:0.0105)
Batch 275/537: Loss=0.8072 (C:0.8072, R:0.0105)
Batch 300/537: Loss=0.7807 (C:0.7807, R:0.0105)
Batch 325/537: Loss=0.7490 (C:0.7490, R:0.0105)
Batch 350/537: Loss=0.7256 (C:0.7256, R:0.0105)
Batch 375/537: Loss=0.7570 (C:0.7570, R:0.0105)
Batch 400/537: Loss=0.7898 (C:0.7898, R:0.0105)
Batch 425/537: Loss=0.7168 (C:0.7168, R:0.0105)
Batch 450/537: Loss=0.7615 (C:0.7615, R:0.0105)
Batch 475/537: Loss=0.7555 (C:0.7555, R:0.0105)
Batch 500/537: Loss=0.8191 (C:0.8191, R:0.0106)
Batch 525/537: Loss=0.7297 (C:0.7297, R:0.0105)

============================================================
Epoch 86/300 completed in 26.5s
Train: Loss=0.7614 (C:0.7614, R:0.0105) Ratio=5.42x
Val:   Loss=1.0513 (C:1.0513, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 87
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.441 ± 0.832
    Neg distances: 4.108 ± 1.677
    Separation ratio: 9.31x
    Gap: -7.008
    ✅ Excellent global separation!

Epoch 87 Training
----------------------------------------
Batch   0/537: Loss=0.7476 (C:0.7476, R:0.0105)
Batch  25/537: Loss=0.7333 (C:0.7333, R:0.0105)
Batch  50/537: Loss=0.7907 (C:0.7907, R:0.0105)
Batch  75/537: Loss=0.7514 (C:0.7514, R:0.0105)
Batch 100/537: Loss=0.7199 (C:0.7199, R:0.0105)
Batch 125/537: Loss=0.7396 (C:0.7396, R:0.0105)
Batch 150/537: Loss=0.7820 (C:0.7820, R:0.0105)
Batch 175/537: Loss=0.7623 (C:0.7623, R:0.0105)
Batch 200/537: Loss=0.7360 (C:0.7360, R:0.0105)
Batch 225/537: Loss=0.7058 (C:0.7058, R:0.0105)
Batch 250/537: Loss=0.7447 (C:0.7447, R:0.0105)
Batch 275/537: Loss=0.7282 (C:0.7282, R:0.0105)
Batch 300/537: Loss=0.7252 (C:0.7252, R:0.0105)
Batch 325/537: Loss=0.7545 (C:0.7545, R:0.0106)
Batch 350/537: Loss=0.7674 (C:0.7674, R:0.0105)
Batch 375/537: Loss=0.7207 (C:0.7207, R:0.0105)
Batch 400/537: Loss=0.7523 (C:0.7523, R:0.0106)
Batch 425/537: Loss=0.7417 (C:0.7417, R:0.0105)
Batch 450/537: Loss=0.7791 (C:0.7791, R:0.0105)
Batch 475/537: Loss=0.7175 (C:0.7175, R:0.0105)
Batch 500/537: Loss=0.8198 (C:0.8198, R:0.0105)
Batch 525/537: Loss=0.7949 (C:0.7949, R:0.0105)

============================================================
Epoch 87/300 completed in 27.3s
Train: Loss=0.7611 (C:0.7611, R:0.0105) Ratio=5.49x
Val:   Loss=1.0441 (C:1.0441, R:0.0104) Ratio=3.12x
Reconstruction weight: 0.300
No improvement for 4 epochs
============================================================

🌍 Updating global dataset at epoch 88
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.419 ± 0.827
    Neg distances: 4.149 ± 1.676
    Separation ratio: 9.91x
    Gap: -7.055
    ✅ Excellent global separation!

Epoch 88 Training
----------------------------------------
Batch   0/537: Loss=0.7336 (C:0.7336, R:0.0105)
Batch  25/537: Loss=0.7342 (C:0.7342, R:0.0105)
Batch  50/537: Loss=0.7621 (C:0.7621, R:0.0105)
Batch  75/537: Loss=0.7493 (C:0.7493, R:0.0105)
Batch 100/537: Loss=0.7179 (C:0.7179, R:0.0105)
Batch 125/537: Loss=0.7167 (C:0.7167, R:0.0105)
Batch 150/537: Loss=0.7203 (C:0.7203, R:0.0105)
Batch 175/537: Loss=0.7735 (C:0.7735, R:0.0105)
Batch 200/537: Loss=0.7422 (C:0.7422, R:0.0105)
Batch 225/537: Loss=0.7710 (C:0.7710, R:0.0105)
Batch 250/537: Loss=0.7777 (C:0.7777, R:0.0105)
Batch 275/537: Loss=0.7137 (C:0.7137, R:0.0105)
Batch 300/537: Loss=0.7543 (C:0.7543, R:0.0105)
Batch 325/537: Loss=0.7258 (C:0.7258, R:0.0105)
Batch 350/537: Loss=0.7545 (C:0.7545, R:0.0105)
Batch 375/537: Loss=0.7373 (C:0.7373, R:0.0105)
Batch 400/537: Loss=0.6863 (C:0.6863, R:0.0105)
Batch 425/537: Loss=0.7625 (C:0.7625, R:0.0105)
Batch 450/537: Loss=0.7177 (C:0.7177, R:0.0105)
Batch 475/537: Loss=0.7645 (C:0.7645, R:0.0105)
Batch 500/537: Loss=0.7269 (C:0.7269, R:0.0105)
Batch 525/537: Loss=0.7876 (C:0.7876, R:0.0105)

============================================================
Epoch 88/300 completed in 27.1s
Train: Loss=0.7433 (C:0.7433, R:0.0105) Ratio=5.45x
Val:   Loss=1.0357 (C:1.0357, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.0357)
============================================================

🌍 Updating global dataset at epoch 89
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.466 ± 0.865
    Neg distances: 4.090 ± 1.689
    Separation ratio: 8.78x
    Gap: -6.890
    ✅ Excellent global separation!

Epoch 89 Training
----------------------------------------
Batch   0/537: Loss=0.7212 (C:0.7212, R:0.0105)
Batch  25/537: Loss=0.7584 (C:0.7584, R:0.0105)
Batch  50/537: Loss=0.7457 (C:0.7457, R:0.0105)
Batch  75/537: Loss=0.7071 (C:0.7071, R:0.0105)
Batch 100/537: Loss=0.7836 (C:0.7836, R:0.0105)
Batch 125/537: Loss=0.7894 (C:0.7894, R:0.0105)
Batch 150/537: Loss=0.7014 (C:0.7014, R:0.0106)
Batch 175/537: Loss=0.8094 (C:0.8094, R:0.0105)
Batch 200/537: Loss=0.7549 (C:0.7549, R:0.0105)
Batch 225/537: Loss=0.7942 (C:0.7942, R:0.0105)
Batch 250/537: Loss=0.8094 (C:0.8094, R:0.0105)
Batch 275/537: Loss=0.8135 (C:0.8135, R:0.0105)
Batch 300/537: Loss=0.8206 (C:0.8206, R:0.0105)
Batch 325/537: Loss=0.8161 (C:0.8161, R:0.0105)
Batch 350/537: Loss=0.8174 (C:0.8174, R:0.0105)
Batch 375/537: Loss=0.8007 (C:0.8007, R:0.0105)
Batch 400/537: Loss=0.8093 (C:0.8093, R:0.0105)
Batch 425/537: Loss=0.7651 (C:0.7651, R:0.0105)
Batch 450/537: Loss=0.7765 (C:0.7765, R:0.0105)
Batch 475/537: Loss=0.7549 (C:0.7549, R:0.0105)
Batch 500/537: Loss=0.8156 (C:0.8156, R:0.0105)
Batch 525/537: Loss=0.7687 (C:0.7687, R:0.0105)

============================================================
Epoch 89/300 completed in 27.3s
Train: Loss=0.7801 (C:0.7801, R:0.0105) Ratio=5.49x
Val:   Loss=1.0773 (C:1.0773, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 90
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.411 ± 0.807
    Neg distances: 4.115 ± 1.659
    Separation ratio: 10.00x
    Gap: -6.950
    ✅ Excellent global separation!

Epoch 90 Training
----------------------------------------
Batch   0/537: Loss=0.7088 (C:0.7088, R:0.0105)
Batch  25/537: Loss=0.6984 (C:0.6984, R:0.0106)
Batch  50/537: Loss=0.7179 (C:0.7179, R:0.0105)
Batch  75/537: Loss=0.7396 (C:0.7396, R:0.0105)
Batch 100/537: Loss=0.6703 (C:0.6703, R:0.0105)
Batch 125/537: Loss=0.7545 (C:0.7545, R:0.0105)
Batch 150/537: Loss=0.7351 (C:0.7351, R:0.0105)
Batch 175/537: Loss=0.7686 (C:0.7686, R:0.0105)
Batch 200/537: Loss=0.6927 (C:0.6927, R:0.0105)
Batch 225/537: Loss=0.6568 (C:0.6568, R:0.0105)
Batch 250/537: Loss=0.7222 (C:0.7222, R:0.0105)
Batch 275/537: Loss=0.7842 (C:0.7842, R:0.0105)
Batch 300/537: Loss=0.7733 (C:0.7733, R:0.0105)
Batch 325/537: Loss=0.7322 (C:0.7322, R:0.0105)
Batch 350/537: Loss=0.7612 (C:0.7612, R:0.0105)
Batch 375/537: Loss=0.7950 (C:0.7950, R:0.0105)
Batch 400/537: Loss=0.7710 (C:0.7710, R:0.0105)
Batch 425/537: Loss=0.7449 (C:0.7449, R:0.0105)
Batch 450/537: Loss=0.7535 (C:0.7535, R:0.0105)
Batch 475/537: Loss=0.7154 (C:0.7154, R:0.0105)
Batch 500/537: Loss=0.7170 (C:0.7170, R:0.0105)
Batch 525/537: Loss=0.7665 (C:0.7665, R:0.0105)

============================================================
Epoch 90/300 completed in 27.1s
Train: Loss=0.7347 (C:0.7347, R:0.0105) Ratio=5.49x
Val:   Loss=1.0254 (C:1.0254, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.0254)
============================================================

🌍 Updating global dataset at epoch 91
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.423 ± 0.821
    Neg distances: 4.126 ± 1.675
    Separation ratio: 9.76x
    Gap: -6.952
    ✅ Excellent global separation!

Epoch 91 Training
----------------------------------------
Batch   0/537: Loss=0.7215 (C:0.7215, R:0.0105)
Batch  25/537: Loss=0.7439 (C:0.7439, R:0.0105)
Batch  50/537: Loss=0.7245 (C:0.7245, R:0.0105)
Batch  75/537: Loss=0.7357 (C:0.7357, R:0.0105)
Batch 100/537: Loss=0.7228 (C:0.7228, R:0.0105)
Batch 125/537: Loss=0.7506 (C:0.7506, R:0.0105)
Batch 150/537: Loss=0.7527 (C:0.7527, R:0.0105)
Batch 175/537: Loss=0.7193 (C:0.7193, R:0.0105)
Batch 200/537: Loss=0.7494 (C:0.7494, R:0.0105)
Batch 225/537: Loss=0.7651 (C:0.7651, R:0.0105)
Batch 250/537: Loss=0.8109 (C:0.8109, R:0.0105)
Batch 275/537: Loss=0.7312 (C:0.7312, R:0.0105)
Batch 300/537: Loss=0.7722 (C:0.7722, R:0.0105)
Batch 325/537: Loss=0.7374 (C:0.7374, R:0.0105)
Batch 350/537: Loss=0.7695 (C:0.7695, R:0.0105)
Batch 375/537: Loss=0.7727 (C:0.7727, R:0.0105)
Batch 400/537: Loss=0.7227 (C:0.7227, R:0.0105)
Batch 425/537: Loss=0.7685 (C:0.7685, R:0.0105)
Batch 450/537: Loss=0.7642 (C:0.7642, R:0.0105)
Batch 475/537: Loss=0.7591 (C:0.7591, R:0.0105)
Batch 500/537: Loss=0.7165 (C:0.7165, R:0.0105)
Batch 525/537: Loss=0.7313 (C:0.7313, R:0.0105)

============================================================
Epoch 91/300 completed in 27.0s
Train: Loss=0.7425 (C:0.7425, R:0.0105) Ratio=5.45x
Val:   Loss=1.0498 (C:1.0498, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 92
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.442 ± 0.862
    Neg distances: 4.113 ± 1.678
    Separation ratio: 9.30x
    Gap: -7.073
    ✅ Excellent global separation!

Epoch 92 Training
----------------------------------------
Batch   0/537: Loss=0.7525 (C:0.7525, R:0.0105)
Batch  25/537: Loss=0.7211 (C:0.7211, R:0.0105)
Batch  50/537: Loss=0.7294 (C:0.7294, R:0.0105)
Batch  75/537: Loss=0.7393 (C:0.7393, R:0.0105)
Batch 100/537: Loss=0.7506 (C:0.7506, R:0.0105)
Batch 125/537: Loss=0.7358 (C:0.7358, R:0.0105)
Batch 150/537: Loss=0.7440 (C:0.7440, R:0.0106)
Batch 175/537: Loss=0.7653 (C:0.7653, R:0.0105)
Batch 200/537: Loss=0.7217 (C:0.7217, R:0.0105)
Batch 225/537: Loss=0.7596 (C:0.7596, R:0.0106)
Batch 250/537: Loss=0.6895 (C:0.6895, R:0.0106)
Batch 275/537: Loss=0.8030 (C:0.8030, R:0.0105)
Batch 300/537: Loss=0.7322 (C:0.7322, R:0.0105)
Batch 325/537: Loss=0.7967 (C:0.7967, R:0.0105)
Batch 350/537: Loss=0.8033 (C:0.8033, R:0.0105)
Batch 375/537: Loss=0.7527 (C:0.7527, R:0.0105)
Batch 400/537: Loss=0.7189 (C:0.7189, R:0.0105)
Batch 425/537: Loss=0.8148 (C:0.8148, R:0.0105)
Batch 450/537: Loss=0.7919 (C:0.7919, R:0.0105)
Batch 475/537: Loss=0.7726 (C:0.7726, R:0.0105)
Batch 500/537: Loss=0.7605 (C:0.7605, R:0.0105)
Batch 525/537: Loss=0.7419 (C:0.7419, R:0.0106)

============================================================
Epoch 92/300 completed in 27.4s
Train: Loss=0.7537 (C:0.7537, R:0.0105) Ratio=5.48x
Val:   Loss=1.0592 (C:1.0592, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 93
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.419 ± 0.842
    Neg distances: 4.116 ± 1.666
    Separation ratio: 9.83x
    Gap: -7.237
    ✅ Excellent global separation!

Epoch 93 Training
----------------------------------------
Batch   0/537: Loss=0.7099 (C:0.7099, R:0.0105)
Batch  25/537: Loss=0.7417 (C:0.7417, R:0.0105)
Batch  50/537: Loss=0.7282 (C:0.7282, R:0.0106)
Batch  75/537: Loss=0.7547 (C:0.7547, R:0.0105)
Batch 100/537: Loss=0.7273 (C:0.7273, R:0.0105)
Batch 125/537: Loss=0.7207 (C:0.7207, R:0.0105)
Batch 150/537: Loss=0.6773 (C:0.6773, R:0.0105)
Batch 175/537: Loss=0.7708 (C:0.7708, R:0.0105)
Batch 200/537: Loss=0.6920 (C:0.6920, R:0.0105)
Batch 225/537: Loss=0.7513 (C:0.7513, R:0.0105)
Batch 250/537: Loss=0.7660 (C:0.7660, R:0.0106)
Batch 275/537: Loss=0.6996 (C:0.6996, R:0.0105)
Batch 300/537: Loss=0.7246 (C:0.7246, R:0.0105)
Batch 325/537: Loss=0.7747 (C:0.7747, R:0.0105)
Batch 350/537: Loss=0.7422 (C:0.7422, R:0.0105)
Batch 375/537: Loss=0.7171 (C:0.7171, R:0.0105)
Batch 400/537: Loss=0.7302 (C:0.7302, R:0.0105)
Batch 425/537: Loss=0.7403 (C:0.7403, R:0.0105)
Batch 450/537: Loss=0.7014 (C:0.7014, R:0.0105)
Batch 475/537: Loss=0.7595 (C:0.7595, R:0.0105)
Batch 500/537: Loss=0.7463 (C:0.7463, R:0.0105)
Batch 525/537: Loss=0.7355 (C:0.7355, R:0.0105)

============================================================
Epoch 93/300 completed in 27.5s
Train: Loss=0.7371 (C:0.7371, R:0.0105) Ratio=5.57x
Val:   Loss=1.0205 (C:1.0205, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.0205)
============================================================

🌍 Updating global dataset at epoch 94
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.427 ± 0.825
    Neg distances: 4.124 ± 1.674
    Separation ratio: 9.65x
    Gap: -6.957
    ✅ Excellent global separation!

Epoch 94 Training
----------------------------------------
Batch   0/537: Loss=0.7346 (C:0.7346, R:0.0105)
Batch  25/537: Loss=0.7601 (C:0.7601, R:0.0105)
Batch  50/537: Loss=0.7501 (C:0.7501, R:0.0105)
Batch  75/537: Loss=0.7881 (C:0.7881, R:0.0105)
Batch 100/537: Loss=0.6943 (C:0.6943, R:0.0105)
Batch 125/537: Loss=0.6744 (C:0.6744, R:0.0105)
Batch 150/537: Loss=0.6916 (C:0.6916, R:0.0105)
Batch 175/537: Loss=0.7703 (C:0.7703, R:0.0105)
Batch 200/537: Loss=0.7266 (C:0.7266, R:0.0105)
Batch 225/537: Loss=0.7446 (C:0.7446, R:0.0106)
Batch 250/537: Loss=0.7697 (C:0.7697, R:0.0105)
Batch 275/537: Loss=0.7503 (C:0.7503, R:0.0105)
Batch 300/537: Loss=0.6913 (C:0.6913, R:0.0105)
Batch 325/537: Loss=0.7394 (C:0.7394, R:0.0105)
Batch 350/537: Loss=0.7564 (C:0.7564, R:0.0105)
Batch 375/537: Loss=0.7357 (C:0.7357, R:0.0105)
Batch 400/537: Loss=0.7718 (C:0.7718, R:0.0105)
Batch 425/537: Loss=0.7254 (C:0.7254, R:0.0105)
Batch 450/537: Loss=0.7455 (C:0.7455, R:0.0105)
Batch 475/537: Loss=0.6994 (C:0.6994, R:0.0105)
Batch 500/537: Loss=0.6999 (C:0.6999, R:0.0105)
Batch 525/537: Loss=0.8135 (C:0.8135, R:0.0105)

============================================================
Epoch 94/300 completed in 27.5s
Train: Loss=0.7421 (C:0.7421, R:0.0105) Ratio=5.55x
Val:   Loss=1.0633 (C:1.0633, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 95
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.428 ± 0.855
    Neg distances: 4.146 ± 1.683
    Separation ratio: 9.68x
    Gap: -6.929
    ✅ Excellent global separation!

Epoch 95 Training
----------------------------------------
Batch   0/537: Loss=0.6338 (C:0.6338, R:0.0105)
Batch  25/537: Loss=0.7484 (C:0.7484, R:0.0105)
Batch  50/537: Loss=0.7048 (C:0.7048, R:0.0105)
Batch  75/537: Loss=0.7542 (C:0.7542, R:0.0105)
Batch 100/537: Loss=0.7267 (C:0.7267, R:0.0105)
Batch 125/537: Loss=0.7238 (C:0.7238, R:0.0105)
Batch 150/537: Loss=0.7785 (C:0.7785, R:0.0105)
Batch 175/537: Loss=0.7459 (C:0.7459, R:0.0105)
Batch 200/537: Loss=0.7409 (C:0.7409, R:0.0105)
Batch 225/537: Loss=0.7157 (C:0.7157, R:0.0105)
Batch 250/537: Loss=0.7157 (C:0.7157, R:0.0105)
Batch 275/537: Loss=0.7637 (C:0.7637, R:0.0105)
Batch 300/537: Loss=0.7769 (C:0.7769, R:0.0105)
Batch 325/537: Loss=0.7206 (C:0.7206, R:0.0105)
Batch 350/537: Loss=0.7672 (C:0.7672, R:0.0105)
Batch 375/537: Loss=0.7539 (C:0.7539, R:0.0105)
Batch 400/537: Loss=0.7301 (C:0.7301, R:0.0105)
Batch 425/537: Loss=0.7311 (C:0.7311, R:0.0105)
Batch 450/537: Loss=0.7496 (C:0.7496, R:0.0105)
Batch 475/537: Loss=0.7509 (C:0.7509, R:0.0105)
Batch 500/537: Loss=0.7617 (C:0.7617, R:0.0105)
Batch 525/537: Loss=0.7627 (C:0.7627, R:0.0105)

============================================================
Epoch 95/300 completed in 27.1s
Train: Loss=0.7398 (C:0.7398, R:0.0105) Ratio=5.53x
Val:   Loss=1.0542 (C:1.0542, R:0.0104) Ratio=3.03x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 96
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.400 ± 0.807
    Neg distances: 4.168 ± 1.677
    Separation ratio: 10.42x
    Gap: -7.106
    ✅ Excellent global separation!

Epoch 96 Training
----------------------------------------
Batch   0/537: Loss=0.7576 (C:0.7576, R:0.0105)
Batch  25/537: Loss=0.7357 (C:0.7357, R:0.0105)
Batch  50/537: Loss=0.6895 (C:0.6895, R:0.0105)
Batch  75/537: Loss=0.6629 (C:0.6629, R:0.0105)
Batch 100/537: Loss=0.6901 (C:0.6901, R:0.0105)
Batch 125/537: Loss=0.6693 (C:0.6693, R:0.0105)
Batch 150/537: Loss=0.6919 (C:0.6919, R:0.0105)
Batch 175/537: Loss=0.6835 (C:0.6835, R:0.0105)
Batch 200/537: Loss=0.7265 (C:0.7265, R:0.0105)
Batch 225/537: Loss=0.7187 (C:0.7187, R:0.0105)
Batch 250/537: Loss=0.7549 (C:0.7549, R:0.0105)
Batch 275/537: Loss=0.7547 (C:0.7547, R:0.0105)
Batch 300/537: Loss=0.7203 (C:0.7203, R:0.0106)
Batch 325/537: Loss=0.7377 (C:0.7377, R:0.0105)
Batch 350/537: Loss=0.7541 (C:0.7541, R:0.0105)
Batch 375/537: Loss=0.7063 (C:0.7063, R:0.0105)
Batch 400/537: Loss=0.6981 (C:0.6981, R:0.0105)
Batch 425/537: Loss=0.7096 (C:0.7096, R:0.0105)
Batch 450/537: Loss=0.7517 (C:0.7517, R:0.0105)
Batch 475/537: Loss=0.7194 (C:0.7194, R:0.0105)
Batch 500/537: Loss=0.7245 (C:0.7245, R:0.0105)
Batch 525/537: Loss=0.7213 (C:0.7213, R:0.0105)

============================================================
Epoch 96/300 completed in 27.1s
Train: Loss=0.7168 (C:0.7168, R:0.0105) Ratio=5.64x
Val:   Loss=1.0197 (C:1.0197, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.0197)
============================================================

🌍 Updating global dataset at epoch 97
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.415 ± 0.812
    Neg distances: 4.196 ± 1.691
    Separation ratio: 10.11x
    Gap: -7.077
    ✅ Excellent global separation!

Epoch 97 Training
----------------------------------------
Batch   0/537: Loss=0.7016 (C:0.7016, R:0.0105)
Batch  25/537: Loss=0.7570 (C:0.7570, R:0.0105)
Batch  50/537: Loss=0.7230 (C:0.7230, R:0.0105)
Batch  75/537: Loss=0.7105 (C:0.7105, R:0.0105)
Batch 100/537: Loss=0.7484 (C:0.7484, R:0.0105)
Batch 125/537: Loss=0.6875 (C:0.6875, R:0.0105)
Batch 150/537: Loss=0.6884 (C:0.6884, R:0.0106)
Batch 175/537: Loss=0.7247 (C:0.7247, R:0.0105)
Batch 200/537: Loss=0.7223 (C:0.7223, R:0.0105)
Batch 225/537: Loss=0.7182 (C:0.7182, R:0.0105)
Batch 250/537: Loss=0.7599 (C:0.7599, R:0.0105)
Batch 275/537: Loss=0.6948 (C:0.6948, R:0.0105)
Batch 300/537: Loss=0.7561 (C:0.7561, R:0.0105)
Batch 325/537: Loss=0.7074 (C:0.7074, R:0.0105)
Batch 350/537: Loss=0.6660 (C:0.6660, R:0.0105)
Batch 375/537: Loss=0.7711 (C:0.7711, R:0.0105)
Batch 400/537: Loss=0.7797 (C:0.7797, R:0.0105)
Batch 425/537: Loss=0.7042 (C:0.7042, R:0.0105)
Batch 450/537: Loss=0.7027 (C:0.7027, R:0.0105)
Batch 475/537: Loss=0.6845 (C:0.6845, R:0.0105)
Batch 500/537: Loss=0.7105 (C:0.7105, R:0.0106)
Batch 525/537: Loss=0.7501 (C:0.7501, R:0.0105)

============================================================
Epoch 97/300 completed in 26.8s
Train: Loss=0.7262 (C:0.7262, R:0.0105) Ratio=5.69x
Val:   Loss=1.0361 (C:1.0361, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 98
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.401 ± 0.786
    Neg distances: 4.207 ± 1.685
    Separation ratio: 10.48x
    Gap: -6.929
    ✅ Excellent global separation!

Epoch 98 Training
----------------------------------------
Batch   0/537: Loss=0.6463 (C:0.6463, R:0.0105)
Batch  25/537: Loss=0.6575 (C:0.6575, R:0.0105)
Batch  50/537: Loss=0.7228 (C:0.7228, R:0.0105)
Batch  75/537: Loss=0.7218 (C:0.7218, R:0.0105)
Batch 100/537: Loss=0.7425 (C:0.7425, R:0.0105)
Batch 125/537: Loss=0.7546 (C:0.7546, R:0.0105)
Batch 150/537: Loss=0.6840 (C:0.6840, R:0.0105)
Batch 175/537: Loss=0.7040 (C:0.7040, R:0.0105)
Batch 200/537: Loss=0.7413 (C:0.7413, R:0.0105)
Batch 225/537: Loss=0.7002 (C:0.7002, R:0.0105)
Batch 250/537: Loss=0.7903 (C:0.7903, R:0.0105)
Batch 275/537: Loss=0.6779 (C:0.6779, R:0.0105)
Batch 300/537: Loss=0.6841 (C:0.6841, R:0.0105)
Batch 325/537: Loss=0.7440 (C:0.7440, R:0.0105)
Batch 350/537: Loss=0.6585 (C:0.6585, R:0.0105)
Batch 375/537: Loss=0.7470 (C:0.7470, R:0.0106)
Batch 400/537: Loss=0.7385 (C:0.7385, R:0.0105)
Batch 425/537: Loss=0.6727 (C:0.6727, R:0.0105)
Batch 450/537: Loss=0.7603 (C:0.7603, R:0.0105)
Batch 475/537: Loss=0.6984 (C:0.6984, R:0.0105)
Batch 500/537: Loss=0.6975 (C:0.6975, R:0.0105)
Batch 525/537: Loss=0.7062 (C:0.7062, R:0.0105)

============================================================
Epoch 98/300 completed in 27.3s
Train: Loss=0.7127 (C:0.7127, R:0.0105) Ratio=5.58x
Val:   Loss=1.0295 (C:1.0295, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 99
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.404 ± 0.808
    Neg distances: 4.223 ± 1.692
    Separation ratio: 10.46x
    Gap: -7.105
    ✅ Excellent global separation!

Epoch 99 Training
----------------------------------------
Batch   0/537: Loss=0.7250 (C:0.7250, R:0.0105)
Batch  25/537: Loss=0.7535 (C:0.7535, R:0.0105)
Batch  50/537: Loss=0.7021 (C:0.7021, R:0.0105)
Batch  75/537: Loss=0.6831 (C:0.6831, R:0.0105)
Batch 100/537: Loss=0.7422 (C:0.7422, R:0.0105)
Batch 125/537: Loss=0.7022 (C:0.7022, R:0.0105)
Batch 150/537: Loss=0.7223 (C:0.7223, R:0.0106)
Batch 175/537: Loss=0.7620 (C:0.7620, R:0.0105)
Batch 200/537: Loss=0.7581 (C:0.7581, R:0.0105)
Batch 225/537: Loss=0.6961 (C:0.6961, R:0.0105)
Batch 250/537: Loss=0.7199 (C:0.7199, R:0.0105)
Batch 275/537: Loss=0.8107 (C:0.8107, R:0.0105)
Batch 300/537: Loss=0.7309 (C:0.7309, R:0.0105)
Batch 325/537: Loss=0.6986 (C:0.6986, R:0.0105)
Batch 350/537: Loss=0.7169 (C:0.7169, R:0.0105)
Batch 375/537: Loss=0.6062 (C:0.6062, R:0.0105)
Batch 400/537: Loss=0.7207 (C:0.7207, R:0.0105)
Batch 425/537: Loss=0.6948 (C:0.6948, R:0.0105)
Batch 450/537: Loss=0.7349 (C:0.7349, R:0.0105)
Batch 475/537: Loss=0.6904 (C:0.6904, R:0.0105)
Batch 500/537: Loss=0.6585 (C:0.6585, R:0.0105)
Batch 525/537: Loss=0.7109 (C:0.7109, R:0.0105)

============================================================
Epoch 99/300 completed in 27.0s
Train: Loss=0.7121 (C:0.7121, R:0.0105) Ratio=5.58x
Val:   Loss=1.0416 (C:1.0416, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 100
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.404 ± 0.821
    Neg distances: 4.181 ± 1.679
    Separation ratio: 10.34x
    Gap: -7.036
    ✅ Excellent global separation!

Epoch 100 Training
----------------------------------------
Batch   0/537: Loss=0.6971 (C:0.6971, R:0.0105)
Batch  25/537: Loss=0.7095 (C:0.7095, R:0.0105)
Batch  50/537: Loss=0.6794 (C:0.6794, R:0.0105)
Batch  75/537: Loss=0.6919 (C:0.6919, R:0.0105)
Batch 100/537: Loss=0.7270 (C:0.7270, R:0.0105)
Batch 125/537: Loss=0.7256 (C:0.7256, R:0.0105)
Batch 150/537: Loss=0.7504 (C:0.7504, R:0.0106)
Batch 175/537: Loss=0.7686 (C:0.7686, R:0.0105)
Batch 200/537: Loss=0.7477 (C:0.7477, R:0.0105)
Batch 225/537: Loss=0.7264 (C:0.7264, R:0.0105)
Batch 250/537: Loss=0.7034 (C:0.7034, R:0.0105)
Batch 275/537: Loss=0.6803 (C:0.6803, R:0.0105)
Batch 300/537: Loss=0.6354 (C:0.6354, R:0.0105)
Batch 325/537: Loss=0.7294 (C:0.7294, R:0.0105)
Batch 350/537: Loss=0.7473 (C:0.7473, R:0.0105)
Batch 375/537: Loss=0.7319 (C:0.7319, R:0.0105)
Batch 400/537: Loss=0.7199 (C:0.7199, R:0.0105)
Batch 425/537: Loss=0.6740 (C:0.6740, R:0.0105)
Batch 450/537: Loss=0.7763 (C:0.7763, R:0.0105)
Batch 475/537: Loss=0.7290 (C:0.7290, R:0.0105)
Batch 500/537: Loss=0.7031 (C:0.7031, R:0.0105)
Batch 525/537: Loss=0.7390 (C:0.7390, R:0.0105)

============================================================
Epoch 100/300 completed in 27.0s
Train: Loss=0.7140 (C:0.7140, R:0.0105) Ratio=5.59x
Val:   Loss=1.0254 (C:1.0254, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
No improvement for 4 epochs
Checkpoint saved at epoch 100
============================================================

🌍 Updating global dataset at epoch 101
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.380 ± 0.761
    Neg distances: 4.210 ± 1.670
    Separation ratio: 11.09x
    Gap: -6.962
    ✅ Excellent global separation!

Epoch 101 Training
----------------------------------------
Batch   0/537: Loss=0.7074 (C:0.7074, R:0.0105)
Batch  25/537: Loss=0.6398 (C:0.6398, R:0.0105)
Batch  50/537: Loss=0.7145 (C:0.7145, R:0.0105)
Batch  75/537: Loss=0.7181 (C:0.7181, R:0.0105)
Batch 100/537: Loss=0.7222 (C:0.7222, R:0.0105)
Batch 125/537: Loss=0.6705 (C:0.6705, R:0.0105)
Batch 150/537: Loss=0.6506 (C:0.6506, R:0.0105)
Batch 175/537: Loss=0.7134 (C:0.7134, R:0.0105)
Batch 200/537: Loss=0.6922 (C:0.6922, R:0.0105)
Batch 225/537: Loss=0.6430 (C:0.6430, R:0.0106)
Batch 250/537: Loss=0.7172 (C:0.7172, R:0.0105)
Batch 275/537: Loss=0.6891 (C:0.6891, R:0.0105)
Batch 300/537: Loss=0.7028 (C:0.7028, R:0.0105)
Batch 325/537: Loss=0.7344 (C:0.7344, R:0.0105)
Batch 350/537: Loss=0.7193 (C:0.7193, R:0.0105)
Batch 375/537: Loss=0.6992 (C:0.6992, R:0.0105)
Batch 400/537: Loss=0.7122 (C:0.7122, R:0.0105)
Batch 425/537: Loss=0.6854 (C:0.6854, R:0.0105)
Batch 450/537: Loss=0.7285 (C:0.7285, R:0.0105)
Batch 475/537: Loss=0.7040 (C:0.7040, R:0.0105)
Batch 500/537: Loss=0.7174 (C:0.7174, R:0.0105)
Batch 525/537: Loss=0.6799 (C:0.6799, R:0.0105)

============================================================
Epoch 101/300 completed in 26.5s
Train: Loss=0.6922 (C:0.6922, R:0.0105) Ratio=5.70x
Val:   Loss=1.0028 (C:1.0028, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.0028)
============================================================

🌍 Updating global dataset at epoch 102
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.395 ± 0.800
    Neg distances: 4.178 ± 1.677
    Separation ratio: 10.59x
    Gap: -7.214
    ✅ Excellent global separation!

Epoch 102 Training
----------------------------------------
Batch   0/537: Loss=0.6846 (C:0.6846, R:0.0105)
Batch  25/537: Loss=0.7250 (C:0.7250, R:0.0105)
Batch  50/537: Loss=0.7862 (C:0.7862, R:0.0105)
Batch  75/537: Loss=0.7048 (C:0.7048, R:0.0105)
Batch 100/537: Loss=0.6420 (C:0.6420, R:0.0105)
Batch 125/537: Loss=0.6881 (C:0.6881, R:0.0106)
Batch 150/537: Loss=0.7246 (C:0.7246, R:0.0105)
Batch 175/537: Loss=0.6960 (C:0.6960, R:0.0105)
Batch 200/537: Loss=0.7642 (C:0.7642, R:0.0105)
Batch 225/537: Loss=0.6902 (C:0.6902, R:0.0105)
Batch 250/537: Loss=0.7111 (C:0.7111, R:0.0105)
Batch 275/537: Loss=0.6686 (C:0.6686, R:0.0105)
Batch 300/537: Loss=0.7250 (C:0.7250, R:0.0105)
Batch 325/537: Loss=0.6767 (C:0.6767, R:0.0105)
Batch 350/537: Loss=0.7292 (C:0.7292, R:0.0105)
Batch 375/537: Loss=0.7589 (C:0.7589, R:0.0106)
Batch 400/537: Loss=0.6540 (C:0.6540, R:0.0105)
Batch 425/537: Loss=0.6747 (C:0.6747, R:0.0105)
Batch 450/537: Loss=0.6995 (C:0.6995, R:0.0105)
Batch 475/537: Loss=0.7190 (C:0.7190, R:0.0105)
Batch 500/537: Loss=0.7449 (C:0.7449, R:0.0105)
Batch 525/537: Loss=0.7036 (C:0.7036, R:0.0105)

============================================================
Epoch 102/300 completed in 26.4s
Train: Loss=0.7044 (C:0.7044, R:0.0105) Ratio=5.69x
Val:   Loss=1.0262 (C:1.0262, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 103
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.391 ± 0.786
    Neg distances: 4.185 ± 1.677
    Separation ratio: 10.70x
    Gap: -7.069
    ✅ Excellent global separation!

Epoch 103 Training
----------------------------------------
Batch   0/537: Loss=0.6618 (C:0.6618, R:0.0105)
Batch  25/537: Loss=0.7023 (C:0.7023, R:0.0105)
Batch  50/537: Loss=0.6824 (C:0.6824, R:0.0105)
Batch  75/537: Loss=0.6883 (C:0.6883, R:0.0106)
Batch 100/537: Loss=0.6684 (C:0.6684, R:0.0105)
Batch 125/537: Loss=0.7512 (C:0.7512, R:0.0105)
Batch 150/537: Loss=0.6715 (C:0.6715, R:0.0105)
Batch 175/537: Loss=0.7079 (C:0.7079, R:0.0105)
Batch 200/537: Loss=0.7138 (C:0.7138, R:0.0105)
Batch 225/537: Loss=0.6939 (C:0.6939, R:0.0105)
Batch 250/537: Loss=0.6936 (C:0.6936, R:0.0105)
Batch 275/537: Loss=0.6978 (C:0.6978, R:0.0105)
Batch 300/537: Loss=0.6473 (C:0.6473, R:0.0105)
Batch 325/537: Loss=0.7306 (C:0.7306, R:0.0105)
Batch 350/537: Loss=0.6958 (C:0.6958, R:0.0105)
Batch 375/537: Loss=0.7139 (C:0.7139, R:0.0105)
Batch 400/537: Loss=0.6694 (C:0.6694, R:0.0105)
Batch 425/537: Loss=0.7655 (C:0.7655, R:0.0105)
Batch 450/537: Loss=0.7483 (C:0.7483, R:0.0105)
Batch 475/537: Loss=0.7477 (C:0.7477, R:0.0105)
Batch 500/537: Loss=0.7161 (C:0.7161, R:0.0106)
Batch 525/537: Loss=0.7179 (C:0.7179, R:0.0105)

============================================================
Epoch 103/300 completed in 26.3s
Train: Loss=0.7020 (C:0.7020, R:0.0105) Ratio=5.68x
Val:   Loss=1.0172 (C:1.0172, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 104
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.373 ± 0.787
    Neg distances: 4.186 ± 1.661
    Separation ratio: 11.22x
    Gap: -6.923
    ✅ Excellent global separation!

Epoch 104 Training
----------------------------------------
Batch   0/537: Loss=0.6307 (C:0.6307, R:0.0105)
Batch  25/537: Loss=0.6858 (C:0.6858, R:0.0105)
Batch  50/537: Loss=0.7499 (C:0.7499, R:0.0105)
Batch  75/537: Loss=0.6752 (C:0.6752, R:0.0105)
Batch 100/537: Loss=0.6283 (C:0.6283, R:0.0105)
Batch 125/537: Loss=0.6294 (C:0.6294, R:0.0106)
Batch 150/537: Loss=0.6553 (C:0.6553, R:0.0105)
Batch 175/537: Loss=0.7232 (C:0.7232, R:0.0106)
Batch 200/537: Loss=0.7107 (C:0.7107, R:0.0105)
Batch 225/537: Loss=0.6827 (C:0.6827, R:0.0106)
Batch 250/537: Loss=0.6745 (C:0.6745, R:0.0105)
Batch 275/537: Loss=0.6984 (C:0.6984, R:0.0105)
Batch 300/537: Loss=0.6794 (C:0.6794, R:0.0105)
Batch 325/537: Loss=0.6756 (C:0.6756, R:0.0105)
Batch 350/537: Loss=0.6827 (C:0.6827, R:0.0105)
Batch 375/537: Loss=0.7022 (C:0.7022, R:0.0105)
Batch 400/537: Loss=0.7069 (C:0.7069, R:0.0105)
Batch 425/537: Loss=0.6724 (C:0.6724, R:0.0105)
Batch 450/537: Loss=0.7179 (C:0.7179, R:0.0105)
Batch 475/537: Loss=0.7186 (C:0.7186, R:0.0105)
Batch 500/537: Loss=0.6872 (C:0.6872, R:0.0105)
Batch 525/537: Loss=0.6622 (C:0.6622, R:0.0105)

============================================================
Epoch 104/300 completed in 26.6s
Train: Loss=0.6851 (C:0.6851, R:0.0105) Ratio=5.70x
Val:   Loss=1.0020 (C:1.0020, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.0020)
============================================================

🌍 Updating global dataset at epoch 105
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.387 ± 0.779
    Neg distances: 4.192 ± 1.672
    Separation ratio: 10.84x
    Gap: -7.006
    ✅ Excellent global separation!

Epoch 105 Training
----------------------------------------
Batch   0/537: Loss=0.6614 (C:0.6614, R:0.0105)
Batch  25/537: Loss=0.6563 (C:0.6563, R:0.0105)
Batch  50/537: Loss=0.7395 (C:0.7395, R:0.0106)
Batch  75/537: Loss=0.7208 (C:0.7208, R:0.0105)
Batch 100/537: Loss=0.6789 (C:0.6789, R:0.0105)
Batch 125/537: Loss=0.7012 (C:0.7012, R:0.0106)
Batch 150/537: Loss=0.7449 (C:0.7449, R:0.0105)
Batch 175/537: Loss=0.6737 (C:0.6737, R:0.0105)
Batch 200/537: Loss=0.6876 (C:0.6876, R:0.0105)
Batch 225/537: Loss=0.7544 (C:0.7544, R:0.0105)
Batch 250/537: Loss=0.7205 (C:0.7205, R:0.0105)
Batch 275/537: Loss=0.6701 (C:0.6701, R:0.0105)
Batch 300/537: Loss=0.6818 (C:0.6818, R:0.0105)
Batch 325/537: Loss=0.6757 (C:0.6757, R:0.0105)
Batch 350/537: Loss=0.7244 (C:0.7244, R:0.0105)
Batch 375/537: Loss=0.6931 (C:0.6931, R:0.0105)
Batch 400/537: Loss=0.6884 (C:0.6884, R:0.0105)
Batch 425/537: Loss=0.6325 (C:0.6325, R:0.0105)
Batch 450/537: Loss=0.7175 (C:0.7175, R:0.0105)
Batch 475/537: Loss=0.6893 (C:0.6893, R:0.0105)
Batch 500/537: Loss=0.7163 (C:0.7163, R:0.0105)
Batch 525/537: Loss=0.7044 (C:0.7044, R:0.0105)

============================================================
Epoch 105/300 completed in 27.1s
Train: Loss=0.6935 (C:0.6935, R:0.0105) Ratio=5.75x
Val:   Loss=1.0123 (C:1.0123, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 106
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.399 ± 0.819
    Neg distances: 4.170 ± 1.675
    Separation ratio: 10.45x
    Gap: -7.030
    ✅ Excellent global separation!

Epoch 106 Training
----------------------------------------
Batch   0/537: Loss=0.7126 (C:0.7126, R:0.0105)
Batch  25/537: Loss=0.6715 (C:0.6715, R:0.0105)
Batch  50/537: Loss=0.7149 (C:0.7149, R:0.0105)
Batch  75/537: Loss=0.6922 (C:0.6922, R:0.0105)
Batch 100/537: Loss=0.7049 (C:0.7049, R:0.0105)
Batch 125/537: Loss=0.6925 (C:0.6925, R:0.0105)
Batch 150/537: Loss=0.7241 (C:0.7241, R:0.0105)
Batch 175/537: Loss=0.7209 (C:0.7209, R:0.0105)
Batch 200/537: Loss=0.7071 (C:0.7071, R:0.0106)
Batch 225/537: Loss=0.7397 (C:0.7397, R:0.0106)
Batch 250/537: Loss=0.6986 (C:0.6986, R:0.0105)
Batch 275/537: Loss=0.7814 (C:0.7814, R:0.0106)
Batch 300/537: Loss=0.6712 (C:0.6712, R:0.0105)
Batch 325/537: Loss=0.7225 (C:0.7225, R:0.0105)
Batch 350/537: Loss=0.7032 (C:0.7032, R:0.0105)
Batch 375/537: Loss=0.7019 (C:0.7019, R:0.0105)
Batch 400/537: Loss=0.7422 (C:0.7422, R:0.0105)
Batch 425/537: Loss=0.7086 (C:0.7086, R:0.0105)
Batch 450/537: Loss=0.6425 (C:0.6425, R:0.0105)
Batch 475/537: Loss=0.7346 (C:0.7346, R:0.0105)
Batch 500/537: Loss=0.7101 (C:0.7101, R:0.0105)
Batch 525/537: Loss=0.7155 (C:0.7155, R:0.0105)

============================================================
Epoch 106/300 completed in 27.1s
Train: Loss=0.7031 (C:0.7031, R:0.0105) Ratio=5.70x
Val:   Loss=1.0413 (C:1.0413, R:0.0104) Ratio=3.03x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 107
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.398 ± 0.808
    Neg distances: 4.161 ± 1.673
    Separation ratio: 10.46x
    Gap: -6.997
    ✅ Excellent global separation!

Epoch 107 Training
----------------------------------------
Batch   0/537: Loss=0.6799 (C:0.6799, R:0.0105)
Batch  25/537: Loss=0.7064 (C:0.7064, R:0.0105)
Batch  50/537: Loss=0.6829 (C:0.6829, R:0.0105)
Batch  75/537: Loss=0.6982 (C:0.6982, R:0.0105)
Batch 100/537: Loss=0.6572 (C:0.6572, R:0.0105)
Batch 125/537: Loss=0.6724 (C:0.6724, R:0.0105)
Batch 150/537: Loss=0.6789 (C:0.6789, R:0.0105)
Batch 175/537: Loss=0.6624 (C:0.6624, R:0.0105)
Batch 200/537: Loss=0.7020 (C:0.7020, R:0.0105)
Batch 225/537: Loss=0.7104 (C:0.7104, R:0.0105)
Batch 250/537: Loss=0.6975 (C:0.6975, R:0.0105)
Batch 275/537: Loss=0.7485 (C:0.7485, R:0.0105)
Batch 300/537: Loss=0.6975 (C:0.6975, R:0.0105)
Batch 325/537: Loss=0.7254 (C:0.7254, R:0.0105)
Batch 350/537: Loss=0.7024 (C:0.7024, R:0.0105)
Batch 375/537: Loss=0.7022 (C:0.7022, R:0.0105)
Batch 400/537: Loss=0.7018 (C:0.7018, R:0.0105)
Batch 425/537: Loss=0.7209 (C:0.7209, R:0.0105)
Batch 450/537: Loss=0.7088 (C:0.7088, R:0.0105)
Batch 475/537: Loss=0.6719 (C:0.6719, R:0.0106)
Batch 500/537: Loss=0.7246 (C:0.7246, R:0.0105)
Batch 525/537: Loss=0.7376 (C:0.7376, R:0.0105)

============================================================
Epoch 107/300 completed in 27.6s
Train: Loss=0.7008 (C:0.7008, R:0.0105) Ratio=5.90x
Val:   Loss=1.0241 (C:1.0241, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 108
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.389 ± 0.796
    Neg distances: 4.195 ± 1.672
    Separation ratio: 10.80x
    Gap: -7.079
    ✅ Excellent global separation!

Epoch 108 Training
----------------------------------------
Batch   0/537: Loss=0.6576 (C:0.6576, R:0.0105)
Batch  25/537: Loss=0.7352 (C:0.7352, R:0.0105)
Batch  50/537: Loss=0.7305 (C:0.7305, R:0.0105)
Batch  75/537: Loss=0.7209 (C:0.7209, R:0.0105)
Batch 100/537: Loss=0.6637 (C:0.6637, R:0.0105)
Batch 125/537: Loss=0.7345 (C:0.7345, R:0.0105)
Batch 150/537: Loss=0.6937 (C:0.6937, R:0.0105)
Batch 175/537: Loss=0.6498 (C:0.6498, R:0.0105)
Batch 200/537: Loss=0.7072 (C:0.7072, R:0.0105)
Batch 225/537: Loss=0.6938 (C:0.6938, R:0.0105)
Batch 250/537: Loss=0.6899 (C:0.6899, R:0.0105)
Batch 275/537: Loss=0.6946 (C:0.6946, R:0.0105)
Batch 300/537: Loss=0.7090 (C:0.7090, R:0.0105)
Batch 325/537: Loss=0.6649 (C:0.6649, R:0.0105)
Batch 350/537: Loss=0.6759 (C:0.6759, R:0.0105)
Batch 375/537: Loss=0.7096 (C:0.7096, R:0.0105)
Batch 400/537: Loss=0.7006 (C:0.7006, R:0.0105)
Batch 425/537: Loss=0.7338 (C:0.7338, R:0.0105)
Batch 450/537: Loss=0.7167 (C:0.7167, R:0.0105)
Batch 475/537: Loss=0.6838 (C:0.6838, R:0.0105)
Batch 500/537: Loss=0.7331 (C:0.7331, R:0.0105)
Batch 525/537: Loss=0.6536 (C:0.6536, R:0.0105)

============================================================
Epoch 108/300 completed in 27.5s
Train: Loss=0.6917 (C:0.6917, R:0.0105) Ratio=5.79x
Val:   Loss=1.0042 (C:1.0042, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 4 epochs
============================================================

🌍 Updating global dataset at epoch 109
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.394 ± 0.809
    Neg distances: 4.191 ± 1.684
    Separation ratio: 10.63x
    Gap: -7.037
    ✅ Excellent global separation!

Epoch 109 Training
----------------------------------------
Batch   0/537: Loss=0.7062 (C:0.7062, R:0.0105)
Batch  25/537: Loss=0.6716 (C:0.6716, R:0.0105)
Batch  50/537: Loss=0.7414 (C:0.7414, R:0.0105)
Batch  75/537: Loss=0.6807 (C:0.6807, R:0.0105)
Batch 100/537: Loss=0.6709 (C:0.6709, R:0.0105)
Batch 125/537: Loss=0.6693 (C:0.6693, R:0.0105)
Batch 150/537: Loss=0.7115 (C:0.7115, R:0.0105)
Batch 175/537: Loss=0.7065 (C:0.7065, R:0.0105)
Batch 200/537: Loss=0.6457 (C:0.6457, R:0.0105)
Batch 225/537: Loss=0.7397 (C:0.7397, R:0.0105)
Batch 250/537: Loss=0.6821 (C:0.6821, R:0.0105)
Batch 275/537: Loss=0.6656 (C:0.6656, R:0.0105)
Batch 300/537: Loss=0.6979 (C:0.6979, R:0.0105)
Batch 325/537: Loss=0.7033 (C:0.7033, R:0.0105)
Batch 350/537: Loss=0.6867 (C:0.6867, R:0.0105)
Batch 375/537: Loss=0.7376 (C:0.7376, R:0.0105)
Batch 400/537: Loss=0.6756 (C:0.6756, R:0.0105)
Batch 425/537: Loss=0.6730 (C:0.6730, R:0.0105)
Batch 450/537: Loss=0.6934 (C:0.6934, R:0.0105)
Batch 475/537: Loss=0.6836 (C:0.6836, R:0.0105)
Batch 500/537: Loss=0.6671 (C:0.6671, R:0.0105)
Batch 525/537: Loss=0.7040 (C:0.7040, R:0.0105)

============================================================
Epoch 109/300 completed in 26.8s
Train: Loss=0.6972 (C:0.6972, R:0.0105) Ratio=5.81x
Val:   Loss=1.0338 (C:1.0338, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.300
No improvement for 5 epochs
============================================================

🌍 Updating global dataset at epoch 110
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.389 ± 0.813
    Neg distances: 4.176 ± 1.674
    Separation ratio: 10.75x
    Gap: -6.979
    ✅ Excellent global separation!

Epoch 110 Training
----------------------------------------
Batch   0/537: Loss=0.6870 (C:0.6870, R:0.0105)
Batch  25/537: Loss=0.6505 (C:0.6505, R:0.0105)
Batch  50/537: Loss=0.6615 (C:0.6615, R:0.0105)
Batch  75/537: Loss=0.6706 (C:0.6706, R:0.0105)
Batch 100/537: Loss=0.6432 (C:0.6432, R:0.0105)
Batch 125/537: Loss=0.7291 (C:0.7291, R:0.0105)
Batch 150/537: Loss=0.6801 (C:0.6801, R:0.0105)
Batch 175/537: Loss=0.7056 (C:0.7056, R:0.0105)
Batch 200/537: Loss=0.6897 (C:0.6897, R:0.0105)
Batch 225/537: Loss=0.7008 (C:0.7008, R:0.0105)
Batch 250/537: Loss=0.6454 (C:0.6454, R:0.0105)
Batch 275/537: Loss=0.7282 (C:0.7282, R:0.0105)
Batch 300/537: Loss=0.7205 (C:0.7205, R:0.0105)
Batch 325/537: Loss=0.6671 (C:0.6671, R:0.0105)
Batch 350/537: Loss=0.6610 (C:0.6610, R:0.0105)
Batch 375/537: Loss=0.6572 (C:0.6572, R:0.0105)
Batch 400/537: Loss=0.6931 (C:0.6931, R:0.0105)
Batch 425/537: Loss=0.6953 (C:0.6953, R:0.0105)
Batch 450/537: Loss=0.7119 (C:0.7119, R:0.0105)
Batch 475/537: Loss=0.6886 (C:0.6886, R:0.0105)
Batch 500/537: Loss=0.6830 (C:0.6830, R:0.0105)
Batch 525/537: Loss=0.6344 (C:0.6344, R:0.0105)

============================================================
Epoch 110/300 completed in 26.7s
Train: Loss=0.6912 (C:0.6912, R:0.0105) Ratio=5.71x
Val:   Loss=1.0245 (C:1.0245, R:0.0104) Ratio=3.03x
Reconstruction weight: 0.300
No improvement for 6 epochs
============================================================

🌍 Updating global dataset at epoch 111
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.392 ± 0.816
    Neg distances: 4.178 ± 1.677
    Separation ratio: 10.65x
    Gap: -7.049
    ✅ Excellent global separation!

Epoch 111 Training
----------------------------------------
Batch   0/537: Loss=0.7143 (C:0.7143, R:0.0105)
Batch  25/537: Loss=0.6859 (C:0.6859, R:0.0105)
Batch  50/537: Loss=0.6565 (C:0.6565, R:0.0105)
Batch  75/537: Loss=0.6691 (C:0.6691, R:0.0105)
Batch 100/537: Loss=0.7240 (C:0.7240, R:0.0105)
Batch 125/537: Loss=0.6869 (C:0.6869, R:0.0105)
Batch 150/537: Loss=0.6619 (C:0.6619, R:0.0105)
Batch 175/537: Loss=0.6928 (C:0.6928, R:0.0105)
Batch 200/537: Loss=0.6171 (C:0.6171, R:0.0105)
Batch 225/537: Loss=0.7551 (C:0.7551, R:0.0105)
Batch 250/537: Loss=0.6721 (C:0.6721, R:0.0105)
Batch 275/537: Loss=0.6253 (C:0.6253, R:0.0105)
Batch 300/537: Loss=0.6507 (C:0.6507, R:0.0105)
Batch 325/537: Loss=0.6744 (C:0.6744, R:0.0105)
Batch 350/537: Loss=0.7419 (C:0.7419, R:0.0105)
Batch 375/537: Loss=0.6679 (C:0.6679, R:0.0105)
Batch 400/537: Loss=0.6685 (C:0.6685, R:0.0105)
Batch 425/537: Loss=0.6989 (C:0.6989, R:0.0105)
Batch 450/537: Loss=0.7681 (C:0.7681, R:0.0105)
Batch 475/537: Loss=0.7000 (C:0.7000, R:0.0105)
Batch 500/537: Loss=0.7593 (C:0.7593, R:0.0105)
Batch 525/537: Loss=0.7272 (C:0.7272, R:0.0105)

============================================================
Epoch 111/300 completed in 26.8s
Train: Loss=0.6932 (C:0.6932, R:0.0105) Ratio=5.83x
Val:   Loss=1.0089 (C:1.0089, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.300
No improvement for 7 epochs
============================================================

🌍 Updating global dataset at epoch 112
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.390 ± 0.812
    Neg distances: 4.207 ± 1.687
    Separation ratio: 10.79x
    Gap: -7.052
    ✅ Excellent global separation!

Epoch 112 Training
----------------------------------------
Batch   0/537: Loss=0.7107 (C:0.7107, R:0.0105)
Batch  25/537: Loss=0.6592 (C:0.6592, R:0.0105)
Batch  50/537: Loss=0.6465 (C:0.6465, R:0.0105)
Batch  75/537: Loss=0.6680 (C:0.6680, R:0.0105)
Batch 100/537: Loss=0.7430 (C:0.7430, R:0.0105)
Batch 125/537: Loss=0.6512 (C:0.6512, R:0.0105)
Batch 150/537: Loss=0.6565 (C:0.6565, R:0.0105)
Batch 175/537: Loss=0.7189 (C:0.7189, R:0.0105)
Batch 200/537: Loss=0.7164 (C:0.7164, R:0.0105)
Batch 225/537: Loss=0.6147 (C:0.6147, R:0.0106)
Batch 250/537: Loss=0.6926 (C:0.6926, R:0.0105)
Batch 275/537: Loss=0.7187 (C:0.7187, R:0.0105)
Batch 300/537: Loss=0.6645 (C:0.6645, R:0.0105)
Batch 325/537: Loss=0.6867 (C:0.6867, R:0.0105)
Batch 350/537: Loss=0.6848 (C:0.6848, R:0.0105)
Batch 375/537: Loss=0.7236 (C:0.7236, R:0.0105)
Batch 400/537: Loss=0.7193 (C:0.7193, R:0.0105)
Batch 425/537: Loss=0.6963 (C:0.6963, R:0.0105)
Batch 450/537: Loss=0.6983 (C:0.6983, R:0.0105)
Batch 475/537: Loss=0.6726 (C:0.6726, R:0.0105)
Batch 500/537: Loss=0.7047 (C:0.7047, R:0.0105)
Batch 525/537: Loss=0.6817 (C:0.6817, R:0.0105)

============================================================
Epoch 112/300 completed in 27.4s
Train: Loss=0.6921 (C:0.6921, R:0.0105) Ratio=5.91x
Val:   Loss=1.0068 (C:1.0068, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
No improvement for 8 epochs

Early stopping triggered after 112 epochs
Best model was at epoch 104 with Val Loss: 1.0020

Global Dataset Training Completed!
Best epoch: 104
Best validation loss: 1.0020
Final separation ratios: Train=5.91x, Val=3.08x
Training completed!
Loading best model from entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin3.0_updatefreq1_max_global_samples10000_20250715_154951/checkpoints/best_model.pt
Starting model evaluation...
========================================
GlobalContrastiveEvaluator initialized on cuda
Starting comprehensive evaluation...
============================================================
Extracting latent representations...
  Processed 1/10 batches
Extracted representations: torch.Size([9824, 75])
Evaluating clustering performance...
Clustering Results:
  Silhouette Score: 0.4550
  Adjusted Rand Score: 0.5244
  Clustering Accuracy: 0.8119
Evaluating classification performance...
  Extracting training representations...
Extracting latent representations...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
Extracted representations: torch.Size([547740, 75])
  Extracting validation representations...
Extracting latent representations...
  Processed 1/9 batches
Extracted representations: torch.Size([9180, 75])
Subsampled training to 50000 samples
  Training on 50000 samples, evaluating on 9180 samples
Classification Results:
  Accuracy: 0.8134
  Per-class F1: [0.8343808391370817, 0.7543586550435866, 0.8556786245660439]
Evaluating reconstruction quality...
Reconstruction Results:
  Average MSE: 0.010432
Evaluating separation quality...
Separation Results:
  Positive distances: 1.202 ± 1.400
  Negative distances: 3.601 ± 1.922
  Separation ratio: 3.00x
  Gap: -7.290
  Perfect separation: No

Comprehensive evaluation completed!

============================================================
EVALUATION SUMMARY
============================================================
Clustering Performance:
  Silhouette Score: 0.4550
  Clustering Accuracy: 0.8119
  Adjusted Rand Score: 0.5244

Classification Performance:
  Accuracy: 0.8134

Separation Quality:
  Separation Ratio: 3.00x
  Gap: -7.290
  Perfect Separation: False

Reconstruction Quality:
  Average MSE: 0.010432
============================================================
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin3.0_updatefreq1_max_global_samples10000_20250715_154951/results/evaluation_results_20250715_164108.json
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin3.0_updatefreq1_max_global_samples10000_20250715_154951/results/evaluation_results_20250715_164108.json
Saving final experiment results...
Final results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin3.0_updatefreq1_max_global_samples10000_20250715_154951/final_results.json

============================================================
PIPELINE COMPLETED SUCCESSFULLY!
============================================================
Experiment directory: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin3.0_updatefreq1_max_global_samples10000_20250715_154951
Best model: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin3.0_updatefreq1_max_global_samples10000_20250715_154951/checkpoints/best_model.pt
Final results: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin3.0_updatefreq1_max_global_samples10000_20250715_154951/final_results.json

Key Results:
  Separation ratio: 3.00x
  Perfect separation: False
  Classification accuracy: 0.8134
  Result: 0.8134% (improvement: +-80.86%)
  Cleaning up: coarse_margin3.0_updatefreq1_max_global_samples10000_20250715_154951

[11/12] Testing: coarse_margin3.0_updatefreq3_max_global_samples5000
  margin: 3.0
  update_frequency: 3
  max_global_samples: 5000
  Reconstruction weight: 0.3 (fixed)
GLOBAL DATASET CONTRASTIVE AUTOENCODER PIPELINE
============================================================
Start time: 2025-07-15 16:41:08.922462
Using device: cuda

Configuration:
  Embedding type: concat
  Batch size: 1020
  Global update frequency: 3 epochs
  Training epochs: 300
Experiment setup completed:
  Experiment directory: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin3.0_updatefreq3_max_global_samples5000_20250715_164108
  Config saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin3.0_updatefreq3_max_global_samples5000_20250715_164108/config.json
Loading data...
========================================
FlexibleEmbedder initialized with type: 'concat'
Output dimension will be: 1536
GlobalDataLoader initialized:
  Embedding type: concat
  Output dimension: 1536
  Sample size: All
Starting data loading pipeline...
============================================================
Loading training data from data/processed/snli_full_standard_SBERT.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 549367 training samples
Loading validation data from data/processed/snli_full_standard_SBERT_validation.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9842 validation samples
Loading test data from data/processed/snli_full_standard_SBERT_test.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9824 test samples
Generating embeddings for training...
Generating concat embeddings on cuda
Processing 549367 samples in batches of 1000
  Processing batch 1/550
  Processing batch 6/550
  Processing batch 11/550
  Processing batch 16/550
  Processing batch 21/550
  Processing batch 26/550
  Processing batch 31/550
  Processing batch 36/550
  Processing batch 41/550
  Processing batch 46/550
  Processing batch 51/550
  Processing batch 56/550
  Processing batch 61/550
  Processing batch 66/550
  Processing batch 71/550
  Processing batch 76/550
  Processing batch 81/550
  Processing batch 86/550
  Processing batch 91/550
  Processing batch 96/550
  Processing batch 101/550
  Processing batch 106/550
  Processing batch 111/550
  Processing batch 116/550
  Processing batch 121/550
  Processing batch 126/550
  Processing batch 131/550
  Processing batch 136/550
  Processing batch 141/550
  Processing batch 146/550
  Processing batch 151/550
  Processing batch 156/550
  Processing batch 161/550
  Processing batch 166/550
  Processing batch 171/550
  Processing batch 176/550
  Processing batch 181/550
  Processing batch 186/550
  Processing batch 191/550
  Processing batch 196/550
  Processing batch 201/550
  Processing batch 206/550
  Processing batch 211/550
  Processing batch 216/550
  Processing batch 221/550
  Processing batch 226/550
  Processing batch 231/550
  Processing batch 236/550
  Processing batch 241/550
  Processing batch 246/550
  Processing batch 251/550
  Processing batch 256/550
  Processing batch 261/550
  Processing batch 266/550
  Processing batch 271/550
  Processing batch 276/550
  Processing batch 281/550
  Processing batch 286/550
  Processing batch 291/550
  Processing batch 296/550
  Processing batch 301/550
  Processing batch 306/550
  Processing batch 311/550
  Processing batch 316/550
  Processing batch 321/550
  Processing batch 326/550
  Processing batch 331/550
  Processing batch 336/550
  Processing batch 341/550
  Processing batch 346/550
  Processing batch 351/550
  Processing batch 356/550
  Processing batch 361/550
  Processing batch 366/550
  Processing batch 371/550
  Processing batch 376/550
  Processing batch 381/550
  Processing batch 386/550
  Processing batch 391/550
  Processing batch 396/550
  Processing batch 401/550
  Processing batch 406/550
  Processing batch 411/550
  Processing batch 416/550
  Processing batch 421/550
  Processing batch 426/550
  Processing batch 431/550
  Processing batch 436/550
  Processing batch 441/550
  Processing batch 446/550
  Processing batch 451/550
  Processing batch 456/550
  Processing batch 461/550
  Processing batch 466/550
  Processing batch 471/550
  Processing batch 476/550
  Processing batch 481/550
  Processing batch 486/550
  Processing batch 491/550
  Processing batch 496/550
  Processing batch 501/550
  Processing batch 506/550
  Processing batch 511/550
  Processing batch 516/550
  Processing batch 521/550
  Processing batch 526/550
  Processing batch 531/550
  Processing batch 536/550
  Processing batch 541/550
  Processing batch 546/550
Generated concat embeddings: torch.Size([549367, 1536])
Generating embeddings for validation...
Generating concat embeddings on cuda
Processing 9842 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9842, 1536])
Generating embeddings for test...
Generating concat embeddings on cuda
Processing 9824 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9824, 1536])
EntailmentDataset created: 549367 samples
  Embedding shape: torch.Size([549367, 1536])
  Class distribution: {'entailment': 183416, 'neutral': 182764, 'contradiction': 183187}
EntailmentDataset created: 9842 samples
  Embedding shape: torch.Size([9842, 1536])
  Class distribution: {'entailment': 3329, 'neutral': 3235, 'contradiction': 3278}
EntailmentDataset created: 9824 samples
  Embedding shape: torch.Size([9824, 1536])
  Class distribution: {'entailment': 3368, 'neutral': 3219, 'contradiction': 3237}

Data loading pipeline completed!
Output embedding dimension: 1536
Updated model input_dim to: 1536
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 537
  Class 2: 183187 samples
  Class 0: 183416 samples
  Class 1: 182764 samples
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 9
  Class 2: 3278 samples
  Class 0: 3329 samples
  Class 1: 3235 samples
DataLoaders created:
  Batch size: 1020
  Balanced sampling: True
  Train batches: 537
  Val batches: 9
  Test batches: 10
Data loading completed!
  Train: 549367 samples, 537 batches
  Val: 9842 samples, 9 batches
  Test: 9824 samples, 10 batches
Creating model and trainer...
========================================
ContrastiveAutoencoder initialized:
  Input dim: 1536
  Latent dim: 75
  Hidden dims: [512, 256]
  Dropout rate: 0.2
  Total parameters: 1,876,555
Model created with 1,876,555 parameters
FullDatasetContrastiveLoss initialized:
  Margin: 3.0
  Update frequency: 3 epochs
  Max global samples: 5000
FullDatasetCombinedLoss initialized:
  Contrastive weight: 1.0
  Base reconstruction weight: 0.0
  Scheduled reconstruction: warmup=30 epochs, max_weight=0.3
Optimizer created (lr=0.0001)
GlobalDatasetTrainer initialized on device: cuda
Model parameters: 1,876,555
Starting training...
========================================
Starting Global Dataset Training...
============================================================

🌍 Updating global dataset at epoch 1
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.092 ± 0.011
    Neg distances: 0.092 ± 0.010
    Separation ratio: 1.00x
    Gap: -0.134
    ❌ Poor global separation

Epoch 1 Training
----------------------------------------
Batch   0/537: Loss=2.9998 (C:2.9998, R:0.0117)
Batch  25/537: Loss=2.9956 (C:2.9956, R:0.0114)
Batch  50/537: Loss=2.9800 (C:2.9800, R:0.0113)
Batch  75/537: Loss=2.9626 (C:2.9626, R:0.0112)
Batch 100/537: Loss=2.9569 (C:2.9569, R:0.0110)
Batch 125/537: Loss=2.9409 (C:2.9409, R:0.0109)
Batch 150/537: Loss=2.9292 (C:2.9292, R:0.0108)
Batch 175/537: Loss=2.9303 (C:2.9303, R:0.0108)
Batch 200/537: Loss=2.8963 (C:2.8963, R:0.0107)
Batch 225/537: Loss=2.8947 (C:2.8947, R:0.0106)
Batch 250/537: Loss=2.8925 (C:2.8925, R:0.0106)
Batch 275/537: Loss=2.8948 (C:2.8948, R:0.0106)
Batch 300/537: Loss=2.8893 (C:2.8893, R:0.0106)
Batch 325/537: Loss=2.8581 (C:2.8581, R:0.0105)
Batch 350/537: Loss=2.8504 (C:2.8504, R:0.0106)
Batch 375/537: Loss=2.8761 (C:2.8761, R:0.0106)
Batch 400/537: Loss=2.8641 (C:2.8641, R:0.0106)
Batch 425/537: Loss=2.8670 (C:2.8670, R:0.0105)
Batch 450/537: Loss=2.8610 (C:2.8610, R:0.0105)
Batch 475/537: Loss=2.8752 (C:2.8752, R:0.0105)
Batch 500/537: Loss=2.8691 (C:2.8691, R:0.0105)
Batch 525/537: Loss=2.8511 (C:2.8511, R:0.0105)

============================================================
Epoch 1/300 completed in 26.7s
Train: Loss=2.9039 (C:2.9039, R:0.0108) Ratio=1.61x
Val:   Loss=2.8488 (C:2.8488, R:0.0104) Ratio=2.16x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 2.8488)
============================================================

Epoch 2 Training
----------------------------------------
Batch   0/537: Loss=2.8455 (C:2.8455, R:0.0105)
Batch  25/537: Loss=2.8374 (C:2.8374, R:0.0105)
Batch  50/537: Loss=2.8432 (C:2.8432, R:0.0106)
Batch  75/537: Loss=2.8560 (C:2.8560, R:0.0105)
Batch 100/537: Loss=2.8504 (C:2.8504, R:0.0105)
Batch 125/537: Loss=2.8459 (C:2.8459, R:0.0105)
Batch 150/537: Loss=2.8453 (C:2.8453, R:0.0105)
Batch 175/537: Loss=2.8266 (C:2.8266, R:0.0105)
Batch 200/537: Loss=2.8376 (C:2.8376, R:0.0106)
Batch 225/537: Loss=2.8578 (C:2.8578, R:0.0106)
Batch 250/537: Loss=2.8228 (C:2.8228, R:0.0105)
Batch 275/537: Loss=2.8422 (C:2.8422, R:0.0105)
Batch 300/537: Loss=2.8432 (C:2.8432, R:0.0105)
Batch 325/537: Loss=2.8301 (C:2.8301, R:0.0105)
Batch 350/537: Loss=2.8429 (C:2.8429, R:0.0105)
Batch 375/537: Loss=2.8233 (C:2.8233, R:0.0106)
Batch 400/537: Loss=2.8287 (C:2.8287, R:0.0105)
Batch 425/537: Loss=2.8306 (C:2.8306, R:0.0105)
Batch 450/537: Loss=2.8232 (C:2.8232, R:0.0105)
Batch 475/537: Loss=2.8389 (C:2.8389, R:0.0105)
Batch 500/537: Loss=2.8443 (C:2.8443, R:0.0105)
Batch 525/537: Loss=2.8187 (C:2.8187, R:0.0105)

============================================================
Epoch 2/300 completed in 20.8s
Train: Loss=2.8398 (C:2.8398, R:0.0105) Ratio=2.23x
Val:   Loss=2.8208 (C:2.8208, R:0.0104) Ratio=2.42x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 2.8208)
============================================================

Epoch 3 Training
----------------------------------------
Batch   0/537: Loss=2.8096 (C:2.8096, R:0.0105)
Batch  25/537: Loss=2.8222 (C:2.8222, R:0.0105)
Batch  50/537: Loss=2.8230 (C:2.8230, R:0.0105)
Batch  75/537: Loss=2.8185 (C:2.8185, R:0.0105)
Batch 100/537: Loss=2.8431 (C:2.8431, R:0.0105)
Batch 125/537: Loss=2.8225 (C:2.8225, R:0.0105)
Batch 150/537: Loss=2.8205 (C:2.8205, R:0.0105)
Batch 175/537: Loss=2.8298 (C:2.8298, R:0.0105)
Batch 200/537: Loss=2.8321 (C:2.8321, R:0.0105)
Batch 225/537: Loss=2.8294 (C:2.8294, R:0.0105)
Batch 250/537: Loss=2.8170 (C:2.8170, R:0.0105)
Batch 275/537: Loss=2.8526 (C:2.8526, R:0.0105)
Batch 300/537: Loss=2.8328 (C:2.8328, R:0.0105)
Batch 325/537: Loss=2.8040 (C:2.8040, R:0.0106)
Batch 350/537: Loss=2.8140 (C:2.8140, R:0.0105)
Batch 375/537: Loss=2.8282 (C:2.8282, R:0.0105)
Batch 400/537: Loss=2.8184 (C:2.8184, R:0.0105)
Batch 425/537: Loss=2.7980 (C:2.7980, R:0.0105)
Batch 450/537: Loss=2.8458 (C:2.8458, R:0.0105)
Batch 475/537: Loss=2.8317 (C:2.8317, R:0.0105)
Batch 500/537: Loss=2.8077 (C:2.8077, R:0.0106)
Batch 525/537: Loss=2.8172 (C:2.8172, R:0.0105)

============================================================
Epoch 3/300 completed in 21.3s
Train: Loss=2.8236 (C:2.8236, R:0.0105) Ratio=2.39x
Val:   Loss=2.8176 (C:2.8176, R:0.0104) Ratio=2.49x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 2.8176)
============================================================

🌍 Updating global dataset at epoch 4
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.772 ± 0.831
    Neg distances: 2.048 ± 1.201
    Separation ratio: 2.65x
    Gap: -4.257
    ✅ Good global separation

Epoch 4 Training
----------------------------------------
Batch   0/537: Loss=1.8862 (C:1.8862, R:0.0105)
Batch  25/537: Loss=1.8782 (C:1.8782, R:0.0105)
Batch  50/537: Loss=1.9303 (C:1.9303, R:0.0105)
Batch  75/537: Loss=1.9482 (C:1.9482, R:0.0105)
Batch 100/537: Loss=1.9014 (C:1.9014, R:0.0105)
Batch 125/537: Loss=1.8921 (C:1.8921, R:0.0105)
Batch 150/537: Loss=1.8679 (C:1.8679, R:0.0105)
Batch 175/537: Loss=1.9025 (C:1.9025, R:0.0105)
Batch 200/537: Loss=1.8536 (C:1.8536, R:0.0105)
Batch 225/537: Loss=1.8749 (C:1.8749, R:0.0105)
Batch 250/537: Loss=1.8903 (C:1.8903, R:0.0105)
Batch 275/537: Loss=1.8912 (C:1.8912, R:0.0105)
Batch 300/537: Loss=1.8229 (C:1.8229, R:0.0105)
Batch 325/537: Loss=1.8382 (C:1.8382, R:0.0105)
Batch 350/537: Loss=1.8834 (C:1.8834, R:0.0105)
Batch 375/537: Loss=1.8566 (C:1.8566, R:0.0105)
Batch 400/537: Loss=1.9129 (C:1.9129, R:0.0105)
Batch 425/537: Loss=1.9039 (C:1.9039, R:0.0105)
Batch 450/537: Loss=1.8287 (C:1.8287, R:0.0105)
Batch 475/537: Loss=1.8247 (C:1.8247, R:0.0105)
Batch 500/537: Loss=1.8584 (C:1.8584, R:0.0105)
Batch 525/537: Loss=1.8308 (C:1.8308, R:0.0105)

============================================================
Epoch 4/300 completed in 26.8s
Train: Loss=1.8743 (C:1.8743, R:0.0105) Ratio=2.49x
Val:   Loss=1.8707 (C:1.8707, R:0.0104) Ratio=2.57x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.8707)
============================================================

Epoch 5 Training
----------------------------------------
Batch   0/537: Loss=1.8291 (C:1.8291, R:0.0105)
Batch  25/537: Loss=1.8400 (C:1.8400, R:0.0105)
Batch  50/537: Loss=1.8233 (C:1.8233, R:0.0106)
Batch  75/537: Loss=1.8694 (C:1.8694, R:0.0105)
Batch 100/537: Loss=1.8883 (C:1.8883, R:0.0105)
Batch 125/537: Loss=1.8100 (C:1.8100, R:0.0106)
Batch 150/537: Loss=1.8714 (C:1.8714, R:0.0105)
Batch 175/537: Loss=1.8195 (C:1.8195, R:0.0105)
Batch 200/537: Loss=1.8537 (C:1.8537, R:0.0105)
Batch 225/537: Loss=1.8525 (C:1.8525, R:0.0105)
Batch 250/537: Loss=1.8119 (C:1.8119, R:0.0105)
Batch 275/537: Loss=1.8257 (C:1.8257, R:0.0105)
Batch 300/537: Loss=1.7980 (C:1.7980, R:0.0105)
Batch 325/537: Loss=1.8184 (C:1.8184, R:0.0105)
Batch 350/537: Loss=1.8571 (C:1.8571, R:0.0105)
Batch 375/537: Loss=1.8747 (C:1.8747, R:0.0105)
Batch 400/537: Loss=1.8357 (C:1.8357, R:0.0105)
Batch 425/537: Loss=1.8522 (C:1.8522, R:0.0105)
Batch 450/537: Loss=1.8536 (C:1.8536, R:0.0105)
Batch 475/537: Loss=1.8816 (C:1.8816, R:0.0105)
Batch 500/537: Loss=1.8446 (C:1.8446, R:0.0105)
Batch 525/537: Loss=1.8761 (C:1.8761, R:0.0105)

============================================================
Epoch 5/300 completed in 21.0s
Train: Loss=1.8457 (C:1.8457, R:0.0105) Ratio=2.68x
Val:   Loss=1.8612 (C:1.8612, R:0.0104) Ratio=2.62x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.8612)
============================================================

Epoch 6 Training
----------------------------------------
Batch   0/537: Loss=1.7596 (C:1.7596, R:0.0105)
Batch  25/537: Loss=1.8273 (C:1.8273, R:0.0105)
Batch  50/537: Loss=1.8174 (C:1.8174, R:0.0105)
Batch  75/537: Loss=1.8097 (C:1.8097, R:0.0105)
Batch 100/537: Loss=1.8016 (C:1.8016, R:0.0105)
Batch 125/537: Loss=1.8589 (C:1.8589, R:0.0105)
Batch 150/537: Loss=1.7792 (C:1.7792, R:0.0105)
Batch 175/537: Loss=1.8175 (C:1.8175, R:0.0105)
Batch 200/537: Loss=1.8333 (C:1.8333, R:0.0105)
Batch 225/537: Loss=1.7731 (C:1.7731, R:0.0106)
Batch 250/537: Loss=1.8464 (C:1.8464, R:0.0105)
Batch 275/537: Loss=1.8108 (C:1.8108, R:0.0105)
Batch 300/537: Loss=1.8359 (C:1.8359, R:0.0105)
Batch 325/537: Loss=1.8762 (C:1.8762, R:0.0105)
Batch 350/537: Loss=1.7973 (C:1.7973, R:0.0105)
Batch 375/537: Loss=1.8121 (C:1.8121, R:0.0105)
Batch 400/537: Loss=1.8234 (C:1.8234, R:0.0105)
Batch 425/537: Loss=1.8040 (C:1.8040, R:0.0105)
Batch 450/537: Loss=1.7980 (C:1.7980, R:0.0105)
Batch 475/537: Loss=1.7914 (C:1.7914, R:0.0105)
Batch 500/537: Loss=1.8736 (C:1.8736, R:0.0105)
Batch 525/537: Loss=1.7864 (C:1.7864, R:0.0105)

============================================================
Epoch 6/300 completed in 21.3s
Train: Loss=1.8274 (C:1.8274, R:0.0105) Ratio=2.83x
Val:   Loss=1.8443 (C:1.8443, R:0.0104) Ratio=2.72x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.8443)
============================================================

🌍 Updating global dataset at epoch 7
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.688 ± 0.808
    Neg distances: 2.231 ± 1.240
    Separation ratio: 3.24x
    Gap: -4.567
    ✅ Excellent global separation!

Epoch 7 Training
----------------------------------------
Batch   0/537: Loss=1.6935 (C:1.6935, R:0.0105)
Batch  25/537: Loss=1.6624 (C:1.6624, R:0.0105)
Batch  50/537: Loss=1.6634 (C:1.6634, R:0.0105)
Batch  75/537: Loss=1.7182 (C:1.7182, R:0.0105)
Batch 100/537: Loss=1.7308 (C:1.7308, R:0.0105)
Batch 125/537: Loss=1.6665 (C:1.6665, R:0.0105)
Batch 150/537: Loss=1.6859 (C:1.6859, R:0.0105)
Batch 175/537: Loss=1.6728 (C:1.6728, R:0.0105)
Batch 200/537: Loss=1.6976 (C:1.6976, R:0.0105)
Batch 225/537: Loss=1.7008 (C:1.7008, R:0.0105)
Batch 250/537: Loss=1.7165 (C:1.7165, R:0.0105)
Batch 275/537: Loss=1.6792 (C:1.6792, R:0.0105)
Batch 300/537: Loss=1.6808 (C:1.6808, R:0.0105)
Batch 325/537: Loss=1.7036 (C:1.7036, R:0.0105)
Batch 350/537: Loss=1.7147 (C:1.7147, R:0.0105)
Batch 375/537: Loss=1.6760 (C:1.6760, R:0.0105)
Batch 400/537: Loss=1.7198 (C:1.7198, R:0.0105)
Batch 425/537: Loss=1.7124 (C:1.7124, R:0.0105)
Batch 450/537: Loss=1.6931 (C:1.6931, R:0.0105)
Batch 475/537: Loss=1.6930 (C:1.6930, R:0.0105)
Batch 500/537: Loss=1.7187 (C:1.7187, R:0.0105)
Batch 525/537: Loss=1.7296 (C:1.7296, R:0.0105)

============================================================
Epoch 7/300 completed in 26.9s
Train: Loss=1.6909 (C:1.6909, R:0.0105) Ratio=2.83x
Val:   Loss=1.7118 (C:1.7118, R:0.0104) Ratio=2.74x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.7118)
============================================================

Epoch 8 Training
----------------------------------------
Batch   0/537: Loss=1.6717 (C:1.6717, R:0.0105)
Batch  25/537: Loss=1.6681 (C:1.6681, R:0.0105)
Batch  50/537: Loss=1.6502 (C:1.6502, R:0.0105)
Batch  75/537: Loss=1.6891 (C:1.6891, R:0.0105)
Batch 100/537: Loss=1.6458 (C:1.6458, R:0.0105)
Batch 125/537: Loss=1.6584 (C:1.6584, R:0.0105)
Batch 150/537: Loss=1.6636 (C:1.6636, R:0.0105)
Batch 175/537: Loss=1.6621 (C:1.6621, R:0.0105)
Batch 200/537: Loss=1.6699 (C:1.6699, R:0.0105)
Batch 225/537: Loss=1.6589 (C:1.6589, R:0.0105)
Batch 250/537: Loss=1.6611 (C:1.6611, R:0.0105)
Batch 275/537: Loss=1.6269 (C:1.6269, R:0.0105)
Batch 300/537: Loss=1.6863 (C:1.6863, R:0.0105)
Batch 325/537: Loss=1.6692 (C:1.6692, R:0.0105)
Batch 350/537: Loss=1.6614 (C:1.6614, R:0.0105)
Batch 375/537: Loss=1.6615 (C:1.6615, R:0.0106)
Batch 400/537: Loss=1.7335 (C:1.7335, R:0.0105)
Batch 425/537: Loss=1.7097 (C:1.7097, R:0.0105)
Batch 450/537: Loss=1.7541 (C:1.7541, R:0.0105)
Batch 475/537: Loss=1.6574 (C:1.6574, R:0.0105)
Batch 500/537: Loss=1.6794 (C:1.6794, R:0.0105)
Batch 525/537: Loss=1.6923 (C:1.6923, R:0.0105)

============================================================
Epoch 8/300 completed in 21.0s
Train: Loss=1.6757 (C:1.6757, R:0.0105) Ratio=3.06x
Val:   Loss=1.7003 (C:1.7003, R:0.0104) Ratio=2.82x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.7003)
============================================================

Epoch 9 Training
----------------------------------------
Batch   0/537: Loss=1.6518 (C:1.6518, R:0.0105)
Batch  25/537: Loss=1.6265 (C:1.6265, R:0.0105)
Batch  50/537: Loss=1.6359 (C:1.6359, R:0.0105)
Batch  75/537: Loss=1.6476 (C:1.6476, R:0.0105)
Batch 100/537: Loss=1.6476 (C:1.6476, R:0.0105)
Batch 125/537: Loss=1.6663 (C:1.6663, R:0.0105)
Batch 150/537: Loss=1.6913 (C:1.6913, R:0.0105)
Batch 175/537: Loss=1.6902 (C:1.6902, R:0.0106)
Batch 200/537: Loss=1.6844 (C:1.6844, R:0.0105)
Batch 225/537: Loss=1.6635 (C:1.6635, R:0.0105)
Batch 250/537: Loss=1.6930 (C:1.6930, R:0.0105)
Batch 275/537: Loss=1.6848 (C:1.6848, R:0.0105)
Batch 300/537: Loss=1.6741 (C:1.6741, R:0.0105)
Batch 325/537: Loss=1.7592 (C:1.7592, R:0.0105)
Batch 350/537: Loss=1.6424 (C:1.6424, R:0.0105)
Batch 375/537: Loss=1.6969 (C:1.6969, R:0.0105)
Batch 400/537: Loss=1.7299 (C:1.7299, R:0.0105)
Batch 425/537: Loss=1.7119 (C:1.7119, R:0.0105)
Batch 450/537: Loss=1.6318 (C:1.6318, R:0.0105)
Batch 475/537: Loss=1.6557 (C:1.6557, R:0.0105)
Batch 500/537: Loss=1.6697 (C:1.6697, R:0.0105)
Batch 525/537: Loss=1.6622 (C:1.6622, R:0.0106)

============================================================
Epoch 9/300 completed in 21.3s
Train: Loss=1.6647 (C:1.6647, R:0.0105) Ratio=3.11x
Val:   Loss=1.7065 (C:1.7065, R:0.0104) Ratio=2.82x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 10
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.618 ± 0.796
    Neg distances: 2.355 ± 1.261
    Separation ratio: 3.81x
    Gap: -4.609
    ✅ Excellent global separation!

Epoch 10 Training
----------------------------------------
Batch   0/537: Loss=1.5749 (C:1.5749, R:0.0105)
Batch  25/537: Loss=1.5652 (C:1.5652, R:0.0105)
Batch  50/537: Loss=1.5409 (C:1.5409, R:0.0105)
Batch  75/537: Loss=1.5612 (C:1.5612, R:0.0105)
Batch 100/537: Loss=1.5116 (C:1.5116, R:0.0105)
Batch 125/537: Loss=1.6023 (C:1.6023, R:0.0105)
Batch 150/537: Loss=1.5721 (C:1.5721, R:0.0105)
Batch 175/537: Loss=1.5048 (C:1.5048, R:0.0105)
Batch 200/537: Loss=1.5909 (C:1.5909, R:0.0105)
Batch 225/537: Loss=1.5751 (C:1.5751, R:0.0105)
Batch 250/537: Loss=1.5510 (C:1.5510, R:0.0105)
Batch 275/537: Loss=1.5872 (C:1.5872, R:0.0105)
Batch 300/537: Loss=1.5406 (C:1.5406, R:0.0105)
Batch 325/537: Loss=1.5511 (C:1.5511, R:0.0105)
Batch 350/537: Loss=1.5902 (C:1.5902, R:0.0105)
Batch 375/537: Loss=1.5881 (C:1.5881, R:0.0105)
Batch 400/537: Loss=1.5811 (C:1.5811, R:0.0105)
Batch 425/537: Loss=1.6115 (C:1.6115, R:0.0105)
Batch 450/537: Loss=1.5342 (C:1.5342, R:0.0105)
Batch 475/537: Loss=1.6388 (C:1.6388, R:0.0105)
Batch 500/537: Loss=1.5365 (C:1.5365, R:0.0106)
Batch 525/537: Loss=1.5431 (C:1.5431, R:0.0105)

============================================================
Epoch 10/300 completed in 27.2s
Train: Loss=1.5717 (C:1.5717, R:0.0105) Ratio=3.25x
Val:   Loss=1.6142 (C:1.6142, R:0.0104) Ratio=2.83x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.6142)
============================================================

Epoch 11 Training
----------------------------------------
Batch   0/537: Loss=1.5641 (C:1.5641, R:0.0105)
Batch  25/537: Loss=1.5266 (C:1.5266, R:0.0105)
Batch  50/537: Loss=1.5582 (C:1.5582, R:0.0105)
Batch  75/537: Loss=1.5241 (C:1.5241, R:0.0105)
Batch 100/537: Loss=1.5590 (C:1.5590, R:0.0105)
Batch 125/537: Loss=1.5874 (C:1.5874, R:0.0105)
Batch 150/537: Loss=1.5399 (C:1.5399, R:0.0105)
Batch 175/537: Loss=1.5422 (C:1.5422, R:0.0105)
Batch 200/537: Loss=1.5873 (C:1.5873, R:0.0105)
Batch 225/537: Loss=1.5335 (C:1.5335, R:0.0105)
Batch 250/537: Loss=1.5775 (C:1.5775, R:0.0105)
Batch 275/537: Loss=1.5550 (C:1.5550, R:0.0105)
Batch 300/537: Loss=1.5765 (C:1.5765, R:0.0105)
Batch 325/537: Loss=1.5826 (C:1.5826, R:0.0105)
Batch 350/537: Loss=1.5463 (C:1.5463, R:0.0105)
Batch 375/537: Loss=1.5705 (C:1.5705, R:0.0105)
Batch 400/537: Loss=1.5434 (C:1.5434, R:0.0105)
Batch 425/537: Loss=1.5650 (C:1.5650, R:0.0105)
Batch 450/537: Loss=1.5749 (C:1.5749, R:0.0105)
Batch 475/537: Loss=1.5331 (C:1.5331, R:0.0105)
Batch 500/537: Loss=1.5504 (C:1.5504, R:0.0105)
Batch 525/537: Loss=1.5535 (C:1.5535, R:0.0105)

============================================================
Epoch 11/300 completed in 21.1s
Train: Loss=1.5620 (C:1.5620, R:0.0105) Ratio=3.32x
Val:   Loss=1.6256 (C:1.6256, R:0.0104) Ratio=2.88x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

Epoch 12 Training
----------------------------------------
Batch   0/537: Loss=1.5514 (C:1.5514, R:0.0105)
Batch  25/537: Loss=1.5334 (C:1.5334, R:0.0105)
Batch  50/537: Loss=1.5355 (C:1.5355, R:0.0105)
Batch  75/537: Loss=1.4844 (C:1.4844, R:0.0105)
Batch 100/537: Loss=1.5009 (C:1.5009, R:0.0105)
Batch 125/537: Loss=1.4977 (C:1.4977, R:0.0105)
Batch 150/537: Loss=1.5235 (C:1.5235, R:0.0105)
Batch 175/537: Loss=1.5593 (C:1.5593, R:0.0105)
Batch 200/537: Loss=1.5770 (C:1.5770, R:0.0105)
Batch 225/537: Loss=1.5332 (C:1.5332, R:0.0105)
Batch 250/537: Loss=1.5028 (C:1.5028, R:0.0105)
Batch 275/537: Loss=1.5441 (C:1.5441, R:0.0105)
Batch 300/537: Loss=1.5670 (C:1.5670, R:0.0105)
Batch 325/537: Loss=1.5991 (C:1.5991, R:0.0105)
Batch 350/537: Loss=1.5076 (C:1.5076, R:0.0105)
Batch 375/537: Loss=1.5704 (C:1.5704, R:0.0105)
Batch 400/537: Loss=1.5123 (C:1.5123, R:0.0105)
Batch 425/537: Loss=1.5996 (C:1.5996, R:0.0105)
Batch 450/537: Loss=1.5165 (C:1.5165, R:0.0105)
Batch 475/537: Loss=1.5382 (C:1.5382, R:0.0105)
Batch 500/537: Loss=1.5295 (C:1.5295, R:0.0105)
Batch 525/537: Loss=1.5566 (C:1.5566, R:0.0105)

============================================================
Epoch 12/300 completed in 21.4s
Train: Loss=1.5517 (C:1.5517, R:0.0105) Ratio=3.48x
Val:   Loss=1.6228 (C:1.6228, R:0.0104) Ratio=2.88x
Reconstruction weight: 0.000
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 13
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.623 ± 0.810
    Neg distances: 2.399 ± 1.285
    Separation ratio: 3.85x
    Gap: -4.550
    ✅ Excellent global separation!

Epoch 13 Training
----------------------------------------
Batch   0/537: Loss=1.5325 (C:1.5325, R:0.0105)
Batch  25/537: Loss=1.5191 (C:1.5191, R:0.0105)
Batch  50/537: Loss=1.4868 (C:1.4868, R:0.0105)
Batch  75/537: Loss=1.4690 (C:1.4690, R:0.0105)
Batch 100/537: Loss=1.5244 (C:1.5244, R:0.0105)
Batch 125/537: Loss=1.5561 (C:1.5561, R:0.0105)
Batch 150/537: Loss=1.5452 (C:1.5452, R:0.0105)
Batch 175/537: Loss=1.5509 (C:1.5509, R:0.0105)
Batch 200/537: Loss=1.5595 (C:1.5595, R:0.0105)
Batch 225/537: Loss=1.5731 (C:1.5731, R:0.0105)
Batch 250/537: Loss=1.5390 (C:1.5390, R:0.0105)
Batch 275/537: Loss=1.4633 (C:1.4633, R:0.0105)
Batch 300/537: Loss=1.5217 (C:1.5217, R:0.0105)
Batch 325/537: Loss=1.5167 (C:1.5167, R:0.0105)
Batch 350/537: Loss=1.5528 (C:1.5528, R:0.0105)
Batch 375/537: Loss=1.5537 (C:1.5537, R:0.0105)
Batch 400/537: Loss=1.4990 (C:1.4990, R:0.0105)
Batch 425/537: Loss=1.5697 (C:1.5697, R:0.0105)
Batch 450/537: Loss=1.5424 (C:1.5424, R:0.0105)
Batch 475/537: Loss=1.5363 (C:1.5363, R:0.0105)
Batch 500/537: Loss=1.5309 (C:1.5309, R:0.0105)
Batch 525/537: Loss=1.5518 (C:1.5518, R:0.0105)

============================================================
Epoch 13/300 completed in 27.3s
Train: Loss=1.5377 (C:1.5377, R:0.0105) Ratio=3.44x
Val:   Loss=1.6094 (C:1.6094, R:0.0104) Ratio=2.93x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.6094)
============================================================

Epoch 14 Training
----------------------------------------
Batch   0/537: Loss=1.5378 (C:1.5378, R:0.0105)
Batch  25/537: Loss=1.5479 (C:1.5479, R:0.0105)
Batch  50/537: Loss=1.4981 (C:1.4981, R:0.0105)
Batch  75/537: Loss=1.5589 (C:1.5589, R:0.0105)
Batch 100/537: Loss=1.5054 (C:1.5054, R:0.0105)
Batch 125/537: Loss=1.5717 (C:1.5717, R:0.0105)
Batch 150/537: Loss=1.5513 (C:1.5513, R:0.0105)
Batch 175/537: Loss=1.5367 (C:1.5367, R:0.0105)
Batch 200/537: Loss=1.5584 (C:1.5584, R:0.0105)
Batch 225/537: Loss=1.5474 (C:1.5474, R:0.0105)
Batch 250/537: Loss=1.5561 (C:1.5561, R:0.0105)
Batch 275/537: Loss=1.5212 (C:1.5212, R:0.0105)
Batch 300/537: Loss=1.5018 (C:1.5018, R:0.0105)
Batch 325/537: Loss=1.5181 (C:1.5181, R:0.0105)
Batch 350/537: Loss=1.5008 (C:1.5008, R:0.0105)
Batch 375/537: Loss=1.5421 (C:1.5421, R:0.0105)
Batch 400/537: Loss=1.5238 (C:1.5238, R:0.0105)
Batch 425/537: Loss=1.6019 (C:1.6019, R:0.0105)
Batch 450/537: Loss=1.5102 (C:1.5102, R:0.0105)
Batch 475/537: Loss=1.5601 (C:1.5601, R:0.0105)
Batch 500/537: Loss=1.5269 (C:1.5269, R:0.0105)
Batch 525/537: Loss=1.5535 (C:1.5535, R:0.0105)

============================================================
Epoch 14/300 completed in 21.2s
Train: Loss=1.5294 (C:1.5294, R:0.0105) Ratio=3.51x
Val:   Loss=1.6048 (C:1.6048, R:0.0104) Ratio=2.91x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.6048)
============================================================

Epoch 15 Training
----------------------------------------
Batch   0/537: Loss=1.5405 (C:1.5405, R:0.0105)
Batch  25/537: Loss=1.5146 (C:1.5146, R:0.0106)
Batch  50/537: Loss=1.5709 (C:1.5709, R:0.0105)
Batch  75/537: Loss=1.4485 (C:1.4485, R:0.0105)
Batch 100/537: Loss=1.5072 (C:1.5072, R:0.0106)
Batch 125/537: Loss=1.5475 (C:1.5475, R:0.0105)
Batch 150/537: Loss=1.4962 (C:1.4962, R:0.0105)
Batch 175/537: Loss=1.5075 (C:1.5075, R:0.0105)
Batch 200/537: Loss=1.5099 (C:1.5099, R:0.0105)
Batch 225/537: Loss=1.5308 (C:1.5308, R:0.0105)
Batch 250/537: Loss=1.5106 (C:1.5106, R:0.0105)
Batch 275/537: Loss=1.5139 (C:1.5139, R:0.0105)
Batch 300/537: Loss=1.5404 (C:1.5404, R:0.0105)
Batch 325/537: Loss=1.5296 (C:1.5296, R:0.0105)
Batch 350/537: Loss=1.5090 (C:1.5090, R:0.0105)
Batch 375/537: Loss=1.5283 (C:1.5283, R:0.0105)
Batch 400/537: Loss=1.5032 (C:1.5032, R:0.0105)
Batch 425/537: Loss=1.5370 (C:1.5370, R:0.0105)
Batch 450/537: Loss=1.5505 (C:1.5505, R:0.0105)
Batch 475/537: Loss=1.5207 (C:1.5207, R:0.0105)
Batch 500/537: Loss=1.5500 (C:1.5500, R:0.0105)
Batch 525/537: Loss=1.4892 (C:1.4892, R:0.0105)

============================================================
Epoch 15/300 completed in 21.5s
Train: Loss=1.5239 (C:1.5239, R:0.0105) Ratio=3.58x
Val:   Loss=1.5928 (C:1.5928, R:0.0104) Ratio=2.92x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.5928)
============================================================

🌍 Updating global dataset at epoch 16
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.533 ± 0.752
    Neg distances: 2.534 ± 1.279
    Separation ratio: 4.75x
    Gap: -4.556
    ✅ Excellent global separation!

Epoch 16 Training
----------------------------------------
Batch   0/537: Loss=1.4199 (C:1.4199, R:0.0105)
Batch  25/537: Loss=1.4074 (C:1.4074, R:0.0105)
Batch  50/537: Loss=1.4064 (C:1.4064, R:0.0105)
Batch  75/537: Loss=1.3716 (C:1.3716, R:0.0105)
Batch 100/537: Loss=1.4272 (C:1.4272, R:0.0105)
Batch 125/537: Loss=1.4357 (C:1.4357, R:0.0105)
Batch 150/537: Loss=1.4144 (C:1.4144, R:0.0105)
Batch 175/537: Loss=1.3855 (C:1.3855, R:0.0105)
Batch 200/537: Loss=1.3536 (C:1.3536, R:0.0105)
Batch 225/537: Loss=1.4448 (C:1.4448, R:0.0105)
Batch 250/537: Loss=1.3869 (C:1.3869, R:0.0105)
Batch 275/537: Loss=1.4640 (C:1.4640, R:0.0105)
Batch 300/537: Loss=1.4264 (C:1.4264, R:0.0105)
Batch 325/537: Loss=1.4542 (C:1.4542, R:0.0105)
Batch 350/537: Loss=1.4428 (C:1.4428, R:0.0106)
Batch 375/537: Loss=1.4045 (C:1.4045, R:0.0106)
Batch 400/537: Loss=1.4402 (C:1.4402, R:0.0105)
Batch 425/537: Loss=1.4582 (C:1.4582, R:0.0106)
Batch 450/537: Loss=1.4170 (C:1.4170, R:0.0105)
Batch 475/537: Loss=1.4167 (C:1.4167, R:0.0105)
Batch 500/537: Loss=1.4691 (C:1.4691, R:0.0105)
Batch 525/537: Loss=1.4139 (C:1.4139, R:0.0105)

============================================================
Epoch 16/300 completed in 27.6s
Train: Loss=1.4180 (C:1.4180, R:0.0105) Ratio=3.59x
Val:   Loss=1.5038 (C:1.5038, R:0.0104) Ratio=2.90x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.5038)
============================================================

Epoch 17 Training
----------------------------------------
Batch   0/537: Loss=1.3759 (C:1.3759, R:0.0105)
Batch  25/537: Loss=1.4035 (C:1.4035, R:0.0105)
Batch  50/537: Loss=1.3695 (C:1.3695, R:0.0105)
Batch  75/537: Loss=1.3706 (C:1.3706, R:0.0105)
Batch 100/537: Loss=1.3857 (C:1.3857, R:0.0105)
Batch 125/537: Loss=1.4433 (C:1.4433, R:0.0105)
Batch 150/537: Loss=1.4060 (C:1.4060, R:0.0105)
Batch 175/537: Loss=1.4316 (C:1.4316, R:0.0106)
Batch 200/537: Loss=1.4159 (C:1.4159, R:0.0105)
Batch 225/537: Loss=1.3774 (C:1.3774, R:0.0105)
Batch 250/537: Loss=1.4223 (C:1.4223, R:0.0105)
Batch 275/537: Loss=1.4143 (C:1.4143, R:0.0105)
Batch 300/537: Loss=1.4304 (C:1.4304, R:0.0106)
Batch 325/537: Loss=1.4468 (C:1.4468, R:0.0105)
Batch 350/537: Loss=1.4222 (C:1.4222, R:0.0105)
Batch 375/537: Loss=1.4089 (C:1.4089, R:0.0105)
Batch 400/537: Loss=1.4642 (C:1.4642, R:0.0105)
Batch 425/537: Loss=1.4361 (C:1.4361, R:0.0105)
Batch 450/537: Loss=1.3861 (C:1.3861, R:0.0105)
Batch 475/537: Loss=1.4479 (C:1.4479, R:0.0105)
Batch 500/537: Loss=1.4046 (C:1.4046, R:0.0105)
Batch 525/537: Loss=1.3997 (C:1.3997, R:0.0105)

============================================================
Epoch 17/300 completed in 21.5s
Train: Loss=1.4093 (C:1.4093, R:0.0105) Ratio=3.69x
Val:   Loss=1.5052 (C:1.5052, R:0.0104) Ratio=2.95x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

Epoch 18 Training
----------------------------------------
Batch   0/537: Loss=1.3643 (C:1.3643, R:0.0105)
Batch  25/537: Loss=1.3817 (C:1.3817, R:0.0105)
Batch  50/537: Loss=1.4156 (C:1.4156, R:0.0105)
Batch  75/537: Loss=1.4329 (C:1.4329, R:0.0105)
Batch 100/537: Loss=1.4134 (C:1.4134, R:0.0105)
Batch 125/537: Loss=1.4020 (C:1.4020, R:0.0105)
Batch 150/537: Loss=1.3844 (C:1.3844, R:0.0105)
Batch 175/537: Loss=1.3549 (C:1.3549, R:0.0105)
Batch 200/537: Loss=1.4698 (C:1.4698, R:0.0105)
Batch 225/537: Loss=1.4717 (C:1.4717, R:0.0105)
Batch 250/537: Loss=1.3741 (C:1.3741, R:0.0105)
Batch 275/537: Loss=1.4048 (C:1.4048, R:0.0105)
Batch 300/537: Loss=1.4017 (C:1.4017, R:0.0105)
Batch 325/537: Loss=1.3645 (C:1.3645, R:0.0105)
Batch 350/537: Loss=1.3884 (C:1.3884, R:0.0105)
Batch 375/537: Loss=1.4351 (C:1.4351, R:0.0105)
Batch 400/537: Loss=1.3392 (C:1.3392, R:0.0105)
Batch 425/537: Loss=1.3661 (C:1.3661, R:0.0105)
Batch 450/537: Loss=1.3808 (C:1.3808, R:0.0105)
Batch 475/537: Loss=1.4185 (C:1.4185, R:0.0105)
Batch 500/537: Loss=1.4098 (C:1.4098, R:0.0105)
Batch 525/537: Loss=1.4145 (C:1.4145, R:0.0105)

============================================================
Epoch 18/300 completed in 21.5s
Train: Loss=1.4044 (C:1.4044, R:0.0105) Ratio=3.79x
Val:   Loss=1.4938 (C:1.4938, R:0.0104) Ratio=2.93x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.4938)
============================================================

🌍 Updating global dataset at epoch 19
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.549 ± 0.777
    Neg distances: 2.606 ± 1.315
    Separation ratio: 4.75x
    Gap: -4.599
    ✅ Excellent global separation!

Epoch 19 Training
----------------------------------------
Batch   0/537: Loss=1.3729 (C:1.3729, R:0.0105)
Batch  25/537: Loss=1.4095 (C:1.4095, R:0.0105)
Batch  50/537: Loss=1.4066 (C:1.4066, R:0.0105)
Batch  75/537: Loss=1.4271 (C:1.4271, R:0.0105)
Batch 100/537: Loss=1.3650 (C:1.3650, R:0.0105)
Batch 125/537: Loss=1.3793 (C:1.3793, R:0.0105)
Batch 150/537: Loss=1.3932 (C:1.3932, R:0.0105)
Batch 175/537: Loss=1.3886 (C:1.3886, R:0.0105)
Batch 200/537: Loss=1.3858 (C:1.3858, R:0.0105)
Batch 225/537: Loss=1.4379 (C:1.4379, R:0.0105)
Batch 250/537: Loss=1.4218 (C:1.4218, R:0.0105)
Batch 275/537: Loss=1.3822 (C:1.3822, R:0.0105)
Batch 300/537: Loss=1.3449 (C:1.3449, R:0.0105)
Batch 325/537: Loss=1.3910 (C:1.3910, R:0.0105)
Batch 350/537: Loss=1.4238 (C:1.4238, R:0.0105)
Batch 375/537: Loss=1.4573 (C:1.4573, R:0.0105)
Batch 400/537: Loss=1.3504 (C:1.3504, R:0.0105)
Batch 425/537: Loss=1.4003 (C:1.4003, R:0.0106)
Batch 450/537: Loss=1.4231 (C:1.4231, R:0.0105)
Batch 475/537: Loss=1.3818 (C:1.3818, R:0.0105)
Batch 500/537: Loss=1.3601 (C:1.3601, R:0.0105)
Batch 525/537: Loss=1.3926 (C:1.3926, R:0.0105)

============================================================
Epoch 19/300 completed in 28.8s
Train: Loss=1.3893 (C:1.3893, R:0.0105) Ratio=3.82x
Val:   Loss=1.4740 (C:1.4740, R:0.0104) Ratio=2.96x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.4740)
============================================================

Epoch 20 Training
----------------------------------------
Batch   0/537: Loss=1.3834 (C:1.3834, R:0.0105)
Batch  25/537: Loss=1.3999 (C:1.3999, R:0.0105)
Batch  50/537: Loss=1.3639 (C:1.3639, R:0.0105)
Batch  75/537: Loss=1.3450 (C:1.3450, R:0.0105)
Batch 100/537: Loss=1.4086 (C:1.4086, R:0.0105)
Batch 125/537: Loss=1.4122 (C:1.4122, R:0.0105)
Batch 150/537: Loss=1.4221 (C:1.4221, R:0.0105)
Batch 175/537: Loss=1.4180 (C:1.4180, R:0.0105)
Batch 200/537: Loss=1.3697 (C:1.3697, R:0.0105)
Batch 225/537: Loss=1.4064 (C:1.4064, R:0.0105)
Batch 250/537: Loss=1.3835 (C:1.3835, R:0.0105)
Batch 275/537: Loss=1.3379 (C:1.3379, R:0.0105)
Batch 300/537: Loss=1.4131 (C:1.4131, R:0.0105)
Batch 325/537: Loss=1.4169 (C:1.4169, R:0.0105)
Batch 350/537: Loss=1.3425 (C:1.3425, R:0.0105)
Batch 375/537: Loss=1.4203 (C:1.4203, R:0.0105)
Batch 400/537: Loss=1.4259 (C:1.4259, R:0.0106)
Batch 425/537: Loss=1.4163 (C:1.4163, R:0.0105)
Batch 450/537: Loss=1.3741 (C:1.3741, R:0.0105)
Batch 475/537: Loss=1.4043 (C:1.4043, R:0.0105)
Batch 500/537: Loss=1.3724 (C:1.3724, R:0.0105)
Batch 525/537: Loss=1.4209 (C:1.4209, R:0.0105)

============================================================
Epoch 20/300 completed in 21.7s
Train: Loss=1.3843 (C:1.3843, R:0.0105) Ratio=3.79x
Val:   Loss=1.5011 (C:1.5011, R:0.0104) Ratio=2.97x
Reconstruction weight: 0.000
No improvement for 1 epochs
Checkpoint saved at epoch 20
============================================================

Epoch 21 Training
----------------------------------------
Batch   0/537: Loss=1.3689 (C:1.3689, R:0.0105)
Batch  25/537: Loss=1.3379 (C:1.3379, R:0.0105)
Batch  50/537: Loss=1.3748 (C:1.3748, R:0.0105)
Batch  75/537: Loss=1.3736 (C:1.3736, R:0.0105)
Batch 100/537: Loss=1.3946 (C:1.3946, R:0.0105)
Batch 125/537: Loss=1.3538 (C:1.3538, R:0.0105)
Batch 150/537: Loss=1.3688 (C:1.3688, R:0.0105)
Batch 175/537: Loss=1.3832 (C:1.3832, R:0.0105)
Batch 200/537: Loss=1.3799 (C:1.3799, R:0.0105)
Batch 225/537: Loss=1.3612 (C:1.3612, R:0.0105)
Batch 250/537: Loss=1.3443 (C:1.3443, R:0.0105)
Batch 275/537: Loss=1.4085 (C:1.4085, R:0.0106)
Batch 300/537: Loss=1.3632 (C:1.3632, R:0.0105)
Batch 325/537: Loss=1.3605 (C:1.3605, R:0.0105)
Batch 350/537: Loss=1.4193 (C:1.4193, R:0.0105)
Batch 375/537: Loss=1.3748 (C:1.3748, R:0.0105)
Batch 400/537: Loss=1.3752 (C:1.3752, R:0.0105)
Batch 425/537: Loss=1.3451 (C:1.3451, R:0.0105)
Batch 450/537: Loss=1.4381 (C:1.4381, R:0.0105)
Batch 475/537: Loss=1.4436 (C:1.4436, R:0.0105)
Batch 500/537: Loss=1.3888 (C:1.3888, R:0.0105)
Batch 525/537: Loss=1.3929 (C:1.3929, R:0.0105)

============================================================
Epoch 21/300 completed in 21.3s
Train: Loss=1.3772 (C:1.3772, R:0.0105) Ratio=3.87x
Val:   Loss=1.4827 (C:1.4827, R:0.0104) Ratio=2.98x
Reconstruction weight: 0.000
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 22
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.535 ± 0.764
    Neg distances: 2.664 ± 1.328
    Separation ratio: 4.98x
    Gap: -4.600
    ✅ Excellent global separation!

Epoch 22 Training
----------------------------------------
Batch   0/537: Loss=1.3689 (C:1.3689, R:0.0105)
Batch  25/537: Loss=1.3721 (C:1.3721, R:0.0106)
Batch  50/537: Loss=1.3728 (C:1.3728, R:0.0105)
Batch  75/537: Loss=1.3374 (C:1.3374, R:0.0105)
Batch 100/537: Loss=1.3477 (C:1.3477, R:0.0105)
Batch 125/537: Loss=1.3561 (C:1.3561, R:0.0105)
Batch 150/537: Loss=1.3714 (C:1.3714, R:0.0105)
Batch 175/537: Loss=1.3261 (C:1.3261, R:0.0105)
Batch 200/537: Loss=1.3299 (C:1.3299, R:0.0105)
Batch 225/537: Loss=1.3146 (C:1.3146, R:0.0105)
Batch 250/537: Loss=1.3555 (C:1.3555, R:0.0105)
Batch 275/537: Loss=1.3040 (C:1.3040, R:0.0105)
Batch 300/537: Loss=1.3695 (C:1.3695, R:0.0105)
Batch 325/537: Loss=1.3600 (C:1.3600, R:0.0105)
Batch 350/537: Loss=1.3320 (C:1.3320, R:0.0105)
Batch 375/537: Loss=1.3699 (C:1.3699, R:0.0105)
Batch 400/537: Loss=1.3200 (C:1.3200, R:0.0105)
Batch 425/537: Loss=1.3891 (C:1.3891, R:0.0105)
Batch 450/537: Loss=1.3722 (C:1.3722, R:0.0105)
Batch 475/537: Loss=1.3745 (C:1.3745, R:0.0105)
Batch 500/537: Loss=1.2929 (C:1.2929, R:0.0105)
Batch 525/537: Loss=1.3799 (C:1.3799, R:0.0105)

============================================================
Epoch 22/300 completed in 27.6s
Train: Loss=1.3473 (C:1.3473, R:0.0105) Ratio=3.98x
Val:   Loss=1.4668 (C:1.4668, R:0.0104) Ratio=2.98x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.4668)
============================================================

Epoch 23 Training
----------------------------------------
Batch   0/537: Loss=1.2593 (C:1.2593, R:0.0105)
Batch  25/537: Loss=1.3704 (C:1.3704, R:0.0105)
Batch  50/537: Loss=1.3543 (C:1.3543, R:0.0105)
Batch  75/537: Loss=1.3149 (C:1.3149, R:0.0105)
Batch 100/537: Loss=1.3071 (C:1.3071, R:0.0105)
Batch 125/537: Loss=1.3151 (C:1.3151, R:0.0105)
Batch 150/537: Loss=1.3294 (C:1.3294, R:0.0105)
Batch 175/537: Loss=1.3076 (C:1.3076, R:0.0105)
Batch 200/537: Loss=1.3006 (C:1.3006, R:0.0105)
Batch 225/537: Loss=1.2907 (C:1.2907, R:0.0105)
Batch 250/537: Loss=1.3288 (C:1.3288, R:0.0105)
Batch 275/537: Loss=1.3039 (C:1.3039, R:0.0105)
Batch 300/537: Loss=1.3317 (C:1.3317, R:0.0105)
Batch 325/537: Loss=1.3378 (C:1.3378, R:0.0105)
Batch 350/537: Loss=1.3412 (C:1.3412, R:0.0105)
Batch 375/537: Loss=1.2962 (C:1.2962, R:0.0105)
Batch 400/537: Loss=1.3690 (C:1.3690, R:0.0105)
Batch 425/537: Loss=1.3526 (C:1.3526, R:0.0105)
Batch 450/537: Loss=1.3692 (C:1.3692, R:0.0105)
Batch 475/537: Loss=1.3889 (C:1.3889, R:0.0105)
Batch 500/537: Loss=1.3479 (C:1.3479, R:0.0105)
Batch 525/537: Loss=1.3489 (C:1.3489, R:0.0105)

============================================================
Epoch 23/300 completed in 21.3s
Train: Loss=1.3457 (C:1.3457, R:0.0105) Ratio=4.05x
Val:   Loss=1.4753 (C:1.4753, R:0.0104) Ratio=2.99x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

Epoch 24 Training
----------------------------------------
Batch   0/537: Loss=1.3201 (C:1.3201, R:0.0105)
Batch  25/537: Loss=1.2883 (C:1.2883, R:0.0105)
Batch  50/537: Loss=1.3071 (C:1.3071, R:0.0105)
Batch  75/537: Loss=1.2934 (C:1.2934, R:0.0105)
Batch 100/537: Loss=1.3126 (C:1.3126, R:0.0105)
Batch 125/537: Loss=1.3067 (C:1.3067, R:0.0105)
Batch 150/537: Loss=1.3205 (C:1.3205, R:0.0105)
Batch 175/537: Loss=1.3472 (C:1.3472, R:0.0105)
Batch 200/537: Loss=1.3092 (C:1.3092, R:0.0105)
Batch 225/537: Loss=1.3187 (C:1.3187, R:0.0105)
Batch 250/537: Loss=1.3252 (C:1.3252, R:0.0105)
Batch 275/537: Loss=1.3251 (C:1.3251, R:0.0105)
Batch 300/537: Loss=1.2820 (C:1.2820, R:0.0105)
Batch 325/537: Loss=1.3852 (C:1.3852, R:0.0105)
Batch 350/537: Loss=1.3263 (C:1.3263, R:0.0106)
Batch 375/537: Loss=1.3946 (C:1.3946, R:0.0105)
Batch 400/537: Loss=1.3723 (C:1.3723, R:0.0105)
Batch 425/537: Loss=1.3396 (C:1.3396, R:0.0105)
Batch 450/537: Loss=1.3269 (C:1.3269, R:0.0105)
Batch 475/537: Loss=1.3807 (C:1.3807, R:0.0105)
Batch 500/537: Loss=1.3271 (C:1.3271, R:0.0105)
Batch 525/537: Loss=1.3776 (C:1.3776, R:0.0105)

============================================================
Epoch 24/300 completed in 22.0s
Train: Loss=1.3374 (C:1.3374, R:0.0105) Ratio=4.04x
Val:   Loss=1.4619 (C:1.4619, R:0.0104) Ratio=2.97x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.4619)
============================================================

🌍 Updating global dataset at epoch 25
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.516 ± 0.748
    Neg distances: 2.763 ± 1.345
    Separation ratio: 5.36x
    Gap: -4.756
    ✅ Excellent global separation!

Epoch 25 Training
----------------------------------------
Batch   0/537: Loss=1.2591 (C:1.2591, R:0.0105)
Batch  25/537: Loss=1.3251 (C:1.3251, R:0.0105)
Batch  50/537: Loss=1.2901 (C:1.2901, R:0.0105)
Batch  75/537: Loss=1.2708 (C:1.2708, R:0.0105)
Batch 100/537: Loss=1.2728 (C:1.2728, R:0.0105)
Batch 125/537: Loss=1.2502 (C:1.2502, R:0.0105)
Batch 150/537: Loss=1.2702 (C:1.2702, R:0.0105)
Batch 175/537: Loss=1.3063 (C:1.3063, R:0.0105)
Batch 200/537: Loss=1.2624 (C:1.2624, R:0.0105)
Batch 225/537: Loss=1.2799 (C:1.2799, R:0.0106)
Batch 250/537: Loss=1.2711 (C:1.2711, R:0.0105)
Batch 275/537: Loss=1.2600 (C:1.2600, R:0.0105)
Batch 300/537: Loss=1.3361 (C:1.3361, R:0.0105)
Batch 325/537: Loss=1.3325 (C:1.3325, R:0.0105)
Batch 350/537: Loss=1.2990 (C:1.2990, R:0.0105)
Batch 375/537: Loss=1.3123 (C:1.3123, R:0.0105)
Batch 400/537: Loss=1.3208 (C:1.3208, R:0.0105)
Batch 425/537: Loss=1.2888 (C:1.2888, R:0.0105)
Batch 450/537: Loss=1.2517 (C:1.2517, R:0.0105)
Batch 475/537: Loss=1.2626 (C:1.2626, R:0.0105)
Batch 500/537: Loss=1.2394 (C:1.2394, R:0.0105)
Batch 525/537: Loss=1.2992 (C:1.2992, R:0.0105)

============================================================
Epoch 25/300 completed in 28.2s
Train: Loss=1.2943 (C:1.2943, R:0.0105) Ratio=4.11x
Val:   Loss=1.4239 (C:1.4239, R:0.0104) Ratio=2.99x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.4239)
============================================================

Epoch 26 Training
----------------------------------------
Batch   0/537: Loss=1.3368 (C:1.3368, R:0.0105)
Batch  25/537: Loss=1.2892 (C:1.2892, R:0.0105)
Batch  50/537: Loss=1.3034 (C:1.3034, R:0.0105)
Batch  75/537: Loss=1.2788 (C:1.2788, R:0.0105)
Batch 100/537: Loss=1.2742 (C:1.2742, R:0.0105)
Batch 125/537: Loss=1.2639 (C:1.2639, R:0.0105)
Batch 150/537: Loss=1.2703 (C:1.2703, R:0.0105)
Batch 175/537: Loss=1.2757 (C:1.2757, R:0.0105)
Batch 200/537: Loss=1.3072 (C:1.3072, R:0.0105)
Batch 225/537: Loss=1.2960 (C:1.2960, R:0.0105)
Batch 250/537: Loss=1.3055 (C:1.3055, R:0.0105)
Batch 275/537: Loss=1.2728 (C:1.2728, R:0.0105)
Batch 300/537: Loss=1.3033 (C:1.3033, R:0.0105)
Batch 325/537: Loss=1.2977 (C:1.2977, R:0.0105)
Batch 350/537: Loss=1.2815 (C:1.2815, R:0.0105)
Batch 375/537: Loss=1.3061 (C:1.3061, R:0.0105)
Batch 400/537: Loss=1.2905 (C:1.2905, R:0.0105)
Batch 425/537: Loss=1.2877 (C:1.2877, R:0.0105)
Batch 450/537: Loss=1.3428 (C:1.3428, R:0.0105)
Batch 475/537: Loss=1.2880 (C:1.2880, R:0.0105)
Batch 500/537: Loss=1.2804 (C:1.2804, R:0.0105)
Batch 525/537: Loss=1.2656 (C:1.2656, R:0.0105)

============================================================
Epoch 26/300 completed in 21.4s
Train: Loss=1.2898 (C:1.2898, R:0.0105) Ratio=4.13x
Val:   Loss=1.4156 (C:1.4156, R:0.0104) Ratio=3.01x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.4156)
============================================================

Epoch 27 Training
----------------------------------------
Batch   0/537: Loss=1.2823 (C:1.2823, R:0.0105)
Batch  25/537: Loss=1.2823 (C:1.2823, R:0.0105)
Batch  50/537: Loss=1.2644 (C:1.2644, R:0.0105)
Batch  75/537: Loss=1.2497 (C:1.2497, R:0.0105)
Batch 100/537: Loss=1.3035 (C:1.3035, R:0.0105)
Batch 125/537: Loss=1.2975 (C:1.2975, R:0.0105)
Batch 150/537: Loss=1.3072 (C:1.3072, R:0.0106)
Batch 175/537: Loss=1.2420 (C:1.2420, R:0.0105)
Batch 200/537: Loss=1.2870 (C:1.2870, R:0.0105)
Batch 225/537: Loss=1.3035 (C:1.3035, R:0.0105)
Batch 250/537: Loss=1.2679 (C:1.2679, R:0.0105)
Batch 275/537: Loss=1.2801 (C:1.2801, R:0.0105)
Batch 300/537: Loss=1.3297 (C:1.3297, R:0.0105)
Batch 325/537: Loss=1.2797 (C:1.2797, R:0.0105)
Batch 350/537: Loss=1.2671 (C:1.2671, R:0.0106)
Batch 375/537: Loss=1.2694 (C:1.2694, R:0.0105)
Batch 400/537: Loss=1.2700 (C:1.2700, R:0.0105)
Batch 425/537: Loss=1.3265 (C:1.3265, R:0.0105)
Batch 450/537: Loss=1.3183 (C:1.3183, R:0.0105)
Batch 475/537: Loss=1.2848 (C:1.2848, R:0.0105)
Batch 500/537: Loss=1.3296 (C:1.3296, R:0.0105)
Batch 525/537: Loss=1.2759 (C:1.2759, R:0.0105)

============================================================
Epoch 27/300 completed in 21.3s
Train: Loss=1.2874 (C:1.2874, R:0.0105) Ratio=4.19x
Val:   Loss=1.4301 (C:1.4301, R:0.0104) Ratio=3.00x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 28
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.505 ± 0.775
    Neg distances: 2.857 ± 1.340
    Separation ratio: 5.66x
    Gap: -5.043
    ✅ Excellent global separation!

Epoch 28 Training
----------------------------------------
Batch   0/537: Loss=1.2419 (C:1.2419, R:0.0105)
Batch  25/537: Loss=1.2137 (C:1.2137, R:0.0105)
Batch  50/537: Loss=1.2199 (C:1.2199, R:0.0105)
Batch  75/537: Loss=1.2220 (C:1.2220, R:0.0105)
Batch 100/537: Loss=1.2257 (C:1.2257, R:0.0105)
Batch 125/537: Loss=1.2476 (C:1.2476, R:0.0105)
Batch 150/537: Loss=1.2216 (C:1.2216, R:0.0105)
Batch 175/537: Loss=1.1884 (C:1.1884, R:0.0105)
Batch 200/537: Loss=1.2434 (C:1.2434, R:0.0105)
Batch 225/537: Loss=1.2713 (C:1.2713, R:0.0105)
Batch 250/537: Loss=1.2762 (C:1.2762, R:0.0105)
Batch 275/537: Loss=1.2032 (C:1.2032, R:0.0105)
Batch 300/537: Loss=1.1812 (C:1.1812, R:0.0105)
Batch 325/537: Loss=1.2166 (C:1.2166, R:0.0105)
Batch 350/537: Loss=1.2313 (C:1.2313, R:0.0105)
Batch 375/537: Loss=1.2211 (C:1.2211, R:0.0106)
Batch 400/537: Loss=1.2690 (C:1.2690, R:0.0105)
Batch 425/537: Loss=1.2265 (C:1.2265, R:0.0105)
Batch 450/537: Loss=1.1989 (C:1.1989, R:0.0105)
Batch 475/537: Loss=1.2772 (C:1.2772, R:0.0105)
Batch 500/537: Loss=1.1942 (C:1.1942, R:0.0105)
Batch 525/537: Loss=1.2575 (C:1.2575, R:0.0105)

============================================================
Epoch 28/300 completed in 28.2s
Train: Loss=1.2413 (C:1.2413, R:0.0105) Ratio=4.15x
Val:   Loss=1.3900 (C:1.3900, R:0.0104) Ratio=2.98x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.3900)
============================================================

Epoch 29 Training
----------------------------------------
Batch   0/537: Loss=1.2474 (C:1.2474, R:0.0106)
Batch  25/537: Loss=1.1993 (C:1.1993, R:0.0105)
Batch  50/537: Loss=1.2504 (C:1.2504, R:0.0105)
Batch  75/537: Loss=1.2691 (C:1.2691, R:0.0105)
Batch 100/537: Loss=1.2554 (C:1.2554, R:0.0105)
Batch 125/537: Loss=1.2362 (C:1.2362, R:0.0105)
Batch 150/537: Loss=1.2308 (C:1.2308, R:0.0105)
Batch 175/537: Loss=1.2543 (C:1.2543, R:0.0105)
Batch 200/537: Loss=1.2573 (C:1.2573, R:0.0105)
Batch 225/537: Loss=1.2592 (C:1.2592, R:0.0105)
Batch 250/537: Loss=1.2164 (C:1.2164, R:0.0105)
Batch 275/537: Loss=1.2218 (C:1.2218, R:0.0105)
Batch 300/537: Loss=1.2497 (C:1.2497, R:0.0105)
Batch 325/537: Loss=1.2756 (C:1.2756, R:0.0105)
Batch 350/537: Loss=1.2016 (C:1.2016, R:0.0105)
Batch 375/537: Loss=1.2757 (C:1.2757, R:0.0105)
Batch 400/537: Loss=1.2455 (C:1.2455, R:0.0105)
Batch 425/537: Loss=1.2359 (C:1.2359, R:0.0105)
Batch 450/537: Loss=1.2551 (C:1.2551, R:0.0105)
Batch 475/537: Loss=1.2362 (C:1.2362, R:0.0105)
Batch 500/537: Loss=1.2306 (C:1.2306, R:0.0105)
Batch 525/537: Loss=1.3173 (C:1.3173, R:0.0106)

============================================================
Epoch 29/300 completed in 21.9s
Train: Loss=1.2366 (C:1.2366, R:0.0105) Ratio=4.17x
Val:   Loss=1.3801 (C:1.3801, R:0.0104) Ratio=3.01x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.3801)
============================================================

Epoch 30 Training
----------------------------------------
Batch   0/537: Loss=1.2003 (C:1.2003, R:0.0105)
Batch  25/537: Loss=1.2925 (C:1.2925, R:0.0105)
Batch  50/537: Loss=1.2151 (C:1.2151, R:0.0105)
Batch  75/537: Loss=1.2366 (C:1.2366, R:0.0105)
Batch 100/537: Loss=1.2591 (C:1.2591, R:0.0105)
Batch 125/537: Loss=1.1895 (C:1.1895, R:0.0105)
Batch 150/537: Loss=1.1585 (C:1.1585, R:0.0105)
Batch 175/537: Loss=1.1738 (C:1.1738, R:0.0105)
Batch 200/537: Loss=1.2172 (C:1.2172, R:0.0105)
Batch 225/537: Loss=1.2192 (C:1.2192, R:0.0105)
Batch 250/537: Loss=1.2445 (C:1.2445, R:0.0105)
Batch 275/537: Loss=1.2487 (C:1.2487, R:0.0105)
Batch 300/537: Loss=1.2388 (C:1.2388, R:0.0105)
Batch 325/537: Loss=1.2658 (C:1.2658, R:0.0105)
Batch 350/537: Loss=1.2559 (C:1.2559, R:0.0105)
Batch 375/537: Loss=1.2055 (C:1.2055, R:0.0105)
Batch 400/537: Loss=1.2529 (C:1.2529, R:0.0105)
Batch 425/537: Loss=1.2441 (C:1.2441, R:0.0106)
Batch 450/537: Loss=1.2080 (C:1.2080, R:0.0105)
Batch 475/537: Loss=1.2090 (C:1.2090, R:0.0105)
Batch 500/537: Loss=1.2139 (C:1.2139, R:0.0105)
Batch 525/537: Loss=1.2094 (C:1.2094, R:0.0105)

============================================================
Epoch 30/300 completed in 21.7s
Train: Loss=1.2324 (C:1.2324, R:0.0105) Ratio=4.30x
Val:   Loss=1.3859 (C:1.3859, R:0.0104) Ratio=2.99x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 31
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.514 ± 0.756
    Neg distances: 2.919 ± 1.374
    Separation ratio: 5.68x
    Gap: -5.078
    ✅ Excellent global separation!

Epoch 31 Training
----------------------------------------
Batch   0/537: Loss=1.2687 (C:1.2687, R:0.0105)
Batch  25/537: Loss=1.2414 (C:1.2414, R:0.0105)
Batch  50/537: Loss=1.2164 (C:1.2164, R:0.0105)
Batch  75/537: Loss=1.1692 (C:1.1692, R:0.0105)
Batch 100/537: Loss=1.2042 (C:1.2042, R:0.0105)
Batch 125/537: Loss=1.2346 (C:1.2346, R:0.0105)
Batch 150/537: Loss=1.2343 (C:1.2343, R:0.0105)
Batch 175/537: Loss=1.2047 (C:1.2047, R:0.0105)
Batch 200/537: Loss=1.2364 (C:1.2364, R:0.0105)
Batch 225/537: Loss=1.2248 (C:1.2248, R:0.0105)
Batch 250/537: Loss=1.2356 (C:1.2356, R:0.0105)
Batch 275/537: Loss=1.2236 (C:1.2236, R:0.0105)
Batch 300/537: Loss=1.2556 (C:1.2556, R:0.0105)
Batch 325/537: Loss=1.1798 (C:1.1798, R:0.0105)
Batch 350/537: Loss=1.2049 (C:1.2049, R:0.0105)
Batch 375/537: Loss=1.2447 (C:1.2447, R:0.0105)
Batch 400/537: Loss=1.1841 (C:1.1841, R:0.0105)
Batch 425/537: Loss=1.2640 (C:1.2640, R:0.0105)
Batch 450/537: Loss=1.2583 (C:1.2583, R:0.0105)
Batch 475/537: Loss=1.2174 (C:1.2174, R:0.0106)
Batch 500/537: Loss=1.1732 (C:1.1732, R:0.0105)
Batch 525/537: Loss=1.2459 (C:1.2459, R:0.0105)

============================================================
Epoch 31/300 completed in 27.6s
Train: Loss=1.2210 (C:1.2210, R:0.0105) Ratio=4.21x
Val:   Loss=1.3725 (C:1.3725, R:0.0104) Ratio=3.01x
Reconstruction weight: 0.015
✅ New best model saved (Val Loss: 1.3725)
============================================================

Epoch 32 Training
----------------------------------------
Batch   0/537: Loss=1.2187 (C:1.2187, R:0.0105)
Batch  25/537: Loss=1.2123 (C:1.2123, R:0.0105)
Batch  50/537: Loss=1.2059 (C:1.2059, R:0.0105)
Batch  75/537: Loss=1.2038 (C:1.2038, R:0.0105)
Batch 100/537: Loss=1.2500 (C:1.2500, R:0.0105)
Batch 125/537: Loss=1.2517 (C:1.2517, R:0.0105)
Batch 150/537: Loss=1.1933 (C:1.1933, R:0.0105)
Batch 175/537: Loss=1.1956 (C:1.1956, R:0.0105)
Batch 200/537: Loss=1.1831 (C:1.1831, R:0.0105)
Batch 225/537: Loss=1.1988 (C:1.1988, R:0.0105)
Batch 250/537: Loss=1.2367 (C:1.2367, R:0.0105)
Batch 275/537: Loss=1.2162 (C:1.2162, R:0.0105)
Batch 300/537: Loss=1.2155 (C:1.2155, R:0.0105)
Batch 325/537: Loss=1.2426 (C:1.2426, R:0.0105)
Batch 350/537: Loss=1.2381 (C:1.2381, R:0.0105)
Batch 375/537: Loss=1.2401 (C:1.2401, R:0.0105)
Batch 400/537: Loss=1.2076 (C:1.2076, R:0.0105)
Batch 425/537: Loss=1.2188 (C:1.2188, R:0.0105)
Batch 450/537: Loss=1.2079 (C:1.2079, R:0.0105)
Batch 475/537: Loss=1.2151 (C:1.2151, R:0.0105)
Batch 500/537: Loss=1.2193 (C:1.2193, R:0.0105)
Batch 525/537: Loss=1.2339 (C:1.2339, R:0.0105)

============================================================
Epoch 32/300 completed in 21.4s
Train: Loss=1.2174 (C:1.2174, R:0.0105) Ratio=4.32x
Val:   Loss=1.3760 (C:1.3760, R:0.0104) Ratio=3.02x
Reconstruction weight: 0.030
No improvement for 1 epochs
============================================================

Epoch 33 Training
----------------------------------------
Batch   0/537: Loss=1.2438 (C:1.2438, R:0.0105)
Batch  25/537: Loss=1.1852 (C:1.1852, R:0.0105)
Batch  50/537: Loss=1.2459 (C:1.2459, R:0.0105)
Batch  75/537: Loss=1.2301 (C:1.2301, R:0.0105)
Batch 100/537: Loss=1.1653 (C:1.1653, R:0.0105)
Batch 125/537: Loss=1.1724 (C:1.1724, R:0.0105)
Batch 150/537: Loss=1.2126 (C:1.2126, R:0.0105)
Batch 175/537: Loss=1.2031 (C:1.2031, R:0.0105)
Batch 200/537: Loss=1.1437 (C:1.1437, R:0.0105)
Batch 225/537: Loss=1.2195 (C:1.2195, R:0.0106)
Batch 250/537: Loss=1.1795 (C:1.1795, R:0.0105)
Batch 275/537: Loss=1.2087 (C:1.2087, R:0.0105)
Batch 300/537: Loss=1.1811 (C:1.1811, R:0.0105)
Batch 325/537: Loss=1.2011 (C:1.2011, R:0.0105)
Batch 350/537: Loss=1.1786 (C:1.1786, R:0.0105)
Batch 375/537: Loss=1.2175 (C:1.2175, R:0.0106)
Batch 400/537: Loss=1.2084 (C:1.2084, R:0.0105)
Batch 425/537: Loss=1.1805 (C:1.1805, R:0.0105)
Batch 450/537: Loss=1.2264 (C:1.2264, R:0.0105)
Batch 475/537: Loss=1.2633 (C:1.2633, R:0.0105)
Batch 500/537: Loss=1.1830 (C:1.1830, R:0.0105)
Batch 525/537: Loss=1.2125 (C:1.2125, R:0.0105)

============================================================
Epoch 33/300 completed in 21.4s
Train: Loss=1.2149 (C:1.2149, R:0.0105) Ratio=4.41x
Val:   Loss=1.3730 (C:1.3730, R:0.0104) Ratio=3.02x
Reconstruction weight: 0.045
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 34
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.501 ± 0.740
    Neg distances: 3.017 ± 1.378
    Separation ratio: 6.02x
    Gap: -5.189
    ✅ Excellent global separation!

Epoch 34 Training
----------------------------------------
Batch   0/537: Loss=1.1576 (C:1.1576, R:0.0105)
Batch  25/537: Loss=1.1598 (C:1.1598, R:0.0105)
Batch  50/537: Loss=1.1098 (C:1.1098, R:0.0106)
Batch  75/537: Loss=1.1638 (C:1.1638, R:0.0105)
Batch 100/537: Loss=1.1931 (C:1.1931, R:0.0105)
Batch 125/537: Loss=1.1558 (C:1.1558, R:0.0105)
Batch 150/537: Loss=1.1971 (C:1.1971, R:0.0105)
Batch 175/537: Loss=1.1987 (C:1.1987, R:0.0105)
Batch 200/537: Loss=1.1535 (C:1.1535, R:0.0105)
Batch 225/537: Loss=1.2407 (C:1.2407, R:0.0105)
Batch 250/537: Loss=1.1695 (C:1.1695, R:0.0105)
Batch 275/537: Loss=1.1995 (C:1.1995, R:0.0106)
Batch 300/537: Loss=1.1799 (C:1.1799, R:0.0105)
Batch 325/537: Loss=1.1898 (C:1.1898, R:0.0105)
Batch 350/537: Loss=1.1652 (C:1.1652, R:0.0105)
Batch 375/537: Loss=1.1743 (C:1.1743, R:0.0105)
Batch 400/537: Loss=1.1838 (C:1.1838, R:0.0105)
Batch 425/537: Loss=1.1897 (C:1.1897, R:0.0105)
Batch 450/537: Loss=1.1683 (C:1.1683, R:0.0105)
Batch 475/537: Loss=1.1976 (C:1.1976, R:0.0105)
Batch 500/537: Loss=1.1643 (C:1.1643, R:0.0106)
Batch 525/537: Loss=1.1529 (C:1.1529, R:0.0105)

============================================================
Epoch 34/300 completed in 27.1s
Train: Loss=1.1684 (C:1.1684, R:0.0105) Ratio=4.34x
Val:   Loss=1.3347 (C:1.3347, R:0.0104) Ratio=3.01x
Reconstruction weight: 0.060
✅ New best model saved (Val Loss: 1.3347)
============================================================

Epoch 35 Training
----------------------------------------
Batch   0/537: Loss=1.1229 (C:1.1229, R:0.0105)
Batch  25/537: Loss=1.1218 (C:1.1218, R:0.0105)
Batch  50/537: Loss=1.1727 (C:1.1727, R:0.0105)
Batch  75/537: Loss=1.1367 (C:1.1367, R:0.0105)
Batch 100/537: Loss=1.1046 (C:1.1046, R:0.0105)
Batch 125/537: Loss=1.1739 (C:1.1739, R:0.0105)
Batch 150/537: Loss=1.2065 (C:1.2065, R:0.0105)
Batch 175/537: Loss=1.1146 (C:1.1146, R:0.0105)
Batch 200/537: Loss=1.1643 (C:1.1643, R:0.0105)
Batch 225/537: Loss=1.1777 (C:1.1777, R:0.0105)
Batch 250/537: Loss=1.1620 (C:1.1620, R:0.0105)
Batch 275/537: Loss=1.1109 (C:1.1109, R:0.0105)
Batch 300/537: Loss=1.2287 (C:1.2287, R:0.0105)
Batch 325/537: Loss=1.1664 (C:1.1664, R:0.0105)
Batch 350/537: Loss=1.1463 (C:1.1463, R:0.0105)
Batch 375/537: Loss=1.1818 (C:1.1818, R:0.0105)
Batch 400/537: Loss=1.1861 (C:1.1861, R:0.0105)
Batch 425/537: Loss=1.1736 (C:1.1736, R:0.0105)
Batch 450/537: Loss=1.1421 (C:1.1421, R:0.0105)
Batch 475/537: Loss=1.2049 (C:1.2049, R:0.0105)
Batch 500/537: Loss=1.1621 (C:1.1621, R:0.0105)
Batch 525/537: Loss=1.1356 (C:1.1356, R:0.0105)

============================================================
Epoch 35/300 completed in 21.5s
Train: Loss=1.1621 (C:1.1621, R:0.0105) Ratio=4.41x
Val:   Loss=1.3307 (C:1.3307, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.075
✅ New best model saved (Val Loss: 1.3307)
============================================================

Epoch 36 Training
----------------------------------------
Batch   0/537: Loss=1.1054 (C:1.1054, R:0.0105)
Batch  25/537: Loss=1.1460 (C:1.1460, R:0.0105)
Batch  50/537: Loss=1.1707 (C:1.1707, R:0.0105)
Batch  75/537: Loss=1.1473 (C:1.1473, R:0.0105)
Batch 100/537: Loss=1.1338 (C:1.1338, R:0.0105)
Batch 125/537: Loss=1.1713 (C:1.1713, R:0.0105)
Batch 150/537: Loss=1.1296 (C:1.1296, R:0.0105)
Batch 175/537: Loss=1.2151 (C:1.2151, R:0.0105)
Batch 200/537: Loss=1.1410 (C:1.1410, R:0.0105)
Batch 225/537: Loss=1.1988 (C:1.1988, R:0.0105)
Batch 250/537: Loss=1.1245 (C:1.1245, R:0.0105)
Batch 275/537: Loss=1.1432 (C:1.1432, R:0.0105)
Batch 300/537: Loss=1.1494 (C:1.1494, R:0.0105)
Batch 325/537: Loss=1.1452 (C:1.1452, R:0.0105)
Batch 350/537: Loss=1.1500 (C:1.1500, R:0.0105)
Batch 375/537: Loss=1.1222 (C:1.1222, R:0.0105)
Batch 400/537: Loss=1.1600 (C:1.1600, R:0.0105)
Batch 425/537: Loss=1.1584 (C:1.1584, R:0.0105)
Batch 450/537: Loss=1.1838 (C:1.1838, R:0.0105)
Batch 475/537: Loss=1.1885 (C:1.1885, R:0.0106)
Batch 500/537: Loss=1.1816 (C:1.1816, R:0.0105)
Batch 525/537: Loss=1.1668 (C:1.1668, R:0.0105)

============================================================
Epoch 36/300 completed in 21.3s
Train: Loss=1.1598 (C:1.1598, R:0.0105) Ratio=4.52x
Val:   Loss=1.3387 (C:1.3387, R:0.0104) Ratio=3.00x
Reconstruction weight: 0.090
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 37
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.526 ± 0.795
    Neg distances: 3.141 ± 1.433
    Separation ratio: 5.97x
    Gap: -5.477
    ✅ Excellent global separation!

Epoch 37 Training
----------------------------------------
Batch   0/537: Loss=1.1905 (C:1.1905, R:0.0105)
Batch  25/537: Loss=1.1481 (C:1.1481, R:0.0105)
Batch  50/537: Loss=1.0791 (C:1.0791, R:0.0105)
Batch  75/537: Loss=1.1575 (C:1.1575, R:0.0105)
Batch 100/537: Loss=1.1387 (C:1.1387, R:0.0105)
Batch 125/537: Loss=1.1346 (C:1.1346, R:0.0104)
Batch 150/537: Loss=1.1487 (C:1.1487, R:0.0105)
Batch 175/537: Loss=1.1876 (C:1.1876, R:0.0105)
Batch 200/537: Loss=1.1331 (C:1.1331, R:0.0106)
Batch 225/537: Loss=1.1595 (C:1.1595, R:0.0105)
Batch 250/537: Loss=1.1152 (C:1.1152, R:0.0105)
Batch 275/537: Loss=1.1588 (C:1.1588, R:0.0105)
Batch 300/537: Loss=1.1313 (C:1.1313, R:0.0105)
Batch 325/537: Loss=1.1516 (C:1.1516, R:0.0105)
Batch 350/537: Loss=1.1345 (C:1.1345, R:0.0105)
Batch 375/537: Loss=1.1324 (C:1.1324, R:0.0105)
Batch 400/537: Loss=1.1746 (C:1.1746, R:0.0105)
Batch 425/537: Loss=1.1407 (C:1.1407, R:0.0105)
Batch 450/537: Loss=1.1668 (C:1.1668, R:0.0105)
Batch 475/537: Loss=1.1627 (C:1.1627, R:0.0105)
Batch 500/537: Loss=1.1749 (C:1.1749, R:0.0105)
Batch 525/537: Loss=1.1647 (C:1.1647, R:0.0105)

============================================================
Epoch 37/300 completed in 27.5s
Train: Loss=1.1404 (C:1.1404, R:0.0105) Ratio=4.43x
Val:   Loss=1.3147 (C:1.3147, R:0.0104) Ratio=3.03x
Reconstruction weight: 0.105
✅ New best model saved (Val Loss: 1.3147)
============================================================

Epoch 38 Training
----------------------------------------
Batch   0/537: Loss=1.1046 (C:1.1046, R:0.0105)
Batch  25/537: Loss=1.1065 (C:1.1065, R:0.0105)
Batch  50/537: Loss=1.1297 (C:1.1297, R:0.0105)
Batch  75/537: Loss=1.1380 (C:1.1380, R:0.0105)
Batch 100/537: Loss=1.1234 (C:1.1234, R:0.0105)
Batch 125/537: Loss=1.1506 (C:1.1506, R:0.0105)
Batch 150/537: Loss=1.1258 (C:1.1258, R:0.0105)
Batch 175/537: Loss=1.1123 (C:1.1123, R:0.0105)
Batch 200/537: Loss=1.1144 (C:1.1144, R:0.0105)
Batch 225/537: Loss=1.1399 (C:1.1399, R:0.0105)
Batch 250/537: Loss=1.1108 (C:1.1108, R:0.0105)
Batch 275/537: Loss=1.2074 (C:1.2074, R:0.0105)
Batch 300/537: Loss=1.1233 (C:1.1233, R:0.0105)
Batch 325/537: Loss=1.0857 (C:1.0857, R:0.0105)
Batch 350/537: Loss=1.1407 (C:1.1407, R:0.0105)
Batch 375/537: Loss=1.1158 (C:1.1158, R:0.0105)
Batch 400/537: Loss=1.1267 (C:1.1267, R:0.0105)
Batch 425/537: Loss=1.1648 (C:1.1648, R:0.0105)
Batch 450/537: Loss=1.1199 (C:1.1199, R:0.0105)
Batch 475/537: Loss=1.2066 (C:1.2066, R:0.0105)
Batch 500/537: Loss=1.1161 (C:1.1161, R:0.0105)
Batch 525/537: Loss=1.1535 (C:1.1535, R:0.0105)

============================================================
Epoch 38/300 completed in 21.6s
Train: Loss=1.1383 (C:1.1383, R:0.0105) Ratio=4.47x
Val:   Loss=1.3247 (C:1.3247, R:0.0104) Ratio=3.00x
Reconstruction weight: 0.120
No improvement for 1 epochs
============================================================

Epoch 39 Training
----------------------------------------
Batch   0/537: Loss=1.0910 (C:1.0910, R:0.0105)
Batch  25/537: Loss=1.1328 (C:1.1328, R:0.0105)
Batch  50/537: Loss=1.0925 (C:1.0925, R:0.0105)
Batch  75/537: Loss=1.1854 (C:1.1854, R:0.0105)
Batch 100/537: Loss=1.1144 (C:1.1144, R:0.0105)
Batch 125/537: Loss=1.1592 (C:1.1592, R:0.0105)
Batch 150/537: Loss=1.0728 (C:1.0728, R:0.0105)
Batch 175/537: Loss=1.1275 (C:1.1275, R:0.0105)
Batch 200/537: Loss=1.1392 (C:1.1392, R:0.0105)
Batch 225/537: Loss=1.1382 (C:1.1382, R:0.0105)
Batch 250/537: Loss=1.1592 (C:1.1592, R:0.0105)
Batch 275/537: Loss=1.1135 (C:1.1135, R:0.0105)
Batch 300/537: Loss=1.1850 (C:1.1850, R:0.0105)
Batch 325/537: Loss=1.1744 (C:1.1744, R:0.0105)
Batch 350/537: Loss=1.1071 (C:1.1071, R:0.0105)
Batch 375/537: Loss=1.1414 (C:1.1414, R:0.0105)
Batch 400/537: Loss=1.1260 (C:1.1260, R:0.0105)
Batch 425/537: Loss=1.1707 (C:1.1707, R:0.0105)
Batch 450/537: Loss=1.1701 (C:1.1701, R:0.0105)
Batch 475/537: Loss=1.1782 (C:1.1782, R:0.0105)
Batch 500/537: Loss=1.1879 (C:1.1879, R:0.0106)
Batch 525/537: Loss=1.1242 (C:1.1242, R:0.0105)

============================================================
Epoch 39/300 completed in 22.1s
Train: Loss=1.1346 (C:1.1346, R:0.0105) Ratio=4.52x
Val:   Loss=1.3245 (C:1.3245, R:0.0104) Ratio=3.03x
Reconstruction weight: 0.135
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 40
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.501 ± 0.793
    Neg distances: 3.284 ± 1.452
    Separation ratio: 6.55x
    Gap: -5.667
    ✅ Excellent global separation!

Epoch 40 Training
----------------------------------------
Batch   0/537: Loss=1.0429 (C:1.0429, R:0.0105)
Batch  25/537: Loss=1.0884 (C:1.0884, R:0.0105)
Batch  50/537: Loss=1.0175 (C:1.0175, R:0.0105)
Batch  75/537: Loss=1.0259 (C:1.0259, R:0.0105)
Batch 100/537: Loss=1.1311 (C:1.1311, R:0.0105)
Batch 125/537: Loss=1.1048 (C:1.1048, R:0.0105)
Batch 150/537: Loss=1.0939 (C:1.0939, R:0.0105)
Batch 175/537: Loss=1.0754 (C:1.0754, R:0.0105)
Batch 200/537: Loss=1.1131 (C:1.1131, R:0.0105)
Batch 225/537: Loss=1.1314 (C:1.1314, R:0.0105)
Batch 250/537: Loss=1.1131 (C:1.1131, R:0.0105)
Batch 275/537: Loss=1.0701 (C:1.0701, R:0.0105)
Batch 300/537: Loss=1.1114 (C:1.1114, R:0.0105)
Batch 325/537: Loss=1.0901 (C:1.0901, R:0.0105)
Batch 350/537: Loss=1.0568 (C:1.0568, R:0.0106)
Batch 375/537: Loss=1.1248 (C:1.1248, R:0.0105)
Batch 400/537: Loss=1.0788 (C:1.0788, R:0.0105)
Batch 425/537: Loss=1.0798 (C:1.0798, R:0.0105)
Batch 450/537: Loss=1.1059 (C:1.1059, R:0.0105)
Batch 475/537: Loss=1.0557 (C:1.0557, R:0.0105)
Batch 500/537: Loss=1.0754 (C:1.0754, R:0.0105)
Batch 525/537: Loss=1.1031 (C:1.1031, R:0.0105)

============================================================
Epoch 40/300 completed in 27.9s
Train: Loss=1.0723 (C:1.0723, R:0.0105) Ratio=4.49x
Val:   Loss=1.2664 (C:1.2664, R:0.0104) Ratio=2.97x
Reconstruction weight: 0.150
✅ New best model saved (Val Loss: 1.2664)
Checkpoint saved at epoch 40
============================================================

Epoch 41 Training
----------------------------------------
Batch   0/537: Loss=1.0400 (C:1.0400, R:0.0105)
Batch  25/537: Loss=1.0601 (C:1.0601, R:0.0105)
Batch  50/537: Loss=1.0417 (C:1.0417, R:0.0105)
Batch  75/537: Loss=1.0189 (C:1.0189, R:0.0105)
Batch 100/537: Loss=1.0885 (C:1.0885, R:0.0105)
Batch 125/537: Loss=1.0436 (C:1.0436, R:0.0105)
Batch 150/537: Loss=1.0656 (C:1.0656, R:0.0105)
Batch 175/537: Loss=0.9924 (C:0.9924, R:0.0105)
Batch 200/537: Loss=1.1220 (C:1.1220, R:0.0105)
Batch 225/537: Loss=1.0801 (C:1.0801, R:0.0105)
Batch 250/537: Loss=1.1026 (C:1.1026, R:0.0105)
Batch 275/537: Loss=1.0476 (C:1.0476, R:0.0105)
Batch 300/537: Loss=1.0275 (C:1.0275, R:0.0105)
Batch 325/537: Loss=1.0617 (C:1.0617, R:0.0105)
Batch 350/537: Loss=1.1016 (C:1.1016, R:0.0105)
Batch 375/537: Loss=1.1236 (C:1.1236, R:0.0105)
Batch 400/537: Loss=1.1346 (C:1.1346, R:0.0105)
Batch 425/537: Loss=1.0906 (C:1.0906, R:0.0105)
Batch 450/537: Loss=1.0595 (C:1.0595, R:0.0105)
Batch 475/537: Loss=1.1309 (C:1.1309, R:0.0105)
Batch 500/537: Loss=1.1156 (C:1.1156, R:0.0105)
Batch 525/537: Loss=1.0578 (C:1.0578, R:0.0105)

============================================================
Epoch 41/300 completed in 21.1s
Train: Loss=1.0683 (C:1.0683, R:0.0105) Ratio=4.55x
Val:   Loss=1.2646 (C:1.2646, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.165
✅ New best model saved (Val Loss: 1.2646)
============================================================

Epoch 42 Training
----------------------------------------
Batch   0/537: Loss=1.0696 (C:1.0696, R:0.0105)
Batch  25/537: Loss=1.0840 (C:1.0840, R:0.0105)
Batch  50/537: Loss=1.0400 (C:1.0400, R:0.0105)
Batch  75/537: Loss=1.1064 (C:1.1064, R:0.0105)
Batch 100/537: Loss=1.0401 (C:1.0401, R:0.0105)
Batch 125/537: Loss=1.0442 (C:1.0442, R:0.0105)
Batch 150/537: Loss=1.1088 (C:1.1088, R:0.0105)
Batch 175/537: Loss=1.0478 (C:1.0478, R:0.0105)
Batch 200/537: Loss=1.0456 (C:1.0456, R:0.0105)
Batch 225/537: Loss=1.0413 (C:1.0413, R:0.0105)
Batch 250/537: Loss=1.0550 (C:1.0550, R:0.0105)
Batch 275/537: Loss=1.1199 (C:1.1199, R:0.0106)
Batch 300/537: Loss=1.0877 (C:1.0877, R:0.0106)
Batch 325/537: Loss=1.0527 (C:1.0527, R:0.0105)
Batch 350/537: Loss=1.0868 (C:1.0868, R:0.0105)
Batch 375/537: Loss=1.0590 (C:1.0590, R:0.0105)
Batch 400/537: Loss=1.0779 (C:1.0779, R:0.0105)
Batch 425/537: Loss=1.0682 (C:1.0682, R:0.0106)
Batch 450/537: Loss=1.0205 (C:1.0205, R:0.0105)
Batch 475/537: Loss=1.0730 (C:1.0730, R:0.0105)
Batch 500/537: Loss=1.0934 (C:1.0934, R:0.0105)
Batch 525/537: Loss=1.0683 (C:1.0683, R:0.0106)

============================================================
Epoch 42/300 completed in 20.9s
Train: Loss=1.0675 (C:1.0675, R:0.0105) Ratio=4.56x
Val:   Loss=1.2656 (C:1.2656, R:0.0104) Ratio=3.02x
Reconstruction weight: 0.180
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 43
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.491 ± 0.798
    Neg distances: 3.373 ± 1.476
    Separation ratio: 6.87x
    Gap: -5.713
    ✅ Excellent global separation!

Epoch 43 Training
----------------------------------------
Batch   0/537: Loss=0.9831 (C:0.9831, R:0.0105)
Batch  25/537: Loss=1.0851 (C:1.0851, R:0.0105)
Batch  50/537: Loss=1.0445 (C:1.0445, R:0.0105)
Batch  75/537: Loss=1.0533 (C:1.0533, R:0.0105)
Batch 100/537: Loss=1.0374 (C:1.0374, R:0.0105)
Batch 125/537: Loss=1.0624 (C:1.0624, R:0.0105)
Batch 150/537: Loss=1.0183 (C:1.0183, R:0.0105)
Batch 175/537: Loss=1.0083 (C:1.0083, R:0.0105)
Batch 200/537: Loss=1.0579 (C:1.0579, R:0.0105)
Batch 225/537: Loss=1.0876 (C:1.0876, R:0.0105)
Batch 250/537: Loss=1.0266 (C:1.0266, R:0.0105)
Batch 275/537: Loss=1.0297 (C:1.0297, R:0.0105)
Batch 300/537: Loss=1.0689 (C:1.0689, R:0.0105)
Batch 325/537: Loss=0.9825 (C:0.9825, R:0.0105)
Batch 350/537: Loss=1.0248 (C:1.0248, R:0.0105)
Batch 375/537: Loss=1.0808 (C:1.0808, R:0.0105)
Batch 400/537: Loss=1.0288 (C:1.0288, R:0.0105)
Batch 425/537: Loss=1.0399 (C:1.0399, R:0.0105)
Batch 450/537: Loss=1.0547 (C:1.0547, R:0.0105)
Batch 475/537: Loss=1.0291 (C:1.0291, R:0.0105)
Batch 500/537: Loss=1.0624 (C:1.0624, R:0.0105)
Batch 525/537: Loss=1.0408 (C:1.0408, R:0.0105)

============================================================
Epoch 43/300 completed in 26.6s
Train: Loss=1.0351 (C:1.0351, R:0.0105) Ratio=4.59x
Val:   Loss=1.2120 (C:1.2120, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.195
✅ New best model saved (Val Loss: 1.2120)
============================================================

Epoch 44 Training
----------------------------------------
Batch   0/537: Loss=1.0054 (C:1.0054, R:0.0105)
Batch  25/537: Loss=1.0084 (C:1.0084, R:0.0105)
Batch  50/537: Loss=1.0248 (C:1.0248, R:0.0105)
Batch  75/537: Loss=1.0612 (C:1.0612, R:0.0105)
Batch 100/537: Loss=1.0322 (C:1.0322, R:0.0105)
Batch 125/537: Loss=1.0151 (C:1.0151, R:0.0105)
Batch 150/537: Loss=1.0217 (C:1.0217, R:0.0105)
Batch 175/537: Loss=1.0471 (C:1.0471, R:0.0105)
Batch 200/537: Loss=1.0358 (C:1.0358, R:0.0105)
Batch 225/537: Loss=1.0207 (C:1.0207, R:0.0105)
Batch 250/537: Loss=1.0636 (C:1.0636, R:0.0105)
Batch 275/537: Loss=1.0267 (C:1.0267, R:0.0105)
Batch 300/537: Loss=1.0641 (C:1.0641, R:0.0105)
Batch 325/537: Loss=1.0544 (C:1.0544, R:0.0105)
Batch 350/537: Loss=0.9700 (C:0.9700, R:0.0105)
Batch 375/537: Loss=0.9973 (C:0.9973, R:0.0105)
Batch 400/537: Loss=1.0030 (C:1.0030, R:0.0105)
Batch 425/537: Loss=1.0897 (C:1.0897, R:0.0105)
Batch 450/537: Loss=1.0353 (C:1.0353, R:0.0105)
Batch 475/537: Loss=0.9969 (C:0.9969, R:0.0105)
Batch 500/537: Loss=1.0113 (C:1.0113, R:0.0105)
Batch 525/537: Loss=1.0337 (C:1.0337, R:0.0105)

============================================================
Epoch 44/300 completed in 21.0s
Train: Loss=1.0323 (C:1.0323, R:0.0105) Ratio=4.71x
Val:   Loss=1.2275 (C:1.2275, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.210
No improvement for 1 epochs
============================================================

Epoch 45 Training
----------------------------------------
Batch   0/537: Loss=1.0393 (C:1.0393, R:0.0105)
Batch  25/537: Loss=0.9888 (C:0.9888, R:0.0105)
Batch  50/537: Loss=1.0222 (C:1.0222, R:0.0105)
Batch  75/537: Loss=0.9627 (C:0.9627, R:0.0105)
Batch 100/537: Loss=0.9969 (C:0.9969, R:0.0105)
Batch 125/537: Loss=1.0378 (C:1.0378, R:0.0105)
Batch 150/537: Loss=0.9901 (C:0.9901, R:0.0105)
Batch 175/537: Loss=1.0185 (C:1.0185, R:0.0105)
Batch 200/537: Loss=1.0490 (C:1.0490, R:0.0105)
Batch 225/537: Loss=1.0623 (C:1.0623, R:0.0105)
Batch 250/537: Loss=1.0397 (C:1.0397, R:0.0105)
Batch 275/537: Loss=1.0186 (C:1.0186, R:0.0106)
Batch 300/537: Loss=1.0346 (C:1.0346, R:0.0105)
Batch 325/537: Loss=1.0185 (C:1.0185, R:0.0105)
Batch 350/537: Loss=1.0066 (C:1.0066, R:0.0105)
Batch 375/537: Loss=1.0389 (C:1.0389, R:0.0105)
Batch 400/537: Loss=0.9919 (C:0.9919, R:0.0105)
Batch 425/537: Loss=1.0397 (C:1.0397, R:0.0105)
Batch 450/537: Loss=1.0815 (C:1.0815, R:0.0105)
Batch 475/537: Loss=1.0396 (C:1.0396, R:0.0105)
Batch 500/537: Loss=1.0098 (C:1.0098, R:0.0105)
Batch 525/537: Loss=1.0238 (C:1.0238, R:0.0105)

============================================================
Epoch 45/300 completed in 21.9s
Train: Loss=1.0291 (C:1.0291, R:0.0105) Ratio=4.67x
Val:   Loss=1.2206 (C:1.2206, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.225
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 46
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.505 ± 0.833
    Neg distances: 3.477 ± 1.518
    Separation ratio: 6.88x
    Gap: -5.879
    ✅ Excellent global separation!

Epoch 46 Training
----------------------------------------
Batch   0/537: Loss=0.9598 (C:0.9598, R:0.0105)
Batch  25/537: Loss=0.9960 (C:0.9960, R:0.0105)
Batch  50/537: Loss=0.9880 (C:0.9880, R:0.0105)
Batch  75/537: Loss=0.9688 (C:0.9688, R:0.0105)
Batch 100/537: Loss=1.0458 (C:1.0458, R:0.0106)
Batch 125/537: Loss=0.9795 (C:0.9795, R:0.0105)
Batch 150/537: Loss=1.0362 (C:1.0362, R:0.0105)
Batch 175/537: Loss=1.0785 (C:1.0785, R:0.0105)
Batch 200/537: Loss=1.0700 (C:1.0700, R:0.0105)
Batch 225/537: Loss=1.0234 (C:1.0234, R:0.0106)
Batch 250/537: Loss=1.0276 (C:1.0276, R:0.0105)
Batch 275/537: Loss=0.9907 (C:0.9907, R:0.0105)
Batch 300/537: Loss=1.0084 (C:1.0084, R:0.0105)
Batch 325/537: Loss=1.0204 (C:1.0204, R:0.0105)
Batch 350/537: Loss=1.0235 (C:1.0235, R:0.0105)
Batch 375/537: Loss=1.0483 (C:1.0483, R:0.0105)
Batch 400/537: Loss=1.0130 (C:1.0130, R:0.0105)
Batch 425/537: Loss=1.0174 (C:1.0174, R:0.0105)
Batch 450/537: Loss=0.9766 (C:0.9766, R:0.0105)
Batch 475/537: Loss=1.0023 (C:1.0023, R:0.0105)
Batch 500/537: Loss=1.0301 (C:1.0301, R:0.0105)
Batch 525/537: Loss=1.0097 (C:1.0097, R:0.0105)

============================================================
Epoch 46/300 completed in 27.2s
Train: Loss=1.0092 (C:1.0092, R:0.0105) Ratio=4.68x
Val:   Loss=1.2152 (C:1.2152, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.240
No improvement for 3 epochs
============================================================

Epoch 47 Training
----------------------------------------
Batch   0/537: Loss=1.0403 (C:1.0403, R:0.0105)
Batch  25/537: Loss=1.0209 (C:1.0209, R:0.0105)
Batch  50/537: Loss=0.9749 (C:0.9749, R:0.0105)
Batch  75/537: Loss=1.0239 (C:1.0239, R:0.0105)
Batch 100/537: Loss=1.0445 (C:1.0445, R:0.0105)
Batch 125/537: Loss=0.9626 (C:0.9626, R:0.0106)
Batch 150/537: Loss=0.9816 (C:0.9816, R:0.0105)
Batch 175/537: Loss=0.9839 (C:0.9839, R:0.0105)
Batch 200/537: Loss=1.0411 (C:1.0411, R:0.0105)
Batch 225/537: Loss=0.9916 (C:0.9916, R:0.0105)
Batch 250/537: Loss=0.9830 (C:0.9830, R:0.0105)
Batch 275/537: Loss=0.9939 (C:0.9939, R:0.0105)
Batch 300/537: Loss=0.9890 (C:0.9890, R:0.0105)
Batch 325/537: Loss=1.0097 (C:1.0097, R:0.0105)
Batch 350/537: Loss=1.0367 (C:1.0367, R:0.0105)
Batch 375/537: Loss=1.0305 (C:1.0305, R:0.0105)
Batch 400/537: Loss=1.0407 (C:1.0407, R:0.0105)
Batch 425/537: Loss=0.9566 (C:0.9566, R:0.0105)
Batch 450/537: Loss=1.0006 (C:1.0006, R:0.0105)
Batch 475/537: Loss=1.0182 (C:1.0182, R:0.0105)
Batch 500/537: Loss=1.0019 (C:1.0019, R:0.0105)
Batch 525/537: Loss=0.9861 (C:0.9861, R:0.0105)

============================================================
Epoch 47/300 completed in 21.4s
Train: Loss=1.0059 (C:1.0059, R:0.0105) Ratio=4.67x
Val:   Loss=1.2159 (C:1.2159, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.255
No improvement for 4 epochs
============================================================

Epoch 48 Training
----------------------------------------
Batch   0/537: Loss=0.9695 (C:0.9695, R:0.0105)
Batch  25/537: Loss=0.9572 (C:0.9572, R:0.0106)
Batch  50/537: Loss=0.9619 (C:0.9619, R:0.0105)
Batch  75/537: Loss=1.0439 (C:1.0439, R:0.0105)
Batch 100/537: Loss=0.9684 (C:0.9684, R:0.0105)
Batch 125/537: Loss=0.9794 (C:0.9794, R:0.0105)
Batch 150/537: Loss=1.0455 (C:1.0455, R:0.0105)
Batch 175/537: Loss=0.9861 (C:0.9861, R:0.0105)
Batch 200/537: Loss=0.9916 (C:0.9916, R:0.0105)
Batch 225/537: Loss=1.0048 (C:1.0048, R:0.0105)
Batch 250/537: Loss=1.0019 (C:1.0019, R:0.0105)
Batch 275/537: Loss=1.0370 (C:1.0370, R:0.0105)
Batch 300/537: Loss=1.0240 (C:1.0240, R:0.0105)
Batch 325/537: Loss=0.9979 (C:0.9979, R:0.0105)
Batch 350/537: Loss=0.9863 (C:0.9863, R:0.0105)
Batch 375/537: Loss=0.9932 (C:0.9932, R:0.0105)
Batch 400/537: Loss=0.9712 (C:0.9712, R:0.0105)
Batch 425/537: Loss=0.9907 (C:0.9907, R:0.0105)
Batch 450/537: Loss=1.0528 (C:1.0528, R:0.0105)
Batch 475/537: Loss=1.0196 (C:1.0196, R:0.0105)
Batch 500/537: Loss=1.0448 (C:1.0448, R:0.0105)
Batch 525/537: Loss=0.9804 (C:0.9804, R:0.0105)

============================================================
Epoch 48/300 completed in 22.0s
Train: Loss=1.0035 (C:1.0035, R:0.0105) Ratio=4.74x
Val:   Loss=1.2156 (C:1.2156, R:0.0104) Ratio=3.03x
Reconstruction weight: 0.270
No improvement for 5 epochs
============================================================

🌍 Updating global dataset at epoch 49
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.499 ± 0.849
    Neg distances: 3.547 ± 1.534
    Separation ratio: 7.11x
    Gap: -5.898
    ✅ Excellent global separation!

Epoch 49 Training
----------------------------------------
Batch   0/537: Loss=0.9316 (C:0.9316, R:0.0105)
Batch  25/537: Loss=0.9422 (C:0.9422, R:0.0105)
Batch  50/537: Loss=0.9934 (C:0.9934, R:0.0105)
Batch  75/537: Loss=0.9954 (C:0.9954, R:0.0105)
Batch 100/537: Loss=1.0028 (C:1.0028, R:0.0105)
Batch 125/537: Loss=0.9445 (C:0.9445, R:0.0105)
Batch 150/537: Loss=0.9673 (C:0.9673, R:0.0106)
Batch 175/537: Loss=1.0105 (C:1.0105, R:0.0105)
Batch 200/537: Loss=0.9688 (C:0.9688, R:0.0105)
Batch 225/537: Loss=0.9165 (C:0.9165, R:0.0105)
Batch 250/537: Loss=0.9298 (C:0.9298, R:0.0105)
Batch 275/537: Loss=1.0006 (C:1.0006, R:0.0105)
Batch 300/537: Loss=0.9591 (C:0.9591, R:0.0105)
Batch 325/537: Loss=0.9550 (C:0.9550, R:0.0105)
Batch 350/537: Loss=0.9963 (C:0.9963, R:0.0105)
Batch 375/537: Loss=0.9955 (C:0.9955, R:0.0105)
Batch 400/537: Loss=0.8988 (C:0.8988, R:0.0105)
Batch 425/537: Loss=1.0253 (C:1.0253, R:0.0105)
Batch 450/537: Loss=1.0417 (C:1.0417, R:0.0105)
Batch 475/537: Loss=0.9435 (C:0.9435, R:0.0105)
Batch 500/537: Loss=0.9660 (C:0.9660, R:0.0105)
Batch 525/537: Loss=0.9615 (C:0.9615, R:0.0105)

============================================================
Epoch 49/300 completed in 28.3s
Train: Loss=0.9798 (C:0.9798, R:0.0105) Ratio=4.82x
Val:   Loss=1.1919 (C:1.1919, R:0.0104) Ratio=3.03x
Reconstruction weight: 0.285
✅ New best model saved (Val Loss: 1.1919)
============================================================

Epoch 50 Training
----------------------------------------
Batch   0/537: Loss=0.9778 (C:0.9778, R:0.0105)
Batch  25/537: Loss=0.9385 (C:0.9385, R:0.0105)
Batch  50/537: Loss=0.9923 (C:0.9923, R:0.0105)
Batch  75/537: Loss=0.9816 (C:0.9816, R:0.0105)
Batch 100/537: Loss=0.9926 (C:0.9926, R:0.0105)
Batch 125/537: Loss=0.9677 (C:0.9677, R:0.0105)
Batch 150/537: Loss=0.9395 (C:0.9395, R:0.0105)
Batch 175/537: Loss=0.9268 (C:0.9268, R:0.0105)
Batch 200/537: Loss=0.9626 (C:0.9626, R:0.0105)
Batch 225/537: Loss=0.9797 (C:0.9797, R:0.0105)
Batch 250/537: Loss=0.9355 (C:0.9355, R:0.0105)
Batch 275/537: Loss=0.9401 (C:0.9401, R:0.0105)
Batch 300/537: Loss=1.0389 (C:1.0389, R:0.0106)
Batch 325/537: Loss=0.9965 (C:0.9965, R:0.0105)
Batch 350/537: Loss=0.9495 (C:0.9495, R:0.0105)
Batch 375/537: Loss=0.9887 (C:0.9887, R:0.0105)
Batch 400/537: Loss=1.0233 (C:1.0233, R:0.0105)
Batch 425/537: Loss=1.0191 (C:1.0191, R:0.0105)
Batch 450/537: Loss=0.9436 (C:0.9436, R:0.0105)
Batch 475/537: Loss=0.8876 (C:0.8876, R:0.0105)
Batch 500/537: Loss=0.9256 (C:0.9256, R:0.0105)
Batch 525/537: Loss=0.9943 (C:0.9943, R:0.0105)

============================================================
Epoch 50/300 completed in 24.3s
Train: Loss=0.9744 (C:0.9744, R:0.0105) Ratio=4.80x
Val:   Loss=1.1858 (C:1.1858, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.1858)
============================================================

Epoch 51 Training
----------------------------------------
Batch   0/537: Loss=0.9059 (C:0.9059, R:0.0105)
Batch  25/537: Loss=1.0104 (C:1.0104, R:0.0106)
Batch  50/537: Loss=1.0139 (C:1.0139, R:0.0106)
Batch  75/537: Loss=0.9444 (C:0.9444, R:0.0105)
Batch 100/537: Loss=0.9696 (C:0.9696, R:0.0105)
Batch 125/537: Loss=0.9454 (C:0.9454, R:0.0105)
Batch 150/537: Loss=0.9431 (C:0.9431, R:0.0105)
Batch 175/537: Loss=0.9572 (C:0.9572, R:0.0105)
Batch 200/537: Loss=0.9725 (C:0.9725, R:0.0105)
Batch 225/537: Loss=0.9751 (C:0.9751, R:0.0105)
Batch 250/537: Loss=0.9456 (C:0.9456, R:0.0105)
Batch 275/537: Loss=0.9598 (C:0.9598, R:0.0105)
Batch 300/537: Loss=0.9575 (C:0.9575, R:0.0105)
Batch 325/537: Loss=0.9297 (C:0.9297, R:0.0105)
Batch 350/537: Loss=0.9893 (C:0.9893, R:0.0105)
Batch 375/537: Loss=1.0069 (C:1.0069, R:0.0105)
Batch 400/537: Loss=1.0258 (C:1.0258, R:0.0105)
Batch 425/537: Loss=0.9011 (C:0.9011, R:0.0105)
Batch 450/537: Loss=0.9612 (C:0.9612, R:0.0105)
Batch 475/537: Loss=0.9248 (C:0.9248, R:0.0105)
Batch 500/537: Loss=1.0145 (C:1.0145, R:0.0105)
Batch 525/537: Loss=0.9893 (C:0.9893, R:0.0105)

============================================================
Epoch 51/300 completed in 21.3s
Train: Loss=0.9701 (C:0.9701, R:0.0105) Ratio=4.89x
Val:   Loss=1.1837 (C:1.1837, R:0.0104) Ratio=3.03x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.1837)
============================================================

🌍 Updating global dataset at epoch 52
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.509 ± 0.866
    Neg distances: 3.570 ± 1.538
    Separation ratio: 7.01x
    Gap: -5.999
    ✅ Excellent global separation!

Epoch 52 Training
----------------------------------------
Batch   0/537: Loss=0.9743 (C:0.9743, R:0.0105)
Batch  25/537: Loss=0.9595 (C:0.9595, R:0.0105)
Batch  50/537: Loss=0.9299 (C:0.9299, R:0.0106)
Batch  75/537: Loss=1.0144 (C:1.0144, R:0.0106)
Batch 100/537: Loss=0.9121 (C:0.9121, R:0.0105)
Batch 125/537: Loss=0.9478 (C:0.9478, R:0.0105)
Batch 150/537: Loss=0.9900 (C:0.9900, R:0.0105)
Batch 175/537: Loss=0.9665 (C:0.9665, R:0.0105)
Batch 200/537: Loss=0.9756 (C:0.9756, R:0.0105)
Batch 225/537: Loss=0.9773 (C:0.9773, R:0.0106)
Batch 250/537: Loss=0.9780 (C:0.9780, R:0.0105)
Batch 275/537: Loss=0.9622 (C:0.9622, R:0.0105)
Batch 300/537: Loss=0.9786 (C:0.9786, R:0.0105)
Batch 325/537: Loss=0.9184 (C:0.9184, R:0.0105)
Batch 350/537: Loss=0.9699 (C:0.9699, R:0.0105)
Batch 375/537: Loss=0.9519 (C:0.9519, R:0.0105)
Batch 400/537: Loss=1.0324 (C:1.0324, R:0.0105)
Batch 425/537: Loss=0.9891 (C:0.9891, R:0.0105)
Batch 450/537: Loss=0.9768 (C:0.9768, R:0.0105)
Batch 475/537: Loss=0.9568 (C:0.9568, R:0.0105)
Batch 500/537: Loss=0.9874 (C:0.9874, R:0.0105)
Batch 525/537: Loss=0.9679 (C:0.9679, R:0.0105)

============================================================
Epoch 52/300 completed in 27.7s
Train: Loss=0.9680 (C:0.9680, R:0.0105) Ratio=4.86x
Val:   Loss=1.1938 (C:1.1938, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

Epoch 53 Training
----------------------------------------
Batch   0/537: Loss=0.8909 (C:0.8909, R:0.0105)
Batch  25/537: Loss=0.9289 (C:0.9289, R:0.0105)
Batch  50/537: Loss=0.9709 (C:0.9709, R:0.0105)
Batch  75/537: Loss=0.9388 (C:0.9388, R:0.0105)
Batch 100/537: Loss=0.9547 (C:0.9547, R:0.0105)
Batch 125/537: Loss=0.9416 (C:0.9416, R:0.0105)
Batch 150/537: Loss=0.9691 (C:0.9691, R:0.0105)
Batch 175/537: Loss=0.9483 (C:0.9483, R:0.0105)
Batch 200/537: Loss=0.9627 (C:0.9627, R:0.0105)
Batch 225/537: Loss=0.9516 (C:0.9516, R:0.0105)
Batch 250/537: Loss=0.9124 (C:0.9124, R:0.0105)
Batch 275/537: Loss=0.9167 (C:0.9167, R:0.0105)
Batch 300/537: Loss=0.9566 (C:0.9566, R:0.0105)
Batch 325/537: Loss=0.9371 (C:0.9371, R:0.0105)
Batch 350/537: Loss=0.9874 (C:0.9874, R:0.0105)
Batch 375/537: Loss=0.9556 (C:0.9556, R:0.0105)
Batch 400/537: Loss=1.0560 (C:1.0560, R:0.0105)
Batch 425/537: Loss=0.9453 (C:0.9453, R:0.0105)
Batch 450/537: Loss=0.9341 (C:0.9341, R:0.0106)
Batch 475/537: Loss=0.9502 (C:0.9502, R:0.0105)
Batch 500/537: Loss=0.9774 (C:0.9774, R:0.0105)
Batch 525/537: Loss=0.9686 (C:0.9686, R:0.0105)

============================================================
Epoch 53/300 completed in 21.5s
Train: Loss=0.9646 (C:0.9646, R:0.0105) Ratio=4.88x
Val:   Loss=1.1727 (C:1.1727, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.1727)
============================================================

Epoch 54 Training
----------------------------------------
Batch   0/537: Loss=0.9762 (C:0.9762, R:0.0105)
Batch  25/537: Loss=0.9577 (C:0.9577, R:0.0105)
Batch  50/537: Loss=1.0145 (C:1.0145, R:0.0105)
Batch  75/537: Loss=0.9554 (C:0.9554, R:0.0105)
Batch 100/537: Loss=0.9762 (C:0.9762, R:0.0105)
Batch 125/537: Loss=0.9360 (C:0.9360, R:0.0105)
Batch 150/537: Loss=0.9226 (C:0.9226, R:0.0105)
Batch 175/537: Loss=0.9811 (C:0.9811, R:0.0105)
Batch 200/537: Loss=0.9588 (C:0.9588, R:0.0105)
Batch 225/537: Loss=0.9551 (C:0.9551, R:0.0105)
Batch 250/537: Loss=0.9487 (C:0.9487, R:0.0105)
Batch 275/537: Loss=0.9163 (C:0.9163, R:0.0105)
Batch 300/537: Loss=0.9430 (C:0.9430, R:0.0105)
Batch 325/537: Loss=0.9898 (C:0.9898, R:0.0105)
Batch 350/537: Loss=0.9948 (C:0.9948, R:0.0105)
Batch 375/537: Loss=0.9647 (C:0.9647, R:0.0105)
Batch 400/537: Loss=0.9496 (C:0.9496, R:0.0105)
Batch 425/537: Loss=0.9699 (C:0.9699, R:0.0105)
Batch 450/537: Loss=0.9219 (C:0.9219, R:0.0105)
Batch 475/537: Loss=0.9688 (C:0.9688, R:0.0105)
Batch 500/537: Loss=0.9760 (C:0.9760, R:0.0105)
Batch 525/537: Loss=0.9439 (C:0.9439, R:0.0105)

============================================================
Epoch 54/300 completed in 21.5s
Train: Loss=0.9629 (C:0.9629, R:0.0105) Ratio=4.95x
Val:   Loss=1.1836 (C:1.1836, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 55
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.488 ± 0.821
    Neg distances: 3.636 ± 1.548
    Separation ratio: 7.45x
    Gap: -6.158
    ✅ Excellent global separation!

Epoch 55 Training
----------------------------------------
Batch   0/537: Loss=0.8746 (C:0.8746, R:0.0105)
Batch  25/537: Loss=0.8992 (C:0.8992, R:0.0105)
Batch  50/537: Loss=0.9188 (C:0.9188, R:0.0105)
Batch  75/537: Loss=0.8556 (C:0.8556, R:0.0105)
Batch 100/537: Loss=0.9160 (C:0.9160, R:0.0105)
Batch 125/537: Loss=0.9253 (C:0.9253, R:0.0105)
Batch 150/537: Loss=0.9554 (C:0.9554, R:0.0105)
Batch 175/537: Loss=0.9442 (C:0.9442, R:0.0105)
Batch 200/537: Loss=0.9344 (C:0.9344, R:0.0105)
Batch 225/537: Loss=0.9032 (C:0.9032, R:0.0105)
Batch 250/537: Loss=0.9664 (C:0.9664, R:0.0105)
Batch 275/537: Loss=0.9365 (C:0.9365, R:0.0105)
Batch 300/537: Loss=0.9831 (C:0.9831, R:0.0105)
Batch 325/537: Loss=0.9677 (C:0.9677, R:0.0105)
Batch 350/537: Loss=0.9281 (C:0.9281, R:0.0106)
Batch 375/537: Loss=0.9325 (C:0.9325, R:0.0105)
Batch 400/537: Loss=0.9818 (C:0.9818, R:0.0105)
Batch 425/537: Loss=0.9445 (C:0.9445, R:0.0105)
Batch 450/537: Loss=0.9546 (C:0.9546, R:0.0105)
Batch 475/537: Loss=0.9445 (C:0.9445, R:0.0105)
Batch 500/537: Loss=0.9749 (C:0.9749, R:0.0105)
Batch 525/537: Loss=0.9574 (C:0.9574, R:0.0105)

============================================================
Epoch 55/300 completed in 28.2s
Train: Loss=0.9322 (C:0.9322, R:0.0105) Ratio=4.86x
Val:   Loss=1.1507 (C:1.1507, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.1507)
============================================================

Epoch 56 Training
----------------------------------------
Batch   0/537: Loss=0.8889 (C:0.8889, R:0.0105)
Batch  25/537: Loss=0.9150 (C:0.9150, R:0.0105)
Batch  50/537: Loss=0.8905 (C:0.8905, R:0.0105)
Batch  75/537: Loss=0.9475 (C:0.9475, R:0.0105)
Batch 100/537: Loss=0.8698 (C:0.8698, R:0.0105)
Batch 125/537: Loss=0.9117 (C:0.9117, R:0.0105)
Batch 150/537: Loss=0.9456 (C:0.9456, R:0.0105)
Batch 175/537: Loss=0.8556 (C:0.8556, R:0.0105)
Batch 200/537: Loss=0.9145 (C:0.9145, R:0.0105)
Batch 225/537: Loss=0.8893 (C:0.8893, R:0.0105)
Batch 250/537: Loss=0.9518 (C:0.9518, R:0.0105)
Batch 275/537: Loss=0.9376 (C:0.9376, R:0.0105)
Batch 300/537: Loss=0.9271 (C:0.9271, R:0.0105)
Batch 325/537: Loss=0.9112 (C:0.9112, R:0.0105)
Batch 350/537: Loss=0.9950 (C:0.9950, R:0.0105)
Batch 375/537: Loss=0.9079 (C:0.9079, R:0.0105)
Batch 400/537: Loss=0.9369 (C:0.9369, R:0.0105)
Batch 425/537: Loss=0.9294 (C:0.9294, R:0.0105)
Batch 450/537: Loss=0.9129 (C:0.9129, R:0.0105)
Batch 475/537: Loss=0.9516 (C:0.9516, R:0.0105)
Batch 500/537: Loss=0.9675 (C:0.9675, R:0.0105)
Batch 525/537: Loss=1.0015 (C:1.0015, R:0.0105)

============================================================
Epoch 56/300 completed in 22.6s
Train: Loss=0.9271 (C:0.9271, R:0.0105) Ratio=4.98x
Val:   Loss=1.1663 (C:1.1663, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

Epoch 57 Training
----------------------------------------
Batch   0/537: Loss=0.9290 (C:0.9290, R:0.0105)
Batch  25/537: Loss=0.9571 (C:0.9571, R:0.0105)
Batch  50/537: Loss=0.9234 (C:0.9234, R:0.0105)
Batch  75/537: Loss=0.9024 (C:0.9024, R:0.0105)
Batch 100/537: Loss=0.9350 (C:0.9350, R:0.0105)
Batch 125/537: Loss=0.9711 (C:0.9711, R:0.0105)
Batch 150/537: Loss=0.9322 (C:0.9322, R:0.0105)
Batch 175/537: Loss=0.9328 (C:0.9328, R:0.0105)
Batch 200/537: Loss=0.9712 (C:0.9712, R:0.0105)
Batch 225/537: Loss=0.9205 (C:0.9205, R:0.0105)
Batch 250/537: Loss=0.9440 (C:0.9440, R:0.0105)
Batch 275/537: Loss=0.9115 (C:0.9115, R:0.0105)
Batch 300/537: Loss=0.9447 (C:0.9447, R:0.0104)
Batch 325/537: Loss=0.9255 (C:0.9255, R:0.0105)
Batch 350/537: Loss=0.9322 (C:0.9322, R:0.0105)
Batch 375/537: Loss=0.9247 (C:0.9247, R:0.0105)
Batch 400/537: Loss=0.9313 (C:0.9313, R:0.0105)
Batch 425/537: Loss=0.9413 (C:0.9413, R:0.0105)
Batch 450/537: Loss=0.9573 (C:0.9573, R:0.0105)
Batch 475/537: Loss=0.9221 (C:0.9221, R:0.0105)
Batch 500/537: Loss=0.9649 (C:0.9649, R:0.0105)
Batch 525/537: Loss=0.9108 (C:0.9108, R:0.0105)

============================================================
Epoch 57/300 completed in 21.5s
Train: Loss=0.9260 (C:0.9260, R:0.0105) Ratio=4.86x
Val:   Loss=1.1588 (C:1.1588, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 58
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.494 ± 0.864
    Neg distances: 3.737 ± 1.595
    Separation ratio: 7.56x
    Gap: -6.410
    ✅ Excellent global separation!

Epoch 58 Training
----------------------------------------
Batch   0/537: Loss=0.9321 (C:0.9321, R:0.0105)
Batch  25/537: Loss=0.8834 (C:0.8834, R:0.0105)
Batch  50/537: Loss=0.8753 (C:0.8753, R:0.0105)
Batch  75/537: Loss=0.9065 (C:0.9065, R:0.0105)
Batch 100/537: Loss=0.8969 (C:0.8969, R:0.0105)
Batch 125/537: Loss=0.9454 (C:0.9454, R:0.0105)
Batch 150/537: Loss=0.9369 (C:0.9369, R:0.0105)
Batch 175/537: Loss=0.9145 (C:0.9145, R:0.0105)
Batch 200/537: Loss=0.9863 (C:0.9863, R:0.0105)
Batch 225/537: Loss=0.9583 (C:0.9583, R:0.0105)
Batch 250/537: Loss=0.9234 (C:0.9234, R:0.0105)
Batch 275/537: Loss=0.9222 (C:0.9222, R:0.0105)
Batch 300/537: Loss=0.9038 (C:0.9038, R:0.0106)
Batch 325/537: Loss=0.9534 (C:0.9534, R:0.0105)
Batch 350/537: Loss=0.8848 (C:0.8848, R:0.0105)
Batch 375/537: Loss=0.8665 (C:0.8665, R:0.0105)
Batch 400/537: Loss=0.9745 (C:0.9745, R:0.0105)
Batch 425/537: Loss=0.9476 (C:0.9476, R:0.0105)
Batch 450/537: Loss=0.9019 (C:0.9019, R:0.0106)
Batch 475/537: Loss=0.8708 (C:0.8708, R:0.0105)
Batch 500/537: Loss=0.8256 (C:0.8256, R:0.0105)
Batch 525/537: Loss=0.8891 (C:0.8891, R:0.0105)

============================================================
Epoch 58/300 completed in 27.8s
Train: Loss=0.9098 (C:0.9098, R:0.0105) Ratio=5.00x
Val:   Loss=1.1443 (C:1.1443, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.1443)
============================================================

Epoch 59 Training
----------------------------------------
Batch   0/537: Loss=0.8732 (C:0.8732, R:0.0105)
Batch  25/537: Loss=0.9525 (C:0.9525, R:0.0105)
Batch  50/537: Loss=0.9258 (C:0.9258, R:0.0105)
Batch  75/537: Loss=0.9189 (C:0.9189, R:0.0105)
Batch 100/537: Loss=0.8526 (C:0.8526, R:0.0105)
Batch 125/537: Loss=0.9469 (C:0.9469, R:0.0105)
Batch 150/537: Loss=0.8995 (C:0.8995, R:0.0105)
Batch 175/537: Loss=0.8404 (C:0.8404, R:0.0105)
Batch 200/537: Loss=0.9208 (C:0.9208, R:0.0105)
Batch 225/537: Loss=0.9120 (C:0.9120, R:0.0105)
Batch 250/537: Loss=0.9140 (C:0.9140, R:0.0105)
Batch 275/537: Loss=0.9477 (C:0.9477, R:0.0105)
Batch 300/537: Loss=0.9461 (C:0.9461, R:0.0105)
Batch 325/537: Loss=0.9454 (C:0.9454, R:0.0105)
Batch 350/537: Loss=0.8582 (C:0.8582, R:0.0105)
Batch 375/537: Loss=0.9189 (C:0.9189, R:0.0105)
Batch 400/537: Loss=0.8743 (C:0.8743, R:0.0105)
Batch 425/537: Loss=0.9079 (C:0.9079, R:0.0105)
Batch 450/537: Loss=0.9273 (C:0.9273, R:0.0105)
Batch 475/537: Loss=0.9679 (C:0.9679, R:0.0105)
Batch 500/537: Loss=0.8916 (C:0.8916, R:0.0105)
Batch 525/537: Loss=0.9248 (C:0.9248, R:0.0105)

============================================================
Epoch 59/300 completed in 21.3s
Train: Loss=0.9092 (C:0.9092, R:0.0105) Ratio=5.00x
Val:   Loss=1.1408 (C:1.1408, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.1408)
============================================================

Epoch 60 Training
----------------------------------------
Batch   0/537: Loss=0.8719 (C:0.8719, R:0.0105)
Batch  25/537: Loss=0.8869 (C:0.8869, R:0.0106)
Batch  50/537: Loss=0.8836 (C:0.8836, R:0.0105)
Batch  75/537: Loss=0.8955 (C:0.8955, R:0.0105)
Batch 100/537: Loss=0.9188 (C:0.9188, R:0.0105)
Batch 125/537: Loss=0.8784 (C:0.8784, R:0.0105)
Batch 150/537: Loss=0.9041 (C:0.9041, R:0.0105)
Batch 175/537: Loss=0.9191 (C:0.9191, R:0.0105)
Batch 200/537: Loss=0.8653 (C:0.8653, R:0.0105)
Batch 225/537: Loss=0.9665 (C:0.9665, R:0.0105)
Batch 250/537: Loss=0.9002 (C:0.9002, R:0.0106)
Batch 275/537: Loss=0.9224 (C:0.9224, R:0.0105)
Batch 300/537: Loss=0.9102 (C:0.9102, R:0.0105)
Batch 325/537: Loss=0.9387 (C:0.9387, R:0.0105)
Batch 350/537: Loss=0.9429 (C:0.9429, R:0.0105)
Batch 375/537: Loss=0.9223 (C:0.9223, R:0.0105)
Batch 400/537: Loss=0.8832 (C:0.8832, R:0.0105)
Batch 425/537: Loss=0.8986 (C:0.8986, R:0.0105)
Batch 450/537: Loss=0.9031 (C:0.9031, R:0.0105)
Batch 475/537: Loss=0.8950 (C:0.8950, R:0.0106)
Batch 500/537: Loss=0.8579 (C:0.8579, R:0.0105)
Batch 525/537: Loss=0.9079 (C:0.9079, R:0.0105)

============================================================
Epoch 60/300 completed in 21.8s
Train: Loss=0.9047 (C:0.9047, R:0.0105) Ratio=5.04x
Val:   Loss=1.1454 (C:1.1454, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
No improvement for 1 epochs
Checkpoint saved at epoch 60
============================================================

🌍 Updating global dataset at epoch 61
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.510 ± 0.899
    Neg distances: 3.750 ± 1.595
    Separation ratio: 7.35x
    Gap: -6.320
    ✅ Excellent global separation!

Epoch 61 Training
----------------------------------------
Batch   0/537: Loss=0.8552 (C:0.8552, R:0.0105)
Batch  25/537: Loss=0.9272 (C:0.9272, R:0.0105)
Batch  50/537: Loss=0.8705 (C:0.8705, R:0.0105)
Batch  75/537: Loss=0.9211 (C:0.9211, R:0.0105)
Batch 100/537: Loss=0.9186 (C:0.9186, R:0.0105)
Batch 125/537: Loss=0.8361 (C:0.8361, R:0.0105)
Batch 150/537: Loss=0.9093 (C:0.9093, R:0.0105)
Batch 175/537: Loss=0.9449 (C:0.9449, R:0.0105)
Batch 200/537: Loss=0.8919 (C:0.8919, R:0.0105)
Batch 225/537: Loss=0.9092 (C:0.9092, R:0.0105)
Batch 250/537: Loss=0.9017 (C:0.9017, R:0.0105)
Batch 275/537: Loss=0.9087 (C:0.9087, R:0.0105)
Batch 300/537: Loss=0.9389 (C:0.9389, R:0.0105)
Batch 325/537: Loss=0.9092 (C:0.9092, R:0.0105)
Batch 350/537: Loss=0.9436 (C:0.9436, R:0.0105)
Batch 375/537: Loss=0.9628 (C:0.9628, R:0.0105)
Batch 400/537: Loss=0.8602 (C:0.8602, R:0.0105)
Batch 425/537: Loss=0.9039 (C:0.9039, R:0.0106)
Batch 450/537: Loss=0.9207 (C:0.9207, R:0.0105)
Batch 475/537: Loss=0.8833 (C:0.8833, R:0.0105)
Batch 500/537: Loss=0.8939 (C:0.8939, R:0.0105)
Batch 525/537: Loss=0.8397 (C:0.8397, R:0.0105)

============================================================
Epoch 61/300 completed in 27.6s
Train: Loss=0.9075 (C:0.9075, R:0.0105) Ratio=5.01x
Val:   Loss=1.1606 (C:1.1606, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

Epoch 62 Training
----------------------------------------
Batch   0/537: Loss=0.8831 (C:0.8831, R:0.0105)
Batch  25/537: Loss=0.9486 (C:0.9486, R:0.0105)
Batch  50/537: Loss=0.8697 (C:0.8697, R:0.0105)
Batch  75/537: Loss=0.9444 (C:0.9444, R:0.0106)
Batch 100/537: Loss=0.9052 (C:0.9052, R:0.0105)
Batch 125/537: Loss=0.9573 (C:0.9573, R:0.0105)
Batch 150/537: Loss=0.9238 (C:0.9238, R:0.0105)
Batch 175/537: Loss=0.8616 (C:0.8616, R:0.0105)
Batch 200/537: Loss=0.9398 (C:0.9398, R:0.0105)
Batch 225/537: Loss=0.9055 (C:0.9055, R:0.0105)
Batch 250/537: Loss=0.9192 (C:0.9192, R:0.0105)
Batch 275/537: Loss=0.8797 (C:0.8797, R:0.0105)
Batch 300/537: Loss=0.9006 (C:0.9006, R:0.0105)
Batch 325/537: Loss=0.9113 (C:0.9113, R:0.0105)
Batch 350/537: Loss=0.8678 (C:0.8678, R:0.0105)
Batch 375/537: Loss=0.8560 (C:0.8560, R:0.0105)
Batch 400/537: Loss=0.8938 (C:0.8938, R:0.0105)
Batch 425/537: Loss=0.8406 (C:0.8406, R:0.0105)
Batch 450/537: Loss=0.8639 (C:0.8639, R:0.0105)
Batch 475/537: Loss=0.9232 (C:0.9232, R:0.0105)
Batch 500/537: Loss=0.9272 (C:0.9272, R:0.0105)
Batch 525/537: Loss=0.9146 (C:0.9146, R:0.0105)

============================================================
Epoch 62/300 completed in 21.6s
Train: Loss=0.9054 (C:0.9054, R:0.0105) Ratio=5.07x
Val:   Loss=1.1473 (C:1.1473, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

Epoch 63 Training
----------------------------------------
Batch   0/537: Loss=0.8794 (C:0.8794, R:0.0105)
Batch  25/537: Loss=0.9061 (C:0.9061, R:0.0105)
Batch  50/537: Loss=0.9028 (C:0.9028, R:0.0105)
Batch  75/537: Loss=0.8805 (C:0.8805, R:0.0105)
Batch 100/537: Loss=0.8777 (C:0.8777, R:0.0105)
Batch 125/537: Loss=0.9174 (C:0.9174, R:0.0106)
Batch 150/537: Loss=0.8455 (C:0.8455, R:0.0105)
Batch 175/537: Loss=0.9546 (C:0.9546, R:0.0105)
Batch 200/537: Loss=0.9124 (C:0.9124, R:0.0105)
Batch 225/537: Loss=0.8408 (C:0.8408, R:0.0105)
Batch 250/537: Loss=0.9698 (C:0.9698, R:0.0106)
Batch 275/537: Loss=0.9420 (C:0.9420, R:0.0105)
Batch 300/537: Loss=0.9127 (C:0.9127, R:0.0105)
Batch 325/537: Loss=0.9388 (C:0.9388, R:0.0105)
Batch 350/537: Loss=0.9358 (C:0.9358, R:0.0106)
Batch 375/537: Loss=0.8847 (C:0.8847, R:0.0105)
Batch 400/537: Loss=0.8578 (C:0.8578, R:0.0105)
Batch 425/537: Loss=0.8913 (C:0.8913, R:0.0105)
Batch 450/537: Loss=0.9698 (C:0.9698, R:0.0105)
Batch 475/537: Loss=0.9408 (C:0.9408, R:0.0105)
Batch 500/537: Loss=0.9480 (C:0.9480, R:0.0105)
Batch 525/537: Loss=0.9264 (C:0.9264, R:0.0105)

============================================================
Epoch 63/300 completed in 21.4s
Train: Loss=0.9015 (C:0.9015, R:0.0105) Ratio=5.10x
Val:   Loss=1.1342 (C:1.1342, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.1342)
============================================================

🌍 Updating global dataset at epoch 64
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.499 ± 0.886
    Neg distances: 3.822 ± 1.621
    Separation ratio: 7.66x
    Gap: -6.442
    ✅ Excellent global separation!

Epoch 64 Training
----------------------------------------
Batch   0/537: Loss=0.8790 (C:0.8790, R:0.0105)
Batch  25/537: Loss=0.9239 (C:0.9239, R:0.0105)
Batch  50/537: Loss=0.8978 (C:0.8978, R:0.0105)
Batch  75/537: Loss=0.8376 (C:0.8376, R:0.0105)
Batch 100/537: Loss=0.8556 (C:0.8556, R:0.0105)
Batch 125/537: Loss=0.8786 (C:0.8786, R:0.0105)
Batch 150/537: Loss=0.8983 (C:0.8983, R:0.0105)
Batch 175/537: Loss=0.8835 (C:0.8835, R:0.0106)
Batch 200/537: Loss=0.8890 (C:0.8890, R:0.0105)
Batch 225/537: Loss=0.8628 (C:0.8628, R:0.0105)
Batch 250/537: Loss=0.8671 (C:0.8671, R:0.0105)
Batch 275/537: Loss=0.8745 (C:0.8745, R:0.0105)
Batch 300/537: Loss=0.9436 (C:0.9436, R:0.0105)
Batch 325/537: Loss=0.9072 (C:0.9072, R:0.0105)
Batch 350/537: Loss=0.8818 (C:0.8818, R:0.0105)
Batch 375/537: Loss=0.8896 (C:0.8896, R:0.0105)
Batch 400/537: Loss=0.9119 (C:0.9119, R:0.0105)
Batch 425/537: Loss=0.8602 (C:0.8602, R:0.0105)
Batch 450/537: Loss=0.9072 (C:0.9072, R:0.0105)
Batch 475/537: Loss=0.9161 (C:0.9161, R:0.0105)
Batch 500/537: Loss=0.9044 (C:0.9044, R:0.0105)
Batch 525/537: Loss=0.8823 (C:0.8823, R:0.0105)

============================================================
Epoch 64/300 completed in 26.6s
Train: Loss=0.8827 (C:0.8827, R:0.0105) Ratio=5.05x
Val:   Loss=1.1366 (C:1.1366, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

Epoch 65 Training
----------------------------------------
Batch   0/537: Loss=0.8519 (C:0.8519, R:0.0105)
Batch  25/537: Loss=0.9222 (C:0.9222, R:0.0105)
Batch  50/537: Loss=0.9164 (C:0.9164, R:0.0105)
Batch  75/537: Loss=0.8847 (C:0.8847, R:0.0105)
Batch 100/537: Loss=0.8801 (C:0.8801, R:0.0105)
Batch 125/537: Loss=0.9523 (C:0.9523, R:0.0105)
Batch 150/537: Loss=0.8630 (C:0.8630, R:0.0106)
Batch 175/537: Loss=0.8304 (C:0.8304, R:0.0105)
Batch 200/537: Loss=0.8586 (C:0.8586, R:0.0105)
Batch 225/537: Loss=0.8924 (C:0.8924, R:0.0105)
Batch 250/537: Loss=0.8552 (C:0.8552, R:0.0105)
Batch 275/537: Loss=0.8495 (C:0.8495, R:0.0105)
Batch 300/537: Loss=0.9104 (C:0.9104, R:0.0105)
Batch 325/537: Loss=0.9420 (C:0.9420, R:0.0105)
Batch 350/537: Loss=0.8983 (C:0.8983, R:0.0105)
Batch 375/537: Loss=0.8640 (C:0.8640, R:0.0105)
Batch 400/537: Loss=0.9255 (C:0.9255, R:0.0105)
Batch 425/537: Loss=0.8463 (C:0.8463, R:0.0105)
Batch 450/537: Loss=0.8341 (C:0.8341, R:0.0105)
Batch 475/537: Loss=0.9232 (C:0.9232, R:0.0105)
Batch 500/537: Loss=0.8738 (C:0.8738, R:0.0105)
Batch 525/537: Loss=0.9480 (C:0.9480, R:0.0105)

============================================================
Epoch 65/300 completed in 21.0s
Train: Loss=0.8810 (C:0.8810, R:0.0105) Ratio=5.08x
Val:   Loss=1.1325 (C:1.1325, R:0.0104) Ratio=3.03x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.1325)
============================================================

Epoch 66 Training
----------------------------------------
Batch   0/537: Loss=0.8110 (C:0.8110, R:0.0105)
Batch  25/537: Loss=0.8263 (C:0.8263, R:0.0105)
Batch  50/537: Loss=0.8782 (C:0.8782, R:0.0105)
Batch  75/537: Loss=0.8352 (C:0.8352, R:0.0105)
Batch 100/537: Loss=0.8827 (C:0.8827, R:0.0105)
Batch 125/537: Loss=0.8097 (C:0.8097, R:0.0105)
Batch 150/537: Loss=0.8395 (C:0.8395, R:0.0105)
Batch 175/537: Loss=0.8957 (C:0.8957, R:0.0105)
Batch 200/537: Loss=0.8801 (C:0.8801, R:0.0105)
Batch 225/537: Loss=0.9204 (C:0.9204, R:0.0105)
Batch 250/537: Loss=0.9080 (C:0.9080, R:0.0105)
Batch 275/537: Loss=0.9149 (C:0.9149, R:0.0105)
Batch 300/537: Loss=0.8463 (C:0.8463, R:0.0105)
Batch 325/537: Loss=0.8768 (C:0.8768, R:0.0105)
Batch 350/537: Loss=0.9218 (C:0.9218, R:0.0105)
Batch 375/537: Loss=0.8653 (C:0.8653, R:0.0105)
Batch 400/537: Loss=0.8467 (C:0.8467, R:0.0105)
Batch 425/537: Loss=0.8684 (C:0.8684, R:0.0105)
Batch 450/537: Loss=0.8702 (C:0.8702, R:0.0105)
Batch 475/537: Loss=0.8806 (C:0.8806, R:0.0105)
Batch 500/537: Loss=0.8952 (C:0.8952, R:0.0105)
Batch 525/537: Loss=0.8640 (C:0.8640, R:0.0105)

============================================================
Epoch 66/300 completed in 21.2s
Train: Loss=0.8780 (C:0.8780, R:0.0105) Ratio=5.26x
Val:   Loss=1.1303 (C:1.1303, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.1303)
============================================================

🌍 Updating global dataset at epoch 67
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.496 ± 0.885
    Neg distances: 3.873 ± 1.643
    Separation ratio: 7.81x
    Gap: -6.458
    ✅ Excellent global separation!

Epoch 67 Training
----------------------------------------
Batch   0/537: Loss=0.9507 (C:0.9507, R:0.0105)
Batch  25/537: Loss=0.8801 (C:0.8801, R:0.0105)
Batch  50/537: Loss=0.8412 (C:0.8412, R:0.0105)
Batch  75/537: Loss=0.9052 (C:0.9052, R:0.0105)
Batch 100/537: Loss=0.9034 (C:0.9034, R:0.0105)
Batch 125/537: Loss=0.8736 (C:0.8736, R:0.0106)
Batch 150/537: Loss=0.8863 (C:0.8863, R:0.0105)
Batch 175/537: Loss=0.8184 (C:0.8184, R:0.0105)
Batch 200/537: Loss=0.8748 (C:0.8748, R:0.0105)
Batch 225/537: Loss=0.8525 (C:0.8525, R:0.0105)
Batch 250/537: Loss=0.8446 (C:0.8446, R:0.0105)
Batch 275/537: Loss=0.8509 (C:0.8509, R:0.0105)
Batch 300/537: Loss=0.8768 (C:0.8768, R:0.0105)
Batch 325/537: Loss=0.8731 (C:0.8731, R:0.0105)
Batch 350/537: Loss=0.8380 (C:0.8380, R:0.0105)
Batch 375/537: Loss=0.8925 (C:0.8925, R:0.0105)
Batch 400/537: Loss=0.8401 (C:0.8401, R:0.0105)
Batch 425/537: Loss=0.8759 (C:0.8759, R:0.0105)
Batch 450/537: Loss=0.9009 (C:0.9009, R:0.0106)
Batch 475/537: Loss=0.8771 (C:0.8771, R:0.0105)
Batch 500/537: Loss=0.9065 (C:0.9065, R:0.0105)
Batch 525/537: Loss=0.8432 (C:0.8432, R:0.0105)

============================================================
Epoch 67/300 completed in 26.6s
Train: Loss=0.8741 (C:0.8741, R:0.0105) Ratio=5.23x
Val:   Loss=1.1327 (C:1.1327, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

Epoch 68 Training
----------------------------------------
Batch   0/537: Loss=0.9168 (C:0.9168, R:0.0106)
Batch  25/537: Loss=0.8460 (C:0.8460, R:0.0105)
Batch  50/537: Loss=0.8968 (C:0.8968, R:0.0105)
Batch  75/537: Loss=0.8975 (C:0.8975, R:0.0105)
Batch 100/537: Loss=0.8666 (C:0.8666, R:0.0105)
Batch 125/537: Loss=0.8492 (C:0.8492, R:0.0105)
Batch 150/537: Loss=0.8458 (C:0.8458, R:0.0105)
Batch 175/537: Loss=0.9078 (C:0.9078, R:0.0105)
Batch 200/537: Loss=0.8861 (C:0.8861, R:0.0105)
Batch 225/537: Loss=0.8985 (C:0.8985, R:0.0105)
Batch 250/537: Loss=0.8892 (C:0.8892, R:0.0105)
Batch 275/537: Loss=0.8967 (C:0.8967, R:0.0105)
Batch 300/537: Loss=0.8626 (C:0.8626, R:0.0105)
Batch 325/537: Loss=0.8994 (C:0.8994, R:0.0105)
Batch 350/537: Loss=0.8995 (C:0.8995, R:0.0105)
Batch 375/537: Loss=0.8886 (C:0.8886, R:0.0105)
Batch 400/537: Loss=0.9518 (C:0.9518, R:0.0105)
Batch 425/537: Loss=0.8225 (C:0.8225, R:0.0105)
Batch 450/537: Loss=0.8873 (C:0.8873, R:0.0105)
Batch 475/537: Loss=0.8744 (C:0.8744, R:0.0105)
Batch 500/537: Loss=0.9408 (C:0.9408, R:0.0105)
Batch 525/537: Loss=0.8571 (C:0.8571, R:0.0105)

============================================================
Epoch 68/300 completed in 21.6s
Train: Loss=0.8724 (C:0.8724, R:0.0105) Ratio=5.12x
Val:   Loss=1.1222 (C:1.1222, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.1222)
============================================================

Epoch 69 Training
----------------------------------------
Batch   0/537: Loss=0.8421 (C:0.8421, R:0.0105)
Batch  25/537: Loss=0.8818 (C:0.8818, R:0.0105)
Batch  50/537: Loss=0.8882 (C:0.8882, R:0.0105)
Batch  75/537: Loss=0.8632 (C:0.8632, R:0.0105)
Batch 100/537: Loss=0.8452 (C:0.8452, R:0.0105)
Batch 125/537: Loss=0.8504 (C:0.8504, R:0.0105)
Batch 150/537: Loss=0.8503 (C:0.8503, R:0.0106)
Batch 175/537: Loss=0.8177 (C:0.8177, R:0.0105)
Batch 200/537: Loss=0.8531 (C:0.8531, R:0.0105)
Batch 225/537: Loss=0.8637 (C:0.8637, R:0.0105)
Batch 250/537: Loss=0.8764 (C:0.8764, R:0.0105)
Batch 275/537: Loss=0.9133 (C:0.9133, R:0.0105)
Batch 300/537: Loss=0.8727 (C:0.8727, R:0.0106)
Batch 325/537: Loss=0.8189 (C:0.8189, R:0.0105)
Batch 350/537: Loss=0.8450 (C:0.8450, R:0.0105)
Batch 375/537: Loss=0.9075 (C:0.9075, R:0.0105)
Batch 400/537: Loss=0.8392 (C:0.8392, R:0.0105)
Batch 425/537: Loss=0.8760 (C:0.8760, R:0.0105)
Batch 450/537: Loss=0.9128 (C:0.9128, R:0.0105)
Batch 475/537: Loss=0.8774 (C:0.8774, R:0.0105)
Batch 500/537: Loss=0.8730 (C:0.8730, R:0.0105)
Batch 525/537: Loss=0.9128 (C:0.9128, R:0.0106)

============================================================
Epoch 69/300 completed in 21.1s
Train: Loss=0.8713 (C:0.8713, R:0.0105) Ratio=5.28x
Val:   Loss=1.1368 (C:1.1368, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 70
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.482 ± 0.872
    Neg distances: 3.897 ± 1.648
    Separation ratio: 8.08x
    Gap: -6.480
    ✅ Excellent global separation!

Epoch 70 Training
----------------------------------------
Batch   0/537: Loss=0.8431 (C:0.8431, R:0.0105)
Batch  25/537: Loss=0.8835 (C:0.8835, R:0.0105)
Batch  50/537: Loss=0.8703 (C:0.8703, R:0.0105)
Batch  75/537: Loss=0.8405 (C:0.8405, R:0.0106)
Batch 100/537: Loss=0.8936 (C:0.8936, R:0.0105)
Batch 125/537: Loss=0.8479 (C:0.8479, R:0.0106)
Batch 150/537: Loss=0.8708 (C:0.8708, R:0.0105)
Batch 175/537: Loss=0.8733 (C:0.8733, R:0.0105)
Batch 200/537: Loss=0.9255 (C:0.9255, R:0.0106)
Batch 225/537: Loss=0.9101 (C:0.9101, R:0.0105)
Batch 250/537: Loss=0.8699 (C:0.8699, R:0.0105)
Batch 275/537: Loss=0.9107 (C:0.9107, R:0.0105)
Batch 300/537: Loss=0.8716 (C:0.8716, R:0.0105)
Batch 325/537: Loss=0.8514 (C:0.8514, R:0.0105)
Batch 350/537: Loss=0.8740 (C:0.8740, R:0.0105)
Batch 375/537: Loss=0.9382 (C:0.9382, R:0.0105)
Batch 400/537: Loss=0.7984 (C:0.7984, R:0.0105)
Batch 425/537: Loss=0.9207 (C:0.9207, R:0.0105)
Batch 450/537: Loss=0.8202 (C:0.8202, R:0.0105)
Batch 475/537: Loss=0.8502 (C:0.8502, R:0.0105)
Batch 500/537: Loss=0.8642 (C:0.8642, R:0.0105)
Batch 525/537: Loss=0.8784 (C:0.8784, R:0.0105)

============================================================
Epoch 70/300 completed in 26.9s
Train: Loss=0.8565 (C:0.8565, R:0.0105) Ratio=5.12x
Val:   Loss=1.1277 (C:1.1277, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

Epoch 71 Training
----------------------------------------
Batch   0/537: Loss=0.8186 (C:0.8186, R:0.0105)
Batch  25/537: Loss=0.8683 (C:0.8683, R:0.0105)
Batch  50/537: Loss=0.8598 (C:0.8598, R:0.0105)
Batch  75/537: Loss=0.8602 (C:0.8602, R:0.0105)
Batch 100/537: Loss=0.8895 (C:0.8895, R:0.0106)
Batch 125/537: Loss=0.7955 (C:0.7955, R:0.0105)
Batch 150/537: Loss=0.8297 (C:0.8297, R:0.0105)
Batch 175/537: Loss=0.8545 (C:0.8545, R:0.0105)
Batch 200/537: Loss=0.8433 (C:0.8433, R:0.0105)
Batch 225/537: Loss=0.8536 (C:0.8536, R:0.0105)
Batch 250/537: Loss=0.8604 (C:0.8604, R:0.0105)
Batch 275/537: Loss=0.8288 (C:0.8288, R:0.0105)
Batch 300/537: Loss=0.8707 (C:0.8707, R:0.0105)
Batch 325/537: Loss=0.8202 (C:0.8202, R:0.0105)
Batch 350/537: Loss=0.8520 (C:0.8520, R:0.0105)
Batch 375/537: Loss=0.8840 (C:0.8840, R:0.0105)
Batch 400/537: Loss=0.8534 (C:0.8534, R:0.0105)
Batch 425/537: Loss=0.8109 (C:0.8109, R:0.0105)
Batch 450/537: Loss=0.8436 (C:0.8436, R:0.0105)
Batch 475/537: Loss=0.7976 (C:0.7976, R:0.0105)
Batch 500/537: Loss=0.8573 (C:0.8573, R:0.0105)
Batch 525/537: Loss=0.8623 (C:0.8623, R:0.0105)

============================================================
Epoch 71/300 completed in 21.0s
Train: Loss=0.8546 (C:0.8546, R:0.0105) Ratio=5.31x
Val:   Loss=1.1140 (C:1.1140, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.1140)
============================================================

Epoch 72 Training
----------------------------------------
Batch   0/537: Loss=0.8502 (C:0.8502, R:0.0106)
Batch  25/537: Loss=0.8627 (C:0.8627, R:0.0105)
Batch  50/537: Loss=0.8667 (C:0.8667, R:0.0105)
Batch  75/537: Loss=0.8928 (C:0.8928, R:0.0105)
Batch 100/537: Loss=0.8396 (C:0.8396, R:0.0105)
Batch 125/537: Loss=0.8579 (C:0.8579, R:0.0105)
Batch 150/537: Loss=0.8090 (C:0.8090, R:0.0105)
Batch 175/537: Loss=0.8571 (C:0.8571, R:0.0105)
Batch 200/537: Loss=0.7984 (C:0.7984, R:0.0105)
Batch 225/537: Loss=0.8806 (C:0.8806, R:0.0105)
Batch 250/537: Loss=0.8737 (C:0.8737, R:0.0105)
Batch 275/537: Loss=0.8840 (C:0.8840, R:0.0105)
Batch 300/537: Loss=0.8777 (C:0.8777, R:0.0106)
Batch 325/537: Loss=0.7882 (C:0.7882, R:0.0105)
Batch 350/537: Loss=0.8568 (C:0.8568, R:0.0105)
Batch 375/537: Loss=0.8862 (C:0.8862, R:0.0105)
Batch 400/537: Loss=0.8596 (C:0.8596, R:0.0105)
Batch 425/537: Loss=0.8873 (C:0.8873, R:0.0105)
Batch 450/537: Loss=0.9049 (C:0.9049, R:0.0105)
Batch 475/537: Loss=0.8144 (C:0.8144, R:0.0105)
Batch 500/537: Loss=0.8907 (C:0.8907, R:0.0105)
Batch 525/537: Loss=0.8649 (C:0.8649, R:0.0105)

============================================================
Epoch 72/300 completed in 21.0s
Train: Loss=0.8523 (C:0.8523, R:0.0105) Ratio=5.22x
Val:   Loss=1.1173 (C:1.1173, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 73
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.465 ± 0.853
    Neg distances: 3.883 ± 1.622
    Separation ratio: 8.35x
    Gap: -6.475
    ✅ Excellent global separation!

Epoch 73 Training
----------------------------------------
Batch   0/537: Loss=0.8540 (C:0.8540, R:0.0105)
Batch  25/537: Loss=0.8569 (C:0.8569, R:0.0105)
Batch  50/537: Loss=0.8349 (C:0.8349, R:0.0105)
Batch  75/537: Loss=0.8037 (C:0.8037, R:0.0105)
Batch 100/537: Loss=0.7841 (C:0.7841, R:0.0105)
Batch 125/537: Loss=0.7898 (C:0.7898, R:0.0105)
Batch 150/537: Loss=0.8383 (C:0.8383, R:0.0105)
Batch 175/537: Loss=0.8608 (C:0.8608, R:0.0105)
Batch 200/537: Loss=0.8417 (C:0.8417, R:0.0105)
Batch 225/537: Loss=0.8245 (C:0.8245, R:0.0105)
Batch 250/537: Loss=0.8684 (C:0.8684, R:0.0105)
Batch 275/537: Loss=0.8539 (C:0.8539, R:0.0105)
Batch 300/537: Loss=0.8060 (C:0.8060, R:0.0105)
Batch 325/537: Loss=0.8321 (C:0.8321, R:0.0105)
Batch 350/537: Loss=0.8424 (C:0.8424, R:0.0105)
Batch 375/537: Loss=0.8496 (C:0.8496, R:0.0105)
Batch 400/537: Loss=0.8179 (C:0.8179, R:0.0105)
Batch 425/537: Loss=0.8471 (C:0.8471, R:0.0105)
Batch 450/537: Loss=0.8211 (C:0.8211, R:0.0105)
Batch 475/537: Loss=0.8023 (C:0.8023, R:0.0105)
Batch 500/537: Loss=0.8760 (C:0.8760, R:0.0105)
Batch 525/537: Loss=0.8637 (C:0.8637, R:0.0105)

============================================================
Epoch 73/300 completed in 26.8s
Train: Loss=0.8350 (C:0.8350, R:0.0105) Ratio=5.30x
Val:   Loss=1.0891 (C:1.0891, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.0891)
============================================================

Epoch 74 Training
----------------------------------------
Batch   0/537: Loss=0.7512 (C:0.7512, R:0.0105)
Batch  25/537: Loss=0.8429 (C:0.8429, R:0.0105)
Batch  50/537: Loss=0.8538 (C:0.8538, R:0.0105)
Batch  75/537: Loss=0.7437 (C:0.7437, R:0.0105)
Batch 100/537: Loss=0.8156 (C:0.8156, R:0.0105)
Batch 125/537: Loss=0.7781 (C:0.7781, R:0.0105)
Batch 150/537: Loss=0.8436 (C:0.8436, R:0.0105)
Batch 175/537: Loss=0.7627 (C:0.7627, R:0.0105)
Batch 200/537: Loss=0.8666 (C:0.8666, R:0.0105)
Batch 225/537: Loss=0.8597 (C:0.8597, R:0.0105)
Batch 250/537: Loss=0.8309 (C:0.8309, R:0.0105)
Batch 275/537: Loss=0.7696 (C:0.7696, R:0.0105)
Batch 300/537: Loss=0.8137 (C:0.8137, R:0.0105)
Batch 325/537: Loss=0.8656 (C:0.8656, R:0.0105)
Batch 350/537: Loss=0.8531 (C:0.8531, R:0.0105)
Batch 375/537: Loss=0.8414 (C:0.8414, R:0.0105)
Batch 400/537: Loss=0.8537 (C:0.8537, R:0.0105)
Batch 425/537: Loss=0.8298 (C:0.8298, R:0.0105)
Batch 450/537: Loss=0.8232 (C:0.8232, R:0.0105)
Batch 475/537: Loss=0.8061 (C:0.8061, R:0.0105)
Batch 500/537: Loss=0.8951 (C:0.8951, R:0.0105)
Batch 525/537: Loss=0.8112 (C:0.8112, R:0.0105)

============================================================
Epoch 74/300 completed in 21.5s
Train: Loss=0.8318 (C:0.8318, R:0.0105) Ratio=5.43x
Val:   Loss=1.1062 (C:1.1062, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

Epoch 75 Training
----------------------------------------
Batch   0/537: Loss=0.8611 (C:0.8611, R:0.0105)
Batch  25/537: Loss=0.8362 (C:0.8362, R:0.0105)
Batch  50/537: Loss=0.8426 (C:0.8426, R:0.0105)
Batch  75/537: Loss=0.8126 (C:0.8126, R:0.0105)
Batch 100/537: Loss=0.8134 (C:0.8134, R:0.0105)
Batch 125/537: Loss=0.8593 (C:0.8593, R:0.0105)
Batch 150/537: Loss=0.8188 (C:0.8188, R:0.0105)
Batch 175/537: Loss=0.8161 (C:0.8161, R:0.0105)
Batch 200/537: Loss=0.7713 (C:0.7713, R:0.0105)
Batch 225/537: Loss=0.8253 (C:0.8253, R:0.0105)
Batch 250/537: Loss=0.7990 (C:0.7990, R:0.0105)
Batch 275/537: Loss=0.8126 (C:0.8126, R:0.0105)
Batch 300/537: Loss=0.8449 (C:0.8449, R:0.0105)
Batch 325/537: Loss=0.8455 (C:0.8455, R:0.0105)
Batch 350/537: Loss=0.8087 (C:0.8087, R:0.0105)
Batch 375/537: Loss=0.8511 (C:0.8511, R:0.0105)
Batch 400/537: Loss=0.8110 (C:0.8110, R:0.0105)
Batch 425/537: Loss=0.8201 (C:0.8201, R:0.0105)
Batch 450/537: Loss=0.8210 (C:0.8210, R:0.0105)
Batch 475/537: Loss=0.8610 (C:0.8610, R:0.0105)
Batch 500/537: Loss=0.8455 (C:0.8455, R:0.0105)
Batch 525/537: Loss=0.8705 (C:0.8705, R:0.0105)

============================================================
Epoch 75/300 completed in 21.7s
Train: Loss=0.8322 (C:0.8322, R:0.0105) Ratio=5.44x
Val:   Loss=1.1122 (C:1.1122, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 76
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.454 ± 0.855
    Neg distances: 3.932 ± 1.634
    Separation ratio: 8.65x
    Gap: -6.567
    ✅ Excellent global separation!

Epoch 76 Training
----------------------------------------
Batch   0/537: Loss=0.7787 (C:0.7787, R:0.0105)
Batch  25/537: Loss=0.7623 (C:0.7623, R:0.0105)
Batch  50/537: Loss=0.7873 (C:0.7873, R:0.0105)
Batch  75/537: Loss=0.7612 (C:0.7612, R:0.0105)
Batch 100/537: Loss=0.8357 (C:0.8357, R:0.0105)
Batch 125/537: Loss=0.8618 (C:0.8618, R:0.0105)
Batch 150/537: Loss=0.8334 (C:0.8334, R:0.0105)
Batch 175/537: Loss=0.8115 (C:0.8115, R:0.0105)
Batch 200/537: Loss=0.8060 (C:0.8060, R:0.0105)
Batch 225/537: Loss=0.8697 (C:0.8697, R:0.0105)
Batch 250/537: Loss=0.8310 (C:0.8310, R:0.0105)
Batch 275/537: Loss=0.8528 (C:0.8528, R:0.0105)
Batch 300/537: Loss=0.8670 (C:0.8670, R:0.0105)
Batch 325/537: Loss=0.8885 (C:0.8885, R:0.0105)
Batch 350/537: Loss=0.8353 (C:0.8353, R:0.0105)
Batch 375/537: Loss=0.8258 (C:0.8258, R:0.0105)
Batch 400/537: Loss=0.7726 (C:0.7726, R:0.0105)
Batch 425/537: Loss=0.7809 (C:0.7809, R:0.0105)
Batch 450/537: Loss=0.8330 (C:0.8330, R:0.0105)
Batch 475/537: Loss=0.8509 (C:0.8509, R:0.0105)
Batch 500/537: Loss=0.8507 (C:0.8507, R:0.0105)
Batch 525/537: Loss=0.8239 (C:0.8239, R:0.0105)

============================================================
Epoch 76/300 completed in 26.6s
Train: Loss=0.8184 (C:0.8184, R:0.0105) Ratio=5.35x
Val:   Loss=1.0947 (C:1.0947, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

Epoch 77 Training
----------------------------------------
Batch   0/537: Loss=0.7744 (C:0.7744, R:0.0105)
Batch  25/537: Loss=0.8090 (C:0.8090, R:0.0105)
Batch  50/537: Loss=0.8126 (C:0.8126, R:0.0105)
Batch  75/537: Loss=0.7650 (C:0.7650, R:0.0105)
Batch 100/537: Loss=0.8217 (C:0.8217, R:0.0105)
Batch 125/537: Loss=0.8395 (C:0.8395, R:0.0105)
Batch 150/537: Loss=0.8127 (C:0.8127, R:0.0105)
Batch 175/537: Loss=0.8221 (C:0.8221, R:0.0105)
Batch 200/537: Loss=0.8435 (C:0.8435, R:0.0105)
Batch 225/537: Loss=0.8206 (C:0.8206, R:0.0106)
Batch 250/537: Loss=0.8160 (C:0.8160, R:0.0106)
Batch 275/537: Loss=0.7495 (C:0.7495, R:0.0105)
Batch 300/537: Loss=0.8518 (C:0.8518, R:0.0105)
Batch 325/537: Loss=0.7658 (C:0.7658, R:0.0105)
Batch 350/537: Loss=0.8189 (C:0.8189, R:0.0106)
Batch 375/537: Loss=0.7924 (C:0.7924, R:0.0105)
Batch 400/537: Loss=0.8425 (C:0.8425, R:0.0105)
Batch 425/537: Loss=0.8445 (C:0.8445, R:0.0105)
Batch 450/537: Loss=0.8217 (C:0.8217, R:0.0105)
Batch 475/537: Loss=0.8740 (C:0.8740, R:0.0106)
Batch 500/537: Loss=0.8403 (C:0.8403, R:0.0105)
Batch 525/537: Loss=0.7881 (C:0.7881, R:0.0105)

============================================================
Epoch 77/300 completed in 21.3s
Train: Loss=0.8167 (C:0.8167, R:0.0105) Ratio=5.43x
Val:   Loss=1.0838 (C:1.0838, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.0838)
============================================================

Epoch 78 Training
----------------------------------------
Batch   0/537: Loss=0.7709 (C:0.7709, R:0.0105)
Batch  25/537: Loss=0.8122 (C:0.8122, R:0.0105)
Batch  50/537: Loss=0.7724 (C:0.7724, R:0.0105)
Batch  75/537: Loss=0.8203 (C:0.8203, R:0.0105)
Batch 100/537: Loss=0.8433 (C:0.8433, R:0.0105)
Batch 125/537: Loss=0.7857 (C:0.7857, R:0.0105)
Batch 150/537: Loss=0.7868 (C:0.7868, R:0.0105)
Batch 175/537: Loss=0.8033 (C:0.8033, R:0.0105)
Batch 200/537: Loss=0.8075 (C:0.8075, R:0.0105)
Batch 225/537: Loss=0.8292 (C:0.8292, R:0.0105)
Batch 250/537: Loss=0.8141 (C:0.8141, R:0.0105)
Batch 275/537: Loss=0.7966 (C:0.7966, R:0.0105)
Batch 300/537: Loss=0.7956 (C:0.7956, R:0.0105)
Batch 325/537: Loss=0.7983 (C:0.7983, R:0.0105)
Batch 350/537: Loss=0.8392 (C:0.8392, R:0.0105)
Batch 375/537: Loss=0.8040 (C:0.8040, R:0.0105)
Batch 400/537: Loss=0.8832 (C:0.8832, R:0.0105)
Batch 425/537: Loss=0.8461 (C:0.8461, R:0.0105)
Batch 450/537: Loss=0.8245 (C:0.8245, R:0.0105)
Batch 475/537: Loss=0.8239 (C:0.8239, R:0.0105)
Batch 500/537: Loss=0.8802 (C:0.8802, R:0.0105)
Batch 525/537: Loss=0.8683 (C:0.8683, R:0.0105)

============================================================
Epoch 78/300 completed in 25.1s
Train: Loss=0.8136 (C:0.8136, R:0.0105) Ratio=5.44x
Val:   Loss=1.0855 (C:1.0855, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 79
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.446 ± 0.827
    Neg distances: 3.866 ± 1.603
    Separation ratio: 8.68x
    Gap: -6.585
    ✅ Excellent global separation!

Epoch 79 Training
----------------------------------------
Batch   0/537: Loss=0.7922 (C:0.7922, R:0.0105)
Batch  25/537: Loss=0.7895 (C:0.7895, R:0.0105)
Batch  50/537: Loss=0.7952 (C:0.7952, R:0.0105)
Batch  75/537: Loss=0.8630 (C:0.8630, R:0.0105)
Batch 100/537: Loss=0.7653 (C:0.7653, R:0.0105)
Batch 125/537: Loss=0.7731 (C:0.7731, R:0.0105)
Batch 150/537: Loss=0.8199 (C:0.8199, R:0.0105)
Batch 175/537: Loss=0.7740 (C:0.7740, R:0.0105)
Batch 200/537: Loss=0.8237 (C:0.8237, R:0.0105)
Batch 225/537: Loss=0.7538 (C:0.7538, R:0.0106)
Batch 250/537: Loss=0.7956 (C:0.7956, R:0.0105)
Batch 275/537: Loss=0.8399 (C:0.8399, R:0.0105)
Batch 300/537: Loss=0.8614 (C:0.8614, R:0.0105)
Batch 325/537: Loss=0.8358 (C:0.8358, R:0.0105)
Batch 350/537: Loss=0.7836 (C:0.7836, R:0.0105)
Batch 375/537: Loss=0.8218 (C:0.8218, R:0.0105)
Batch 400/537: Loss=0.8482 (C:0.8482, R:0.0106)
Batch 425/537: Loss=0.8123 (C:0.8123, R:0.0105)
Batch 450/537: Loss=0.7873 (C:0.7873, R:0.0105)
Batch 475/537: Loss=0.8280 (C:0.8280, R:0.0105)
Batch 500/537: Loss=0.8154 (C:0.8154, R:0.0106)
Batch 525/537: Loss=0.8123 (C:0.8123, R:0.0105)

============================================================
Epoch 79/300 completed in 27.1s
Train: Loss=0.8080 (C:0.8080, R:0.0105) Ratio=5.39x
Val:   Loss=1.0869 (C:1.0869, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

Epoch 80 Training
----------------------------------------
Batch   0/537: Loss=0.8435 (C:0.8435, R:0.0105)
Batch  25/537: Loss=0.8047 (C:0.8047, R:0.0106)
Batch  50/537: Loss=0.7633 (C:0.7633, R:0.0105)
Batch  75/537: Loss=0.7843 (C:0.7843, R:0.0105)
Batch 100/537: Loss=0.8401 (C:0.8401, R:0.0105)
Batch 125/537: Loss=0.7826 (C:0.7826, R:0.0105)
Batch 150/537: Loss=0.8710 (C:0.8710, R:0.0105)
Batch 175/537: Loss=0.7838 (C:0.7838, R:0.0105)
Batch 200/537: Loss=0.8059 (C:0.8059, R:0.0105)
Batch 225/537: Loss=0.7818 (C:0.7818, R:0.0105)
Batch 250/537: Loss=0.8295 (C:0.8295, R:0.0105)
Batch 275/537: Loss=0.8241 (C:0.8241, R:0.0105)
Batch 300/537: Loss=0.8587 (C:0.8587, R:0.0105)
Batch 325/537: Loss=0.9072 (C:0.9072, R:0.0105)
Batch 350/537: Loss=0.8217 (C:0.8217, R:0.0105)
Batch 375/537: Loss=0.7789 (C:0.7789, R:0.0105)
Batch 400/537: Loss=0.8479 (C:0.8479, R:0.0105)
Batch 425/537: Loss=0.8310 (C:0.8310, R:0.0105)
Batch 450/537: Loss=0.7944 (C:0.7944, R:0.0105)
Batch 475/537: Loss=0.8709 (C:0.8709, R:0.0105)
Batch 500/537: Loss=0.7468 (C:0.7468, R:0.0105)
Batch 525/537: Loss=0.8504 (C:0.8504, R:0.0105)

============================================================
Epoch 80/300 completed in 21.3s
Train: Loss=0.8077 (C:0.8077, R:0.0105) Ratio=5.37x
Val:   Loss=1.0805 (C:1.0805, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.0805)
Checkpoint saved at epoch 80
============================================================

Epoch 81 Training
----------------------------------------
Batch   0/537: Loss=0.7927 (C:0.7927, R:0.0105)
Batch  25/537: Loss=0.7704 (C:0.7704, R:0.0105)
Batch  50/537: Loss=0.7604 (C:0.7604, R:0.0105)
Batch  75/537: Loss=0.8442 (C:0.8442, R:0.0105)
Batch 100/537: Loss=0.8343 (C:0.8343, R:0.0105)
Batch 125/537: Loss=0.7781 (C:0.7781, R:0.0105)
Batch 150/537: Loss=0.7890 (C:0.7890, R:0.0105)
Batch 175/537: Loss=0.7627 (C:0.7627, R:0.0105)
Batch 200/537: Loss=0.7848 (C:0.7848, R:0.0105)
Batch 225/537: Loss=0.8379 (C:0.8379, R:0.0105)
Batch 250/537: Loss=0.7708 (C:0.7708, R:0.0105)
Batch 275/537: Loss=0.8712 (C:0.8712, R:0.0105)
Batch 300/537: Loss=0.8011 (C:0.8011, R:0.0105)
Batch 325/537: Loss=0.7970 (C:0.7970, R:0.0105)
Batch 350/537: Loss=0.8056 (C:0.8056, R:0.0105)
Batch 375/537: Loss=0.7646 (C:0.7646, R:0.0105)
Batch 400/537: Loss=0.8064 (C:0.8064, R:0.0105)
Batch 425/537: Loss=0.8060 (C:0.8060, R:0.0105)
Batch 450/537: Loss=0.8119 (C:0.8119, R:0.0105)
Batch 475/537: Loss=0.7878 (C:0.7878, R:0.0105)
Batch 500/537: Loss=0.8381 (C:0.8381, R:0.0105)
Batch 525/537: Loss=0.8219 (C:0.8219, R:0.0105)

============================================================
Epoch 81/300 completed in 21.2s
Train: Loss=0.8070 (C:0.8070, R:0.0105) Ratio=5.55x
Val:   Loss=1.0907 (C:1.0907, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 82
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.447 ± 0.814
    Neg distances: 3.942 ± 1.632
    Separation ratio: 8.82x
    Gap: -6.573
    ✅ Excellent global separation!

Epoch 82 Training
----------------------------------------
Batch   0/537: Loss=0.7944 (C:0.7944, R:0.0105)
Batch  25/537: Loss=0.8328 (C:0.8328, R:0.0105)
Batch  50/537: Loss=0.8323 (C:0.8323, R:0.0105)
Batch  75/537: Loss=0.7766 (C:0.7766, R:0.0105)
Batch 100/537: Loss=0.8094 (C:0.8094, R:0.0105)
Batch 125/537: Loss=0.7831 (C:0.7831, R:0.0105)
Batch 150/537: Loss=0.8198 (C:0.8198, R:0.0105)
Batch 175/537: Loss=0.8114 (C:0.8114, R:0.0105)
Batch 200/537: Loss=0.7865 (C:0.7865, R:0.0105)
Batch 225/537: Loss=0.8359 (C:0.8359, R:0.0105)
Batch 250/537: Loss=0.8017 (C:0.8017, R:0.0105)
Batch 275/537: Loss=0.8226 (C:0.8226, R:0.0105)
Batch 300/537: Loss=0.7686 (C:0.7686, R:0.0105)
Batch 325/537: Loss=0.7846 (C:0.7846, R:0.0105)
Batch 350/537: Loss=0.8213 (C:0.8213, R:0.0105)
Batch 375/537: Loss=0.8019 (C:0.8019, R:0.0105)
Batch 400/537: Loss=0.7999 (C:0.7999, R:0.0105)
Batch 425/537: Loss=0.7698 (C:0.7698, R:0.0105)
Batch 450/537: Loss=0.8118 (C:0.8118, R:0.0106)
Batch 475/537: Loss=0.8039 (C:0.8039, R:0.0105)
Batch 500/537: Loss=0.7843 (C:0.7843, R:0.0105)
Batch 525/537: Loss=0.8266 (C:0.8266, R:0.0106)

============================================================
Epoch 82/300 completed in 28.0s
Train: Loss=0.7983 (C:0.7983, R:0.0105) Ratio=5.42x
Val:   Loss=1.0734 (C:1.0734, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.0734)
============================================================

Epoch 83 Training
----------------------------------------
Batch   0/537: Loss=0.7882 (C:0.7882, R:0.0105)
Batch  25/537: Loss=0.7998 (C:0.7998, R:0.0105)
Batch  50/537: Loss=0.8140 (C:0.8140, R:0.0105)
Batch  75/537: Loss=0.8660 (C:0.8660, R:0.0105)
Batch 100/537: Loss=0.7503 (C:0.7503, R:0.0105)
Batch 125/537: Loss=0.7865 (C:0.7865, R:0.0105)
Batch 150/537: Loss=0.8182 (C:0.8182, R:0.0105)
Batch 175/537: Loss=0.7808 (C:0.7808, R:0.0105)
Batch 200/537: Loss=0.7893 (C:0.7893, R:0.0105)
Batch 225/537: Loss=0.8138 (C:0.8138, R:0.0105)
Batch 250/537: Loss=0.7939 (C:0.7939, R:0.0105)
Batch 275/537: Loss=0.7758 (C:0.7758, R:0.0105)
Batch 300/537: Loss=0.7508 (C:0.7508, R:0.0105)
Batch 325/537: Loss=0.8232 (C:0.8232, R:0.0105)
Batch 350/537: Loss=0.7867 (C:0.7867, R:0.0105)
Batch 375/537: Loss=0.8045 (C:0.8045, R:0.0105)
Batch 400/537: Loss=0.8356 (C:0.8356, R:0.0105)
Batch 425/537: Loss=0.8461 (C:0.8461, R:0.0105)
Batch 450/537: Loss=0.7943 (C:0.7943, R:0.0105)
Batch 475/537: Loss=0.7951 (C:0.7951, R:0.0105)
Batch 500/537: Loss=0.7921 (C:0.7921, R:0.0105)
Batch 525/537: Loss=0.8496 (C:0.8496, R:0.0105)

============================================================
Epoch 83/300 completed in 21.5s
Train: Loss=0.7979 (C:0.7979, R:0.0105) Ratio=5.42x
Val:   Loss=1.0918 (C:1.0918, R:0.0104) Ratio=3.02x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

Epoch 84 Training
----------------------------------------
Batch   0/537: Loss=0.8162 (C:0.8162, R:0.0105)
Batch  25/537: Loss=0.7866 (C:0.7866, R:0.0105)
Batch  50/537: Loss=0.8192 (C:0.8192, R:0.0105)
Batch  75/537: Loss=0.8133 (C:0.8133, R:0.0105)
Batch 100/537: Loss=0.8112 (C:0.8112, R:0.0105)
Batch 125/537: Loss=0.7881 (C:0.7881, R:0.0105)
Batch 150/537: Loss=0.7491 (C:0.7491, R:0.0105)
Batch 175/537: Loss=0.8102 (C:0.8102, R:0.0105)
Batch 200/537: Loss=0.8324 (C:0.8324, R:0.0105)
Batch 225/537: Loss=0.7621 (C:0.7621, R:0.0105)
Batch 250/537: Loss=0.8339 (C:0.8339, R:0.0105)
Batch 275/537: Loss=0.7990 (C:0.7990, R:0.0105)
Batch 300/537: Loss=0.8312 (C:0.8312, R:0.0105)
Batch 325/537: Loss=0.7716 (C:0.7716, R:0.0105)
Batch 350/537: Loss=0.8483 (C:0.8483, R:0.0105)
Batch 375/537: Loss=0.7587 (C:0.7587, R:0.0105)
Batch 400/537: Loss=0.7933 (C:0.7933, R:0.0105)
Batch 425/537: Loss=0.8395 (C:0.8395, R:0.0105)
Batch 450/537: Loss=0.8451 (C:0.8451, R:0.0105)
Batch 475/537: Loss=0.7719 (C:0.7719, R:0.0105)
Batch 500/537: Loss=0.8016 (C:0.8016, R:0.0105)
Batch 525/537: Loss=0.7800 (C:0.7800, R:0.0105)

============================================================
Epoch 84/300 completed in 21.2s
Train: Loss=0.7985 (C:0.7985, R:0.0105) Ratio=5.47x
Val:   Loss=1.0711 (C:1.0711, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.0711)
============================================================

🌍 Updating global dataset at epoch 85
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.465 ± 0.896
    Neg distances: 3.969 ± 1.660
    Separation ratio: 8.53x
    Gap: -6.660
    ✅ Excellent global separation!

Epoch 85 Training
----------------------------------------
Batch   0/537: Loss=0.7632 (C:0.7632, R:0.0105)
Batch  25/537: Loss=0.7981 (C:0.7981, R:0.0105)
Batch  50/537: Loss=0.8092 (C:0.8092, R:0.0105)
Batch  75/537: Loss=0.8417 (C:0.8417, R:0.0105)
Batch 100/537: Loss=0.8195 (C:0.8195, R:0.0105)
Batch 125/537: Loss=0.7700 (C:0.7700, R:0.0105)
Batch 150/537: Loss=0.8259 (C:0.8259, R:0.0105)
Batch 175/537: Loss=0.7383 (C:0.7383, R:0.0105)
Batch 200/537: Loss=0.7760 (C:0.7760, R:0.0105)
Batch 225/537: Loss=0.8125 (C:0.8125, R:0.0106)
Batch 250/537: Loss=0.8181 (C:0.8181, R:0.0106)
Batch 275/537: Loss=0.7894 (C:0.7894, R:0.0105)
Batch 300/537: Loss=0.8227 (C:0.8227, R:0.0105)
Batch 325/537: Loss=0.7825 (C:0.7825, R:0.0105)
Batch 350/537: Loss=0.8148 (C:0.8148, R:0.0105)
Batch 375/537: Loss=0.8212 (C:0.8212, R:0.0105)
Batch 400/537: Loss=0.8503 (C:0.8503, R:0.0105)
Batch 425/537: Loss=0.8229 (C:0.8229, R:0.0105)
Batch 450/537: Loss=0.8246 (C:0.8246, R:0.0105)
Batch 475/537: Loss=0.8714 (C:0.8714, R:0.0105)
Batch 500/537: Loss=0.8228 (C:0.8228, R:0.0105)
Batch 525/537: Loss=0.8057 (C:0.8057, R:0.0105)

============================================================
Epoch 85/300 completed in 27.1s
Train: Loss=0.8083 (C:0.8083, R:0.0105) Ratio=5.56x
Val:   Loss=1.0885 (C:1.0885, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

Epoch 86 Training
----------------------------------------
Batch   0/537: Loss=0.7618 (C:0.7618, R:0.0105)
Batch  25/537: Loss=0.7614 (C:0.7614, R:0.0105)
Batch  50/537: Loss=0.8338 (C:0.8338, R:0.0105)
Batch  75/537: Loss=0.7852 (C:0.7852, R:0.0105)
Batch 100/537: Loss=0.7383 (C:0.7383, R:0.0105)
Batch 125/537: Loss=0.7980 (C:0.7980, R:0.0105)
Batch 150/537: Loss=0.8141 (C:0.8141, R:0.0105)
Batch 175/537: Loss=0.8428 (C:0.8428, R:0.0105)
Batch 200/537: Loss=0.8373 (C:0.8373, R:0.0105)
Batch 225/537: Loss=0.7699 (C:0.7699, R:0.0105)
Batch 250/537: Loss=0.8271 (C:0.8271, R:0.0105)
Batch 275/537: Loss=0.8047 (C:0.8047, R:0.0105)
Batch 300/537: Loss=0.8063 (C:0.8063, R:0.0105)
Batch 325/537: Loss=0.8275 (C:0.8275, R:0.0105)
Batch 350/537: Loss=0.7683 (C:0.7683, R:0.0105)
Batch 375/537: Loss=0.8124 (C:0.8124, R:0.0105)
Batch 400/537: Loss=0.8173 (C:0.8173, R:0.0105)
Batch 425/537: Loss=0.7917 (C:0.7917, R:0.0105)
Batch 450/537: Loss=0.8222 (C:0.8222, R:0.0105)
Batch 475/537: Loss=0.8042 (C:0.8042, R:0.0105)
Batch 500/537: Loss=0.8141 (C:0.8141, R:0.0105)
Batch 525/537: Loss=0.7733 (C:0.7733, R:0.0105)

============================================================
Epoch 86/300 completed in 21.5s
Train: Loss=0.8092 (C:0.8092, R:0.0105) Ratio=5.58x
Val:   Loss=1.0934 (C:1.0934, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

Epoch 87 Training
----------------------------------------
Batch   0/537: Loss=0.7985 (C:0.7985, R:0.0105)
Batch  25/537: Loss=0.7876 (C:0.7876, R:0.0105)
Batch  50/537: Loss=0.8142 (C:0.8142, R:0.0105)
Batch  75/537: Loss=0.7997 (C:0.7997, R:0.0105)
Batch 100/537: Loss=0.7619 (C:0.7619, R:0.0105)
Batch 125/537: Loss=0.7989 (C:0.7989, R:0.0105)
Batch 150/537: Loss=0.8202 (C:0.8202, R:0.0105)
Batch 175/537: Loss=0.7869 (C:0.7869, R:0.0105)
Batch 200/537: Loss=0.7868 (C:0.7868, R:0.0105)
Batch 225/537: Loss=0.8031 (C:0.8031, R:0.0105)
Batch 250/537: Loss=0.8694 (C:0.8694, R:0.0105)
Batch 275/537: Loss=0.8009 (C:0.8009, R:0.0105)
Batch 300/537: Loss=0.8133 (C:0.8133, R:0.0105)
Batch 325/537: Loss=0.7950 (C:0.7950, R:0.0105)
Batch 350/537: Loss=0.8414 (C:0.8414, R:0.0105)
Batch 375/537: Loss=0.7950 (C:0.7950, R:0.0105)
Batch 400/537: Loss=0.8341 (C:0.8341, R:0.0105)
Batch 425/537: Loss=0.8393 (C:0.8393, R:0.0105)
Batch 450/537: Loss=0.8439 (C:0.8439, R:0.0105)
Batch 475/537: Loss=0.8121 (C:0.8121, R:0.0105)
Batch 500/537: Loss=0.8514 (C:0.8514, R:0.0105)
Batch 525/537: Loss=0.7778 (C:0.7778, R:0.0105)

============================================================
Epoch 87/300 completed in 21.8s
Train: Loss=0.8047 (C:0.8047, R:0.0105) Ratio=5.64x
Val:   Loss=1.0935 (C:1.0935, R:0.0104) Ratio=3.03x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 88
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.456 ± 0.835
    Neg distances: 3.958 ± 1.644
    Separation ratio: 8.68x
    Gap: -6.777
    ✅ Excellent global separation!

Epoch 88 Training
----------------------------------------
Batch   0/537: Loss=0.7681 (C:0.7681, R:0.0105)
Batch  25/537: Loss=0.7347 (C:0.7347, R:0.0105)
Batch  50/537: Loss=0.8184 (C:0.8184, R:0.0105)
Batch  75/537: Loss=0.8287 (C:0.8287, R:0.0105)
Batch 100/537: Loss=0.8060 (C:0.8060, R:0.0106)
Batch 125/537: Loss=0.7981 (C:0.7981, R:0.0105)
Batch 150/537: Loss=0.7815 (C:0.7815, R:0.0105)
Batch 175/537: Loss=0.8315 (C:0.8315, R:0.0105)
Batch 200/537: Loss=0.8197 (C:0.8197, R:0.0105)
Batch 225/537: Loss=0.8269 (C:0.8269, R:0.0105)
Batch 250/537: Loss=0.8084 (C:0.8084, R:0.0105)
Batch 275/537: Loss=0.7732 (C:0.7732, R:0.0106)
Batch 300/537: Loss=0.7651 (C:0.7651, R:0.0105)
Batch 325/537: Loss=0.7509 (C:0.7509, R:0.0105)
Batch 350/537: Loss=0.8290 (C:0.8290, R:0.0105)
Batch 375/537: Loss=0.7534 (C:0.7534, R:0.0105)
Batch 400/537: Loss=0.7924 (C:0.7924, R:0.0105)
Batch 425/537: Loss=0.8140 (C:0.8140, R:0.0105)
Batch 450/537: Loss=0.7958 (C:0.7958, R:0.0105)
Batch 475/537: Loss=0.8173 (C:0.8173, R:0.0105)
Batch 500/537: Loss=0.8037 (C:0.8037, R:0.0105)
Batch 525/537: Loss=0.7543 (C:0.7543, R:0.0105)

============================================================
Epoch 88/300 completed in 27.7s
Train: Loss=0.7932 (C:0.7932, R:0.0105) Ratio=5.55x
Val:   Loss=1.0722 (C:1.0722, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
No improvement for 4 epochs
============================================================

Epoch 89 Training
----------------------------------------
Batch   0/537: Loss=0.7816 (C:0.7816, R:0.0105)
Batch  25/537: Loss=0.7962 (C:0.7962, R:0.0105)
Batch  50/537: Loss=0.7914 (C:0.7914, R:0.0105)
Batch  75/537: Loss=0.7584 (C:0.7584, R:0.0105)
Batch 100/537: Loss=0.8258 (C:0.8258, R:0.0105)
Batch 125/537: Loss=0.8053 (C:0.8053, R:0.0105)
Batch 150/537: Loss=0.8058 (C:0.8058, R:0.0106)
Batch 175/537: Loss=0.8398 (C:0.8398, R:0.0105)
Batch 200/537: Loss=0.8122 (C:0.8122, R:0.0105)
Batch 225/537: Loss=0.8315 (C:0.8315, R:0.0105)
Batch 250/537: Loss=0.7500 (C:0.7500, R:0.0105)
Batch 275/537: Loss=0.8015 (C:0.8015, R:0.0105)
Batch 300/537: Loss=0.7652 (C:0.7652, R:0.0105)
Batch 325/537: Loss=0.8544 (C:0.8544, R:0.0105)
Batch 350/537: Loss=0.8051 (C:0.8051, R:0.0105)
Batch 375/537: Loss=0.7960 (C:0.7960, R:0.0105)
Batch 400/537: Loss=0.8387 (C:0.8387, R:0.0105)
Batch 425/537: Loss=0.8184 (C:0.8184, R:0.0105)
Batch 450/537: Loss=0.8241 (C:0.8241, R:0.0105)
Batch 475/537: Loss=0.8330 (C:0.8330, R:0.0105)
Batch 500/537: Loss=0.7661 (C:0.7661, R:0.0105)
Batch 525/537: Loss=0.8375 (C:0.8375, R:0.0105)

============================================================
Epoch 89/300 completed in 21.3s
Train: Loss=0.7928 (C:0.7928, R:0.0105) Ratio=5.41x
Val:   Loss=1.1012 (C:1.1012, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
No improvement for 5 epochs
============================================================

Epoch 90 Training
----------------------------------------
Batch   0/537: Loss=0.8286 (C:0.8286, R:0.0105)
Batch  25/537: Loss=0.8305 (C:0.8305, R:0.0104)
Batch  50/537: Loss=0.7689 (C:0.7689, R:0.0105)
Batch  75/537: Loss=0.8277 (C:0.8277, R:0.0105)
Batch 100/537: Loss=0.7568 (C:0.7568, R:0.0105)
Batch 125/537: Loss=0.8158 (C:0.8158, R:0.0105)
Batch 150/537: Loss=0.7936 (C:0.7936, R:0.0105)
Batch 175/537: Loss=0.7807 (C:0.7807, R:0.0105)
Batch 200/537: Loss=0.7513 (C:0.7513, R:0.0105)
Batch 225/537: Loss=0.7838 (C:0.7838, R:0.0105)
Batch 250/537: Loss=0.7621 (C:0.7621, R:0.0105)
Batch 275/537: Loss=0.7682 (C:0.7682, R:0.0105)
Batch 300/537: Loss=0.8141 (C:0.8141, R:0.0105)
Batch 325/537: Loss=0.7401 (C:0.7401, R:0.0105)
Batch 350/537: Loss=0.7836 (C:0.7836, R:0.0105)
Batch 375/537: Loss=0.7973 (C:0.7973, R:0.0105)
Batch 400/537: Loss=0.8636 (C:0.8636, R:0.0105)
Batch 425/537: Loss=0.8326 (C:0.8326, R:0.0105)
Batch 450/537: Loss=0.8189 (C:0.8189, R:0.0106)
Batch 475/537: Loss=0.8054 (C:0.8054, R:0.0105)
Batch 500/537: Loss=0.8082 (C:0.8082, R:0.0105)
Batch 525/537: Loss=0.8295 (C:0.8295, R:0.0105)

============================================================
Epoch 90/300 completed in 21.4s
Train: Loss=0.7912 (C:0.7912, R:0.0105) Ratio=5.54x
Val:   Loss=1.0827 (C:1.0827, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.300
No improvement for 6 epochs
============================================================

🌍 Updating global dataset at epoch 91
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 5000 samples
  Global dataset updated: 5000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.441 ± 0.830
    Neg distances: 3.988 ± 1.644
    Separation ratio: 9.04x
    Gap: -6.715
    ✅ Excellent global separation!

Epoch 91 Training
----------------------------------------
Batch   0/537: Loss=0.7752 (C:0.7752, R:0.0105)
Batch  25/537: Loss=0.8128 (C:0.8128, R:0.0105)
Batch  50/537: Loss=0.7888 (C:0.7888, R:0.0106)
Batch  75/537: Loss=0.7432 (C:0.7432, R:0.0105)
Batch 100/537: Loss=0.7395 (C:0.7395, R:0.0105)
Batch 125/537: Loss=0.7725 (C:0.7725, R:0.0105)
Batch 150/537: Loss=0.7715 (C:0.7715, R:0.0105)
Batch 175/537: Loss=0.7638 (C:0.7638, R:0.0105)
Batch 200/537: Loss=0.7628 (C:0.7628, R:0.0105)
Batch 225/537: Loss=0.7745 (C:0.7745, R:0.0105)
Batch 250/537: Loss=0.7694 (C:0.7694, R:0.0105)
Batch 275/537: Loss=0.7714 (C:0.7714, R:0.0105)
Batch 300/537: Loss=0.7612 (C:0.7612, R:0.0105)
Batch 325/537: Loss=0.7885 (C:0.7885, R:0.0105)
Batch 350/537: Loss=0.8190 (C:0.8190, R:0.0105)
Batch 375/537: Loss=0.8042 (C:0.8042, R:0.0105)
Batch 400/537: Loss=0.7734 (C:0.7734, R:0.0105)
Batch 425/537: Loss=0.7675 (C:0.7675, R:0.0105)
Batch 450/537: Loss=0.7601 (C:0.7601, R:0.0105)
Batch 475/537: Loss=0.7441 (C:0.7441, R:0.0105)
Batch 500/537: Loss=0.7988 (C:0.7988, R:0.0105)
Batch 525/537: Loss=0.7700 (C:0.7700, R:0.0105)

============================================================
Epoch 91/300 completed in 27.7s
Train: Loss=0.7766 (C:0.7766, R:0.0105) Ratio=5.66x
Val:   Loss=1.0866 (C:1.0866, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
No improvement for 7 epochs
============================================================

Epoch 92 Training
----------------------------------------
Batch   0/537: Loss=0.7724 (C:0.7724, R:0.0105)
Batch  25/537: Loss=0.7305 (C:0.7305, R:0.0105)
Batch  50/537: Loss=0.7703 (C:0.7703, R:0.0105)
Batch  75/537: Loss=0.7658 (C:0.7658, R:0.0105)
Batch 100/537: Loss=0.7958 (C:0.7958, R:0.0105)
Batch 125/537: Loss=0.7297 (C:0.7297, R:0.0105)
Batch 150/537: Loss=0.7209 (C:0.7209, R:0.0105)
Batch 175/537: Loss=0.7942 (C:0.7942, R:0.0105)
Batch 200/537: Loss=0.7440 (C:0.7440, R:0.0105)
Batch 225/537: Loss=0.7856 (C:0.7856, R:0.0106)
Batch 250/537: Loss=0.7845 (C:0.7845, R:0.0105)
Batch 275/537: Loss=0.7388 (C:0.7388, R:0.0105)
Batch 300/537: Loss=0.8005 (C:0.8005, R:0.0105)
Batch 325/537: Loss=0.7989 (C:0.7989, R:0.0105)
Batch 350/537: Loss=0.7540 (C:0.7540, R:0.0106)
Batch 375/537: Loss=0.7801 (C:0.7801, R:0.0105)
Batch 400/537: Loss=0.7452 (C:0.7452, R:0.0105)
Batch 425/537: Loss=0.8230 (C:0.8230, R:0.0105)
Batch 450/537: Loss=0.7747 (C:0.7747, R:0.0105)
Batch 475/537: Loss=0.7873 (C:0.7873, R:0.0105)
Batch 500/537: Loss=0.7719 (C:0.7719, R:0.0105)
Batch 525/537: Loss=0.7587 (C:0.7587, R:0.0105)

============================================================
Epoch 92/300 completed in 21.6s
Train: Loss=0.7753 (C:0.7753, R:0.0105) Ratio=5.69x
Val:   Loss=1.0852 (C:1.0852, R:0.0104) Ratio=3.03x
Reconstruction weight: 0.300
No improvement for 8 epochs

Early stopping triggered after 92 epochs
Best model was at epoch 84 with Val Loss: 1.0711

Global Dataset Training Completed!
Best epoch: 84
Best validation loss: 1.0711
Final separation ratios: Train=5.69x, Val=3.03x
Training completed!
Loading best model from entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin3.0_updatefreq3_max_global_samples5000_20250715_164108/checkpoints/best_model.pt
Starting model evaluation...
========================================
GlobalContrastiveEvaluator initialized on cuda
Starting comprehensive evaluation...
============================================================
Extracting latent representations...
  Processed 1/10 batches
Extracted representations: torch.Size([9824, 75])
Evaluating clustering performance...
Clustering Results:
  Silhouette Score: 0.4527
  Adjusted Rand Score: 0.5287
  Clustering Accuracy: 0.8125
Evaluating classification performance...
  Extracting training representations...
Extracting latent representations...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
Extracted representations: torch.Size([547740, 75])
  Extracting validation representations...
Extracting latent representations...
  Processed 1/9 batches
Extracted representations: torch.Size([9180, 75])
Subsampled training to 50000 samples
  Training on 50000 samples, evaluating on 9180 samples
Classification Results:
  Accuracy: 0.8090
  Per-class F1: [0.8293590394047017, 0.7408595253367543, 0.8581548864917083]
Evaluating reconstruction quality...
Reconstruction Results:
  Average MSE: 0.010432
Evaluating separation quality...
Separation Results:
  Positive distances: 1.165 ± 1.409
  Negative distances: 3.503 ± 1.869
  Separation ratio: 3.01x
  Gap: -6.702
  Perfect separation: No

Comprehensive evaluation completed!

============================================================
EVALUATION SUMMARY
============================================================
Clustering Performance:
  Silhouette Score: 0.4527
  Clustering Accuracy: 0.8125
  Adjusted Rand Score: 0.5287

Classification Performance:
  Accuracy: 0.8090

Separation Quality:
  Separation Ratio: 3.01x
  Gap: -6.702
  Perfect Separation: False

Reconstruction Quality:
  Average MSE: 0.010432
============================================================
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin3.0_updatefreq3_max_global_samples5000_20250715_164108/results/evaluation_results_20250715_171731.json
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin3.0_updatefreq3_max_global_samples5000_20250715_164108/results/evaluation_results_20250715_171731.json
Saving final experiment results...
Final results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin3.0_updatefreq3_max_global_samples5000_20250715_164108/final_results.json

============================================================
PIPELINE COMPLETED SUCCESSFULLY!
============================================================
Experiment directory: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin3.0_updatefreq3_max_global_samples5000_20250715_164108
Best model: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin3.0_updatefreq3_max_global_samples5000_20250715_164108/checkpoints/best_model.pt
Final results: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin3.0_updatefreq3_max_global_samples5000_20250715_164108/final_results.json

Key Results:
  Separation ratio: 3.01x
  Perfect separation: False
  Classification accuracy: 0.8090
  Result: 0.8090% (improvement: +-80.86%)
  Cleaning up: coarse_margin3.0_updatefreq3_max_global_samples5000_20250715_164108

[12/12] Testing: coarse_margin3.0_updatefreq3_max_global_samples10000
  margin: 3.0
  update_frequency: 3
  max_global_samples: 10000
  Reconstruction weight: 0.3 (fixed)
GLOBAL DATASET CONTRASTIVE AUTOENCODER PIPELINE
============================================================
Start time: 2025-07-15 17:17:31.951627
Using device: cuda

Configuration:
  Embedding type: concat
  Batch size: 1020
  Global update frequency: 3 epochs
  Training epochs: 300
Experiment setup completed:
  Experiment directory: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin3.0_updatefreq3_max_global_samples10000_20250715_171731
  Config saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin3.0_updatefreq3_max_global_samples10000_20250715_171731/config.json
Loading data...
========================================
FlexibleEmbedder initialized with type: 'concat'
Output dimension will be: 1536
GlobalDataLoader initialized:
  Embedding type: concat
  Output dimension: 1536
  Sample size: All
Starting data loading pipeline...
============================================================
Loading training data from data/processed/snli_full_standard_SBERT.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 549367 training samples
Loading validation data from data/processed/snli_full_standard_SBERT_validation.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9842 validation samples
Loading test data from data/processed/snli_full_standard_SBERT_test.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9824 test samples
Generating embeddings for training...
Generating concat embeddings on cuda
Processing 549367 samples in batches of 1000
  Processing batch 1/550
  Processing batch 6/550
  Processing batch 11/550
  Processing batch 16/550
  Processing batch 21/550
  Processing batch 26/550
  Processing batch 31/550
  Processing batch 36/550
  Processing batch 41/550
  Processing batch 46/550
  Processing batch 51/550
  Processing batch 56/550
  Processing batch 61/550
  Processing batch 66/550
  Processing batch 71/550
  Processing batch 76/550
  Processing batch 81/550
  Processing batch 86/550
  Processing batch 91/550
  Processing batch 96/550
  Processing batch 101/550
  Processing batch 106/550
  Processing batch 111/550
  Processing batch 116/550
  Processing batch 121/550
  Processing batch 126/550
  Processing batch 131/550
  Processing batch 136/550
  Processing batch 141/550
  Processing batch 146/550
  Processing batch 151/550
  Processing batch 156/550
  Processing batch 161/550
  Processing batch 166/550
  Processing batch 171/550
  Processing batch 176/550
  Processing batch 181/550
  Processing batch 186/550
  Processing batch 191/550
  Processing batch 196/550
  Processing batch 201/550
  Processing batch 206/550
  Processing batch 211/550
  Processing batch 216/550
  Processing batch 221/550
  Processing batch 226/550
  Processing batch 231/550
  Processing batch 236/550
  Processing batch 241/550
  Processing batch 246/550
  Processing batch 251/550
  Processing batch 256/550
  Processing batch 261/550
  Processing batch 266/550
  Processing batch 271/550
  Processing batch 276/550
  Processing batch 281/550
  Processing batch 286/550
  Processing batch 291/550
  Processing batch 296/550
  Processing batch 301/550
  Processing batch 306/550
  Processing batch 311/550
  Processing batch 316/550
  Processing batch 321/550
  Processing batch 326/550
  Processing batch 331/550
  Processing batch 336/550
  Processing batch 341/550
  Processing batch 346/550
  Processing batch 351/550
  Processing batch 356/550
  Processing batch 361/550
  Processing batch 366/550
  Processing batch 371/550
  Processing batch 376/550
  Processing batch 381/550
  Processing batch 386/550
  Processing batch 391/550
  Processing batch 396/550
  Processing batch 401/550
  Processing batch 406/550
  Processing batch 411/550
  Processing batch 416/550
  Processing batch 421/550
  Processing batch 426/550
  Processing batch 431/550
  Processing batch 436/550
  Processing batch 441/550
  Processing batch 446/550
  Processing batch 451/550
  Processing batch 456/550
  Processing batch 461/550
  Processing batch 466/550
  Processing batch 471/550
  Processing batch 476/550
  Processing batch 481/550
  Processing batch 486/550
  Processing batch 491/550
  Processing batch 496/550
  Processing batch 501/550
  Processing batch 506/550
  Processing batch 511/550
  Processing batch 516/550
  Processing batch 521/550
  Processing batch 526/550
  Processing batch 531/550
  Processing batch 536/550
  Processing batch 541/550
  Processing batch 546/550
Generated concat embeddings: torch.Size([549367, 1536])
Generating embeddings for validation...
Generating concat embeddings on cuda
Processing 9842 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9842, 1536])
Generating embeddings for test...
Generating concat embeddings on cuda
Processing 9824 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9824, 1536])
EntailmentDataset created: 549367 samples
  Embedding shape: torch.Size([549367, 1536])
  Class distribution: {'entailment': 183416, 'neutral': 182764, 'contradiction': 183187}
EntailmentDataset created: 9842 samples
  Embedding shape: torch.Size([9842, 1536])
  Class distribution: {'entailment': 3329, 'neutral': 3235, 'contradiction': 3278}
EntailmentDataset created: 9824 samples
  Embedding shape: torch.Size([9824, 1536])
  Class distribution: {'entailment': 3368, 'neutral': 3219, 'contradiction': 3237}

Data loading pipeline completed!
Output embedding dimension: 1536
Updated model input_dim to: 1536
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 537
  Class 2: 183187 samples
  Class 0: 183416 samples
  Class 1: 182764 samples
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 9
  Class 2: 3278 samples
  Class 0: 3329 samples
  Class 1: 3235 samples
DataLoaders created:
  Batch size: 1020
  Balanced sampling: True
  Train batches: 537
  Val batches: 9
  Test batches: 10
Data loading completed!
  Train: 549367 samples, 537 batches
  Val: 9842 samples, 9 batches
  Test: 9824 samples, 10 batches
Creating model and trainer...
========================================
ContrastiveAutoencoder initialized:
  Input dim: 1536
  Latent dim: 75
  Hidden dims: [512, 256]
  Dropout rate: 0.2
  Total parameters: 1,876,555
Model created with 1,876,555 parameters
FullDatasetContrastiveLoss initialized:
  Margin: 3.0
  Update frequency: 3 epochs
  Max global samples: 10000
FullDatasetCombinedLoss initialized:
  Contrastive weight: 1.0
  Base reconstruction weight: 0.0
  Scheduled reconstruction: warmup=30 epochs, max_weight=0.3
Optimizer created (lr=0.0001)
GlobalDatasetTrainer initialized on device: cuda
Model parameters: 1,876,555
Starting training...
========================================
Starting Global Dataset Training...
============================================================

🌍 Updating global dataset at epoch 1
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.091 ± 0.010
    Neg distances: 0.091 ± 0.010
    Separation ratio: 1.00x
    Gap: -0.127
    ❌ Poor global separation

Epoch 1 Training
----------------------------------------
Batch   0/537: Loss=2.9998 (C:2.9998, R:0.0116)
Batch  25/537: Loss=2.9957 (C:2.9957, R:0.0114)
Batch  50/537: Loss=2.9711 (C:2.9711, R:0.0113)
Batch  75/537: Loss=2.9591 (C:2.9591, R:0.0112)
Batch 100/537: Loss=2.9507 (C:2.9507, R:0.0110)
Batch 125/537: Loss=2.9235 (C:2.9235, R:0.0110)
Batch 150/537: Loss=2.9289 (C:2.9289, R:0.0109)
Batch 175/537: Loss=2.8869 (C:2.8869, R:0.0108)
Batch 200/537: Loss=2.9025 (C:2.9025, R:0.0108)
Batch 225/537: Loss=2.9015 (C:2.9015, R:0.0107)
Batch 250/537: Loss=2.8815 (C:2.8815, R:0.0106)
Batch 275/537: Loss=2.8954 (C:2.8954, R:0.0107)
Batch 300/537: Loss=2.8559 (C:2.8559, R:0.0106)
Batch 325/537: Loss=2.8580 (C:2.8580, R:0.0106)
Batch 350/537: Loss=2.8727 (C:2.8727, R:0.0105)
Batch 375/537: Loss=2.8719 (C:2.8719, R:0.0106)
Batch 400/537: Loss=2.8486 (C:2.8486, R:0.0106)
Batch 425/537: Loss=2.8567 (C:2.8567, R:0.0105)
Batch 450/537: Loss=2.8377 (C:2.8377, R:0.0105)
Batch 475/537: Loss=2.8521 (C:2.8521, R:0.0105)
Batch 500/537: Loss=2.8514 (C:2.8514, R:0.0105)
Batch 525/537: Loss=2.8454 (C:2.8454, R:0.0105)

============================================================
Epoch 1/300 completed in 27.7s
Train: Loss=2.8971 (C:2.8971, R:0.0108) Ratio=1.64x
Val:   Loss=2.8387 (C:2.8387, R:0.0105) Ratio=2.14x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 2.8387)
============================================================

Epoch 2 Training
----------------------------------------
Batch   0/537: Loss=2.8169 (C:2.8169, R:0.0105)
Batch  25/537: Loss=2.8219 (C:2.8219, R:0.0105)
Batch  50/537: Loss=2.8239 (C:2.8239, R:0.0105)
Batch  75/537: Loss=2.8349 (C:2.8349, R:0.0105)
Batch 100/537: Loss=2.8294 (C:2.8294, R:0.0105)
Batch 125/537: Loss=2.8332 (C:2.8332, R:0.0106)
Batch 150/537: Loss=2.8324 (C:2.8324, R:0.0106)
Batch 175/537: Loss=2.8341 (C:2.8341, R:0.0105)
Batch 200/537: Loss=2.8416 (C:2.8416, R:0.0105)
Batch 225/537: Loss=2.8047 (C:2.8047, R:0.0105)
Batch 250/537: Loss=2.8186 (C:2.8186, R:0.0105)
Batch 275/537: Loss=2.8365 (C:2.8365, R:0.0105)
Batch 300/537: Loss=2.8167 (C:2.8167, R:0.0105)
Batch 325/537: Loss=2.8080 (C:2.8080, R:0.0105)
Batch 350/537: Loss=2.8189 (C:2.8189, R:0.0105)
Batch 375/537: Loss=2.8316 (C:2.8316, R:0.0105)
Batch 400/537: Loss=2.8234 (C:2.8234, R:0.0105)
Batch 425/537: Loss=2.8228 (C:2.8228, R:0.0105)
Batch 450/537: Loss=2.8426 (C:2.8426, R:0.0105)
Batch 475/537: Loss=2.8041 (C:2.8041, R:0.0105)
Batch 500/537: Loss=2.8360 (C:2.8360, R:0.0105)
Batch 525/537: Loss=2.8237 (C:2.8237, R:0.0105)

============================================================
Epoch 2/300 completed in 21.2s
Train: Loss=2.8310 (C:2.8310, R:0.0105) Ratio=2.19x
Val:   Loss=2.8171 (C:2.8171, R:0.0104) Ratio=2.36x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 2.8171)
============================================================

Epoch 3 Training
----------------------------------------
Batch   0/537: Loss=2.8228 (C:2.8228, R:0.0105)
Batch  25/537: Loss=2.8267 (C:2.8267, R:0.0105)
Batch  50/537: Loss=2.8189 (C:2.8189, R:0.0105)
Batch  75/537: Loss=2.7992 (C:2.7992, R:0.0105)
Batch 100/537: Loss=2.8203 (C:2.8203, R:0.0105)
Batch 125/537: Loss=2.8007 (C:2.8007, R:0.0105)
Batch 150/537: Loss=2.8019 (C:2.8019, R:0.0105)
Batch 175/537: Loss=2.8267 (C:2.8267, R:0.0105)
Batch 200/537: Loss=2.7767 (C:2.7767, R:0.0105)
Batch 225/537: Loss=2.8004 (C:2.8004, R:0.0105)
Batch 250/537: Loss=2.8069 (C:2.8069, R:0.0105)
Batch 275/537: Loss=2.7999 (C:2.7999, R:0.0105)
Batch 300/537: Loss=2.8095 (C:2.8095, R:0.0105)
Batch 325/537: Loss=2.8119 (C:2.8119, R:0.0105)
Batch 350/537: Loss=2.8111 (C:2.8111, R:0.0105)
Batch 375/537: Loss=2.8119 (C:2.8119, R:0.0105)
Batch 400/537: Loss=2.8244 (C:2.8244, R:0.0105)
Batch 425/537: Loss=2.8016 (C:2.8016, R:0.0105)
Batch 450/537: Loss=2.8286 (C:2.8286, R:0.0105)
Batch 475/537: Loss=2.8191 (C:2.8191, R:0.0105)
Batch 500/537: Loss=2.8039 (C:2.8039, R:0.0105)
Batch 525/537: Loss=2.8032 (C:2.8032, R:0.0105)

============================================================
Epoch 3/300 completed in 21.3s
Train: Loss=2.8144 (C:2.8144, R:0.0105) Ratio=2.42x
Val:   Loss=2.8137 (C:2.8137, R:0.0104) Ratio=2.48x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 2.8137)
============================================================

🌍 Updating global dataset at epoch 4
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.745 ± 0.812
    Neg distances: 2.017 ± 1.169
    Separation ratio: 2.71x
    Gap: -4.502
    ✅ Good global separation

Epoch 4 Training
----------------------------------------
Batch   0/537: Loss=1.8974 (C:1.8974, R:0.0105)
Batch  25/537: Loss=1.8549 (C:1.8549, R:0.0105)
Batch  50/537: Loss=1.8471 (C:1.8471, R:0.0105)
Batch  75/537: Loss=1.8204 (C:1.8204, R:0.0105)
Batch 100/537: Loss=1.8877 (C:1.8877, R:0.0106)
Batch 125/537: Loss=1.8654 (C:1.8654, R:0.0105)
Batch 150/537: Loss=1.8783 (C:1.8783, R:0.0105)
Batch 175/537: Loss=1.9003 (C:1.9003, R:0.0105)
Batch 200/537: Loss=1.8370 (C:1.8370, R:0.0105)
Batch 225/537: Loss=1.8700 (C:1.8700, R:0.0105)
Batch 250/537: Loss=1.8521 (C:1.8521, R:0.0105)
Batch 275/537: Loss=1.9044 (C:1.9044, R:0.0105)
Batch 300/537: Loss=1.8605 (C:1.8605, R:0.0105)
Batch 325/537: Loss=1.8486 (C:1.8486, R:0.0105)
Batch 350/537: Loss=1.8280 (C:1.8280, R:0.0105)
Batch 375/537: Loss=1.8860 (C:1.8860, R:0.0105)
Batch 400/537: Loss=1.8713 (C:1.8713, R:0.0105)
Batch 425/537: Loss=1.8365 (C:1.8365, R:0.0105)
Batch 450/537: Loss=1.8332 (C:1.8332, R:0.0105)
Batch 475/537: Loss=1.8397 (C:1.8397, R:0.0105)
Batch 500/537: Loss=1.8401 (C:1.8401, R:0.0105)
Batch 525/537: Loss=1.9551 (C:1.9551, R:0.0105)

============================================================
Epoch 4/300 completed in 27.0s
Train: Loss=1.8615 (C:1.8615, R:0.0105) Ratio=2.52x
Val:   Loss=1.8568 (C:1.8568, R:0.0104) Ratio=2.61x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.8568)
============================================================

Epoch 5 Training
----------------------------------------
Batch   0/537: Loss=1.8855 (C:1.8855, R:0.0105)
Batch  25/537: Loss=1.8042 (C:1.8042, R:0.0105)
Batch  50/537: Loss=1.8423 (C:1.8423, R:0.0105)
Batch  75/537: Loss=1.8435 (C:1.8435, R:0.0106)
Batch 100/537: Loss=1.8306 (C:1.8306, R:0.0106)
Batch 125/537: Loss=1.8591 (C:1.8591, R:0.0105)
Batch 150/537: Loss=1.8566 (C:1.8566, R:0.0105)
Batch 175/537: Loss=1.8362 (C:1.8362, R:0.0105)
Batch 200/537: Loss=1.7984 (C:1.7984, R:0.0105)
Batch 225/537: Loss=1.8487 (C:1.8487, R:0.0105)
Batch 250/537: Loss=1.8469 (C:1.8469, R:0.0105)
Batch 275/537: Loss=1.8262 (C:1.8262, R:0.0105)
Batch 300/537: Loss=1.8246 (C:1.8246, R:0.0105)
Batch 325/537: Loss=1.8376 (C:1.8376, R:0.0105)
Batch 350/537: Loss=1.7850 (C:1.7850, R:0.0105)
Batch 375/537: Loss=1.8372 (C:1.8372, R:0.0105)
Batch 400/537: Loss=1.8479 (C:1.8479, R:0.0106)
Batch 425/537: Loss=1.8338 (C:1.8338, R:0.0105)
Batch 450/537: Loss=1.8341 (C:1.8341, R:0.0105)
Batch 475/537: Loss=1.8868 (C:1.8868, R:0.0105)
Batch 500/537: Loss=1.7942 (C:1.7942, R:0.0105)
Batch 525/537: Loss=1.8428 (C:1.8428, R:0.0105)

============================================================
Epoch 5/300 completed in 21.3s
Train: Loss=1.8325 (C:1.8325, R:0.0105) Ratio=2.68x
Val:   Loss=1.8455 (C:1.8455, R:0.0104) Ratio=2.64x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.8455)
============================================================

Epoch 6 Training
----------------------------------------
Batch   0/537: Loss=1.7986 (C:1.7986, R:0.0105)
Batch  25/537: Loss=1.8513 (C:1.8513, R:0.0105)
Batch  50/537: Loss=1.7480 (C:1.7480, R:0.0105)
Batch  75/537: Loss=1.8096 (C:1.8096, R:0.0105)
Batch 100/537: Loss=1.8600 (C:1.8600, R:0.0105)
Batch 125/537: Loss=1.8097 (C:1.8097, R:0.0105)
Batch 150/537: Loss=1.7717 (C:1.7717, R:0.0105)
Batch 175/537: Loss=1.8313 (C:1.8313, R:0.0105)
Batch 200/537: Loss=1.8254 (C:1.8254, R:0.0105)
Batch 225/537: Loss=1.8247 (C:1.8247, R:0.0106)
Batch 250/537: Loss=1.7933 (C:1.7933, R:0.0106)
Batch 275/537: Loss=1.8441 (C:1.8441, R:0.0105)
Batch 300/537: Loss=1.8100 (C:1.8100, R:0.0105)
Batch 325/537: Loss=1.8090 (C:1.8090, R:0.0106)
Batch 350/537: Loss=1.8052 (C:1.8052, R:0.0105)
Batch 375/537: Loss=1.7571 (C:1.7571, R:0.0105)
Batch 400/537: Loss=1.7984 (C:1.7984, R:0.0105)
Batch 425/537: Loss=1.8223 (C:1.8223, R:0.0105)
Batch 450/537: Loss=1.8464 (C:1.8464, R:0.0105)
Batch 475/537: Loss=1.8563 (C:1.8563, R:0.0105)
Batch 500/537: Loss=1.7648 (C:1.7648, R:0.0105)
Batch 525/537: Loss=1.8493 (C:1.8493, R:0.0105)

============================================================
Epoch 6/300 completed in 22.1s
Train: Loss=1.8151 (C:1.8151, R:0.0105) Ratio=2.84x
Val:   Loss=1.8281 (C:1.8281, R:0.0104) Ratio=2.68x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.8281)
============================================================

🌍 Updating global dataset at epoch 7
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.669 ± 0.812
    Neg distances: 2.212 ± 1.227
    Separation ratio: 3.31x
    Gap: -5.124
    ✅ Excellent global separation!

Epoch 7 Training
----------------------------------------
Batch   0/537: Loss=1.6660 (C:1.6660, R:0.0105)
Batch  25/537: Loss=1.7034 (C:1.7034, R:0.0105)
Batch  50/537: Loss=1.6726 (C:1.6726, R:0.0105)
Batch  75/537: Loss=1.6958 (C:1.6958, R:0.0105)
Batch 100/537: Loss=1.5545 (C:1.5545, R:0.0105)
Batch 125/537: Loss=1.6995 (C:1.6995, R:0.0105)
Batch 150/537: Loss=1.6524 (C:1.6524, R:0.0105)
Batch 175/537: Loss=1.7204 (C:1.7204, R:0.0105)
Batch 200/537: Loss=1.6837 (C:1.6837, R:0.0105)
Batch 225/537: Loss=1.6651 (C:1.6651, R:0.0105)
Batch 250/537: Loss=1.7241 (C:1.7241, R:0.0105)
Batch 275/537: Loss=1.6955 (C:1.6955, R:0.0105)
Batch 300/537: Loss=1.7301 (C:1.7301, R:0.0105)
Batch 325/537: Loss=1.7259 (C:1.7259, R:0.0105)
Batch 350/537: Loss=1.6658 (C:1.6658, R:0.0105)
Batch 375/537: Loss=1.7330 (C:1.7330, R:0.0105)
Batch 400/537: Loss=1.6917 (C:1.6917, R:0.0105)
Batch 425/537: Loss=1.7161 (C:1.7161, R:0.0105)
Batch 450/537: Loss=1.6831 (C:1.6831, R:0.0105)
Batch 475/537: Loss=1.7192 (C:1.7192, R:0.0105)
Batch 500/537: Loss=1.6930 (C:1.6930, R:0.0105)
Batch 525/537: Loss=1.6730 (C:1.6730, R:0.0105)

============================================================
Epoch 7/300 completed in 28.9s
Train: Loss=1.6795 (C:1.6795, R:0.0105) Ratio=2.89x
Val:   Loss=1.7130 (C:1.7130, R:0.0104) Ratio=2.73x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.7130)
============================================================

Epoch 8 Training
----------------------------------------
Batch   0/537: Loss=1.6417 (C:1.6417, R:0.0105)
Batch  25/537: Loss=1.7476 (C:1.7476, R:0.0105)
Batch  50/537: Loss=1.6228 (C:1.6228, R:0.0105)
Batch  75/537: Loss=1.6693 (C:1.6693, R:0.0105)
Batch 100/537: Loss=1.6292 (C:1.6292, R:0.0105)
Batch 125/537: Loss=1.6335 (C:1.6335, R:0.0105)
Batch 150/537: Loss=1.6474 (C:1.6474, R:0.0105)
Batch 175/537: Loss=1.6591 (C:1.6591, R:0.0105)
Batch 200/537: Loss=1.7127 (C:1.7127, R:0.0105)
Batch 225/537: Loss=1.6910 (C:1.6910, R:0.0106)
Batch 250/537: Loss=1.6697 (C:1.6697, R:0.0105)
Batch 275/537: Loss=1.6569 (C:1.6569, R:0.0105)
Batch 300/537: Loss=1.6700 (C:1.6700, R:0.0105)
Batch 325/537: Loss=1.7309 (C:1.7309, R:0.0105)
Batch 350/537: Loss=1.6051 (C:1.6051, R:0.0105)
Batch 375/537: Loss=1.6330 (C:1.6330, R:0.0105)
Batch 400/537: Loss=1.6672 (C:1.6672, R:0.0105)
Batch 425/537: Loss=1.6008 (C:1.6008, R:0.0105)
Batch 450/537: Loss=1.6495 (C:1.6495, R:0.0105)
Batch 475/537: Loss=1.7039 (C:1.7039, R:0.0105)
Batch 500/537: Loss=1.6728 (C:1.6728, R:0.0105)
Batch 525/537: Loss=1.7225 (C:1.7225, R:0.0105)

============================================================
Epoch 8/300 completed in 21.8s
Train: Loss=1.6640 (C:1.6640, R:0.0105) Ratio=3.03x
Val:   Loss=1.7051 (C:1.7051, R:0.0104) Ratio=2.80x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.7051)
============================================================

Epoch 9 Training
----------------------------------------
Batch   0/537: Loss=1.5946 (C:1.5946, R:0.0105)
Batch  25/537: Loss=1.6471 (C:1.6471, R:0.0105)
Batch  50/537: Loss=1.6500 (C:1.6500, R:0.0106)
Batch  75/537: Loss=1.5920 (C:1.5920, R:0.0105)
Batch 100/537: Loss=1.6619 (C:1.6619, R:0.0105)
Batch 125/537: Loss=1.6854 (C:1.6854, R:0.0105)
Batch 150/537: Loss=1.6094 (C:1.6094, R:0.0105)
Batch 175/537: Loss=1.6538 (C:1.6538, R:0.0105)
Batch 200/537: Loss=1.6714 (C:1.6714, R:0.0105)
Batch 225/537: Loss=1.6752 (C:1.6752, R:0.0105)
Batch 250/537: Loss=1.6328 (C:1.6328, R:0.0105)
Batch 275/537: Loss=1.6690 (C:1.6690, R:0.0105)
Batch 300/537: Loss=1.6347 (C:1.6347, R:0.0105)
Batch 325/537: Loss=1.7115 (C:1.7115, R:0.0105)
Batch 350/537: Loss=1.6857 (C:1.6857, R:0.0105)
Batch 375/537: Loss=1.6651 (C:1.6651, R:0.0105)
Batch 400/537: Loss=1.6686 (C:1.6686, R:0.0105)
Batch 425/537: Loss=1.6472 (C:1.6472, R:0.0105)
Batch 450/537: Loss=1.6436 (C:1.6436, R:0.0105)
Batch 475/537: Loss=1.6375 (C:1.6375, R:0.0105)
Batch 500/537: Loss=1.5870 (C:1.5870, R:0.0105)
Batch 525/537: Loss=1.6694 (C:1.6694, R:0.0105)

============================================================
Epoch 9/300 completed in 21.7s
Train: Loss=1.6566 (C:1.6566, R:0.0105) Ratio=3.14x
Val:   Loss=1.7048 (C:1.7048, R:0.0104) Ratio=2.82x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.7048)
============================================================

🌍 Updating global dataset at epoch 10
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.630 ± 0.810
    Neg distances: 2.290 ± 1.235
    Separation ratio: 3.63x
    Gap: -4.383
    ✅ Excellent global separation!

Epoch 10 Training
----------------------------------------
Batch   0/537: Loss=1.6057 (C:1.6057, R:0.0105)
Batch  25/537: Loss=1.5698 (C:1.5698, R:0.0105)
Batch  50/537: Loss=1.5747 (C:1.5747, R:0.0105)
Batch  75/537: Loss=1.5916 (C:1.5916, R:0.0105)
Batch 100/537: Loss=1.5144 (C:1.5144, R:0.0105)
Batch 125/537: Loss=1.5678 (C:1.5678, R:0.0105)
Batch 150/537: Loss=1.5930 (C:1.5930, R:0.0105)
Batch 175/537: Loss=1.5871 (C:1.5871, R:0.0105)
Batch 200/537: Loss=1.6048 (C:1.6048, R:0.0105)
Batch 225/537: Loss=1.5986 (C:1.5986, R:0.0105)
Batch 250/537: Loss=1.5271 (C:1.5271, R:0.0105)
Batch 275/537: Loss=1.5584 (C:1.5584, R:0.0106)
Batch 300/537: Loss=1.5929 (C:1.5929, R:0.0105)
Batch 325/537: Loss=1.5638 (C:1.5638, R:0.0105)
Batch 350/537: Loss=1.6130 (C:1.6130, R:0.0105)
Batch 375/537: Loss=1.6183 (C:1.6183, R:0.0105)
Batch 400/537: Loss=1.6289 (C:1.6289, R:0.0105)
Batch 425/537: Loss=1.6042 (C:1.6042, R:0.0105)
Batch 450/537: Loss=1.5602 (C:1.5602, R:0.0105)
Batch 475/537: Loss=1.6035 (C:1.6035, R:0.0105)
Batch 500/537: Loss=1.5715 (C:1.5715, R:0.0105)
Batch 525/537: Loss=1.6458 (C:1.6458, R:0.0105)

============================================================
Epoch 10/300 completed in 28.4s
Train: Loss=1.5949 (C:1.5949, R:0.0105) Ratio=3.23x
Val:   Loss=1.6412 (C:1.6412, R:0.0104) Ratio=2.86x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.6412)
============================================================

Epoch 11 Training
----------------------------------------
Batch   0/537: Loss=1.6061 (C:1.6061, R:0.0105)
Batch  25/537: Loss=1.5722 (C:1.5722, R:0.0105)
Batch  50/537: Loss=1.5703 (C:1.5703, R:0.0105)
Batch  75/537: Loss=1.5962 (C:1.5962, R:0.0105)
Batch 100/537: Loss=1.5930 (C:1.5930, R:0.0105)
Batch 125/537: Loss=1.5981 (C:1.5981, R:0.0105)
Batch 150/537: Loss=1.6014 (C:1.6014, R:0.0106)
Batch 175/537: Loss=1.5694 (C:1.5694, R:0.0105)
Batch 200/537: Loss=1.5730 (C:1.5730, R:0.0105)
Batch 225/537: Loss=1.5725 (C:1.5725, R:0.0105)
Batch 250/537: Loss=1.5430 (C:1.5430, R:0.0105)
Batch 275/537: Loss=1.5773 (C:1.5773, R:0.0105)
Batch 300/537: Loss=1.5560 (C:1.5560, R:0.0105)
Batch 325/537: Loss=1.5586 (C:1.5586, R:0.0105)
Batch 350/537: Loss=1.6121 (C:1.6121, R:0.0105)
Batch 375/537: Loss=1.6122 (C:1.6122, R:0.0105)
Batch 400/537: Loss=1.5644 (C:1.5644, R:0.0105)
Batch 425/537: Loss=1.5809 (C:1.5809, R:0.0106)
Batch 450/537: Loss=1.6147 (C:1.6147, R:0.0105)
Batch 475/537: Loss=1.6245 (C:1.6245, R:0.0105)
Batch 500/537: Loss=1.5692 (C:1.5692, R:0.0105)
Batch 525/537: Loss=1.5780 (C:1.5780, R:0.0105)

============================================================
Epoch 11/300 completed in 21.8s
Train: Loss=1.5837 (C:1.5837, R:0.0105) Ratio=3.35x
Val:   Loss=1.6533 (C:1.6533, R:0.0104) Ratio=2.89x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

Epoch 12 Training
----------------------------------------
Batch   0/537: Loss=1.6010 (C:1.6010, R:0.0105)
Batch  25/537: Loss=1.5422 (C:1.5422, R:0.0105)
Batch  50/537: Loss=1.5930 (C:1.5930, R:0.0105)
Batch  75/537: Loss=1.5155 (C:1.5155, R:0.0105)
Batch 100/537: Loss=1.5927 (C:1.5927, R:0.0105)
Batch 125/537: Loss=1.5752 (C:1.5752, R:0.0105)
Batch 150/537: Loss=1.5361 (C:1.5361, R:0.0105)
Batch 175/537: Loss=1.5741 (C:1.5741, R:0.0105)
Batch 200/537: Loss=1.5841 (C:1.5841, R:0.0105)
Batch 225/537: Loss=1.5361 (C:1.5361, R:0.0105)
Batch 250/537: Loss=1.5976 (C:1.5976, R:0.0105)
Batch 275/537: Loss=1.5684 (C:1.5684, R:0.0105)
Batch 300/537: Loss=1.5921 (C:1.5921, R:0.0105)
Batch 325/537: Loss=1.5757 (C:1.5757, R:0.0105)
Batch 350/537: Loss=1.5780 (C:1.5780, R:0.0105)
Batch 375/537: Loss=1.6097 (C:1.6097, R:0.0105)
Batch 400/537: Loss=1.6002 (C:1.6002, R:0.0105)
Batch 425/537: Loss=1.5644 (C:1.5644, R:0.0105)
Batch 450/537: Loss=1.5427 (C:1.5427, R:0.0105)
Batch 475/537: Loss=1.6016 (C:1.6016, R:0.0105)
Batch 500/537: Loss=1.5596 (C:1.5596, R:0.0105)
Batch 525/537: Loss=1.6144 (C:1.6144, R:0.0105)

============================================================
Epoch 12/300 completed in 21.7s
Train: Loss=1.5756 (C:1.5756, R:0.0105) Ratio=3.43x
Val:   Loss=1.6329 (C:1.6329, R:0.0104) Ratio=2.91x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.6329)
============================================================

🌍 Updating global dataset at epoch 13
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.572 ± 0.786
    Neg distances: 2.393 ± 1.262
    Separation ratio: 4.18x
    Gap: -4.302
    ✅ Excellent global separation!

Epoch 13 Training
----------------------------------------
Batch   0/537: Loss=1.5160 (C:1.5160, R:0.0105)
Batch  25/537: Loss=1.4880 (C:1.4880, R:0.0105)
Batch  50/537: Loss=1.5116 (C:1.5116, R:0.0105)
Batch  75/537: Loss=1.4484 (C:1.4484, R:0.0105)
Batch 100/537: Loss=1.4890 (C:1.4890, R:0.0106)
Batch 125/537: Loss=1.4797 (C:1.4797, R:0.0105)
Batch 150/537: Loss=1.5693 (C:1.5693, R:0.0105)
Batch 175/537: Loss=1.5325 (C:1.5325, R:0.0105)
Batch 200/537: Loss=1.5711 (C:1.5711, R:0.0105)
Batch 225/537: Loss=1.5346 (C:1.5346, R:0.0105)
Batch 250/537: Loss=1.4688 (C:1.4688, R:0.0105)
Batch 275/537: Loss=1.5600 (C:1.5600, R:0.0105)
Batch 300/537: Loss=1.5476 (C:1.5476, R:0.0105)
Batch 325/537: Loss=1.5226 (C:1.5226, R:0.0105)
Batch 350/537: Loss=1.4936 (C:1.4936, R:0.0105)
Batch 375/537: Loss=1.5275 (C:1.5275, R:0.0105)
Batch 400/537: Loss=1.4854 (C:1.4854, R:0.0105)
Batch 425/537: Loss=1.4977 (C:1.4977, R:0.0105)
Batch 450/537: Loss=1.5422 (C:1.5422, R:0.0105)
Batch 475/537: Loss=1.4978 (C:1.4978, R:0.0105)
Batch 500/537: Loss=1.4705 (C:1.4705, R:0.0105)
Batch 525/537: Loss=1.4955 (C:1.4955, R:0.0105)

============================================================
Epoch 13/300 completed in 27.6s
Train: Loss=1.5026 (C:1.5026, R:0.0105) Ratio=3.45x
Val:   Loss=1.5711 (C:1.5711, R:0.0104) Ratio=2.95x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.5711)
============================================================

Epoch 14 Training
----------------------------------------
Batch   0/537: Loss=1.4538 (C:1.4538, R:0.0105)
Batch  25/537: Loss=1.5162 (C:1.5162, R:0.0105)
Batch  50/537: Loss=1.4729 (C:1.4729, R:0.0105)
Batch  75/537: Loss=1.5249 (C:1.5249, R:0.0105)
Batch 100/537: Loss=1.4857 (C:1.4857, R:0.0105)
Batch 125/537: Loss=1.4886 (C:1.4886, R:0.0105)
Batch 150/537: Loss=1.5221 (C:1.5221, R:0.0105)
Batch 175/537: Loss=1.4894 (C:1.4894, R:0.0105)
Batch 200/537: Loss=1.4850 (C:1.4850, R:0.0105)
Batch 225/537: Loss=1.4546 (C:1.4546, R:0.0105)
Batch 250/537: Loss=1.5023 (C:1.5023, R:0.0105)
Batch 275/537: Loss=1.4871 (C:1.4871, R:0.0105)
Batch 300/537: Loss=1.4707 (C:1.4707, R:0.0105)
Batch 325/537: Loss=1.5513 (C:1.5513, R:0.0105)
Batch 350/537: Loss=1.5591 (C:1.5591, R:0.0105)
Batch 375/537: Loss=1.5075 (C:1.5075, R:0.0105)
Batch 400/537: Loss=1.4999 (C:1.4999, R:0.0105)
Batch 425/537: Loss=1.5367 (C:1.5367, R:0.0105)
Batch 450/537: Loss=1.4738 (C:1.4738, R:0.0105)
Batch 475/537: Loss=1.5064 (C:1.5064, R:0.0105)
Batch 500/537: Loss=1.4627 (C:1.4627, R:0.0105)
Batch 525/537: Loss=1.5131 (C:1.5131, R:0.0105)

============================================================
Epoch 14/300 completed in 21.5s
Train: Loss=1.4939 (C:1.4939, R:0.0105) Ratio=3.57x
Val:   Loss=1.5661 (C:1.5661, R:0.0104) Ratio=2.94x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.5661)
============================================================

Epoch 15 Training
----------------------------------------
Batch   0/537: Loss=1.4634 (C:1.4634, R:0.0105)
Batch  25/537: Loss=1.4650 (C:1.4650, R:0.0105)
Batch  50/537: Loss=1.4743 (C:1.4743, R:0.0105)
Batch  75/537: Loss=1.5024 (C:1.5024, R:0.0105)
Batch 100/537: Loss=1.4813 (C:1.4813, R:0.0105)
Batch 125/537: Loss=1.5092 (C:1.5092, R:0.0105)
Batch 150/537: Loss=1.4826 (C:1.4826, R:0.0105)
Batch 175/537: Loss=1.4912 (C:1.4912, R:0.0105)
Batch 200/537: Loss=1.4455 (C:1.4455, R:0.0105)
Batch 225/537: Loss=1.4857 (C:1.4857, R:0.0105)
Batch 250/537: Loss=1.4373 (C:1.4373, R:0.0105)
Batch 275/537: Loss=1.4928 (C:1.4928, R:0.0105)
Batch 300/537: Loss=1.5237 (C:1.5237, R:0.0105)
Batch 325/537: Loss=1.4125 (C:1.4125, R:0.0105)
Batch 350/537: Loss=1.4976 (C:1.4976, R:0.0105)
Batch 375/537: Loss=1.4774 (C:1.4774, R:0.0105)
Batch 400/537: Loss=1.5599 (C:1.5599, R:0.0105)
Batch 425/537: Loss=1.4773 (C:1.4773, R:0.0105)
Batch 450/537: Loss=1.4945 (C:1.4945, R:0.0105)
Batch 475/537: Loss=1.4954 (C:1.4954, R:0.0105)
Batch 500/537: Loss=1.5163 (C:1.5163, R:0.0105)
Batch 525/537: Loss=1.5012 (C:1.5012, R:0.0105)

============================================================
Epoch 15/300 completed in 21.5s
Train: Loss=1.4849 (C:1.4849, R:0.0105) Ratio=3.56x
Val:   Loss=1.5765 (C:1.5765, R:0.0104) Ratio=2.95x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 16
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.548 ± 0.798
    Neg distances: 2.488 ± 1.285
    Separation ratio: 4.54x
    Gap: -4.339
    ✅ Excellent global separation!

Epoch 16 Training
----------------------------------------
Batch   0/537: Loss=1.4868 (C:1.4868, R:0.0105)
Batch  25/537: Loss=1.4995 (C:1.4995, R:0.0105)
Batch  50/537: Loss=1.4682 (C:1.4682, R:0.0105)
Batch  75/537: Loss=1.4565 (C:1.4565, R:0.0105)
Batch 100/537: Loss=1.4311 (C:1.4311, R:0.0105)
Batch 125/537: Loss=1.4297 (C:1.4297, R:0.0105)
Batch 150/537: Loss=1.4415 (C:1.4415, R:0.0105)
Batch 175/537: Loss=1.5331 (C:1.5331, R:0.0105)
Batch 200/537: Loss=1.4572 (C:1.4572, R:0.0105)
Batch 225/537: Loss=1.4601 (C:1.4601, R:0.0105)
Batch 250/537: Loss=1.4257 (C:1.4257, R:0.0105)
Batch 275/537: Loss=1.4580 (C:1.4580, R:0.0105)
Batch 300/537: Loss=1.4278 (C:1.4278, R:0.0105)
Batch 325/537: Loss=1.4482 (C:1.4482, R:0.0105)
Batch 350/537: Loss=1.4482 (C:1.4482, R:0.0105)
Batch 375/537: Loss=1.3993 (C:1.3993, R:0.0105)
Batch 400/537: Loss=1.4219 (C:1.4219, R:0.0105)
Batch 425/537: Loss=1.4819 (C:1.4819, R:0.0105)
Batch 450/537: Loss=1.4542 (C:1.4542, R:0.0105)
Batch 475/537: Loss=1.3995 (C:1.3995, R:0.0105)
Batch 500/537: Loss=1.4275 (C:1.4275, R:0.0105)
Batch 525/537: Loss=1.4777 (C:1.4777, R:0.0105)

============================================================
Epoch 16/300 completed in 27.5s
Train: Loss=1.4374 (C:1.4374, R:0.0105) Ratio=3.62x
Val:   Loss=1.5275 (C:1.5275, R:0.0104) Ratio=2.92x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.5275)
============================================================

Epoch 17 Training
----------------------------------------
Batch   0/537: Loss=1.4523 (C:1.4523, R:0.0106)
Batch  25/537: Loss=1.4207 (C:1.4207, R:0.0105)
Batch  50/537: Loss=1.4207 (C:1.4207, R:0.0105)
Batch  75/537: Loss=1.4314 (C:1.4314, R:0.0105)
Batch 100/537: Loss=1.4120 (C:1.4120, R:0.0105)
Batch 125/537: Loss=1.4358 (C:1.4358, R:0.0105)
Batch 150/537: Loss=1.4158 (C:1.4158, R:0.0105)
Batch 175/537: Loss=1.4140 (C:1.4140, R:0.0105)
Batch 200/537: Loss=1.4696 (C:1.4696, R:0.0105)
Batch 225/537: Loss=1.4546 (C:1.4546, R:0.0105)
Batch 250/537: Loss=1.4683 (C:1.4683, R:0.0105)
Batch 275/537: Loss=1.4157 (C:1.4157, R:0.0105)
Batch 300/537: Loss=1.5017 (C:1.5017, R:0.0105)
Batch 325/537: Loss=1.4387 (C:1.4387, R:0.0105)
Batch 350/537: Loss=1.3897 (C:1.3897, R:0.0105)
Batch 375/537: Loss=1.4407 (C:1.4407, R:0.0105)
Batch 400/537: Loss=1.4148 (C:1.4148, R:0.0105)
Batch 425/537: Loss=1.4182 (C:1.4182, R:0.0106)
Batch 450/537: Loss=1.4734 (C:1.4734, R:0.0106)
Batch 475/537: Loss=1.3953 (C:1.3953, R:0.0105)
Batch 500/537: Loss=1.3586 (C:1.3586, R:0.0105)
Batch 525/537: Loss=1.4849 (C:1.4849, R:0.0105)

============================================================
Epoch 17/300 completed in 21.4s
Train: Loss=1.4313 (C:1.4313, R:0.0105) Ratio=3.72x
Val:   Loss=1.5239 (C:1.5239, R:0.0104) Ratio=2.95x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.5239)
============================================================

Epoch 18 Training
----------------------------------------
Batch   0/537: Loss=1.4624 (C:1.4624, R:0.0105)
Batch  25/537: Loss=1.3960 (C:1.3960, R:0.0105)
Batch  50/537: Loss=1.4279 (C:1.4279, R:0.0105)
Batch  75/537: Loss=1.4673 (C:1.4673, R:0.0105)
Batch 100/537: Loss=1.3623 (C:1.3623, R:0.0105)
Batch 125/537: Loss=1.4500 (C:1.4500, R:0.0105)
Batch 150/537: Loss=1.4510 (C:1.4510, R:0.0105)
Batch 175/537: Loss=1.3602 (C:1.3602, R:0.0105)
Batch 200/537: Loss=1.4309 (C:1.4309, R:0.0105)
Batch 225/537: Loss=1.3965 (C:1.3965, R:0.0105)
Batch 250/537: Loss=1.3738 (C:1.3738, R:0.0105)
Batch 275/537: Loss=1.4878 (C:1.4878, R:0.0105)
Batch 300/537: Loss=1.4601 (C:1.4601, R:0.0105)
Batch 325/537: Loss=1.4422 (C:1.4422, R:0.0105)
Batch 350/537: Loss=1.4245 (C:1.4245, R:0.0105)
Batch 375/537: Loss=1.3998 (C:1.3998, R:0.0105)
Batch 400/537: Loss=1.4897 (C:1.4897, R:0.0106)
Batch 425/537: Loss=1.4320 (C:1.4320, R:0.0105)
Batch 450/537: Loss=1.4239 (C:1.4239, R:0.0105)
Batch 475/537: Loss=1.4568 (C:1.4568, R:0.0106)
Batch 500/537: Loss=1.4445 (C:1.4445, R:0.0105)
Batch 525/537: Loss=1.4970 (C:1.4970, R:0.0105)

============================================================
Epoch 18/300 completed in 21.1s
Train: Loss=1.4257 (C:1.4257, R:0.0105) Ratio=3.78x
Val:   Loss=1.5170 (C:1.5170, R:0.0104) Ratio=2.97x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.5170)
============================================================

🌍 Updating global dataset at epoch 19
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.554 ± 0.820
    Neg distances: 2.535 ± 1.290
    Separation ratio: 4.58x
    Gap: -4.417
    ✅ Excellent global separation!

Epoch 19 Training
----------------------------------------
Batch   0/537: Loss=1.3447 (C:1.3447, R:0.0105)
Batch  25/537: Loss=1.4504 (C:1.4504, R:0.0105)
Batch  50/537: Loss=1.4350 (C:1.4350, R:0.0105)
Batch  75/537: Loss=1.4209 (C:1.4209, R:0.0105)
Batch 100/537: Loss=1.4274 (C:1.4274, R:0.0105)
Batch 125/537: Loss=1.4486 (C:1.4486, R:0.0105)
Batch 150/537: Loss=1.3965 (C:1.3965, R:0.0105)
Batch 175/537: Loss=1.4324 (C:1.4324, R:0.0105)
Batch 200/537: Loss=1.4176 (C:1.4176, R:0.0105)
Batch 225/537: Loss=1.3575 (C:1.3575, R:0.0105)
Batch 250/537: Loss=1.4214 (C:1.4214, R:0.0105)
Batch 275/537: Loss=1.3781 (C:1.3781, R:0.0105)
Batch 300/537: Loss=1.4306 (C:1.4306, R:0.0105)
Batch 325/537: Loss=1.4340 (C:1.4340, R:0.0105)
Batch 350/537: Loss=1.3833 (C:1.3833, R:0.0105)
Batch 375/537: Loss=1.3978 (C:1.3978, R:0.0105)
Batch 400/537: Loss=1.3454 (C:1.3454, R:0.0105)
Batch 425/537: Loss=1.4319 (C:1.4319, R:0.0105)
Batch 450/537: Loss=1.4613 (C:1.4613, R:0.0105)
Batch 475/537: Loss=1.3987 (C:1.3987, R:0.0105)
Batch 500/537: Loss=1.4411 (C:1.4411, R:0.0105)
Batch 525/537: Loss=1.4045 (C:1.4045, R:0.0105)

============================================================
Epoch 19/300 completed in 27.5s
Train: Loss=1.4072 (C:1.4072, R:0.0105) Ratio=3.83x
Val:   Loss=1.5242 (C:1.5242, R:0.0104) Ratio=3.00x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

Epoch 20 Training
----------------------------------------
Batch   0/537: Loss=1.4472 (C:1.4472, R:0.0105)
Batch  25/537: Loss=1.4464 (C:1.4464, R:0.0105)
Batch  50/537: Loss=1.4206 (C:1.4206, R:0.0105)
Batch  75/537: Loss=1.4171 (C:1.4171, R:0.0106)
Batch 100/537: Loss=1.4284 (C:1.4284, R:0.0105)
Batch 125/537: Loss=1.4038 (C:1.4038, R:0.0105)
Batch 150/537: Loss=1.4556 (C:1.4556, R:0.0105)
Batch 175/537: Loss=1.3487 (C:1.3487, R:0.0105)
Batch 200/537: Loss=1.4151 (C:1.4151, R:0.0105)
Batch 225/537: Loss=1.4149 (C:1.4149, R:0.0106)
Batch 250/537: Loss=1.4188 (C:1.4188, R:0.0105)
Batch 275/537: Loss=1.4355 (C:1.4355, R:0.0105)
Batch 300/537: Loss=1.4270 (C:1.4270, R:0.0105)
Batch 325/537: Loss=1.3960 (C:1.3960, R:0.0105)
Batch 350/537: Loss=1.4283 (C:1.4283, R:0.0105)
Batch 375/537: Loss=1.4030 (C:1.4030, R:0.0105)
Batch 400/537: Loss=1.4237 (C:1.4237, R:0.0105)
Batch 425/537: Loss=1.3858 (C:1.3858, R:0.0105)
Batch 450/537: Loss=1.4086 (C:1.4086, R:0.0105)
Batch 475/537: Loss=1.4419 (C:1.4419, R:0.0105)
Batch 500/537: Loss=1.4366 (C:1.4366, R:0.0105)
Batch 525/537: Loss=1.3612 (C:1.3612, R:0.0105)

============================================================
Epoch 20/300 completed in 21.2s
Train: Loss=1.4044 (C:1.4044, R:0.0105) Ratio=3.87x
Val:   Loss=1.5126 (C:1.5126, R:0.0104) Ratio=2.97x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.5126)
Checkpoint saved at epoch 20
============================================================

Epoch 21 Training
----------------------------------------
Batch   0/537: Loss=1.3695 (C:1.3695, R:0.0105)
Batch  25/537: Loss=1.4114 (C:1.4114, R:0.0105)
Batch  50/537: Loss=1.3748 (C:1.3748, R:0.0105)
Batch  75/537: Loss=1.3624 (C:1.3624, R:0.0105)
Batch 100/537: Loss=1.3517 (C:1.3517, R:0.0105)
Batch 125/537: Loss=1.3544 (C:1.3544, R:0.0105)
Batch 150/537: Loss=1.3826 (C:1.3826, R:0.0105)
Batch 175/537: Loss=1.3812 (C:1.3812, R:0.0105)
Batch 200/537: Loss=1.4097 (C:1.4097, R:0.0105)
Batch 225/537: Loss=1.3496 (C:1.3496, R:0.0105)
Batch 250/537: Loss=1.4118 (C:1.4118, R:0.0105)
Batch 275/537: Loss=1.4130 (C:1.4130, R:0.0105)
Batch 300/537: Loss=1.3870 (C:1.3870, R:0.0105)
Batch 325/537: Loss=1.4181 (C:1.4181, R:0.0105)
Batch 350/537: Loss=1.3780 (C:1.3780, R:0.0105)
Batch 375/537: Loss=1.3745 (C:1.3745, R:0.0105)
Batch 400/537: Loss=1.4095 (C:1.4095, R:0.0105)
Batch 425/537: Loss=1.4091 (C:1.4091, R:0.0105)
Batch 450/537: Loss=1.4088 (C:1.4088, R:0.0105)
Batch 475/537: Loss=1.3758 (C:1.3758, R:0.0105)
Batch 500/537: Loss=1.4599 (C:1.4599, R:0.0105)
Batch 525/537: Loss=1.4097 (C:1.4097, R:0.0105)

============================================================
Epoch 21/300 completed in 21.2s
Train: Loss=1.3979 (C:1.3979, R:0.0105) Ratio=3.91x
Val:   Loss=1.5071 (C:1.5071, R:0.0104) Ratio=2.99x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.5071)
============================================================

🌍 Updating global dataset at epoch 22
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.523 ± 0.784
    Neg distances: 2.599 ± 1.296
    Separation ratio: 4.97x
    Gap: -4.507
    ✅ Excellent global separation!

Epoch 22 Training
----------------------------------------
Batch   0/537: Loss=1.3336 (C:1.3336, R:0.0105)
Batch  25/537: Loss=1.3374 (C:1.3374, R:0.0105)
Batch  50/537: Loss=1.3233 (C:1.3233, R:0.0105)
Batch  75/537: Loss=1.3383 (C:1.3383, R:0.0105)
Batch 100/537: Loss=1.3274 (C:1.3274, R:0.0105)
Batch 125/537: Loss=1.3801 (C:1.3801, R:0.0105)
Batch 150/537: Loss=1.3571 (C:1.3571, R:0.0105)
Batch 175/537: Loss=1.3546 (C:1.3546, R:0.0105)
Batch 200/537: Loss=1.3440 (C:1.3440, R:0.0105)
Batch 225/537: Loss=1.3575 (C:1.3575, R:0.0105)
Batch 250/537: Loss=1.3502 (C:1.3502, R:0.0105)
Batch 275/537: Loss=1.3893 (C:1.3893, R:0.0105)
Batch 300/537: Loss=1.3365 (C:1.3365, R:0.0105)
Batch 325/537: Loss=1.3281 (C:1.3281, R:0.0105)
Batch 350/537: Loss=1.3757 (C:1.3757, R:0.0105)
Batch 375/537: Loss=1.3202 (C:1.3202, R:0.0105)
Batch 400/537: Loss=1.3515 (C:1.3515, R:0.0105)
Batch 425/537: Loss=1.3401 (C:1.3401, R:0.0105)
Batch 450/537: Loss=1.3652 (C:1.3652, R:0.0105)
Batch 475/537: Loss=1.4103 (C:1.4103, R:0.0105)
Batch 500/537: Loss=1.3752 (C:1.3752, R:0.0105)
Batch 525/537: Loss=1.3728 (C:1.3728, R:0.0105)

============================================================
Epoch 22/300 completed in 27.5s
Train: Loss=1.3569 (C:1.3569, R:0.0105) Ratio=4.03x
Val:   Loss=1.4672 (C:1.4672, R:0.0104) Ratio=2.97x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.4672)
============================================================

Epoch 23 Training
----------------------------------------
Batch   0/537: Loss=1.3367 (C:1.3367, R:0.0105)
Batch  25/537: Loss=1.3251 (C:1.3251, R:0.0105)
Batch  50/537: Loss=1.3773 (C:1.3773, R:0.0105)
Batch  75/537: Loss=1.3250 (C:1.3250, R:0.0105)
Batch 100/537: Loss=1.4237 (C:1.4237, R:0.0105)
Batch 125/537: Loss=1.3597 (C:1.3597, R:0.0105)
Batch 150/537: Loss=1.3273 (C:1.3273, R:0.0105)
Batch 175/537: Loss=1.3493 (C:1.3493, R:0.0105)
Batch 200/537: Loss=1.3131 (C:1.3131, R:0.0105)
Batch 225/537: Loss=1.3475 (C:1.3475, R:0.0105)
Batch 250/537: Loss=1.3969 (C:1.3969, R:0.0105)
Batch 275/537: Loss=1.3821 (C:1.3821, R:0.0105)
Batch 300/537: Loss=1.3480 (C:1.3480, R:0.0105)
Batch 325/537: Loss=1.3709 (C:1.3709, R:0.0105)
Batch 350/537: Loss=1.3594 (C:1.3594, R:0.0105)
Batch 375/537: Loss=1.3080 (C:1.3080, R:0.0105)
Batch 400/537: Loss=1.3609 (C:1.3609, R:0.0105)
Batch 425/537: Loss=1.3207 (C:1.3207, R:0.0105)
Batch 450/537: Loss=1.3199 (C:1.3199, R:0.0105)
Batch 475/537: Loss=1.3720 (C:1.3720, R:0.0105)
Batch 500/537: Loss=1.3581 (C:1.3581, R:0.0105)
Batch 525/537: Loss=1.3510 (C:1.3510, R:0.0105)

============================================================
Epoch 23/300 completed in 27.2s
Train: Loss=1.3531 (C:1.3531, R:0.0105) Ratio=4.05x
Val:   Loss=1.4776 (C:1.4776, R:0.0104) Ratio=2.98x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

Epoch 24 Training
----------------------------------------
Batch   0/537: Loss=1.3345 (C:1.3345, R:0.0105)
Batch  25/537: Loss=1.3193 (C:1.3193, R:0.0106)
Batch  50/537: Loss=1.2977 (C:1.2977, R:0.0105)
Batch  75/537: Loss=1.3420 (C:1.3420, R:0.0106)
Batch 100/537: Loss=1.3290 (C:1.3290, R:0.0105)
Batch 125/537: Loss=1.3483 (C:1.3483, R:0.0105)
Batch 150/537: Loss=1.3848 (C:1.3848, R:0.0105)
Batch 175/537: Loss=1.3033 (C:1.3033, R:0.0105)
Batch 200/537: Loss=1.3318 (C:1.3318, R:0.0105)
Batch 225/537: Loss=1.3406 (C:1.3406, R:0.0105)
Batch 250/537: Loss=1.3518 (C:1.3518, R:0.0105)
Batch 275/537: Loss=1.3391 (C:1.3391, R:0.0105)
Batch 300/537: Loss=1.3441 (C:1.3441, R:0.0105)
Batch 325/537: Loss=1.3402 (C:1.3402, R:0.0105)
Batch 350/537: Loss=1.4010 (C:1.4010, R:0.0105)
Batch 375/537: Loss=1.3394 (C:1.3394, R:0.0105)
Batch 400/537: Loss=1.3900 (C:1.3900, R:0.0105)
Batch 425/537: Loss=1.3537 (C:1.3537, R:0.0105)
Batch 450/537: Loss=1.3553 (C:1.3553, R:0.0106)
Batch 475/537: Loss=1.3796 (C:1.3796, R:0.0105)
Batch 500/537: Loss=1.3589 (C:1.3589, R:0.0105)
Batch 525/537: Loss=1.3479 (C:1.3479, R:0.0105)

============================================================
Epoch 24/300 completed in 21.4s
Train: Loss=1.3487 (C:1.3487, R:0.0105) Ratio=4.13x
Val:   Loss=1.4732 (C:1.4732, R:0.0104) Ratio=3.02x
Reconstruction weight: 0.000
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 25
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.516 ± 0.772
    Neg distances: 2.699 ± 1.322
    Separation ratio: 5.23x
    Gap: -4.711
    ✅ Excellent global separation!

Epoch 25 Training
----------------------------------------
Batch   0/537: Loss=1.3727 (C:1.3727, R:0.0105)
Batch  25/537: Loss=1.3148 (C:1.3148, R:0.0105)
Batch  50/537: Loss=1.2931 (C:1.2931, R:0.0105)
Batch  75/537: Loss=1.2531 (C:1.2531, R:0.0105)
Batch 100/537: Loss=1.3147 (C:1.3147, R:0.0105)
Batch 125/537: Loss=1.2931 (C:1.2931, R:0.0105)
Batch 150/537: Loss=1.3042 (C:1.3042, R:0.0105)
Batch 175/537: Loss=1.2938 (C:1.2938, R:0.0105)
Batch 200/537: Loss=1.2556 (C:1.2556, R:0.0105)
Batch 225/537: Loss=1.2590 (C:1.2590, R:0.0105)
Batch 250/537: Loss=1.3332 (C:1.3332, R:0.0105)
Batch 275/537: Loss=1.2983 (C:1.2983, R:0.0105)
Batch 300/537: Loss=1.3500 (C:1.3500, R:0.0105)
Batch 325/537: Loss=1.3102 (C:1.3102, R:0.0105)
Batch 350/537: Loss=1.2830 (C:1.2830, R:0.0105)
Batch 375/537: Loss=1.3340 (C:1.3340, R:0.0105)
Batch 400/537: Loss=1.3071 (C:1.3071, R:0.0105)
Batch 425/537: Loss=1.3246 (C:1.3246, R:0.0105)
Batch 450/537: Loss=1.3032 (C:1.3032, R:0.0105)
Batch 475/537: Loss=1.3171 (C:1.3171, R:0.0105)
Batch 500/537: Loss=1.2823 (C:1.2823, R:0.0105)
Batch 525/537: Loss=1.2846 (C:1.2846, R:0.0105)

============================================================
Epoch 25/300 completed in 30.6s
Train: Loss=1.3093 (C:1.3093, R:0.0105) Ratio=4.15x
Val:   Loss=1.4455 (C:1.4455, R:0.0104) Ratio=3.02x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.4455)
============================================================

Epoch 26 Training
----------------------------------------
Batch   0/537: Loss=1.3178 (C:1.3178, R:0.0105)
Batch  25/537: Loss=1.2895 (C:1.2895, R:0.0105)
Batch  50/537: Loss=1.3029 (C:1.3029, R:0.0105)
Batch  75/537: Loss=1.2511 (C:1.2511, R:0.0105)
Batch 100/537: Loss=1.3330 (C:1.3330, R:0.0105)
Batch 125/537: Loss=1.3397 (C:1.3397, R:0.0105)
Batch 150/537: Loss=1.2336 (C:1.2336, R:0.0105)
Batch 175/537: Loss=1.2819 (C:1.2819, R:0.0105)
Batch 200/537: Loss=1.3554 (C:1.3554, R:0.0105)
Batch 225/537: Loss=1.3192 (C:1.3192, R:0.0105)
Batch 250/537: Loss=1.3179 (C:1.3179, R:0.0105)
Batch 275/537: Loss=1.3053 (C:1.3053, R:0.0105)
Batch 300/537: Loss=1.3060 (C:1.3060, R:0.0105)
Batch 325/537: Loss=1.3022 (C:1.3022, R:0.0105)
Batch 350/537: Loss=1.3134 (C:1.3134, R:0.0105)
Batch 375/537: Loss=1.3018 (C:1.3018, R:0.0105)
Batch 400/537: Loss=1.3109 (C:1.3109, R:0.0105)
Batch 425/537: Loss=1.3883 (C:1.3883, R:0.0105)
Batch 450/537: Loss=1.3449 (C:1.3449, R:0.0105)
Batch 475/537: Loss=1.3284 (C:1.3284, R:0.0105)
Batch 500/537: Loss=1.2407 (C:1.2407, R:0.0105)
Batch 525/537: Loss=1.3307 (C:1.3307, R:0.0105)

============================================================
Epoch 26/300 completed in 21.4s
Train: Loss=1.3101 (C:1.3101, R:0.0105) Ratio=4.11x
Val:   Loss=1.4414 (C:1.4414, R:0.0104) Ratio=3.02x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.4414)
============================================================

Epoch 27 Training
----------------------------------------
Batch   0/537: Loss=1.3073 (C:1.3073, R:0.0105)
Batch  25/537: Loss=1.2817 (C:1.2817, R:0.0105)
Batch  50/537: Loss=1.3049 (C:1.3049, R:0.0105)
Batch  75/537: Loss=1.2618 (C:1.2618, R:0.0105)
Batch 100/537: Loss=1.2678 (C:1.2678, R:0.0105)
Batch 125/537: Loss=1.2503 (C:1.2503, R:0.0106)
Batch 150/537: Loss=1.3114 (C:1.3114, R:0.0106)
Batch 175/537: Loss=1.3088 (C:1.3088, R:0.0105)
Batch 200/537: Loss=1.3317 (C:1.3317, R:0.0105)
Batch 225/537: Loss=1.3051 (C:1.3051, R:0.0105)
Batch 250/537: Loss=1.3410 (C:1.3410, R:0.0105)
Batch 275/537: Loss=1.2801 (C:1.2801, R:0.0105)
Batch 300/537: Loss=1.3006 (C:1.3006, R:0.0105)
Batch 325/537: Loss=1.3198 (C:1.3198, R:0.0105)
Batch 350/537: Loss=1.3306 (C:1.3306, R:0.0105)
Batch 375/537: Loss=1.3119 (C:1.3119, R:0.0105)
Batch 400/537: Loss=1.2926 (C:1.2926, R:0.0105)
Batch 425/537: Loss=1.2690 (C:1.2690, R:0.0105)
Batch 450/537: Loss=1.3025 (C:1.3025, R:0.0105)
Batch 475/537: Loss=1.3594 (C:1.3594, R:0.0105)
Batch 500/537: Loss=1.2963 (C:1.2963, R:0.0105)
Batch 525/537: Loss=1.3026 (C:1.3026, R:0.0105)

============================================================
Epoch 27/300 completed in 21.1s
Train: Loss=1.3006 (C:1.3006, R:0.0105) Ratio=4.21x
Val:   Loss=1.4345 (C:1.4345, R:0.0104) Ratio=3.02x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.4345)
============================================================

🌍 Updating global dataset at epoch 28
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.511 ± 0.777
    Neg distances: 2.800 ± 1.346
    Separation ratio: 5.48x
    Gap: -4.810
    ✅ Excellent global separation!

Epoch 28 Training
----------------------------------------
Batch   0/537: Loss=1.2943 (C:1.2943, R:0.0105)
Batch  25/537: Loss=1.2211 (C:1.2211, R:0.0105)
Batch  50/537: Loss=1.2292 (C:1.2292, R:0.0105)
Batch  75/537: Loss=1.2117 (C:1.2117, R:0.0105)
Batch 100/537: Loss=1.2730 (C:1.2730, R:0.0105)
Batch 125/537: Loss=1.2211 (C:1.2211, R:0.0105)
Batch 150/537: Loss=1.2897 (C:1.2897, R:0.0105)
Batch 175/537: Loss=1.2319 (C:1.2319, R:0.0105)
Batch 200/537: Loss=1.1953 (C:1.1953, R:0.0105)
Batch 225/537: Loss=1.2570 (C:1.2570, R:0.0105)
Batch 250/537: Loss=1.2586 (C:1.2586, R:0.0105)
Batch 275/537: Loss=1.2360 (C:1.2360, R:0.0105)
Batch 300/537: Loss=1.2549 (C:1.2549, R:0.0105)
Batch 325/537: Loss=1.2887 (C:1.2887, R:0.0105)
Batch 350/537: Loss=1.2374 (C:1.2374, R:0.0105)
Batch 375/537: Loss=1.2432 (C:1.2432, R:0.0105)
Batch 400/537: Loss=1.2829 (C:1.2829, R:0.0105)
Batch 425/537: Loss=1.2526 (C:1.2526, R:0.0105)
Batch 450/537: Loss=1.2304 (C:1.2304, R:0.0105)
Batch 475/537: Loss=1.2198 (C:1.2198, R:0.0105)
Batch 500/537: Loss=1.2584 (C:1.2584, R:0.0105)
Batch 525/537: Loss=1.2614 (C:1.2614, R:0.0105)

============================================================
Epoch 28/300 completed in 27.3s
Train: Loss=1.2625 (C:1.2625, R:0.0105) Ratio=4.25x
Val:   Loss=1.4086 (C:1.4086, R:0.0104) Ratio=2.99x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.4086)
============================================================

Epoch 29 Training
----------------------------------------
Batch   0/537: Loss=1.2863 (C:1.2863, R:0.0105)
Batch  25/537: Loss=1.2153 (C:1.2153, R:0.0105)
Batch  50/537: Loss=1.2593 (C:1.2593, R:0.0105)
Batch  75/537: Loss=1.2130 (C:1.2130, R:0.0105)
Batch 100/537: Loss=1.2423 (C:1.2423, R:0.0105)
Batch 125/537: Loss=1.2667 (C:1.2667, R:0.0105)
Batch 150/537: Loss=1.2606 (C:1.2606, R:0.0105)
Batch 175/537: Loss=1.2747 (C:1.2747, R:0.0105)
Batch 200/537: Loss=1.2517 (C:1.2517, R:0.0105)
Batch 225/537: Loss=1.2620 (C:1.2620, R:0.0105)
Batch 250/537: Loss=1.2307 (C:1.2307, R:0.0105)
Batch 275/537: Loss=1.2838 (C:1.2838, R:0.0105)
Batch 300/537: Loss=1.2381 (C:1.2381, R:0.0105)
Batch 325/537: Loss=1.2455 (C:1.2455, R:0.0106)
Batch 350/537: Loss=1.2900 (C:1.2900, R:0.0105)
Batch 375/537: Loss=1.2179 (C:1.2179, R:0.0105)
Batch 400/537: Loss=1.2665 (C:1.2665, R:0.0105)
Batch 425/537: Loss=1.2771 (C:1.2771, R:0.0105)
Batch 450/537: Loss=1.2886 (C:1.2886, R:0.0105)
Batch 475/537: Loss=1.2810 (C:1.2810, R:0.0105)
Batch 500/537: Loss=1.2555 (C:1.2555, R:0.0105)
Batch 525/537: Loss=1.2587 (C:1.2587, R:0.0105)

============================================================
Epoch 29/300 completed in 21.1s
Train: Loss=1.2597 (C:1.2597, R:0.0105) Ratio=4.28x
Val:   Loss=1.4172 (C:1.4172, R:0.0104) Ratio=3.01x
Reconstruction weight: 0.000
No improvement for 1 epochs
============================================================

Epoch 30 Training
----------------------------------------
Batch   0/537: Loss=1.2556 (C:1.2556, R:0.0105)
Batch  25/537: Loss=1.2441 (C:1.2441, R:0.0105)
Batch  50/537: Loss=1.2226 (C:1.2226, R:0.0105)
Batch  75/537: Loss=1.2407 (C:1.2407, R:0.0105)
Batch 100/537: Loss=1.2161 (C:1.2161, R:0.0105)
Batch 125/537: Loss=1.3082 (C:1.3082, R:0.0105)
Batch 150/537: Loss=1.2498 (C:1.2498, R:0.0105)
Batch 175/537: Loss=1.2232 (C:1.2232, R:0.0105)
Batch 200/537: Loss=1.2094 (C:1.2094, R:0.0105)
Batch 225/537: Loss=1.2317 (C:1.2317, R:0.0105)
Batch 250/537: Loss=1.2616 (C:1.2616, R:0.0105)
Batch 275/537: Loss=1.2524 (C:1.2524, R:0.0105)
Batch 300/537: Loss=1.2367 (C:1.2367, R:0.0105)
Batch 325/537: Loss=1.2924 (C:1.2924, R:0.0105)
Batch 350/537: Loss=1.2243 (C:1.2243, R:0.0105)
Batch 375/537: Loss=1.2144 (C:1.2144, R:0.0105)
Batch 400/537: Loss=1.2533 (C:1.2533, R:0.0106)
Batch 425/537: Loss=1.2621 (C:1.2621, R:0.0105)
Batch 450/537: Loss=1.3051 (C:1.3051, R:0.0105)
Batch 475/537: Loss=1.2891 (C:1.2891, R:0.0105)
Batch 500/537: Loss=1.2519 (C:1.2519, R:0.0105)
Batch 525/537: Loss=1.2632 (C:1.2632, R:0.0105)

============================================================
Epoch 30/300 completed in 21.0s
Train: Loss=1.2579 (C:1.2579, R:0.0105) Ratio=4.31x
Val:   Loss=1.3989 (C:1.3989, R:0.0104) Ratio=3.02x
Reconstruction weight: 0.000
✅ New best model saved (Val Loss: 1.3989)
============================================================

🌍 Updating global dataset at epoch 31
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.494 ± 0.784
    Neg distances: 2.909 ± 1.364
    Separation ratio: 5.89x
    Gap: -4.982
    ✅ Excellent global separation!

Epoch 31 Training
----------------------------------------
Batch   0/537: Loss=1.2164 (C:1.2164, R:0.0105)
Batch  25/537: Loss=1.1909 (C:1.1909, R:0.0105)
Batch  50/537: Loss=1.1962 (C:1.1962, R:0.0105)
Batch  75/537: Loss=1.2164 (C:1.2164, R:0.0105)
Batch 100/537: Loss=1.1729 (C:1.1729, R:0.0105)
Batch 125/537: Loss=1.1860 (C:1.1860, R:0.0105)
Batch 150/537: Loss=1.2227 (C:1.2227, R:0.0105)
Batch 175/537: Loss=1.1816 (C:1.1816, R:0.0105)
Batch 200/537: Loss=1.2104 (C:1.2104, R:0.0106)
Batch 225/537: Loss=1.1339 (C:1.1339, R:0.0105)
Batch 250/537: Loss=1.1907 (C:1.1907, R:0.0105)
Batch 275/537: Loss=1.2195 (C:1.2195, R:0.0105)
Batch 300/537: Loss=1.1632 (C:1.1632, R:0.0105)
Batch 325/537: Loss=1.2337 (C:1.2337, R:0.0105)
Batch 350/537: Loss=1.2090 (C:1.2090, R:0.0105)
Batch 375/537: Loss=1.2236 (C:1.2236, R:0.0105)
Batch 400/537: Loss=1.2145 (C:1.2145, R:0.0105)
Batch 425/537: Loss=1.2154 (C:1.2154, R:0.0105)
Batch 450/537: Loss=1.2648 (C:1.2648, R:0.0105)
Batch 475/537: Loss=1.2663 (C:1.2663, R:0.0105)
Batch 500/537: Loss=1.1948 (C:1.1948, R:0.0106)
Batch 525/537: Loss=1.1714 (C:1.1714, R:0.0105)

============================================================
Epoch 31/300 completed in 27.3s
Train: Loss=1.2086 (C:1.2086, R:0.0105) Ratio=4.36x
Val:   Loss=1.3565 (C:1.3565, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.015
✅ New best model saved (Val Loss: 1.3565)
============================================================

Epoch 32 Training
----------------------------------------
Batch   0/537: Loss=1.1903 (C:1.1903, R:0.0105)
Batch  25/537: Loss=1.2145 (C:1.2145, R:0.0105)
Batch  50/537: Loss=1.1578 (C:1.1578, R:0.0105)
Batch  75/537: Loss=1.1856 (C:1.1856, R:0.0105)
Batch 100/537: Loss=1.1670 (C:1.1670, R:0.0105)
Batch 125/537: Loss=1.1762 (C:1.1762, R:0.0105)
Batch 150/537: Loss=1.1691 (C:1.1691, R:0.0105)
Batch 175/537: Loss=1.2339 (C:1.2339, R:0.0105)
Batch 200/537: Loss=1.2032 (C:1.2032, R:0.0105)
Batch 225/537: Loss=1.1439 (C:1.1439, R:0.0105)
Batch 250/537: Loss=1.2082 (C:1.2082, R:0.0105)
Batch 275/537: Loss=1.2361 (C:1.2361, R:0.0105)
Batch 300/537: Loss=1.2645 (C:1.2645, R:0.0106)
Batch 325/537: Loss=1.1355 (C:1.1355, R:0.0106)
Batch 350/537: Loss=1.2069 (C:1.2069, R:0.0105)
Batch 375/537: Loss=1.2004 (C:1.2004, R:0.0106)
Batch 400/537: Loss=1.2077 (C:1.2077, R:0.0105)
Batch 425/537: Loss=1.2578 (C:1.2578, R:0.0105)
Batch 450/537: Loss=1.1801 (C:1.1801, R:0.0105)
Batch 475/537: Loss=1.2194 (C:1.2194, R:0.0105)
Batch 500/537: Loss=1.2113 (C:1.2113, R:0.0105)
Batch 525/537: Loss=1.1942 (C:1.1942, R:0.0105)

============================================================
Epoch 32/300 completed in 27.8s
Train: Loss=1.2028 (C:1.2028, R:0.0105) Ratio=4.39x
Val:   Loss=1.3633 (C:1.3633, R:0.0104) Ratio=3.03x
Reconstruction weight: 0.030
No improvement for 1 epochs
============================================================

Epoch 33 Training
----------------------------------------
Batch   0/537: Loss=1.2108 (C:1.2108, R:0.0105)
Batch  25/537: Loss=1.1749 (C:1.1749, R:0.0105)
Batch  50/537: Loss=1.2185 (C:1.2185, R:0.0105)
Batch  75/537: Loss=1.2212 (C:1.2212, R:0.0105)
Batch 100/537: Loss=1.1703 (C:1.1703, R:0.0105)
Batch 125/537: Loss=1.2355 (C:1.2355, R:0.0105)
Batch 150/537: Loss=1.2460 (C:1.2460, R:0.0105)
Batch 175/537: Loss=1.1919 (C:1.1919, R:0.0105)
Batch 200/537: Loss=1.1464 (C:1.1464, R:0.0105)
Batch 225/537: Loss=1.1853 (C:1.1853, R:0.0105)
Batch 250/537: Loss=1.2085 (C:1.2085, R:0.0105)
Batch 275/537: Loss=1.2272 (C:1.2272, R:0.0105)
Batch 300/537: Loss=1.1479 (C:1.1479, R:0.0105)
Batch 325/537: Loss=1.1950 (C:1.1950, R:0.0105)
Batch 350/537: Loss=1.2122 (C:1.2122, R:0.0105)
Batch 375/537: Loss=1.2111 (C:1.2111, R:0.0105)
Batch 400/537: Loss=1.2090 (C:1.2090, R:0.0105)
Batch 425/537: Loss=1.2397 (C:1.2397, R:0.0105)
Batch 450/537: Loss=1.1780 (C:1.1780, R:0.0106)
Batch 475/537: Loss=1.2276 (C:1.2276, R:0.0105)
Batch 500/537: Loss=1.2232 (C:1.2232, R:0.0105)
Batch 525/537: Loss=1.1649 (C:1.1649, R:0.0105)

============================================================
Epoch 33/300 completed in 20.9s
Train: Loss=1.1996 (C:1.1996, R:0.0105) Ratio=4.42x
Val:   Loss=1.3701 (C:1.3701, R:0.0104) Ratio=3.02x
Reconstruction weight: 0.045
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 34
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.491 ± 0.773
    Neg distances: 3.014 ± 1.386
    Separation ratio: 6.13x
    Gap: -5.144
    ✅ Excellent global separation!

Epoch 34 Training
----------------------------------------
Batch   0/537: Loss=1.1103 (C:1.1103, R:0.0105)
Batch  25/537: Loss=1.1205 (C:1.1205, R:0.0105)
Batch  50/537: Loss=1.1533 (C:1.1533, R:0.0105)
Batch  75/537: Loss=1.1382 (C:1.1382, R:0.0105)
Batch 100/537: Loss=1.1481 (C:1.1481, R:0.0105)
Batch 125/537: Loss=1.1967 (C:1.1967, R:0.0105)
Batch 150/537: Loss=1.2195 (C:1.2195, R:0.0105)
Batch 175/537: Loss=1.1848 (C:1.1848, R:0.0105)
Batch 200/537: Loss=1.1669 (C:1.1669, R:0.0105)
Batch 225/537: Loss=1.1616 (C:1.1616, R:0.0105)
Batch 250/537: Loss=1.1861 (C:1.1861, R:0.0105)
Batch 275/537: Loss=1.1638 (C:1.1638, R:0.0105)
Batch 300/537: Loss=1.1581 (C:1.1581, R:0.0105)
Batch 325/537: Loss=1.2297 (C:1.2297, R:0.0105)
Batch 350/537: Loss=1.2168 (C:1.2168, R:0.0105)
Batch 375/537: Loss=1.1580 (C:1.1580, R:0.0105)
Batch 400/537: Loss=1.2160 (C:1.2160, R:0.0105)
Batch 425/537: Loss=1.2307 (C:1.2307, R:0.0105)
Batch 450/537: Loss=1.1875 (C:1.1875, R:0.0105)
Batch 475/537: Loss=1.1837 (C:1.1837, R:0.0105)
Batch 500/537: Loss=1.1716 (C:1.1716, R:0.0105)
Batch 525/537: Loss=1.2071 (C:1.2071, R:0.0105)

============================================================
Epoch 34/300 completed in 26.5s
Train: Loss=1.1620 (C:1.1620, R:0.0105) Ratio=4.42x
Val:   Loss=1.3521 (C:1.3521, R:0.0104) Ratio=2.98x
Reconstruction weight: 0.060
✅ New best model saved (Val Loss: 1.3521)
============================================================

Epoch 35 Training
----------------------------------------
Batch   0/537: Loss=1.0990 (C:1.0990, R:0.0105)
Batch  25/537: Loss=1.1759 (C:1.1759, R:0.0106)
Batch  50/537: Loss=1.1678 (C:1.1678, R:0.0105)
Batch  75/537: Loss=1.1622 (C:1.1622, R:0.0105)
Batch 100/537: Loss=1.1547 (C:1.1547, R:0.0105)
Batch 125/537: Loss=1.1811 (C:1.1811, R:0.0105)
Batch 150/537: Loss=1.1787 (C:1.1787, R:0.0105)
Batch 175/537: Loss=1.1244 (C:1.1244, R:0.0105)
Batch 200/537: Loss=1.1419 (C:1.1419, R:0.0105)
Batch 225/537: Loss=1.1410 (C:1.1410, R:0.0105)
Batch 250/537: Loss=1.1579 (C:1.1579, R:0.0105)
Batch 275/537: Loss=1.1005 (C:1.1005, R:0.0106)
Batch 300/537: Loss=1.1357 (C:1.1357, R:0.0105)
Batch 325/537: Loss=1.1562 (C:1.1562, R:0.0105)
Batch 350/537: Loss=1.1340 (C:1.1340, R:0.0105)
Batch 375/537: Loss=1.2033 (C:1.2033, R:0.0105)
Batch 400/537: Loss=1.1521 (C:1.1521, R:0.0105)
Batch 425/537: Loss=1.1592 (C:1.1592, R:0.0105)
Batch 450/537: Loss=1.2045 (C:1.2045, R:0.0105)
Batch 475/537: Loss=1.2263 (C:1.2263, R:0.0105)
Batch 500/537: Loss=1.1685 (C:1.1685, R:0.0105)
Batch 525/537: Loss=1.1376 (C:1.1376, R:0.0105)

============================================================
Epoch 35/300 completed in 21.2s
Train: Loss=1.1572 (C:1.1572, R:0.0105) Ratio=4.55x
Val:   Loss=1.3273 (C:1.3273, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.075
✅ New best model saved (Val Loss: 1.3273)
============================================================

Epoch 36 Training
----------------------------------------
Batch   0/537: Loss=1.1357 (C:1.1357, R:0.0105)
Batch  25/537: Loss=1.1214 (C:1.1214, R:0.0105)
Batch  50/537: Loss=1.1125 (C:1.1125, R:0.0105)
Batch  75/537: Loss=1.1621 (C:1.1621, R:0.0106)
Batch 100/537: Loss=1.1603 (C:1.1603, R:0.0105)
Batch 125/537: Loss=1.1631 (C:1.1631, R:0.0105)
Batch 150/537: Loss=1.1142 (C:1.1142, R:0.0105)
Batch 175/537: Loss=1.1208 (C:1.1208, R:0.0105)
Batch 200/537: Loss=1.2080 (C:1.2080, R:0.0105)
Batch 225/537: Loss=1.1553 (C:1.1553, R:0.0105)
Batch 250/537: Loss=1.1446 (C:1.1446, R:0.0105)
Batch 275/537: Loss=1.1757 (C:1.1757, R:0.0105)
Batch 300/537: Loss=1.1342 (C:1.1342, R:0.0105)
Batch 325/537: Loss=1.1011 (C:1.1011, R:0.0105)
Batch 350/537: Loss=1.1362 (C:1.1362, R:0.0105)
Batch 375/537: Loss=1.1608 (C:1.1608, R:0.0106)
Batch 400/537: Loss=1.1963 (C:1.1963, R:0.0105)
Batch 425/537: Loss=1.1419 (C:1.1419, R:0.0105)
Batch 450/537: Loss=1.1561 (C:1.1561, R:0.0105)
Batch 475/537: Loss=1.2084 (C:1.2084, R:0.0105)
Batch 500/537: Loss=1.1758 (C:1.1758, R:0.0105)
Batch 525/537: Loss=1.1506 (C:1.1506, R:0.0105)

============================================================
Epoch 36/300 completed in 21.1s
Train: Loss=1.1541 (C:1.1541, R:0.0105) Ratio=4.52x
Val:   Loss=1.3197 (C:1.3197, R:0.0104) Ratio=3.07x
Reconstruction weight: 0.090
✅ New best model saved (Val Loss: 1.3197)
============================================================

🌍 Updating global dataset at epoch 37
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.500 ± 0.803
    Neg distances: 3.112 ± 1.421
    Separation ratio: 6.23x
    Gap: -5.223
    ✅ Excellent global separation!

Epoch 37 Training
----------------------------------------
Batch   0/537: Loss=1.1120 (C:1.1120, R:0.0105)
Batch  25/537: Loss=1.1082 (C:1.1082, R:0.0105)
Batch  50/537: Loss=1.1513 (C:1.1513, R:0.0105)
Batch  75/537: Loss=1.1253 (C:1.1253, R:0.0105)
Batch 100/537: Loss=1.1253 (C:1.1253, R:0.0105)
Batch 125/537: Loss=1.1307 (C:1.1307, R:0.0105)
Batch 150/537: Loss=1.0918 (C:1.0918, R:0.0106)
Batch 175/537: Loss=1.1443 (C:1.1443, R:0.0106)
Batch 200/537: Loss=1.1411 (C:1.1411, R:0.0105)
Batch 225/537: Loss=1.1445 (C:1.1445, R:0.0105)
Batch 250/537: Loss=1.1384 (C:1.1384, R:0.0105)
Batch 275/537: Loss=1.1813 (C:1.1813, R:0.0105)
Batch 300/537: Loss=1.1523 (C:1.1523, R:0.0104)
Batch 325/537: Loss=1.1812 (C:1.1812, R:0.0105)
Batch 350/537: Loss=1.1217 (C:1.1217, R:0.0105)
Batch 375/537: Loss=1.1495 (C:1.1495, R:0.0105)
Batch 400/537: Loss=1.1492 (C:1.1492, R:0.0106)
Batch 425/537: Loss=1.1451 (C:1.1451, R:0.0105)
Batch 450/537: Loss=1.1247 (C:1.1247, R:0.0105)
Batch 475/537: Loss=1.1628 (C:1.1628, R:0.0105)
Batch 500/537: Loss=1.1374 (C:1.1374, R:0.0105)
Batch 525/537: Loss=1.0421 (C:1.0421, R:0.0105)

============================================================
Epoch 37/300 completed in 30.3s
Train: Loss=1.1328 (C:1.1328, R:0.0105) Ratio=4.54x
Val:   Loss=1.3049 (C:1.3049, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.105
✅ New best model saved (Val Loss: 1.3049)
============================================================

Epoch 38 Training
----------------------------------------
Batch   0/537: Loss=1.1332 (C:1.1332, R:0.0105)
Batch  25/537: Loss=1.1012 (C:1.1012, R:0.0105)
Batch  50/537: Loss=1.1232 (C:1.1232, R:0.0105)
Batch  75/537: Loss=1.1280 (C:1.1280, R:0.0105)
Batch 100/537: Loss=1.1849 (C:1.1849, R:0.0105)
Batch 125/537: Loss=1.0988 (C:1.0988, R:0.0105)
Batch 150/537: Loss=1.1094 (C:1.1094, R:0.0105)
Batch 175/537: Loss=1.0836 (C:1.0836, R:0.0106)
Batch 200/537: Loss=1.1391 (C:1.1391, R:0.0105)
Batch 225/537: Loss=1.1172 (C:1.1172, R:0.0105)
Batch 250/537: Loss=1.1569 (C:1.1569, R:0.0105)
Batch 275/537: Loss=1.1670 (C:1.1670, R:0.0105)
Batch 300/537: Loss=1.1877 (C:1.1877, R:0.0106)
Batch 325/537: Loss=1.1076 (C:1.1076, R:0.0105)
Batch 350/537: Loss=1.1471 (C:1.1471, R:0.0105)
Batch 375/537: Loss=1.1443 (C:1.1443, R:0.0105)
Batch 400/537: Loss=1.1026 (C:1.1026, R:0.0105)
Batch 425/537: Loss=1.1403 (C:1.1403, R:0.0105)
Batch 450/537: Loss=1.1094 (C:1.1094, R:0.0105)
Batch 475/537: Loss=1.1234 (C:1.1234, R:0.0105)
Batch 500/537: Loss=1.1096 (C:1.1096, R:0.0105)
Batch 525/537: Loss=1.1416 (C:1.1416, R:0.0105)

============================================================
Epoch 38/300 completed in 20.9s
Train: Loss=1.1269 (C:1.1269, R:0.0105) Ratio=4.50x
Val:   Loss=1.2984 (C:1.2984, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.120
✅ New best model saved (Val Loss: 1.2984)
============================================================

Epoch 39 Training
----------------------------------------
Batch   0/537: Loss=1.1175 (C:1.1175, R:0.0105)
Batch  25/537: Loss=1.1605 (C:1.1605, R:0.0105)
Batch  50/537: Loss=1.1433 (C:1.1433, R:0.0105)
Batch  75/537: Loss=1.1328 (C:1.1328, R:0.0105)
Batch 100/537: Loss=1.0960 (C:1.0960, R:0.0105)
Batch 125/537: Loss=1.1091 (C:1.1091, R:0.0105)
Batch 150/537: Loss=1.1152 (C:1.1152, R:0.0105)
Batch 175/537: Loss=1.0997 (C:1.0997, R:0.0105)
Batch 200/537: Loss=1.0684 (C:1.0684, R:0.0105)
Batch 225/537: Loss=1.1294 (C:1.1294, R:0.0105)
Batch 250/537: Loss=1.0812 (C:1.0812, R:0.0105)
Batch 275/537: Loss=1.1301 (C:1.1301, R:0.0105)
Batch 300/537: Loss=1.1612 (C:1.1612, R:0.0105)
Batch 325/537: Loss=1.1853 (C:1.1853, R:0.0106)
Batch 350/537: Loss=1.1142 (C:1.1142, R:0.0105)
Batch 375/537: Loss=1.1722 (C:1.1722, R:0.0105)
Batch 400/537: Loss=1.1626 (C:1.1626, R:0.0105)
Batch 425/537: Loss=1.1445 (C:1.1445, R:0.0105)
Batch 450/537: Loss=1.1338 (C:1.1338, R:0.0105)
Batch 475/537: Loss=1.1424 (C:1.1424, R:0.0105)
Batch 500/537: Loss=1.1423 (C:1.1423, R:0.0105)
Batch 525/537: Loss=1.1473 (C:1.1473, R:0.0105)

============================================================
Epoch 39/300 completed in 21.0s
Train: Loss=1.1247 (C:1.1247, R:0.0105) Ratio=4.58x
Val:   Loss=1.2991 (C:1.2991, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.135
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 40
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.496 ± 0.822
    Neg distances: 3.187 ± 1.426
    Separation ratio: 6.43x
    Gap: -5.403
    ✅ Excellent global separation!

Epoch 40 Training
----------------------------------------
Batch   0/537: Loss=1.0810 (C:1.0810, R:0.0105)
Batch  25/537: Loss=1.1131 (C:1.1131, R:0.0105)
Batch  50/537: Loss=1.0844 (C:1.0844, R:0.0105)
Batch  75/537: Loss=1.0569 (C:1.0569, R:0.0105)
Batch 100/537: Loss=1.0749 (C:1.0749, R:0.0105)
Batch 125/537: Loss=1.0977 (C:1.0977, R:0.0105)
Batch 150/537: Loss=1.0927 (C:1.0927, R:0.0105)
Batch 175/537: Loss=1.0578 (C:1.0578, R:0.0105)
Batch 200/537: Loss=1.1111 (C:1.1111, R:0.0105)
Batch 225/537: Loss=1.0741 (C:1.0741, R:0.0105)
Batch 250/537: Loss=1.0932 (C:1.0932, R:0.0105)
Batch 275/537: Loss=1.0902 (C:1.0902, R:0.0105)
Batch 300/537: Loss=1.1077 (C:1.1077, R:0.0105)
Batch 325/537: Loss=1.1037 (C:1.1037, R:0.0105)
Batch 350/537: Loss=1.0756 (C:1.0756, R:0.0105)
Batch 375/537: Loss=1.1357 (C:1.1357, R:0.0105)
Batch 400/537: Loss=1.0750 (C:1.0750, R:0.0105)
Batch 425/537: Loss=1.0665 (C:1.0665, R:0.0105)
Batch 450/537: Loss=1.1140 (C:1.1140, R:0.0105)
Batch 475/537: Loss=1.1197 (C:1.1197, R:0.0105)
Batch 500/537: Loss=1.1223 (C:1.1223, R:0.0106)
Batch 525/537: Loss=1.1072 (C:1.1072, R:0.0104)

============================================================
Epoch 40/300 completed in 26.6s
Train: Loss=1.0935 (C:1.0935, R:0.0105) Ratio=4.57x
Val:   Loss=1.2677 (C:1.2677, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.150
✅ New best model saved (Val Loss: 1.2677)
Checkpoint saved at epoch 40
============================================================

Epoch 41 Training
----------------------------------------
Batch   0/537: Loss=1.1060 (C:1.1060, R:0.0105)
Batch  25/537: Loss=1.1106 (C:1.1106, R:0.0105)
Batch  50/537: Loss=1.1122 (C:1.1122, R:0.0105)
Batch  75/537: Loss=1.1352 (C:1.1352, R:0.0105)
Batch 100/537: Loss=1.1063 (C:1.1063, R:0.0105)
Batch 125/537: Loss=1.0796 (C:1.0796, R:0.0105)
Batch 150/537: Loss=1.0608 (C:1.0608, R:0.0105)
Batch 175/537: Loss=1.1342 (C:1.1342, R:0.0105)
Batch 200/537: Loss=1.0592 (C:1.0592, R:0.0105)
Batch 225/537: Loss=1.0686 (C:1.0686, R:0.0105)
Batch 250/537: Loss=1.1401 (C:1.1401, R:0.0105)
Batch 275/537: Loss=1.1200 (C:1.1200, R:0.0105)
Batch 300/537: Loss=1.1176 (C:1.1176, R:0.0106)
Batch 325/537: Loss=1.0543 (C:1.0543, R:0.0105)
Batch 350/537: Loss=1.0767 (C:1.0767, R:0.0105)
Batch 375/537: Loss=1.0833 (C:1.0833, R:0.0105)
Batch 400/537: Loss=1.1063 (C:1.1063, R:0.0105)
Batch 425/537: Loss=1.0608 (C:1.0608, R:0.0105)
Batch 450/537: Loss=1.1058 (C:1.1058, R:0.0105)
Batch 475/537: Loss=1.1107 (C:1.1107, R:0.0105)
Batch 500/537: Loss=1.0966 (C:1.0966, R:0.0105)
Batch 525/537: Loss=1.0867 (C:1.0867, R:0.0105)

============================================================
Epoch 41/300 completed in 21.2s
Train: Loss=1.0918 (C:1.0918, R:0.0105) Ratio=4.62x
Val:   Loss=1.2938 (C:1.2938, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.165
No improvement for 1 epochs
============================================================

Epoch 42 Training
----------------------------------------
Batch   0/537: Loss=1.0764 (C:1.0764, R:0.0105)
Batch  25/537: Loss=1.0833 (C:1.0833, R:0.0105)
Batch  50/537: Loss=1.0848 (C:1.0848, R:0.0105)
Batch  75/537: Loss=1.0489 (C:1.0489, R:0.0105)
Batch 100/537: Loss=1.0641 (C:1.0641, R:0.0105)
Batch 125/537: Loss=1.0593 (C:1.0593, R:0.0106)
Batch 150/537: Loss=1.1228 (C:1.1228, R:0.0105)
Batch 175/537: Loss=1.1041 (C:1.1041, R:0.0106)
Batch 200/537: Loss=1.0953 (C:1.0953, R:0.0105)
Batch 225/537: Loss=1.0711 (C:1.0711, R:0.0105)
Batch 250/537: Loss=1.1187 (C:1.1187, R:0.0105)
Batch 275/537: Loss=1.0420 (C:1.0420, R:0.0105)
Batch 300/537: Loss=1.1165 (C:1.1165, R:0.0105)
Batch 325/537: Loss=1.1144 (C:1.1144, R:0.0105)
Batch 350/537: Loss=1.0989 (C:1.0989, R:0.0105)
Batch 375/537: Loss=1.0543 (C:1.0543, R:0.0105)
Batch 400/537: Loss=1.0857 (C:1.0857, R:0.0105)
Batch 425/537: Loss=1.0671 (C:1.0671, R:0.0105)
Batch 450/537: Loss=1.1264 (C:1.1264, R:0.0105)
Batch 475/537: Loss=1.0553 (C:1.0553, R:0.0105)
Batch 500/537: Loss=1.1364 (C:1.1364, R:0.0105)
Batch 525/537: Loss=1.1229 (C:1.1229, R:0.0105)

============================================================
Epoch 42/300 completed in 21.4s
Train: Loss=1.0873 (C:1.0873, R:0.0105) Ratio=4.68x
Val:   Loss=1.2864 (C:1.2864, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.180
No improvement for 2 epochs
============================================================

🌍 Updating global dataset at epoch 43
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.474 ± 0.795
    Neg distances: 3.309 ± 1.458
    Separation ratio: 6.99x
    Gap: -5.491
    ✅ Excellent global separation!

Epoch 43 Training
----------------------------------------
Batch   0/537: Loss=0.9793 (C:0.9793, R:0.0105)
Batch  25/537: Loss=1.0227 (C:1.0227, R:0.0105)
Batch  50/537: Loss=1.0083 (C:1.0083, R:0.0105)
Batch  75/537: Loss=1.0294 (C:1.0294, R:0.0105)
Batch 100/537: Loss=1.0345 (C:1.0345, R:0.0105)
Batch 125/537: Loss=1.0778 (C:1.0778, R:0.0106)
Batch 150/537: Loss=0.9924 (C:0.9924, R:0.0105)
Batch 175/537: Loss=1.0683 (C:1.0683, R:0.0105)
Batch 200/537: Loss=1.0061 (C:1.0061, R:0.0105)
Batch 225/537: Loss=0.9995 (C:0.9995, R:0.0105)
Batch 250/537: Loss=1.0698 (C:1.0698, R:0.0105)
Batch 275/537: Loss=1.0086 (C:1.0086, R:0.0105)
Batch 300/537: Loss=1.0299 (C:1.0299, R:0.0105)
Batch 325/537: Loss=1.0730 (C:1.0730, R:0.0105)
Batch 350/537: Loss=0.9946 (C:0.9946, R:0.0105)
Batch 375/537: Loss=1.0681 (C:1.0681, R:0.0105)
Batch 400/537: Loss=1.0177 (C:1.0177, R:0.0105)
Batch 425/537: Loss=1.0455 (C:1.0455, R:0.0105)
Batch 450/537: Loss=1.0773 (C:1.0773, R:0.0105)
Batch 475/537: Loss=1.1128 (C:1.1128, R:0.0105)
Batch 500/537: Loss=1.0764 (C:1.0764, R:0.0105)
Batch 525/537: Loss=1.0677 (C:1.0677, R:0.0105)

============================================================
Epoch 43/300 completed in 27.3s
Train: Loss=1.0368 (C:1.0368, R:0.0105) Ratio=4.71x
Val:   Loss=1.2261 (C:1.2261, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.195
✅ New best model saved (Val Loss: 1.2261)
============================================================

Epoch 44 Training
----------------------------------------
Batch   0/537: Loss=1.0266 (C:1.0266, R:0.0105)
Batch  25/537: Loss=1.0332 (C:1.0332, R:0.0105)
Batch  50/537: Loss=0.9614 (C:0.9614, R:0.0105)
Batch  75/537: Loss=1.0710 (C:1.0710, R:0.0105)
Batch 100/537: Loss=1.0404 (C:1.0404, R:0.0105)
Batch 125/537: Loss=1.0201 (C:1.0201, R:0.0105)
Batch 150/537: Loss=1.0846 (C:1.0846, R:0.0105)
Batch 175/537: Loss=1.0787 (C:1.0787, R:0.0105)
Batch 200/537: Loss=1.0502 (C:1.0502, R:0.0105)
Batch 225/537: Loss=1.0525 (C:1.0525, R:0.0105)
Batch 250/537: Loss=1.0194 (C:1.0194, R:0.0105)
Batch 275/537: Loss=1.0707 (C:1.0707, R:0.0106)
Batch 300/537: Loss=1.0051 (C:1.0051, R:0.0105)
Batch 325/537: Loss=1.0212 (C:1.0212, R:0.0105)
Batch 350/537: Loss=1.0270 (C:1.0270, R:0.0106)
Batch 375/537: Loss=1.0765 (C:1.0765, R:0.0105)
Batch 400/537: Loss=1.0165 (C:1.0165, R:0.0106)
Batch 425/537: Loss=1.0422 (C:1.0422, R:0.0105)
Batch 450/537: Loss=1.0480 (C:1.0480, R:0.0105)
Batch 475/537: Loss=1.0484 (C:1.0484, R:0.0105)
Batch 500/537: Loss=1.0180 (C:1.0180, R:0.0105)
Batch 525/537: Loss=1.0572 (C:1.0572, R:0.0105)

============================================================
Epoch 44/300 completed in 21.5s
Train: Loss=1.0347 (C:1.0347, R:0.0105) Ratio=4.72x
Val:   Loss=1.2302 (C:1.2302, R:0.0104) Ratio=3.13x
Reconstruction weight: 0.210
No improvement for 1 epochs
============================================================

Epoch 45 Training
----------------------------------------
Batch   0/537: Loss=1.0247 (C:1.0247, R:0.0105)
Batch  25/537: Loss=1.0234 (C:1.0234, R:0.0105)
Batch  50/537: Loss=1.0066 (C:1.0066, R:0.0105)
Batch  75/537: Loss=1.0000 (C:1.0000, R:0.0105)
Batch 100/537: Loss=1.0424 (C:1.0424, R:0.0105)
Batch 125/537: Loss=1.0594 (C:1.0594, R:0.0105)
Batch 150/537: Loss=1.0993 (C:1.0993, R:0.0104)
Batch 175/537: Loss=1.0517 (C:1.0517, R:0.0105)
Batch 200/537: Loss=0.9564 (C:0.9564, R:0.0105)
Batch 225/537: Loss=1.0271 (C:1.0271, R:0.0105)
Batch 250/537: Loss=0.9987 (C:0.9987, R:0.0105)
Batch 275/537: Loss=1.0205 (C:1.0205, R:0.0105)
Batch 300/537: Loss=1.0340 (C:1.0340, R:0.0105)
Batch 325/537: Loss=1.0134 (C:1.0134, R:0.0105)
Batch 350/537: Loss=1.0185 (C:1.0185, R:0.0105)
Batch 375/537: Loss=1.0682 (C:1.0682, R:0.0105)
Batch 400/537: Loss=1.0720 (C:1.0720, R:0.0105)
Batch 425/537: Loss=1.0470 (C:1.0470, R:0.0105)
Batch 450/537: Loss=1.0780 (C:1.0780, R:0.0105)
Batch 475/537: Loss=1.0426 (C:1.0426, R:0.0105)
Batch 500/537: Loss=1.0276 (C:1.0276, R:0.0105)
Batch 525/537: Loss=1.0791 (C:1.0791, R:0.0105)

============================================================
Epoch 45/300 completed in 22.0s
Train: Loss=1.0314 (C:1.0314, R:0.0105) Ratio=4.79x
Val:   Loss=1.2211 (C:1.2211, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.225
✅ New best model saved (Val Loss: 1.2211)
============================================================

🌍 Updating global dataset at epoch 46
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.499 ± 0.846
    Neg distances: 3.374 ± 1.484
    Separation ratio: 6.76x
    Gap: -5.643
    ✅ Excellent global separation!

Epoch 46 Training
----------------------------------------
Batch   0/537: Loss=1.0161 (C:1.0161, R:0.0105)
Batch  25/537: Loss=1.0635 (C:1.0635, R:0.0105)
Batch  50/537: Loss=1.0438 (C:1.0438, R:0.0105)
Batch  75/537: Loss=1.0412 (C:1.0412, R:0.0105)
Batch 100/537: Loss=1.0356 (C:1.0356, R:0.0105)
Batch 125/537: Loss=1.0224 (C:1.0224, R:0.0105)
Batch 150/537: Loss=0.9944 (C:0.9944, R:0.0105)
Batch 175/537: Loss=1.0230 (C:1.0230, R:0.0105)
Batch 200/537: Loss=1.0615 (C:1.0615, R:0.0105)
Batch 225/537: Loss=0.9692 (C:0.9692, R:0.0105)
Batch 250/537: Loss=1.0533 (C:1.0533, R:0.0105)
Batch 275/537: Loss=1.0372 (C:1.0372, R:0.0106)
Batch 300/537: Loss=0.9861 (C:0.9861, R:0.0105)
Batch 325/537: Loss=1.0179 (C:1.0179, R:0.0105)
Batch 350/537: Loss=1.0155 (C:1.0155, R:0.0105)
Batch 375/537: Loss=1.0381 (C:1.0381, R:0.0105)
Batch 400/537: Loss=1.0000 (C:1.0000, R:0.0105)
Batch 425/537: Loss=1.0388 (C:1.0388, R:0.0105)
Batch 450/537: Loss=1.0726 (C:1.0726, R:0.0105)
Batch 475/537: Loss=1.0211 (C:1.0211, R:0.0105)
Batch 500/537: Loss=1.0198 (C:1.0198, R:0.0105)
Batch 525/537: Loss=1.0556 (C:1.0556, R:0.0106)

============================================================
Epoch 46/300 completed in 27.1s
Train: Loss=1.0286 (C:1.0286, R:0.0105) Ratio=4.77x
Val:   Loss=1.2297 (C:1.2297, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.240
No improvement for 1 epochs
============================================================

Epoch 47 Training
----------------------------------------
Batch   0/537: Loss=1.0290 (C:1.0290, R:0.0105)
Batch  25/537: Loss=0.9897 (C:0.9897, R:0.0105)
Batch  50/537: Loss=1.0389 (C:1.0389, R:0.0105)
Batch  75/537: Loss=1.0074 (C:1.0074, R:0.0105)
Batch 100/537: Loss=1.0560 (C:1.0560, R:0.0105)
Batch 125/537: Loss=0.9999 (C:0.9999, R:0.0105)
Batch 150/537: Loss=0.9642 (C:0.9642, R:0.0105)
Batch 175/537: Loss=1.0606 (C:1.0606, R:0.0105)
Batch 200/537: Loss=1.0010 (C:1.0010, R:0.0105)
Batch 225/537: Loss=1.0187 (C:1.0187, R:0.0105)
Batch 250/537: Loss=1.0027 (C:1.0027, R:0.0105)
Batch 275/537: Loss=1.0309 (C:1.0309, R:0.0105)
Batch 300/537: Loss=1.0034 (C:1.0034, R:0.0105)
Batch 325/537: Loss=1.0063 (C:1.0063, R:0.0106)
Batch 350/537: Loss=1.0506 (C:1.0506, R:0.0105)
Batch 375/537: Loss=1.0337 (C:1.0337, R:0.0106)
Batch 400/537: Loss=1.0101 (C:1.0101, R:0.0105)
Batch 425/537: Loss=0.9957 (C:0.9957, R:0.0105)
Batch 450/537: Loss=1.0306 (C:1.0306, R:0.0106)
Batch 475/537: Loss=0.9939 (C:0.9939, R:0.0105)
Batch 500/537: Loss=1.0581 (C:1.0581, R:0.0105)
Batch 525/537: Loss=1.0540 (C:1.0540, R:0.0105)

============================================================
Epoch 47/300 completed in 21.2s
Train: Loss=1.0237 (C:1.0237, R:0.0105) Ratio=4.82x
Val:   Loss=1.2227 (C:1.2227, R:0.0104) Ratio=3.04x
Reconstruction weight: 0.255
No improvement for 2 epochs
============================================================

Epoch 48 Training
----------------------------------------
Batch   0/537: Loss=1.0146 (C:1.0146, R:0.0105)
Batch  25/537: Loss=0.9834 (C:0.9834, R:0.0105)
Batch  50/537: Loss=1.0255 (C:1.0255, R:0.0105)
Batch  75/537: Loss=0.9961 (C:0.9961, R:0.0105)
Batch 100/537: Loss=0.9852 (C:0.9852, R:0.0105)
Batch 125/537: Loss=0.9800 (C:0.9800, R:0.0105)
Batch 150/537: Loss=0.9743 (C:0.9743, R:0.0105)
Batch 175/537: Loss=1.0019 (C:1.0019, R:0.0105)
Batch 200/537: Loss=1.0442 (C:1.0442, R:0.0105)
Batch 225/537: Loss=0.9826 (C:0.9826, R:0.0105)
Batch 250/537: Loss=1.0682 (C:1.0682, R:0.0105)
Batch 275/537: Loss=0.9787 (C:0.9787, R:0.0105)
Batch 300/537: Loss=0.9228 (C:0.9228, R:0.0105)
Batch 325/537: Loss=1.0579 (C:1.0579, R:0.0105)
Batch 350/537: Loss=1.0243 (C:1.0243, R:0.0105)
Batch 375/537: Loss=1.0041 (C:1.0041, R:0.0105)
Batch 400/537: Loss=1.0380 (C:1.0380, R:0.0105)
Batch 425/537: Loss=1.0585 (C:1.0585, R:0.0105)
Batch 450/537: Loss=1.0297 (C:1.0297, R:0.0105)
Batch 475/537: Loss=1.0737 (C:1.0737, R:0.0105)
Batch 500/537: Loss=1.0209 (C:1.0209, R:0.0105)
Batch 525/537: Loss=1.0273 (C:1.0273, R:0.0105)

============================================================
Epoch 48/300 completed in 21.3s
Train: Loss=1.0222 (C:1.0222, R:0.0105) Ratio=4.93x
Val:   Loss=1.2309 (C:1.2309, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.270
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 49
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.486 ± 0.832
    Neg distances: 3.458 ± 1.502
    Separation ratio: 7.12x
    Gap: -5.725
    ✅ Excellent global separation!

Epoch 49 Training
----------------------------------------
Batch   0/537: Loss=0.9356 (C:0.9356, R:0.0105)
Batch  25/537: Loss=0.9205 (C:0.9205, R:0.0105)
Batch  50/537: Loss=0.9899 (C:0.9899, R:0.0105)
Batch  75/537: Loss=0.9776 (C:0.9776, R:0.0105)
Batch 100/537: Loss=0.9551 (C:0.9551, R:0.0105)
Batch 125/537: Loss=0.9501 (C:0.9501, R:0.0105)
Batch 150/537: Loss=0.9611 (C:0.9611, R:0.0105)
Batch 175/537: Loss=1.0013 (C:1.0013, R:0.0105)
Batch 200/537: Loss=0.9477 (C:0.9477, R:0.0105)
Batch 225/537: Loss=0.9728 (C:0.9728, R:0.0105)
Batch 250/537: Loss=1.0249 (C:1.0249, R:0.0105)
Batch 275/537: Loss=0.9505 (C:0.9505, R:0.0105)
Batch 300/537: Loss=0.9720 (C:0.9720, R:0.0105)
Batch 325/537: Loss=0.9886 (C:0.9886, R:0.0105)
Batch 350/537: Loss=1.0005 (C:1.0005, R:0.0105)
Batch 375/537: Loss=1.0189 (C:1.0189, R:0.0105)
Batch 400/537: Loss=0.9637 (C:0.9637, R:0.0105)
Batch 425/537: Loss=1.0619 (C:1.0619, R:0.0105)
Batch 450/537: Loss=1.0016 (C:1.0016, R:0.0105)
Batch 475/537: Loss=0.9517 (C:0.9517, R:0.0105)
Batch 500/537: Loss=0.9886 (C:0.9886, R:0.0105)
Batch 525/537: Loss=0.9948 (C:0.9948, R:0.0105)

============================================================
Epoch 49/300 completed in 27.7s
Train: Loss=0.9866 (C:0.9866, R:0.0105) Ratio=4.87x
Val:   Loss=1.2137 (C:1.2137, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.285
✅ New best model saved (Val Loss: 1.2137)
============================================================

Epoch 50 Training
----------------------------------------
Batch   0/537: Loss=0.9610 (C:0.9610, R:0.0105)
Batch  25/537: Loss=1.0037 (C:1.0037, R:0.0105)
Batch  50/537: Loss=1.0091 (C:1.0091, R:0.0105)
Batch  75/537: Loss=0.9933 (C:0.9933, R:0.0105)
Batch 100/537: Loss=0.9710 (C:0.9710, R:0.0105)
Batch 125/537: Loss=0.9796 (C:0.9796, R:0.0105)
Batch 150/537: Loss=1.0303 (C:1.0303, R:0.0105)
Batch 175/537: Loss=1.0306 (C:1.0306, R:0.0105)
Batch 200/537: Loss=0.9563 (C:0.9563, R:0.0105)
Batch 225/537: Loss=1.0033 (C:1.0033, R:0.0105)
Batch 250/537: Loss=0.9524 (C:0.9524, R:0.0105)
Batch 275/537: Loss=0.9945 (C:0.9945, R:0.0105)
Batch 300/537: Loss=1.0438 (C:1.0438, R:0.0105)
Batch 325/537: Loss=1.0026 (C:1.0026, R:0.0105)
Batch 350/537: Loss=0.9398 (C:0.9398, R:0.0105)
Batch 375/537: Loss=0.9544 (C:0.9544, R:0.0105)
Batch 400/537: Loss=0.9780 (C:0.9780, R:0.0105)
Batch 425/537: Loss=0.9939 (C:0.9939, R:0.0105)
Batch 450/537: Loss=1.0060 (C:1.0060, R:0.0105)
Batch 475/537: Loss=1.0508 (C:1.0508, R:0.0105)
Batch 500/537: Loss=0.9792 (C:0.9792, R:0.0105)
Batch 525/537: Loss=0.9756 (C:0.9756, R:0.0105)

============================================================
Epoch 50/300 completed in 21.0s
Train: Loss=0.9834 (C:0.9834, R:0.0105) Ratio=4.91x
Val:   Loss=1.1725 (C:1.1725, R:0.0104) Ratio=3.11x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.1725)
============================================================

Epoch 51 Training
----------------------------------------
Batch   0/537: Loss=0.9740 (C:0.9740, R:0.0105)
Batch  25/537: Loss=0.9978 (C:0.9978, R:0.0105)
Batch  50/537: Loss=0.9361 (C:0.9361, R:0.0105)
Batch  75/537: Loss=0.9824 (C:0.9824, R:0.0105)
Batch 100/537: Loss=0.9838 (C:0.9838, R:0.0105)
Batch 125/537: Loss=0.9946 (C:0.9946, R:0.0105)
Batch 150/537: Loss=0.9982 (C:0.9982, R:0.0105)
Batch 175/537: Loss=0.9780 (C:0.9780, R:0.0105)
Batch 200/537: Loss=1.0008 (C:1.0008, R:0.0105)
Batch 225/537: Loss=0.9149 (C:0.9149, R:0.0105)
Batch 250/537: Loss=0.9780 (C:0.9780, R:0.0105)
Batch 275/537: Loss=1.0285 (C:1.0285, R:0.0105)
Batch 300/537: Loss=0.9357 (C:0.9357, R:0.0105)
Batch 325/537: Loss=0.9761 (C:0.9761, R:0.0105)
Batch 350/537: Loss=0.9787 (C:0.9787, R:0.0105)
Batch 375/537: Loss=1.0372 (C:1.0372, R:0.0105)
Batch 400/537: Loss=0.9836 (C:0.9836, R:0.0105)
Batch 425/537: Loss=0.9656 (C:0.9656, R:0.0105)
Batch 450/537: Loss=0.9439 (C:0.9439, R:0.0105)
Batch 475/537: Loss=1.0022 (C:1.0022, R:0.0105)
Batch 500/537: Loss=0.9910 (C:0.9910, R:0.0105)
Batch 525/537: Loss=0.9781 (C:0.9781, R:0.0105)

============================================================
Epoch 51/300 completed in 21.0s
Train: Loss=0.9812 (C:0.9812, R:0.0105) Ratio=5.01x
Val:   Loss=1.2001 (C:1.2001, R:0.0104) Ratio=3.06x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 52
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.475 ± 0.826
    Neg distances: 3.536 ± 1.517
    Separation ratio: 7.44x
    Gap: -5.885
    ✅ Excellent global separation!

Epoch 52 Training
----------------------------------------
Batch   0/537: Loss=0.9359 (C:0.9359, R:0.0105)
Batch  25/537: Loss=0.9040 (C:0.9040, R:0.0105)
Batch  50/537: Loss=0.9647 (C:0.9647, R:0.0105)
Batch  75/537: Loss=0.9278 (C:0.9278, R:0.0105)
Batch 100/537: Loss=0.8959 (C:0.8959, R:0.0105)
Batch 125/537: Loss=0.9645 (C:0.9645, R:0.0105)
Batch 150/537: Loss=0.9741 (C:0.9741, R:0.0105)
Batch 175/537: Loss=0.9699 (C:0.9699, R:0.0105)
Batch 200/537: Loss=0.9102 (C:0.9102, R:0.0105)
Batch 225/537: Loss=0.9274 (C:0.9274, R:0.0105)
Batch 250/537: Loss=0.9618 (C:0.9618, R:0.0105)
Batch 275/537: Loss=0.9445 (C:0.9445, R:0.0105)
Batch 300/537: Loss=0.9775 (C:0.9775, R:0.0105)
Batch 325/537: Loss=0.9325 (C:0.9325, R:0.0105)
Batch 350/537: Loss=0.9412 (C:0.9412, R:0.0105)
Batch 375/537: Loss=0.9292 (C:0.9292, R:0.0105)
Batch 400/537: Loss=0.9778 (C:0.9778, R:0.0105)
Batch 425/537: Loss=0.9107 (C:0.9107, R:0.0105)
Batch 450/537: Loss=0.9310 (C:0.9310, R:0.0105)
Batch 475/537: Loss=0.9176 (C:0.9176, R:0.0105)
Batch 500/537: Loss=0.9078 (C:0.9078, R:0.0105)
Batch 525/537: Loss=0.9416 (C:0.9416, R:0.0105)

============================================================
Epoch 52/300 completed in 27.2s
Train: Loss=0.9461 (C:0.9461, R:0.0105) Ratio=4.98x
Val:   Loss=1.1665 (C:1.1665, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.1665)
============================================================

Epoch 53 Training
----------------------------------------
Batch   0/537: Loss=0.9198 (C:0.9198, R:0.0105)
Batch  25/537: Loss=0.8827 (C:0.8827, R:0.0105)
Batch  50/537: Loss=0.9158 (C:0.9158, R:0.0105)
Batch  75/537: Loss=0.9861 (C:0.9861, R:0.0105)
Batch 100/537: Loss=0.9118 (C:0.9118, R:0.0105)
Batch 125/537: Loss=0.9966 (C:0.9966, R:0.0105)
Batch 150/537: Loss=0.8978 (C:0.8978, R:0.0105)
Batch 175/537: Loss=0.8831 (C:0.8831, R:0.0105)
Batch 200/537: Loss=0.9296 (C:0.9296, R:0.0106)
Batch 225/537: Loss=0.9553 (C:0.9553, R:0.0105)
Batch 250/537: Loss=0.9661 (C:0.9661, R:0.0105)
Batch 275/537: Loss=0.9360 (C:0.9360, R:0.0105)
Batch 300/537: Loss=0.9210 (C:0.9210, R:0.0105)
Batch 325/537: Loss=0.9516 (C:0.9516, R:0.0105)
Batch 350/537: Loss=0.8780 (C:0.8780, R:0.0105)
Batch 375/537: Loss=0.9220 (C:0.9220, R:0.0105)
Batch 400/537: Loss=0.9177 (C:0.9177, R:0.0105)
Batch 425/537: Loss=0.9019 (C:0.9019, R:0.0105)
Batch 450/537: Loss=0.8639 (C:0.8639, R:0.0105)
Batch 475/537: Loss=0.9436 (C:0.9436, R:0.0105)
Batch 500/537: Loss=0.9320 (C:0.9320, R:0.0105)
Batch 525/537: Loss=0.9833 (C:0.9833, R:0.0105)

============================================================
Epoch 53/300 completed in 22.0s
Train: Loss=0.9422 (C:0.9422, R:0.0105) Ratio=5.12x
Val:   Loss=1.1625 (C:1.1625, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.1625)
============================================================

Epoch 54 Training
----------------------------------------
Batch   0/537: Loss=0.8825 (C:0.8825, R:0.0105)
Batch  25/537: Loss=0.9165 (C:0.9165, R:0.0105)
Batch  50/537: Loss=0.9559 (C:0.9559, R:0.0105)
Batch  75/537: Loss=0.9298 (C:0.9298, R:0.0105)
Batch 100/537: Loss=0.9304 (C:0.9304, R:0.0105)
Batch 125/537: Loss=0.8952 (C:0.8952, R:0.0105)
Batch 150/537: Loss=0.8816 (C:0.8816, R:0.0105)
Batch 175/537: Loss=0.9192 (C:0.9192, R:0.0105)
Batch 200/537: Loss=0.9524 (C:0.9524, R:0.0105)
Batch 225/537: Loss=0.9478 (C:0.9478, R:0.0105)
Batch 250/537: Loss=0.9887 (C:0.9887, R:0.0105)
Batch 275/537: Loss=0.9579 (C:0.9579, R:0.0105)
Batch 300/537: Loss=0.9324 (C:0.9324, R:0.0105)
Batch 325/537: Loss=0.9603 (C:0.9603, R:0.0105)
Batch 350/537: Loss=0.8684 (C:0.8684, R:0.0105)
Batch 375/537: Loss=0.8906 (C:0.8906, R:0.0105)
Batch 400/537: Loss=0.9341 (C:0.9341, R:0.0105)
Batch 425/537: Loss=1.0097 (C:1.0097, R:0.0105)
Batch 450/537: Loss=0.9430 (C:0.9430, R:0.0105)
Batch 475/537: Loss=0.9253 (C:0.9253, R:0.0105)
Batch 500/537: Loss=0.9098 (C:0.9098, R:0.0106)
Batch 525/537: Loss=0.9648 (C:0.9648, R:0.0105)

============================================================
Epoch 54/300 completed in 21.5s
Train: Loss=0.9401 (C:0.9401, R:0.0105) Ratio=5.01x
Val:   Loss=1.1569 (C:1.1569, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.1569)
============================================================

🌍 Updating global dataset at epoch 55
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.497 ± 0.868
    Neg distances: 3.626 ± 1.564
    Separation ratio: 7.30x
    Gap: -6.049
    ✅ Excellent global separation!

Epoch 55 Training
----------------------------------------
Batch   0/537: Loss=0.9493 (C:0.9493, R:0.0105)
Batch  25/537: Loss=0.9058 (C:0.9058, R:0.0105)
Batch  50/537: Loss=0.8839 (C:0.8839, R:0.0105)
Batch  75/537: Loss=0.8795 (C:0.8795, R:0.0105)
Batch 100/537: Loss=0.9158 (C:0.9158, R:0.0105)
Batch 125/537: Loss=0.9291 (C:0.9291, R:0.0105)
Batch 150/537: Loss=0.9197 (C:0.9197, R:0.0105)
Batch 175/537: Loss=0.9233 (C:0.9233, R:0.0105)
Batch 200/537: Loss=0.9669 (C:0.9669, R:0.0105)
Batch 225/537: Loss=0.9621 (C:0.9621, R:0.0105)
Batch 250/537: Loss=0.9563 (C:0.9563, R:0.0105)
Batch 275/537: Loss=0.9744 (C:0.9744, R:0.0105)
Batch 300/537: Loss=0.8934 (C:0.8934, R:0.0105)
Batch 325/537: Loss=0.9358 (C:0.9358, R:0.0105)
Batch 350/537: Loss=0.9182 (C:0.9182, R:0.0105)
Batch 375/537: Loss=0.9715 (C:0.9715, R:0.0105)
Batch 400/537: Loss=0.9072 (C:0.9072, R:0.0105)
Batch 425/537: Loss=0.9350 (C:0.9350, R:0.0106)
Batch 450/537: Loss=0.8434 (C:0.8434, R:0.0106)
Batch 475/537: Loss=0.9796 (C:0.9796, R:0.0105)
Batch 500/537: Loss=0.9346 (C:0.9346, R:0.0105)
Batch 525/537: Loss=0.9212 (C:0.9212, R:0.0105)

============================================================
Epoch 55/300 completed in 27.2s
Train: Loss=0.9363 (C:0.9363, R:0.0105) Ratio=5.01x
Val:   Loss=1.1621 (C:1.1621, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

Epoch 56 Training
----------------------------------------
Batch   0/537: Loss=0.9119 (C:0.9119, R:0.0105)
Batch  25/537: Loss=0.9943 (C:0.9943, R:0.0105)
Batch  50/537: Loss=0.9379 (C:0.9379, R:0.0106)
Batch  75/537: Loss=0.9627 (C:0.9627, R:0.0105)
Batch 100/537: Loss=0.8924 (C:0.8924, R:0.0105)
Batch 125/537: Loss=0.9396 (C:0.9396, R:0.0105)
Batch 150/537: Loss=0.9126 (C:0.9126, R:0.0105)
Batch 175/537: Loss=0.8981 (C:0.8981, R:0.0105)
Batch 200/537: Loss=0.9855 (C:0.9855, R:0.0105)
Batch 225/537: Loss=0.9142 (C:0.9142, R:0.0105)
Batch 250/537: Loss=0.9491 (C:0.9491, R:0.0105)
Batch 275/537: Loss=0.8889 (C:0.8889, R:0.0105)
Batch 300/537: Loss=0.8630 (C:0.8630, R:0.0105)
Batch 325/537: Loss=0.8943 (C:0.8943, R:0.0105)
Batch 350/537: Loss=0.9312 (C:0.9312, R:0.0105)
Batch 375/537: Loss=0.9403 (C:0.9403, R:0.0105)
Batch 400/537: Loss=0.9154 (C:0.9154, R:0.0106)
Batch 425/537: Loss=0.8957 (C:0.8957, R:0.0105)
Batch 450/537: Loss=0.8965 (C:0.8965, R:0.0105)
Batch 475/537: Loss=0.9033 (C:0.9033, R:0.0105)
Batch 500/537: Loss=0.9388 (C:0.9388, R:0.0105)
Batch 525/537: Loss=0.9826 (C:0.9826, R:0.0105)

============================================================
Epoch 56/300 completed in 21.3s
Train: Loss=0.9341 (C:0.9341, R:0.0105) Ratio=5.04x
Val:   Loss=1.1524 (C:1.1524, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.1524)
============================================================

Epoch 57 Training
----------------------------------------
Batch   0/537: Loss=0.8827 (C:0.8827, R:0.0105)
Batch  25/537: Loss=0.9487 (C:0.9487, R:0.0105)
Batch  50/537: Loss=0.9259 (C:0.9259, R:0.0105)
Batch  75/537: Loss=0.9685 (C:0.9685, R:0.0105)
Batch 100/537: Loss=0.9149 (C:0.9149, R:0.0105)
Batch 125/537: Loss=0.9226 (C:0.9226, R:0.0105)
Batch 150/537: Loss=0.9139 (C:0.9139, R:0.0105)
Batch 175/537: Loss=0.9685 (C:0.9685, R:0.0105)
Batch 200/537: Loss=0.9290 (C:0.9290, R:0.0105)
Batch 225/537: Loss=0.9308 (C:0.9308, R:0.0105)
Batch 250/537: Loss=0.8939 (C:0.8939, R:0.0105)
Batch 275/537: Loss=0.9103 (C:0.9103, R:0.0105)
Batch 300/537: Loss=0.9527 (C:0.9527, R:0.0105)
Batch 325/537: Loss=0.9065 (C:0.9065, R:0.0105)
Batch 350/537: Loss=0.9787 (C:0.9787, R:0.0105)
Batch 375/537: Loss=0.9531 (C:0.9531, R:0.0105)
Batch 400/537: Loss=0.9516 (C:0.9516, R:0.0106)
Batch 425/537: Loss=0.9678 (C:0.9678, R:0.0106)
Batch 450/537: Loss=0.9992 (C:0.9992, R:0.0105)
Batch 475/537: Loss=0.9126 (C:0.9126, R:0.0105)
Batch 500/537: Loss=0.9524 (C:0.9524, R:0.0105)
Batch 525/537: Loss=0.9359 (C:0.9359, R:0.0105)

============================================================
Epoch 57/300 completed in 21.2s
Train: Loss=0.9311 (C:0.9311, R:0.0105) Ratio=5.03x
Val:   Loss=1.1569 (C:1.1569, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 58
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.507 ± 0.899
    Neg distances: 3.684 ± 1.585
    Separation ratio: 7.26x
    Gap: -6.122
    ✅ Excellent global separation!

Epoch 58 Training
----------------------------------------
Batch   0/537: Loss=0.9065 (C:0.9065, R:0.0105)
Batch  25/537: Loss=0.9242 (C:0.9242, R:0.0105)
Batch  50/537: Loss=0.9170 (C:0.9170, R:0.0105)
Batch  75/537: Loss=0.9459 (C:0.9459, R:0.0105)
Batch 100/537: Loss=0.9404 (C:0.9404, R:0.0105)
Batch 125/537: Loss=0.9259 (C:0.9259, R:0.0105)
Batch 150/537: Loss=0.9258 (C:0.9258, R:0.0105)
Batch 175/537: Loss=0.9540 (C:0.9540, R:0.0105)
Batch 200/537: Loss=0.9319 (C:0.9319, R:0.0105)
Batch 225/537: Loss=0.8903 (C:0.8903, R:0.0105)
Batch 250/537: Loss=0.9335 (C:0.9335, R:0.0105)
Batch 275/537: Loss=0.9705 (C:0.9705, R:0.0105)
Batch 300/537: Loss=0.9110 (C:0.9110, R:0.0105)
Batch 325/537: Loss=0.8974 (C:0.8974, R:0.0105)
Batch 350/537: Loss=0.9238 (C:0.9238, R:0.0105)
Batch 375/537: Loss=0.9185 (C:0.9185, R:0.0105)
Batch 400/537: Loss=0.9119 (C:0.9119, R:0.0105)
Batch 425/537: Loss=0.9624 (C:0.9624, R:0.0105)
Batch 450/537: Loss=0.9120 (C:0.9120, R:0.0105)
Batch 475/537: Loss=0.9039 (C:0.9039, R:0.0105)
Batch 500/537: Loss=0.9140 (C:0.9140, R:0.0105)
Batch 525/537: Loss=0.9377 (C:0.9377, R:0.0105)

============================================================
Epoch 58/300 completed in 27.2s
Train: Loss=0.9220 (C:0.9220, R:0.0105) Ratio=5.05x
Val:   Loss=1.1543 (C:1.1543, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

Epoch 59 Training
----------------------------------------
Batch   0/537: Loss=0.9010 (C:0.9010, R:0.0105)
Batch  25/537: Loss=0.9388 (C:0.9388, R:0.0105)
Batch  50/537: Loss=0.9291 (C:0.9291, R:0.0105)
Batch  75/537: Loss=0.8803 (C:0.8803, R:0.0105)
Batch 100/537: Loss=0.8524 (C:0.8524, R:0.0105)
Batch 125/537: Loss=0.9107 (C:0.9107, R:0.0105)
Batch 150/537: Loss=0.9538 (C:0.9538, R:0.0105)
Batch 175/537: Loss=0.8650 (C:0.8650, R:0.0105)
Batch 200/537: Loss=0.9074 (C:0.9074, R:0.0105)
Batch 225/537: Loss=0.9687 (C:0.9687, R:0.0105)
Batch 250/537: Loss=0.9089 (C:0.9089, R:0.0105)
Batch 275/537: Loss=0.8725 (C:0.8725, R:0.0105)
Batch 300/537: Loss=0.9325 (C:0.9325, R:0.0105)
Batch 325/537: Loss=0.9095 (C:0.9095, R:0.0105)
Batch 350/537: Loss=0.9236 (C:0.9236, R:0.0105)
Batch 375/537: Loss=0.9030 (C:0.9030, R:0.0105)
Batch 400/537: Loss=0.9107 (C:0.9107, R:0.0105)
Batch 425/537: Loss=0.8899 (C:0.8899, R:0.0105)
Batch 450/537: Loss=0.8633 (C:0.8633, R:0.0105)
Batch 475/537: Loss=0.8528 (C:0.8528, R:0.0105)
Batch 500/537: Loss=0.9288 (C:0.9288, R:0.0105)
Batch 525/537: Loss=0.9222 (C:0.9222, R:0.0105)

============================================================
Epoch 59/300 completed in 21.1s
Train: Loss=0.9166 (C:0.9166, R:0.0105) Ratio=5.13x
Val:   Loss=1.1569 (C:1.1569, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

Epoch 60 Training
----------------------------------------
Batch   0/537: Loss=0.8727 (C:0.8727, R:0.0105)
Batch  25/537: Loss=0.9086 (C:0.9086, R:0.0105)
Batch  50/537: Loss=0.8859 (C:0.8859, R:0.0105)
Batch  75/537: Loss=0.8549 (C:0.8549, R:0.0105)
Batch 100/537: Loss=0.8838 (C:0.8838, R:0.0105)
Batch 125/537: Loss=0.9143 (C:0.9143, R:0.0105)
Batch 150/537: Loss=0.8657 (C:0.8657, R:0.0105)
Batch 175/537: Loss=0.8961 (C:0.8961, R:0.0105)
Batch 200/537: Loss=0.9299 (C:0.9299, R:0.0105)
Batch 225/537: Loss=0.9475 (C:0.9475, R:0.0106)
Batch 250/537: Loss=0.8977 (C:0.8977, R:0.0105)
Batch 275/537: Loss=0.8999 (C:0.8999, R:0.0105)
Batch 300/537: Loss=0.9039 (C:0.9039, R:0.0105)
Batch 325/537: Loss=0.9216 (C:0.9216, R:0.0105)
Batch 350/537: Loss=0.9387 (C:0.9387, R:0.0105)
Batch 375/537: Loss=0.9208 (C:0.9208, R:0.0105)
Batch 400/537: Loss=0.8943 (C:0.8943, R:0.0105)
Batch 425/537: Loss=0.9059 (C:0.9059, R:0.0105)
Batch 450/537: Loss=0.8672 (C:0.8672, R:0.0105)
Batch 475/537: Loss=0.9312 (C:0.9312, R:0.0105)
Batch 500/537: Loss=0.9682 (C:0.9682, R:0.0105)
Batch 525/537: Loss=0.9636 (C:0.9636, R:0.0105)

============================================================
Epoch 60/300 completed in 21.2s
Train: Loss=0.9152 (C:0.9152, R:0.0105) Ratio=5.16x
Val:   Loss=1.1533 (C:1.1533, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
No improvement for 4 epochs
Checkpoint saved at epoch 60
============================================================

🌍 Updating global dataset at epoch 61
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.493 ± 0.898
    Neg distances: 3.727 ± 1.591
    Separation ratio: 7.56x
    Gap: -6.194
    ✅ Excellent global separation!

Epoch 61 Training
----------------------------------------
Batch   0/537: Loss=0.8687 (C:0.8687, R:0.0106)
Batch  25/537: Loss=0.9145 (C:0.9145, R:0.0105)
Batch  50/537: Loss=0.9282 (C:0.9282, R:0.0105)
Batch  75/537: Loss=0.8480 (C:0.8480, R:0.0105)
Batch 100/537: Loss=0.8526 (C:0.8526, R:0.0105)
Batch 125/537: Loss=0.9151 (C:0.9151, R:0.0106)
Batch 150/537: Loss=0.8261 (C:0.8261, R:0.0105)
Batch 175/537: Loss=0.8868 (C:0.8868, R:0.0105)
Batch 200/537: Loss=0.8319 (C:0.8319, R:0.0105)
Batch 225/537: Loss=0.8657 (C:0.8657, R:0.0105)
Batch 250/537: Loss=0.8921 (C:0.8921, R:0.0105)
Batch 275/537: Loss=0.9135 (C:0.9135, R:0.0105)
Batch 300/537: Loss=0.9287 (C:0.9287, R:0.0105)
Batch 325/537: Loss=0.9049 (C:0.9049, R:0.0105)
Batch 350/537: Loss=0.8958 (C:0.8958, R:0.0105)
Batch 375/537: Loss=0.9176 (C:0.9176, R:0.0105)
Batch 400/537: Loss=0.9031 (C:0.9031, R:0.0105)
Batch 425/537: Loss=0.9006 (C:0.9006, R:0.0105)
Batch 450/537: Loss=0.9090 (C:0.9090, R:0.0105)
Batch 475/537: Loss=0.9071 (C:0.9071, R:0.0105)
Batch 500/537: Loss=0.8987 (C:0.8987, R:0.0105)
Batch 525/537: Loss=0.9222 (C:0.9222, R:0.0105)

============================================================
Epoch 61/300 completed in 26.9s
Train: Loss=0.8950 (C:0.8950, R:0.0105) Ratio=5.09x
Val:   Loss=1.1377 (C:1.1377, R:0.0104) Ratio=3.08x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.1377)
============================================================

Epoch 62 Training
----------------------------------------
Batch   0/537: Loss=0.9103 (C:0.9103, R:0.0105)
Batch  25/537: Loss=0.8562 (C:0.8562, R:0.0105)
Batch  50/537: Loss=0.8694 (C:0.8694, R:0.0105)
Batch  75/537: Loss=0.8827 (C:0.8827, R:0.0105)
Batch 100/537: Loss=0.8865 (C:0.8865, R:0.0105)
Batch 125/537: Loss=0.8086 (C:0.8086, R:0.0105)
Batch 150/537: Loss=0.8821 (C:0.8821, R:0.0106)
Batch 175/537: Loss=0.9248 (C:0.9248, R:0.0105)
Batch 200/537: Loss=0.8822 (C:0.8822, R:0.0105)
Batch 225/537: Loss=0.9107 (C:0.9107, R:0.0105)
Batch 250/537: Loss=0.9257 (C:0.9257, R:0.0105)
Batch 275/537: Loss=0.8718 (C:0.8718, R:0.0105)
Batch 300/537: Loss=0.8929 (C:0.8929, R:0.0105)
Batch 325/537: Loss=0.9095 (C:0.9095, R:0.0105)
Batch 350/537: Loss=0.9706 (C:0.9706, R:0.0105)
Batch 375/537: Loss=0.8548 (C:0.8548, R:0.0105)
Batch 400/537: Loss=0.9307 (C:0.9307, R:0.0105)
Batch 425/537: Loss=0.9140 (C:0.9140, R:0.0105)
Batch 450/537: Loss=0.9005 (C:0.9005, R:0.0105)
Batch 475/537: Loss=0.9307 (C:0.9307, R:0.0105)
Batch 500/537: Loss=0.8718 (C:0.8718, R:0.0105)
Batch 525/537: Loss=0.8198 (C:0.8198, R:0.0105)

============================================================
Epoch 62/300 completed in 21.3s
Train: Loss=0.8937 (C:0.8937, R:0.0105) Ratio=5.16x
Val:   Loss=1.1359 (C:1.1359, R:0.0104) Ratio=3.14x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.1359)
============================================================

Epoch 63 Training
----------------------------------------
Batch   0/537: Loss=0.8919 (C:0.8919, R:0.0105)
Batch  25/537: Loss=0.8696 (C:0.8696, R:0.0105)
Batch  50/537: Loss=0.8916 (C:0.8916, R:0.0106)
Batch  75/537: Loss=0.9285 (C:0.9285, R:0.0105)
Batch 100/537: Loss=0.8752 (C:0.8752, R:0.0105)
Batch 125/537: Loss=0.8620 (C:0.8620, R:0.0105)
Batch 150/537: Loss=0.8519 (C:0.8519, R:0.0105)
Batch 175/537: Loss=0.9223 (C:0.9223, R:0.0105)
Batch 200/537: Loss=0.8890 (C:0.8890, R:0.0105)
Batch 225/537: Loss=0.8832 (C:0.8832, R:0.0105)
Batch 250/537: Loss=0.8714 (C:0.8714, R:0.0105)
Batch 275/537: Loss=0.8868 (C:0.8868, R:0.0105)
Batch 300/537: Loss=0.8658 (C:0.8658, R:0.0105)
Batch 325/537: Loss=0.8606 (C:0.8606, R:0.0105)
Batch 350/537: Loss=0.9314 (C:0.9314, R:0.0105)
Batch 375/537: Loss=0.8783 (C:0.8783, R:0.0105)
Batch 400/537: Loss=0.9390 (C:0.9390, R:0.0105)
Batch 425/537: Loss=0.8756 (C:0.8756, R:0.0105)
Batch 450/537: Loss=0.9157 (C:0.9157, R:0.0105)
Batch 475/537: Loss=0.8683 (C:0.8683, R:0.0105)
Batch 500/537: Loss=0.8774 (C:0.8774, R:0.0105)
Batch 525/537: Loss=0.9011 (C:0.9011, R:0.0105)

============================================================
Epoch 63/300 completed in 21.9s
Train: Loss=0.8897 (C:0.8897, R:0.0105) Ratio=5.20x
Val:   Loss=1.1434 (C:1.1434, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

🌍 Updating global dataset at epoch 64
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.466 ± 0.878
    Neg distances: 3.820 ± 1.599
    Separation ratio: 8.20x
    Gap: -6.452
    ✅ Excellent global separation!

Epoch 64 Training
----------------------------------------
Batch   0/537: Loss=0.8652 (C:0.8652, R:0.0105)
Batch  25/537: Loss=0.8693 (C:0.8693, R:0.0105)
Batch  50/537: Loss=0.8502 (C:0.8502, R:0.0105)
Batch  75/537: Loss=0.8532 (C:0.8532, R:0.0105)
Batch 100/537: Loss=0.8350 (C:0.8350, R:0.0105)
Batch 125/537: Loss=0.8642 (C:0.8642, R:0.0106)
Batch 150/537: Loss=0.8977 (C:0.8977, R:0.0105)
Batch 175/537: Loss=0.8656 (C:0.8656, R:0.0105)
Batch 200/537: Loss=0.7732 (C:0.7732, R:0.0105)
Batch 225/537: Loss=0.8975 (C:0.8975, R:0.0105)
Batch 250/537: Loss=0.9009 (C:0.9009, R:0.0105)
Batch 275/537: Loss=0.8195 (C:0.8195, R:0.0105)
Batch 300/537: Loss=0.8352 (C:0.8352, R:0.0105)
Batch 325/537: Loss=0.8700 (C:0.8700, R:0.0105)
Batch 350/537: Loss=0.8725 (C:0.8725, R:0.0105)
Batch 375/537: Loss=0.8616 (C:0.8616, R:0.0105)
Batch 400/537: Loss=0.9070 (C:0.9070, R:0.0106)
Batch 425/537: Loss=0.8490 (C:0.8490, R:0.0105)
Batch 450/537: Loss=0.8583 (C:0.8583, R:0.0105)
Batch 475/537: Loss=0.8485 (C:0.8485, R:0.0105)
Batch 500/537: Loss=0.9364 (C:0.9364, R:0.0105)
Batch 525/537: Loss=0.8640 (C:0.8640, R:0.0105)

============================================================
Epoch 64/300 completed in 27.5s
Train: Loss=0.8542 (C:0.8542, R:0.0105) Ratio=5.11x
Val:   Loss=1.0943 (C:1.0943, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.0943)
============================================================

Epoch 65 Training
----------------------------------------
Batch   0/537: Loss=0.7741 (C:0.7741, R:0.0105)
Batch  25/537: Loss=0.8958 (C:0.8958, R:0.0105)
Batch  50/537: Loss=0.8356 (C:0.8356, R:0.0105)
Batch  75/537: Loss=0.8606 (C:0.8606, R:0.0105)
Batch 100/537: Loss=0.8150 (C:0.8150, R:0.0105)
Batch 125/537: Loss=0.8682 (C:0.8682, R:0.0105)
Batch 150/537: Loss=0.7873 (C:0.7873, R:0.0105)
Batch 175/537: Loss=0.8034 (C:0.8034, R:0.0105)
Batch 200/537: Loss=0.8389 (C:0.8389, R:0.0105)
Batch 225/537: Loss=0.8878 (C:0.8878, R:0.0105)
Batch 250/537: Loss=0.8396 (C:0.8396, R:0.0105)
Batch 275/537: Loss=0.8585 (C:0.8585, R:0.0105)
Batch 300/537: Loss=0.8692 (C:0.8692, R:0.0105)
Batch 325/537: Loss=0.7971 (C:0.7971, R:0.0105)
Batch 350/537: Loss=0.8334 (C:0.8334, R:0.0106)
Batch 375/537: Loss=0.8858 (C:0.8858, R:0.0105)
Batch 400/537: Loss=0.8506 (C:0.8506, R:0.0105)
Batch 425/537: Loss=0.9083 (C:0.9083, R:0.0105)
Batch 450/537: Loss=0.7292 (C:0.7292, R:0.0105)
Batch 475/537: Loss=0.8395 (C:0.8395, R:0.0105)
Batch 500/537: Loss=0.8151 (C:0.8151, R:0.0105)
Batch 525/537: Loss=0.8919 (C:0.8919, R:0.0105)

============================================================
Epoch 65/300 completed in 21.1s
Train: Loss=0.8484 (C:0.8484, R:0.0105) Ratio=5.33x
Val:   Loss=1.0949 (C:1.0949, R:0.0104) Ratio=3.14x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

Epoch 66 Training
----------------------------------------
Batch   0/537: Loss=0.8549 (C:0.8549, R:0.0105)
Batch  25/537: Loss=0.8154 (C:0.8154, R:0.0105)
Batch  50/537: Loss=0.8418 (C:0.8418, R:0.0105)
Batch  75/537: Loss=0.8307 (C:0.8307, R:0.0105)
Batch 100/537: Loss=0.8121 (C:0.8121, R:0.0105)
Batch 125/537: Loss=0.8264 (C:0.8264, R:0.0105)
Batch 150/537: Loss=0.8565 (C:0.8565, R:0.0105)
Batch 175/537: Loss=0.8415 (C:0.8415, R:0.0105)
Batch 200/537: Loss=0.8580 (C:0.8580, R:0.0105)
Batch 225/537: Loss=0.8984 (C:0.8984, R:0.0105)
Batch 250/537: Loss=0.7754 (C:0.7754, R:0.0105)
Batch 275/537: Loss=0.8374 (C:0.8374, R:0.0106)
Batch 300/537: Loss=0.8368 (C:0.8368, R:0.0105)
Batch 325/537: Loss=0.8642 (C:0.8642, R:0.0105)
Batch 350/537: Loss=0.8205 (C:0.8205, R:0.0105)
Batch 375/537: Loss=0.8527 (C:0.8527, R:0.0105)
Batch 400/537: Loss=0.8069 (C:0.8069, R:0.0105)
Batch 425/537: Loss=0.8449 (C:0.8449, R:0.0105)
Batch 450/537: Loss=0.8378 (C:0.8378, R:0.0105)
Batch 475/537: Loss=0.8420 (C:0.8420, R:0.0105)
Batch 500/537: Loss=0.8095 (C:0.8095, R:0.0105)
Batch 525/537: Loss=0.8720 (C:0.8720, R:0.0105)

============================================================
Epoch 66/300 completed in 21.2s
Train: Loss=0.8476 (C:0.8476, R:0.0105) Ratio=5.25x
Val:   Loss=1.0769 (C:1.0769, R:0.0104) Ratio=3.10x
Reconstruction weight: 0.300
✅ New best model saved (Val Loss: 1.0769)
============================================================

🌍 Updating global dataset at epoch 67
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.487 ± 0.882
    Neg distances: 3.835 ± 1.627
    Separation ratio: 7.87x
    Gap: -6.424
    ✅ Excellent global separation!

Epoch 67 Training
----------------------------------------
Batch   0/537: Loss=0.8878 (C:0.8878, R:0.0105)
Batch  25/537: Loss=0.8816 (C:0.8816, R:0.0105)
Batch  50/537: Loss=0.8955 (C:0.8955, R:0.0105)
Batch  75/537: Loss=0.8934 (C:0.8934, R:0.0105)
Batch 100/537: Loss=0.8603 (C:0.8603, R:0.0105)
Batch 125/537: Loss=0.8680 (C:0.8680, R:0.0105)
Batch 150/537: Loss=0.8801 (C:0.8801, R:0.0105)
Batch 175/537: Loss=0.8929 (C:0.8929, R:0.0105)
Batch 200/537: Loss=0.8879 (C:0.8879, R:0.0106)
Batch 225/537: Loss=0.8615 (C:0.8615, R:0.0105)
Batch 250/537: Loss=0.8263 (C:0.8263, R:0.0105)
Batch 275/537: Loss=0.8515 (C:0.8515, R:0.0105)
Batch 300/537: Loss=0.9211 (C:0.9211, R:0.0105)
Batch 325/537: Loss=0.8647 (C:0.8647, R:0.0105)
Batch 350/537: Loss=0.8825 (C:0.8825, R:0.0105)
Batch 375/537: Loss=0.9230 (C:0.9230, R:0.0105)
Batch 400/537: Loss=0.8767 (C:0.8767, R:0.0105)
Batch 425/537: Loss=0.8830 (C:0.8830, R:0.0105)
Batch 450/537: Loss=0.8101 (C:0.8101, R:0.0105)
Batch 475/537: Loss=0.8556 (C:0.8556, R:0.0105)
Batch 500/537: Loss=0.8513 (C:0.8513, R:0.0105)
Batch 525/537: Loss=0.8079 (C:0.8079, R:0.0105)

============================================================
Epoch 67/300 completed in 27.7s
Train: Loss=0.8638 (C:0.8638, R:0.0105) Ratio=5.20x
Val:   Loss=1.1151 (C:1.1151, R:0.0104) Ratio=3.12x
Reconstruction weight: 0.300
No improvement for 1 epochs
============================================================

Epoch 68 Training
----------------------------------------
Batch   0/537: Loss=0.8557 (C:0.8557, R:0.0106)
Batch  25/537: Loss=0.8698 (C:0.8698, R:0.0105)
Batch  50/537: Loss=0.8642 (C:0.8642, R:0.0105)
Batch  75/537: Loss=0.8762 (C:0.8762, R:0.0105)
Batch 100/537: Loss=0.8645 (C:0.8645, R:0.0105)
Batch 125/537: Loss=0.8749 (C:0.8749, R:0.0105)
Batch 150/537: Loss=0.8683 (C:0.8683, R:0.0105)
Batch 175/537: Loss=0.8832 (C:0.8832, R:0.0105)
Batch 200/537: Loss=0.9029 (C:0.9029, R:0.0105)
Batch 225/537: Loss=0.8487 (C:0.8487, R:0.0105)
Batch 250/537: Loss=0.8520 (C:0.8520, R:0.0105)
Batch 275/537: Loss=0.8407 (C:0.8407, R:0.0105)
Batch 300/537: Loss=0.8850 (C:0.8850, R:0.0105)
Batch 325/537: Loss=0.8922 (C:0.8922, R:0.0105)
Batch 350/537: Loss=0.7864 (C:0.7864, R:0.0105)
Batch 375/537: Loss=0.8878 (C:0.8878, R:0.0105)
Batch 400/537: Loss=0.8729 (C:0.8729, R:0.0105)
Batch 425/537: Loss=0.8662 (C:0.8662, R:0.0105)
Batch 450/537: Loss=0.9228 (C:0.9228, R:0.0105)
Batch 475/537: Loss=0.7969 (C:0.7969, R:0.0105)
Batch 500/537: Loss=0.8949 (C:0.8949, R:0.0105)
Batch 525/537: Loss=0.8815 (C:0.8815, R:0.0105)

============================================================
Epoch 68/300 completed in 21.2s
Train: Loss=0.8629 (C:0.8629, R:0.0105) Ratio=5.20x
Val:   Loss=1.0954 (C:1.0954, R:0.0104) Ratio=3.14x
Reconstruction weight: 0.300
No improvement for 2 epochs
============================================================

Epoch 69 Training
----------------------------------------
Batch   0/537: Loss=0.8082 (C:0.8082, R:0.0105)
Batch  25/537: Loss=0.8598 (C:0.8598, R:0.0105)
Batch  50/537: Loss=0.8898 (C:0.8898, R:0.0105)
Batch  75/537: Loss=0.8606 (C:0.8606, R:0.0105)
Batch 100/537: Loss=0.8495 (C:0.8495, R:0.0106)
Batch 125/537: Loss=0.8473 (C:0.8473, R:0.0105)
Batch 150/537: Loss=0.8543 (C:0.8543, R:0.0105)
Batch 175/537: Loss=0.8347 (C:0.8347, R:0.0105)
Batch 200/537: Loss=0.8500 (C:0.8500, R:0.0105)
Batch 225/537: Loss=0.8683 (C:0.8683, R:0.0105)
Batch 250/537: Loss=0.8326 (C:0.8326, R:0.0105)
Batch 275/537: Loss=0.8846 (C:0.8846, R:0.0105)
Batch 300/537: Loss=0.8516 (C:0.8516, R:0.0105)
Batch 325/537: Loss=0.8076 (C:0.8076, R:0.0105)
Batch 350/537: Loss=0.8585 (C:0.8585, R:0.0106)
Batch 375/537: Loss=0.8444 (C:0.8444, R:0.0105)
Batch 400/537: Loss=0.8450 (C:0.8450, R:0.0105)
Batch 425/537: Loss=0.8676 (C:0.8676, R:0.0105)
Batch 450/537: Loss=0.8571 (C:0.8571, R:0.0105)
Batch 475/537: Loss=0.9170 (C:0.9170, R:0.0105)
Batch 500/537: Loss=0.9210 (C:0.9210, R:0.0105)
Batch 525/537: Loss=0.8746 (C:0.8746, R:0.0105)

============================================================
Epoch 69/300 completed in 21.2s
Train: Loss=0.8611 (C:0.8611, R:0.0105) Ratio=5.37x
Val:   Loss=1.1240 (C:1.1240, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
No improvement for 3 epochs
============================================================

🌍 Updating global dataset at epoch 70
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.485 ± 0.919
    Neg distances: 3.891 ± 1.642
    Separation ratio: 8.03x
    Gap: -6.609
    ✅ Excellent global separation!

Epoch 70 Training
----------------------------------------
Batch   0/537: Loss=0.8575 (C:0.8575, R:0.0106)
Batch  25/537: Loss=0.8528 (C:0.8528, R:0.0105)
Batch  50/537: Loss=0.8700 (C:0.8700, R:0.0106)
Batch  75/537: Loss=0.8881 (C:0.8881, R:0.0105)
Batch 100/537: Loss=0.7808 (C:0.7808, R:0.0105)
Batch 125/537: Loss=0.8842 (C:0.8842, R:0.0105)
Batch 150/537: Loss=0.8351 (C:0.8351, R:0.0105)
Batch 175/537: Loss=0.8902 (C:0.8902, R:0.0105)
Batch 200/537: Loss=0.8826 (C:0.8826, R:0.0105)
Batch 225/537: Loss=0.8216 (C:0.8216, R:0.0105)
Batch 250/537: Loss=0.8578 (C:0.8578, R:0.0105)
Batch 275/537: Loss=0.8155 (C:0.8155, R:0.0105)
Batch 300/537: Loss=0.7815 (C:0.7815, R:0.0105)
Batch 325/537: Loss=0.7845 (C:0.7845, R:0.0105)
Batch 350/537: Loss=0.9088 (C:0.9088, R:0.0105)
Batch 375/537: Loss=0.8541 (C:0.8541, R:0.0105)
Batch 400/537: Loss=0.8363 (C:0.8363, R:0.0105)
Batch 425/537: Loss=0.8716 (C:0.8716, R:0.0105)
Batch 450/537: Loss=0.8736 (C:0.8736, R:0.0105)
Batch 475/537: Loss=0.9086 (C:0.9086, R:0.0105)
Batch 500/537: Loss=0.8653 (C:0.8653, R:0.0105)
Batch 525/537: Loss=0.8224 (C:0.8224, R:0.0105)

============================================================
Epoch 70/300 completed in 27.1s
Train: Loss=0.8504 (C:0.8504, R:0.0105) Ratio=5.36x
Val:   Loss=1.1142 (C:1.1142, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
No improvement for 4 epochs
============================================================

Epoch 71 Training
----------------------------------------
Batch   0/537: Loss=0.8626 (C:0.8626, R:0.0105)
Batch  25/537: Loss=0.8665 (C:0.8665, R:0.0105)
Batch  50/537: Loss=0.8205 (C:0.8205, R:0.0105)
Batch  75/537: Loss=0.7930 (C:0.7930, R:0.0105)
Batch 100/537: Loss=0.8118 (C:0.8118, R:0.0105)
Batch 125/537: Loss=0.8449 (C:0.8449, R:0.0105)
Batch 150/537: Loss=0.7595 (C:0.7595, R:0.0105)
Batch 175/537: Loss=0.8064 (C:0.8064, R:0.0105)
Batch 200/537: Loss=0.8607 (C:0.8607, R:0.0105)
Batch 225/537: Loss=0.8937 (C:0.8937, R:0.0105)
Batch 250/537: Loss=0.8219 (C:0.8219, R:0.0105)
Batch 275/537: Loss=0.8394 (C:0.8394, R:0.0105)
Batch 300/537: Loss=0.8417 (C:0.8417, R:0.0105)
Batch 325/537: Loss=0.8839 (C:0.8839, R:0.0105)
Batch 350/537: Loss=0.7908 (C:0.7908, R:0.0105)
Batch 375/537: Loss=0.8011 (C:0.8011, R:0.0105)
Batch 400/537: Loss=0.8687 (C:0.8687, R:0.0105)
Batch 425/537: Loss=0.7901 (C:0.7901, R:0.0105)
Batch 450/537: Loss=0.8808 (C:0.8808, R:0.0105)
Batch 475/537: Loss=0.8732 (C:0.8732, R:0.0105)
Batch 500/537: Loss=0.8938 (C:0.8938, R:0.0105)
Batch 525/537: Loss=0.8838 (C:0.8838, R:0.0105)

============================================================
Epoch 71/300 completed in 21.1s
Train: Loss=0.8471 (C:0.8471, R:0.0105) Ratio=5.34x
Val:   Loss=1.1131 (C:1.1131, R:0.0104) Ratio=3.05x
Reconstruction weight: 0.300
No improvement for 5 epochs
============================================================

Epoch 72 Training
----------------------------------------
Batch   0/537: Loss=0.8483 (C:0.8483, R:0.0105)
Batch  25/537: Loss=0.8074 (C:0.8074, R:0.0105)
Batch  50/537: Loss=0.8524 (C:0.8524, R:0.0105)
Batch  75/537: Loss=0.7206 (C:0.7206, R:0.0105)
Batch 100/537: Loss=0.8545 (C:0.8545, R:0.0105)
Batch 125/537: Loss=0.8013 (C:0.8013, R:0.0105)
Batch 150/537: Loss=0.7968 (C:0.7968, R:0.0105)
Batch 175/537: Loss=0.9243 (C:0.9243, R:0.0105)
Batch 200/537: Loss=0.8557 (C:0.8557, R:0.0105)
Batch 225/537: Loss=0.7918 (C:0.7918, R:0.0105)
Batch 250/537: Loss=0.8327 (C:0.8327, R:0.0105)
Batch 275/537: Loss=0.8751 (C:0.8751, R:0.0105)
Batch 300/537: Loss=0.9099 (C:0.9099, R:0.0105)
Batch 325/537: Loss=0.8447 (C:0.8447, R:0.0105)
Batch 350/537: Loss=0.7616 (C:0.7616, R:0.0105)
Batch 375/537: Loss=0.8176 (C:0.8176, R:0.0105)
Batch 400/537: Loss=0.8194 (C:0.8194, R:0.0105)
Batch 425/537: Loss=0.8660 (C:0.8660, R:0.0105)
Batch 450/537: Loss=0.8187 (C:0.8187, R:0.0105)
Batch 475/537: Loss=0.8392 (C:0.8392, R:0.0105)
Batch 500/537: Loss=0.8769 (C:0.8769, R:0.0105)
Batch 525/537: Loss=0.8224 (C:0.8224, R:0.0105)

============================================================
Epoch 72/300 completed in 21.4s
Train: Loss=0.8440 (C:0.8440, R:0.0105) Ratio=5.42x
Val:   Loss=1.1017 (C:1.1017, R:0.0104) Ratio=3.13x
Reconstruction weight: 0.300
No improvement for 6 epochs
============================================================

🌍 Updating global dataset at epoch 73
🌍 Extracting features for entire dataset...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
  Subsampled to 10000 samples
  Global dataset updated: 10000 samples
  Analyzing global separation...
  GLOBAL ANALYSIS:
    Pos distances: 0.485 ± 0.928
    Neg distances: 3.915 ± 1.651
    Separation ratio: 8.07x
    Gap: -6.555
    ✅ Excellent global separation!

Epoch 73 Training
----------------------------------------
Batch   0/537: Loss=0.8824 (C:0.8824, R:0.0106)
Batch  25/537: Loss=0.8277 (C:0.8277, R:0.0106)
Batch  50/537: Loss=0.8674 (C:0.8674, R:0.0105)
Batch  75/537: Loss=0.7908 (C:0.7908, R:0.0105)
Batch 100/537: Loss=0.8423 (C:0.8423, R:0.0105)
Batch 125/537: Loss=0.8310 (C:0.8310, R:0.0105)
Batch 150/537: Loss=0.8275 (C:0.8275, R:0.0105)
Batch 175/537: Loss=0.8184 (C:0.8184, R:0.0105)
Batch 200/537: Loss=0.8448 (C:0.8448, R:0.0105)
Batch 225/537: Loss=0.8694 (C:0.8694, R:0.0105)
Batch 250/537: Loss=0.8819 (C:0.8819, R:0.0105)
Batch 275/537: Loss=0.8486 (C:0.8486, R:0.0105)
Batch 300/537: Loss=0.8628 (C:0.8628, R:0.0105)
Batch 325/537: Loss=0.8406 (C:0.8406, R:0.0105)
Batch 350/537: Loss=0.8520 (C:0.8520, R:0.0105)
Batch 375/537: Loss=0.8127 (C:0.8127, R:0.0105)
Batch 400/537: Loss=0.8153 (C:0.8153, R:0.0105)
Batch 425/537: Loss=0.8758 (C:0.8758, R:0.0106)
Batch 450/537: Loss=0.9088 (C:0.9088, R:0.0105)
Batch 475/537: Loss=0.7989 (C:0.7989, R:0.0105)
Batch 500/537: Loss=0.8645 (C:0.8645, R:0.0105)
Batch 525/537: Loss=0.8175 (C:0.8175, R:0.0105)

============================================================
Epoch 73/300 completed in 27.6s
Train: Loss=0.8393 (C:0.8393, R:0.0105) Ratio=5.32x
Val:   Loss=1.0882 (C:1.0882, R:0.0104) Ratio=3.17x
Reconstruction weight: 0.300
No improvement for 7 epochs
============================================================

Epoch 74 Training
----------------------------------------
Batch   0/537: Loss=0.8909 (C:0.8909, R:0.0105)
Batch  25/537: Loss=0.8184 (C:0.8184, R:0.0105)
Batch  50/537: Loss=0.7950 (C:0.7950, R:0.0105)
Batch  75/537: Loss=0.8277 (C:0.8277, R:0.0105)
Batch 100/537: Loss=0.7855 (C:0.7855, R:0.0105)
Batch 125/537: Loss=0.8643 (C:0.8643, R:0.0105)
Batch 150/537: Loss=0.7981 (C:0.7981, R:0.0106)
Batch 175/537: Loss=0.8001 (C:0.8001, R:0.0105)
Batch 200/537: Loss=0.8408 (C:0.8408, R:0.0105)
Batch 225/537: Loss=0.8052 (C:0.8052, R:0.0105)
Batch 250/537: Loss=0.7498 (C:0.7498, R:0.0105)
Batch 275/537: Loss=0.8188 (C:0.8188, R:0.0105)
Batch 300/537: Loss=0.8874 (C:0.8874, R:0.0105)
Batch 325/537: Loss=0.8446 (C:0.8446, R:0.0105)
Batch 350/537: Loss=0.8093 (C:0.8093, R:0.0105)
Batch 375/537: Loss=0.8526 (C:0.8526, R:0.0105)
Batch 400/537: Loss=0.8180 (C:0.8180, R:0.0105)
Batch 425/537: Loss=0.8588 (C:0.8588, R:0.0105)
Batch 450/537: Loss=0.8774 (C:0.8774, R:0.0106)
Batch 475/537: Loss=0.8507 (C:0.8507, R:0.0105)
Batch 500/537: Loss=0.8437 (C:0.8437, R:0.0105)
Batch 525/537: Loss=0.8671 (C:0.8671, R:0.0105)

============================================================
Epoch 74/300 completed in 22.1s
Train: Loss=0.8381 (C:0.8381, R:0.0105) Ratio=5.38x
Val:   Loss=1.1158 (C:1.1158, R:0.0104) Ratio=3.09x
Reconstruction weight: 0.300
No improvement for 8 epochs

Early stopping triggered after 74 epochs
Best model was at epoch 66 with Val Loss: 1.0769

Global Dataset Training Completed!
Best epoch: 66
Best validation loss: 1.0769
Final separation ratios: Train=5.38x, Val=3.09x
Training completed!
Loading best model from entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin3.0_updatefreq3_max_global_samples10000_20250715_171731/checkpoints/best_model.pt
Starting model evaluation...
========================================
GlobalContrastiveEvaluator initialized on cuda
Starting comprehensive evaluation...
============================================================
Extracting latent representations...
  Processed 1/10 batches
Extracted representations: torch.Size([9824, 75])
Evaluating clustering performance...
Clustering Results:
  Silhouette Score: 0.4588
  Adjusted Rand Score: 0.5297
  Clustering Accuracy: 0.8125
Evaluating classification performance...
  Extracting training representations...
Extracting latent representations...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
Extracted representations: torch.Size([547740, 75])
  Extracting validation representations...
Extracting latent representations...
  Processed 1/9 batches
Extracted representations: torch.Size([9180, 75])
Subsampled training to 50000 samples
  Training on 50000 samples, evaluating on 9180 samples
Classification Results:
  Accuracy: 0.8174
  Per-class F1: [0.8351464435146444, 0.7524240465416937, 0.865257382604486]
Evaluating reconstruction quality...
Reconstruction Results:
  Average MSE: 0.010432
Evaluating separation quality...
Separation Results:
  Positive distances: 1.123 ± 1.387
  Negative distances: 3.436 ± 1.829
  Separation ratio: 3.06x
  Gap: -6.322
  Perfect separation: No

Comprehensive evaluation completed!

============================================================
EVALUATION SUMMARY
============================================================
Clustering Performance:
  Silhouette Score: 0.4588
  Clustering Accuracy: 0.8125
  Adjusted Rand Score: 0.5297

Classification Performance:
  Accuracy: 0.8174

Separation Quality:
  Separation Ratio: 3.06x
  Gap: -6.322
  Perfect Separation: False

Reconstruction Quality:
  Average MSE: 0.010432
============================================================
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin3.0_updatefreq3_max_global_samples10000_20250715_171731/results/evaluation_results_20250715_174701.json
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin3.0_updatefreq3_max_global_samples10000_20250715_171731/results/evaluation_results_20250715_174701.json
Saving final experiment results...
Final results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin3.0_updatefreq3_max_global_samples10000_20250715_171731/final_results.json

============================================================
PIPELINE COMPLETED SUCCESSFULLY!
============================================================
Experiment directory: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin3.0_updatefreq3_max_global_samples10000_20250715_171731
Best model: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin3.0_updatefreq3_max_global_samples10000_20250715_171731/checkpoints/best_model.pt
Final results: entailment_surfaces/supervised_contrastive_autoencoder/experiments/coarse_margin3.0_updatefreq3_max_global_samples10000_20250715_171731/final_results.json

Key Results:
  Separation ratio: 3.06x
  Perfect separation: False
  Classification accuracy: 0.8174
  Result: 0.8174% (improvement: +-80.85%)
  Cleaning up: coarse_margin3.0_updatefreq3_max_global_samples10000_20250715_171731

======================================================================
COARSE SEARCH COMPLETED
======================================================================
Best accuracy: 0.8178%
Total improvement: +-80.85%
Best config: {'margin': 2.0, 'update_frequency': 1, 'max_global_samples': 5000}
Best model saved in: coarse_margin2.0_updatefreq1_max_global_samples5000_20250715_125326

Detailed results saved to: coarse_hyperparameter_search_20250715_174701.json
Readable summary saved to: coarse_search_summary_20250715_174701.txt

Search completed. Review coarse_search_summary_20250715_174701.txt for easy analysis.
Best model saved in: experiments/coarse_margin2.0_updatefreq1_max_global_samples5000_20250715_125326
All other experiment directories were cleaned up to save space.

Analysis completed with exit code: 0
Time: Tue 15 Jul 17:47:03 BST 2025

=== ANALYSIS SUCCESSFUL ===
Hyperparam search successful!


Job finished.
