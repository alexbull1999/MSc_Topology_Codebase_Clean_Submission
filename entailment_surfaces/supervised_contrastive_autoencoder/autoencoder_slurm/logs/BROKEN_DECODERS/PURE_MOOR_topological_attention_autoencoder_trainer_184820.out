Starting Surface Distance Metric Analysis job...
Job ID: 184820
Node: gpuvm16
Time: Tue 22 Jul 14:14:53 BST 2025
Loading CUDA...
Activating conda environment...
Activated conda environment: /vol/bitbucket/ahb24/tda_entailment_new
Python location: /vol/bitbucket/ahb24/tda_entailment_new/bin/python
Checking GPU availability...
Tue Jul 22 14:14:55 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.133.07             Driver Version: 570.133.07     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla T4                       Off |   00000000:00:06.0 Off |                    0 |
| N/A   35C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+

Testing PyTorch and CUDA...
PyTorch version: 2.4.1
CUDA available: True
CUDA device: Tesla T4
GPU memory: 15.6 GB
PyTorch setup verified!

Starting Topological Training...

============================================================
TOPOLOGICAL AUTOENCODER TRAINING WITH TORCHPH
============================================================
Experiment setup completed:
  Experiment directory: entailment_surfaces/supervised_contrastive_autoencoder/experiments/topological_autoencoder_torchph_phase1_20250722_141516
  Config saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/topological_autoencoder_torchph_phase1_20250722_141516/config.json
Loading data...
========================================
FlexibleEmbedder initialized with type: 'concat'
Output dimension will be: 1536
GlobalDataLoader initialized:
  Embedding type: concat
  Output dimension: 1536
  Sample size: All
Starting data loading pipeline...
============================================================
Loading training data from data/processed/snli_full_standard_SBERT.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 549367 training samples
Loading validation data from data/processed/snli_full_standard_SBERT_validation.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9842 validation samples
Loading test data from data/processed/snli_full_standard_SBERT_test.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9824 test samples
Generating embeddings for training...
Generating concat embeddings on cuda
Processing 549367 samples in batches of 1000
  Processing batch 1/550
  Processing batch 6/550
  Processing batch 11/550
  Processing batch 16/550
  Processing batch 21/550
  Processing batch 26/550
  Processing batch 31/550
  Processing batch 36/550
  Processing batch 41/550
  Processing batch 46/550
  Processing batch 51/550
  Processing batch 56/550
  Processing batch 61/550
  Processing batch 66/550
  Processing batch 71/550
  Processing batch 76/550
  Processing batch 81/550
  Processing batch 86/550
  Processing batch 91/550
  Processing batch 96/550
  Processing batch 101/550
  Processing batch 106/550
  Processing batch 111/550
  Processing batch 116/550
  Processing batch 121/550
  Processing batch 126/550
  Processing batch 131/550
  Processing batch 136/550
  Processing batch 141/550
  Processing batch 146/550
  Processing batch 151/550
  Processing batch 156/550
  Processing batch 161/550
  Processing batch 166/550
  Processing batch 171/550
  Processing batch 176/550
  Processing batch 181/550
  Processing batch 186/550
  Processing batch 191/550
  Processing batch 196/550
  Processing batch 201/550
  Processing batch 206/550
  Processing batch 211/550
  Processing batch 216/550
  Processing batch 221/550
  Processing batch 226/550
  Processing batch 231/550
  Processing batch 236/550
  Processing batch 241/550
  Processing batch 246/550
  Processing batch 251/550
  Processing batch 256/550
  Processing batch 261/550
  Processing batch 266/550
  Processing batch 271/550
  Processing batch 276/550
  Processing batch 281/550
  Processing batch 286/550
  Processing batch 291/550
  Processing batch 296/550
  Processing batch 301/550
  Processing batch 306/550
  Processing batch 311/550
  Processing batch 316/550
  Processing batch 321/550
  Processing batch 326/550
  Processing batch 331/550
  Processing batch 336/550
  Processing batch 341/550
  Processing batch 346/550
  Processing batch 351/550
  Processing batch 356/550
  Processing batch 361/550
  Processing batch 366/550
  Processing batch 371/550
  Processing batch 376/550
  Processing batch 381/550
  Processing batch 386/550
  Processing batch 391/550
  Processing batch 396/550
  Processing batch 401/550
  Processing batch 406/550
  Processing batch 411/550
  Processing batch 416/550
  Processing batch 421/550
  Processing batch 426/550
  Processing batch 431/550
  Processing batch 436/550
  Processing batch 441/550
  Processing batch 446/550
  Processing batch 451/550
  Processing batch 456/550
  Processing batch 461/550
  Processing batch 466/550
  Processing batch 471/550
  Processing batch 476/550
  Processing batch 481/550
  Processing batch 486/550
  Processing batch 491/550
  Processing batch 496/550
  Processing batch 501/550
  Processing batch 506/550
  Processing batch 511/550
  Processing batch 516/550
  Processing batch 521/550
  Processing batch 526/550
  Processing batch 531/550
  Processing batch 536/550
  Processing batch 541/550
  Processing batch 546/550
Generated concat embeddings: torch.Size([549367, 1536])
Generating embeddings for validation...
Generating concat embeddings on cuda
Processing 9842 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9842, 1536])
Generating embeddings for test...
Generating concat embeddings on cuda
Processing 9824 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9824, 1536])
EntailmentDataset created: 549367 samples
  Embedding shape: torch.Size([549367, 1536])
  Class distribution: {'entailment': 183416, 'neutral': 182764, 'contradiction': 183187}
EntailmentDataset created: 9842 samples
  Embedding shape: torch.Size([9842, 1536])
  Class distribution: {'entailment': 3329, 'neutral': 3235, 'contradiction': 3278}
EntailmentDataset created: 9824 samples
  Embedding shape: torch.Size([9824, 1536])
  Class distribution: {'entailment': 3368, 'neutral': 3219, 'contradiction': 3237}

Data loading pipeline completed!
Output embedding dimension: 1536
Updated model input_dim to: 1536
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 537
  Class 2: 183187 samples
  Class 0: 183416 samples
  Class 1: 182764 samples
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 9
  Class 2: 3278 samples
  Class 0: 3329 samples
  Class 1: 3235 samples
DataLoaders created:
  Batch size: 1020
  Balanced sampling: True
  Train batches: 537
  Val batches: 9
  Test batches: 10
Data loading completed!
  Train: 549367 samples, 537 batches
  Val: 9842 samples, 9 batches
  Test: 9824 samples, 10 batches
AttentionAutoencoder initialized:
  Input dim: 1536
  Latent dim: 100
  Hidden dims: [1024, 768, 512, 256, 128]
  Attention Heads: 5
  Total parameters: 5,905,916
FullDatasetContrastiveLoss initialized:
  Margin: 2.0
  Update frequency: 3 epochs
  Max global samples: 5000
FullDatasetCombinedLoss initialized:
  Contrastive weight: 0.0
  Base reconstruction weight: 0.1
  Scheduled reconstruction: warmup=10 epochs, max_weight=0.3
MoorTopologicalLoss Initialized: Using 0-dimensional persistence pairings (MST edges).
No prototypes being used for topological loss - whole dataset instead.
TopologicalTrainer initialized on device: cuda
Model parameters: 5,905,916
Enhanced with topological loss monitoring
Starting Phase 1: Pure Topological Training
  Contrastive weight: 0.0
  Topological weight: 1.0
  Reconstruction weight: 0.1

======================================================================
ğŸ§  TOPOLOGICAL AUTOENCODER TRAINING STARTED
======================================================================

============================================================
EPOCH 1 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=16.3784 (C:3.3511, R:0.0110, T:16.3772(w:1.000)âš ï¸)
Batch  25/537: Loss=3.5323 (C:5.7227, R:0.0099, T:3.5314(w:1.000)ğŸš€)
Batch  50/537: Loss=3.0908 (C:5.4049, R:0.0099, T:3.0898(w:1.000)ğŸš€)
Batch  75/537: Loss=2.7888 (C:5.5028, R:0.0100, T:2.7878(w:1.000)ğŸš€)
Batch 100/537: Loss=2.3209 (C:5.4665, R:0.0100, T:2.3199(w:1.000)ğŸš€)
Batch 125/537: Loss=2.1597 (C:5.4843, R:0.0100, T:2.1587(w:1.000)ğŸš€)
Batch 150/537: Loss=1.8421 (C:5.5374, R:0.0100, T:1.8411(w:1.000)ğŸš€)
Batch 175/537: Loss=1.6927 (C:5.6498, R:0.0100, T:1.6917(w:1.000)ğŸš€)
Batch 200/537: Loss=1.5139 (C:5.5941, R:0.0099, T:1.5129(w:1.000)ğŸš€)
Batch 225/537: Loss=1.4125 (C:5.5261, R:0.0100, T:1.4116(w:1.000)ğŸš€)
Batch 250/537: Loss=1.2937 (C:5.5684, R:0.0099, T:1.2927(w:1.000)ğŸš€)
Batch 275/537: Loss=1.2838 (C:5.6532, R:0.0100, T:1.2828(w:1.000)ğŸš€)
Batch 300/537: Loss=1.2141 (C:5.5588, R:0.0100, T:1.2131(w:1.000)ğŸš€)
Batch 325/537: Loss=1.1985 (C:5.6456, R:0.0100, T:1.1975(w:1.000)ğŸš€)
Batch 350/537: Loss=1.0916 (C:5.6101, R:0.0100, T:1.0906(w:1.000)ğŸš€)
Batch 375/537: Loss=1.1003 (C:5.5569, R:0.0099, T:1.0993(w:1.000)ğŸš€)
Batch 400/537: Loss=1.1281 (C:5.6133, R:0.0100, T:1.1271(w:1.000)ğŸš€)
Batch 425/537: Loss=1.0453 (C:5.5631, R:0.0100, T:1.0443(w:1.000)ğŸš€)
Batch 450/537: Loss=1.0756 (C:5.6058, R:0.0100, T:1.0746(w:1.000)ğŸš€)
Batch 475/537: Loss=0.9896 (C:5.6722, R:0.0099, T:0.9887(w:1.000)ğŸ‰)
Batch 500/537: Loss=1.0666 (C:5.6945, R:0.0099, T:1.0656(w:1.000)ğŸš€)
Batch 525/537: Loss=0.9956 (C:5.6532, R:0.0100, T:0.9946(w:1.000)ğŸ‰)
ğŸ‰ MILESTONE: First topological learning detected at epoch 1!
   Initial topological loss: 1.7540
ğŸ“ˆ New best topological loss: 1.7540

ğŸ“Š EPOCH 1 TRAINING SUMMARY:
  Total Loss: 1.7550
  Contrastive: 5.5568
  Reconstruction: 0.0100
  Topological: 1.7540 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 14.6535
  Contrastive: 3.5785
  Reconstruction: 0.0099
  Topological: 14.6525 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 1/300 COMPLETE (49.4s)
Train Loss: 1.7550 (C:5.5568, R:0.0100, T:1.7540)
Val Loss:   14.6535 (C:3.5785, R:0.0099, T:14.6525)
ğŸš€ Good topological learning progress
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 2 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.0291 (C:5.5535, R:0.0099, T:1.0281(w:1.000)ğŸš€)
Batch  25/537: Loss=1.0069 (C:5.5570, R:0.0100, T:1.0059(w:1.000)ğŸš€)
Batch  50/537: Loss=0.9234 (C:5.5897, R:0.0100, T:0.9224(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.9586 (C:5.6057, R:0.0099, T:0.9576(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.9207 (C:5.5132, R:0.0100, T:0.9197(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.9432 (C:5.6887, R:0.0100, T:0.9422(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.9643 (C:5.5802, R:0.0100, T:0.9633(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.9531 (C:5.6083, R:0.0100, T:0.9521(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.9494 (C:5.5662, R:0.0099, T:0.9484(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.9113 (C:5.5706, R:0.0099, T:0.9103(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.9069 (C:5.6107, R:0.0099, T:0.9059(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.9179 (C:5.4453, R:0.0100, T:0.9169(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.9175 (C:5.6390, R:0.0100, T:0.9165(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.9020 (C:5.6337, R:0.0100, T:0.9010(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.8786 (C:5.6233, R:0.0099, T:0.8776(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.8701 (C:5.4550, R:0.0099, T:0.8691(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.8747 (C:5.5921, R:0.0100, T:0.8737(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.8654 (C:5.5934, R:0.0099, T:0.8644(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.8686 (C:5.5324, R:0.0099, T:0.8676(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.8503 (C:5.5739, R:0.0100, T:0.8493(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.9053 (C:5.7014, R:0.0100, T:0.9043(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.8451 (C:5.6394, R:0.0099, T:0.8441(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.9173

ğŸ“Š EPOCH 2 TRAINING SUMMARY:
  Total Loss: 0.9183
  Contrastive: 5.5771
  Reconstruction: 0.0100
  Topological: 0.9173 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 12.4321
  Contrastive: 3.7312
  Reconstruction: 0.0099
  Topological: 12.4311 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 2/300 COMPLETE (47.0s)
Train Loss: 0.9183 (C:5.5771, R:0.0100, T:0.9173)
Val Loss:   12.4321 (C:3.7312, R:0.0099, T:12.4311)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 3 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.8686 (C:5.5315, R:0.0100, T:0.8676(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.8956 (C:5.4764, R:0.0099, T:0.8946(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.8329 (C:5.5570, R:0.0100, T:0.8319(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.8332 (C:5.5174, R:0.0100, T:0.8322(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.8037 (C:5.5069, R:0.0099, T:0.8027(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.8115 (C:5.5423, R:0.0099, T:0.8105(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.8587 (C:5.5142, R:0.0099, T:0.8578(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.7840 (C:5.5129, R:0.0099, T:0.7830(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.8183 (C:5.5157, R:0.0099, T:0.8173(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.8479 (C:5.5718, R:0.0100, T:0.8469(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.8078 (C:5.5973, R:0.0099, T:0.8068(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.8410 (C:5.5934, R:0.0099, T:0.8400(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.8208 (C:5.5776, R:0.0099, T:0.8198(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.8048 (C:5.6575, R:0.0099, T:0.8038(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.8064 (C:5.5688, R:0.0100, T:0.8054(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.8225 (C:5.5828, R:0.0099, T:0.8215(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.8420 (C:5.6442, R:0.0099, T:0.8410(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.8636 (C:5.5200, R:0.0099, T:0.8626(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.8065 (C:5.5686, R:0.0100, T:0.8055(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.7828 (C:5.5166, R:0.0099, T:0.7818(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.8158 (C:5.5337, R:0.0099, T:0.8148(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.8019 (C:5.6167, R:0.0100, T:0.8009(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.8255

ğŸ“Š EPOCH 3 TRAINING SUMMARY:
  Total Loss: 0.8265
  Contrastive: 5.5665
  Reconstruction: 0.0100
  Topological: 0.8255 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 11.7640
  Contrastive: 3.7800
  Reconstruction: 0.0099
  Topological: 11.7631 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 3/300 COMPLETE (45.1s)
Train Loss: 0.8265 (C:5.5665, R:0.0100, T:0.8255)
Val Loss:   11.7640 (C:3.7800, R:0.0099, T:11.7631)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 4 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.7734 (C:5.5459, R:0.0100, T:0.7724(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.7917 (C:5.5761, R:0.0100, T:0.7907(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.7770 (C:5.5829, R:0.0100, T:0.7760(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.7827 (C:5.5666, R:0.0099, T:0.7817(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.7746 (C:5.6322, R:0.0099, T:0.7736(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.7846 (C:5.5437, R:0.0100, T:0.7836(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.7570 (C:5.5605, R:0.0099, T:0.7560(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.7486 (C:5.5484, R:0.0100, T:0.7476(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.8081 (C:5.5856, R:0.0100, T:0.8071(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.7461 (C:5.5612, R:0.0099, T:0.7451(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.7641 (C:5.5679, R:0.0100, T:0.7631(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.7809 (C:5.5949, R:0.0100, T:0.7799(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.7833 (C:5.5383, R:0.0100, T:0.7823(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.8024 (C:5.6365, R:0.0099, T:0.8014(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.7933 (C:5.5439, R:0.0100, T:0.7923(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.7645 (C:5.5910, R:0.0099, T:0.7635(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.7641 (C:5.5279, R:0.0099, T:0.7631(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.8120 (C:5.6507, R:0.0100, T:0.8110(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.7664 (C:5.5752, R:0.0099, T:0.7654(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.7928 (C:5.5728, R:0.0100, T:0.7918(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.7733 (C:5.5233, R:0.0100, T:0.7723(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.7481 (C:5.5580, R:0.0100, T:0.7471(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.7791

ğŸ“Š EPOCH 4 TRAINING SUMMARY:
  Total Loss: 0.7801
  Contrastive: 5.5698
  Reconstruction: 0.0100
  Topological: 0.7791 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 11.0113
  Contrastive: 3.8930
  Reconstruction: 0.0099
  Topological: 11.0103 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 4/300 COMPLETE (45.9s)
Train Loss: 0.7801 (C:5.5698, R:0.0100, T:0.7791)
Val Loss:   11.0113 (C:3.8930, R:0.0099, T:11.0103)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 5 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.7479 (C:5.5954, R:0.0099, T:0.7469(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.7893 (C:5.5585, R:0.0099, T:0.7883(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.7520 (C:5.4747, R:0.0100, T:0.7510(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.7404 (C:5.5950, R:0.0099, T:0.7394(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.7748 (C:5.5431, R:0.0100, T:0.7738(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.7540 (C:5.6372, R:0.0100, T:0.7530(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.7626 (C:5.5432, R:0.0099, T:0.7616(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.7419 (C:5.5373, R:0.0099, T:0.7409(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.8205 (C:5.6505, R:0.0100, T:0.8195(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.7696 (C:5.6070, R:0.0099, T:0.7686(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.7424 (C:5.5713, R:0.0100, T:0.7414(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.7263 (C:5.6094, R:0.0100, T:0.7253(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.7702 (C:5.6051, R:0.0099, T:0.7692(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.7476 (C:5.5287, R:0.0099, T:0.7466(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.7496 (C:5.5169, R:0.0099, T:0.7486(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.7398 (C:5.6270, R:0.0100, T:0.7388(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.7158 (C:5.5627, R:0.0099, T:0.7148(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.7287 (C:5.5710, R:0.0100, T:0.7277(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.7421 (C:5.6150, R:0.0100, T:0.7411(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.7314 (C:5.5788, R:0.0100, T:0.7304(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.7211 (C:5.5811, R:0.0099, T:0.7201(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.7394 (C:5.5456, R:0.0099, T:0.7384(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.7506

ğŸ“Š EPOCH 5 TRAINING SUMMARY:
  Total Loss: 0.7516
  Contrastive: 5.5710
  Reconstruction: 0.0100
  Topological: 0.7506 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 10.6680
  Contrastive: 3.9139
  Reconstruction: 0.0099
  Topological: 10.6670 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 5/300 COMPLETE (45.5s)
Train Loss: 0.7516 (C:5.5710, R:0.0100, T:0.7506)
Val Loss:   10.6680 (C:3.9139, R:0.0099, T:10.6670)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 6 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.7892 (C:5.6060, R:0.0100, T:0.7882(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.7114 (C:5.5005, R:0.0099, T:0.7104(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.7342 (C:5.5309, R:0.0099, T:0.7332(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.7513 (C:5.5967, R:0.0100, T:0.7503(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.7543 (C:5.4846, R:0.0100, T:0.7533(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.7380 (C:5.5799, R:0.0099, T:0.7370(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.7395 (C:5.5961, R:0.0100, T:0.7385(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.7142 (C:5.5487, R:0.0100, T:0.7132(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6911 (C:5.5999, R:0.0099, T:0.6901(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.7575 (C:5.5058, R:0.0100, T:0.7565(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6998 (C:5.5653, R:0.0099, T:0.6988(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.7037 (C:5.5467, R:0.0100, T:0.7027(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.7622 (C:5.5811, R:0.0100, T:0.7612(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.7565 (C:5.5754, R:0.0099, T:0.7555(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.7319 (C:5.5079, R:0.0100, T:0.7309(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.7025 (C:5.5884, R:0.0099, T:0.7015(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.7487 (C:5.5485, R:0.0100, T:0.7477(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.7684 (C:5.6259, R:0.0100, T:0.7674(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.7124 (C:5.5479, R:0.0100, T:0.7114(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6996 (C:5.5736, R:0.0100, T:0.6986(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.7075 (C:5.5867, R:0.0100, T:0.7065(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.7268 (C:5.4788, R:0.0099, T:0.7258(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.7307

ğŸ“Š EPOCH 6 TRAINING SUMMARY:
  Total Loss: 0.7317
  Contrastive: 5.5765
  Reconstruction: 0.0100
  Topological: 0.7307 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 10.1454
  Contrastive: 3.9831
  Reconstruction: 0.0099
  Topological: 10.1445 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 6/300 COMPLETE (48.6s)
Train Loss: 0.7317 (C:5.5765, R:0.0100, T:0.7307)
Val Loss:   10.1454 (C:3.9831, R:0.0099, T:10.1445)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 7 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6947 (C:5.5808, R:0.0100, T:0.6937(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.7442 (C:5.5897, R:0.0100, T:0.7432(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6950 (C:5.5324, R:0.0099, T:0.6940(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.7159 (C:5.5708, R:0.0099, T:0.7149(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.7017 (C:5.6104, R:0.0099, T:0.7007(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6934 (C:5.5879, R:0.0100, T:0.6924(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6992 (C:5.5605, R:0.0100, T:0.6982(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.7282 (C:5.6164, R:0.0100, T:0.7272(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.7037 (C:5.5207, R:0.0099, T:0.7027(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.7395 (C:5.4623, R:0.0099, T:0.7385(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.7097 (C:5.5321, R:0.0099, T:0.7087(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.7128 (C:5.5915, R:0.0100, T:0.7118(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6854 (C:5.5947, R:0.0099, T:0.6844(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.7077 (C:5.5585, R:0.0100, T:0.7067(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6636 (C:5.5822, R:0.0099, T:0.6626(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.7179 (C:5.5821, R:0.0100, T:0.7169(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.7351 (C:5.5990, R:0.0100, T:0.7341(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6964 (C:5.6012, R:0.0100, T:0.6954(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6929 (C:5.5418, R:0.0099, T:0.6920(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.7209 (C:5.6372, R:0.0100, T:0.7199(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.7327 (C:5.5713, R:0.0099, T:0.7317(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.7384 (C:5.6135, R:0.0100, T:0.7374(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.7103

ğŸ“Š EPOCH 7 TRAINING SUMMARY:
  Total Loss: 0.7113
  Contrastive: 5.5790
  Reconstruction: 0.0100
  Topological: 0.7103 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 9.6601
  Contrastive: 4.0332
  Reconstruction: 0.0099
  Topological: 9.6592 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 7/300 COMPLETE (50.4s)
Train Loss: 0.7113 (C:5.5790, R:0.0100, T:0.7103)
Val Loss:   9.6601 (C:4.0332, R:0.0099, T:9.6592)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 8 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6543 (C:5.5912, R:0.0099, T:0.6533(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.7124 (C:5.6183, R:0.0100, T:0.7114(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.7056 (C:5.6614, R:0.0100, T:0.7046(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.7151 (C:5.4989, R:0.0100, T:0.7141(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6915 (C:5.5614, R:0.0099, T:0.6905(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.7159 (C:5.5702, R:0.0099, T:0.7149(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.7047 (C:5.4869, R:0.0099, T:0.7037(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.7181 (C:5.6053, R:0.0100, T:0.7171(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6937 (C:5.5515, R:0.0099, T:0.6927(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6874 (C:5.6094, R:0.0099, T:0.6864(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6827 (C:5.5603, R:0.0100, T:0.6817(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6917 (C:5.6039, R:0.0100, T:0.6907(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6707 (C:5.5572, R:0.0099, T:0.6697(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.7293 (C:5.5895, R:0.0100, T:0.7283(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6631 (C:5.5839, R:0.0100, T:0.6621(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6915 (C:5.5957, R:0.0100, T:0.6905(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6596 (C:5.6470, R:0.0100, T:0.6586(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6432 (C:5.5561, R:0.0099, T:0.6422(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6625 (C:5.6167, R:0.0099, T:0.6615(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6488 (C:5.5972, R:0.0100, T:0.6478(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6895 (C:5.5406, R:0.0099, T:0.6885(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6881 (C:5.5503, R:0.0100, T:0.6871(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6939

ğŸ“Š EPOCH 8 TRAINING SUMMARY:
  Total Loss: 0.6949
  Contrastive: 5.5801
  Reconstruction: 0.0100
  Topological: 0.6939 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 9.3897
  Contrastive: 4.0703
  Reconstruction: 0.0099
  Topological: 9.3888 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 8/300 COMPLETE (51.1s)
Train Loss: 0.6949 (C:5.5801, R:0.0100, T:0.6939)
Val Loss:   9.3897 (C:4.0703, R:0.0099, T:9.3888)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 9 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6455 (C:5.5729, R:0.0099, T:0.6445(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6656 (C:5.5592, R:0.0100, T:0.6646(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6849 (C:5.5254, R:0.0100, T:0.6839(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6807 (C:5.6361, R:0.0100, T:0.6797(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.7334 (C:5.5613, R:0.0100, T:0.7324(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.7039 (C:5.6813, R:0.0100, T:0.7029(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.7026 (C:5.5476, R:0.0099, T:0.7016(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6658 (C:5.5598, R:0.0099, T:0.6648(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6477 (C:5.6311, R:0.0100, T:0.6467(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6975 (C:5.5923, R:0.0100, T:0.6965(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6492 (C:5.5763, R:0.0099, T:0.6482(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6870 (C:5.5195, R:0.0100, T:0.6860(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.7203 (C:5.5827, R:0.0100, T:0.7193(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.7151 (C:5.6538, R:0.0100, T:0.7141(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6635 (C:5.5535, R:0.0100, T:0.6625(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6562 (C:5.5536, R:0.0100, T:0.6552(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6565 (C:5.6198, R:0.0099, T:0.6555(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6985 (C:5.6652, R:0.0099, T:0.6975(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6764 (C:5.5568, R:0.0099, T:0.6754(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6604 (C:5.5794, R:0.0099, T:0.6594(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6799 (C:5.6278, R:0.0099, T:0.6789(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6701 (C:5.4965, R:0.0099, T:0.6691(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6794

ğŸ“Š EPOCH 9 TRAINING SUMMARY:
  Total Loss: 0.6804
  Contrastive: 5.5836
  Reconstruction: 0.0100
  Topological: 0.6794 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 8.9741
  Contrastive: 4.1266
  Reconstruction: 0.0099
  Topological: 8.9731 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 9/300 COMPLETE (46.6s)
Train Loss: 0.6804 (C:5.5836, R:0.0100, T:0.6794)
Val Loss:   8.9741 (C:4.1266, R:0.0099, T:8.9731)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 10 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6712 (C:5.6174, R:0.0100, T:0.6702(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6662 (C:5.5617, R:0.0100, T:0.6652(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6486 (C:5.5507, R:0.0100, T:0.6476(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6656 (C:5.6264, R:0.0099, T:0.6646(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6550 (C:5.6323, R:0.0100, T:0.6540(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6428 (C:5.5520, R:0.0100, T:0.6418(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6505 (C:5.5791, R:0.0099, T:0.6495(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6746 (C:5.5943, R:0.0100, T:0.6736(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6272 (C:5.5125, R:0.0100, T:0.6262(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6808 (C:5.5220, R:0.0099, T:0.6798(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6885 (C:5.6144, R:0.0099, T:0.6875(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6721 (C:5.6506, R:0.0100, T:0.6711(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6934 (C:5.5945, R:0.0100, T:0.6924(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6545 (C:5.5963, R:0.0099, T:0.6535(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6528 (C:5.5793, R:0.0100, T:0.6518(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6455 (C:5.6031, R:0.0099, T:0.6445(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6567 (C:5.5597, R:0.0099, T:0.6557(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6555 (C:5.5717, R:0.0099, T:0.6546(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6694 (C:5.5609, R:0.0099, T:0.6684(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6739 (C:5.5388, R:0.0099, T:0.6729(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6422 (C:5.5340, R:0.0099, T:0.6412(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6685 (C:5.6352, R:0.0099, T:0.6675(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6665

ğŸ“Š EPOCH 10 TRAINING SUMMARY:
  Total Loss: 0.6675
  Contrastive: 5.5843
  Reconstruction: 0.0100
  Topological: 0.6665 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 8.5409
  Contrastive: 4.1608
  Reconstruction: 0.0099
  Topological: 8.5399 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 10/300 COMPLETE (46.2s)
Train Loss: 0.6675 (C:5.5843, R:0.0100, T:0.6665)
Val Loss:   8.5409 (C:4.1608, R:0.0099, T:8.5399)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 11 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6563 (C:5.6198, R:0.0099, T:0.6553(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6484 (C:5.5491, R:0.0099, T:0.6474(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6544 (C:5.5862, R:0.0100, T:0.6534(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6764 (C:5.5899, R:0.0099, T:0.6754(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6409 (C:5.5805, R:0.0099, T:0.6399(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6931 (C:5.5425, R:0.0099, T:0.6921(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6821 (C:5.5218, R:0.0100, T:0.6811(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6644 (C:5.5693, R:0.0100, T:0.6634(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6721 (C:5.5675, R:0.0099, T:0.6711(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6656 (C:5.5979, R:0.0099, T:0.6646(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6550 (C:5.6517, R:0.0100, T:0.6540(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6545 (C:5.6145, R:0.0100, T:0.6535(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6416 (C:5.5427, R:0.0100, T:0.6406(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6713 (C:5.6147, R:0.0100, T:0.6703(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6150 (C:5.5798, R:0.0100, T:0.6140(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6284 (C:5.6380, R:0.0099, T:0.6274(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6221 (C:5.5535, R:0.0099, T:0.6212(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6579 (C:5.5680, R:0.0100, T:0.6569(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6589 (C:5.6296, R:0.0100, T:0.6579(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6624 (C:5.5289, R:0.0100, T:0.6614(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6471 (C:5.5798, R:0.0099, T:0.6461(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6787 (C:5.6106, R:0.0099, T:0.6778(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6545

ğŸ“Š EPOCH 11 TRAINING SUMMARY:
  Total Loss: 0.6555
  Contrastive: 5.5832
  Reconstruction: 0.0100
  Topological: 0.6545 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 8.4926
  Contrastive: 4.1568
  Reconstruction: 0.0099
  Topological: 8.4916 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 11/300 COMPLETE (46.0s)
Train Loss: 0.6555 (C:5.5832, R:0.0100, T:0.6545)
Val Loss:   8.4926 (C:4.1568, R:0.0099, T:8.4916)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 12 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6557 (C:5.5444, R:0.0099, T:0.6547(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6438 (C:5.5837, R:0.0099, T:0.6428(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6538 (C:5.5735, R:0.0100, T:0.6528(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6332 (C:5.5760, R:0.0100, T:0.6322(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6335 (C:5.5607, R:0.0100, T:0.6325(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6306 (C:5.6278, R:0.0100, T:0.6296(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6640 (C:5.5312, R:0.0099, T:0.6630(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6059 (C:5.6241, R:0.0100, T:0.6049(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6889 (C:5.6027, R:0.0100, T:0.6879(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6560 (C:5.5524, R:0.0100, T:0.6550(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6398 (C:5.5598, R:0.0100, T:0.6388(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6646 (C:5.7001, R:0.0100, T:0.6635(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6584 (C:5.5904, R:0.0099, T:0.6574(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6268 (C:5.6065, R:0.0099, T:0.6258(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6715 (C:5.6988, R:0.0099, T:0.6705(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6131 (C:5.6162, R:0.0099, T:0.6121(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6228 (C:5.5597, R:0.0099, T:0.6218(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6373 (C:5.6144, R:0.0100, T:0.6363(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6170 (C:5.5286, R:0.0099, T:0.6161(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6565 (C:5.6051, R:0.0099, T:0.6555(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6258 (C:5.5706, R:0.0100, T:0.6248(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6481 (C:5.6408, R:0.0099, T:0.6471(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6465

ğŸ“Š EPOCH 12 TRAINING SUMMARY:
  Total Loss: 0.6475
  Contrastive: 5.5848
  Reconstruction: 0.0100
  Topological: 0.6465 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 8.3167
  Contrastive: 4.1511
  Reconstruction: 0.0099
  Topological: 8.3158 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 12/300 COMPLETE (45.6s)
Train Loss: 0.6475 (C:5.5848, R:0.0100, T:0.6465)
Val Loss:   8.3167 (C:4.1511, R:0.0099, T:8.3158)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 13 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6553 (C:5.4959, R:0.0099, T:0.6543(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6368 (C:5.5938, R:0.0100, T:0.6358(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6290 (C:5.5813, R:0.0099, T:0.6280(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6187 (C:5.5800, R:0.0099, T:0.6177(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6438 (C:5.5781, R:0.0100, T:0.6428(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6367 (C:5.5429, R:0.0100, T:0.6357(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6311 (C:5.6065, R:0.0099, T:0.6301(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6607 (C:5.5838, R:0.0100, T:0.6597(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6408 (C:5.5371, R:0.0099, T:0.6398(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6587 (C:5.5548, R:0.0100, T:0.6577(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6476 (C:5.5883, R:0.0100, T:0.6466(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6201 (C:5.5755, R:0.0100, T:0.6191(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6580 (C:5.6644, R:0.0099, T:0.6570(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6377 (C:5.5835, R:0.0100, T:0.6367(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6278 (C:5.5653, R:0.0099, T:0.6268(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6276 (C:5.5624, R:0.0100, T:0.6266(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6141 (C:5.5566, R:0.0099, T:0.6131(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6526 (C:5.5717, R:0.0099, T:0.6516(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6420 (C:5.6039, R:0.0099, T:0.6410(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6022 (C:5.6016, R:0.0100, T:0.6012(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6514 (C:5.6337, R:0.0100, T:0.6504(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6105 (C:5.6157, R:0.0099, T:0.6095(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6381

ğŸ“Š EPOCH 13 TRAINING SUMMARY:
  Total Loss: 0.6391
  Contrastive: 5.5831
  Reconstruction: 0.0100
  Topological: 0.6381 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 7.7107
  Contrastive: 4.2858
  Reconstruction: 0.0099
  Topological: 7.7097 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 13/300 COMPLETE (45.4s)
Train Loss: 0.6391 (C:5.5831, R:0.0100, T:0.6381)
Val Loss:   7.7107 (C:4.2858, R:0.0099, T:7.7097)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 14 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6066 (C:5.6116, R:0.0099, T:0.6056(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6270 (C:5.5909, R:0.0100, T:0.6260(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6695 (C:5.5062, R:0.0099, T:0.6685(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6329 (C:5.5496, R:0.0099, T:0.6319(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6058 (C:5.6073, R:0.0100, T:0.6048(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6233 (C:5.5979, R:0.0100, T:0.6223(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6451 (C:5.6342, R:0.0099, T:0.6441(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.7222 (C:5.6777, R:0.0100, T:0.7212(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6419 (C:5.5638, R:0.0099, T:0.6409(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6414 (C:5.5859, R:0.0100, T:0.6404(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6092 (C:5.5705, R:0.0099, T:0.6082(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6493 (C:5.5688, R:0.0100, T:0.6483(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6398 (C:5.5692, R:0.0100, T:0.6388(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6083 (C:5.5248, R:0.0099, T:0.6073(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6157 (C:5.5802, R:0.0099, T:0.6147(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6127 (C:5.5482, R:0.0100, T:0.6118(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5860 (C:5.6252, R:0.0099, T:0.5850(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6313 (C:5.4958, R:0.0099, T:0.6303(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6418 (C:5.6085, R:0.0099, T:0.6408(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6489 (C:5.6659, R:0.0100, T:0.6479(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6116 (C:5.6342, R:0.0099, T:0.6106(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6219 (C:5.6178, R:0.0100, T:0.6209(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6295

ğŸ“Š EPOCH 14 TRAINING SUMMARY:
  Total Loss: 0.6305
  Contrastive: 5.5843
  Reconstruction: 0.0100
  Topological: 0.6295 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 7.2702
  Contrastive: 4.3437
  Reconstruction: 0.0099
  Topological: 7.2692 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 14/300 COMPLETE (45.7s)
Train Loss: 0.6305 (C:5.5843, R:0.0100, T:0.6295)
Val Loss:   7.2702 (C:4.3437, R:0.0099, T:7.2692)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 15 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6140 (C:5.6044, R:0.0099, T:0.6130(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6083 (C:5.5503, R:0.0100, T:0.6073(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6138 (C:5.6087, R:0.0100, T:0.6128(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6288 (C:5.5750, R:0.0100, T:0.6278(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6389 (C:5.6043, R:0.0099, T:0.6379(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6211 (C:5.6880, R:0.0100, T:0.6201(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6256 (C:5.6533, R:0.0100, T:0.6246(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6392 (C:5.5755, R:0.0100, T:0.6382(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6461 (C:5.6048, R:0.0100, T:0.6451(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6138 (C:5.5581, R:0.0100, T:0.6128(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6121 (C:5.6031, R:0.0100, T:0.6111(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6500 (C:5.4888, R:0.0100, T:0.6490(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6337 (C:5.5616, R:0.0099, T:0.6328(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6337 (C:5.5437, R:0.0100, T:0.6327(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6193 (C:5.6147, R:0.0099, T:0.6183(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6093 (C:5.6313, R:0.0099, T:0.6083(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6267 (C:5.5760, R:0.0099, T:0.6257(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6258 (C:5.6437, R:0.0100, T:0.6248(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6027 (C:5.6422, R:0.0100, T:0.6017(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6180 (C:5.6020, R:0.0100, T:0.6170(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5957 (C:5.5459, R:0.0099, T:0.5947(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6544 (C:5.5245, R:0.0100, T:0.6534(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6230

ğŸ“Š EPOCH 15 TRAINING SUMMARY:
  Total Loss: 0.6240
  Contrastive: 5.5829
  Reconstruction: 0.0100
  Topological: 0.6230 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 7.0776
  Contrastive: 4.3301
  Reconstruction: 0.0099
  Topological: 7.0766 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 15/300 COMPLETE (47.0s)
Train Loss: 0.6240 (C:5.5829, R:0.0100, T:0.6230)
Val Loss:   7.0776 (C:4.3301, R:0.0099, T:7.0766)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 16 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6657 (C:5.5393, R:0.0100, T:0.6647(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6292 (C:5.4960, R:0.0099, T:0.6283(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6193 (C:5.5446, R:0.0099, T:0.6183(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6431 (C:5.5812, R:0.0100, T:0.6421(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6171 (C:5.5753, R:0.0099, T:0.6161(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6368 (C:5.5343, R:0.0100, T:0.6358(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6504 (C:5.6347, R:0.0100, T:0.6494(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6355 (C:5.5896, R:0.0100, T:0.6345(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5885 (C:5.5857, R:0.0100, T:0.5875(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6529 (C:5.6631, R:0.0100, T:0.6519(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6230 (C:5.6243, R:0.0099, T:0.6220(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6442 (C:5.5652, R:0.0100, T:0.6432(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6229 (C:5.5908, R:0.0099, T:0.6220(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6086 (C:5.5625, R:0.0100, T:0.6076(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6106 (C:5.6170, R:0.0100, T:0.6096(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6189 (C:5.6589, R:0.0100, T:0.6179(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5882 (C:5.5957, R:0.0100, T:0.5872(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6338 (C:5.5768, R:0.0099, T:0.6328(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6073 (C:5.6194, R:0.0099, T:0.6063(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5742 (C:5.5868, R:0.0100, T:0.5732(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6170 (C:5.5713, R:0.0100, T:0.6160(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6645 (C:5.5405, R:0.0100, T:0.6635(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6131

ğŸ“Š EPOCH 16 TRAINING SUMMARY:
  Total Loss: 0.6141
  Contrastive: 5.5814
  Reconstruction: 0.0100
  Topological: 0.6131 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.7276
  Contrastive: 4.4200
  Reconstruction: 0.0099
  Topological: 6.7266 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 16/300 COMPLETE (46.5s)
Train Loss: 0.6141 (C:5.5814, R:0.0100, T:0.6131)
Val Loss:   6.7276 (C:4.4200, R:0.0099, T:6.7266)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 17 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6285 (C:5.5736, R:0.0100, T:0.6275(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5983 (C:5.5323, R:0.0100, T:0.5973(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6131 (C:5.5736, R:0.0099, T:0.6121(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6122 (C:5.6175, R:0.0099, T:0.6112(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6401 (C:5.5873, R:0.0100, T:0.6391(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6206 (C:5.5972, R:0.0100, T:0.6196(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6018 (C:5.5217, R:0.0100, T:0.6008(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6004 (C:5.5606, R:0.0100, T:0.5995(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6138 (C:5.5131, R:0.0100, T:0.6129(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6138 (C:5.5603, R:0.0099, T:0.6128(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6243 (C:5.5525, R:0.0100, T:0.6233(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6161 (C:5.5530, R:0.0099, T:0.6151(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5873 (C:5.6092, R:0.0100, T:0.5863(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6114 (C:5.5508, R:0.0100, T:0.6104(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6409 (C:5.6159, R:0.0100, T:0.6399(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6049 (C:5.5716, R:0.0100, T:0.6039(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5718 (C:5.5541, R:0.0099, T:0.5709(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5951 (C:5.5936, R:0.0100, T:0.5941(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6091 (C:5.5307, R:0.0099, T:0.6081(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6267 (C:5.5928, R:0.0099, T:0.6257(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6244 (C:5.5494, R:0.0099, T:0.6234(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6291 (C:5.5990, R:0.0100, T:0.6281(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6071

ğŸ“Š EPOCH 17 TRAINING SUMMARY:
  Total Loss: 0.6081
  Contrastive: 5.5830
  Reconstruction: 0.0100
  Topological: 0.6071 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.3694
  Contrastive: 4.4949
  Reconstruction: 0.0099
  Topological: 6.3684 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 17/300 COMPLETE (46.5s)
Train Loss: 0.6081 (C:5.5830, R:0.0100, T:0.6071)
Val Loss:   6.3694 (C:4.4949, R:0.0099, T:6.3684)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 18 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6104 (C:5.5414, R:0.0099, T:0.6094(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5925 (C:5.6278, R:0.0100, T:0.5915(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6049 (C:5.5537, R:0.0099, T:0.6039(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5915 (C:5.5937, R:0.0100, T:0.5905(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5981 (C:5.5478, R:0.0100, T:0.5971(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6204 (C:5.5770, R:0.0100, T:0.6194(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5919 (C:5.5402, R:0.0100, T:0.5909(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6186 (C:5.6278, R:0.0100, T:0.6176(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5992 (C:5.5643, R:0.0100, T:0.5982(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6001 (C:5.5743, R:0.0100, T:0.5991(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5879 (C:5.6046, R:0.0099, T:0.5869(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5707 (C:5.5499, R:0.0100, T:0.5697(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5712 (C:5.5741, R:0.0099, T:0.5702(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5999 (C:5.5253, R:0.0100, T:0.5989(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5796 (C:5.5844, R:0.0100, T:0.5786(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5796 (C:5.5448, R:0.0100, T:0.5786(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6012 (C:5.6012, R:0.0100, T:0.6003(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5704 (C:5.5995, R:0.0100, T:0.5694(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6019 (C:5.5538, R:0.0099, T:0.6009(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6107 (C:5.6098, R:0.0099, T:0.6097(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6082 (C:5.6156, R:0.0100, T:0.6072(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6083 (C:5.5702, R:0.0100, T:0.6073(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5962

ğŸ“Š EPOCH 18 TRAINING SUMMARY:
  Total Loss: 0.5972
  Contrastive: 5.5820
  Reconstruction: 0.0100
  Topological: 0.5962 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.8474
  Contrastive: 4.5814
  Reconstruction: 0.0099
  Topological: 5.8464 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 18/300 COMPLETE (46.3s)
Train Loss: 0.5972 (C:5.5820, R:0.0100, T:0.5962)
Val Loss:   5.8474 (C:4.5814, R:0.0099, T:5.8464)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 19 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6222 (C:5.5510, R:0.0100, T:0.6212(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5786 (C:5.5669, R:0.0100, T:0.5776(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5718 (C:5.5749, R:0.0099, T:0.5708(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5629 (C:5.5465, R:0.0100, T:0.5619(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5989 (C:5.5637, R:0.0100, T:0.5979(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5563 (C:5.5819, R:0.0099, T:0.5553(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5901 (C:5.5669, R:0.0099, T:0.5891(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6002 (C:5.5979, R:0.0099, T:0.5993(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6007 (C:5.5637, R:0.0099, T:0.5997(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6005 (C:5.6146, R:0.0100, T:0.5995(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6092 (C:5.5766, R:0.0100, T:0.6082(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5966 (C:5.5341, R:0.0099, T:0.5956(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5924 (C:5.5913, R:0.0099, T:0.5914(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5958 (C:5.5992, R:0.0100, T:0.5948(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6023 (C:5.5608, R:0.0100, T:0.6013(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6034 (C:5.5947, R:0.0100, T:0.6024(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5906 (C:5.6026, R:0.0100, T:0.5896(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5984 (C:5.5183, R:0.0100, T:0.5974(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5821 (C:5.6078, R:0.0099, T:0.5811(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5723 (C:5.6249, R:0.0099, T:0.5713(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6262 (C:5.5755, R:0.0100, T:0.6252(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6297 (C:5.5455, R:0.0099, T:0.6287(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5902

ğŸ“Š EPOCH 19 TRAINING SUMMARY:
  Total Loss: 0.5912
  Contrastive: 5.5809
  Reconstruction: 0.0100
  Topological: 0.5902 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.6051
  Contrastive: 4.6242
  Reconstruction: 0.0099
  Topological: 5.6041 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 19/300 COMPLETE (45.9s)
Train Loss: 0.5912 (C:5.5809, R:0.0100, T:0.5902)
Val Loss:   5.6051 (C:4.6242, R:0.0099, T:5.6041)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 20 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5830 (C:5.4921, R:0.0100, T:0.5820(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6073 (C:5.5279, R:0.0100, T:0.6063(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5758 (C:5.5715, R:0.0099, T:0.5748(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5822 (C:5.5814, R:0.0100, T:0.5812(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5516 (C:5.6186, R:0.0100, T:0.5506(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5490 (C:5.5474, R:0.0100, T:0.5480(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5907 (C:5.5982, R:0.0100, T:0.5897(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5944 (C:5.6260, R:0.0100, T:0.5934(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5926 (C:5.5630, R:0.0100, T:0.5916(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5779 (C:5.5255, R:0.0099, T:0.5769(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6339 (C:5.6037, R:0.0099, T:0.6329(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5436 (C:5.6091, R:0.0100, T:0.5426(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6073 (C:5.6011, R:0.0099, T:0.6063(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5534 (C:5.5481, R:0.0099, T:0.5524(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5625 (C:5.5593, R:0.0100, T:0.5615(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5668 (C:5.5769, R:0.0099, T:0.5658(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5881 (C:5.5866, R:0.0099, T:0.5872(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5971 (C:5.5729, R:0.0100, T:0.5961(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5605 (C:5.5575, R:0.0099, T:0.5596(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5573 (C:5.5583, R:0.0099, T:0.5563(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5281 (C:5.5483, R:0.0099, T:0.5271(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5386 (C:5.5547, R:0.0099, T:0.5376(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5760

ğŸ“Š EPOCH 20 TRAINING SUMMARY:
  Total Loss: 0.5770
  Contrastive: 5.5785
  Reconstruction: 0.0100
  Topological: 0.5760 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.2764
  Contrastive: 4.9930
  Reconstruction: 0.0099
  Topological: 4.2754 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 20/300 COMPLETE (45.8s)
Train Loss: 0.5770 (C:5.5785, R:0.0100, T:0.5760)
Val Loss:   4.2764 (C:4.9930, R:0.0099, T:4.2754)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 21 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5541 (C:5.5929, R:0.0099, T:0.5531(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5776 (C:5.5795, R:0.0099, T:0.5766(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5712 (C:5.6416, R:0.0100, T:0.5702(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5742 (C:5.5795, R:0.0100, T:0.5732(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5569 (C:5.5803, R:0.0099, T:0.5559(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5387 (C:5.5396, R:0.0099, T:0.5377(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5559 (C:5.5591, R:0.0099, T:0.5549(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5297 (C:5.5794, R:0.0099, T:0.5287(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5575 (C:5.6159, R:0.0100, T:0.5565(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5926 (C:5.5491, R:0.0100, T:0.5916(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5627 (C:5.5564, R:0.0099, T:0.5617(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5733 (C:5.6008, R:0.0100, T:0.5723(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5457 (C:5.5894, R:0.0099, T:0.5447(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5477 (C:5.5730, R:0.0099, T:0.5467(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5701 (C:5.6076, R:0.0100, T:0.5691(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5569 (C:5.5517, R:0.0099, T:0.5559(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5412 (C:5.6025, R:0.0100, T:0.5402(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5770 (C:5.5856, R:0.0100, T:0.5760(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5333 (C:5.5687, R:0.0099, T:0.5323(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5666 (C:5.6107, R:0.0099, T:0.5656(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5548 (C:5.5712, R:0.0099, T:0.5538(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5561 (C:5.5343, R:0.0099, T:0.5551(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5569

ğŸ“Š EPOCH 21 TRAINING SUMMARY:
  Total Loss: 0.5579
  Contrastive: 5.5775
  Reconstruction: 0.0100
  Topological: 0.5569 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 3.3053
  Contrastive: 5.2561
  Reconstruction: 0.0099
  Topological: 3.3043 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 21/300 COMPLETE (46.4s)
Train Loss: 0.5579 (C:5.5775, R:0.0100, T:0.5569)
Val Loss:   3.3053 (C:5.2561, R:0.0099, T:3.3043)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 22 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5542 (C:5.5828, R:0.0100, T:0.5532(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5315 (C:5.5780, R:0.0099, T:0.5305(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5325 (C:5.5716, R:0.0100, T:0.5315(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5590 (C:5.5898, R:0.0100, T:0.5580(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5517 (C:5.5643, R:0.0100, T:0.5507(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5299 (C:5.5175, R:0.0100, T:0.5289(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5460 (C:5.5667, R:0.0099, T:0.5450(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5390 (C:5.5697, R:0.0099, T:0.5381(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5231 (C:5.5668, R:0.0099, T:0.5221(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5314 (C:5.5641, R:0.0099, T:0.5304(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5207 (C:5.6035, R:0.0100, T:0.5197(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5431 (C:5.5661, R:0.0100, T:0.5421(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5315 (C:5.5396, R:0.0100, T:0.5305(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5317 (C:5.5970, R:0.0100, T:0.5307(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5321 (C:5.5626, R:0.0099, T:0.5311(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5280 (C:5.5714, R:0.0099, T:0.5270(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5451 (C:5.5497, R:0.0099, T:0.5441(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5523 (C:5.5452, R:0.0100, T:0.5513(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5245 (C:5.5599, R:0.0100, T:0.5235(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5326 (C:5.5382, R:0.0100, T:0.5316(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5377 (C:5.6033, R:0.0099, T:0.5367(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5298 (C:5.5397, R:0.0099, T:0.5288(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5409

ğŸ“Š EPOCH 22 TRAINING SUMMARY:
  Total Loss: 0.5419
  Contrastive: 5.5654
  Reconstruction: 0.0100
  Topological: 0.5409 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 3.0116
  Contrastive: 5.3757
  Reconstruction: 0.0099
  Topological: 3.0106 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 22/300 COMPLETE (46.0s)
Train Loss: 0.5419 (C:5.5654, R:0.0100, T:0.5409)
Val Loss:   3.0116 (C:5.3757, R:0.0099, T:3.0106)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 23 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5412 (C:5.5718, R:0.0099, T:0.5402(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5324 (C:5.5350, R:0.0099, T:0.5314(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5474 (C:5.5881, R:0.0100, T:0.5464(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5693 (C:5.5716, R:0.0100, T:0.5684(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5309 (C:5.5696, R:0.0099, T:0.5299(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5887 (C:5.5578, R:0.0100, T:0.5877(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5218 (C:5.5645, R:0.0100, T:0.5208(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5239 (C:5.5532, R:0.0099, T:0.5229(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5236 (C:5.5722, R:0.0100, T:0.5226(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5302 (C:5.5651, R:0.0100, T:0.5292(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4891 (C:5.5502, R:0.0099, T:0.4881(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5528 (C:5.5717, R:0.0100, T:0.5518(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5346 (C:5.5442, R:0.0100, T:0.5336(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5047 (C:5.5898, R:0.0100, T:0.5037(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5353 (C:5.5729, R:0.0099, T:0.5343(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5201 (C:5.5557, R:0.0100, T:0.5191(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5438 (C:5.5647, R:0.0099, T:0.5428(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5446 (C:5.5567, R:0.0100, T:0.5436(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5329 (C:5.5815, R:0.0100, T:0.5319(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5323 (C:5.5567, R:0.0100, T:0.5313(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5251 (C:5.5645, R:0.0100, T:0.5241(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5241 (C:5.5317, R:0.0100, T:0.5231(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5329

ğŸ“Š EPOCH 23 TRAINING SUMMARY:
  Total Loss: 0.5339
  Contrastive: 5.5637
  Reconstruction: 0.0100
  Topological: 0.5329 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 3.0008
  Contrastive: 5.3696
  Reconstruction: 0.0099
  Topological: 2.9998 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 23/300 COMPLETE (46.5s)
Train Loss: 0.5339 (C:5.5637, R:0.0100, T:0.5329)
Val Loss:   3.0008 (C:5.3696, R:0.0099, T:2.9998)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 24 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5495 (C:5.5568, R:0.0100, T:0.5485(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5380 (C:5.5807, R:0.0099, T:0.5370(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5161 (C:5.5805, R:0.0100, T:0.5151(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5236 (C:5.5641, R:0.0100, T:0.5226(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5194 (C:5.5982, R:0.0100, T:0.5184(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4892 (C:5.5528, R:0.0099, T:0.4882(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5297 (C:5.5829, R:0.0100, T:0.5287(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5399 (C:5.5657, R:0.0100, T:0.5389(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5492 (C:5.5586, R:0.0100, T:0.5482(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5418 (C:5.5564, R:0.0100, T:0.5408(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5313 (C:5.5927, R:0.0099, T:0.5303(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5316 (C:5.5394, R:0.0099, T:0.5306(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5132 (C:5.5674, R:0.0100, T:0.5122(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5248 (C:5.5721, R:0.0100, T:0.5238(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5470 (C:5.5553, R:0.0100, T:0.5460(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5440 (C:5.5821, R:0.0100, T:0.5430(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5212 (C:5.5771, R:0.0100, T:0.5202(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5290 (C:5.5701, R:0.0100, T:0.5280(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5154 (C:5.5693, R:0.0099, T:0.5144(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5376 (C:5.5529, R:0.0099, T:0.5366(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4965 (C:5.5521, R:0.0100, T:0.4955(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5115 (C:5.5846, R:0.0099, T:0.5105(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5254

ğŸ“Š EPOCH 24 TRAINING SUMMARY:
  Total Loss: 0.5264
  Contrastive: 5.5655
  Reconstruction: 0.0100
  Topological: 0.5254 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.8508
  Contrastive: 5.3695
  Reconstruction: 0.0099
  Topological: 2.8498 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 24/300 COMPLETE (46.3s)
Train Loss: 0.5264 (C:5.5655, R:0.0100, T:0.5254)
Val Loss:   2.8508 (C:5.3695, R:0.0099, T:2.8498)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 25 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4931 (C:5.5398, R:0.0100, T:0.4921(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5320 (C:5.5793, R:0.0099, T:0.5310(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5295 (C:5.5376, R:0.0100, T:0.5285(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5261 (C:5.5221, R:0.0100, T:0.5251(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5359 (C:5.5883, R:0.0099, T:0.5349(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5571 (C:5.5359, R:0.0100, T:0.5561(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5504 (C:5.5705, R:0.0100, T:0.5494(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5264 (C:5.5603, R:0.0100, T:0.5254(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5077 (C:5.5439, R:0.0099, T:0.5067(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5077 (C:5.5766, R:0.0100, T:0.5067(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5134 (C:5.5484, R:0.0100, T:0.5124(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5017 (C:5.5576, R:0.0099, T:0.5007(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4917 (C:5.5602, R:0.0100, T:0.4907(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5103 (C:5.5946, R:0.0099, T:0.5093(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5203 (C:5.5812, R:0.0100, T:0.5193(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5083 (C:5.5953, R:0.0100, T:0.5074(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5162 (C:5.5574, R:0.0100, T:0.5152(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5265 (C:5.5825, R:0.0100, T:0.5255(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5056 (C:5.5498, R:0.0099, T:0.5046(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5454 (C:5.5383, R:0.0099, T:0.5444(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5507 (C:5.5497, R:0.0099, T:0.5497(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5178 (C:5.5579, R:0.0099, T:0.5168(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5208

ğŸ“Š EPOCH 25 TRAINING SUMMARY:
  Total Loss: 0.5218
  Contrastive: 5.5676
  Reconstruction: 0.0100
  Topological: 0.5208 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.6810
  Contrastive: 5.4274
  Reconstruction: 0.0099
  Topological: 2.6800 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 25/300 COMPLETE (46.9s)
Train Loss: 0.5218 (C:5.5676, R:0.0100, T:0.5208)
Val Loss:   2.6810 (C:5.4274, R:0.0099, T:2.6800)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 26 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5218 (C:5.5611, R:0.0099, T:0.5208(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5264 (C:5.6107, R:0.0100, T:0.5254(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5079 (C:5.6010, R:0.0100, T:0.5069(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4948 (C:5.5680, R:0.0100, T:0.4938(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5104 (C:5.5945, R:0.0100, T:0.5094(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4998 (C:5.5459, R:0.0099, T:0.4988(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5158 (C:5.5201, R:0.0100, T:0.5148(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5080 (C:5.5614, R:0.0100, T:0.5070(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5157 (C:5.5365, R:0.0100, T:0.5147(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5250 (C:5.5697, R:0.0100, T:0.5240(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4972 (C:5.6074, R:0.0100, T:0.4962(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5440 (C:5.5745, R:0.0100, T:0.5430(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5010 (C:5.5522, R:0.0100, T:0.5000(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5197 (C:5.5668, R:0.0100, T:0.5187(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5278 (C:5.5590, R:0.0100, T:0.5268(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5358 (C:5.5727, R:0.0099, T:0.5348(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5054 (C:5.5544, R:0.0100, T:0.5044(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5364 (C:5.5669, R:0.0100, T:0.5354(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5284 (C:5.6023, R:0.0100, T:0.5274(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5234 (C:5.5718, R:0.0099, T:0.5224(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5289 (C:5.5709, R:0.0099, T:0.5279(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4941 (C:5.5607, R:0.0100, T:0.4931(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5149

ğŸ“Š EPOCH 26 TRAINING SUMMARY:
  Total Loss: 0.5159
  Contrastive: 5.5676
  Reconstruction: 0.0100
  Topological: 0.5149 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.6195
  Contrastive: 5.4327
  Reconstruction: 0.0099
  Topological: 2.6185 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 26/300 COMPLETE (46.6s)
Train Loss: 0.5159 (C:5.5676, R:0.0100, T:0.5149)
Val Loss:   2.6195 (C:5.4327, R:0.0099, T:2.6185)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 27 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5188 (C:5.5728, R:0.0099, T:0.5178(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5301 (C:5.6092, R:0.0099, T:0.5291(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5359 (C:5.5623, R:0.0100, T:0.5349(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5338 (C:5.5342, R:0.0100, T:0.5328(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5313 (C:5.5949, R:0.0099, T:0.5303(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4898 (C:5.5931, R:0.0100, T:0.4888(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5348 (C:5.5444, R:0.0099, T:0.5338(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5064 (C:5.5915, R:0.0099, T:0.5054(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5150 (C:5.5819, R:0.0099, T:0.5140(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5429 (C:5.5559, R:0.0099, T:0.5419(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5442 (C:5.5808, R:0.0099, T:0.5432(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5165 (C:5.5819, R:0.0099, T:0.5155(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5607 (C:5.5881, R:0.0100, T:0.5597(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4930 (C:5.5810, R:0.0099, T:0.4920(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5226 (C:5.5629, R:0.0099, T:0.5216(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5112 (C:5.5695, R:0.0100, T:0.5102(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5002 (C:5.5569, R:0.0099, T:0.4992(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5160 (C:5.6008, R:0.0100, T:0.5150(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4919 (C:5.5639, R:0.0099, T:0.4909(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5064 (C:5.5747, R:0.0099, T:0.5054(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5038 (C:5.5810, R:0.0100, T:0.5028(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5102 (C:5.5034, R:0.0100, T:0.5092(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5117

ğŸ“Š EPOCH 27 TRAINING SUMMARY:
  Total Loss: 0.5127
  Contrastive: 5.5696
  Reconstruction: 0.0100
  Topological: 0.5117 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.6093
  Contrastive: 5.4050
  Reconstruction: 0.0099
  Topological: 2.6084 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 27/300 COMPLETE (46.4s)
Train Loss: 0.5127 (C:5.5696, R:0.0100, T:0.5117)
Val Loss:   2.6093 (C:5.4050, R:0.0099, T:2.6084)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 28 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5176 (C:5.5568, R:0.0100, T:0.5166(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4784 (C:5.5658, R:0.0099, T:0.4774(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5099 (C:5.5444, R:0.0100, T:0.5089(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5516 (C:5.6190, R:0.0100, T:0.5506(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5033 (C:5.5535, R:0.0099, T:0.5023(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4972 (C:5.5841, R:0.0099, T:0.4962(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5218 (C:5.5765, R:0.0099, T:0.5208(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5130 (C:5.5793, R:0.0100, T:0.5120(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5033 (C:5.5804, R:0.0099, T:0.5023(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4959 (C:5.6175, R:0.0100, T:0.4949(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4987 (C:5.5678, R:0.0099, T:0.4977(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5068 (C:5.5731, R:0.0100, T:0.5058(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4965 (C:5.5692, R:0.0099, T:0.4955(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5350 (C:5.5868, R:0.0099, T:0.5340(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5162 (C:5.5552, R:0.0099, T:0.5152(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4980 (C:5.5661, R:0.0100, T:0.4970(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4892 (C:5.5840, R:0.0100, T:0.4882(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5186 (C:5.5784, R:0.0099, T:0.5176(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5043 (C:5.5900, R:0.0099, T:0.5033(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5000 (C:5.5951, R:0.0100, T:0.4990(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5420 (C:5.5855, R:0.0100, T:0.5410(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5158 (C:5.5779, R:0.0100, T:0.5148(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5053

ğŸ“Š EPOCH 28 TRAINING SUMMARY:
  Total Loss: 0.5063
  Contrastive: 5.5743
  Reconstruction: 0.0100
  Topological: 0.5053 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.3620
  Contrastive: 5.5259
  Reconstruction: 0.0099
  Topological: 2.3610 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 28/300 COMPLETE (49.0s)
Train Loss: 0.5063 (C:5.5743, R:0.0100, T:0.5053)
Val Loss:   2.3620 (C:5.5259, R:0.0099, T:2.3610)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 29 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4978 (C:5.6073, R:0.0100, T:0.4968(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5048 (C:5.5559, R:0.0100, T:0.5038(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4965 (C:5.5930, R:0.0099, T:0.4955(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5096 (C:5.5716, R:0.0099, T:0.5086(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5057 (C:5.5500, R:0.0100, T:0.5047(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5200 (C:5.5624, R:0.0100, T:0.5190(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4993 (C:5.5774, R:0.0100, T:0.4983(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4933 (C:5.5590, R:0.0099, T:0.4923(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4898 (C:5.5511, R:0.0099, T:0.4888(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5034 (C:5.5606, R:0.0099, T:0.5024(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4989 (C:5.5757, R:0.0099, T:0.4979(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5100 (C:5.5779, R:0.0100, T:0.5090(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4897 (C:5.6035, R:0.0099, T:0.4887(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5208 (C:5.6109, R:0.0100, T:0.5198(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5122 (C:5.6145, R:0.0100, T:0.5112(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4911 (C:5.5744, R:0.0099, T:0.4901(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4925 (C:5.5591, R:0.0099, T:0.4915(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4922 (C:5.5832, R:0.0100, T:0.4912(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4790 (C:5.5832, R:0.0099, T:0.4780(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4969 (C:5.5641, R:0.0099, T:0.4959(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4630 (C:5.5818, R:0.0100, T:0.4620(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5021 (C:5.5697, R:0.0099, T:0.5011(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5012

ğŸ“Š EPOCH 29 TRAINING SUMMARY:
  Total Loss: 0.5022
  Contrastive: 5.5759
  Reconstruction: 0.0100
  Topological: 0.5012 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.5273
  Contrastive: 5.4491
  Reconstruction: 0.0099
  Topological: 2.5263 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 29/300 COMPLETE (51.1s)
Train Loss: 0.5022 (C:5.5759, R:0.0100, T:0.5012)
Val Loss:   2.5273 (C:5.4491, R:0.0099, T:2.5263)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 30 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5250 (C:5.5598, R:0.0100, T:0.5240(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4778 (C:5.5663, R:0.0100, T:0.4768(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5037 (C:5.5619, R:0.0100, T:0.5027(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5009 (C:5.5527, R:0.0100, T:0.4999(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5142 (C:5.6197, R:0.0100, T:0.5132(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5034 (C:5.5282, R:0.0099, T:0.5024(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4554 (C:5.5663, R:0.0099, T:0.4544(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4809 (C:5.5738, R:0.0100, T:0.4799(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4928 (C:5.5947, R:0.0100, T:0.4918(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5039 (C:5.5241, R:0.0099, T:0.5029(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5084 (C:5.5947, R:0.0100, T:0.5074(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5272 (C:5.6095, R:0.0100, T:0.5262(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5005 (C:5.5685, R:0.0100, T:0.4995(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4942 (C:5.5911, R:0.0100, T:0.4932(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4857 (C:5.5796, R:0.0100, T:0.4847(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4912 (C:5.5920, R:0.0100, T:0.4902(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5110 (C:5.5682, R:0.0100, T:0.5100(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4982 (C:5.5484, R:0.0099, T:0.4972(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5084 (C:5.5578, R:0.0100, T:0.5074(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4877 (C:5.5744, R:0.0099, T:0.4867(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4951 (C:5.5743, R:0.0099, T:0.4941(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4913 (C:5.5502, R:0.0099, T:0.4903(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4963

ğŸ“Š EPOCH 30 TRAINING SUMMARY:
  Total Loss: 0.4973
  Contrastive: 5.5768
  Reconstruction: 0.0100
  Topological: 0.4963 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.4300
  Contrastive: 5.4540
  Reconstruction: 0.0099
  Topological: 2.4290 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 30/300 COMPLETE (52.5s)
Train Loss: 0.4973 (C:5.5768, R:0.0100, T:0.4963)
Val Loss:   2.4300 (C:5.4540, R:0.0099, T:2.4290)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 31 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5013 (C:5.5570, R:0.0099, T:0.5003(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4977 (C:5.5323, R:0.0099, T:0.4967(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4910 (C:5.5249, R:0.0099, T:0.4900(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4931 (C:5.5701, R:0.0099, T:0.4921(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4846 (C:5.5868, R:0.0100, T:0.4836(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5086 (C:5.5474, R:0.0100, T:0.5076(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4776 (C:5.5352, R:0.0099, T:0.4766(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4965 (C:5.5685, R:0.0100, T:0.4955(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5123 (C:5.5710, R:0.0099, T:0.5113(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5016 (C:5.5598, R:0.0100, T:0.5006(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5094 (C:5.5747, R:0.0100, T:0.5084(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5105 (C:5.5852, R:0.0099, T:0.5095(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4785 (C:5.5808, R:0.0099, T:0.4775(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4800 (C:5.5640, R:0.0099, T:0.4790(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4885 (C:5.6160, R:0.0099, T:0.4875(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5066 (C:5.6137, R:0.0100, T:0.5056(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4850 (C:5.5863, R:0.0100, T:0.4840(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4980 (C:5.5739, R:0.0099, T:0.4970(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4828 (C:5.5987, R:0.0100, T:0.4818(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4765 (C:5.5941, R:0.0099, T:0.4755(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5037 (C:5.5612, R:0.0100, T:0.5027(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4961 (C:5.6102, R:0.0100, T:0.4951(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4942

ğŸ“Š EPOCH 31 TRAINING SUMMARY:
  Total Loss: 0.4952
  Contrastive: 5.5784
  Reconstruction: 0.0100
  Topological: 0.4942 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.2684
  Contrastive: 5.5187
  Reconstruction: 0.0099
  Topological: 2.2674 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 31/300 COMPLETE (51.7s)
Train Loss: 0.4952 (C:5.5784, R:0.0100, T:0.4942)
Val Loss:   2.2684 (C:5.5187, R:0.0099, T:2.2674)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 32 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5020 (C:5.5980, R:0.0100, T:0.5010(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4630 (C:5.5734, R:0.0099, T:0.4621(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4753 (C:5.6179, R:0.0100, T:0.4743(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4665 (C:5.5867, R:0.0099, T:0.4655(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5113 (C:5.5736, R:0.0099, T:0.5103(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4904 (C:5.5870, R:0.0100, T:0.4894(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4732 (C:5.5655, R:0.0100, T:0.4722(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5187 (C:5.5523, R:0.0099, T:0.5177(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4614 (C:5.6038, R:0.0100, T:0.4604(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4932 (C:5.5529, R:0.0100, T:0.4922(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4977 (C:5.5813, R:0.0099, T:0.4967(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4834 (C:5.5210, R:0.0099, T:0.4824(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4624 (C:5.5943, R:0.0100, T:0.4614(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4827 (C:5.5559, R:0.0099, T:0.4817(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4596 (C:5.5906, R:0.0100, T:0.4586(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4812 (C:5.5906, R:0.0100, T:0.4802(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4863 (C:5.5866, R:0.0099, T:0.4853(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5067 (C:5.5922, R:0.0100, T:0.5057(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4717 (C:5.5840, R:0.0099, T:0.4707(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4835 (C:5.5548, R:0.0099, T:0.4825(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5077 (C:5.5710, R:0.0099, T:0.5067(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5059 (C:5.5895, R:0.0100, T:0.5050(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4896

ğŸ“Š EPOCH 32 TRAINING SUMMARY:
  Total Loss: 0.4906
  Contrastive: 5.5820
  Reconstruction: 0.0100
  Topological: 0.4896 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.3081
  Contrastive: 5.4796
  Reconstruction: 0.0099
  Topological: 2.3071 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 32/300 COMPLETE (54.5s)
Train Loss: 0.4906 (C:5.5820, R:0.0100, T:0.4896)
Val Loss:   2.3081 (C:5.4796, R:0.0099, T:2.3071)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 33 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4839 (C:5.5759, R:0.0100, T:0.4829(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4899 (C:5.5633, R:0.0100, T:0.4889(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5074 (C:5.5509, R:0.0099, T:0.5064(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4846 (C:5.5877, R:0.0099, T:0.4836(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4984 (C:5.5625, R:0.0100, T:0.4974(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4970 (C:5.6219, R:0.0099, T:0.4960(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4934 (C:5.5891, R:0.0100, T:0.4924(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4961 (C:5.5388, R:0.0100, T:0.4951(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4819 (C:5.5765, R:0.0099, T:0.4809(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4848 (C:5.5962, R:0.0099, T:0.4838(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4665 (C:5.5847, R:0.0099, T:0.4655(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4606 (C:5.6156, R:0.0100, T:0.4596(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4799 (C:5.5908, R:0.0099, T:0.4789(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4687 (C:5.6010, R:0.0099, T:0.4677(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4806 (C:5.6129, R:0.0100, T:0.4796(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4816 (C:5.5919, R:0.0100, T:0.4806(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4853 (C:5.5878, R:0.0100, T:0.4844(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4987 (C:5.5692, R:0.0100, T:0.4977(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4667 (C:5.6013, R:0.0100, T:0.4657(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4631 (C:5.5543, R:0.0100, T:0.4621(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4495 (C:5.5743, R:0.0100, T:0.4485(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4938 (C:5.5685, R:0.0099, T:0.4928(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4863

ğŸ“Š EPOCH 33 TRAINING SUMMARY:
  Total Loss: 0.4873
  Contrastive: 5.5839
  Reconstruction: 0.0100
  Topological: 0.4863 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.1803
  Contrastive: 5.5457
  Reconstruction: 0.0099
  Topological: 2.1793 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 33/300 COMPLETE (52.3s)
Train Loss: 0.4873 (C:5.5839, R:0.0100, T:0.4863)
Val Loss:   2.1803 (C:5.5457, R:0.0099, T:2.1793)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 34 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4973 (C:5.6032, R:0.0100, T:0.4963(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4639 (C:5.5740, R:0.0100, T:0.4629(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5060 (C:5.5871, R:0.0099, T:0.5050(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4976 (C:5.6158, R:0.0100, T:0.4966(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4861 (C:5.5229, R:0.0099, T:0.4851(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5302 (C:5.6212, R:0.0100, T:0.5293(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4834 (C:5.6359, R:0.0099, T:0.4824(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4731 (C:5.6327, R:0.0100, T:0.4721(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4768 (C:5.6338, R:0.0099, T:0.4758(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4947 (C:5.5779, R:0.0099, T:0.4937(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5041 (C:5.5402, R:0.0099, T:0.5031(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5170 (C:5.5448, R:0.0100, T:0.5160(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4584 (C:5.5870, R:0.0100, T:0.4574(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4927 (C:5.5855, R:0.0100, T:0.4917(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5118 (C:5.5736, R:0.0099, T:0.5108(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4728 (C:5.5708, R:0.0100, T:0.4718(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5087 (C:5.6087, R:0.0100, T:0.5077(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4639 (C:5.6121, R:0.0099, T:0.4629(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4805 (C:5.5600, R:0.0099, T:0.4795(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4783 (C:5.5293, R:0.0100, T:0.4773(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4868 (C:5.5868, R:0.0099, T:0.4858(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4942 (C:5.5977, R:0.0100, T:0.4932(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4832

ğŸ“Š EPOCH 34 TRAINING SUMMARY:
  Total Loss: 0.4842
  Contrastive: 5.5840
  Reconstruction: 0.0100
  Topological: 0.4832 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.2049
  Contrastive: 5.5278
  Reconstruction: 0.0099
  Topological: 2.2039 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 34/300 COMPLETE (49.6s)
Train Loss: 0.4842 (C:5.5840, R:0.0100, T:0.4832)
Val Loss:   2.2049 (C:5.5278, R:0.0099, T:2.2039)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 35 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4818 (C:5.5979, R:0.0100, T:0.4808(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4831 (C:5.6170, R:0.0100, T:0.4821(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4882 (C:5.6160, R:0.0100, T:0.4872(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4641 (C:5.5902, R:0.0100, T:0.4631(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4591 (C:5.5646, R:0.0100, T:0.4581(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4827 (C:5.6052, R:0.0099, T:0.4817(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5402 (C:5.6164, R:0.0099, T:0.5392(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4597 (C:5.6405, R:0.0100, T:0.4587(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4716 (C:5.5633, R:0.0100, T:0.4706(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4849 (C:5.6108, R:0.0100, T:0.4839(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5030 (C:5.5993, R:0.0100, T:0.5020(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4818 (C:5.5718, R:0.0099, T:0.4808(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4870 (C:5.5867, R:0.0100, T:0.4860(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4774 (C:5.5694, R:0.0099, T:0.4764(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4957 (C:5.6107, R:0.0100, T:0.4947(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4959 (C:5.5849, R:0.0099, T:0.4950(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5002 (C:5.5722, R:0.0099, T:0.4992(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4462 (C:5.5904, R:0.0100, T:0.4452(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4898 (C:5.5799, R:0.0100, T:0.4888(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4615 (C:5.5907, R:0.0100, T:0.4605(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4745 (C:5.5753, R:0.0099, T:0.4735(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4825 (C:5.5934, R:0.0100, T:0.4815(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4793

ğŸ“Š EPOCH 35 TRAINING SUMMARY:
  Total Loss: 0.4803
  Contrastive: 5.5865
  Reconstruction: 0.0100
  Topological: 0.4793 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.1563
  Contrastive: 5.5391
  Reconstruction: 0.0099
  Topological: 2.1553 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 35/300 COMPLETE (47.7s)
Train Loss: 0.4803 (C:5.5865, R:0.0100, T:0.4793)
Val Loss:   2.1563 (C:5.5391, R:0.0099, T:2.1553)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 36 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4825 (C:5.6015, R:0.0099, T:0.4815(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4521 (C:5.5619, R:0.0099, T:0.4511(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4637 (C:5.5958, R:0.0099, T:0.4627(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4856 (C:5.5947, R:0.0099, T:0.4847(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4855 (C:5.5899, R:0.0100, T:0.4845(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4765 (C:5.6139, R:0.0100, T:0.4755(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4679 (C:5.5813, R:0.0100, T:0.4669(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4949 (C:5.5770, R:0.0100, T:0.4939(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4801 (C:5.5749, R:0.0100, T:0.4791(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4848 (C:5.5902, R:0.0100, T:0.4838(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5020 (C:5.6183, R:0.0100, T:0.5010(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4792 (C:5.6016, R:0.0100, T:0.4782(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4851 (C:5.6318, R:0.0100, T:0.4841(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4691 (C:5.5906, R:0.0099, T:0.4681(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4878 (C:5.6004, R:0.0100, T:0.4868(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4499 (C:5.5928, R:0.0100, T:0.4489(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4769 (C:5.5730, R:0.0099, T:0.4759(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4718 (C:5.5916, R:0.0100, T:0.4709(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4718 (C:5.5571, R:0.0099, T:0.4708(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4780 (C:5.6137, R:0.0100, T:0.4770(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4740 (C:5.5947, R:0.0099, T:0.4730(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4493 (C:5.6197, R:0.0099, T:0.4483(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4755

ğŸ“Š EPOCH 36 TRAINING SUMMARY:
  Total Loss: 0.4765
  Contrastive: 5.5905
  Reconstruction: 0.0100
  Topological: 0.4755 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.1702
  Contrastive: 5.5055
  Reconstruction: 0.0099
  Topological: 2.1692 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 36/300 COMPLETE (49.6s)
Train Loss: 0.4765 (C:5.5905, R:0.0100, T:0.4755)
Val Loss:   2.1702 (C:5.5055, R:0.0099, T:2.1692)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 37 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4753 (C:5.5867, R:0.0100, T:0.4743(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5065 (C:5.5696, R:0.0100, T:0.5055(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4506 (C:5.5688, R:0.0100, T:0.4496(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4794 (C:5.5890, R:0.0100, T:0.4785(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4980 (C:5.6101, R:0.0100, T:0.4970(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4608 (C:5.5894, R:0.0100, T:0.4598(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4785 (C:5.6345, R:0.0099, T:0.4775(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4779 (C:5.5911, R:0.0100, T:0.4769(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4765 (C:5.6001, R:0.0100, T:0.4755(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5034 (C:5.5999, R:0.0099, T:0.5024(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4696 (C:5.6405, R:0.0099, T:0.4687(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4875 (C:5.5813, R:0.0099, T:0.4865(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4645 (C:5.5637, R:0.0099, T:0.4636(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4678 (C:5.6226, R:0.0099, T:0.4668(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4590 (C:5.5754, R:0.0099, T:0.4580(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4600 (C:5.5921, R:0.0100, T:0.4590(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4518 (C:5.6319, R:0.0100, T:0.4508(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4751 (C:5.5980, R:0.0099, T:0.4741(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4597 (C:5.6204, R:0.0100, T:0.4587(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4747 (C:5.5973, R:0.0100, T:0.4737(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4676 (C:5.6011, R:0.0099, T:0.4666(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4712 (C:5.6018, R:0.0100, T:0.4702(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4708

ğŸ“Š EPOCH 37 TRAINING SUMMARY:
  Total Loss: 0.4718
  Contrastive: 5.5927
  Reconstruction: 0.0100
  Topological: 0.4708 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.1078
  Contrastive: 5.5257
  Reconstruction: 0.0099
  Topological: 2.1068 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 37/300 COMPLETE (49.9s)
Train Loss: 0.4718 (C:5.5927, R:0.0100, T:0.4708)
Val Loss:   2.1078 (C:5.5257, R:0.0099, T:2.1068)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 38 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4563 (C:5.5820, R:0.0099, T:0.4553(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4857 (C:5.5429, R:0.0099, T:0.4847(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4773 (C:5.6277, R:0.0100, T:0.4763(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4845 (C:5.6290, R:0.0100, T:0.4835(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4389 (C:5.5933, R:0.0099, T:0.4379(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4751 (C:5.5747, R:0.0100, T:0.4741(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4552 (C:5.6033, R:0.0100, T:0.4542(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4773 (C:5.6069, R:0.0100, T:0.4763(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4743 (C:5.5807, R:0.0100, T:0.4733(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4646 (C:5.5878, R:0.0100, T:0.4636(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4703 (C:5.6360, R:0.0099, T:0.4693(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4455 (C:5.6109, R:0.0100, T:0.4445(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4804 (C:5.5662, R:0.0099, T:0.4794(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4850 (C:5.5871, R:0.0100, T:0.4840(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4425 (C:5.6047, R:0.0099, T:0.4415(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4788 (C:5.6251, R:0.0099, T:0.4778(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4792 (C:5.6126, R:0.0100, T:0.4782(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4536 (C:5.5869, R:0.0100, T:0.4526(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4726 (C:5.6212, R:0.0100, T:0.4716(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4747 (C:5.5925, R:0.0099, T:0.4737(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4729 (C:5.6152, R:0.0100, T:0.4719(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4702 (C:5.5964, R:0.0100, T:0.4692(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4681

ğŸ“Š EPOCH 38 TRAINING SUMMARY:
  Total Loss: 0.4691
  Contrastive: 5.5936
  Reconstruction: 0.0100
  Topological: 0.4681 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.0774
  Contrastive: 5.5607
  Reconstruction: 0.0099
  Topological: 2.0764 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 38/300 COMPLETE (50.2s)
Train Loss: 0.4691 (C:5.5936, R:0.0100, T:0.4681)
Val Loss:   2.0774 (C:5.5607, R:0.0099, T:2.0764)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 39 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4791 (C:5.6145, R:0.0099, T:0.4781(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4610 (C:5.6129, R:0.0099, T:0.4600(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4369 (C:5.5890, R:0.0099, T:0.4359(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4533 (C:5.6093, R:0.0099, T:0.4523(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4619 (C:5.5838, R:0.0100, T:0.4609(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4669 (C:5.5923, R:0.0099, T:0.4659(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4309 (C:5.6001, R:0.0099, T:0.4299(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4650 (C:5.6285, R:0.0100, T:0.4641(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4913 (C:5.5822, R:0.0100, T:0.4903(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4413 (C:5.5721, R:0.0099, T:0.4403(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4554 (C:5.5936, R:0.0099, T:0.4545(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4642 (C:5.6177, R:0.0099, T:0.4632(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4454 (C:5.5872, R:0.0100, T:0.4444(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4538 (C:5.6251, R:0.0100, T:0.4528(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4755 (C:5.6158, R:0.0099, T:0.4745(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4638 (C:5.6104, R:0.0099, T:0.4628(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4715 (C:5.6382, R:0.0100, T:0.4705(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4646 (C:5.6066, R:0.0099, T:0.4636(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4463 (C:5.5870, R:0.0099, T:0.4453(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4525 (C:5.6159, R:0.0099, T:0.4515(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4652 (C:5.6041, R:0.0100, T:0.4642(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4603 (C:5.6313, R:0.0100, T:0.4593(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4651

ğŸ“Š EPOCH 39 TRAINING SUMMARY:
  Total Loss: 0.4661
  Contrastive: 5.5959
  Reconstruction: 0.0100
  Topological: 0.4651 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.0045
  Contrastive: 5.5670
  Reconstruction: 0.0099
  Topological: 2.0035 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 39/300 COMPLETE (51.3s)
Train Loss: 0.4661 (C:5.5959, R:0.0100, T:0.4651)
Val Loss:   2.0045 (C:5.5670, R:0.0099, T:2.0035)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 40 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4555 (C:5.5987, R:0.0099, T:0.4545(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4804 (C:5.5934, R:0.0100, T:0.4794(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4688 (C:5.6071, R:0.0100, T:0.4678(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4309 (C:5.6160, R:0.0099, T:0.4299(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4808 (C:5.6014, R:0.0099, T:0.4798(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4557 (C:5.5769, R:0.0099, T:0.4547(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4671 (C:5.6197, R:0.0099, T:0.4661(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4562 (C:5.6050, R:0.0100, T:0.4552(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4591 (C:5.5992, R:0.0100, T:0.4581(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4656 (C:5.6144, R:0.0100, T:0.4646(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4658 (C:5.5733, R:0.0100, T:0.4648(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4404 (C:5.6170, R:0.0100, T:0.4394(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4591 (C:5.5678, R:0.0099, T:0.4581(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4731 (C:5.5613, R:0.0099, T:0.4721(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4708 (C:5.5790, R:0.0100, T:0.4698(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4686 (C:5.5912, R:0.0100, T:0.4676(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4533 (C:5.5853, R:0.0100, T:0.4523(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4573 (C:5.5880, R:0.0100, T:0.4563(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4822 (C:5.6063, R:0.0100, T:0.4812(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4817 (C:5.5745, R:0.0100, T:0.4807(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4693 (C:5.5971, R:0.0100, T:0.4683(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4572 (C:5.5803, R:0.0100, T:0.4562(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4630

ğŸ“Š EPOCH 40 TRAINING SUMMARY:
  Total Loss: 0.4640
  Contrastive: 5.5953
  Reconstruction: 0.0100
  Topological: 0.4630 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.0351
  Contrastive: 5.5494
  Reconstruction: 0.0099
  Topological: 2.0341 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 40/300 COMPLETE (48.9s)
Train Loss: 0.4640 (C:5.5953, R:0.0100, T:0.4630)
Val Loss:   2.0351 (C:5.5494, R:0.0099, T:2.0341)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 41 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4475 (C:5.5943, R:0.0100, T:0.4465(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4892 (C:5.5609, R:0.0100, T:0.4882(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4684 (C:5.6119, R:0.0100, T:0.4675(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4524 (C:5.6280, R:0.0099, T:0.4514(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4560 (C:5.6242, R:0.0100, T:0.4550(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4497 (C:5.6211, R:0.0100, T:0.4488(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4543 (C:5.6086, R:0.0099, T:0.4533(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4575 (C:5.5885, R:0.0099, T:0.4565(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4775 (C:5.5669, R:0.0100, T:0.4765(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4340 (C:5.5847, R:0.0100, T:0.4330(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4740 (C:5.5977, R:0.0099, T:0.4731(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4604 (C:5.6138, R:0.0100, T:0.4595(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4730 (C:5.5673, R:0.0099, T:0.4720(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4553 (C:5.6000, R:0.0100, T:0.4543(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4569 (C:5.5694, R:0.0099, T:0.4559(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4798 (C:5.5975, R:0.0099, T:0.4788(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4496 (C:5.5586, R:0.0100, T:0.4486(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4441 (C:5.5887, R:0.0099, T:0.4431(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4647 (C:5.5797, R:0.0099, T:0.4637(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4638 (C:5.5861, R:0.0099, T:0.4629(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4706 (C:5.6354, R:0.0100, T:0.4696(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4499 (C:5.5824, R:0.0099, T:0.4489(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4619

ğŸ“Š EPOCH 41 TRAINING SUMMARY:
  Total Loss: 0.4629
  Contrastive: 5.5958
  Reconstruction: 0.0100
  Topological: 0.4619 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.9063
  Contrastive: 5.5953
  Reconstruction: 0.0099
  Topological: 1.9053 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 41/300 COMPLETE (48.3s)
Train Loss: 0.4629 (C:5.5958, R:0.0100, T:0.4619)
Val Loss:   1.9063 (C:5.5953, R:0.0099, T:1.9053)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 42 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4781 (C:5.6143, R:0.0100, T:0.4771(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4584 (C:5.6162, R:0.0100, T:0.4574(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4546 (C:5.5888, R:0.0100, T:0.4536(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4626 (C:5.5630, R:0.0099, T:0.4617(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4760 (C:5.5697, R:0.0100, T:0.4750(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4428 (C:5.6034, R:0.0100, T:0.4418(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4562 (C:5.5891, R:0.0099, T:0.4552(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4643 (C:5.6166, R:0.0099, T:0.4633(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4625 (C:5.5613, R:0.0099, T:0.4615(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4403 (C:5.5700, R:0.0100, T:0.4393(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4482 (C:5.5747, R:0.0100, T:0.4472(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4747 (C:5.6090, R:0.0100, T:0.4737(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4835 (C:5.6161, R:0.0100, T:0.4825(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4858 (C:5.6001, R:0.0100, T:0.4848(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4423 (C:5.6319, R:0.0100, T:0.4413(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4838 (C:5.6219, R:0.0100, T:0.4829(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4510 (C:5.5833, R:0.0099, T:0.4500(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4471 (C:5.6227, R:0.0099, T:0.4461(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4577 (C:5.5842, R:0.0100, T:0.4567(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4690 (C:5.5861, R:0.0100, T:0.4680(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4513 (C:5.5906, R:0.0100, T:0.4503(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4628 (C:5.5709, R:0.0099, T:0.4618(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4592

ğŸ“Š EPOCH 42 TRAINING SUMMARY:
  Total Loss: 0.4602
  Contrastive: 5.5981
  Reconstruction: 0.0100
  Topological: 0.4592 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.9607
  Contrastive: 5.5603
  Reconstruction: 0.0099
  Topological: 1.9597 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 42/300 COMPLETE (47.4s)
Train Loss: 0.4602 (C:5.5981, R:0.0100, T:0.4592)
Val Loss:   1.9607 (C:5.5603, R:0.0099, T:1.9597)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 43 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4741 (C:5.5915, R:0.0099, T:0.4731(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4559 (C:5.5621, R:0.0099, T:0.4549(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4513 (C:5.6060, R:0.0099, T:0.4503(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4437 (C:5.6089, R:0.0100, T:0.4427(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4507 (C:5.6324, R:0.0100, T:0.4497(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4671 (C:5.5913, R:0.0099, T:0.4661(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4474 (C:5.5813, R:0.0099, T:0.4464(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4420 (C:5.5953, R:0.0099, T:0.4410(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4774 (C:5.6344, R:0.0100, T:0.4764(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4717 (C:5.6038, R:0.0100, T:0.4707(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4652 (C:5.5886, R:0.0100, T:0.4642(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4758 (C:5.5904, R:0.0099, T:0.4748(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4658 (C:5.5848, R:0.0100, T:0.4648(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4509 (C:5.5816, R:0.0099, T:0.4499(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4519 (C:5.6274, R:0.0100, T:0.4509(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4602 (C:5.6153, R:0.0100, T:0.4592(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4845 (C:5.5791, R:0.0100, T:0.4835(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4361 (C:5.5964, R:0.0100, T:0.4351(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4518 (C:5.6006, R:0.0099, T:0.4508(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4817 (C:5.5235, R:0.0100, T:0.4808(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4701 (C:5.6298, R:0.0099, T:0.4691(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4578 (C:5.5954, R:0.0100, T:0.4568(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4580

ğŸ“Š EPOCH 43 TRAINING SUMMARY:
  Total Loss: 0.4590
  Contrastive: 5.5971
  Reconstruction: 0.0100
  Topological: 0.4580 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.9328
  Contrastive: 5.5456
  Reconstruction: 0.0099
  Topological: 1.9319 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 43/300 COMPLETE (51.6s)
Train Loss: 0.4590 (C:5.5971, R:0.0100, T:0.4580)
Val Loss:   1.9328 (C:5.5456, R:0.0099, T:1.9319)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 44 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4720 (C:5.5828, R:0.0100, T:0.4710(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4584 (C:5.6271, R:0.0099, T:0.4574(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4425 (C:5.6009, R:0.0100, T:0.4415(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4429 (C:5.5957, R:0.0100, T:0.4419(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4455 (C:5.6113, R:0.0099, T:0.4445(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4446 (C:5.6277, R:0.0099, T:0.4436(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4528 (C:5.6233, R:0.0099, T:0.4518(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5019 (C:5.6450, R:0.0100, T:0.5009(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4576 (C:5.5983, R:0.0099, T:0.4566(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4606 (C:5.6199, R:0.0100, T:0.4596(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4609 (C:5.5907, R:0.0099, T:0.4599(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4658 (C:5.5888, R:0.0099, T:0.4648(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4501 (C:5.6171, R:0.0100, T:0.4491(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4343 (C:5.5492, R:0.0099, T:0.4333(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4453 (C:5.6095, R:0.0099, T:0.4443(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4431 (C:5.5920, R:0.0099, T:0.4421(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4378 (C:5.5590, R:0.0100, T:0.4368(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4466 (C:5.6354, R:0.0099, T:0.4456(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4597 (C:5.6441, R:0.0100, T:0.4587(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4478 (C:5.6151, R:0.0099, T:0.4468(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4414 (C:5.5881, R:0.0100, T:0.4404(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4441 (C:5.6386, R:0.0099, T:0.4431(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4557

ğŸ“Š EPOCH 44 TRAINING SUMMARY:
  Total Loss: 0.4567
  Contrastive: 5.5990
  Reconstruction: 0.0100
  Topological: 0.4557 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.9008
  Contrastive: 5.6020
  Reconstruction: 0.0099
  Topological: 1.8998 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 44/300 COMPLETE (52.7s)
Train Loss: 0.4567 (C:5.5990, R:0.0100, T:0.4557)
Val Loss:   1.9008 (C:5.6020, R:0.0099, T:1.8998)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 45 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4699 (C:5.6245, R:0.0100, T:0.4689(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4524 (C:5.6088, R:0.0099, T:0.4514(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4358 (C:5.5637, R:0.0100, T:0.4348(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4563 (C:5.6193, R:0.0099, T:0.4553(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4583 (C:5.5896, R:0.0100, T:0.4573(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4455 (C:5.5909, R:0.0100, T:0.4445(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4532 (C:5.5891, R:0.0099, T:0.4522(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4826 (C:5.5975, R:0.0100, T:0.4816(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4644 (C:5.6190, R:0.0100, T:0.4634(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4548 (C:5.6206, R:0.0099, T:0.4538(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4504 (C:5.6042, R:0.0099, T:0.4494(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4306 (C:5.6200, R:0.0100, T:0.4296(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4464 (C:5.6005, R:0.0099, T:0.4455(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4555 (C:5.6110, R:0.0100, T:0.4545(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4524 (C:5.5938, R:0.0099, T:0.4514(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4440 (C:5.5792, R:0.0099, T:0.4430(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4454 (C:5.6046, R:0.0099, T:0.4445(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4340 (C:5.6191, R:0.0100, T:0.4330(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4526 (C:5.5736, R:0.0099, T:0.4516(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4596 (C:5.6451, R:0.0100, T:0.4586(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4487 (C:5.5955, R:0.0099, T:0.4477(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4578 (C:5.6119, R:0.0099, T:0.4568(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4536

ğŸ“Š EPOCH 45 TRAINING SUMMARY:
  Total Loss: 0.4546
  Contrastive: 5.6006
  Reconstruction: 0.0100
  Topological: 0.4536 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.9243
  Contrastive: 5.5720
  Reconstruction: 0.0099
  Topological: 1.9233 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 45/300 COMPLETE (51.7s)
Train Loss: 0.4546 (C:5.6006, R:0.0100, T:0.4536)
Val Loss:   1.9243 (C:5.5720, R:0.0099, T:1.9233)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 46 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4414 (C:5.5859, R:0.0099, T:0.4405(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4530 (C:5.5723, R:0.0099, T:0.4520(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4510 (C:5.5599, R:0.0100, T:0.4500(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4320 (C:5.6054, R:0.0100, T:0.4310(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4483 (C:5.5911, R:0.0100, T:0.4473(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4447 (C:5.5864, R:0.0100, T:0.4437(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4431 (C:5.5744, R:0.0100, T:0.4421(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4492 (C:5.6008, R:0.0099, T:0.4482(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4368 (C:5.5775, R:0.0099, T:0.4358(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4516 (C:5.5951, R:0.0100, T:0.4506(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4559 (C:5.5726, R:0.0100, T:0.4549(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4371 (C:5.5945, R:0.0099, T:0.4361(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4562 (C:5.6046, R:0.0099, T:0.4552(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4682 (C:5.6000, R:0.0099, T:0.4672(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4727 (C:5.6508, R:0.0099, T:0.4717(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4324 (C:5.6498, R:0.0099, T:0.4314(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4672 (C:5.6233, R:0.0100, T:0.4662(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4811 (C:5.6121, R:0.0099, T:0.4801(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4612 (C:5.6032, R:0.0100, T:0.4602(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4334 (C:5.6282, R:0.0100, T:0.4324(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4590 (C:5.5538, R:0.0100, T:0.4580(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4570 (C:5.5848, R:0.0100, T:0.4560(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4527

ğŸ“Š EPOCH 46 TRAINING SUMMARY:
  Total Loss: 0.4537
  Contrastive: 5.5999
  Reconstruction: 0.0100
  Topological: 0.4527 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.7758
  Contrastive: 5.6376
  Reconstruction: 0.0099
  Topological: 1.7748 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 46/300 COMPLETE (52.3s)
Train Loss: 0.4537 (C:5.5999, R:0.0100, T:0.4527)
Val Loss:   1.7758 (C:5.6376, R:0.0099, T:1.7748)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 47 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4518 (C:5.6245, R:0.0099, T:0.4508(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4638 (C:5.5869, R:0.0100, T:0.4628(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4642 (C:5.6024, R:0.0099, T:0.4632(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4637 (C:5.5881, R:0.0099, T:0.4627(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4610 (C:5.6116, R:0.0099, T:0.4600(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4715 (C:5.5648, R:0.0099, T:0.4705(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4521 (C:5.6270, R:0.0100, T:0.4511(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4642 (C:5.6378, R:0.0100, T:0.4632(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4560 (C:5.6091, R:0.0100, T:0.4550(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4605 (C:5.5870, R:0.0100, T:0.4595(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4572 (C:5.6101, R:0.0099, T:0.4562(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4279 (C:5.5998, R:0.0100, T:0.4269(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4633 (C:5.6002, R:0.0100, T:0.4623(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4301 (C:5.6038, R:0.0099, T:0.4291(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4640 (C:5.6279, R:0.0100, T:0.4630(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4395 (C:5.6197, R:0.0099, T:0.4385(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4583 (C:5.6097, R:0.0099, T:0.4573(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4303 (C:5.5916, R:0.0100, T:0.4293(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4496 (C:5.5826, R:0.0099, T:0.4486(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4325 (C:5.6368, R:0.0099, T:0.4315(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4511 (C:5.5833, R:0.0099, T:0.4501(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4284 (C:5.6011, R:0.0100, T:0.4274(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4500

ğŸ“Š EPOCH 47 TRAINING SUMMARY:
  Total Loss: 0.4510
  Contrastive: 5.6010
  Reconstruction: 0.0100
  Topological: 0.4500 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.8640
  Contrastive: 5.5995
  Reconstruction: 0.0099
  Topological: 1.8630 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 47/300 COMPLETE (52.2s)
Train Loss: 0.4510 (C:5.6010, R:0.0100, T:0.4500)
Val Loss:   1.8640 (C:5.5995, R:0.0099, T:1.8630)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 48 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4451 (C:5.6320, R:0.0100, T:0.4441(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4481 (C:5.6076, R:0.0100, T:0.4471(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4519 (C:5.5927, R:0.0100, T:0.4509(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4626 (C:5.6015, R:0.0099, T:0.4616(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4340 (C:5.5984, R:0.0100, T:0.4330(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4591 (C:5.6340, R:0.0100, T:0.4581(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4540 (C:5.6023, R:0.0099, T:0.4530(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4427 (C:5.6047, R:0.0100, T:0.4417(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4437 (C:5.6042, R:0.0099, T:0.4428(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4298 (C:5.6259, R:0.0100, T:0.4288(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4579 (C:5.6284, R:0.0100, T:0.4569(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4620 (C:5.6199, R:0.0100, T:0.4610(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4247 (C:5.5600, R:0.0099, T:0.4237(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4584 (C:5.5872, R:0.0099, T:0.4574(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4513 (C:5.5786, R:0.0099, T:0.4503(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4414 (C:5.5941, R:0.0100, T:0.4404(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4419 (C:5.5692, R:0.0100, T:0.4409(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4338 (C:5.5829, R:0.0100, T:0.4328(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4425 (C:5.6562, R:0.0099, T:0.4415(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4584 (C:5.5887, R:0.0099, T:0.4574(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4424 (C:5.6077, R:0.0099, T:0.4414(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4612 (C:5.6330, R:0.0099, T:0.4602(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 48 TRAINING SUMMARY:
  Total Loss: 0.4511
  Contrastive: 5.6019
  Reconstruction: 0.0100
  Topological: 0.4502 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.8014
  Contrastive: 5.6108
  Reconstruction: 0.0099
  Topological: 1.8004 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 48/300 COMPLETE (52.3s)
Train Loss: 0.4511 (C:5.6019, R:0.0100, T:0.4502)
Val Loss:   1.8014 (C:5.6108, R:0.0099, T:1.8004)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 49 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4472 (C:5.6180, R:0.0100, T:0.4462(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4415 (C:5.6144, R:0.0100, T:0.4405(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4474 (C:5.6022, R:0.0100, T:0.4464(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4433 (C:5.6495, R:0.0100, T:0.4423(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4679 (C:5.6001, R:0.0099, T:0.4669(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4489 (C:5.6088, R:0.0099, T:0.4479(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4787 (C:5.5712, R:0.0100, T:0.4777(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4732 (C:5.6064, R:0.0099, T:0.4722(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4792 (C:5.6205, R:0.0099, T:0.4782(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4397 (C:5.6152, R:0.0100, T:0.4387(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4312 (C:5.5857, R:0.0099, T:0.4302(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4420 (C:5.5923, R:0.0099, T:0.4410(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4292 (C:5.5967, R:0.0099, T:0.4282(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4470 (C:5.5794, R:0.0100, T:0.4460(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4348 (C:5.6059, R:0.0100, T:0.4338(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4700 (C:5.6206, R:0.0100, T:0.4690(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4518 (C:5.6337, R:0.0100, T:0.4508(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4586 (C:5.6138, R:0.0099, T:0.4576(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4464 (C:5.6212, R:0.0099, T:0.4454(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4387 (C:5.5751, R:0.0100, T:0.4377(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4519 (C:5.6002, R:0.0100, T:0.4509(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4471 (C:5.5823, R:0.0100, T:0.4461(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4474

ğŸ“Š EPOCH 49 TRAINING SUMMARY:
  Total Loss: 0.4484
  Contrastive: 5.6026
  Reconstruction: 0.0100
  Topological: 0.4474 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.7770
  Contrastive: 5.6452
  Reconstruction: 0.0099
  Topological: 1.7760 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 49/300 COMPLETE (52.1s)
Train Loss: 0.4484 (C:5.6026, R:0.0100, T:0.4474)
Val Loss:   1.7770 (C:5.6452, R:0.0099, T:1.7760)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 50 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4221 (C:5.6337, R:0.0099, T:0.4211(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4474 (C:5.6112, R:0.0099, T:0.4464(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4366 (C:5.6035, R:0.0099, T:0.4356(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4476 (C:5.5961, R:0.0100, T:0.4466(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4370 (C:5.6004, R:0.0099, T:0.4360(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4199 (C:5.6132, R:0.0100, T:0.4189(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4313 (C:5.6040, R:0.0100, T:0.4303(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4231 (C:5.6034, R:0.0100, T:0.4221(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4294 (C:5.6033, R:0.0099, T:0.4285(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4489 (C:5.6072, R:0.0100, T:0.4479(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4524 (C:5.6236, R:0.0100, T:0.4514(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4668 (C:5.5767, R:0.0100, T:0.4658(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4241 (C:5.6411, R:0.0099, T:0.4231(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4503 (C:5.6602, R:0.0100, T:0.4493(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4209 (C:5.5989, R:0.0100, T:0.4199(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4708 (C:5.6040, R:0.0099, T:0.4698(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4443 (C:5.6008, R:0.0100, T:0.4433(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4526 (C:5.6061, R:0.0100, T:0.4516(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4613 (C:5.5955, R:0.0100, T:0.4603(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4484 (C:5.6519, R:0.0099, T:0.4474(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4712 (C:5.6112, R:0.0099, T:0.4702(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4571 (C:5.6017, R:0.0100, T:0.4562(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4463

ğŸ“Š EPOCH 50 TRAINING SUMMARY:
  Total Loss: 0.4473
  Contrastive: 5.6053
  Reconstruction: 0.0100
  Topological: 0.4463 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.8796
  Contrastive: 5.5729
  Reconstruction: 0.0099
  Topological: 1.8787 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 50/300 COMPLETE (49.4s)
Train Loss: 0.4473 (C:5.6053, R:0.0100, T:0.4463)
Val Loss:   1.8796 (C:5.5729, R:0.0099, T:1.8787)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 51 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4323 (C:5.5844, R:0.0099, T:0.4313(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4462 (C:5.5623, R:0.0099, T:0.4452(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4466 (C:5.6525, R:0.0100, T:0.4456(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4293 (C:5.5758, R:0.0099, T:0.4283(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4368 (C:5.5882, R:0.0099, T:0.4358(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4385 (C:5.5763, R:0.0100, T:0.4375(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4336 (C:5.5979, R:0.0099, T:0.4326(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4373 (C:5.5984, R:0.0099, T:0.4363(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4497 (C:5.6126, R:0.0099, T:0.4487(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4483 (C:5.6042, R:0.0099, T:0.4473(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4316 (C:5.5878, R:0.0099, T:0.4306(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4484 (C:5.6473, R:0.0100, T:0.4474(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4457 (C:5.5788, R:0.0099, T:0.4447(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4426 (C:5.6539, R:0.0100, T:0.4416(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4351 (C:5.6150, R:0.0099, T:0.4341(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4617 (C:5.6299, R:0.0100, T:0.4607(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4664 (C:5.6388, R:0.0100, T:0.4654(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4347 (C:5.5731, R:0.0099, T:0.4338(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4401 (C:5.5959, R:0.0100, T:0.4391(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4344 (C:5.5867, R:0.0099, T:0.4334(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4506 (C:5.6271, R:0.0099, T:0.4496(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4571 (C:5.5789, R:0.0100, T:0.4561(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4440

ğŸ“Š EPOCH 51 TRAINING SUMMARY:
  Total Loss: 0.4450
  Contrastive: 5.6060
  Reconstruction: 0.0100
  Topological: 0.4440 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.7447
  Contrastive: 5.6205
  Reconstruction: 0.0099
  Topological: 1.7438 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 51/300 COMPLETE (49.1s)
Train Loss: 0.4450 (C:5.6060, R:0.0100, T:0.4440)
Val Loss:   1.7447 (C:5.6205, R:0.0099, T:1.7438)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 52 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4587 (C:5.6212, R:0.0099, T:0.4577(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4575 (C:5.5976, R:0.0099, T:0.4565(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4342 (C:5.6008, R:0.0100, T:0.4332(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4449 (C:5.5806, R:0.0100, T:0.4440(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4532 (C:5.6038, R:0.0099, T:0.4523(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4413 (C:5.6139, R:0.0100, T:0.4403(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4488 (C:5.5903, R:0.0099, T:0.4478(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4365 (C:5.6182, R:0.0100, T:0.4355(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4205 (C:5.6248, R:0.0100, T:0.4195(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4429 (C:5.5704, R:0.0100, T:0.4419(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4497 (C:5.5914, R:0.0099, T:0.4487(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4102 (C:5.5885, R:0.0100, T:0.4092(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4630 (C:5.6067, R:0.0100, T:0.4620(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4749 (C:5.5835, R:0.0100, T:0.4739(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4259 (C:5.6305, R:0.0099, T:0.4249(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4329 (C:5.5806, R:0.0099, T:0.4319(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4103 (C:5.6085, R:0.0099, T:0.4093(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4423 (C:5.5910, R:0.0099, T:0.4413(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4564 (C:5.6112, R:0.0100, T:0.4554(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4277 (C:5.6120, R:0.0100, T:0.4267(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4653 (C:5.6363, R:0.0099, T:0.4643(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4564 (C:5.6523, R:0.0099, T:0.4554(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4427

ğŸ“Š EPOCH 52 TRAINING SUMMARY:
  Total Loss: 0.4437
  Contrastive: 5.6053
  Reconstruction: 0.0100
  Topological: 0.4427 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.8445
  Contrastive: 5.5767
  Reconstruction: 0.0099
  Topological: 1.8435 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 52/300 COMPLETE (48.5s)
Train Loss: 0.4437 (C:5.6053, R:0.0100, T:0.4427)
Val Loss:   1.8445 (C:5.5767, R:0.0099, T:1.8435)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 53 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4653 (C:5.5963, R:0.0099, T:0.4643(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4462 (C:5.5735, R:0.0100, T:0.4452(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4630 (C:5.6091, R:0.0100, T:0.4620(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4287 (C:5.6071, R:0.0100, T:0.4277(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4150 (C:5.6039, R:0.0100, T:0.4140(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4400 (C:5.5826, R:0.0099, T:0.4390(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4318 (C:5.5551, R:0.0099, T:0.4309(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4635 (C:5.6141, R:0.0100, T:0.4625(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4429 (C:5.6261, R:0.0100, T:0.4419(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4393 (C:5.6017, R:0.0100, T:0.4383(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4292 (C:5.6020, R:0.0099, T:0.4282(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4266 (C:5.6185, R:0.0100, T:0.4256(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4460 (C:5.5956, R:0.0099, T:0.4450(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4304 (C:5.5859, R:0.0099, T:0.4294(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4412 (C:5.5919, R:0.0100, T:0.4402(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4317 (C:5.6252, R:0.0100, T:0.4307(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4340 (C:5.5794, R:0.0100, T:0.4330(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4457 (C:5.6071, R:0.0099, T:0.4447(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4381 (C:5.5746, R:0.0100, T:0.4371(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4336 (C:5.5834, R:0.0100, T:0.4326(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4275 (C:5.6056, R:0.0099, T:0.4265(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4323 (C:5.6022, R:0.0100, T:0.4313(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4417

ğŸ“Š EPOCH 53 TRAINING SUMMARY:
  Total Loss: 0.4427
  Contrastive: 5.6047
  Reconstruction: 0.0100
  Topological: 0.4417 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.8345
  Contrastive: 5.5647
  Reconstruction: 0.0099
  Topological: 1.8335 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 53/300 COMPLETE (48.5s)
Train Loss: 0.4427 (C:5.6047, R:0.0100, T:0.4417)
Val Loss:   1.8345 (C:5.5647, R:0.0099, T:1.8335)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 54 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4634 (C:5.5925, R:0.0100, T:0.4624(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4522 (C:5.6172, R:0.0100, T:0.4512(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4508 (C:5.6065, R:0.0100, T:0.4498(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4313 (C:5.5987, R:0.0099, T:0.4303(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4646 (C:5.6353, R:0.0099, T:0.4636(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4650 (C:5.6017, R:0.0100, T:0.4640(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4520 (C:5.5822, R:0.0099, T:0.4510(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4410 (C:5.5589, R:0.0100, T:0.4400(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4160 (C:5.5823, R:0.0099, T:0.4150(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4486 (C:5.6134, R:0.0099, T:0.4476(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4607 (C:5.5934, R:0.0100, T:0.4597(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4541 (C:5.5846, R:0.0100, T:0.4531(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4374 (C:5.6100, R:0.0100, T:0.4364(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4689 (C:5.6464, R:0.0100, T:0.4679(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4571 (C:5.6075, R:0.0099, T:0.4561(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4493 (C:5.6313, R:0.0099, T:0.4483(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4607 (C:5.5802, R:0.0099, T:0.4597(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4165 (C:5.5550, R:0.0100, T:0.4155(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4266 (C:5.5666, R:0.0100, T:0.4256(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4311 (C:5.6026, R:0.0100, T:0.4301(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4486 (C:5.6051, R:0.0099, T:0.4476(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4147 (C:5.5943, R:0.0099, T:0.4137(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4408

ğŸ“Š EPOCH 54 TRAINING SUMMARY:
  Total Loss: 0.4418
  Contrastive: 5.6073
  Reconstruction: 0.0100
  Topological: 0.4408 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.8178
  Contrastive: 5.5725
  Reconstruction: 0.0099
  Topological: 1.8169 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 54/300 COMPLETE (48.4s)
Train Loss: 0.4418 (C:5.6073, R:0.0100, T:0.4408)
Val Loss:   1.8178 (C:5.5725, R:0.0099, T:1.8169)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 55 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4362 (C:5.5853, R:0.0099, T:0.4352(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4137 (C:5.5949, R:0.0100, T:0.4127(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4264 (C:5.6240, R:0.0099, T:0.4254(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4568 (C:5.6245, R:0.0100, T:0.4558(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4306 (C:5.6099, R:0.0100, T:0.4296(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4364 (C:5.6018, R:0.0099, T:0.4355(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4262 (C:5.6047, R:0.0099, T:0.4252(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4493 (C:5.6089, R:0.0100, T:0.4483(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4444 (C:5.5801, R:0.0100, T:0.4434(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4476 (C:5.6259, R:0.0099, T:0.4466(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4489 (C:5.5912, R:0.0099, T:0.4479(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4369 (C:5.5756, R:0.0100, T:0.4359(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4524 (C:5.6061, R:0.0100, T:0.4514(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4173 (C:5.5958, R:0.0099, T:0.4163(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4327 (C:5.6186, R:0.0099, T:0.4317(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4315 (C:5.6217, R:0.0100, T:0.4305(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4550 (C:5.6247, R:0.0100, T:0.4540(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4610 (C:5.6191, R:0.0100, T:0.4600(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4197 (C:5.5963, R:0.0100, T:0.4187(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4478 (C:5.5993, R:0.0099, T:0.4468(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4367 (C:5.5637, R:0.0100, T:0.4357(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4423 (C:5.6071, R:0.0099, T:0.4413(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4399

ğŸ“Š EPOCH 55 TRAINING SUMMARY:
  Total Loss: 0.4409
  Contrastive: 5.6069
  Reconstruction: 0.0100
  Topological: 0.4399 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.7754
  Contrastive: 5.5939
  Reconstruction: 0.0099
  Topological: 1.7745 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 55/300 COMPLETE (48.7s)
Train Loss: 0.4409 (C:5.6069, R:0.0100, T:0.4399)
Val Loss:   1.7754 (C:5.5939, R:0.0099, T:1.7745)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 56 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4292 (C:5.6004, R:0.0100, T:0.4282(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4332 (C:5.5849, R:0.0100, T:0.4322(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4270 (C:5.6225, R:0.0100, T:0.4260(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4398 (C:5.5774, R:0.0099, T:0.4388(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4273 (C:5.5963, R:0.0099, T:0.4263(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4248 (C:5.5915, R:0.0099, T:0.4238(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4242 (C:5.6007, R:0.0100, T:0.4233(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4363 (C:5.6446, R:0.0100, T:0.4353(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4420 (C:5.5719, R:0.0099, T:0.4410(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4397 (C:5.6223, R:0.0100, T:0.4387(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4349 (C:5.6314, R:0.0099, T:0.4339(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4518 (C:5.5795, R:0.0099, T:0.4508(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4501 (C:5.5914, R:0.0100, T:0.4491(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4142 (C:5.6237, R:0.0099, T:0.4132(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4456 (C:5.6026, R:0.0100, T:0.4446(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4379 (C:5.6213, R:0.0100, T:0.4369(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4429 (C:5.6185, R:0.0100, T:0.4419(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4294 (C:5.6055, R:0.0099, T:0.4284(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4415 (C:5.6119, R:0.0100, T:0.4405(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4457 (C:5.5997, R:0.0099, T:0.4447(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4254 (C:5.5864, R:0.0100, T:0.4244(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4261 (C:5.6041, R:0.0100, T:0.4251(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4381

ğŸ“Š EPOCH 56 TRAINING SUMMARY:
  Total Loss: 0.4391
  Contrastive: 5.6080
  Reconstruction: 0.0100
  Topological: 0.4381 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.7775
  Contrastive: 5.5720
  Reconstruction: 0.0099
  Topological: 1.7765 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 56/300 COMPLETE (48.8s)
Train Loss: 0.4391 (C:5.6080, R:0.0100, T:0.4381)
Val Loss:   1.7775 (C:5.5720, R:0.0099, T:1.7765)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 57 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4238 (C:5.5799, R:0.0100, T:0.4228(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4172 (C:5.5935, R:0.0100, T:0.4162(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4397 (C:5.6115, R:0.0100, T:0.4387(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4338 (C:5.5657, R:0.0099, T:0.4328(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4342 (C:5.6002, R:0.0099, T:0.4332(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4440 (C:5.6013, R:0.0100, T:0.4430(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4260 (C:5.5743, R:0.0100, T:0.4250(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4417 (C:5.6097, R:0.0099, T:0.4407(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4384 (C:5.6240, R:0.0100, T:0.4374(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4382 (C:5.6253, R:0.0099, T:0.4372(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4399 (C:5.6309, R:0.0100, T:0.4389(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.3997 (C:5.5612, R:0.0100, T:0.3987(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4198 (C:5.6039, R:0.0099, T:0.4188(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4387 (C:5.6501, R:0.0100, T:0.4377(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4360 (C:5.5889, R:0.0099, T:0.4350(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4176 (C:5.6147, R:0.0100, T:0.4166(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4386 (C:5.5990, R:0.0100, T:0.4376(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4332 (C:5.5716, R:0.0100, T:0.4322(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4396 (C:5.6062, R:0.0100, T:0.4386(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4350 (C:5.6285, R:0.0099, T:0.4340(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4378 (C:5.6248, R:0.0100, T:0.4368(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4577 (C:5.5971, R:0.0100, T:0.4568(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 57 TRAINING SUMMARY:
  Total Loss: 0.4395
  Contrastive: 5.6073
  Reconstruction: 0.0100
  Topological: 0.4385 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.7526
  Contrastive: 5.5842
  Reconstruction: 0.0099
  Topological: 1.7516 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 57/300 COMPLETE (49.7s)
Train Loss: 0.4395 (C:5.6073, R:0.0100, T:0.4385)
Val Loss:   1.7526 (C:5.5842, R:0.0099, T:1.7516)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 58 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4705 (C:5.6007, R:0.0099, T:0.4695(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4584 (C:5.5903, R:0.0099, T:0.4574(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4516 (C:5.5944, R:0.0100, T:0.4506(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4311 (C:5.6409, R:0.0100, T:0.4301(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4458 (C:5.6049, R:0.0100, T:0.4448(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4499 (C:5.6463, R:0.0099, T:0.4489(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4292 (C:5.5666, R:0.0099, T:0.4282(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4418 (C:5.6124, R:0.0100, T:0.4408(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4572 (C:5.5999, R:0.0099, T:0.4563(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4090 (C:5.6336, R:0.0100, T:0.4080(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4316 (C:5.6273, R:0.0099, T:0.4306(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4249 (C:5.5908, R:0.0100, T:0.4239(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4659 (C:5.6359, R:0.0100, T:0.4649(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4504 (C:5.5944, R:0.0099, T:0.4494(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4265 (C:5.6179, R:0.0100, T:0.4255(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4331 (C:5.6076, R:0.0100, T:0.4321(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4234 (C:5.5833, R:0.0099, T:0.4224(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4236 (C:5.5917, R:0.0099, T:0.4227(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4440 (C:5.5853, R:0.0100, T:0.4430(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4281 (C:5.6098, R:0.0100, T:0.4271(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4416 (C:5.6226, R:0.0100, T:0.4406(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4420 (C:5.6042, R:0.0099, T:0.4410(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4368

ğŸ“Š EPOCH 58 TRAINING SUMMARY:
  Total Loss: 0.4378
  Contrastive: 5.6076
  Reconstruction: 0.0100
  Topological: 0.4368 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.8649
  Contrastive: 5.5618
  Reconstruction: 0.0099
  Topological: 1.8639 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 58/300 COMPLETE (49.3s)
Train Loss: 0.4378 (C:5.6076, R:0.0100, T:0.4368)
Val Loss:   1.8649 (C:5.5618, R:0.0099, T:1.8639)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 59 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4119 (C:5.5747, R:0.0099, T:0.4109(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4448 (C:5.6210, R:0.0099, T:0.4439(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4415 (C:5.5708, R:0.0099, T:0.4405(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4633 (C:5.6396, R:0.0100, T:0.4623(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4521 (C:5.5873, R:0.0099, T:0.4511(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4416 (C:5.6213, R:0.0099, T:0.4406(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4309 (C:5.6400, R:0.0099, T:0.4300(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4269 (C:5.5909, R:0.0099, T:0.4259(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4285 (C:5.6227, R:0.0099, T:0.4275(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4490 (C:5.6239, R:0.0100, T:0.4480(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4377 (C:5.5837, R:0.0100, T:0.4367(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4374 (C:5.5968, R:0.0099, T:0.4364(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4296 (C:5.6202, R:0.0099, T:0.4286(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4337 (C:5.5942, R:0.0099, T:0.4327(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4594 (C:5.6146, R:0.0100, T:0.4584(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4510 (C:5.6031, R:0.0100, T:0.4500(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4611 (C:5.5873, R:0.0099, T:0.4601(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4284 (C:5.6165, R:0.0100, T:0.4274(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4277 (C:5.6025, R:0.0099, T:0.4267(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4478 (C:5.6063, R:0.0099, T:0.4468(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4326 (C:5.6016, R:0.0099, T:0.4316(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4400 (C:5.6172, R:0.0099, T:0.4390(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4357

ğŸ“Š EPOCH 59 TRAINING SUMMARY:
  Total Loss: 0.4367
  Contrastive: 5.6064
  Reconstruction: 0.0100
  Topological: 0.4357 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.7448
  Contrastive: 5.6092
  Reconstruction: 0.0099
  Topological: 1.7438 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 59/300 COMPLETE (49.4s)
Train Loss: 0.4367 (C:5.6064, R:0.0100, T:0.4357)
Val Loss:   1.7448 (C:5.6092, R:0.0099, T:1.7438)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 60 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4267 (C:5.6008, R:0.0099, T:0.4257(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4448 (C:5.6056, R:0.0099, T:0.4438(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4485 (C:5.6262, R:0.0099, T:0.4475(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4346 (C:5.6149, R:0.0099, T:0.4336(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4324 (C:5.6344, R:0.0100, T:0.4314(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4410 (C:5.5917, R:0.0099, T:0.4400(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4270 (C:5.6221, R:0.0099, T:0.4260(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4260 (C:5.6085, R:0.0099, T:0.4250(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4345 (C:5.5825, R:0.0099, T:0.4335(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4562 (C:5.5533, R:0.0100, T:0.4552(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4398 (C:5.6034, R:0.0099, T:0.4388(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4336 (C:5.6219, R:0.0100, T:0.4326(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4203 (C:5.6205, R:0.0099, T:0.4193(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4682 (C:5.5909, R:0.0099, T:0.4672(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4502 (C:5.5680, R:0.0099, T:0.4492(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4204 (C:5.6212, R:0.0099, T:0.4194(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4317 (C:5.5998, R:0.0099, T:0.4307(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4202 (C:5.6016, R:0.0100, T:0.4192(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4582 (C:5.6177, R:0.0100, T:0.4572(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4386 (C:5.6291, R:0.0100, T:0.4376(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4280 (C:5.5951, R:0.0100, T:0.4270(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4203 (C:5.5735, R:0.0100, T:0.4193(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4356

ğŸ“Š EPOCH 60 TRAINING SUMMARY:
  Total Loss: 0.4366
  Contrastive: 5.6090
  Reconstruction: 0.0100
  Topological: 0.4356 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.6771
  Contrastive: 5.6302
  Reconstruction: 0.0099
  Topological: 1.6761 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 60/300 COMPLETE (50.1s)
Train Loss: 0.4366 (C:5.6090, R:0.0100, T:0.4356)
Val Loss:   1.6771 (C:5.6302, R:0.0099, T:1.6761)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 61 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4238 (C:5.6234, R:0.0100, T:0.4228(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4148 (C:5.5992, R:0.0099, T:0.4138(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4528 (C:5.6147, R:0.0099, T:0.4518(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4297 (C:5.6478, R:0.0100, T:0.4287(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4352 (C:5.6185, R:0.0100, T:0.4342(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4310 (C:5.6187, R:0.0100, T:0.4300(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4774 (C:5.5979, R:0.0100, T:0.4764(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4175 (C:5.6197, R:0.0100, T:0.4165(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4760 (C:5.6267, R:0.0099, T:0.4750(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4348 (C:5.6390, R:0.0099, T:0.4338(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4249 (C:5.6476, R:0.0100, T:0.4239(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4332 (C:5.6163, R:0.0099, T:0.4322(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4517 (C:5.5690, R:0.0099, T:0.4507(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4427 (C:5.6341, R:0.0100, T:0.4417(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4191 (C:5.6099, R:0.0099, T:0.4181(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4465 (C:5.5932, R:0.0100, T:0.4455(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4104 (C:5.6005, R:0.0099, T:0.4094(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4465 (C:5.6038, R:0.0099, T:0.4455(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4347 (C:5.6215, R:0.0100, T:0.4338(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4352 (C:5.5978, R:0.0100, T:0.4342(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4277 (C:5.5770, R:0.0099, T:0.4268(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4287 (C:5.5988, R:0.0099, T:0.4278(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4343

ğŸ“Š EPOCH 61 TRAINING SUMMARY:
  Total Loss: 0.4353
  Contrastive: 5.6076
  Reconstruction: 0.0100
  Topological: 0.4343 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.7336
  Contrastive: 5.6134
  Reconstruction: 0.0099
  Topological: 1.7326 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 61/300 COMPLETE (49.8s)
Train Loss: 0.4353 (C:5.6076, R:0.0100, T:0.4343)
Val Loss:   1.7336 (C:5.6134, R:0.0099, T:1.7326)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 62 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4106 (C:5.6200, R:0.0100, T:0.4096(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4176 (C:5.6093, R:0.0100, T:0.4166(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4208 (C:5.6084, R:0.0099, T:0.4198(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4095 (C:5.6322, R:0.0100, T:0.4085(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4293 (C:5.5971, R:0.0100, T:0.4283(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4488 (C:5.6318, R:0.0100, T:0.4478(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4279 (C:5.5565, R:0.0099, T:0.4269(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4343 (C:5.6232, R:0.0099, T:0.4333(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4251 (C:5.6139, R:0.0099, T:0.4241(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4266 (C:5.6032, R:0.0100, T:0.4256(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4513 (C:5.6079, R:0.0100, T:0.4503(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4591 (C:5.5882, R:0.0100, T:0.4581(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4077 (C:5.5914, R:0.0099, T:0.4067(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4196 (C:5.6026, R:0.0100, T:0.4186(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4533 (C:5.5707, R:0.0099, T:0.4523(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4379 (C:5.6053, R:0.0099, T:0.4369(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4208 (C:5.6124, R:0.0100, T:0.4198(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4538 (C:5.6690, R:0.0100, T:0.4528(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4542 (C:5.5703, R:0.0100, T:0.4532(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4333 (C:5.6353, R:0.0100, T:0.4323(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4292 (C:5.6062, R:0.0099, T:0.4282(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4301 (C:5.6100, R:0.0100, T:0.4291(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4334

ğŸ“Š EPOCH 62 TRAINING SUMMARY:
  Total Loss: 0.4344
  Contrastive: 5.6085
  Reconstruction: 0.0100
  Topological: 0.4334 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.7145
  Contrastive: 5.5905
  Reconstruction: 0.0099
  Topological: 1.7135 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 62/300 COMPLETE (47.0s)
Train Loss: 0.4344 (C:5.6085, R:0.0100, T:0.4334)
Val Loss:   1.7145 (C:5.5905, R:0.0099, T:1.7135)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 63 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4348 (C:5.5884, R:0.0099, T:0.4339(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4293 (C:5.6217, R:0.0099, T:0.4283(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4395 (C:5.5783, R:0.0099, T:0.4385(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4231 (C:5.6296, R:0.0100, T:0.4221(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4360 (C:5.6098, R:0.0099, T:0.4350(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4187 (C:5.5885, R:0.0099, T:0.4177(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4445 (C:5.6201, R:0.0099, T:0.4435(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4119 (C:5.6421, R:0.0100, T:0.4109(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4375 (C:5.5725, R:0.0100, T:0.4365(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4116 (C:5.6056, R:0.0099, T:0.4107(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4497 (C:5.6217, R:0.0099, T:0.4487(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4163 (C:5.5957, R:0.0100, T:0.4153(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4371 (C:5.5993, R:0.0100, T:0.4361(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4416 (C:5.5682, R:0.0099, T:0.4406(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4329 (C:5.6298, R:0.0100, T:0.4319(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4172 (C:5.6008, R:0.0099, T:0.4163(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4317 (C:5.6059, R:0.0099, T:0.4307(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4409 (C:5.5939, R:0.0099, T:0.4399(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4262 (C:5.6197, R:0.0100, T:0.4252(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4261 (C:5.6110, R:0.0099, T:0.4251(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4078 (C:5.6035, R:0.0100, T:0.4069(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4353 (C:5.6159, R:0.0099, T:0.4343(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4333

ğŸ“Š EPOCH 63 TRAINING SUMMARY:
  Total Loss: 0.4343
  Contrastive: 5.6068
  Reconstruction: 0.0100
  Topological: 0.4333 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.7018
  Contrastive: 5.6006
  Reconstruction: 0.0099
  Topological: 1.7008 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 63/300 COMPLETE (46.8s)
Train Loss: 0.4343 (C:5.6068, R:0.0100, T:0.4333)
Val Loss:   1.7018 (C:5.6006, R:0.0099, T:1.7008)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 64 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4551 (C:5.5920, R:0.0099, T:0.4541(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4358 (C:5.6073, R:0.0100, T:0.4348(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4255 (C:5.5833, R:0.0100, T:0.4245(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4111 (C:5.6277, R:0.0100, T:0.4101(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4227 (C:5.6278, R:0.0100, T:0.4217(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4533 (C:5.5836, R:0.0100, T:0.4523(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4139 (C:5.5962, R:0.0099, T:0.4129(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4123 (C:5.6110, R:0.0100, T:0.4113(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4307 (C:5.5954, R:0.0099, T:0.4297(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4279 (C:5.6067, R:0.0100, T:0.4269(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4296 (C:5.6054, R:0.0100, T:0.4286(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4255 (C:5.6054, R:0.0100, T:0.4245(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4332 (C:5.6157, R:0.0099, T:0.4322(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4400 (C:5.6207, R:0.0099, T:0.4390(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4208 (C:5.6058, R:0.0100, T:0.4198(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4261 (C:5.5897, R:0.0100, T:0.4251(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4190 (C:5.5896, R:0.0100, T:0.4180(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4160 (C:5.6313, R:0.0099, T:0.4150(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4218 (C:5.5959, R:0.0099, T:0.4208(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4164 (C:5.5934, R:0.0099, T:0.4154(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4373 (C:5.5874, R:0.0100, T:0.4363(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4385 (C:5.6468, R:0.0100, T:0.4375(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4322

ğŸ“Š EPOCH 64 TRAINING SUMMARY:
  Total Loss: 0.4332
  Contrastive: 5.6088
  Reconstruction: 0.0100
  Topological: 0.4322 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.6313
  Contrastive: 5.6543
  Reconstruction: 0.0099
  Topological: 1.6303 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 64/300 COMPLETE (50.2s)
Train Loss: 0.4332 (C:5.6088, R:0.0100, T:0.4322)
Val Loss:   1.6313 (C:5.6543, R:0.0099, T:1.6303)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 65 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4317 (C:5.6259, R:0.0100, T:0.4307(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4083 (C:5.5883, R:0.0099, T:0.4073(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4318 (C:5.6716, R:0.0100, T:0.4308(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4287 (C:5.6100, R:0.0099, T:0.4278(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4360 (C:5.6158, R:0.0100, T:0.4350(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4294 (C:5.6111, R:0.0100, T:0.4284(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4555 (C:5.5240, R:0.0099, T:0.4545(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4656 (C:5.6325, R:0.0099, T:0.4647(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4108 (C:5.6157, R:0.0099, T:0.4098(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4181 (C:5.6082, R:0.0100, T:0.4171(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4378 (C:5.5958, R:0.0100, T:0.4368(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4394 (C:5.5753, R:0.0099, T:0.4385(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4403 (C:5.5781, R:0.0099, T:0.4393(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4312 (C:5.5875, R:0.0099, T:0.4302(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4132 (C:5.6223, R:0.0099, T:0.4122(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4316 (C:5.6229, R:0.0100, T:0.4306(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4156 (C:5.5847, R:0.0099, T:0.4146(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4402 (C:5.6308, R:0.0100, T:0.4392(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4423 (C:5.6452, R:0.0099, T:0.4413(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4306 (C:5.5560, R:0.0100, T:0.4296(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4404 (C:5.5968, R:0.0099, T:0.4394(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4350 (C:5.6336, R:0.0100, T:0.4340(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4318

ğŸ“Š EPOCH 65 TRAINING SUMMARY:
  Total Loss: 0.4328
  Contrastive: 5.6077
  Reconstruction: 0.0100
  Topological: 0.4318 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.8363
  Contrastive: 5.5525
  Reconstruction: 0.0099
  Topological: 1.8353 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 65/300 COMPLETE (51.8s)
Train Loss: 0.4328 (C:5.6077, R:0.0100, T:0.4318)
Val Loss:   1.8363 (C:5.5525, R:0.0099, T:1.8353)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 66 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4371 (C:5.5762, R:0.0100, T:0.4361(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4259 (C:5.6297, R:0.0100, T:0.4249(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4508 (C:5.6259, R:0.0100, T:0.4498(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4217 (C:5.6143, R:0.0100, T:0.4207(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4481 (C:5.6298, R:0.0100, T:0.4471(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4142 (C:5.6227, R:0.0099, T:0.4132(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4145 (C:5.6197, R:0.0100, T:0.4135(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4053 (C:5.6012, R:0.0100, T:0.4043(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4404 (C:5.5724, R:0.0099, T:0.4394(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4516 (C:5.6153, R:0.0099, T:0.4506(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4395 (C:5.5896, R:0.0099, T:0.4385(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4107 (C:5.6241, R:0.0100, T:0.4097(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4300 (C:5.6077, R:0.0099, T:0.4290(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4388 (C:5.5805, R:0.0099, T:0.4378(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4351 (C:5.6165, R:0.0100, T:0.4341(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4225 (C:5.5822, R:0.0099, T:0.4215(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4512 (C:5.6152, R:0.0100, T:0.4502(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4274 (C:5.5864, R:0.0099, T:0.4264(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4614 (C:5.6065, R:0.0099, T:0.4604(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4125 (C:5.6241, R:0.0100, T:0.4115(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4436 (C:5.6088, R:0.0099, T:0.4426(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4290 (C:5.6248, R:0.0100, T:0.4280(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4305

ğŸ“Š EPOCH 66 TRAINING SUMMARY:
  Total Loss: 0.4315
  Contrastive: 5.6096
  Reconstruction: 0.0100
  Topological: 0.4305 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.6909
  Contrastive: 5.6258
  Reconstruction: 0.0099
  Topological: 1.6899 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 66/300 COMPLETE (49.8s)
Train Loss: 0.4315 (C:5.6096, R:0.0100, T:0.4305)
Val Loss:   1.6909 (C:5.6258, R:0.0099, T:1.6899)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 67 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4132 (C:5.6220, R:0.0099, T:0.4122(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4360 (C:5.6164, R:0.0100, T:0.4350(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4243 (C:5.5679, R:0.0099, T:0.4233(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4434 (C:5.6440, R:0.0100, T:0.4424(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4126 (C:5.6081, R:0.0099, T:0.4116(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4387 (C:5.6039, R:0.0100, T:0.4377(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.3752 (C:5.5917, R:0.0099, T:0.3742(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4439 (C:5.5986, R:0.0100, T:0.4430(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4414 (C:5.5989, R:0.0099, T:0.4404(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4479 (C:5.6105, R:0.0099, T:0.4469(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4400 (C:5.6117, R:0.0100, T:0.4390(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4276 (C:5.6120, R:0.0100, T:0.4266(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4283 (C:5.5961, R:0.0099, T:0.4273(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4225 (C:5.5986, R:0.0099, T:0.4215(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4292 (C:5.6128, R:0.0100, T:0.4282(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4279 (C:5.6044, R:0.0100, T:0.4269(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4295 (C:5.6011, R:0.0100, T:0.4285(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4282 (C:5.5929, R:0.0099, T:0.4272(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4367 (C:5.6343, R:0.0100, T:0.4357(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4399 (C:5.6282, R:0.0100, T:0.4389(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4161 (C:5.6417, R:0.0099, T:0.4151(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4136 (C:5.5784, R:0.0099, T:0.4126(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4302

ğŸ“Š EPOCH 67 TRAINING SUMMARY:
  Total Loss: 0.4312
  Contrastive: 5.6102
  Reconstruction: 0.0100
  Topological: 0.4302 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.6688
  Contrastive: 5.6250
  Reconstruction: 0.0099
  Topological: 1.6678 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 67/300 COMPLETE (49.7s)
Train Loss: 0.4312 (C:5.6102, R:0.0100, T:0.4302)
Val Loss:   1.6688 (C:5.6250, R:0.0099, T:1.6678)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 68 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4298 (C:5.6299, R:0.0100, T:0.4289(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4149 (C:5.5932, R:0.0100, T:0.4139(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4482 (C:5.6406, R:0.0100, T:0.4472(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4382 (C:5.6316, R:0.0099, T:0.4372(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4232 (C:5.6243, R:0.0100, T:0.4222(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4339 (C:5.6259, R:0.0100, T:0.4329(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4265 (C:5.5919, R:0.0100, T:0.4255(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4138 (C:5.6091, R:0.0100, T:0.4128(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4480 (C:5.5705, R:0.0100, T:0.4470(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4349 (C:5.6363, R:0.0099, T:0.4339(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4358 (C:5.5703, R:0.0099, T:0.4348(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4302 (C:5.6301, R:0.0100, T:0.4292(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4294 (C:5.6260, R:0.0100, T:0.4284(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4135 (C:5.6156, R:0.0100, T:0.4125(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4258 (C:5.6270, R:0.0099, T:0.4248(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4374 (C:5.5981, R:0.0099, T:0.4364(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4178 (C:5.5539, R:0.0099, T:0.4168(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4247 (C:5.6097, R:0.0099, T:0.4237(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4345 (C:5.5851, R:0.0099, T:0.4335(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4471 (C:5.5909, R:0.0099, T:0.4461(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4149 (C:5.6217, R:0.0099, T:0.4139(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4447 (C:5.5895, R:0.0100, T:0.4437(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4270

ğŸ“Š EPOCH 68 TRAINING SUMMARY:
  Total Loss: 0.4280
  Contrastive: 5.6106
  Reconstruction: 0.0100
  Topological: 0.4270 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.6739
  Contrastive: 5.6142
  Reconstruction: 0.0099
  Topological: 1.6729 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 68/300 COMPLETE (48.2s)
Train Loss: 0.4280 (C:5.6106, R:0.0100, T:0.4270)
Val Loss:   1.6739 (C:5.6142, R:0.0099, T:1.6729)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 69 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4336 (C:5.6103, R:0.0100, T:0.4326(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4226 (C:5.5736, R:0.0100, T:0.4216(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4256 (C:5.5865, R:0.0099, T:0.4246(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4265 (C:5.6177, R:0.0100, T:0.4255(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4086 (C:5.6392, R:0.0099, T:0.4076(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4032 (C:5.6156, R:0.0099, T:0.4022(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4266 (C:5.6039, R:0.0100, T:0.4256(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4258 (C:5.6016, R:0.0100, T:0.4248(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4518 (C:5.6243, R:0.0099, T:0.4508(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4307 (C:5.6355, R:0.0099, T:0.4297(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4206 (C:5.5719, R:0.0099, T:0.4196(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4409 (C:5.5948, R:0.0100, T:0.4399(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4334 (C:5.5923, R:0.0100, T:0.4324(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4315 (C:5.6093, R:0.0100, T:0.4305(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4083 (C:5.6150, R:0.0099, T:0.4073(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4175 (C:5.6163, R:0.0099, T:0.4165(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4334 (C:5.6429, R:0.0100, T:0.4324(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4279 (C:5.6131, R:0.0100, T:0.4269(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4270 (C:5.6179, R:0.0100, T:0.4260(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4160 (C:5.5594, R:0.0099, T:0.4150(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4237 (C:5.5901, R:0.0100, T:0.4227(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4458 (C:5.5919, R:0.0099, T:0.4448(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 69 TRAINING SUMMARY:
  Total Loss: 0.4288
  Contrastive: 5.6108
  Reconstruction: 0.0100
  Topological: 0.4278 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.6888
  Contrastive: 5.6074
  Reconstruction: 0.0099
  Topological: 1.6878 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 69/300 COMPLETE (50.3s)
Train Loss: 0.4288 (C:5.6108, R:0.0100, T:0.4278)
Val Loss:   1.6888 (C:5.6074, R:0.0099, T:1.6878)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 70 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4130 (C:5.6097, R:0.0100, T:0.4121(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4299 (C:5.5999, R:0.0100, T:0.4289(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4118 (C:5.6342, R:0.0099, T:0.4108(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4205 (C:5.5999, R:0.0100, T:0.4195(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4305 (C:5.5857, R:0.0099, T:0.4295(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4422 (C:5.6003, R:0.0100, T:0.4412(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4170 (C:5.6165, R:0.0099, T:0.4160(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4148 (C:5.6262, R:0.0099, T:0.4138(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4106 (C:5.6244, R:0.0099, T:0.4097(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4235 (C:5.6274, R:0.0100, T:0.4225(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4099 (C:5.6195, R:0.0100, T:0.4089(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4095 (C:5.6121, R:0.0100, T:0.4085(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4274 (C:5.5806, R:0.0099, T:0.4264(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4430 (C:5.6197, R:0.0100, T:0.4420(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4259 (C:5.6260, R:0.0100, T:0.4249(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4265 (C:5.6044, R:0.0100, T:0.4255(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4226 (C:5.5996, R:0.0100, T:0.4216(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4279 (C:5.5910, R:0.0099, T:0.4269(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4353 (C:5.6292, R:0.0099, T:0.4343(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4111 (C:5.6295, R:0.0099, T:0.4101(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4340 (C:5.6173, R:0.0100, T:0.4330(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4232 (C:5.5959, R:0.0100, T:0.4222(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4250

ğŸ“Š EPOCH 70 TRAINING SUMMARY:
  Total Loss: 0.4260
  Contrastive: 5.6115
  Reconstruction: 0.0100
  Topological: 0.4250 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.6777
  Contrastive: 5.6195
  Reconstruction: 0.0099
  Topological: 1.6767 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 70/300 COMPLETE (51.0s)
Train Loss: 0.4260 (C:5.6115, R:0.0100, T:0.4250)
Val Loss:   1.6777 (C:5.6195, R:0.0099, T:1.6767)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 71 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4418 (C:5.6145, R:0.0100, T:0.4408(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4227 (C:5.6677, R:0.0100, T:0.4217(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4487 (C:5.6248, R:0.0100, T:0.4477(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4489 (C:5.6124, R:0.0099, T:0.4479(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4325 (C:5.6371, R:0.0099, T:0.4315(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4346 (C:5.6261, R:0.0100, T:0.4336(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4238 (C:5.6020, R:0.0100, T:0.4228(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4390 (C:5.6282, R:0.0099, T:0.4380(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4447 (C:5.6249, R:0.0100, T:0.4437(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4277 (C:5.5990, R:0.0100, T:0.4267(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4225 (C:5.6140, R:0.0099, T:0.4215(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4074 (C:5.5806, R:0.0099, T:0.4064(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4490 (C:5.5845, R:0.0099, T:0.4480(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4269 (C:5.6221, R:0.0099, T:0.4259(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4192 (C:5.6434, R:0.0100, T:0.4182(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4237 (C:5.6084, R:0.0100, T:0.4227(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4486 (C:5.6023, R:0.0099, T:0.4477(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4142 (C:5.6105, R:0.0100, T:0.4132(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4346 (C:5.5825, R:0.0100, T:0.4336(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4344 (C:5.6245, R:0.0100, T:0.4334(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4420 (C:5.6112, R:0.0100, T:0.4410(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4382 (C:5.6227, R:0.0100, T:0.4372(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 71 TRAINING SUMMARY:
  Total Loss: 0.4278
  Contrastive: 5.6135
  Reconstruction: 0.0100
  Topological: 0.4268 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.6616
  Contrastive: 5.6198
  Reconstruction: 0.0099
  Topological: 1.6606 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 71/300 COMPLETE (51.2s)
Train Loss: 0.4278 (C:5.6135, R:0.0100, T:0.4268)
Val Loss:   1.6616 (C:5.6198, R:0.0099, T:1.6606)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 72 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4222 (C:5.5973, R:0.0100, T:0.4213(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4203 (C:5.5981, R:0.0099, T:0.4193(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4215 (C:5.5927, R:0.0100, T:0.4205(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4446 (C:5.6097, R:0.0099, T:0.4436(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4277 (C:5.6241, R:0.0099, T:0.4267(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4434 (C:5.6226, R:0.0100, T:0.4424(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4202 (C:5.5981, R:0.0099, T:0.4192(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4304 (C:5.6188, R:0.0099, T:0.4294(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4259 (C:5.6065, R:0.0099, T:0.4249(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4084 (C:5.6168, R:0.0100, T:0.4074(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4384 (C:5.6380, R:0.0099, T:0.4374(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4208 (C:5.5503, R:0.0099, T:0.4198(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4123 (C:5.6130, R:0.0100, T:0.4113(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4325 (C:5.5961, R:0.0099, T:0.4315(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4030 (C:5.6120, R:0.0099, T:0.4020(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4281 (C:5.6140, R:0.0100, T:0.4271(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4247 (C:5.6098, R:0.0100, T:0.4238(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4535 (C:5.5891, R:0.0099, T:0.4525(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4171 (C:5.6081, R:0.0100, T:0.4161(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4252 (C:5.5939, R:0.0100, T:0.4242(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4297 (C:5.5937, R:0.0099, T:0.4287(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4254 (C:5.6266, R:0.0099, T:0.4244(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 72 TRAINING SUMMARY:
  Total Loss: 0.4277
  Contrastive: 5.6118
  Reconstruction: 0.0100
  Topological: 0.4267 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.4734
  Contrastive: 5.7111
  Reconstruction: 0.0099
  Topological: 1.4724 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 72/300 COMPLETE (50.9s)
Train Loss: 0.4277 (C:5.6118, R:0.0100, T:0.4267)
Val Loss:   1.4734 (C:5.7111, R:0.0099, T:1.4724)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 73 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4454 (C:5.6643, R:0.0099, T:0.4444(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4365 (C:5.6145, R:0.0099, T:0.4355(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4363 (C:5.6082, R:0.0100, T:0.4353(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4245 (C:5.6129, R:0.0100, T:0.4235(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4123 (C:5.6120, R:0.0100, T:0.4113(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.3960 (C:5.6041, R:0.0099, T:0.3950(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4444 (C:5.6075, R:0.0099, T:0.4434(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4381 (C:5.5991, R:0.0099, T:0.4372(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4345 (C:5.6299, R:0.0100, T:0.4335(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4261 (C:5.6139, R:0.0099, T:0.4252(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4384 (C:5.6095, R:0.0099, T:0.4375(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4305 (C:5.6133, R:0.0099, T:0.4295(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4556 (C:5.5533, R:0.0100, T:0.4546(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4232 (C:5.5756, R:0.0099, T:0.4222(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4287 (C:5.6494, R:0.0100, T:0.4277(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4277 (C:5.6135, R:0.0099, T:0.4268(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4197 (C:5.6201, R:0.0100, T:0.4187(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4270 (C:5.6460, R:0.0099, T:0.4260(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4231 (C:5.6138, R:0.0099, T:0.4221(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4095 (C:5.6506, R:0.0100, T:0.4085(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4060 (C:5.6160, R:0.0100, T:0.4050(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4176 (C:5.6332, R:0.0100, T:0.4166(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4246

ğŸ“Š EPOCH 73 TRAINING SUMMARY:
  Total Loss: 0.4256
  Contrastive: 5.6126
  Reconstruction: 0.0100
  Topological: 0.4246 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.5521
  Contrastive: 5.6623
  Reconstruction: 0.0099
  Topological: 1.5511 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 73/300 COMPLETE (48.3s)
Train Loss: 0.4256 (C:5.6126, R:0.0100, T:0.4246)
Val Loss:   1.5521 (C:5.6623, R:0.0099, T:1.5511)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 74 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4243 (C:5.6268, R:0.0099, T:0.4233(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4414 (C:5.6150, R:0.0099, T:0.4404(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4514 (C:5.6344, R:0.0100, T:0.4504(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4180 (C:5.5994, R:0.0100, T:0.4170(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4120 (C:5.6255, R:0.0100, T:0.4110(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4246 (C:5.5845, R:0.0100, T:0.4236(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4304 (C:5.6230, R:0.0100, T:0.4294(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4081 (C:5.6002, R:0.0100, T:0.4071(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4293 (C:5.6193, R:0.0100, T:0.4283(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4055 (C:5.6205, R:0.0100, T:0.4045(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4205 (C:5.5805, R:0.0100, T:0.4195(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4341 (C:5.6296, R:0.0100, T:0.4331(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4262 (C:5.5951, R:0.0100, T:0.4252(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4195 (C:5.6205, R:0.0100, T:0.4185(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4344 (C:5.6283, R:0.0100, T:0.4334(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4273 (C:5.5999, R:0.0100, T:0.4263(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4358 (C:5.6017, R:0.0099, T:0.4348(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4393 (C:5.6226, R:0.0100, T:0.4383(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4591 (C:5.6152, R:0.0100, T:0.4581(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4075 (C:5.6056, R:0.0099, T:0.4065(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4173 (C:5.5920, R:0.0099, T:0.4163(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4133 (C:5.6053, R:0.0100, T:0.4123(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4245

ğŸ“Š EPOCH 74 TRAINING SUMMARY:
  Total Loss: 0.4255
  Contrastive: 5.6112
  Reconstruction: 0.0100
  Topological: 0.4245 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.5630
  Contrastive: 5.6660
  Reconstruction: 0.0099
  Topological: 1.5620 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 74/300 COMPLETE (47.9s)
Train Loss: 0.4255 (C:5.6112, R:0.0100, T:0.4245)
Val Loss:   1.5630 (C:5.6660, R:0.0099, T:1.5620)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 75 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4184 (C:5.6265, R:0.0099, T:0.4174(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4272 (C:5.6333, R:0.0099, T:0.4262(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4448 (C:5.6190, R:0.0099, T:0.4438(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.3863 (C:5.6166, R:0.0100, T:0.3853(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4376 (C:5.6310, R:0.0099, T:0.4366(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4131 (C:5.5846, R:0.0099, T:0.4121(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4333 (C:5.5754, R:0.0100, T:0.4323(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4308 (C:5.6254, R:0.0099, T:0.4298(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4217 (C:5.6062, R:0.0100, T:0.4207(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4184 (C:5.6474, R:0.0099, T:0.4174(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4540 (C:5.6251, R:0.0100, T:0.4530(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.3979 (C:5.6286, R:0.0099, T:0.3969(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4114 (C:5.6053, R:0.0100, T:0.4104(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4492 (C:5.5801, R:0.0100, T:0.4482(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4147 (C:5.6068, R:0.0100, T:0.4137(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4174 (C:5.6303, R:0.0100, T:0.4164(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4400 (C:5.6218, R:0.0099, T:0.4390(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4130 (C:5.6007, R:0.0100, T:0.4120(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4425 (C:5.5642, R:0.0099, T:0.4415(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4396 (C:5.6078, R:0.0100, T:0.4386(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4112 (C:5.6128, R:0.0099, T:0.4102(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4147 (C:5.6294, R:0.0100, T:0.4137(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4236

ğŸ“Š EPOCH 75 TRAINING SUMMARY:
  Total Loss: 0.4246
  Contrastive: 5.6124
  Reconstruction: 0.0100
  Topological: 0.4236 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.6253
  Contrastive: 5.6368
  Reconstruction: 0.0099
  Topological: 1.6243 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 75/300 COMPLETE (49.0s)
Train Loss: 0.4246 (C:5.6124, R:0.0100, T:0.4236)
Val Loss:   1.6253 (C:5.6368, R:0.0099, T:1.6243)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 76 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.3984 (C:5.6096, R:0.0099, T:0.3974(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4159 (C:5.5739, R:0.0099, T:0.4149(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4274 (C:5.6287, R:0.0100, T:0.4264(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4343 (C:5.6267, R:0.0100, T:0.4333(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4438 (C:5.6291, R:0.0099, T:0.4428(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.3981 (C:5.6352, R:0.0099, T:0.3971(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4242 (C:5.6068, R:0.0099, T:0.4232(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4263 (C:5.6659, R:0.0100, T:0.4253(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4159 (C:5.6116, R:0.0100, T:0.4149(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4447 (C:5.6242, R:0.0099, T:0.4437(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4522 (C:5.6275, R:0.0100, T:0.4512(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4169 (C:5.6417, R:0.0099, T:0.4159(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4319 (C:5.6226, R:0.0099, T:0.4309(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4416 (C:5.6127, R:0.0100, T:0.4406(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4075 (C:5.6150, R:0.0100, T:0.4065(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4318 (C:5.6389, R:0.0099, T:0.4308(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4598 (C:5.6330, R:0.0100, T:0.4588(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4301 (C:5.6338, R:0.0099, T:0.4291(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4265 (C:5.6543, R:0.0100, T:0.4255(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4174 (C:5.6367, R:0.0100, T:0.4164(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4211 (C:5.6683, R:0.0100, T:0.4201(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4477 (C:5.6086, R:0.0100, T:0.4467(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4233

ğŸ“Š EPOCH 76 TRAINING SUMMARY:
  Total Loss: 0.4243
  Contrastive: 5.6126
  Reconstruction: 0.0100
  Topological: 0.4233 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.6030
  Contrastive: 5.6639
  Reconstruction: 0.0099
  Topological: 1.6021 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 76/300 COMPLETE (49.6s)
Train Loss: 0.4243 (C:5.6126, R:0.0100, T:0.4233)
Val Loss:   1.6030 (C:5.6639, R:0.0099, T:1.6021)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 77 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4147 (C:5.6301, R:0.0100, T:0.4137(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4021 (C:5.5897, R:0.0099, T:0.4011(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4277 (C:5.6107, R:0.0100, T:0.4268(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4167 (C:5.6477, R:0.0100, T:0.4157(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4102 (C:5.6443, R:0.0099, T:0.4092(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4221 (C:5.5979, R:0.0100, T:0.4211(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4227 (C:5.5852, R:0.0099, T:0.4217(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4307 (C:5.6059, R:0.0100, T:0.4297(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4064 (C:5.5936, R:0.0099, T:0.4054(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4110 (C:5.6282, R:0.0100, T:0.4100(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4265 (C:5.5907, R:0.0100, T:0.4255(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4241 (C:5.6086, R:0.0099, T:0.4232(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4314 (C:5.6369, R:0.0100, T:0.4304(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4297 (C:5.6326, R:0.0100, T:0.4287(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4106 (C:5.5861, R:0.0100, T:0.4096(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4170 (C:5.6003, R:0.0099, T:0.4160(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4271 (C:5.6008, R:0.0100, T:0.4261(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4256 (C:5.6251, R:0.0100, T:0.4246(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4060 (C:5.6208, R:0.0099, T:0.4050(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4208 (C:5.6055, R:0.0099, T:0.4198(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4133 (C:5.6451, R:0.0100, T:0.4123(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4465 (C:5.5935, R:0.0099, T:0.4455(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4226

ğŸ“Š EPOCH 77 TRAINING SUMMARY:
  Total Loss: 0.4236
  Contrastive: 5.6141
  Reconstruction: 0.0100
  Topological: 0.4226 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.5096
  Contrastive: 5.6874
  Reconstruction: 0.0099
  Topological: 1.5086 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 77/300 COMPLETE (50.2s)
Train Loss: 0.4236 (C:5.6141, R:0.0100, T:0.4226)
Val Loss:   1.5096 (C:5.6874, R:0.0099, T:1.5086)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 78 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4273 (C:5.6528, R:0.0100, T:0.4263(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4181 (C:5.6665, R:0.0099, T:0.4171(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4361 (C:5.5853, R:0.0100, T:0.4351(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4044 (C:5.5834, R:0.0100, T:0.4034(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4029 (C:5.6273, R:0.0099, T:0.4019(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4084 (C:5.5986, R:0.0099, T:0.4074(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4243 (C:5.6146, R:0.0100, T:0.4233(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.3892 (C:5.6092, R:0.0099, T:0.3882(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4001 (C:5.6002, R:0.0099, T:0.3991(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4320 (C:5.6289, R:0.0100, T:0.4310(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4000 (C:5.6186, R:0.0099, T:0.3990(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4223 (C:5.6549, R:0.0100, T:0.4213(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4362 (C:5.6175, R:0.0099, T:0.4352(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4380 (C:5.6142, R:0.0100, T:0.4370(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4293 (C:5.5821, R:0.0099, T:0.4283(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4485 (C:5.6018, R:0.0100, T:0.4475(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4321 (C:5.6042, R:0.0099, T:0.4311(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4147 (C:5.6185, R:0.0100, T:0.4137(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4468 (C:5.6133, R:0.0100, T:0.4458(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4103 (C:5.6196, R:0.0100, T:0.4093(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4414 (C:5.6267, R:0.0099, T:0.4404(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4133 (C:5.6586, R:0.0100, T:0.4123(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4221

ğŸ“Š EPOCH 78 TRAINING SUMMARY:
  Total Loss: 0.4231
  Contrastive: 5.6126
  Reconstruction: 0.0100
  Topological: 0.4221 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.5265
  Contrastive: 5.6484
  Reconstruction: 0.0099
  Topological: 1.5255 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 78/300 COMPLETE (48.6s)
Train Loss: 0.4231 (C:5.6126, R:0.0100, T:0.4221)
Val Loss:   1.5265 (C:5.6484, R:0.0099, T:1.5255)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 79 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4069 (C:5.6106, R:0.0100, T:0.4059(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4166 (C:5.6266, R:0.0099, T:0.4156(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4093 (C:5.6349, R:0.0100, T:0.4083(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4379 (C:5.5794, R:0.0099, T:0.4369(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4440 (C:5.6360, R:0.0100, T:0.4430(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4270 (C:5.6270, R:0.0099, T:0.4260(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4134 (C:5.6031, R:0.0099, T:0.4124(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4199 (C:5.6264, R:0.0100, T:0.4189(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4368 (C:5.6243, R:0.0099, T:0.4359(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4261 (C:5.6074, R:0.0100, T:0.4251(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4100 (C:5.6261, R:0.0099, T:0.4090(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4478 (C:5.6098, R:0.0099, T:0.4468(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4252 (C:5.5910, R:0.0099, T:0.4242(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4163 (C:5.6038, R:0.0099, T:0.4153(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4139 (C:5.6324, R:0.0100, T:0.4129(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4246 (C:5.6119, R:0.0100, T:0.4236(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4315 (C:5.6444, R:0.0100, T:0.4306(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4301 (C:5.6327, R:0.0100, T:0.4291(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4317 (C:5.5984, R:0.0099, T:0.4307(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4160 (C:5.6359, R:0.0100, T:0.4150(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4220 (C:5.6010, R:0.0100, T:0.4210(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4190 (C:5.6253, R:0.0100, T:0.4180(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4208

ğŸ“Š EPOCH 79 TRAINING SUMMARY:
  Total Loss: 0.4218
  Contrastive: 5.6136
  Reconstruction: 0.0100
  Topological: 0.4208 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.5914
  Contrastive: 5.6223
  Reconstruction: 0.0099
  Topological: 1.5904 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 79/300 COMPLETE (50.2s)
Train Loss: 0.4218 (C:5.6136, R:0.0100, T:0.4208)
Val Loss:   1.5914 (C:5.6223, R:0.0099, T:1.5904)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 80 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4162 (C:5.6030, R:0.0100, T:0.4152(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4235 (C:5.6225, R:0.0099, T:0.4225(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4222 (C:5.6246, R:0.0100, T:0.4212(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4246 (C:5.6281, R:0.0100, T:0.4236(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4271 (C:5.6286, R:0.0100, T:0.4261(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4255 (C:5.6316, R:0.0100, T:0.4245(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4114 (C:5.6001, R:0.0100, T:0.4104(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4375 (C:5.5966, R:0.0099, T:0.4365(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4044 (C:5.5899, R:0.0100, T:0.4034(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.3957 (C:5.6161, R:0.0100, T:0.3947(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4385 (C:5.5969, R:0.0099, T:0.4375(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4460 (C:5.5957, R:0.0100, T:0.4450(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4071 (C:5.6205, R:0.0100, T:0.4061(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4422 (C:5.6238, R:0.0099, T:0.4412(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.3976 (C:5.5997, R:0.0100, T:0.3966(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4582 (C:5.5789, R:0.0100, T:0.4573(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4085 (C:5.6244, R:0.0100, T:0.4075(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4232 (C:5.6185, R:0.0099, T:0.4222(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4289 (C:5.6296, R:0.0099, T:0.4279(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4199 (C:5.6352, R:0.0100, T:0.4189(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4394 (C:5.5932, R:0.0099, T:0.4384(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4091 (C:5.6200, R:0.0099, T:0.4081(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 80 TRAINING SUMMARY:
  Total Loss: 0.4220
  Contrastive: 5.6137
  Reconstruction: 0.0100
  Topological: 0.4210 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.5892
  Contrastive: 5.6370
  Reconstruction: 0.0099
  Topological: 1.5882 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 80/300 COMPLETE (49.8s)
Train Loss: 0.4220 (C:5.6137, R:0.0100, T:0.4210)
Val Loss:   1.5892 (C:5.6370, R:0.0099, T:1.5882)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 81 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4294 (C:5.6090, R:0.0100, T:0.4284(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4205 (C:5.5851, R:0.0099, T:0.4195(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4217 (C:5.5916, R:0.0099, T:0.4207(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4326 (C:5.6288, R:0.0100, T:0.4316(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4300 (C:5.6582, R:0.0099, T:0.4290(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4190 (C:5.6082, R:0.0100, T:0.4180(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4205 (C:5.6143, R:0.0100, T:0.4195(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4401 (C:5.5915, R:0.0099, T:0.4391(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4126 (C:5.6379, R:0.0100, T:0.4116(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4100 (C:5.6295, R:0.0100, T:0.4090(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4305 (C:5.6198, R:0.0100, T:0.4295(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4150 (C:5.6112, R:0.0100, T:0.4140(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.3938 (C:5.6369, R:0.0100, T:0.3928(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4028 (C:5.6273, R:0.0099, T:0.4018(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.3934 (C:5.6120, R:0.0100, T:0.3924(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4229 (C:5.6285, R:0.0100, T:0.4219(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4182 (C:5.5943, R:0.0100, T:0.4172(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4270 (C:5.6281, R:0.0100, T:0.4260(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.3997 (C:5.6282, R:0.0099, T:0.3987(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4089 (C:5.6156, R:0.0099, T:0.4079(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4162 (C:5.6455, R:0.0100, T:0.4152(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4130 (C:5.6109, R:0.0100, T:0.4120(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4192

ğŸ“Š EPOCH 81 TRAINING SUMMARY:
  Total Loss: 0.4202
  Contrastive: 5.6145
  Reconstruction: 0.0100
  Topological: 0.4192 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.6686
  Contrastive: 5.5875
  Reconstruction: 0.0099
  Topological: 1.6676 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 81/300 COMPLETE (49.0s)
Train Loss: 0.4202 (C:5.6145, R:0.0100, T:0.4192)
Val Loss:   1.6686 (C:5.5875, R:0.0099, T:1.6676)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 82 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4183 (C:5.5720, R:0.0099, T:0.4173(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4267 (C:5.5975, R:0.0099, T:0.4257(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4385 (C:5.6025, R:0.0099, T:0.4375(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4282 (C:5.6012, R:0.0099, T:0.4272(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4397 (C:5.6490, R:0.0100, T:0.4387(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.3978 (C:5.5558, R:0.0099, T:0.3968(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4126 (C:5.6493, R:0.0100, T:0.4116(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4341 (C:5.6347, R:0.0100, T:0.4331(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4215 (C:5.5965, R:0.0100, T:0.4205(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4308 (C:5.6448, R:0.0100, T:0.4298(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4003 (C:5.6013, R:0.0099, T:0.3993(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4284 (C:5.5882, R:0.0100, T:0.4274(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4148 (C:5.6073, R:0.0099, T:0.4138(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4091 (C:5.6164, R:0.0100, T:0.4081(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.3933 (C:5.5924, R:0.0099, T:0.3923(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4378 (C:5.6505, R:0.0100, T:0.4368(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.3979 (C:5.5935, R:0.0100, T:0.3970(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4120 (C:5.6410, R:0.0100, T:0.4110(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4175 (C:5.5963, R:0.0099, T:0.4165(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4101 (C:5.5914, R:0.0099, T:0.4091(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4199 (C:5.6250, R:0.0100, T:0.4189(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4002 (C:5.6083, R:0.0100, T:0.3992(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4184

ğŸ“Š EPOCH 82 TRAINING SUMMARY:
  Total Loss: 0.4194
  Contrastive: 5.6144
  Reconstruction: 0.0100
  Topological: 0.4184 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.6780
  Contrastive: 5.5746
  Reconstruction: 0.0099
  Topological: 1.6770 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 82/300 COMPLETE (49.2s)
Train Loss: 0.4194 (C:5.6144, R:0.0100, T:0.4184)
Val Loss:   1.6780 (C:5.5746, R:0.0099, T:1.6770)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 83 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4290 (C:5.5740, R:0.0100, T:0.4280(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4098 (C:5.6167, R:0.0099, T:0.4088(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4183 (C:5.6032, R:0.0100, T:0.4173(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4062 (C:5.6111, R:0.0099, T:0.4052(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.3977 (C:5.5861, R:0.0100, T:0.3967(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4315 (C:5.6184, R:0.0100, T:0.4305(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4141 (C:5.5892, R:0.0100, T:0.4131(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4322 (C:5.6386, R:0.0100, T:0.4312(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4217 (C:5.6036, R:0.0100, T:0.4207(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4028 (C:5.6051, R:0.0099, T:0.4018(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4030 (C:5.6165, R:0.0100, T:0.4020(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4469 (C:5.6199, R:0.0099, T:0.4459(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4301 (C:5.6010, R:0.0100, T:0.4291(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4040 (C:5.6102, R:0.0100, T:0.4030(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4316 (C:5.5737, R:0.0099, T:0.4306(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4238 (C:5.6419, R:0.0100, T:0.4228(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4125 (C:5.6443, R:0.0100, T:0.4115(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4241 (C:5.6500, R:0.0100, T:0.4231(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.3895 (C:5.6300, R:0.0100, T:0.3885(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4030 (C:5.6227, R:0.0099, T:0.4020(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4169 (C:5.6128, R:0.0100, T:0.4159(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4070 (C:5.5830, R:0.0099, T:0.4060(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 83 TRAINING SUMMARY:
  Total Loss: 0.4201
  Contrastive: 5.6138
  Reconstruction: 0.0100
  Topological: 0.4191 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.5789
  Contrastive: 5.6450
  Reconstruction: 0.0099
  Topological: 1.5779 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 83/300 COMPLETE (49.1s)
Train Loss: 0.4201 (C:5.6138, R:0.0100, T:0.4191)
Val Loss:   1.5789 (C:5.6450, R:0.0099, T:1.5779)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 84 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4334 (C:5.6298, R:0.0100, T:0.4324(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4262 (C:5.5969, R:0.0100, T:0.4252(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4106 (C:5.5956, R:0.0099, T:0.4096(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4288 (C:5.6320, R:0.0099, T:0.4278(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4280 (C:5.6035, R:0.0100, T:0.4270(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4428 (C:5.5731, R:0.0100, T:0.4418(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4029 (C:5.6120, R:0.0100, T:0.4019(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4153 (C:5.6162, R:0.0099, T:0.4143(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.3865 (C:5.6039, R:0.0099, T:0.3855(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4104 (C:5.6091, R:0.0100, T:0.4094(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4353 (C:5.6292, R:0.0099, T:0.4343(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4306 (C:5.6253, R:0.0100, T:0.4296(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4136 (C:5.6158, R:0.0100, T:0.4126(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4303 (C:5.6117, R:0.0099, T:0.4293(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4091 (C:5.5875, R:0.0099, T:0.4082(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4224 (C:5.6177, R:0.0100, T:0.4214(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4069 (C:5.6215, R:0.0099, T:0.4059(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4497 (C:5.6237, R:0.0099, T:0.4487(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4367 (C:5.6153, R:0.0100, T:0.4357(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4182 (C:5.6269, R:0.0100, T:0.4172(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4164 (C:5.5909, R:0.0100, T:0.4154(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4254 (C:5.6493, R:0.0099, T:0.4244(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4167

ğŸ“Š EPOCH 84 TRAINING SUMMARY:
  Total Loss: 0.4177
  Contrastive: 5.6153
  Reconstruction: 0.0100
  Topological: 0.4167 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.5990
  Contrastive: 5.6448
  Reconstruction: 0.0099
  Topological: 1.5980 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 84/300 COMPLETE (48.9s)
Train Loss: 0.4177 (C:5.6153, R:0.0100, T:0.4167)
Val Loss:   1.5990 (C:5.6448, R:0.0099, T:1.5980)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 85 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4159 (C:5.6173, R:0.0100, T:0.4149(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4227 (C:5.6320, R:0.0099, T:0.4217(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4067 (C:5.6263, R:0.0100, T:0.4057(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4008 (C:5.6042, R:0.0100, T:0.3998(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4205 (C:5.5791, R:0.0100, T:0.4195(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4084 (C:5.6152, R:0.0099, T:0.4074(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.3988 (C:5.6048, R:0.0099, T:0.3978(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4353 (C:5.6530, R:0.0099, T:0.4344(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4131 (C:5.6360, R:0.0099, T:0.4121(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.3946 (C:5.6235, R:0.0100, T:0.3936(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4451 (C:5.5817, R:0.0100, T:0.4441(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4305 (C:5.5833, R:0.0100, T:0.4295(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4334 (C:5.6015, R:0.0099, T:0.4324(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4310 (C:5.6154, R:0.0100, T:0.4300(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4175 (C:5.6150, R:0.0100, T:0.4165(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4181 (C:5.6077, R:0.0099, T:0.4171(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.3993 (C:5.6588, R:0.0100, T:0.3983(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4085 (C:5.6551, R:0.0100, T:0.4075(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4176 (C:5.6482, R:0.0100, T:0.4166(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4263 (C:5.5775, R:0.0099, T:0.4254(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4060 (C:5.5959, R:0.0100, T:0.4050(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4042 (C:5.5671, R:0.0100, T:0.4032(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4165

ğŸ“Š EPOCH 85 TRAINING SUMMARY:
  Total Loss: 0.4175
  Contrastive: 5.6140
  Reconstruction: 0.0100
  Topological: 0.4165 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.6541
  Contrastive: 5.6078
  Reconstruction: 0.0099
  Topological: 1.6531 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 85/300 COMPLETE (49.2s)
Train Loss: 0.4175 (C:5.6140, R:0.0100, T:0.4165)
Val Loss:   1.6541 (C:5.6078, R:0.0099, T:1.6531)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 86 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4176 (C:5.5907, R:0.0100, T:0.4166(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4155 (C:5.6313, R:0.0099, T:0.4145(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4202 (C:5.5957, R:0.0099, T:0.4192(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4000 (C:5.6128, R:0.0100, T:0.3990(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4328 (C:5.6568, R:0.0100, T:0.4318(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4065 (C:5.6375, R:0.0100, T:0.4055(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4088 (C:5.6333, R:0.0100, T:0.4078(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4140 (C:5.6025, R:0.0100, T:0.4130(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4059 (C:5.6440, R:0.0099, T:0.4049(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4143 (C:5.6419, R:0.0100, T:0.4133(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4186 (C:5.6374, R:0.0100, T:0.4176(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4151 (C:5.6317, R:0.0100, T:0.4141(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4164 (C:5.6429, R:0.0100, T:0.4154(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4298 (C:5.6101, R:0.0100, T:0.4288(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.3994 (C:5.6291, R:0.0099, T:0.3984(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4322 (C:5.5791, R:0.0100, T:0.4312(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4257 (C:5.6088, R:0.0100, T:0.4247(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4044 (C:5.6408, R:0.0100, T:0.4034(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4242 (C:5.6276, R:0.0100, T:0.4232(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4240 (C:5.6036, R:0.0100, T:0.4230(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4105 (C:5.6307, R:0.0099, T:0.4095(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4116 (C:5.6401, R:0.0100, T:0.4106(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 86 TRAINING SUMMARY:
  Total Loss: 0.4175
  Contrastive: 5.6144
  Reconstruction: 0.0100
  Topological: 0.4165 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.6160
  Contrastive: 5.6241
  Reconstruction: 0.0099
  Topological: 1.6151 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 86/300 COMPLETE (48.2s)
Train Loss: 0.4175 (C:5.6144, R:0.0100, T:0.4165)
Val Loss:   1.6160 (C:5.6241, R:0.0099, T:1.6151)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 87 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4257 (C:5.6131, R:0.0100, T:0.4247(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4301 (C:5.6095, R:0.0100, T:0.4291(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.3944 (C:5.5993, R:0.0099, T:0.3934(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4285 (C:5.5998, R:0.0099, T:0.4275(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4306 (C:5.6454, R:0.0100, T:0.4296(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4369 (C:5.5898, R:0.0099, T:0.4359(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4052 (C:5.6086, R:0.0099, T:0.4042(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4506 (C:5.5738, R:0.0099, T:0.4496(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4096 (C:5.5888, R:0.0099, T:0.4086(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4070 (C:5.6344, R:0.0099, T:0.4060(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4298 (C:5.6655, R:0.0100, T:0.4288(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4257 (C:5.5842, R:0.0099, T:0.4247(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4253 (C:5.5945, R:0.0100, T:0.4243(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4190 (C:5.6068, R:0.0099, T:0.4180(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4145 (C:5.6132, R:0.0099, T:0.4135(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4036 (C:5.6097, R:0.0099, T:0.4026(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4055 (C:5.6563, R:0.0100, T:0.4045(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4213 (C:5.6310, R:0.0100, T:0.4203(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4133 (C:5.6341, R:0.0100, T:0.4123(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4114 (C:5.6896, R:0.0100, T:0.4104(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4118 (C:5.6034, R:0.0100, T:0.4108(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4142 (C:5.5757, R:0.0099, T:0.4132(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 87 TRAINING SUMMARY:
  Total Loss: 0.4187
  Contrastive: 5.6143
  Reconstruction: 0.0100
  Topological: 0.4178 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.6647
  Contrastive: 5.6058
  Reconstruction: 0.0099
  Topological: 1.6637 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 87/300 COMPLETE (51.6s)
Train Loss: 0.4187 (C:5.6143, R:0.0100, T:0.4178)
Val Loss:   1.6647 (C:5.6058, R:0.0099, T:1.6637)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 88 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4216 (C:5.5905, R:0.0099, T:0.4206(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4427 (C:5.6472, R:0.0100, T:0.4417(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4004 (C:5.6322, R:0.0099, T:0.3994(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4254 (C:5.6289, R:0.0099, T:0.4244(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4015 (C:5.6307, R:0.0100, T:0.4005(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4131 (C:5.6047, R:0.0099, T:0.4121(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4333 (C:5.5988, R:0.0099, T:0.4323(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4340 (C:5.6277, R:0.0100, T:0.4330(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4095 (C:5.6022, R:0.0099, T:0.4085(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4203 (C:5.6313, R:0.0100, T:0.4193(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4073 (C:5.6532, R:0.0100, T:0.4063(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4088 (C:5.6362, R:0.0100, T:0.4078(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.3911 (C:5.6086, R:0.0100, T:0.3901(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4424 (C:5.5940, R:0.0100, T:0.4414(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4191 (C:5.5940, R:0.0100, T:0.4181(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.3963 (C:5.6317, R:0.0100, T:0.3953(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4096 (C:5.5875, R:0.0100, T:0.4086(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4106 (C:5.6142, R:0.0100, T:0.4096(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4172 (C:5.6481, R:0.0100, T:0.4162(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4356 (C:5.6271, R:0.0100, T:0.4346(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.3878 (C:5.6500, R:0.0100, T:0.3868(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4223 (C:5.6544, R:0.0100, T:0.4213(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 88 TRAINING SUMMARY:
  Total Loss: 0.4183
  Contrastive: 5.6147
  Reconstruction: 0.0100
  Topological: 0.4173 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.6278
  Contrastive: 5.6246
  Reconstruction: 0.0099
  Topological: 1.6268 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 88/300 COMPLETE (50.6s)
Train Loss: 0.4183 (C:5.6147, R:0.0100, T:0.4173)
Val Loss:   1.6278 (C:5.6246, R:0.0099, T:1.6268)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 89 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.3965 (C:5.6036, R:0.0100, T:0.3955(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4031 (C:5.6117, R:0.0099, T:0.4021(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4118 (C:5.5999, R:0.0099, T:0.4108(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4433 (C:5.6327, R:0.0100, T:0.4423(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4008 (C:5.6299, R:0.0099, T:0.3998(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4265 (C:5.6295, R:0.0100, T:0.4255(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4163 (C:5.6034, R:0.0099, T:0.4153(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4231 (C:5.6044, R:0.0099, T:0.4221(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4102 (C:5.5954, R:0.0099, T:0.4092(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4085 (C:5.6079, R:0.0100, T:0.4075(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4190 (C:5.6015, R:0.0099, T:0.4181(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4212 (C:5.6230, R:0.0100, T:0.4202(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4084 (C:5.6260, R:0.0100, T:0.4074(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4190 (C:5.5963, R:0.0100, T:0.4180(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4076 (C:5.6387, R:0.0100, T:0.4067(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4093 (C:5.5848, R:0.0099, T:0.4083(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4297 (C:5.6339, R:0.0100, T:0.4287(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4330 (C:5.6237, R:0.0100, T:0.4320(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4025 (C:5.6355, R:0.0099, T:0.4015(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4077 (C:5.6059, R:0.0100, T:0.4067(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4144 (C:5.6175, R:0.0100, T:0.4134(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.3934 (C:5.5524, R:0.0099, T:0.3924(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 89 TRAINING SUMMARY:
  Total Loss: 0.4177
  Contrastive: 5.6140
  Reconstruction: 0.0100
  Topological: 0.4167 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.7118
  Contrastive: 5.5779
  Reconstruction: 0.0099
  Topological: 1.7108 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 89/300 COMPLETE (51.4s)
Train Loss: 0.4177 (C:5.6140, R:0.0100, T:0.4167)
Val Loss:   1.7118 (C:5.5779, R:0.0099, T:1.7108)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 90 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4224 (C:5.5685, R:0.0099, T:0.4214(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.3991 (C:5.6115, R:0.0099, T:0.3981(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4166 (C:5.6302, R:0.0099, T:0.4156(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4150 (C:5.6075, R:0.0100, T:0.4140(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4101 (C:5.6106, R:0.0100, T:0.4091(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4226 (C:5.6317, R:0.0100, T:0.4216(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4118 (C:5.6019, R:0.0099, T:0.4108(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4290 (C:5.6392, R:0.0100, T:0.4280(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4161 (C:5.6362, R:0.0100, T:0.4151(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4119 (C:5.6612, R:0.0100, T:0.4109(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4013 (C:5.6045, R:0.0099, T:0.4003(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4186 (C:5.6255, R:0.0100, T:0.4176(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4238 (C:5.5923, R:0.0099, T:0.4228(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.3965 (C:5.5940, R:0.0100, T:0.3955(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4194 (C:5.6003, R:0.0099, T:0.4184(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4071 (C:5.6264, R:0.0100, T:0.4061(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4221 (C:5.6298, R:0.0099, T:0.4211(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4080 (C:5.6558, R:0.0100, T:0.4070(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4326 (C:5.5935, R:0.0099, T:0.4316(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4207 (C:5.5865, R:0.0100, T:0.4197(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4146 (C:5.6017, R:0.0100, T:0.4136(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4326 (C:5.6330, R:0.0100, T:0.4317(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4156

ğŸ“Š EPOCH 90 TRAINING SUMMARY:
  Total Loss: 0.4166
  Contrastive: 5.6131
  Reconstruction: 0.0100
  Topological: 0.4156 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.5968
  Contrastive: 5.6515
  Reconstruction: 0.0099
  Topological: 1.5958 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 90/300 COMPLETE (52.1s)
Train Loss: 0.4166 (C:5.6131, R:0.0100, T:0.4156)
Val Loss:   1.5968 (C:5.6515, R:0.0099, T:1.5958)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 91 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4116 (C:5.6156, R:0.0099, T:0.4106(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4279 (C:5.6464, R:0.0100, T:0.4269(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.3898 (C:5.5955, R:0.0100, T:0.3888(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.3958 (C:5.6136, R:0.0100, T:0.3948(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.3985 (C:5.6204, R:0.0100, T:0.3975(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4022 (C:5.6140, R:0.0100, T:0.4012(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4415 (C:5.6211, R:0.0099, T:0.4405(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4359 (C:5.6255, R:0.0099, T:0.4349(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4224 (C:5.6484, R:0.0099, T:0.4214(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4337 (C:5.6161, R:0.0100, T:0.4327(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4421 (C:5.6164, R:0.0099, T:0.4411(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4038 (C:5.5890, R:0.0100, T:0.4028(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4338 (C:5.5721, R:0.0099, T:0.4328(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4149 (C:5.6209, R:0.0099, T:0.4139(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.3987 (C:5.6086, R:0.0099, T:0.3977(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4086 (C:5.6132, R:0.0099, T:0.4076(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4156 (C:5.6481, R:0.0100, T:0.4146(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4016 (C:5.6439, R:0.0100, T:0.4006(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4237 (C:5.6454, R:0.0100, T:0.4227(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.4021 (C:5.6168, R:0.0100, T:0.4011(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.4048 (C:5.6258, R:0.0100, T:0.4038(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.3938 (C:5.6203, R:0.0100, T:0.3928(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.4145

ğŸ“Š EPOCH 91 TRAINING SUMMARY:
  Total Loss: 0.4155
  Contrastive: 5.6148
  Reconstruction: 0.0100
  Topological: 0.4145 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.6057
  Contrastive: 5.6171
  Reconstruction: 0.0099
  Topological: 1.6047 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 91/300 COMPLETE (52.0s)
Train Loss: 0.4155 (C:5.6148, R:0.0100, T:0.4145)
Val Loss:   1.6057 (C:5.6171, R:0.0099, T:1.6047)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 92 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.4096 (C:5.6065, R:0.0100, T:0.4086(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.4049 (C:5.5935, R:0.0099, T:0.4039(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.4242 (C:5.6238, R:0.0100, T:0.4232(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.4296 (C:5.6189, R:0.0099, T:0.4286(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.4374 (C:5.6273, R:0.0100, T:0.4364(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.4138 (C:5.6312, R:0.0100, T:0.4128(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.4121 (C:5.6412, R:0.0100, T:0.4111(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.4225 (C:5.5773, R:0.0099, T:0.4215(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.4057 (C:5.6034, R:0.0100, T:0.4047(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.4297 (C:5.6286, R:0.0100, T:0.4287(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.4085 (C:5.6386, R:0.0100, T:0.4075(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.4157 (C:5.6150, R:0.0100, T:0.4147(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.4301 (C:5.5907, R:0.0099, T:0.4291(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.4206 (C:5.5914, R:0.0100, T:0.4197(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.4229 (C:5.6143, R:0.0100, T:0.4219(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.4043 (C:5.6078, R:0.0100, T:0.4033(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.4177 (C:5.6138, R:0.0100, T:0.4167(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.4250 (C:5.5652, R:0.0100, T:0.4240(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.4125 (C:5.6096, R:0.0099, T:0.4115(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.3772 (C:5.6497, R:0.0099, T:0.3762(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.3949 (C:5.6333, R:0.0100, T:0.3939(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.4238 (C:5.6379, R:0.0100, T:0.4228(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 92 TRAINING SUMMARY:
  Total Loss: 0.4162
  Contrastive: 5.6155
  Reconstruction: 0.0100
  Topological: 0.4152 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.4898
  Contrastive: 5.6840
  Reconstruction: 0.0099
  Topological: 1.4888 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 92/300 COMPLETE (55.8s)
Train Loss: 0.4162 (C:5.6155, R:0.0100, T:0.4152)
Val Loss:   1.4898 (C:5.6840, R:0.0099, T:1.4888)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

ğŸ›‘ Early stopping triggered after 92 epochs
Best model was at epoch 72 with Val Loss: 1.4734

======================================================================
ğŸ“ˆ FINAL TOPOLOGICAL LEARNING ANALYSIS
======================================================================
First topological learning: Epoch 1
Epochs with topology: 92/92
Max consecutive topology epochs: 92
Best topological loss: 0.4145
Final topological loss: 0.4152
âœ… SUCCESS: Topological learning achieved!
ğŸš€ EXCELLENT: Very consistent topological learning (>80%)
ğŸ“ˆ Topological learning appears stable

======================================================================
ğŸ¯ TOPOLOGICAL AUTOENCODER TRAINING COMPLETED
======================================================================
âœ… Topological training completed successfully!
Saving results...
Loading best model from entailment_surfaces/supervised_contrastive_autoencoder/experiments/topological_autoencoder_torchph_phase1_20250722_141516/checkpoints/best_model.pt
Starting model evaluation...
========================================
GlobalContrastiveEvaluator initialized on cuda
Starting comprehensive evaluation...
============================================================
Extracting latent representations...
  Processed 1/10 batches
Extracted representations: torch.Size([9824, 100])
Evaluating clustering performance...
Clustering Results:
  Silhouette Score: -0.0035
  Adjusted Rand Score: 0.0001
  Clustering Accuracy: 0.3402
Evaluating classification performance...
  Extracting training representations...
Extracting latent representations...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
Extracted representations: torch.Size([547740, 100])
  Extracting validation representations...
Extracting latent representations...
  Processed 1/9 batches
Extracted representations: torch.Size([9180, 100])
Subsampled training to 50000 samples
  Training on 50000 samples, evaluating on 9180 samples
Classification Results:
  Accuracy: 0.5063
  Per-class F1: [0.5619954211350765, 0.40453890489913547, 0.5291638944333555]
Evaluating reconstruction quality...
Reconstruction Results:
  Average MSE: 0.009863
Evaluating separation quality...
Separation Results:
  Positive distances: 5.696 Â± 0.591
  Negative distances: 5.725 Â± 0.571
  Separation ratio: 1.01x
  Gap: -7.693
  Perfect separation: No

Comprehensive evaluation completed!

============================================================
EVALUATION SUMMARY
============================================================
Clustering Performance:
  Silhouette Score: -0.0035
  Clustering Accuracy: 0.3402
  Adjusted Rand Score: 0.0001

Classification Performance:
  Accuracy: 0.5063

Separation Quality:
  Separation Ratio: 1.01x
  Gap: -7.693
  Perfect Separation: False

Reconstruction Quality:
  Average MSE: 0.009863
============================================================
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/topological_autoencoder_torchph_phase1_20250722_141516/results/evaluation_results_20250722_153112.json
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/topological_autoencoder_torchph_phase1_20250722_141516/results/evaluation_results_20250722_153112.json

Key Results:
  Separation ratio: 1.01x
  Perfect separation: False
  Classification accuracy: 0.5063

============================================================
TOPOLOGICAL TRAINING ANALYSIS
============================================================

ğŸ“ˆ TOPOLOGICAL LEARNING DIAGNOSIS:
  Total epochs: 92
  Epochs with topological learning: 92
  Current topological loss: 0.4152
  Current topological weight: 1.0000
  âœ… Topological loss is decreasing (good progress)
ğŸš€ EXCELLENT: Consistent topological learning achieved!
Final topological loss: 0.4152
Epochs with topology: 92/92
âš ï¸  Poor clustering accuracy: 0.340

Final analysis saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/topological_autoencoder_torchph_phase1_20250722_141516/results/final_analysis.json
Experiment saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/topological_autoencoder_torchph_phase1_20250722_141516

Analysis completed with exit code: 0
Time: Tue 22 Jul 15:31:13 BST 2025

=== ANALYSIS SUCCESSFUL ===
Regularization successful!


Job finished.
