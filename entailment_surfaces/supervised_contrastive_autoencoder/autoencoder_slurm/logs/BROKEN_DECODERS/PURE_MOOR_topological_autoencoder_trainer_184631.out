Starting Surface Distance Metric Analysis job...
Job ID: 184631
Node: gpuvm18
Time: Mon 21 Jul 18:35:43 BST 2025
Loading CUDA...
Activating conda environment...
Activated conda environment: /vol/bitbucket/ahb24/tda_entailment_new
Python location: /vol/bitbucket/ahb24/tda_entailment_new/bin/python
Checking GPU availability...
Mon Jul 21 18:35:45 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.133.07             Driver Version: 570.133.07     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla T4                       Off |   00000000:00:06.0 Off |                    0 |
| N/A   32C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+

Testing PyTorch and CUDA...
PyTorch version: 2.4.1
CUDA available: True
CUDA device: Tesla T4
GPU memory: 15.6 GB
PyTorch setup verified!

Starting Topological Training...

============================================================
TOPOLOGICAL AUTOENCODER TRAINING WITH TORCHPH
============================================================
Experiment setup completed:
  Experiment directory: entailment_surfaces/supervised_contrastive_autoencoder/experiments/topological_autoencoder_torchph_phase1_20250721_183602
  Config saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/topological_autoencoder_torchph_phase1_20250721_183602/config.json
Loading data...
========================================
FlexibleEmbedder initialized with type: 'concat'
Output dimension will be: 1536
GlobalDataLoader initialized:
  Embedding type: concat
  Output dimension: 1536
  Sample size: All
Starting data loading pipeline...
============================================================
Loading training data from data/processed/snli_full_standard_SBERT.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 549367 training samples
Loading validation data from data/processed/snli_full_standard_SBERT.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 549367 validation samples
Loading test data from data/processed/snli_full_standard_SBERT.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 549367 test samples
Generating embeddings for training...
Generating concat embeddings on cuda
Processing 549367 samples in batches of 1000
  Processing batch 1/550
  Processing batch 6/550
  Processing batch 11/550
  Processing batch 16/550
  Processing batch 21/550
  Processing batch 26/550
  Processing batch 31/550
  Processing batch 36/550
  Processing batch 41/550
  Processing batch 46/550
  Processing batch 51/550
  Processing batch 56/550
  Processing batch 61/550
  Processing batch 66/550
  Processing batch 71/550
  Processing batch 76/550
  Processing batch 81/550
  Processing batch 86/550
  Processing batch 91/550
  Processing batch 96/550
  Processing batch 101/550
  Processing batch 106/550
  Processing batch 111/550
  Processing batch 116/550
  Processing batch 121/550
  Processing batch 126/550
  Processing batch 131/550
  Processing batch 136/550
  Processing batch 141/550
  Processing batch 146/550
  Processing batch 151/550
  Processing batch 156/550
  Processing batch 161/550
  Processing batch 166/550
  Processing batch 171/550
  Processing batch 176/550
  Processing batch 181/550
  Processing batch 186/550
  Processing batch 191/550
  Processing batch 196/550
  Processing batch 201/550
  Processing batch 206/550
  Processing batch 211/550
  Processing batch 216/550
  Processing batch 221/550
  Processing batch 226/550
  Processing batch 231/550
  Processing batch 236/550
  Processing batch 241/550
  Processing batch 246/550
  Processing batch 251/550
  Processing batch 256/550
  Processing batch 261/550
  Processing batch 266/550
  Processing batch 271/550
  Processing batch 276/550
  Processing batch 281/550
  Processing batch 286/550
  Processing batch 291/550
  Processing batch 296/550
  Processing batch 301/550
  Processing batch 306/550
  Processing batch 311/550
  Processing batch 316/550
  Processing batch 321/550
  Processing batch 326/550
  Processing batch 331/550
  Processing batch 336/550
  Processing batch 341/550
  Processing batch 346/550
  Processing batch 351/550
  Processing batch 356/550
  Processing batch 361/550
  Processing batch 366/550
  Processing batch 371/550
  Processing batch 376/550
  Processing batch 381/550
  Processing batch 386/550
  Processing batch 391/550
  Processing batch 396/550
  Processing batch 401/550
  Processing batch 406/550
  Processing batch 411/550
  Processing batch 416/550
  Processing batch 421/550
  Processing batch 426/550
  Processing batch 431/550
  Processing batch 436/550
  Processing batch 441/550
  Processing batch 446/550
  Processing batch 451/550
  Processing batch 456/550
  Processing batch 461/550
  Processing batch 466/550
  Processing batch 471/550
  Processing batch 476/550
  Processing batch 481/550
  Processing batch 486/550
  Processing batch 491/550
  Processing batch 496/550
  Processing batch 501/550
  Processing batch 506/550
  Processing batch 511/550
  Processing batch 516/550
  Processing batch 521/550
  Processing batch 526/550
  Processing batch 531/550
  Processing batch 536/550
  Processing batch 541/550
  Processing batch 546/550
Generated concat embeddings: torch.Size([549367, 1536])
Generating embeddings for validation...
Generating concat embeddings on cuda
Processing 549367 samples in batches of 1000
  Processing batch 1/550
  Processing batch 6/550
  Processing batch 11/550
  Processing batch 16/550
  Processing batch 21/550
  Processing batch 26/550
  Processing batch 31/550
  Processing batch 36/550
  Processing batch 41/550
  Processing batch 46/550
  Processing batch 51/550
  Processing batch 56/550
  Processing batch 61/550
  Processing batch 66/550
  Processing batch 71/550
  Processing batch 76/550
  Processing batch 81/550
  Processing batch 86/550
  Processing batch 91/550
  Processing batch 96/550
  Processing batch 101/550
  Processing batch 106/550
  Processing batch 111/550
  Processing batch 116/550
  Processing batch 121/550
  Processing batch 126/550
  Processing batch 131/550
  Processing batch 136/550
  Processing batch 141/550
  Processing batch 146/550
  Processing batch 151/550
  Processing batch 156/550
  Processing batch 161/550
  Processing batch 166/550
  Processing batch 171/550
  Processing batch 176/550
  Processing batch 181/550
  Processing batch 186/550
  Processing batch 191/550
  Processing batch 196/550
  Processing batch 201/550
  Processing batch 206/550
  Processing batch 211/550
  Processing batch 216/550
  Processing batch 221/550
  Processing batch 226/550
  Processing batch 231/550
  Processing batch 236/550
  Processing batch 241/550
  Processing batch 246/550
  Processing batch 251/550
  Processing batch 256/550
  Processing batch 261/550
  Processing batch 266/550
  Processing batch 271/550
  Processing batch 276/550
  Processing batch 281/550
  Processing batch 286/550
  Processing batch 291/550
  Processing batch 296/550
  Processing batch 301/550
  Processing batch 306/550
  Processing batch 311/550
  Processing batch 316/550
  Processing batch 321/550
  Processing batch 326/550
  Processing batch 331/550
  Processing batch 336/550
  Processing batch 341/550
  Processing batch 346/550
  Processing batch 351/550
  Processing batch 356/550
  Processing batch 361/550
  Processing batch 366/550
  Processing batch 371/550
  Processing batch 376/550
  Processing batch 381/550
  Processing batch 386/550
  Processing batch 391/550
  Processing batch 396/550
  Processing batch 401/550
  Processing batch 406/550
  Processing batch 411/550
  Processing batch 416/550
  Processing batch 421/550
  Processing batch 426/550
  Processing batch 431/550
  Processing batch 436/550
  Processing batch 441/550
  Processing batch 446/550
  Processing batch 451/550
  Processing batch 456/550
  Processing batch 461/550
  Processing batch 466/550
  Processing batch 471/550
  Processing batch 476/550
  Processing batch 481/550
  Processing batch 486/550
  Processing batch 491/550
  Processing batch 496/550
  Processing batch 501/550
  Processing batch 506/550
  Processing batch 511/550
  Processing batch 516/550
  Processing batch 521/550
  Processing batch 526/550
  Processing batch 531/550
  Processing batch 536/550
  Processing batch 541/550
  Processing batch 546/550
Generated concat embeddings: torch.Size([549367, 1536])
Generating embeddings for test...
Generating concat embeddings on cuda
Processing 549367 samples in batches of 1000
  Processing batch 1/550
  Processing batch 6/550
  Processing batch 11/550
  Processing batch 16/550
  Processing batch 21/550
  Processing batch 26/550
  Processing batch 31/550
  Processing batch 36/550
  Processing batch 41/550
  Processing batch 46/550
  Processing batch 51/550
  Processing batch 56/550
  Processing batch 61/550
  Processing batch 66/550
  Processing batch 71/550
  Processing batch 76/550
  Processing batch 81/550
  Processing batch 86/550
  Processing batch 91/550
  Processing batch 96/550
  Processing batch 101/550
  Processing batch 106/550
  Processing batch 111/550
  Processing batch 116/550
  Processing batch 121/550
  Processing batch 126/550
  Processing batch 131/550
  Processing batch 136/550
  Processing batch 141/550
  Processing batch 146/550
  Processing batch 151/550
  Processing batch 156/550
  Processing batch 161/550
  Processing batch 166/550
  Processing batch 171/550
  Processing batch 176/550
  Processing batch 181/550
  Processing batch 186/550
  Processing batch 191/550
  Processing batch 196/550
  Processing batch 201/550
  Processing batch 206/550
  Processing batch 211/550
  Processing batch 216/550
  Processing batch 221/550
  Processing batch 226/550
  Processing batch 231/550
  Processing batch 236/550
  Processing batch 241/550
  Processing batch 246/550
  Processing batch 251/550
  Processing batch 256/550
  Processing batch 261/550
  Processing batch 266/550
  Processing batch 271/550
  Processing batch 276/550
  Processing batch 281/550
  Processing batch 286/550
  Processing batch 291/550
  Processing batch 296/550
  Processing batch 301/550
  Processing batch 306/550
  Processing batch 311/550
  Processing batch 316/550
  Processing batch 321/550
  Processing batch 326/550
  Processing batch 331/550
  Processing batch 336/550
  Processing batch 341/550
  Processing batch 346/550
  Processing batch 351/550
  Processing batch 356/550
  Processing batch 361/550
  Processing batch 366/550
  Processing batch 371/550
  Processing batch 376/550
  Processing batch 381/550
  Processing batch 386/550
  Processing batch 391/550
  Processing batch 396/550
  Processing batch 401/550
  Processing batch 406/550
  Processing batch 411/550
  Processing batch 416/550
  Processing batch 421/550
  Processing batch 426/550
  Processing batch 431/550
  Processing batch 436/550
  Processing batch 441/550
  Processing batch 446/550
  Processing batch 451/550
  Processing batch 456/550
  Processing batch 461/550
  Processing batch 466/550
  Processing batch 471/550
  Processing batch 476/550
  Processing batch 481/550
  Processing batch 486/550
  Processing batch 491/550
  Processing batch 496/550
  Processing batch 501/550
  Processing batch 506/550
  Processing batch 511/550
  Processing batch 516/550
  Processing batch 521/550
  Processing batch 526/550
  Processing batch 531/550
  Processing batch 536/550
  Processing batch 541/550
  Processing batch 546/550
Generated concat embeddings: torch.Size([549367, 1536])
EntailmentDataset created: 549367 samples
  Embedding shape: torch.Size([549367, 1536])
  Class distribution: {'entailment': 183416, 'neutral': 182764, 'contradiction': 183187}
EntailmentDataset created: 549367 samples
  Embedding shape: torch.Size([549367, 1536])
  Class distribution: {'entailment': 183416, 'neutral': 182764, 'contradiction': 183187}
EntailmentDataset created: 549367 samples
  Embedding shape: torch.Size([549367, 1536])
  Class distribution: {'entailment': 183416, 'neutral': 182764, 'contradiction': 183187}

Data loading pipeline completed!
Output embedding dimension: 1536
Updated model input_dim to: 1536
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 537
  Class 2: 183187 samples
  Class 0: 183416 samples
  Class 1: 182764 samples
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 537
  Class 2: 183187 samples
  Class 0: 183416 samples
  Class 1: 182764 samples
DataLoaders created:
  Batch size: 1020
  Balanced sampling: True
  Train batches: 537
  Val batches: 537
  Test batches: 539
Data loading completed!
  Train: 549367 samples, 537 batches
  Val: 549367 samples, 537 batches
  Test: 549367 samples, 539 batches
ContrastiveAutoencoder initialized:
  Input dim: 1536
  Latent dim: 75
  Hidden dims: [1024, 768, 512, 256, 128]
  Dropout rate: 0.2
  Total parameters: 5,858,891
FullDatasetContrastiveLoss initialized:
  Margin: 2.0
  Update frequency: 3 epochs
  Max global samples: 5000
FullDatasetCombinedLoss initialized:
  Contrastive weight: 0.0
  Base reconstruction weight: 0.1
  Scheduled reconstruction: warmup=10 epochs, max_weight=0.3
MoorTopologicalLoss Initialized: Using 0-dimensional persistence pairings (MST edges).
No prototypes being used for topological loss - whole dataset instead.
TopologicalTrainer initialized on device: cuda
Model parameters: 5,858,891
Enhanced with topological loss monitoring
Starting Phase 1: Pure Topological Training
  Contrastive weight: 0.0
  Topological weight: 1.0
  Reconstruction weight: 0.1

======================================================================
ğŸ§  TOPOLOGICAL AUTOENCODER TRAINING STARTED
======================================================================

============================================================
EPOCH 1 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=47.6589 (C:2.0000, R:0.0110, T:47.6578(w:1.000)âš ï¸)
Batch  25/537: Loss=8.5578 (C:3.8612, R:0.0100, T:8.5568(w:1.000)ğŸš€)
Batch  50/537: Loss=4.5041 (C:4.9222, R:0.0100, T:4.5031(w:1.000)ğŸš€)
Batch  75/537: Loss=3.7370 (C:5.4328, R:0.0099, T:3.7360(w:1.000)ğŸš€)
Batch 100/537: Loss=3.5497 (C:5.3413, R:0.0099, T:3.5487(w:1.000)ğŸš€)
Batch 125/537: Loss=3.2980 (C:5.3067, R:0.0099, T:3.2970(w:1.000)ğŸš€)
Batch 150/537: Loss=3.1823 (C:5.3525, R:0.0100, T:3.1813(w:1.000)ğŸš€)
Batch 175/537: Loss=3.1502 (C:5.3541, R:0.0100, T:3.1492(w:1.000)ğŸš€)
Batch 200/537: Loss=2.9120 (C:5.3364, R:0.0099, T:2.9110(w:1.000)ğŸš€)
Batch 225/537: Loss=2.9118 (C:5.3519, R:0.0099, T:2.9109(w:1.000)ğŸš€)
Batch 250/537: Loss=2.9330 (C:5.3225, R:0.0100, T:2.9320(w:1.000)ğŸš€)
Batch 275/537: Loss=2.8323 (C:5.3597, R:0.0099, T:2.8313(w:1.000)ğŸš€)
Batch 300/537: Loss=2.8465 (C:5.3643, R:0.0100, T:2.8455(w:1.000)ğŸš€)
Batch 325/537: Loss=2.7662 (C:5.3555, R:0.0100, T:2.7652(w:1.000)ğŸš€)
Batch 350/537: Loss=2.7643 (C:5.2976, R:0.0099, T:2.7633(w:1.000)ğŸš€)
Batch 375/537: Loss=2.7823 (C:5.3551, R:0.0099, T:2.7813(w:1.000)ğŸš€)
Batch 400/537: Loss=2.9391 (C:5.3033, R:0.0100, T:2.9381(w:1.000)ğŸš€)
Batch 425/537: Loss=2.8328 (C:5.3990, R:0.0100, T:2.8318(w:1.000)ğŸš€)
Batch 450/537: Loss=2.8416 (C:5.3852, R:0.0100, T:2.8406(w:1.000)ğŸš€)
Batch 475/537: Loss=2.6595 (C:5.3304, R:0.0099, T:2.6585(w:1.000)ğŸš€)
Batch 500/537: Loss=2.7701 (C:5.2124, R:0.0099, T:2.7691(w:1.000)ğŸš€)
Batch 525/537: Loss=2.7497 (C:5.3792, R:0.0099, T:2.7487(w:1.000)ğŸš€)
ğŸ‰ MILESTONE: First topological learning detected at epoch 1!
   Initial topological loss: 3.8398
ğŸ“ˆ New best topological loss: 3.8398

ğŸ“Š EPOCH 1 TRAINING SUMMARY:
  Total Loss: 3.8408
  Contrastive: 5.3018
  Reconstruction: 0.0100
  Topological: 3.8398 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 42.7575
  Contrastive: 1.9776
  Reconstruction: 0.0100
  Topological: 42.7565 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 1/100 COMPLETE (91.0s)
Train Loss: 3.8408 (C:5.3018, R:0.0100, T:3.8398)
Val Loss:   42.7575 (C:1.9776, R:0.0100, T:42.7565)
ğŸš€ Good topological learning progress
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 2 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=2.7534 (C:5.3099, R:0.0100, T:2.7524(w:1.000)ğŸš€)
Batch  25/537: Loss=2.7626 (C:5.3609, R:0.0100, T:2.7616(w:1.000)ğŸš€)
Batch  50/537: Loss=2.7354 (C:5.3395, R:0.0100, T:2.7344(w:1.000)ğŸš€)
Batch  75/537: Loss=2.6724 (C:5.4579, R:0.0100, T:2.6714(w:1.000)ğŸš€)
Batch 100/537: Loss=2.7241 (C:5.4120, R:0.0099, T:2.7231(w:1.000)ğŸš€)
Batch 125/537: Loss=2.7701 (C:5.3484, R:0.0099, T:2.7691(w:1.000)ğŸš€)
Batch 150/537: Loss=2.7903 (C:5.2869, R:0.0100, T:2.7893(w:1.000)ğŸš€)
Batch 175/537: Loss=2.7015 (C:5.3422, R:0.0099, T:2.7005(w:1.000)ğŸš€)
Batch 200/537: Loss=2.6126 (C:5.4304, R:0.0099, T:2.6116(w:1.000)ğŸš€)
Batch 225/537: Loss=2.7356 (C:5.3084, R:0.0099, T:2.7346(w:1.000)ğŸš€)
Batch 250/537: Loss=2.7452 (C:5.3376, R:0.0099, T:2.7442(w:1.000)ğŸš€)
Batch 275/537: Loss=2.7149 (C:5.4019, R:0.0099, T:2.7139(w:1.000)ğŸš€)
Batch 300/537: Loss=2.6294 (C:5.3332, R:0.0099, T:2.6284(w:1.000)ğŸš€)
Batch 325/537: Loss=2.7077 (C:5.3810, R:0.0099, T:2.7067(w:1.000)ğŸš€)
Batch 350/537: Loss=2.6131 (C:5.3538, R:0.0099, T:2.6121(w:1.000)ğŸš€)
Batch 375/537: Loss=2.6902 (C:5.3120, R:0.0099, T:2.6892(w:1.000)ğŸš€)
Batch 400/537: Loss=2.6225 (C:5.2731, R:0.0099, T:2.6215(w:1.000)ğŸš€)
Batch 425/537: Loss=2.7123 (C:5.4240, R:0.0099, T:2.7113(w:1.000)ğŸš€)
Batch 450/537: Loss=2.7018 (C:5.3182, R:0.0099, T:2.7008(w:1.000)ğŸš€)
Batch 475/537: Loss=2.5735 (C:5.3113, R:0.0099, T:2.5725(w:1.000)ğŸš€)
Batch 500/537: Loss=2.4714 (C:5.2786, R:0.0100, T:2.4704(w:1.000)ğŸš€)
Batch 525/537: Loss=2.3992 (C:5.4538, R:0.0100, T:2.3982(w:1.000)ğŸš€)
ğŸ“ˆ New best topological loss: 2.6749

ğŸ“Š EPOCH 2 TRAINING SUMMARY:
  Total Loss: 2.6759
  Contrastive: 5.3603
  Reconstruction: 0.0100
  Topological: 2.6749 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 40.6912
  Contrastive: 2.0521
  Reconstruction: 0.0100
  Topological: 40.6902 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 2/100 COMPLETE (88.9s)
Train Loss: 2.6759 (C:5.3603, R:0.0100, T:2.6749)
Val Loss:   40.6912 (C:2.0521, R:0.0100, T:40.6902)
ğŸš€ Good topological learning progress
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 3 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=2.4240 (C:5.4121, R:0.0100, T:2.4230(w:1.000)ğŸš€)
Batch  25/537: Loss=2.3645 (C:5.4035, R:0.0099, T:2.3635(w:1.000)ğŸš€)
Batch  50/537: Loss=2.2533 (C:5.2713, R:0.0099, T:2.2523(w:1.000)ğŸš€)
Batch  75/537: Loss=2.3393 (C:5.3689, R:0.0100, T:2.3383(w:1.000)ğŸš€)
Batch 100/537: Loss=2.2175 (C:5.3757, R:0.0099, T:2.2165(w:1.000)ğŸš€)
Batch 125/537: Loss=2.2310 (C:5.4409, R:0.0100, T:2.2300(w:1.000)ğŸš€)
Batch 150/537: Loss=2.3437 (C:5.3838, R:0.0100, T:2.3427(w:1.000)ğŸš€)
Batch 175/537: Loss=2.2377 (C:5.4033, R:0.0099, T:2.2368(w:1.000)ğŸš€)
Batch 200/537: Loss=2.2892 (C:5.4284, R:0.0100, T:2.2882(w:1.000)ğŸš€)
Batch 225/537: Loss=2.2105 (C:5.5006, R:0.0099, T:2.2095(w:1.000)ğŸš€)
Batch 250/537: Loss=2.1334 (C:5.3861, R:0.0100, T:2.1324(w:1.000)ğŸš€)
Batch 275/537: Loss=2.0797 (C:5.4630, R:0.0100, T:2.0787(w:1.000)ğŸš€)
Batch 300/537: Loss=2.1833 (C:5.3003, R:0.0100, T:2.1823(w:1.000)ğŸš€)
Batch 325/537: Loss=2.1153 (C:5.4501, R:0.0100, T:2.1143(w:1.000)ğŸš€)
Batch 350/537: Loss=2.0962 (C:5.4582, R:0.0099, T:2.0952(w:1.000)ğŸš€)
Batch 375/537: Loss=2.0459 (C:5.5156, R:0.0099, T:2.0449(w:1.000)ğŸš€)
Batch 400/537: Loss=1.9491 (C:5.4721, R:0.0100, T:1.9481(w:1.000)ğŸš€)
Batch 425/537: Loss=1.9203 (C:5.6047, R:0.0099, T:1.9193(w:1.000)ğŸš€)
Batch 450/537: Loss=1.8935 (C:5.5482, R:0.0099, T:1.8925(w:1.000)ğŸš€)
Batch 475/537: Loss=1.9723 (C:5.6603, R:0.0100, T:1.9713(w:1.000)ğŸš€)
Batch 500/537: Loss=1.9226 (C:5.5359, R:0.0099, T:1.9216(w:1.000)ğŸš€)
Batch 525/537: Loss=1.9569 (C:5.6594, R:0.0100, T:1.9559(w:1.000)ğŸš€)
ğŸ“ˆ New best topological loss: 2.1231

ğŸ“Š EPOCH 3 TRAINING SUMMARY:
  Total Loss: 2.1240
  Contrastive: 5.4595
  Reconstruction: 0.0100
  Topological: 2.1231 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 34.7486
  Contrastive: 2.4355
  Reconstruction: 0.0100
  Topological: 34.7476 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 3/100 COMPLETE (90.4s)
Train Loss: 2.1240 (C:5.4595, R:0.0100, T:2.1231)
Val Loss:   34.7486 (C:2.4355, R:0.0100, T:34.7476)
ğŸš€ Good topological learning progress
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 4 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.8720 (C:5.3930, R:0.0099, T:1.8710(w:1.000)ğŸš€)
Batch  25/537: Loss=1.9517 (C:5.5098, R:0.0099, T:1.9507(w:1.000)ğŸš€)
Batch  50/537: Loss=1.8382 (C:5.6062, R:0.0100, T:1.8372(w:1.000)ğŸš€)
Batch  75/537: Loss=1.7793 (C:5.5724, R:0.0099, T:1.7783(w:1.000)ğŸš€)
Batch 100/537: Loss=1.7389 (C:5.5452, R:0.0099, T:1.7379(w:1.000)ğŸš€)
Batch 125/537: Loss=1.8215 (C:5.5342, R:0.0100, T:1.8205(w:1.000)ğŸš€)
Batch 150/537: Loss=1.7627 (C:5.3655, R:0.0100, T:1.7617(w:1.000)ğŸš€)
Batch 175/537: Loss=1.6918 (C:5.6851, R:0.0099, T:1.6908(w:1.000)ğŸš€)
Batch 200/537: Loss=1.6252 (C:5.5401, R:0.0100, T:1.6242(w:1.000)ğŸš€)
Batch 225/537: Loss=1.6470 (C:5.6565, R:0.0099, T:1.6460(w:1.000)ğŸš€)
Batch 250/537: Loss=1.5984 (C:5.5192, R:0.0099, T:1.5974(w:1.000)ğŸš€)
Batch 275/537: Loss=1.6686 (C:5.5114, R:0.0100, T:1.6676(w:1.000)ğŸš€)
Batch 300/537: Loss=1.6679 (C:5.6271, R:0.0100, T:1.6669(w:1.000)ğŸš€)
Batch 325/537: Loss=1.5975 (C:5.5925, R:0.0100, T:1.5965(w:1.000)ğŸš€)
Batch 350/537: Loss=1.5302 (C:5.6641, R:0.0099, T:1.5292(w:1.000)ğŸš€)
Batch 375/537: Loss=1.6056 (C:5.4316, R:0.0100, T:1.6046(w:1.000)ğŸš€)
Batch 400/537: Loss=1.5726 (C:5.6612, R:0.0099, T:1.5716(w:1.000)ğŸš€)
Batch 425/537: Loss=1.5076 (C:5.5091, R:0.0100, T:1.5066(w:1.000)ğŸš€)
Batch 450/537: Loss=1.5803 (C:5.5104, R:0.0100, T:1.5793(w:1.000)ğŸš€)
Batch 475/537: Loss=1.5514 (C:5.6417, R:0.0099, T:1.5504(w:1.000)ğŸš€)
Batch 500/537: Loss=1.5631 (C:5.6751, R:0.0100, T:1.5621(w:1.000)ğŸš€)
Batch 525/537: Loss=1.4599 (C:5.5922, R:0.0099, T:1.4589(w:1.000)ğŸš€)
ğŸ“ˆ New best topological loss: 1.6744

ğŸ“Š EPOCH 4 TRAINING SUMMARY:
  Total Loss: 1.6754
  Contrastive: 5.5725
  Reconstruction: 0.0100
  Topological: 1.6744 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 27.0942
  Contrastive: 2.9563
  Reconstruction: 0.0100
  Topological: 27.0933 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 4/100 COMPLETE (89.5s)
Train Loss: 1.6754 (C:5.5725, R:0.0100, T:1.6744)
Val Loss:   27.0942 (C:2.9563, R:0.0100, T:27.0933)
ğŸš€ Good topological learning progress
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 5 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.5192 (C:5.5139, R:0.0099, T:1.5183(w:1.000)ğŸš€)
Batch  25/537: Loss=1.4962 (C:5.5909, R:0.0100, T:1.4952(w:1.000)ğŸš€)
Batch  50/537: Loss=1.4745 (C:5.5319, R:0.0099, T:1.4735(w:1.000)ğŸš€)
Batch  75/537: Loss=1.3995 (C:5.5791, R:0.0100, T:1.3985(w:1.000)ğŸš€)
Batch 100/537: Loss=1.4316 (C:5.6527, R:0.0100, T:1.4306(w:1.000)ğŸš€)
Batch 125/537: Loss=1.4027 (C:5.7603, R:0.0100, T:1.4017(w:1.000)ğŸš€)
Batch 150/537: Loss=1.4004 (C:5.5575, R:0.0100, T:1.3994(w:1.000)ğŸš€)
Batch 175/537: Loss=1.3453 (C:5.7151, R:0.0099, T:1.3443(w:1.000)ğŸš€)
Batch 200/537: Loss=1.3886 (C:5.6998, R:0.0099, T:1.3876(w:1.000)ğŸš€)
Batch 225/537: Loss=1.3519 (C:5.7114, R:0.0100, T:1.3509(w:1.000)ğŸš€)
Batch 250/537: Loss=1.3152 (C:5.6993, R:0.0099, T:1.3142(w:1.000)ğŸš€)
Batch 275/537: Loss=1.4255 (C:5.5304, R:0.0100, T:1.4245(w:1.000)ğŸš€)
Batch 300/537: Loss=1.3798 (C:5.6875, R:0.0100, T:1.3788(w:1.000)ğŸš€)
Batch 325/537: Loss=1.3002 (C:5.6581, R:0.0100, T:1.2992(w:1.000)ğŸš€)
Batch 350/537: Loss=1.3539 (C:5.7075, R:0.0100, T:1.3529(w:1.000)ğŸš€)
Batch 375/537: Loss=1.2691 (C:5.6884, R:0.0099, T:1.2681(w:1.000)ğŸš€)
Batch 400/537: Loss=1.2932 (C:5.6587, R:0.0099, T:1.2922(w:1.000)ğŸš€)
Batch 425/537: Loss=1.2510 (C:5.5943, R:0.0099, T:1.2500(w:1.000)ğŸš€)
Batch 450/537: Loss=1.3117 (C:5.6209, R:0.0099, T:1.3107(w:1.000)ğŸš€)
Batch 475/537: Loss=1.3066 (C:5.7825, R:0.0100, T:1.3057(w:1.000)ğŸš€)
Batch 500/537: Loss=1.2733 (C:5.7491, R:0.0100, T:1.2723(w:1.000)ğŸš€)
Batch 525/537: Loss=1.2719 (C:5.6221, R:0.0099, T:1.2709(w:1.000)ğŸš€)
ğŸ“ˆ New best topological loss: 1.3528

ğŸ“Š EPOCH 5 TRAINING SUMMARY:
  Total Loss: 1.3538
  Contrastive: 5.6723
  Reconstruction: 0.0100
  Topological: 1.3528 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 22.2880
  Contrastive: 3.2946
  Reconstruction: 0.0100
  Topological: 22.2870 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 5/100 COMPLETE (89.1s)
Train Loss: 1.3538 (C:5.6723, R:0.0100, T:1.3528)
Val Loss:   22.2880 (C:3.2946, R:0.0100, T:22.2870)
ğŸš€ Good topological learning progress
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 6 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.2883 (C:5.7513, R:0.0100, T:1.2873(w:1.000)ğŸš€)
Batch  25/537: Loss=1.2373 (C:5.5886, R:0.0099, T:1.2363(w:1.000)ğŸš€)
Batch  50/537: Loss=1.2396 (C:5.7179, R:0.0100, T:1.2386(w:1.000)ğŸš€)
Batch  75/537: Loss=1.2420 (C:5.7171, R:0.0100, T:1.2410(w:1.000)ğŸš€)
Batch 100/537: Loss=1.2648 (C:5.7259, R:0.0099, T:1.2638(w:1.000)ğŸš€)
Batch 125/537: Loss=1.2043 (C:5.8468, R:0.0099, T:1.2033(w:1.000)ğŸš€)
Batch 150/537: Loss=1.1653 (C:5.8655, R:0.0100, T:1.1643(w:1.000)ğŸš€)
Batch 175/537: Loss=1.2506 (C:5.6399, R:0.0099, T:1.2496(w:1.000)ğŸš€)
Batch 200/537: Loss=1.1820 (C:5.7041, R:0.0099, T:1.1810(w:1.000)ğŸš€)
Batch 225/537: Loss=1.2034 (C:5.7142, R:0.0100, T:1.2024(w:1.000)ğŸš€)
Batch 250/537: Loss=1.2036 (C:5.6128, R:0.0100, T:1.2026(w:1.000)ğŸš€)
Batch 275/537: Loss=1.1746 (C:5.5784, R:0.0100, T:1.1736(w:1.000)ğŸš€)
Batch 300/537: Loss=1.1349 (C:5.6337, R:0.0100, T:1.1339(w:1.000)ğŸš€)
Batch 325/537: Loss=1.1583 (C:5.6651, R:0.0100, T:1.1573(w:1.000)ğŸš€)
Batch 350/537: Loss=1.1774 (C:5.7155, R:0.0100, T:1.1764(w:1.000)ğŸš€)
Batch 375/537: Loss=1.1957 (C:5.6824, R:0.0099, T:1.1947(w:1.000)ğŸš€)
Batch 400/537: Loss=1.0918 (C:5.7645, R:0.0099, T:1.0908(w:1.000)ğŸš€)
Batch 425/537: Loss=1.1537 (C:5.6836, R:0.0099, T:1.1527(w:1.000)ğŸš€)
Batch 450/537: Loss=1.0769 (C:5.6653, R:0.0099, T:1.0759(w:1.000)ğŸš€)
Batch 475/537: Loss=1.1354 (C:5.7536, R:0.0099, T:1.1344(w:1.000)ğŸš€)
Batch 500/537: Loss=1.1131 (C:5.7519, R:0.0100, T:1.1121(w:1.000)ğŸš€)
Batch 525/537: Loss=1.0901 (C:5.7651, R:0.0100, T:1.0891(w:1.000)ğŸš€)
ğŸ“ˆ New best topological loss: 1.1776

ğŸ“Š EPOCH 6 TRAINING SUMMARY:
  Total Loss: 1.1786
  Contrastive: 5.7134
  Reconstruction: 0.0100
  Topological: 1.1776 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 19.5613
  Contrastive: 3.4243
  Reconstruction: 0.0100
  Topological: 19.5603 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 6/100 COMPLETE (72.0s)
Train Loss: 1.1786 (C:5.7134, R:0.0100, T:1.1776)
Val Loss:   19.5613 (C:3.4243, R:0.0100, T:19.5603)
ğŸš€ Good topological learning progress
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 7 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1441 (C:5.6896, R:0.0099, T:1.1431(w:1.000)ğŸš€)
Batch  25/537: Loss=1.1306 (C:5.7259, R:0.0100, T:1.1296(w:1.000)ğŸš€)
Batch  50/537: Loss=1.1287 (C:5.7529, R:0.0099, T:1.1277(w:1.000)ğŸš€)
Batch  75/537: Loss=1.0456 (C:5.7961, R:0.0099, T:1.0447(w:1.000)ğŸš€)
Batch 100/537: Loss=1.0064 (C:5.7994, R:0.0100, T:1.0054(w:1.000)ğŸš€)
Batch 125/537: Loss=1.0404 (C:5.7417, R:0.0100, T:1.0394(w:1.000)ğŸš€)
Batch 150/537: Loss=1.0570 (C:5.6871, R:0.0100, T:1.0560(w:1.000)ğŸš€)
Batch 175/537: Loss=1.0920 (C:5.6613, R:0.0099, T:1.0911(w:1.000)ğŸš€)
Batch 200/537: Loss=1.0331 (C:5.6793, R:0.0100, T:1.0321(w:1.000)ğŸš€)
Batch 225/537: Loss=1.0367 (C:5.7510, R:0.0100, T:1.0357(w:1.000)ğŸš€)
Batch 250/537: Loss=1.1070 (C:5.7427, R:0.0100, T:1.1060(w:1.000)ğŸš€)
Batch 275/537: Loss=1.0488 (C:5.7367, R:0.0100, T:1.0478(w:1.000)ğŸš€)
Batch 300/537: Loss=1.0584 (C:5.8187, R:0.0100, T:1.0574(w:1.000)ğŸš€)
Batch 325/537: Loss=1.0434 (C:5.7858, R:0.0100, T:1.0424(w:1.000)ğŸš€)
Batch 350/537: Loss=1.0549 (C:5.7241, R:0.0099, T:1.0539(w:1.000)ğŸš€)
Batch 375/537: Loss=1.0203 (C:5.7727, R:0.0099, T:1.0194(w:1.000)ğŸš€)
Batch 400/537: Loss=1.0204 (C:5.7381, R:0.0100, T:1.0194(w:1.000)ğŸš€)
Batch 425/537: Loss=1.0787 (C:5.7764, R:0.0099, T:1.0777(w:1.000)ğŸš€)
Batch 450/537: Loss=1.0403 (C:5.7712, R:0.0099, T:1.0393(w:1.000)ğŸš€)
Batch 475/537: Loss=1.0120 (C:5.7843, R:0.0099, T:1.0110(w:1.000)ğŸš€)
Batch 500/537: Loss=0.9363 (C:5.7624, R:0.0099, T:0.9353(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.9463 (C:5.7682, R:0.0100, T:0.9453(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 1.0521

ğŸ“Š EPOCH 7 TRAINING SUMMARY:
  Total Loss: 1.0531
  Contrastive: 5.7408
  Reconstruction: 0.0100
  Topological: 1.0521 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 17.0219
  Contrastive: 3.6252
  Reconstruction: 0.0100
  Topological: 17.0209 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 7/100 COMPLETE (83.0s)
Train Loss: 1.0531 (C:5.7408, R:0.0100, T:1.0521)
Val Loss:   17.0219 (C:3.6252, R:0.0100, T:17.0209)
ğŸš€ Good topological learning progress
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 8 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.0073 (C:5.7269, R:0.0100, T:1.0063(w:1.000)ğŸš€)
Batch  25/537: Loss=1.0164 (C:5.8380, R:0.0099, T:1.0154(w:1.000)ğŸš€)
Batch  50/537: Loss=0.9807 (C:5.6859, R:0.0100, T:0.9797(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.9906 (C:5.8257, R:0.0100, T:0.9896(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.9976 (C:5.8634, R:0.0100, T:0.9966(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.9492 (C:5.6824, R:0.0100, T:0.9482(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.9728 (C:5.7502, R:0.0099, T:0.9718(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.9409 (C:5.7412, R:0.0099, T:0.9399(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.0170 (C:5.7722, R:0.0099, T:1.0160(w:1.000)ğŸš€)
Batch 225/537: Loss=0.9995 (C:5.7760, R:0.0099, T:0.9985(w:1.000)ğŸ‰)
Batch 250/537: Loss=1.0028 (C:5.8212, R:0.0099, T:1.0018(w:1.000)ğŸš€)
Batch 275/537: Loss=0.9474 (C:5.8255, R:0.0100, T:0.9464(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.9232 (C:5.7905, R:0.0099, T:0.9222(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.9544 (C:5.7411, R:0.0100, T:0.9534(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.9587 (C:5.7357, R:0.0099, T:0.9577(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.9494 (C:5.7761, R:0.0100, T:0.9484(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.9200 (C:5.7886, R:0.0100, T:0.9190(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.9622 (C:5.7302, R:0.0100, T:0.9612(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.9176 (C:5.7025, R:0.0099, T:0.9166(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.8879 (C:5.7213, R:0.0099, T:0.8869(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.9689 (C:5.8184, R:0.0100, T:0.9679(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.9403 (C:5.8217, R:0.0100, T:0.9393(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.9623

ğŸ“Š EPOCH 8 TRAINING SUMMARY:
  Total Loss: 0.9633
  Contrastive: 5.7613
  Reconstruction: 0.0100
  Topological: 0.9623 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 15.0820
  Contrastive: 3.7684
  Reconstruction: 0.0100
  Topological: 15.0811 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 8/100 COMPLETE (82.1s)
Train Loss: 0.9633 (C:5.7613, R:0.0100, T:0.9623)
Val Loss:   15.0820 (C:3.7684, R:0.0100, T:15.0811)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 9 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.9204 (C:5.7758, R:0.0099, T:0.9194(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.9349 (C:5.6964, R:0.0100, T:0.9339(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.9046 (C:5.7837, R:0.0099, T:0.9036(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.8955 (C:5.8341, R:0.0099, T:0.8945(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.8738 (C:5.7651, R:0.0100, T:0.8728(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.9640 (C:5.7583, R:0.0099, T:0.9630(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.8895 (C:5.7716, R:0.0099, T:0.8885(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.9272 (C:5.7468, R:0.0100, T:0.9262(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.9095 (C:5.7354, R:0.0100, T:0.9085(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.8645 (C:5.8007, R:0.0099, T:0.8635(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.8366 (C:5.7715, R:0.0099, T:0.8357(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.9344 (C:5.6947, R:0.0099, T:0.9334(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.8764 (C:5.8526, R:0.0099, T:0.8754(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.8719 (C:5.7301, R:0.0099, T:0.8710(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.8692 (C:5.8016, R:0.0100, T:0.8682(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.8614 (C:5.7594, R:0.0099, T:0.8604(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.9165 (C:5.7167, R:0.0100, T:0.9155(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.8955 (C:5.8388, R:0.0100, T:0.8945(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.8792 (C:5.7574, R:0.0100, T:0.8782(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.8550 (C:5.7647, R:0.0100, T:0.8540(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.8996 (C:5.7530, R:0.0100, T:0.8986(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.8546 (C:5.6857, R:0.0100, T:0.8536(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.8912

ğŸ“Š EPOCH 9 TRAINING SUMMARY:
  Total Loss: 0.8922
  Contrastive: 5.7650
  Reconstruction: 0.0100
  Topological: 0.8912 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 13.2734
  Contrastive: 3.8908
  Reconstruction: 0.0100
  Topological: 13.2724 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 9/100 COMPLETE (87.2s)
Train Loss: 0.8922 (C:5.7650, R:0.0100, T:0.8912)
Val Loss:   13.2734 (C:3.8908, R:0.0100, T:13.2724)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 10 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.8445 (C:5.8090, R:0.0100, T:0.8435(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.8366 (C:5.7851, R:0.0100, T:0.8356(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.8540 (C:5.7737, R:0.0100, T:0.8530(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.8631 (C:5.8296, R:0.0100, T:0.8621(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.8589 (C:5.7925, R:0.0100, T:0.8579(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.8490 (C:5.7918, R:0.0100, T:0.8480(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.8370 (C:5.7597, R:0.0099, T:0.8360(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.8880 (C:5.9299, R:0.0099, T:0.8870(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.8293 (C:5.7769, R:0.0100, T:0.8283(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.8443 (C:5.8076, R:0.0099, T:0.8433(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.8430 (C:5.7270, R:0.0099, T:0.8420(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.8586 (C:5.7344, R:0.0099, T:0.8576(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.8536 (C:5.7489, R:0.0100, T:0.8526(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.8616 (C:5.7698, R:0.0100, T:0.8606(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.8215 (C:5.7305, R:0.0099, T:0.8205(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.8332 (C:5.9049, R:0.0100, T:0.8322(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.8236 (C:5.8056, R:0.0100, T:0.8226(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.8346 (C:5.7402, R:0.0099, T:0.8336(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.8217 (C:5.7759, R:0.0099, T:0.8207(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.8819 (C:5.7884, R:0.0100, T:0.8809(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.8426 (C:5.7521, R:0.0099, T:0.8416(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.8174 (C:5.8175, R:0.0100, T:0.8164(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.8322

ğŸ“Š EPOCH 10 TRAINING SUMMARY:
  Total Loss: 0.8331
  Contrastive: 5.7724
  Reconstruction: 0.0100
  Topological: 0.8322 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 12.0828
  Contrastive: 3.9741
  Reconstruction: 0.0100
  Topological: 12.0818 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 10/100 COMPLETE (88.3s)
Train Loss: 0.8331 (C:5.7724, R:0.0100, T:0.8322)
Val Loss:   12.0828 (C:3.9741, R:0.0100, T:12.0818)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 11 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.7906 (C:5.8224, R:0.0100, T:0.7896(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.7686 (C:5.7955, R:0.0099, T:0.7676(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.7867 (C:5.8082, R:0.0100, T:0.7857(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.8521 (C:5.8018, R:0.0100, T:0.8511(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.8336 (C:5.7606, R:0.0100, T:0.8326(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.7946 (C:5.7980, R:0.0099, T:0.7937(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.7765 (C:5.8360, R:0.0100, T:0.7755(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.8351 (C:5.7555, R:0.0100, T:0.8341(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.8807 (C:5.7975, R:0.0100, T:0.8797(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.8124 (C:5.8081, R:0.0100, T:0.8114(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.7776 (C:5.7197, R:0.0100, T:0.7766(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.8129 (C:5.7348, R:0.0099, T:0.8119(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.8422 (C:5.7889, R:0.0100, T:0.8412(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.8244 (C:5.7505, R:0.0100, T:0.8234(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.8102 (C:5.8383, R:0.0100, T:0.8092(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.7855 (C:5.7409, R:0.0100, T:0.7845(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.7655 (C:5.8212, R:0.0099, T:0.7645(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.8332 (C:5.7319, R:0.0100, T:0.8322(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.7442 (C:5.7012, R:0.0099, T:0.7432(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.7910 (C:5.7436, R:0.0100, T:0.7901(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.7207 (C:5.7604, R:0.0100, T:0.7197(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.7565 (C:5.8088, R:0.0099, T:0.7555(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.7942

ğŸ“Š EPOCH 11 TRAINING SUMMARY:
  Total Loss: 0.7952
  Contrastive: 5.7751
  Reconstruction: 0.0100
  Topological: 0.7942 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 11.2545
  Contrastive: 4.0162
  Reconstruction: 0.0100
  Topological: 11.2535 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 11/100 COMPLETE (87.4s)
Train Loss: 0.7952 (C:5.7751, R:0.0100, T:0.7942)
Val Loss:   11.2545 (C:4.0162, R:0.0100, T:11.2535)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 12 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.7693 (C:5.7373, R:0.0099, T:0.7683(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.7744 (C:5.7778, R:0.0099, T:0.7734(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.7736 (C:5.8282, R:0.0100, T:0.7726(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.7732 (C:5.7068, R:0.0099, T:0.7722(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.7296 (C:5.8008, R:0.0099, T:0.7286(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.7627 (C:5.8379, R:0.0099, T:0.7617(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.7649 (C:5.7987, R:0.0100, T:0.7639(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.7583 (C:5.7749, R:0.0100, T:0.7573(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.7874 (C:5.8484, R:0.0100, T:0.7864(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.7652 (C:5.7688, R:0.0100, T:0.7642(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.7969 (C:5.8242, R:0.0100, T:0.7959(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.7731 (C:5.7706, R:0.0099, T:0.7721(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.7771 (C:5.7484, R:0.0099, T:0.7761(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.7525 (C:5.7598, R:0.0099, T:0.7515(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.7810 (C:5.7476, R:0.0100, T:0.7800(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.7340 (C:5.7936, R:0.0100, T:0.7330(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.7035 (C:5.7746, R:0.0100, T:0.7025(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.7563 (C:5.7886, R:0.0100, T:0.7553(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.8105 (C:5.7875, R:0.0100, T:0.8095(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.7144 (C:5.8386, R:0.0099, T:0.7134(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.7699 (C:5.7605, R:0.0100, T:0.7689(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.7694 (C:5.7599, R:0.0099, T:0.7684(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.7700

ğŸ“Š EPOCH 12 TRAINING SUMMARY:
  Total Loss: 0.7710
  Contrastive: 5.7732
  Reconstruction: 0.0100
  Topological: 0.7700 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 10.1777
  Contrastive: 4.0991
  Reconstruction: 0.0100
  Topological: 10.1767 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 12/100 COMPLETE (87.5s)
Train Loss: 0.7710 (C:5.7732, R:0.0100, T:0.7700)
Val Loss:   10.1777 (C:4.0991, R:0.0100, T:10.1767)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 13 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.7669 (C:5.7428, R:0.0099, T:0.7660(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.7608 (C:5.7255, R:0.0099, T:0.7598(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.7766 (C:5.7416, R:0.0099, T:0.7756(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.7111 (C:5.7646, R:0.0100, T:0.7101(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.7485 (C:5.7571, R:0.0100, T:0.7475(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.7247 (C:5.7629, R:0.0099, T:0.7238(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.7677 (C:5.7192, R:0.0099, T:0.7667(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.7685 (C:5.7782, R:0.0099, T:0.7675(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.7851 (C:5.7633, R:0.0099, T:0.7842(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.7018 (C:5.8126, R:0.0099, T:0.7008(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.7268 (C:5.8210, R:0.0100, T:0.7258(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.7381 (C:5.7875, R:0.0099, T:0.7371(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.7528 (C:5.7899, R:0.0100, T:0.7518(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.7124 (C:5.8228, R:0.0099, T:0.7114(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.7764 (C:5.7597, R:0.0099, T:0.7754(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.7505 (C:5.7816, R:0.0099, T:0.7495(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.7264 (C:5.7433, R:0.0099, T:0.7254(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.7671 (C:5.7520, R:0.0099, T:0.7661(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.7786 (C:5.7584, R:0.0100, T:0.7776(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.7644 (C:5.7457, R:0.0100, T:0.7634(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.7241 (C:5.7395, R:0.0100, T:0.7231(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.7773 (C:5.6962, R:0.0099, T:0.7763(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.7495

ğŸ“Š EPOCH 13 TRAINING SUMMARY:
  Total Loss: 0.7505
  Contrastive: 5.7740
  Reconstruction: 0.0100
  Topological: 0.7495 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 9.5006
  Contrastive: 4.2032
  Reconstruction: 0.0100
  Topological: 9.4996 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 13/100 COMPLETE (87.2s)
Train Loss: 0.7505 (C:5.7740, R:0.0100, T:0.7495)
Val Loss:   9.5006 (C:4.2032, R:0.0100, T:9.4996)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 14 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.7403 (C:5.8589, R:0.0100, T:0.7393(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.7490 (C:5.7914, R:0.0100, T:0.7480(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.7479 (C:5.7816, R:0.0100, T:0.7469(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.7397 (C:5.7430, R:0.0099, T:0.7387(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.7736 (C:5.7808, R:0.0100, T:0.7726(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.7665 (C:5.7731, R:0.0100, T:0.7655(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.7306 (C:5.8031, R:0.0100, T:0.7296(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.7391 (C:5.7913, R:0.0100, T:0.7381(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.7217 (C:5.8353, R:0.0100, T:0.7207(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.7461 (C:5.7589, R:0.0100, T:0.7451(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.7435 (C:5.7799, R:0.0099, T:0.7425(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.7446 (C:5.7331, R:0.0100, T:0.7436(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.7506 (C:5.7421, R:0.0100, T:0.7496(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.7246 (C:5.7512, R:0.0100, T:0.7236(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.7723 (C:5.8071, R:0.0100, T:0.7713(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.7428 (C:5.7167, R:0.0099, T:0.7418(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.7917 (C:5.7194, R:0.0099, T:0.7907(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.7133 (C:5.7900, R:0.0100, T:0.7123(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.7428 (C:5.8073, R:0.0100, T:0.7418(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6816 (C:5.7874, R:0.0099, T:0.6806(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.7164 (C:5.7226, R:0.0099, T:0.7154(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.7707 (C:5.7583, R:0.0100, T:0.7697(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.7373

ğŸ“Š EPOCH 14 TRAINING SUMMARY:
  Total Loss: 0.7383
  Contrastive: 5.7724
  Reconstruction: 0.0100
  Topological: 0.7373 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 9.0789
  Contrastive: 4.2230
  Reconstruction: 0.0100
  Topological: 9.0779 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 14/100 COMPLETE (87.3s)
Train Loss: 0.7383 (C:5.7724, R:0.0100, T:0.7373)
Val Loss:   9.0789 (C:4.2230, R:0.0100, T:9.0779)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 15 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.7210 (C:5.8016, R:0.0099, T:0.7200(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6977 (C:5.7958, R:0.0100, T:0.6967(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.7097 (C:5.7359, R:0.0099, T:0.7087(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6751 (C:5.8016, R:0.0099, T:0.6741(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.7434 (C:5.7671, R:0.0099, T:0.7424(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.7172 (C:5.8280, R:0.0100, T:0.7162(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.7274 (C:5.7806, R:0.0100, T:0.7264(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6893 (C:5.7409, R:0.0099, T:0.6883(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.7433 (C:5.7503, R:0.0099, T:0.7423(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.7334 (C:5.7779, R:0.0099, T:0.7325(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.7180 (C:5.7578, R:0.0100, T:0.7170(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.7474 (C:5.8170, R:0.0099, T:0.7464(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.7054 (C:5.7261, R:0.0099, T:0.7044(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.7368 (C:5.7571, R:0.0099, T:0.7358(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.7054 (C:5.8009, R:0.0099, T:0.7044(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.7237 (C:5.8328, R:0.0100, T:0.7227(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.7373 (C:5.7292, R:0.0100, T:0.7363(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.7100 (C:5.7935, R:0.0100, T:0.7090(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.7262 (C:5.7584, R:0.0100, T:0.7252(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.7155 (C:5.7917, R:0.0100, T:0.7145(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.7412 (C:5.8472, R:0.0100, T:0.7402(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.7081 (C:5.7713, R:0.0099, T:0.7071(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.7264

ğŸ“Š EPOCH 15 TRAINING SUMMARY:
  Total Loss: 0.7274
  Contrastive: 5.7713
  Reconstruction: 0.0100
  Topological: 0.7264 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 8.9039
  Contrastive: 4.2129
  Reconstruction: 0.0100
  Topological: 8.9029 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 15/100 COMPLETE (89.2s)
Train Loss: 0.7274 (C:5.7713, R:0.0100, T:0.7264)
Val Loss:   8.9039 (C:4.2129, R:0.0100, T:8.9029)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 16 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.7346 (C:5.7851, R:0.0100, T:0.7336(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.7239 (C:5.7543, R:0.0100, T:0.7229(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.7263 (C:5.7769, R:0.0100, T:0.7253(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6958 (C:5.7638, R:0.0100, T:0.6948(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.7139 (C:5.7351, R:0.0099, T:0.7129(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.7822 (C:5.7933, R:0.0099, T:0.7812(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6780 (C:5.7879, R:0.0099, T:0.6770(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.7046 (C:5.7897, R:0.0099, T:0.7036(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.7132 (C:5.7098, R:0.0099, T:0.7122(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.7507 (C:5.7961, R:0.0100, T:0.7497(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.7165 (C:5.7731, R:0.0099, T:0.7155(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.7394 (C:5.7557, R:0.0099, T:0.7384(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.7061 (C:5.7794, R:0.0099, T:0.7051(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.7219 (C:5.7413, R:0.0100, T:0.7209(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.7505 (C:5.7532, R:0.0100, T:0.7495(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.7010 (C:5.7016, R:0.0100, T:0.7000(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.7432 (C:5.7163, R:0.0099, T:0.7422(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.7325 (C:5.7699, R:0.0099, T:0.7315(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.7143 (C:5.7788, R:0.0099, T:0.7133(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6947 (C:5.7835, R:0.0100, T:0.6937(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.7275 (C:5.8079, R:0.0099, T:0.7266(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.7226 (C:5.7547, R:0.0100, T:0.7216(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.7175

ğŸ“Š EPOCH 16 TRAINING SUMMARY:
  Total Loss: 0.7185
  Contrastive: 5.7726
  Reconstruction: 0.0100
  Topological: 0.7175 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 8.5429
  Contrastive: 4.2332
  Reconstruction: 0.0100
  Topological: 8.5419 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 16/100 COMPLETE (87.4s)
Train Loss: 0.7185 (C:5.7726, R:0.0100, T:0.7175)
Val Loss:   8.5429 (C:4.2332, R:0.0100, T:8.5419)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 17 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.7250 (C:5.7723, R:0.0100, T:0.7240(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.7370 (C:5.7665, R:0.0100, T:0.7360(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.7195 (C:5.8261, R:0.0100, T:0.7185(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.7295 (C:5.7527, R:0.0100, T:0.7285(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.7497 (C:5.7442, R:0.0100, T:0.7487(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6737 (C:5.7392, R:0.0100, T:0.6727(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6996 (C:5.7778, R:0.0099, T:0.6986(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.7006 (C:5.7721, R:0.0099, T:0.6996(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6983 (C:5.7437, R:0.0100, T:0.6973(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6930 (C:5.7947, R:0.0099, T:0.6920(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6625 (C:5.7532, R:0.0099, T:0.6615(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6979 (C:5.7715, R:0.0100, T:0.6969(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.7389 (C:5.7773, R:0.0100, T:0.7379(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.7485 (C:5.7598, R:0.0099, T:0.7475(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.7114 (C:5.7642, R:0.0099, T:0.7104(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6833 (C:5.7673, R:0.0100, T:0.6823(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.7242 (C:5.7424, R:0.0099, T:0.7233(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.7320 (C:5.7335, R:0.0099, T:0.7310(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.7397 (C:5.7801, R:0.0099, T:0.7387(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.7157 (C:5.7841, R:0.0099, T:0.7147(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.7174 (C:5.7957, R:0.0100, T:0.7164(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6818 (C:5.7607, R:0.0100, T:0.6808(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.7115

ğŸ“Š EPOCH 17 TRAINING SUMMARY:
  Total Loss: 0.7125
  Contrastive: 5.7706
  Reconstruction: 0.0100
  Topological: 0.7115 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 8.3993
  Contrastive: 4.2654
  Reconstruction: 0.0100
  Topological: 8.3983 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 17/100 COMPLETE (89.8s)
Train Loss: 0.7125 (C:5.7706, R:0.0100, T:0.7115)
Val Loss:   8.3993 (C:4.2654, R:0.0100, T:8.3983)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 18 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.7242 (C:5.7410, R:0.0100, T:0.7232(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6950 (C:5.8090, R:0.0100, T:0.6940(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.7275 (C:5.7853, R:0.0099, T:0.7265(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.7262 (C:5.7800, R:0.0100, T:0.7252(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6959 (C:5.8263, R:0.0099, T:0.6949(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.7183 (C:5.8011, R:0.0100, T:0.7173(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6825 (C:5.8283, R:0.0100, T:0.6815(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.7074 (C:5.7461, R:0.0099, T:0.7064(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6804 (C:5.7570, R:0.0100, T:0.6794(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.7148 (C:5.8327, R:0.0100, T:0.7138(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.7100 (C:5.7429, R:0.0100, T:0.7090(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.7110 (C:5.8029, R:0.0100, T:0.7101(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6981 (C:5.7864, R:0.0100, T:0.6971(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.7249 (C:5.7622, R:0.0099, T:0.7239(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.7229 (C:5.7630, R:0.0100, T:0.7219(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6997 (C:5.7797, R:0.0100, T:0.6987(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.7345 (C:5.7446, R:0.0099, T:0.7335(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.7317 (C:5.7768, R:0.0100, T:0.7307(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.7341 (C:5.7663, R:0.0099, T:0.7331(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.7493 (C:5.7387, R:0.0100, T:0.7483(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.7268 (C:5.8251, R:0.0099, T:0.7258(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.7529 (C:5.8368, R:0.0100, T:0.7519(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.7055

ğŸ“Š EPOCH 18 TRAINING SUMMARY:
  Total Loss: 0.7065
  Contrastive: 5.7712
  Reconstruction: 0.0100
  Topological: 0.7055 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 8.2149
  Contrastive: 4.2737
  Reconstruction: 0.0100
  Topological: 8.2140 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 18/100 COMPLETE (88.6s)
Train Loss: 0.7065 (C:5.7712, R:0.0100, T:0.7055)
Val Loss:   8.2149 (C:4.2737, R:0.0100, T:8.2140)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 19 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.7308 (C:5.7392, R:0.0099, T:0.7298(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6923 (C:5.7480, R:0.0100, T:0.6913(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6882 (C:5.7861, R:0.0100, T:0.6872(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6753 (C:5.7350, R:0.0099, T:0.6743(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.7028 (C:5.7532, R:0.0100, T:0.7018(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6918 (C:5.7549, R:0.0099, T:0.6908(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6652 (C:5.7845, R:0.0100, T:0.6642(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.7496 (C:5.7309, R:0.0100, T:0.7486(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.7214 (C:5.7415, R:0.0100, T:0.7204(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.7200 (C:5.7699, R:0.0099, T:0.7190(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6689 (C:5.7615, R:0.0100, T:0.6679(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.7213 (C:5.7924, R:0.0099, T:0.7203(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.7109 (C:5.7983, R:0.0099, T:0.7099(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.7018 (C:5.7830, R:0.0099, T:0.7008(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.7127 (C:5.8034, R:0.0100, T:0.7117(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6936 (C:5.8013, R:0.0099, T:0.6926(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6875 (C:5.8151, R:0.0100, T:0.6865(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6799 (C:5.7591, R:0.0100, T:0.6789(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.7165 (C:5.7509, R:0.0099, T:0.7155(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.7291 (C:5.7633, R:0.0100, T:0.7281(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6895 (C:5.7348, R:0.0099, T:0.6885(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.7021 (C:5.7775, R:0.0099, T:0.7011(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.7007

ğŸ“Š EPOCH 19 TRAINING SUMMARY:
  Total Loss: 0.7017
  Contrastive: 5.7711
  Reconstruction: 0.0100
  Topological: 0.7007 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 7.8138
  Contrastive: 4.3178
  Reconstruction: 0.0100
  Topological: 7.8128 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 19/100 COMPLETE (87.8s)
Train Loss: 0.7017 (C:5.7711, R:0.0100, T:0.7007)
Val Loss:   7.8138 (C:4.3178, R:0.0100, T:7.8128)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 20 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6976 (C:5.7432, R:0.0099, T:0.6966(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6845 (C:5.8005, R:0.0100, T:0.6835(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.7050 (C:5.8026, R:0.0099, T:0.7040(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6790 (C:5.7900, R:0.0099, T:0.6780(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6900 (C:5.7643, R:0.0100, T:0.6890(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6733 (C:5.7854, R:0.0100, T:0.6723(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.7088 (C:5.7754, R:0.0100, T:0.7078(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.7019 (C:5.7322, R:0.0100, T:0.7009(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.7135 (C:5.7823, R:0.0100, T:0.7125(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6782 (C:5.7968, R:0.0099, T:0.6772(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.7299 (C:5.7831, R:0.0100, T:0.7289(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6696 (C:5.7848, R:0.0100, T:0.6686(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6979 (C:5.7583, R:0.0099, T:0.6969(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6615 (C:5.7720, R:0.0100, T:0.6605(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.7066 (C:5.7523, R:0.0100, T:0.7056(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6682 (C:5.7756, R:0.0099, T:0.6672(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6907 (C:5.7627, R:0.0100, T:0.6897(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.7132 (C:5.7939, R:0.0100, T:0.7122(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6655 (C:5.7510, R:0.0099, T:0.6645(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.7296 (C:5.8274, R:0.0100, T:0.7286(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.7105 (C:5.7696, R:0.0100, T:0.7095(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.7028 (C:5.7615, R:0.0100, T:0.7018(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6936

ğŸ“Š EPOCH 20 TRAINING SUMMARY:
  Total Loss: 0.6946
  Contrastive: 5.7695
  Reconstruction: 0.0100
  Topological: 0.6936 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 7.8225
  Contrastive: 4.2947
  Reconstruction: 0.0100
  Topological: 7.8215 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 20/100 COMPLETE (88.5s)
Train Loss: 0.6946 (C:5.7695, R:0.0100, T:0.6936)
Val Loss:   7.8225 (C:4.2947, R:0.0100, T:7.8215)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 21 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.7027 (C:5.7260, R:0.0100, T:0.7017(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.7379 (C:5.8126, R:0.0100, T:0.7369(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6787 (C:5.7687, R:0.0099, T:0.6777(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6652 (C:5.7798, R:0.0099, T:0.6642(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6771 (C:5.7491, R:0.0100, T:0.6761(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6876 (C:5.7200, R:0.0100, T:0.6866(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6769 (C:5.7270, R:0.0099, T:0.6759(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.7002 (C:5.7550, R:0.0099, T:0.6993(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.7029 (C:5.7953, R:0.0100, T:0.7019(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6839 (C:5.7639, R:0.0099, T:0.6829(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6954 (C:5.7330, R:0.0099, T:0.6944(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.7039 (C:5.7756, R:0.0100, T:0.7029(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.7076 (C:5.7752, R:0.0100, T:0.7066(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.7097 (C:5.7822, R:0.0100, T:0.7087(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6849 (C:5.7720, R:0.0100, T:0.6839(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6673 (C:5.7875, R:0.0100, T:0.6663(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6802 (C:5.7657, R:0.0100, T:0.6792(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6920 (C:5.7598, R:0.0099, T:0.6910(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.7090 (C:5.7614, R:0.0100, T:0.7080(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6800 (C:5.7916, R:0.0099, T:0.6790(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6609 (C:5.8123, R:0.0099, T:0.6599(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6945 (C:5.8321, R:0.0100, T:0.6936(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6897

ğŸ“Š EPOCH 21 TRAINING SUMMARY:
  Total Loss: 0.6907
  Contrastive: 5.7698
  Reconstruction: 0.0100
  Topological: 0.6897 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 7.7176
  Contrastive: 4.3094
  Reconstruction: 0.0100
  Topological: 7.7166 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 21/100 COMPLETE (87.0s)
Train Loss: 0.6907 (C:5.7698, R:0.0100, T:0.6897)
Val Loss:   7.7176 (C:4.3094, R:0.0100, T:7.7166)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 22 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6836 (C:5.7158, R:0.0100, T:0.6826(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6708 (C:5.7893, R:0.0099, T:0.6698(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6903 (C:5.8049, R:0.0100, T:0.6893(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6973 (C:5.7446, R:0.0099, T:0.6963(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6726 (C:5.7760, R:0.0099, T:0.6716(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6839 (C:5.7144, R:0.0099, T:0.6829(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6858 (C:5.7707, R:0.0100, T:0.6848(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6968 (C:5.7790, R:0.0099, T:0.6958(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6774 (C:5.7414, R:0.0099, T:0.6764(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6511 (C:5.7990, R:0.0100, T:0.6501(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.7115 (C:5.7882, R:0.0100, T:0.7105(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.7595 (C:5.7510, R:0.0100, T:0.7585(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.7243 (C:5.7912, R:0.0100, T:0.7233(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.7079 (C:5.7358, R:0.0099, T:0.7069(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.7156 (C:5.7939, R:0.0100, T:0.7146(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.7117 (C:5.7827, R:0.0099, T:0.7107(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6611 (C:5.7943, R:0.0099, T:0.6601(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6819 (C:5.7643, R:0.0100, T:0.6809(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6645 (C:5.7352, R:0.0100, T:0.6635(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6931 (C:5.7748, R:0.0100, T:0.6921(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6928 (C:5.7609, R:0.0100, T:0.6918(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6707 (C:5.8198, R:0.0100, T:0.6697(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6832

ğŸ“Š EPOCH 22 TRAINING SUMMARY:
  Total Loss: 0.6842
  Contrastive: 5.7704
  Reconstruction: 0.0100
  Topological: 0.6832 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 7.4032
  Contrastive: 4.3685
  Reconstruction: 0.0100
  Topological: 7.4022 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 22/100 COMPLETE (86.4s)
Train Loss: 0.6842 (C:5.7704, R:0.0100, T:0.6832)
Val Loss:   7.4032 (C:4.3685, R:0.0100, T:7.4022)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 23 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6646 (C:5.7574, R:0.0099, T:0.6636(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6931 (C:5.8118, R:0.0100, T:0.6921(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6939 (C:5.8007, R:0.0100, T:0.6929(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6974 (C:5.7825, R:0.0100, T:0.6964(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6655 (C:5.7978, R:0.0100, T:0.6645(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6397 (C:5.7443, R:0.0100, T:0.6387(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6795 (C:5.7300, R:0.0099, T:0.6785(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6722 (C:5.7803, R:0.0100, T:0.6712(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6991 (C:5.7893, R:0.0100, T:0.6981(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6894 (C:5.7652, R:0.0100, T:0.6884(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6731 (C:5.7175, R:0.0099, T:0.6721(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6629 (C:5.7575, R:0.0100, T:0.6619(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6932 (C:5.6936, R:0.0099, T:0.6922(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6895 (C:5.7434, R:0.0099, T:0.6885(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6798 (C:5.8253, R:0.0099, T:0.6788(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6787 (C:5.7786, R:0.0100, T:0.6777(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6440 (C:5.7650, R:0.0099, T:0.6430(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.7060 (C:5.7584, R:0.0100, T:0.7050(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6880 (C:5.7826, R:0.0099, T:0.6870(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6861 (C:5.7425, R:0.0100, T:0.6851(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6554 (C:5.7415, R:0.0099, T:0.6544(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6800 (C:5.7629, R:0.0099, T:0.6790(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6791

ğŸ“Š EPOCH 23 TRAINING SUMMARY:
  Total Loss: 0.6801
  Contrastive: 5.7687
  Reconstruction: 0.0100
  Topological: 0.6791 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 7.2988
  Contrastive: 4.3741
  Reconstruction: 0.0100
  Topological: 7.2978 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 23/100 COMPLETE (86.0s)
Train Loss: 0.6801 (C:5.7687, R:0.0100, T:0.6791)
Val Loss:   7.2988 (C:4.3741, R:0.0100, T:7.2978)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 24 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6709 (C:5.7396, R:0.0099, T:0.6699(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6582 (C:5.7856, R:0.0100, T:0.6572(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6686 (C:5.7302, R:0.0099, T:0.6677(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6535 (C:5.7821, R:0.0100, T:0.6525(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6971 (C:5.7898, R:0.0100, T:0.6961(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6929 (C:5.7374, R:0.0099, T:0.6919(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6864 (C:5.7476, R:0.0100, T:0.6854(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6706 (C:5.7308, R:0.0100, T:0.6696(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6678 (C:5.7898, R:0.0100, T:0.6668(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6754 (C:5.7598, R:0.0100, T:0.6744(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6912 (C:5.8037, R:0.0100, T:0.6902(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6762 (C:5.8164, R:0.0100, T:0.6752(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6865 (C:5.7733, R:0.0100, T:0.6855(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6599 (C:5.7723, R:0.0100, T:0.6589(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6578 (C:5.7813, R:0.0100, T:0.6568(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6907 (C:5.8241, R:0.0100, T:0.6897(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6887 (C:5.7789, R:0.0100, T:0.6877(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6483 (C:5.8185, R:0.0099, T:0.6473(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6577 (C:5.7442, R:0.0100, T:0.6567(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.7001 (C:5.7814, R:0.0100, T:0.6991(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6812 (C:5.7537, R:0.0099, T:0.6802(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.7119 (C:5.7616, R:0.0100, T:0.7109(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6749

ğŸ“Š EPOCH 24 TRAINING SUMMARY:
  Total Loss: 0.6759
  Contrastive: 5.7688
  Reconstruction: 0.0100
  Topological: 0.6749 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.9867
  Contrastive: 4.4199
  Reconstruction: 0.0100
  Topological: 6.9857 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 24/100 COMPLETE (87.8s)
Train Loss: 0.6759 (C:5.7688, R:0.0100, T:0.6749)
Val Loss:   6.9867 (C:4.4199, R:0.0100, T:6.9857)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 25 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6604 (C:5.7596, R:0.0099, T:0.6594(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6910 (C:5.8183, R:0.0100, T:0.6900(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.7032 (C:5.7675, R:0.0100, T:0.7022(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6504 (C:5.7387, R:0.0099, T:0.6494(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6652 (C:5.7948, R:0.0100, T:0.6643(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.7116 (C:5.7501, R:0.0100, T:0.7106(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6856 (C:5.7521, R:0.0099, T:0.6847(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6908 (C:5.7249, R:0.0100, T:0.6898(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6804 (C:5.7484, R:0.0100, T:0.6794(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6832 (C:5.7577, R:0.0100, T:0.6822(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6444 (C:5.8154, R:0.0100, T:0.6434(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6570 (C:5.7265, R:0.0099, T:0.6560(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6493 (C:5.7774, R:0.0099, T:0.6483(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6957 (C:5.7992, R:0.0100, T:0.6947(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6775 (C:5.7196, R:0.0099, T:0.6765(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6849 (C:5.7693, R:0.0099, T:0.6839(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6583 (C:5.7846, R:0.0099, T:0.6573(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6582 (C:5.7600, R:0.0099, T:0.6572(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6527 (C:5.8161, R:0.0100, T:0.6517(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6774 (C:5.7770, R:0.0099, T:0.6764(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6774 (C:5.7692, R:0.0100, T:0.6764(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6680 (C:5.7647, R:0.0100, T:0.6670(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6714

ğŸ“Š EPOCH 25 TRAINING SUMMARY:
  Total Loss: 0.6724
  Contrastive: 5.7681
  Reconstruction: 0.0100
  Topological: 0.6714 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 7.0748
  Contrastive: 4.4004
  Reconstruction: 0.0100
  Topological: 7.0738 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 25/100 COMPLETE (87.7s)
Train Loss: 0.6724 (C:5.7681, R:0.0100, T:0.6714)
Val Loss:   7.0748 (C:4.4004, R:0.0100, T:7.0738)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 26 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6745 (C:5.7557, R:0.0099, T:0.6735(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6658 (C:5.7715, R:0.0099, T:0.6648(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6680 (C:5.7566, R:0.0099, T:0.6670(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6648 (C:5.7964, R:0.0100, T:0.6638(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6608 (C:5.7777, R:0.0100, T:0.6598(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6783 (C:5.7577, R:0.0100, T:0.6773(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.7140 (C:5.7716, R:0.0099, T:0.7130(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6620 (C:5.7593, R:0.0100, T:0.6610(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6283 (C:5.7629, R:0.0100, T:0.6273(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.7078 (C:5.7186, R:0.0100, T:0.7068(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6848 (C:5.7364, R:0.0099, T:0.6839(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6952 (C:5.7249, R:0.0100, T:0.6942(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.7013 (C:5.7697, R:0.0100, T:0.7003(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6401 (C:5.7133, R:0.0099, T:0.6391(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6664 (C:5.7087, R:0.0099, T:0.6654(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6592 (C:5.7785, R:0.0100, T:0.6582(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6749 (C:5.7853, R:0.0099, T:0.6739(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6778 (C:5.7511, R:0.0100, T:0.6768(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6476 (C:5.7160, R:0.0100, T:0.6466(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6736 (C:5.7829, R:0.0099, T:0.6726(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6473 (C:5.7581, R:0.0099, T:0.6463(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6768 (C:5.8138, R:0.0099, T:0.6758(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6695

ğŸ“Š EPOCH 26 TRAINING SUMMARY:
  Total Loss: 0.6705
  Contrastive: 5.7695
  Reconstruction: 0.0100
  Topological: 0.6695 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 7.0712
  Contrastive: 4.3792
  Reconstruction: 0.0100
  Topological: 7.0702 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 26/100 COMPLETE (87.2s)
Train Loss: 0.6705 (C:5.7695, R:0.0100, T:0.6695)
Val Loss:   7.0712 (C:4.3792, R:0.0100, T:7.0702)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 27 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6537 (C:5.7133, R:0.0099, T:0.6527(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6847 (C:5.7685, R:0.0099, T:0.6837(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6680 (C:5.7550, R:0.0100, T:0.6670(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6720 (C:5.7601, R:0.0100, T:0.6711(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6526 (C:5.8462, R:0.0100, T:0.6516(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6288 (C:5.7608, R:0.0099, T:0.6278(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6661 (C:5.7806, R:0.0099, T:0.6651(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.7136 (C:5.7453, R:0.0099, T:0.7126(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6770 (C:5.7693, R:0.0100, T:0.6760(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6410 (C:5.7673, R:0.0099, T:0.6400(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6742 (C:5.7934, R:0.0099, T:0.6732(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6616 (C:5.7450, R:0.0099, T:0.6606(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6880 (C:5.7777, R:0.0100, T:0.6870(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.7260 (C:5.7978, R:0.0100, T:0.7250(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6793 (C:5.8135, R:0.0099, T:0.6783(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6621 (C:5.7763, R:0.0100, T:0.6611(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6696 (C:5.7852, R:0.0100, T:0.6686(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6438 (C:5.7215, R:0.0100, T:0.6428(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6633 (C:5.8058, R:0.0099, T:0.6624(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6684 (C:5.8098, R:0.0100, T:0.6674(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6888 (C:5.7781, R:0.0100, T:0.6878(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6709 (C:5.7639, R:0.0100, T:0.6699(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6652

ğŸ“Š EPOCH 27 TRAINING SUMMARY:
  Total Loss: 0.6662
  Contrastive: 5.7666
  Reconstruction: 0.0100
  Topological: 0.6652 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.8111
  Contrastive: 4.4412
  Reconstruction: 0.0100
  Topological: 6.8101 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 27/100 COMPLETE (87.5s)
Train Loss: 0.6662 (C:5.7666, R:0.0100, T:0.6652)
Val Loss:   6.8111 (C:4.4412, R:0.0100, T:6.8101)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 28 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6671 (C:5.7885, R:0.0100, T:0.6661(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.7122 (C:5.8047, R:0.0100, T:0.7112(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6163 (C:5.7742, R:0.0099, T:0.6153(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6486 (C:5.7526, R:0.0100, T:0.6476(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6740 (C:5.7396, R:0.0100, T:0.6730(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6577 (C:5.7617, R:0.0099, T:0.6567(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6950 (C:5.7522, R:0.0100, T:0.6940(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6674 (C:5.8117, R:0.0100, T:0.6664(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6582 (C:5.7614, R:0.0100, T:0.6572(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.7024 (C:5.7436, R:0.0100, T:0.7014(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6250 (C:5.7752, R:0.0099, T:0.6240(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6750 (C:5.8196, R:0.0100, T:0.6740(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.7148 (C:5.7253, R:0.0099, T:0.7138(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6744 (C:5.7898, R:0.0100, T:0.6734(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6798 (C:5.8070, R:0.0100, T:0.6788(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6947 (C:5.7940, R:0.0099, T:0.6937(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6810 (C:5.7832, R:0.0100, T:0.6800(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6688 (C:5.7609, R:0.0099, T:0.6678(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6548 (C:5.7591, R:0.0100, T:0.6538(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6603 (C:5.8077, R:0.0099, T:0.6593(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6612 (C:5.7792, R:0.0099, T:0.6602(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6865 (C:5.7617, R:0.0100, T:0.6856(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6630

ğŸ“Š EPOCH 28 TRAINING SUMMARY:
  Total Loss: 0.6640
  Contrastive: 5.7684
  Reconstruction: 0.0100
  Topological: 0.6630 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.7625
  Contrastive: 4.4329
  Reconstruction: 0.0100
  Topological: 6.7615 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 28/100 COMPLETE (87.1s)
Train Loss: 0.6640 (C:5.7684, R:0.0100, T:0.6630)
Val Loss:   6.7625 (C:4.4329, R:0.0100, T:6.7615)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 29 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6591 (C:5.7860, R:0.0100, T:0.6581(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6522 (C:5.7479, R:0.0099, T:0.6512(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6478 (C:5.7633, R:0.0100, T:0.6468(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6356 (C:5.7562, R:0.0099, T:0.6346(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6641 (C:5.7502, R:0.0100, T:0.6631(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6939 (C:5.7480, R:0.0099, T:0.6929(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6827 (C:5.7247, R:0.0100, T:0.6817(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6470 (C:5.7885, R:0.0100, T:0.6460(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6722 (C:5.7918, R:0.0099, T:0.6712(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6812 (C:5.7684, R:0.0099, T:0.6802(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6429 (C:5.7616, R:0.0099, T:0.6419(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6515 (C:5.7638, R:0.0100, T:0.6505(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6639 (C:5.7166, R:0.0099, T:0.6629(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6930 (C:5.7509, R:0.0099, T:0.6920(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6517 (C:5.7675, R:0.0099, T:0.6507(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6645 (C:5.7769, R:0.0100, T:0.6635(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.7035 (C:5.7459, R:0.0100, T:0.7025(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6486 (C:5.7685, R:0.0099, T:0.6476(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6611 (C:5.7798, R:0.0099, T:0.6601(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6686 (C:5.7355, R:0.0099, T:0.6676(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6651 (C:5.7476, R:0.0100, T:0.6641(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6357 (C:5.7714, R:0.0099, T:0.6347(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6605

ğŸ“Š EPOCH 29 TRAINING SUMMARY:
  Total Loss: 0.6615
  Contrastive: 5.7645
  Reconstruction: 0.0100
  Topological: 0.6605 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.5294
  Contrastive: 4.4665
  Reconstruction: 0.0100
  Topological: 6.5284 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 29/100 COMPLETE (87.4s)
Train Loss: 0.6615 (C:5.7645, R:0.0100, T:0.6605)
Val Loss:   6.5294 (C:4.4665, R:0.0100, T:6.5284)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 30 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6540 (C:5.8022, R:0.0100, T:0.6530(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6877 (C:5.7506, R:0.0100, T:0.6867(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6868 (C:5.7732, R:0.0100, T:0.6858(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6914 (C:5.7722, R:0.0099, T:0.6904(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6965 (C:5.8232, R:0.0100, T:0.6956(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6771 (C:5.7558, R:0.0100, T:0.6761(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6692 (C:5.7525, R:0.0099, T:0.6682(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6677 (C:5.7645, R:0.0100, T:0.6667(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6642 (C:5.7292, R:0.0099, T:0.6632(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6353 (C:5.7651, R:0.0099, T:0.6343(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6824 (C:5.7657, R:0.0099, T:0.6814(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6709 (C:5.7667, R:0.0100, T:0.6699(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6561 (C:5.7879, R:0.0100, T:0.6551(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6784 (C:5.7473, R:0.0100, T:0.6774(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6744 (C:5.7604, R:0.0099, T:0.6734(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6714 (C:5.7886, R:0.0100, T:0.6704(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6181 (C:5.7662, R:0.0100, T:0.6171(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6763 (C:5.7182, R:0.0099, T:0.6753(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5965 (C:5.7557, R:0.0099, T:0.5955(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6691 (C:5.7788, R:0.0099, T:0.6681(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6721 (C:5.7491, R:0.0099, T:0.6711(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6732 (C:5.7475, R:0.0100, T:0.6722(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6592

ğŸ“Š EPOCH 30 TRAINING SUMMARY:
  Total Loss: 0.6602
  Contrastive: 5.7638
  Reconstruction: 0.0100
  Topological: 0.6592 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.6683
  Contrastive: 4.4453
  Reconstruction: 0.0100
  Topological: 6.6673 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 30/100 COMPLETE (87.2s)
Train Loss: 0.6602 (C:5.7638, R:0.0100, T:0.6592)
Val Loss:   6.6683 (C:4.4453, R:0.0100, T:6.6673)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 31 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6539 (C:5.7436, R:0.0099, T:0.6529(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6648 (C:5.7717, R:0.0100, T:0.6638(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6411 (C:5.7348, R:0.0099, T:0.6401(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6672 (C:5.7429, R:0.0099, T:0.6662(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6884 (C:5.7946, R:0.0100, T:0.6874(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6914 (C:5.7952, R:0.0100, T:0.6904(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6271 (C:5.7813, R:0.0099, T:0.6261(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6587 (C:5.7629, R:0.0099, T:0.6577(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6544 (C:5.7662, R:0.0100, T:0.6534(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6687 (C:5.7943, R:0.0100, T:0.6677(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6302 (C:5.7550, R:0.0100, T:0.6292(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6595 (C:5.7626, R:0.0099, T:0.6585(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6732 (C:5.7344, R:0.0100, T:0.6722(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6531 (C:5.7637, R:0.0099, T:0.6522(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6645 (C:5.7180, R:0.0100, T:0.6635(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6631 (C:5.7512, R:0.0100, T:0.6621(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6468 (C:5.7463, R:0.0100, T:0.6459(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6865 (C:5.8296, R:0.0099, T:0.6855(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6407 (C:5.7957, R:0.0099, T:0.6397(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6441 (C:5.8285, R:0.0100, T:0.6431(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6637 (C:5.7698, R:0.0099, T:0.6627(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6668 (C:5.7848, R:0.0100, T:0.6658(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6579

ğŸ“Š EPOCH 31 TRAINING SUMMARY:
  Total Loss: 0.6589
  Contrastive: 5.7618
  Reconstruction: 0.0100
  Topological: 0.6579 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.4857
  Contrastive: 4.4566
  Reconstruction: 0.0100
  Topological: 6.4847 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 31/100 COMPLETE (89.8s)
Train Loss: 0.6589 (C:5.7618, R:0.0100, T:0.6579)
Val Loss:   6.4857 (C:4.4566, R:0.0100, T:6.4847)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 32 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6622 (C:5.7698, R:0.0100, T:0.6612(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6491 (C:5.7609, R:0.0099, T:0.6481(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6466 (C:5.7347, R:0.0100, T:0.6456(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6406 (C:5.7649, R:0.0100, T:0.6396(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6604 (C:5.7479, R:0.0100, T:0.6594(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6468 (C:5.7857, R:0.0100, T:0.6458(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6428 (C:5.7460, R:0.0099, T:0.6418(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6777 (C:5.7642, R:0.0100, T:0.6767(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6429 (C:5.7875, R:0.0100, T:0.6419(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6906 (C:5.7802, R:0.0100, T:0.6896(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6971 (C:5.7315, R:0.0100, T:0.6961(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6693 (C:5.7546, R:0.0100, T:0.6683(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6439 (C:5.7658, R:0.0099, T:0.6429(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6672 (C:5.7904, R:0.0100, T:0.6662(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6439 (C:5.7907, R:0.0100, T:0.6429(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6781 (C:5.8093, R:0.0100, T:0.6771(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6251 (C:5.7744, R:0.0100, T:0.6241(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6480 (C:5.7533, R:0.0100, T:0.6470(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6713 (C:5.8203, R:0.0099, T:0.6703(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6553 (C:5.7538, R:0.0099, T:0.6543(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6630 (C:5.7509, R:0.0100, T:0.6620(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6907 (C:5.8209, R:0.0100, T:0.6897(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6556

ğŸ“Š EPOCH 32 TRAINING SUMMARY:
  Total Loss: 0.6566
  Contrastive: 5.7613
  Reconstruction: 0.0100
  Topological: 0.6556 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.5003
  Contrastive: 4.4456
  Reconstruction: 0.0100
  Topological: 6.4993 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 32/100 COMPLETE (88.7s)
Train Loss: 0.6566 (C:5.7613, R:0.0100, T:0.6556)
Val Loss:   6.5003 (C:4.4456, R:0.0100, T:6.4993)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 33 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6461 (C:5.7241, R:0.0099, T:0.6451(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6767 (C:5.7622, R:0.0100, T:0.6757(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6508 (C:5.7808, R:0.0099, T:0.6498(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6176 (C:5.7451, R:0.0099, T:0.6166(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6384 (C:5.7584, R:0.0100, T:0.6374(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6452 (C:5.7192, R:0.0099, T:0.6442(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6326 (C:5.7723, R:0.0100, T:0.6317(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6424 (C:5.7576, R:0.0099, T:0.6414(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6563 (C:5.7566, R:0.0099, T:0.6553(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6569 (C:5.8070, R:0.0100, T:0.6559(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6319 (C:5.7665, R:0.0099, T:0.6309(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6650 (C:5.7428, R:0.0100, T:0.6640(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6661 (C:5.7525, R:0.0099, T:0.6651(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6619 (C:5.7035, R:0.0099, T:0.6609(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6654 (C:5.7881, R:0.0099, T:0.6644(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6575 (C:5.7619, R:0.0099, T:0.6565(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6213 (C:5.7280, R:0.0100, T:0.6204(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6563 (C:5.7309, R:0.0100, T:0.6553(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6231 (C:5.7283, R:0.0099, T:0.6221(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6561 (C:5.7407, R:0.0099, T:0.6551(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6711 (C:5.7912, R:0.0100, T:0.6701(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6346 (C:5.7145, R:0.0099, T:0.6336(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6539

ğŸ“Š EPOCH 33 TRAINING SUMMARY:
  Total Loss: 0.6549
  Contrastive: 5.7608
  Reconstruction: 0.0100
  Topological: 0.6539 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.2041
  Contrastive: 4.5269
  Reconstruction: 0.0100
  Topological: 6.2031 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 33/100 COMPLETE (89.4s)
Train Loss: 0.6549 (C:5.7608, R:0.0100, T:0.6539)
Val Loss:   6.2041 (C:4.5269, R:0.0100, T:6.2031)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 34 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6509 (C:5.8216, R:0.0100, T:0.6499(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6677 (C:5.7173, R:0.0100, T:0.6667(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6314 (C:5.7754, R:0.0099, T:0.6305(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6203 (C:5.7768, R:0.0100, T:0.6193(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6675 (C:5.7355, R:0.0100, T:0.6665(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6598 (C:5.7721, R:0.0100, T:0.6588(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6734 (C:5.7444, R:0.0100, T:0.6724(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6126 (C:5.6933, R:0.0099, T:0.6116(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6350 (C:5.7494, R:0.0099, T:0.6340(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6459 (C:5.7792, R:0.0099, T:0.6449(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6706 (C:5.6845, R:0.0099, T:0.6696(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6738 (C:5.7434, R:0.0100, T:0.6728(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6772 (C:5.7824, R:0.0100, T:0.6762(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6242 (C:5.7297, R:0.0099, T:0.6233(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6563 (C:5.7607, R:0.0099, T:0.6554(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6259 (C:5.7562, R:0.0100, T:0.6249(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6303 (C:5.7716, R:0.0100, T:0.6293(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6463 (C:5.7797, R:0.0100, T:0.6453(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6498 (C:5.7524, R:0.0099, T:0.6488(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6602 (C:5.7343, R:0.0099, T:0.6592(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6327 (C:5.7755, R:0.0100, T:0.6317(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6377 (C:5.7409, R:0.0099, T:0.6367(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6507

ğŸ“Š EPOCH 34 TRAINING SUMMARY:
  Total Loss: 0.6517
  Contrastive: 5.7615
  Reconstruction: 0.0100
  Topological: 0.6507 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.1005
  Contrastive: 4.5305
  Reconstruction: 0.0100
  Topological: 6.0995 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 34/100 COMPLETE (90.3s)
Train Loss: 0.6517 (C:5.7615, R:0.0100, T:0.6507)
Val Loss:   6.1005 (C:4.5305, R:0.0100, T:6.0995)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 35 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6317 (C:5.8172, R:0.0100, T:0.6307(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6499 (C:5.7860, R:0.0100, T:0.6489(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6440 (C:5.7622, R:0.0100, T:0.6430(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6584 (C:5.7567, R:0.0100, T:0.6574(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6336 (C:5.7948, R:0.0099, T:0.6326(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6359 (C:5.7592, R:0.0099, T:0.6349(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6424 (C:5.7567, R:0.0099, T:0.6414(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6545 (C:5.8059, R:0.0100, T:0.6535(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6460 (C:5.7432, R:0.0099, T:0.6450(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6802 (C:5.7980, R:0.0099, T:0.6792(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6259 (C:5.7526, R:0.0099, T:0.6249(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6175 (C:5.7745, R:0.0099, T:0.6166(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6517 (C:5.7248, R:0.0099, T:0.6507(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6412 (C:5.7385, R:0.0100, T:0.6402(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6499 (C:5.7985, R:0.0100, T:0.6489(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6466 (C:5.8227, R:0.0100, T:0.6456(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6009 (C:5.7756, R:0.0100, T:0.5999(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6401 (C:5.7898, R:0.0099, T:0.6391(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6408 (C:5.7202, R:0.0100, T:0.6398(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6703 (C:5.7389, R:0.0100, T:0.6693(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6526 (C:5.7337, R:0.0100, T:0.6516(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6437 (C:5.7775, R:0.0099, T:0.6427(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 35 TRAINING SUMMARY:
  Total Loss: 0.6521
  Contrastive: 5.7599
  Reconstruction: 0.0100
  Topological: 0.6511 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.2518
  Contrastive: 4.4815
  Reconstruction: 0.0100
  Topological: 6.2508 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 35/100 COMPLETE (89.8s)
Train Loss: 0.6521 (C:5.7599, R:0.0100, T:0.6511)
Val Loss:   6.2518 (C:4.4815, R:0.0100, T:6.2508)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 36 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6646 (C:5.7144, R:0.0100, T:0.6636(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6697 (C:5.7566, R:0.0100, T:0.6687(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6547 (C:5.7817, R:0.0100, T:0.6537(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6462 (C:5.7713, R:0.0099, T:0.6453(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6220 (C:5.7320, R:0.0099, T:0.6210(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6929 (C:5.7599, R:0.0100, T:0.6919(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6236 (C:5.7198, R:0.0099, T:0.6226(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6669 (C:5.8017, R:0.0100, T:0.6659(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6452 (C:5.7682, R:0.0100, T:0.6442(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6727 (C:5.7466, R:0.0100, T:0.6717(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6381 (C:5.7420, R:0.0099, T:0.6371(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6433 (C:5.7833, R:0.0100, T:0.6423(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6492 (C:5.7656, R:0.0099, T:0.6482(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6528 (C:5.7692, R:0.0099, T:0.6518(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6414 (C:5.7733, R:0.0100, T:0.6404(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6390 (C:5.7349, R:0.0100, T:0.6380(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6261 (C:5.7144, R:0.0100, T:0.6251(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6605 (C:5.7580, R:0.0099, T:0.6595(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6632 (C:5.7888, R:0.0099, T:0.6623(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6868 (C:5.7012, R:0.0099, T:0.6858(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6561 (C:5.7687, R:0.0100, T:0.6551(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6396 (C:5.7777, R:0.0099, T:0.6386(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6475

ğŸ“Š EPOCH 36 TRAINING SUMMARY:
  Total Loss: 0.6485
  Contrastive: 5.7602
  Reconstruction: 0.0100
  Topological: 0.6475 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.1263
  Contrastive: 4.5060
  Reconstruction: 0.0100
  Topological: 6.1253 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 36/100 COMPLETE (88.4s)
Train Loss: 0.6485 (C:5.7602, R:0.0100, T:0.6475)
Val Loss:   6.1263 (C:4.5060, R:0.0100, T:6.1253)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 37 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6393 (C:5.7529, R:0.0100, T:0.6383(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6180 (C:5.6917, R:0.0099, T:0.6170(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6461 (C:5.7223, R:0.0099, T:0.6451(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6616 (C:5.7752, R:0.0100, T:0.6606(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6564 (C:5.7450, R:0.0100, T:0.6554(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6554 (C:5.7553, R:0.0100, T:0.6543(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6631 (C:5.7173, R:0.0100, T:0.6621(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6572 (C:5.7197, R:0.0099, T:0.6562(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6323 (C:5.7656, R:0.0099, T:0.6313(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6593 (C:5.7508, R:0.0099, T:0.6583(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6638 (C:5.8074, R:0.0100, T:0.6628(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6627 (C:5.7576, R:0.0100, T:0.6617(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6432 (C:5.6872, R:0.0100, T:0.6422(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6473 (C:5.7521, R:0.0099, T:0.6463(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6688 (C:5.7298, R:0.0100, T:0.6678(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6453 (C:5.7251, R:0.0100, T:0.6443(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6646 (C:5.7992, R:0.0099, T:0.6636(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6434 (C:5.7157, R:0.0100, T:0.6424(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6524 (C:5.7341, R:0.0100, T:0.6514(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6346 (C:5.7895, R:0.0100, T:0.6336(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6274 (C:5.7573, R:0.0099, T:0.6264(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6768 (C:5.7341, R:0.0100, T:0.6758(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 37 TRAINING SUMMARY:
  Total Loss: 0.6486
  Contrastive: 5.7591
  Reconstruction: 0.0100
  Topological: 0.6476 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.9573
  Contrastive: 4.5128
  Reconstruction: 0.0100
  Topological: 5.9563 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 37/100 COMPLETE (89.1s)
Train Loss: 0.6486 (C:5.7591, R:0.0100, T:0.6476)
Val Loss:   5.9573 (C:4.5128, R:0.0100, T:5.9563)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 38 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6423 (C:5.7788, R:0.0099, T:0.6413(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6424 (C:5.7304, R:0.0099, T:0.6415(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6457 (C:5.7442, R:0.0100, T:0.6447(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6495 (C:5.7908, R:0.0100, T:0.6485(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6521 (C:5.8030, R:0.0100, T:0.6511(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6516 (C:5.7241, R:0.0099, T:0.6506(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6616 (C:5.7596, R:0.0100, T:0.6606(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6917 (C:5.7240, R:0.0100, T:0.6907(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6858 (C:5.7666, R:0.0100, T:0.6848(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6494 (C:5.7089, R:0.0099, T:0.6484(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6433 (C:5.7804, R:0.0099, T:0.6423(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6380 (C:5.7843, R:0.0100, T:0.6370(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6061 (C:5.7415, R:0.0100, T:0.6051(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6571 (C:5.7182, R:0.0099, T:0.6561(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6529 (C:5.7493, R:0.0100, T:0.6519(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6553 (C:5.7798, R:0.0099, T:0.6543(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6664 (C:5.7762, R:0.0099, T:0.6654(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6400 (C:5.7515, R:0.0100, T:0.6390(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6501 (C:5.7590, R:0.0099, T:0.6491(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6576 (C:5.7765, R:0.0100, T:0.6566(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6721 (C:5.7238, R:0.0099, T:0.6711(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6502 (C:5.7335, R:0.0099, T:0.6492(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6457

ğŸ“Š EPOCH 38 TRAINING SUMMARY:
  Total Loss: 0.6467
  Contrastive: 5.7581
  Reconstruction: 0.0100
  Topological: 0.6457 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.9854
  Contrastive: 4.4785
  Reconstruction: 0.0100
  Topological: 5.9844 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 38/100 COMPLETE (89.3s)
Train Loss: 0.6467 (C:5.7581, R:0.0100, T:0.6457)
Val Loss:   5.9854 (C:4.4785, R:0.0100, T:5.9844)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 39 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6325 (C:5.7085, R:0.0100, T:0.6315(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6418 (C:5.7573, R:0.0099, T:0.6408(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6705 (C:5.7610, R:0.0099, T:0.6695(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6461 (C:5.7793, R:0.0100, T:0.6451(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6443 (C:5.7812, R:0.0100, T:0.6433(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6180 (C:5.7626, R:0.0100, T:0.6170(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6435 (C:5.7701, R:0.0099, T:0.6425(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5983 (C:5.7477, R:0.0099, T:0.5973(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6423 (C:5.7696, R:0.0100, T:0.6413(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5901 (C:5.8012, R:0.0100, T:0.5891(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6444 (C:5.7493, R:0.0100, T:0.6434(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6551 (C:5.7499, R:0.0100, T:0.6541(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6450 (C:5.7631, R:0.0099, T:0.6440(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6992 (C:5.7661, R:0.0100, T:0.6982(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6899 (C:5.7394, R:0.0100, T:0.6889(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6015 (C:5.7737, R:0.0100, T:0.6005(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6351 (C:5.7194, R:0.0099, T:0.6342(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6658 (C:5.7380, R:0.0100, T:0.6648(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6470 (C:5.7883, R:0.0100, T:0.6460(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6295 (C:5.7857, R:0.0099, T:0.6285(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6418 (C:5.7306, R:0.0100, T:0.6408(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6182 (C:5.8086, R:0.0100, T:0.6172(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6444

ğŸ“Š EPOCH 39 TRAINING SUMMARY:
  Total Loss: 0.6454
  Contrastive: 5.7576
  Reconstruction: 0.0100
  Topological: 0.6444 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.9235
  Contrastive: 4.5147
  Reconstruction: 0.0100
  Topological: 5.9225 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 39/100 COMPLETE (90.3s)
Train Loss: 0.6454 (C:5.7576, R:0.0100, T:0.6444)
Val Loss:   5.9235 (C:4.5147, R:0.0100, T:5.9225)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 40 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6638 (C:5.7366, R:0.0100, T:0.6628(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6391 (C:5.7500, R:0.0099, T:0.6381(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6574 (C:5.7725, R:0.0099, T:0.6564(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6298 (C:5.7034, R:0.0099, T:0.6288(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6335 (C:5.7346, R:0.0099, T:0.6325(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5982 (C:5.7409, R:0.0099, T:0.5972(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6617 (C:5.7363, R:0.0099, T:0.6607(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6383 (C:5.7126, R:0.0099, T:0.6373(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6497 (C:5.7572, R:0.0099, T:0.6487(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6284 (C:5.7617, R:0.0100, T:0.6274(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6389 (C:5.7322, R:0.0099, T:0.6379(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6796 (C:5.7465, R:0.0099, T:0.6786(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6567 (C:5.7734, R:0.0099, T:0.6558(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6561 (C:5.7951, R:0.0100, T:0.6551(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6717 (C:5.7545, R:0.0099, T:0.6708(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6498 (C:5.7189, R:0.0100, T:0.6488(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6437 (C:5.7893, R:0.0100, T:0.6427(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6538 (C:5.7879, R:0.0100, T:0.6528(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6463 (C:5.7323, R:0.0099, T:0.6453(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6389 (C:5.7628, R:0.0100, T:0.6379(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6575 (C:5.7272, R:0.0100, T:0.6566(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6241 (C:5.7477, R:0.0099, T:0.6231(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 40 TRAINING SUMMARY:
  Total Loss: 0.6461
  Contrastive: 5.7581
  Reconstruction: 0.0100
  Topological: 0.6451 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.7401
  Contrastive: 4.5671
  Reconstruction: 0.0100
  Topological: 5.7391 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 40/100 COMPLETE (90.1s)
Train Loss: 0.6461 (C:5.7581, R:0.0100, T:0.6451)
Val Loss:   5.7401 (C:4.5671, R:0.0100, T:5.7391)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 41 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6054 (C:5.8293, R:0.0100, T:0.6044(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6962 (C:5.7989, R:0.0099, T:0.6952(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6323 (C:5.7468, R:0.0100, T:0.6313(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6553 (C:5.6834, R:0.0099, T:0.6543(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6647 (C:5.7176, R:0.0099, T:0.6637(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6220 (C:5.7697, R:0.0100, T:0.6210(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6350 (C:5.7584, R:0.0100, T:0.6340(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6399 (C:5.7687, R:0.0099, T:0.6389(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6530 (C:5.7598, R:0.0099, T:0.6520(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6442 (C:5.6990, R:0.0100, T:0.6432(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6524 (C:5.7554, R:0.0099, T:0.6514(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6268 (C:5.7553, R:0.0100, T:0.6258(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6652 (C:5.8046, R:0.0100, T:0.6642(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6190 (C:5.7441, R:0.0100, T:0.6180(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6233 (C:5.7830, R:0.0100, T:0.6223(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6488 (C:5.7589, R:0.0099, T:0.6478(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6379 (C:5.7768, R:0.0100, T:0.6369(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6312 (C:5.7697, R:0.0099, T:0.6302(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6446 (C:5.7649, R:0.0099, T:0.6437(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6256 (C:5.7694, R:0.0100, T:0.6246(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6491 (C:5.7760, R:0.0100, T:0.6481(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6413 (C:5.7672, R:0.0100, T:0.6403(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6412

ğŸ“Š EPOCH 41 TRAINING SUMMARY:
  Total Loss: 0.6422
  Contrastive: 5.7559
  Reconstruction: 0.0100
  Topological: 0.6412 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.7543
  Contrastive: 4.5245
  Reconstruction: 0.0100
  Topological: 5.7533 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 41/100 COMPLETE (89.5s)
Train Loss: 0.6422 (C:5.7559, R:0.0100, T:0.6412)
Val Loss:   5.7543 (C:4.5245, R:0.0100, T:5.7533)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 42 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6470 (C:5.7475, R:0.0100, T:0.6460(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6593 (C:5.7495, R:0.0099, T:0.6583(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6355 (C:5.7652, R:0.0100, T:0.6345(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6292 (C:5.8315, R:0.0099, T:0.6282(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6511 (C:5.7280, R:0.0100, T:0.6501(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6593 (C:5.7687, R:0.0100, T:0.6583(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6174 (C:5.7675, R:0.0100, T:0.6164(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6600 (C:5.7240, R:0.0099, T:0.6590(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6862 (C:5.7754, R:0.0100, T:0.6852(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6540 (C:5.7451, R:0.0099, T:0.6530(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6327 (C:5.7686, R:0.0100, T:0.6317(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6337 (C:5.7479, R:0.0099, T:0.6327(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6469 (C:5.7654, R:0.0099, T:0.6459(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6163 (C:5.7832, R:0.0099, T:0.6153(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6555 (C:5.7531, R:0.0100, T:0.6545(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6314 (C:5.7606, R:0.0099, T:0.6304(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6212 (C:5.7769, R:0.0100, T:0.6202(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6562 (C:5.7306, R:0.0100, T:0.6552(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6343 (C:5.7127, R:0.0099, T:0.6334(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6331 (C:5.7796, R:0.0100, T:0.6321(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6419 (C:5.7474, R:0.0099, T:0.6409(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6448 (C:5.7332, R:0.0099, T:0.6438(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 42 TRAINING SUMMARY:
  Total Loss: 0.6436
  Contrastive: 5.7546
  Reconstruction: 0.0100
  Topological: 0.6426 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.8093
  Contrastive: 4.5196
  Reconstruction: 0.0100
  Topological: 5.8083 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 42/100 COMPLETE (89.1s)
Train Loss: 0.6436 (C:5.7546, R:0.0100, T:0.6426)
Val Loss:   5.8093 (C:4.5196, R:0.0100, T:5.8083)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 43 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6753 (C:5.7369, R:0.0100, T:0.6743(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6529 (C:5.7722, R:0.0099, T:0.6519(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6275 (C:5.7278, R:0.0100, T:0.6265(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6327 (C:5.8247, R:0.0100, T:0.6317(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6334 (C:5.7595, R:0.0099, T:0.6324(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6285 (C:5.7689, R:0.0100, T:0.6275(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6375 (C:5.7065, R:0.0099, T:0.6365(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6702 (C:5.7287, R:0.0100, T:0.6692(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6268 (C:5.7733, R:0.0100, T:0.6258(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6806 (C:5.7267, R:0.0100, T:0.6796(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6610 (C:5.7321, R:0.0100, T:0.6600(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6330 (C:5.7612, R:0.0100, T:0.6320(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6279 (C:5.8159, R:0.0100, T:0.6269(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6688 (C:5.7636, R:0.0099, T:0.6678(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6666 (C:5.7655, R:0.0100, T:0.6656(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6228 (C:5.7644, R:0.0100, T:0.6218(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6271 (C:5.7369, R:0.0099, T:0.6261(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6147 (C:5.8249, R:0.0099, T:0.6137(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6448 (C:5.7652, R:0.0100, T:0.6438(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6435 (C:5.7279, R:0.0099, T:0.6425(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6292 (C:5.7394, R:0.0100, T:0.6282(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6391 (C:5.7323, R:0.0100, T:0.6381(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 43 TRAINING SUMMARY:
  Total Loss: 0.6437
  Contrastive: 5.7558
  Reconstruction: 0.0100
  Topological: 0.6427 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.5767
  Contrastive: 4.5742
  Reconstruction: 0.0100
  Topological: 5.5757 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 43/100 COMPLETE (89.8s)
Train Loss: 0.6437 (C:5.7558, R:0.0100, T:0.6427)
Val Loss:   5.5767 (C:4.5742, R:0.0100, T:5.5757)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 44 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6037 (C:5.7523, R:0.0099, T:0.6027(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6155 (C:5.7746, R:0.0099, T:0.6145(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6401 (C:5.7118, R:0.0099, T:0.6391(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6199 (C:5.7606, R:0.0099, T:0.6189(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6433 (C:5.7754, R:0.0100, T:0.6423(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6172 (C:5.7307, R:0.0099, T:0.6162(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6909 (C:5.7786, R:0.0100, T:0.6899(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6325 (C:5.7634, R:0.0099, T:0.6316(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6543 (C:5.7498, R:0.0099, T:0.6533(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6578 (C:5.7541, R:0.0100, T:0.6568(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6369 (C:5.7701, R:0.0099, T:0.6360(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6590 (C:5.7395, R:0.0100, T:0.6580(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6531 (C:5.7433, R:0.0099, T:0.6522(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6536 (C:5.7910, R:0.0100, T:0.6526(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6611 (C:5.7566, R:0.0099, T:0.6601(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6170 (C:5.7993, R:0.0100, T:0.6160(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6287 (C:5.7410, R:0.0100, T:0.6277(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6596 (C:5.7743, R:0.0100, T:0.6587(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6546 (C:5.7329, R:0.0099, T:0.6536(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6213 (C:5.7713, R:0.0100, T:0.6203(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6501 (C:5.7849, R:0.0100, T:0.6491(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6320 (C:5.7339, R:0.0099, T:0.6310(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 44 TRAINING SUMMARY:
  Total Loss: 0.6425
  Contrastive: 5.7531
  Reconstruction: 0.0100
  Topological: 0.6415 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.5042
  Contrastive: 4.5748
  Reconstruction: 0.0100
  Topological: 5.5032 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 44/100 COMPLETE (90.0s)
Train Loss: 0.6425 (C:5.7531, R:0.0100, T:0.6415)
Val Loss:   5.5042 (C:4.5748, R:0.0100, T:5.5032)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 45 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6203 (C:5.7948, R:0.0099, T:0.6193(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6462 (C:5.7717, R:0.0100, T:0.6452(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6543 (C:5.7122, R:0.0099, T:0.6533(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6233 (C:5.7689, R:0.0099, T:0.6223(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6361 (C:5.7420, R:0.0099, T:0.6351(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6379 (C:5.7912, R:0.0100, T:0.6369(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6469 (C:5.7550, R:0.0100, T:0.6459(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6834 (C:5.7820, R:0.0099, T:0.6824(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6177 (C:5.7148, R:0.0099, T:0.6167(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6384 (C:5.7934, R:0.0099, T:0.6374(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6549 (C:5.7496, R:0.0099, T:0.6539(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6330 (C:5.7512, R:0.0100, T:0.6320(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6121 (C:5.7207, R:0.0099, T:0.6111(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5986 (C:5.7948, R:0.0099, T:0.5976(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6435 (C:5.7782, R:0.0100, T:0.6425(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6671 (C:5.7315, R:0.0100, T:0.6661(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6449 (C:5.7574, R:0.0100, T:0.6439(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6200 (C:5.7717, R:0.0099, T:0.6190(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6537 (C:5.7646, R:0.0100, T:0.6527(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6353 (C:5.7480, R:0.0100, T:0.6343(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6401 (C:5.7296, R:0.0100, T:0.6391(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6579 (C:5.7235, R:0.0099, T:0.6569(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6401

ğŸ“Š EPOCH 45 TRAINING SUMMARY:
  Total Loss: 0.6411
  Contrastive: 5.7537
  Reconstruction: 0.0100
  Topological: 0.6401 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.6195
  Contrastive: 4.5462
  Reconstruction: 0.0100
  Topological: 5.6185 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 45/100 COMPLETE (89.0s)
Train Loss: 0.6411 (C:5.7537, R:0.0100, T:0.6401)
Val Loss:   5.6195 (C:4.5462, R:0.0100, T:5.6185)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 46 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6280 (C:5.7313, R:0.0099, T:0.6270(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6658 (C:5.7425, R:0.0099, T:0.6648(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6587 (C:5.7821, R:0.0099, T:0.6577(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6367 (C:5.7286, R:0.0100, T:0.6357(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6356 (C:5.7275, R:0.0100, T:0.6346(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6313 (C:5.7256, R:0.0100, T:0.6303(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6412 (C:5.7385, R:0.0099, T:0.6402(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6388 (C:5.7175, R:0.0099, T:0.6378(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6185 (C:5.7955, R:0.0099, T:0.6175(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6415 (C:5.7648, R:0.0100, T:0.6405(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6512 (C:5.7728, R:0.0100, T:0.6502(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5964 (C:5.7677, R:0.0100, T:0.5954(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6430 (C:5.7511, R:0.0100, T:0.6421(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6669 (C:5.7703, R:0.0099, T:0.6659(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6266 (C:5.7255, R:0.0100, T:0.6256(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6383 (C:5.7743, R:0.0099, T:0.6374(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6385 (C:5.7610, R:0.0099, T:0.6375(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6576 (C:5.7563, R:0.0100, T:0.6566(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6324 (C:5.7187, R:0.0099, T:0.6314(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6604 (C:5.7532, R:0.0099, T:0.6594(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6218 (C:5.7101, R:0.0099, T:0.6208(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6358 (C:5.7121, R:0.0099, T:0.6348(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6399

ğŸ“Š EPOCH 46 TRAINING SUMMARY:
  Total Loss: 0.6409
  Contrastive: 5.7515
  Reconstruction: 0.0100
  Topological: 0.6399 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.4145
  Contrastive: 4.5783
  Reconstruction: 0.0100
  Topological: 5.4135 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 46/100 COMPLETE (89.6s)
Train Loss: 0.6409 (C:5.7515, R:0.0100, T:0.6399)
Val Loss:   5.4145 (C:4.5783, R:0.0100, T:5.4135)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 47 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6082 (C:5.7505, R:0.0100, T:0.6072(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6516 (C:5.7362, R:0.0100, T:0.6506(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6572 (C:5.7647, R:0.0099, T:0.6562(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6133 (C:5.7453, R:0.0100, T:0.6123(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6534 (C:5.7502, R:0.0100, T:0.6524(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6285 (C:5.7315, R:0.0099, T:0.6275(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6082 (C:5.7365, R:0.0100, T:0.6072(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6061 (C:5.7209, R:0.0099, T:0.6051(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6258 (C:5.7748, R:0.0099, T:0.6248(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6454 (C:5.8055, R:0.0100, T:0.6444(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6354 (C:5.7438, R:0.0100, T:0.6344(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6466 (C:5.7304, R:0.0100, T:0.6456(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6600 (C:5.7565, R:0.0100, T:0.6590(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6262 (C:5.7235, R:0.0099, T:0.6252(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6568 (C:5.7953, R:0.0100, T:0.6558(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6492 (C:5.7353, R:0.0100, T:0.6482(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6644 (C:5.7665, R:0.0100, T:0.6634(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6428 (C:5.7601, R:0.0099, T:0.6418(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6477 (C:5.7732, R:0.0100, T:0.6467(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6570 (C:5.7542, R:0.0100, T:0.6560(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6581 (C:5.7665, R:0.0100, T:0.6571(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5927 (C:5.7099, R:0.0099, T:0.5917(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 47 TRAINING SUMMARY:
  Total Loss: 0.6420
  Contrastive: 5.7529
  Reconstruction: 0.0100
  Topological: 0.6410 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.3505
  Contrastive: 4.5800
  Reconstruction: 0.0100
  Topological: 5.3496 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 47/100 COMPLETE (89.5s)
Train Loss: 0.6420 (C:5.7529, R:0.0100, T:0.6410)
Val Loss:   5.3505 (C:4.5800, R:0.0100, T:5.3496)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 48 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6651 (C:5.7430, R:0.0099, T:0.6641(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6408 (C:5.7537, R:0.0100, T:0.6398(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6449 (C:5.7485, R:0.0100, T:0.6439(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6444 (C:5.7370, R:0.0099, T:0.6434(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6147 (C:5.7719, R:0.0099, T:0.6138(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6824 (C:5.7475, R:0.0099, T:0.6814(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6320 (C:5.8092, R:0.0099, T:0.6311(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6514 (C:5.7877, R:0.0100, T:0.6504(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6061 (C:5.8002, R:0.0100, T:0.6051(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6705 (C:5.7651, R:0.0100, T:0.6695(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6397 (C:5.7255, R:0.0100, T:0.6387(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6139 (C:5.7774, R:0.0099, T:0.6129(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6533 (C:5.7787, R:0.0099, T:0.6523(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6705 (C:5.6761, R:0.0100, T:0.6695(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6477 (C:5.7306, R:0.0100, T:0.6467(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6119 (C:5.7840, R:0.0100, T:0.6109(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6482 (C:5.6787, R:0.0099, T:0.6472(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6250 (C:5.7615, R:0.0100, T:0.6241(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6582 (C:5.7625, R:0.0100, T:0.6572(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6118 (C:5.7151, R:0.0099, T:0.6108(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6298 (C:5.7838, R:0.0100, T:0.6289(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6094 (C:5.7612, R:0.0099, T:0.6084(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6369

ğŸ“Š EPOCH 48 TRAINING SUMMARY:
  Total Loss: 0.6379
  Contrastive: 5.7519
  Reconstruction: 0.0100
  Topological: 0.6369 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.4610
  Contrastive: 4.5595
  Reconstruction: 0.0100
  Topological: 5.4600 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 48/100 COMPLETE (91.4s)
Train Loss: 0.6379 (C:5.7519, R:0.0100, T:0.6369)
Val Loss:   5.4610 (C:4.5595, R:0.0100, T:5.4600)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 49 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6416 (C:5.7315, R:0.0100, T:0.6407(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6495 (C:5.7317, R:0.0100, T:0.6485(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6652 (C:5.7441, R:0.0099, T:0.6642(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6094 (C:5.7228, R:0.0100, T:0.6084(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6227 (C:5.7625, R:0.0100, T:0.6217(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6448 (C:5.7540, R:0.0099, T:0.6438(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6416 (C:5.7523, R:0.0099, T:0.6406(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6446 (C:5.7582, R:0.0100, T:0.6436(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6305 (C:5.8041, R:0.0099, T:0.6295(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6188 (C:5.7434, R:0.0099, T:0.6178(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6508 (C:5.7154, R:0.0099, T:0.6498(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6664 (C:5.7884, R:0.0099, T:0.6654(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6258 (C:5.7407, R:0.0099, T:0.6248(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6609 (C:5.7622, R:0.0100, T:0.6599(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6277 (C:5.7746, R:0.0100, T:0.6267(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6557 (C:5.7447, R:0.0100, T:0.6547(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6200 (C:5.7515, R:0.0099, T:0.6190(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6380 (C:5.7422, R:0.0100, T:0.6370(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6776 (C:5.7483, R:0.0100, T:0.6766(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6397 (C:5.7201, R:0.0100, T:0.6387(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6276 (C:5.8018, R:0.0100, T:0.6266(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6601 (C:5.7405, R:0.0100, T:0.6591(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6367

ğŸ“Š EPOCH 49 TRAINING SUMMARY:
  Total Loss: 0.6377
  Contrastive: 5.7509
  Reconstruction: 0.0100
  Topological: 0.6367 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.2416
  Contrastive: 4.6324
  Reconstruction: 0.0100
  Topological: 5.2406 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 49/100 COMPLETE (90.7s)
Train Loss: 0.6377 (C:5.7509, R:0.0100, T:0.6367)
Val Loss:   5.2416 (C:4.6324, R:0.0100, T:5.2406)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 50 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6344 (C:5.7962, R:0.0100, T:0.6334(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6253 (C:5.7835, R:0.0099, T:0.6243(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6321 (C:5.7256, R:0.0099, T:0.6311(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6686 (C:5.7926, R:0.0100, T:0.6676(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6495 (C:5.7820, R:0.0100, T:0.6485(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6483 (C:5.7451, R:0.0100, T:0.6473(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6304 (C:5.7555, R:0.0099, T:0.6294(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6151 (C:5.7402, R:0.0100, T:0.6141(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6279 (C:5.7853, R:0.0099, T:0.6269(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6460 (C:5.7959, R:0.0100, T:0.6450(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6281 (C:5.7467, R:0.0100, T:0.6271(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6251 (C:5.7747, R:0.0100, T:0.6241(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6543 (C:5.7755, R:0.0099, T:0.6533(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6278 (C:5.7853, R:0.0099, T:0.6268(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6333 (C:5.7668, R:0.0100, T:0.6323(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6163 (C:5.7038, R:0.0099, T:0.6153(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6585 (C:5.8060, R:0.0100, T:0.6575(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6601 (C:5.7750, R:0.0100, T:0.6591(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6333 (C:5.7085, R:0.0099, T:0.6323(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6408 (C:5.7335, R:0.0099, T:0.6398(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6791 (C:5.7781, R:0.0100, T:0.6781(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6421 (C:5.7565, R:0.0100, T:0.6411(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 50 TRAINING SUMMARY:
  Total Loss: 0.6382
  Contrastive: 5.7489
  Reconstruction: 0.0100
  Topological: 0.6372 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.3719
  Contrastive: 4.5830
  Reconstruction: 0.0100
  Topological: 5.3709 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 50/100 COMPLETE (92.8s)
Train Loss: 0.6382 (C:5.7489, R:0.0100, T:0.6372)
Val Loss:   5.3719 (C:4.5830, R:0.0100, T:5.3709)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 51 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6150 (C:5.7691, R:0.0100, T:0.6140(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6169 (C:5.7019, R:0.0099, T:0.6159(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6744 (C:5.7215, R:0.0099, T:0.6734(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6417 (C:5.7634, R:0.0099, T:0.6407(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6017 (C:5.7425, R:0.0099, T:0.6007(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6681 (C:5.7754, R:0.0100, T:0.6671(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6226 (C:5.6906, R:0.0100, T:0.6216(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6501 (C:5.7452, R:0.0099, T:0.6491(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6625 (C:5.7357, R:0.0099, T:0.6616(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6689 (C:5.7874, R:0.0100, T:0.6679(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6277 (C:5.7494, R:0.0099, T:0.6267(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6198 (C:5.7428, R:0.0100, T:0.6188(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6407 (C:5.7510, R:0.0100, T:0.6397(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6525 (C:5.7639, R:0.0100, T:0.6515(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6832 (C:5.7668, R:0.0099, T:0.6822(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6035 (C:5.7557, R:0.0100, T:0.6025(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6637 (C:5.7706, R:0.0100, T:0.6627(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6314 (C:5.7174, R:0.0099, T:0.6304(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6396 (C:5.7005, R:0.0099, T:0.6386(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6252 (C:5.7207, R:0.0099, T:0.6242(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6219 (C:5.7226, R:0.0099, T:0.6210(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6331 (C:5.7904, R:0.0099, T:0.6321(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6359

ğŸ“Š EPOCH 51 TRAINING SUMMARY:
  Total Loss: 0.6369
  Contrastive: 5.7484
  Reconstruction: 0.0100
  Topological: 0.6359 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.3104
  Contrastive: 4.5573
  Reconstruction: 0.0100
  Topological: 5.3094 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 51/100 COMPLETE (105.0s)
Train Loss: 0.6369 (C:5.7484, R:0.0100, T:0.6359)
Val Loss:   5.3104 (C:4.5573, R:0.0100, T:5.3094)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 52 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6318 (C:5.7129, R:0.0100, T:0.6308(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6582 (C:5.7582, R:0.0099, T:0.6572(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6478 (C:5.7800, R:0.0100, T:0.6468(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6316 (C:5.7377, R:0.0099, T:0.6306(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6541 (C:5.7450, R:0.0100, T:0.6531(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6165 (C:5.7760, R:0.0099, T:0.6156(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6183 (C:5.7555, R:0.0100, T:0.6173(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6277 (C:5.7327, R:0.0100, T:0.6267(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6385 (C:5.7467, R:0.0099, T:0.6375(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6476 (C:5.7475, R:0.0100, T:0.6466(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6432 (C:5.7465, R:0.0100, T:0.6422(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6674 (C:5.7697, R:0.0100, T:0.6664(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6439 (C:5.7428, R:0.0100, T:0.6429(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6442 (C:5.7752, R:0.0099, T:0.6432(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6070 (C:5.7114, R:0.0099, T:0.6060(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6061 (C:5.7266, R:0.0100, T:0.6051(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6216 (C:5.7397, R:0.0099, T:0.6206(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6223 (C:5.7492, R:0.0100, T:0.6213(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6399 (C:5.7622, R:0.0100, T:0.6389(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6429 (C:5.7301, R:0.0099, T:0.6419(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6415 (C:5.7826, R:0.0100, T:0.6405(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6424 (C:5.7341, R:0.0100, T:0.6414(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6353

ğŸ“Š EPOCH 52 TRAINING SUMMARY:
  Total Loss: 0.6362
  Contrastive: 5.7476
  Reconstruction: 0.0100
  Topological: 0.6353 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.3017
  Contrastive: 4.6049
  Reconstruction: 0.0100
  Topological: 5.3007 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 52/100 COMPLETE (108.9s)
Train Loss: 0.6362 (C:5.7476, R:0.0100, T:0.6353)
Val Loss:   5.3017 (C:4.6049, R:0.0100, T:5.3007)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 53 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6380 (C:5.7653, R:0.0100, T:0.6370(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6113 (C:5.7864, R:0.0100, T:0.6103(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6028 (C:5.7274, R:0.0099, T:0.6018(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6284 (C:5.7927, R:0.0100, T:0.6274(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6210 (C:5.7063, R:0.0100, T:0.6200(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6269 (C:5.7470, R:0.0100, T:0.6259(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6142 (C:5.7722, R:0.0099, T:0.6132(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6443 (C:5.7669, R:0.0100, T:0.6433(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6582 (C:5.7457, R:0.0099, T:0.6572(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6602 (C:5.7302, R:0.0100, T:0.6592(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6033 (C:5.7651, R:0.0100, T:0.6023(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6364 (C:5.7904, R:0.0099, T:0.6354(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6753 (C:5.7604, R:0.0100, T:0.6743(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6770 (C:5.7260, R:0.0099, T:0.6760(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6343 (C:5.7770, R:0.0099, T:0.6333(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6504 (C:5.7549, R:0.0100, T:0.6494(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6332 (C:5.6945, R:0.0100, T:0.6322(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6578 (C:5.7349, R:0.0099, T:0.6568(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6513 (C:5.7532, R:0.0099, T:0.6503(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6300 (C:5.7334, R:0.0099, T:0.6290(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6197 (C:5.7400, R:0.0099, T:0.6187(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6111 (C:5.7719, R:0.0099, T:0.6101(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 53 TRAINING SUMMARY:
  Total Loss: 0.6373
  Contrastive: 5.7469
  Reconstruction: 0.0100
  Topological: 0.6363 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.2727
  Contrastive: 4.5739
  Reconstruction: 0.0100
  Topological: 5.2717 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 53/100 COMPLETE (87.7s)
Train Loss: 0.6373 (C:5.7469, R:0.0100, T:0.6363)
Val Loss:   5.2727 (C:4.5739, R:0.0100, T:5.2717)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 54 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6300 (C:5.7076, R:0.0100, T:0.6290(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6332 (C:5.7635, R:0.0100, T:0.6322(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6609 (C:5.7173, R:0.0100, T:0.6599(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6423 (C:5.7341, R:0.0099, T:0.6413(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6396 (C:5.7570, R:0.0100, T:0.6386(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6272 (C:5.7344, R:0.0100, T:0.6262(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6469 (C:5.7331, R:0.0099, T:0.6459(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6239 (C:5.7566, R:0.0099, T:0.6229(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6111 (C:5.7371, R:0.0100, T:0.6102(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6064 (C:5.7666, R:0.0099, T:0.6054(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6341 (C:5.7709, R:0.0100, T:0.6331(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6142 (C:5.7463, R:0.0100, T:0.6132(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6603 (C:5.7255, R:0.0099, T:0.6593(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6265 (C:5.7066, R:0.0100, T:0.6255(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6072 (C:5.7626, R:0.0100, T:0.6063(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6473 (C:5.7904, R:0.0099, T:0.6463(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6488 (C:5.8078, R:0.0100, T:0.6478(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6337 (C:5.7144, R:0.0100, T:0.6327(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6430 (C:5.7798, R:0.0100, T:0.6420(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6380 (C:5.7240, R:0.0099, T:0.6370(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6495 (C:5.7599, R:0.0099, T:0.6485(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6263 (C:5.8002, R:0.0100, T:0.6253(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6316

ğŸ“Š EPOCH 54 TRAINING SUMMARY:
  Total Loss: 0.6326
  Contrastive: 5.7481
  Reconstruction: 0.0100
  Topological: 0.6316 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.3759
  Contrastive: 4.5649
  Reconstruction: 0.0100
  Topological: 5.3749 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 54/100 COMPLETE (87.3s)
Train Loss: 0.6326 (C:5.7481, R:0.0100, T:0.6316)
Val Loss:   5.3759 (C:4.5649, R:0.0100, T:5.3749)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 55 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6261 (C:5.7313, R:0.0100, T:0.6251(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6126 (C:5.7989, R:0.0100, T:0.6116(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6016 (C:5.7354, R:0.0099, T:0.6006(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6125 (C:5.7225, R:0.0099, T:0.6115(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6173 (C:5.7110, R:0.0099, T:0.6163(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6241 (C:5.7848, R:0.0100, T:0.6231(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6038 (C:5.7881, R:0.0099, T:0.6028(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6440 (C:5.8188, R:0.0100, T:0.6430(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6409 (C:5.7667, R:0.0099, T:0.6399(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6007 (C:5.7293, R:0.0100, T:0.5997(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6380 (C:5.7892, R:0.0100, T:0.6370(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6097 (C:5.7595, R:0.0100, T:0.6087(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6307 (C:5.7373, R:0.0100, T:0.6297(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6295 (C:5.7760, R:0.0099, T:0.6285(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6501 (C:5.7293, R:0.0100, T:0.6491(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6442 (C:5.7704, R:0.0100, T:0.6432(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6374 (C:5.7426, R:0.0099, T:0.6364(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6418 (C:5.7249, R:0.0099, T:0.6408(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6588 (C:5.7678, R:0.0100, T:0.6578(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6429 (C:5.7248, R:0.0100, T:0.6419(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6409 (C:5.7577, R:0.0100, T:0.6399(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6040 (C:5.7678, R:0.0100, T:0.6030(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 55 TRAINING SUMMARY:
  Total Loss: 0.6338
  Contrastive: 5.7472
  Reconstruction: 0.0100
  Topological: 0.6328 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.2407
  Contrastive: 4.5715
  Reconstruction: 0.0100
  Topological: 5.2397 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 55/100 COMPLETE (87.6s)
Train Loss: 0.6338 (C:5.7472, R:0.0100, T:0.6328)
Val Loss:   5.2407 (C:4.5715, R:0.0100, T:5.2397)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 56 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6325 (C:5.6691, R:0.0099, T:0.6315(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6448 (C:5.7571, R:0.0099, T:0.6439(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6458 (C:5.7089, R:0.0099, T:0.6448(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6328 (C:5.7774, R:0.0100, T:0.6319(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6500 (C:5.7143, R:0.0099, T:0.6490(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6090 (C:5.7741, R:0.0099, T:0.6081(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6022 (C:5.7658, R:0.0099, T:0.6012(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6159 (C:5.7343, R:0.0099, T:0.6149(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6342 (C:5.7097, R:0.0099, T:0.6332(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6146 (C:5.6897, R:0.0100, T:0.6136(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5927 (C:5.7728, R:0.0100, T:0.5917(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6324 (C:5.7550, R:0.0100, T:0.6314(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6127 (C:5.7752, R:0.0100, T:0.6117(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6265 (C:5.7181, R:0.0099, T:0.6256(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6564 (C:5.7272, R:0.0100, T:0.6554(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6473 (C:5.8242, R:0.0099, T:0.6463(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6402 (C:5.7429, R:0.0100, T:0.6392(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6186 (C:5.7612, R:0.0100, T:0.6176(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6593 (C:5.6960, R:0.0100, T:0.6583(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6376 (C:5.7367, R:0.0100, T:0.6366(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6001 (C:5.7857, R:0.0100, T:0.5991(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6136 (C:5.7580, R:0.0099, T:0.6126(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 56 TRAINING SUMMARY:
  Total Loss: 0.6331
  Contrastive: 5.7468
  Reconstruction: 0.0100
  Topological: 0.6321 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.2718
  Contrastive: 4.5604
  Reconstruction: 0.0100
  Topological: 5.2708 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 56/100 COMPLETE (86.6s)
Train Loss: 0.6331 (C:5.7468, R:0.0100, T:0.6321)
Val Loss:   5.2718 (C:4.5604, R:0.0100, T:5.2708)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 57 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6455 (C:5.7247, R:0.0100, T:0.6445(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6201 (C:5.7465, R:0.0099, T:0.6191(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5993 (C:5.7877, R:0.0099, T:0.5983(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6277 (C:5.7227, R:0.0099, T:0.6267(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6063 (C:5.7758, R:0.0100, T:0.6053(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6364 (C:5.7758, R:0.0100, T:0.6354(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6218 (C:5.7141, R:0.0099, T:0.6208(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6414 (C:5.7689, R:0.0099, T:0.6404(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6276 (C:5.7158, R:0.0100, T:0.6266(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6412 (C:5.8204, R:0.0099, T:0.6402(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6080 (C:5.7332, R:0.0100, T:0.6070(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6482 (C:5.7157, R:0.0099, T:0.6472(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6664 (C:5.8107, R:0.0100, T:0.6654(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6296 (C:5.7413, R:0.0099, T:0.6286(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6069 (C:5.7844, R:0.0100, T:0.6059(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6504 (C:5.7414, R:0.0100, T:0.6494(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6151 (C:5.7339, R:0.0100, T:0.6141(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6184 (C:5.7589, R:0.0099, T:0.6174(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6273 (C:5.7329, R:0.0100, T:0.6263(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6478 (C:5.7869, R:0.0100, T:0.6468(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6569 (C:5.7077, R:0.0099, T:0.6560(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6556 (C:5.7982, R:0.0100, T:0.6546(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6301

ğŸ“Š EPOCH 57 TRAINING SUMMARY:
  Total Loss: 0.6311
  Contrastive: 5.7494
  Reconstruction: 0.0100
  Topological: 0.6301 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.1542
  Contrastive: 4.5867
  Reconstruction: 0.0100
  Topological: 5.1532 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 57/100 COMPLETE (89.3s)
Train Loss: 0.6311 (C:5.7494, R:0.0100, T:0.6301)
Val Loss:   5.1542 (C:4.5867, R:0.0100, T:5.1532)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 58 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6491 (C:5.7177, R:0.0099, T:0.6481(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6321 (C:5.7997, R:0.0099, T:0.6311(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6267 (C:5.7226, R:0.0099, T:0.6257(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5781 (C:5.7524, R:0.0099, T:0.5771(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6269 (C:5.8000, R:0.0100, T:0.6259(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6213 (C:5.6619, R:0.0099, T:0.6204(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6263 (C:5.7543, R:0.0100, T:0.6253(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6509 (C:5.7413, R:0.0099, T:0.6499(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6447 (C:5.7213, R:0.0099, T:0.6437(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6824 (C:5.7339, R:0.0099, T:0.6814(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6341 (C:5.7347, R:0.0100, T:0.6331(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6332 (C:5.8069, R:0.0099, T:0.6322(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6570 (C:5.6841, R:0.0100, T:0.6560(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6370 (C:5.7765, R:0.0100, T:0.6360(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6532 (C:5.6864, R:0.0100, T:0.6522(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5844 (C:5.7210, R:0.0099, T:0.5834(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6337 (C:5.7602, R:0.0100, T:0.6327(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6027 (C:5.7625, R:0.0099, T:0.6017(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6255 (C:5.7268, R:0.0099, T:0.6245(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6405 (C:5.7984, R:0.0099, T:0.6395(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5996 (C:5.6984, R:0.0100, T:0.5986(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6309 (C:5.7430, R:0.0100, T:0.6299(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 58 TRAINING SUMMARY:
  Total Loss: 0.6325
  Contrastive: 5.7453
  Reconstruction: 0.0100
  Topological: 0.6315 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0955
  Contrastive: 4.5951
  Reconstruction: 0.0100
  Topological: 5.0945 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 58/100 COMPLETE (89.8s)
Train Loss: 0.6325 (C:5.7453, R:0.0100, T:0.6315)
Val Loss:   5.0955 (C:4.5951, R:0.0100, T:5.0945)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 59 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6266 (C:5.7530, R:0.0100, T:0.6256(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6287 (C:5.7916, R:0.0099, T:0.6277(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6415 (C:5.7269, R:0.0099, T:0.6405(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6301 (C:5.8087, R:0.0100, T:0.6291(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5947 (C:5.7239, R:0.0099, T:0.5937(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6564 (C:5.7029, R:0.0099, T:0.6554(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6042 (C:5.7296, R:0.0100, T:0.6032(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6563 (C:5.7365, R:0.0100, T:0.6553(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6178 (C:5.6964, R:0.0099, T:0.6168(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6319 (C:5.7404, R:0.0100, T:0.6309(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6372 (C:5.7733, R:0.0100, T:0.6362(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6446 (C:5.7262, R:0.0099, T:0.6437(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6211 (C:5.7730, R:0.0100, T:0.6201(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5946 (C:5.7593, R:0.0099, T:0.5936(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6005 (C:5.7397, R:0.0099, T:0.5995(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6610 (C:5.7578, R:0.0100, T:0.6600(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6298 (C:5.7308, R:0.0100, T:0.6288(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6238 (C:5.7369, R:0.0100, T:0.6228(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6034 (C:5.7360, R:0.0100, T:0.6024(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6457 (C:5.7930, R:0.0100, T:0.6447(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5947 (C:5.7144, R:0.0099, T:0.5937(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6127 (C:5.7572, R:0.0100, T:0.6117(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 59 TRAINING SUMMARY:
  Total Loss: 0.6318
  Contrastive: 5.7461
  Reconstruction: 0.0100
  Topological: 0.6308 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9973
  Contrastive: 4.6371
  Reconstruction: 0.0100
  Topological: 4.9963 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 59/100 COMPLETE (89.2s)
Train Loss: 0.6318 (C:5.7461, R:0.0100, T:0.6308)
Val Loss:   4.9973 (C:4.6371, R:0.0100, T:4.9963)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 60 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6089 (C:5.7782, R:0.0099, T:0.6079(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5992 (C:5.7950, R:0.0099, T:0.5982(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6350 (C:5.7444, R:0.0100, T:0.6340(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6565 (C:5.7575, R:0.0099, T:0.6555(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6436 (C:5.7229, R:0.0099, T:0.6426(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6508 (C:5.7967, R:0.0099, T:0.6498(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6233 (C:5.6804, R:0.0099, T:0.6223(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6518 (C:5.7696, R:0.0100, T:0.6508(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6336 (C:5.7524, R:0.0099, T:0.6326(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6329 (C:5.7701, R:0.0100, T:0.6319(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6404 (C:5.7822, R:0.0100, T:0.6394(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6262 (C:5.7314, R:0.0100, T:0.6252(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6370 (C:5.7495, R:0.0100, T:0.6360(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6044 (C:5.7301, R:0.0099, T:0.6034(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6840 (C:5.7945, R:0.0100, T:0.6830(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6342 (C:5.7619, R:0.0099, T:0.6332(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6421 (C:5.7109, R:0.0100, T:0.6411(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6618 (C:5.6704, R:0.0100, T:0.6608(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6053 (C:5.7650, R:0.0100, T:0.6043(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6420 (C:5.7643, R:0.0100, T:0.6410(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6255 (C:5.7915, R:0.0099, T:0.6245(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6408 (C:5.7250, R:0.0100, T:0.6398(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 60 TRAINING SUMMARY:
  Total Loss: 0.6322
  Contrastive: 5.7442
  Reconstruction: 0.0100
  Topological: 0.6312 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9599
  Contrastive: 4.6244
  Reconstruction: 0.0100
  Topological: 4.9589 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 60/100 COMPLETE (89.8s)
Train Loss: 0.6322 (C:5.7442, R:0.0100, T:0.6312)
Val Loss:   4.9599 (C:4.6244, R:0.0100, T:4.9589)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 61 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6315 (C:5.7736, R:0.0100, T:0.6305(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6583 (C:5.7594, R:0.0099, T:0.6573(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6271 (C:5.7228, R:0.0099, T:0.6261(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6386 (C:5.7385, R:0.0100, T:0.6376(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6170 (C:5.7465, R:0.0100, T:0.6160(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6376 (C:5.7180, R:0.0099, T:0.6366(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6307 (C:5.7000, R:0.0100, T:0.6297(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6079 (C:5.7588, R:0.0100, T:0.6069(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6296 (C:5.7333, R:0.0100, T:0.6286(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6328 (C:5.7628, R:0.0100, T:0.6318(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6183 (C:5.7624, R:0.0100, T:0.6173(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6154 (C:5.7378, R:0.0100, T:0.6144(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6319 (C:5.7432, R:0.0100, T:0.6309(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6661 (C:5.7471, R:0.0100, T:0.6651(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6342 (C:5.7200, R:0.0099, T:0.6332(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6096 (C:5.7246, R:0.0100, T:0.6086(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6201 (C:5.7848, R:0.0100, T:0.6191(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6511 (C:5.7202, R:0.0099, T:0.6501(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5998 (C:5.7250, R:0.0099, T:0.5988(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6509 (C:5.7713, R:0.0099, T:0.6499(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6143 (C:5.7602, R:0.0100, T:0.6133(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6338 (C:5.7334, R:0.0100, T:0.6328(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 61 TRAINING SUMMARY:
  Total Loss: 0.6318
  Contrastive: 5.7420
  Reconstruction: 0.0100
  Topological: 0.6308 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9487
  Contrastive: 4.6269
  Reconstruction: 0.0100
  Topological: 4.9477 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 61/100 COMPLETE (89.3s)
Train Loss: 0.6318 (C:5.7420, R:0.0100, T:0.6308)
Val Loss:   4.9487 (C:4.6269, R:0.0100, T:4.9477)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 62 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6377 (C:5.7857, R:0.0100, T:0.6367(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6217 (C:5.7544, R:0.0100, T:0.6207(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6328 (C:5.7217, R:0.0100, T:0.6318(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6151 (C:5.7412, R:0.0100, T:0.6141(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6640 (C:5.7010, R:0.0100, T:0.6630(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6554 (C:5.7285, R:0.0100, T:0.6544(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6319 (C:5.7584, R:0.0100, T:0.6309(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6472 (C:5.6943, R:0.0099, T:0.6463(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6005 (C:5.8141, R:0.0100, T:0.5995(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6590 (C:5.7185, R:0.0100, T:0.6580(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6165 (C:5.7517, R:0.0099, T:0.6155(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6490 (C:5.7058, R:0.0099, T:0.6480(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6451 (C:5.8226, R:0.0100, T:0.6441(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6344 (C:5.6505, R:0.0099, T:0.6334(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6094 (C:5.7491, R:0.0100, T:0.6084(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6047 (C:5.7287, R:0.0099, T:0.6037(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6265 (C:5.7996, R:0.0099, T:0.6256(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6403 (C:5.7243, R:0.0099, T:0.6394(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6285 (C:5.7606, R:0.0100, T:0.6275(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5824 (C:5.7562, R:0.0099, T:0.5814(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6036 (C:5.7539, R:0.0099, T:0.6026(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6468 (C:5.7042, R:0.0100, T:0.6458(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6269

ğŸ“Š EPOCH 62 TRAINING SUMMARY:
  Total Loss: 0.6279
  Contrastive: 5.7456
  Reconstruction: 0.0100
  Topological: 0.6269 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0079
  Contrastive: 4.6210
  Reconstruction: 0.0100
  Topological: 5.0069 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 62/100 COMPLETE (89.4s)
Train Loss: 0.6279 (C:5.7456, R:0.0100, T:0.6269)
Val Loss:   5.0079 (C:4.6210, R:0.0100, T:5.0069)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 63 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6301 (C:5.7542, R:0.0099, T:0.6291(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6107 (C:5.7431, R:0.0099, T:0.6097(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6372 (C:5.7242, R:0.0099, T:0.6362(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6167 (C:5.7816, R:0.0100, T:0.6157(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6262 (C:5.6724, R:0.0099, T:0.6252(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6464 (C:5.7670, R:0.0100, T:0.6454(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6084 (C:5.7748, R:0.0100, T:0.6074(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6540 (C:5.7285, R:0.0100, T:0.6530(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6116 (C:5.7761, R:0.0100, T:0.6106(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6353 (C:5.7215, R:0.0100, T:0.6343(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6289 (C:5.7217, R:0.0100, T:0.6279(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6235 (C:5.7551, R:0.0100, T:0.6225(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6166 (C:5.7215, R:0.0100, T:0.6156(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6221 (C:5.7409, R:0.0100, T:0.6211(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6251 (C:5.7372, R:0.0099, T:0.6242(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6497 (C:5.7004, R:0.0100, T:0.6487(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6307 (C:5.7756, R:0.0099, T:0.6297(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6317 (C:5.7547, R:0.0100, T:0.6307(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6298 (C:5.7690, R:0.0100, T:0.6288(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6759 (C:5.7777, R:0.0100, T:0.6749(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6414 (C:5.7176, R:0.0100, T:0.6404(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6208 (C:5.7739, R:0.0100, T:0.6198(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 63 TRAINING SUMMARY:
  Total Loss: 0.6298
  Contrastive: 5.7460
  Reconstruction: 0.0100
  Topological: 0.6288 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9228
  Contrastive: 4.6451
  Reconstruction: 0.0100
  Topological: 4.9218 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 63/100 COMPLETE (90.1s)
Train Loss: 0.6298 (C:5.7460, R:0.0100, T:0.6288)
Val Loss:   4.9228 (C:4.6451, R:0.0100, T:4.9218)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 64 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6189 (C:5.7511, R:0.0099, T:0.6179(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6259 (C:5.7904, R:0.0099, T:0.6249(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6166 (C:5.7563, R:0.0100, T:0.6156(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6211 (C:5.7316, R:0.0100, T:0.6201(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6156 (C:5.7028, R:0.0099, T:0.6147(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6274 (C:5.7724, R:0.0100, T:0.6264(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5970 (C:5.7354, R:0.0099, T:0.5960(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6274 (C:5.7585, R:0.0099, T:0.6264(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6682 (C:5.7444, R:0.0100, T:0.6672(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6621 (C:5.7713, R:0.0099, T:0.6611(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6486 (C:5.7996, R:0.0100, T:0.6476(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6369 (C:5.7081, R:0.0100, T:0.6359(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6149 (C:5.7656, R:0.0099, T:0.6139(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6521 (C:5.7590, R:0.0099, T:0.6511(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6257 (C:5.7301, R:0.0100, T:0.6247(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6218 (C:5.7573, R:0.0100, T:0.6208(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6263 (C:5.6958, R:0.0099, T:0.6254(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6212 (C:5.7480, R:0.0099, T:0.6202(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6237 (C:5.7615, R:0.0100, T:0.6227(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6309 (C:5.7381, R:0.0099, T:0.6299(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5943 (C:5.7369, R:0.0099, T:0.5933(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6388 (C:5.7547, R:0.0100, T:0.6378(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6260

ğŸ“Š EPOCH 64 TRAINING SUMMARY:
  Total Loss: 0.6270
  Contrastive: 5.7454
  Reconstruction: 0.0100
  Topological: 0.6260 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9489
  Contrastive: 4.6345
  Reconstruction: 0.0100
  Topological: 4.9479 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 64/100 COMPLETE (89.6s)
Train Loss: 0.6270 (C:5.7454, R:0.0100, T:0.6260)
Val Loss:   4.9489 (C:4.6345, R:0.0100, T:4.9479)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 65 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6491 (C:5.7686, R:0.0100, T:0.6481(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6012 (C:5.8186, R:0.0099, T:0.6002(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6637 (C:5.7321, R:0.0099, T:0.6627(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6245 (C:5.7070, R:0.0099, T:0.6235(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6076 (C:5.7336, R:0.0099, T:0.6066(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6372 (C:5.7404, R:0.0099, T:0.6362(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6339 (C:5.7658, R:0.0100, T:0.6329(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6430 (C:5.7482, R:0.0099, T:0.6420(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5941 (C:5.7459, R:0.0100, T:0.5931(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6514 (C:5.7078, R:0.0099, T:0.6504(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6367 (C:5.7849, R:0.0100, T:0.6357(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6259 (C:5.6784, R:0.0100, T:0.6249(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6367 (C:5.7355, R:0.0099, T:0.6357(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6297 (C:5.7106, R:0.0099, T:0.6287(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6203 (C:5.7421, R:0.0100, T:0.6193(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6095 (C:5.7482, R:0.0100, T:0.6085(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6430 (C:5.7070, R:0.0099, T:0.6420(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6241 (C:5.7252, R:0.0100, T:0.6231(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5977 (C:5.7404, R:0.0099, T:0.5967(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6210 (C:5.6913, R:0.0100, T:0.6200(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6183 (C:5.7338, R:0.0100, T:0.6173(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6412 (C:5.6893, R:0.0100, T:0.6402(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 65 TRAINING SUMMARY:
  Total Loss: 0.6289
  Contrastive: 5.7427
  Reconstruction: 0.0100
  Topological: 0.6279 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8733
  Contrastive: 4.6239
  Reconstruction: 0.0100
  Topological: 4.8723 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 65/100 COMPLETE (90.3s)
Train Loss: 0.6289 (C:5.7427, R:0.0100, T:0.6279)
Val Loss:   4.8733 (C:4.6239, R:0.0100, T:4.8723)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 66 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6320 (C:5.7443, R:0.0100, T:0.6310(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6200 (C:5.7426, R:0.0100, T:0.6190(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6231 (C:5.7742, R:0.0099, T:0.6221(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5957 (C:5.7393, R:0.0099, T:0.5947(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6539 (C:5.7501, R:0.0100, T:0.6529(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6295 (C:5.7739, R:0.0099, T:0.6285(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6142 (C:5.7753, R:0.0100, T:0.6132(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5923 (C:5.7693, R:0.0099, T:0.5913(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6482 (C:5.7551, R:0.0100, T:0.6472(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5981 (C:5.7249, R:0.0099, T:0.5971(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6352 (C:5.7609, R:0.0099, T:0.6342(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6055 (C:5.7444, R:0.0100, T:0.6045(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6336 (C:5.7168, R:0.0099, T:0.6326(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6275 (C:5.7446, R:0.0100, T:0.6265(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6254 (C:5.7318, R:0.0100, T:0.6244(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6526 (C:5.7524, R:0.0100, T:0.6516(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6307 (C:5.7818, R:0.0100, T:0.6297(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6038 (C:5.7285, R:0.0099, T:0.6028(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6180 (C:5.6970, R:0.0100, T:0.6170(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6335 (C:5.7751, R:0.0100, T:0.6325(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6043 (C:5.7656, R:0.0100, T:0.6033(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5866 (C:5.7508, R:0.0099, T:0.5856(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 66 TRAINING SUMMARY:
  Total Loss: 0.6290
  Contrastive: 5.7435
  Reconstruction: 0.0100
  Topological: 0.6280 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8670
  Contrastive: 4.6430
  Reconstruction: 0.0100
  Topological: 4.8660 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 66/100 COMPLETE (89.7s)
Train Loss: 0.6290 (C:5.7435, R:0.0100, T:0.6280)
Val Loss:   4.8670 (C:4.6430, R:0.0100, T:4.8660)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 67 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6270 (C:5.7529, R:0.0099, T:0.6261(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6488 (C:5.8168, R:0.0099, T:0.6478(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6486 (C:5.7387, R:0.0099, T:0.6476(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6570 (C:5.7371, R:0.0100, T:0.6560(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6288 (C:5.7774, R:0.0100, T:0.6278(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6371 (C:5.7278, R:0.0099, T:0.6361(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6155 (C:5.7410, R:0.0100, T:0.6145(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6063 (C:5.7137, R:0.0099, T:0.6053(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6246 (C:5.8210, R:0.0099, T:0.6236(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5996 (C:5.7279, R:0.0100, T:0.5986(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6114 (C:5.7608, R:0.0100, T:0.6104(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6570 (C:5.7459, R:0.0100, T:0.6560(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6170 (C:5.7250, R:0.0100, T:0.6160(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6183 (C:5.7468, R:0.0100, T:0.6173(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6232 (C:5.7854, R:0.0099, T:0.6222(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6201 (C:5.7976, R:0.0100, T:0.6191(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6541 (C:5.7147, R:0.0100, T:0.6531(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6246 (C:5.7980, R:0.0100, T:0.6236(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6161 (C:5.7250, R:0.0099, T:0.6151(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6378 (C:5.7563, R:0.0099, T:0.6368(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5988 (C:5.7436, R:0.0099, T:0.5978(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6285 (C:5.7507, R:0.0100, T:0.6275(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 67 TRAINING SUMMARY:
  Total Loss: 0.6277
  Contrastive: 5.7440
  Reconstruction: 0.0100
  Topological: 0.6267 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9424
  Contrastive: 4.6157
  Reconstruction: 0.0100
  Topological: 4.9414 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 67/100 COMPLETE (89.8s)
Train Loss: 0.6277 (C:5.7440, R:0.0100, T:0.6267)
Val Loss:   4.9424 (C:4.6157, R:0.0100, T:4.9414)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 68 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6534 (C:5.7296, R:0.0100, T:0.6525(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6042 (C:5.7673, R:0.0100, T:0.6032(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6404 (C:5.7134, R:0.0100, T:0.6394(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6566 (C:5.7598, R:0.0100, T:0.6556(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6420 (C:5.7670, R:0.0099, T:0.6411(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6315 (C:5.7325, R:0.0100, T:0.6305(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6293 (C:5.6985, R:0.0099, T:0.6283(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6387 (C:5.8434, R:0.0099, T:0.6377(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6330 (C:5.7320, R:0.0099, T:0.6320(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6330 (C:5.7487, R:0.0099, T:0.6320(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6229 (C:5.7682, R:0.0099, T:0.6219(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6084 (C:5.7249, R:0.0100, T:0.6074(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6276 (C:5.7658, R:0.0100, T:0.6266(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6099 (C:5.7623, R:0.0099, T:0.6089(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6078 (C:5.7627, R:0.0100, T:0.6068(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6193 (C:5.7440, R:0.0100, T:0.6183(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6372 (C:5.7693, R:0.0100, T:0.6362(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6434 (C:5.7771, R:0.0099, T:0.6424(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6572 (C:5.6538, R:0.0100, T:0.6562(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6128 (C:5.7397, R:0.0099, T:0.6118(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5885 (C:5.7305, R:0.0100, T:0.5875(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6650 (C:5.8014, R:0.0100, T:0.6640(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 68 TRAINING SUMMARY:
  Total Loss: 0.6300
  Contrastive: 5.7431
  Reconstruction: 0.0100
  Topological: 0.6290 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8942
  Contrastive: 4.6276
  Reconstruction: 0.0100
  Topological: 4.8932 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 68/100 COMPLETE (90.3s)
Train Loss: 0.6300 (C:5.7431, R:0.0100, T:0.6290)
Val Loss:   4.8942 (C:4.6276, R:0.0100, T:4.8932)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 69 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6370 (C:5.7409, R:0.0100, T:0.6360(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6444 (C:5.7734, R:0.0099, T:0.6435(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6350 (C:5.7225, R:0.0099, T:0.6341(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6254 (C:5.7421, R:0.0100, T:0.6244(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6688 (C:5.7230, R:0.0100, T:0.6678(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6012 (C:5.7498, R:0.0099, T:0.6002(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6188 (C:5.7838, R:0.0100, T:0.6179(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6338 (C:5.6932, R:0.0099, T:0.6328(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6269 (C:5.7606, R:0.0100, T:0.6259(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6309 (C:5.7394, R:0.0100, T:0.6299(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6446 (C:5.7337, R:0.0099, T:0.6436(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6179 (C:5.7659, R:0.0099, T:0.6169(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6447 (C:5.7007, R:0.0100, T:0.6438(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6241 (C:5.7101, R:0.0099, T:0.6231(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6326 (C:5.7968, R:0.0100, T:0.6316(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6443 (C:5.7247, R:0.0100, T:0.6433(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6189 (C:5.7456, R:0.0099, T:0.6179(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6407 (C:5.7519, R:0.0100, T:0.6397(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6091 (C:5.7586, R:0.0100, T:0.6081(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6420 (C:5.7575, R:0.0100, T:0.6410(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6200 (C:5.7537, R:0.0100, T:0.6190(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6283 (C:5.7345, R:0.0100, T:0.6273(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 69 TRAINING SUMMARY:
  Total Loss: 0.6279
  Contrastive: 5.7413
  Reconstruction: 0.0100
  Topological: 0.6269 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8012
  Contrastive: 4.6444
  Reconstruction: 0.0100
  Topological: 4.8002 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 69/100 COMPLETE (89.8s)
Train Loss: 0.6279 (C:5.7413, R:0.0100, T:0.6269)
Val Loss:   4.8012 (C:4.6444, R:0.0100, T:4.8002)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 70 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6370 (C:5.7693, R:0.0100, T:0.6360(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6377 (C:5.6816, R:0.0099, T:0.6367(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6139 (C:5.7865, R:0.0100, T:0.6129(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6098 (C:5.7084, R:0.0099, T:0.6088(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6062 (C:5.7222, R:0.0099, T:0.6052(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6739 (C:5.7603, R:0.0099, T:0.6729(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6280 (C:5.7643, R:0.0100, T:0.6270(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6480 (C:5.7997, R:0.0100, T:0.6470(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6064 (C:5.7488, R:0.0100, T:0.6054(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6457 (C:5.7408, R:0.0099, T:0.6447(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6247 (C:5.6938, R:0.0099, T:0.6237(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6242 (C:5.7309, R:0.0099, T:0.6232(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6391 (C:5.7860, R:0.0099, T:0.6381(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6420 (C:5.7207, R:0.0099, T:0.6410(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6153 (C:5.7334, R:0.0099, T:0.6143(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6486 (C:5.7576, R:0.0100, T:0.6476(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6114 (C:5.7379, R:0.0099, T:0.6104(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6286 (C:5.7188, R:0.0099, T:0.6276(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6270 (C:5.7827, R:0.0100, T:0.6260(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6436 (C:5.7583, R:0.0100, T:0.6426(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6292 (C:5.7587, R:0.0100, T:0.6283(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6512 (C:5.7263, R:0.0100, T:0.6502(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 70 TRAINING SUMMARY:
  Total Loss: 0.6289
  Contrastive: 5.7428
  Reconstruction: 0.0100
  Topological: 0.6279 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8580
  Contrastive: 4.6264
  Reconstruction: 0.0100
  Topological: 4.8570 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 70/100 COMPLETE (89.4s)
Train Loss: 0.6289 (C:5.7428, R:0.0100, T:0.6279)
Val Loss:   4.8580 (C:4.6264, R:0.0100, T:4.8570)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 71 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6389 (C:5.7405, R:0.0100, T:0.6379(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6316 (C:5.7346, R:0.0100, T:0.6306(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6045 (C:5.7297, R:0.0099, T:0.6036(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5964 (C:5.7349, R:0.0099, T:0.5954(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6442 (C:5.6785, R:0.0099, T:0.6432(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6404 (C:5.7285, R:0.0099, T:0.6394(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6085 (C:5.7848, R:0.0100, T:0.6075(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6196 (C:5.7440, R:0.0100, T:0.6186(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5984 (C:5.7679, R:0.0099, T:0.5974(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6180 (C:5.7671, R:0.0100, T:0.6170(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6224 (C:5.7484, R:0.0099, T:0.6214(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6396 (C:5.7105, R:0.0100, T:0.6386(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6161 (C:5.7432, R:0.0100, T:0.6151(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6130 (C:5.7311, R:0.0099, T:0.6120(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6341 (C:5.7525, R:0.0100, T:0.6331(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6322 (C:5.7658, R:0.0099, T:0.6312(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6388 (C:5.7355, R:0.0099, T:0.6378(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6343 (C:5.7369, R:0.0099, T:0.6333(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5954 (C:5.7411, R:0.0099, T:0.5944(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6333 (C:5.7558, R:0.0100, T:0.6323(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6375 (C:5.7547, R:0.0100, T:0.6365(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6134 (C:5.7375, R:0.0099, T:0.6124(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 71 TRAINING SUMMARY:
  Total Loss: 0.6271
  Contrastive: 5.7437
  Reconstruction: 0.0100
  Topological: 0.6261 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.6820
  Contrastive: 4.6540
  Reconstruction: 0.0100
  Topological: 4.6810 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 71/100 COMPLETE (89.2s)
Train Loss: 0.6271 (C:5.7437, R:0.0100, T:0.6261)
Val Loss:   4.6820 (C:4.6540, R:0.0100, T:4.6810)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 72 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6282 (C:5.7526, R:0.0099, T:0.6272(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6415 (C:5.7882, R:0.0099, T:0.6405(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5954 (C:5.7345, R:0.0099, T:0.5944(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6602 (C:5.7554, R:0.0100, T:0.6592(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6297 (C:5.7378, R:0.0100, T:0.6287(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6216 (C:5.7354, R:0.0099, T:0.6206(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5973 (C:5.7187, R:0.0099, T:0.5963(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6129 (C:5.7272, R:0.0099, T:0.6119(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6181 (C:5.7304, R:0.0099, T:0.6171(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6065 (C:5.7827, R:0.0099, T:0.6055(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5956 (C:5.7547, R:0.0099, T:0.5946(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6274 (C:5.7202, R:0.0100, T:0.6264(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6398 (C:5.7528, R:0.0099, T:0.6388(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6154 (C:5.7302, R:0.0099, T:0.6144(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6294 (C:5.7265, R:0.0099, T:0.6284(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5924 (C:5.7441, R:0.0100, T:0.5914(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6284 (C:5.7822, R:0.0099, T:0.6274(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6413 (C:5.7290, R:0.0100, T:0.6403(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6356 (C:5.7317, R:0.0100, T:0.6346(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6181 (C:5.7217, R:0.0099, T:0.6171(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6256 (C:5.7462, R:0.0099, T:0.6247(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6147 (C:5.7370, R:0.0100, T:0.6137(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6251

ğŸ“Š EPOCH 72 TRAINING SUMMARY:
  Total Loss: 0.6261
  Contrastive: 5.7427
  Reconstruction: 0.0100
  Topological: 0.6251 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.7505
  Contrastive: 4.6527
  Reconstruction: 0.0100
  Topological: 4.7495 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 72/100 COMPLETE (89.2s)
Train Loss: 0.6261 (C:5.7427, R:0.0100, T:0.6251)
Val Loss:   4.7505 (C:4.6527, R:0.0100, T:4.7495)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 73 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6400 (C:5.7768, R:0.0100, T:0.6390(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6401 (C:5.7435, R:0.0099, T:0.6391(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6330 (C:5.7088, R:0.0099, T:0.6320(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6243 (C:5.7709, R:0.0100, T:0.6233(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6382 (C:5.7281, R:0.0099, T:0.6372(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6208 (C:5.7438, R:0.0100, T:0.6198(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6101 (C:5.7566, R:0.0100, T:0.6091(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6526 (C:5.7533, R:0.0100, T:0.6516(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6167 (C:5.7918, R:0.0100, T:0.6157(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6378 (C:5.6939, R:0.0099, T:0.6368(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6334 (C:5.8070, R:0.0100, T:0.6324(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6436 (C:5.7413, R:0.0100, T:0.6426(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6544 (C:5.7439, R:0.0099, T:0.6534(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6565 (C:5.7614, R:0.0100, T:0.6555(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5993 (C:5.7347, R:0.0100, T:0.5983(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6149 (C:5.7741, R:0.0100, T:0.6139(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6340 (C:5.7236, R:0.0100, T:0.6330(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6133 (C:5.7626, R:0.0099, T:0.6123(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6090 (C:5.7643, R:0.0100, T:0.6080(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6438 (C:5.7600, R:0.0100, T:0.6429(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6219 (C:5.7180, R:0.0099, T:0.6209(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6378 (C:5.7918, R:0.0100, T:0.6368(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 73 TRAINING SUMMARY:
  Total Loss: 0.6285
  Contrastive: 5.7415
  Reconstruction: 0.0100
  Topological: 0.6276 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9145
  Contrastive: 4.6084
  Reconstruction: 0.0100
  Topological: 4.9135 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 73/100 COMPLETE (90.3s)
Train Loss: 0.6285 (C:5.7415, R:0.0100, T:0.6276)
Val Loss:   4.9145 (C:4.6084, R:0.0100, T:4.9135)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 74 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6105 (C:5.7199, R:0.0100, T:0.6095(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6319 (C:5.7551, R:0.0100, T:0.6309(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6183 (C:5.7214, R:0.0099, T:0.6173(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6482 (C:5.7735, R:0.0099, T:0.6472(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6569 (C:5.7171, R:0.0099, T:0.6559(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6664 (C:5.7663, R:0.0100, T:0.6654(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6308 (C:5.7267, R:0.0100, T:0.6298(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6111 (C:5.7928, R:0.0100, T:0.6101(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6218 (C:5.7383, R:0.0099, T:0.6209(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6392 (C:5.6820, R:0.0100, T:0.6382(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6124 (C:5.6910, R:0.0099, T:0.6114(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6092 (C:5.7230, R:0.0100, T:0.6082(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6409 (C:5.7685, R:0.0099, T:0.6399(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6020 (C:5.6913, R:0.0099, T:0.6010(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6178 (C:5.7528, R:0.0099, T:0.6168(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6453 (C:5.7674, R:0.0100, T:0.6443(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6129 (C:5.7809, R:0.0099, T:0.6119(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6124 (C:5.7738, R:0.0100, T:0.6114(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6246 (C:5.8070, R:0.0100, T:0.6236(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6266 (C:5.7698, R:0.0100, T:0.6256(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6681 (C:5.6867, R:0.0100, T:0.6671(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6427 (C:5.7633, R:0.0099, T:0.6417(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 74 TRAINING SUMMARY:
  Total Loss: 0.6283
  Contrastive: 5.7412
  Reconstruction: 0.0100
  Topological: 0.6273 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8539
  Contrastive: 4.6142
  Reconstruction: 0.0100
  Topological: 4.8529 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 74/100 COMPLETE (89.2s)
Train Loss: 0.6283 (C:5.7412, R:0.0100, T:0.6273)
Val Loss:   4.8539 (C:4.6142, R:0.0100, T:4.8529)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 75 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6426 (C:5.7178, R:0.0099, T:0.6416(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6086 (C:5.7499, R:0.0100, T:0.6076(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6194 (C:5.7119, R:0.0099, T:0.6185(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6179 (C:5.7319, R:0.0100, T:0.6169(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6390 (C:5.7520, R:0.0099, T:0.6380(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6357 (C:5.7683, R:0.0099, T:0.6347(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5948 (C:5.7272, R:0.0099, T:0.5938(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6338 (C:5.7723, R:0.0099, T:0.6328(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6507 (C:5.7702, R:0.0100, T:0.6497(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5927 (C:5.7314, R:0.0099, T:0.5917(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6681 (C:5.7574, R:0.0100, T:0.6671(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6255 (C:5.7327, R:0.0099, T:0.6245(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6353 (C:5.7301, R:0.0099, T:0.6343(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6776 (C:5.7922, R:0.0100, T:0.6766(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6433 (C:5.7698, R:0.0099, T:0.6423(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6744 (C:5.7655, R:0.0100, T:0.6734(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6506 (C:5.6895, R:0.0099, T:0.6496(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6091 (C:5.7577, R:0.0100, T:0.6081(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6127 (C:5.7276, R:0.0100, T:0.6117(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6217 (C:5.7335, R:0.0099, T:0.6207(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6400 (C:5.8204, R:0.0100, T:0.6390(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6311 (C:5.7034, R:0.0099, T:0.6301(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 75 TRAINING SUMMARY:
  Total Loss: 0.6278
  Contrastive: 5.7407
  Reconstruction: 0.0100
  Topological: 0.6268 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8870
  Contrastive: 4.6127
  Reconstruction: 0.0100
  Topological: 4.8860 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 75/100 COMPLETE (89.6s)
Train Loss: 0.6278 (C:5.7407, R:0.0100, T:0.6268)
Val Loss:   4.8870 (C:4.6127, R:0.0100, T:4.8860)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 76 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5913 (C:5.7207, R:0.0100, T:0.5903(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6285 (C:5.7052, R:0.0099, T:0.6275(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6109 (C:5.7635, R:0.0099, T:0.6099(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6129 (C:5.7157, R:0.0099, T:0.6119(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6471 (C:5.7304, R:0.0099, T:0.6461(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6240 (C:5.6968, R:0.0100, T:0.6231(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6155 (C:5.7760, R:0.0100, T:0.6145(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6436 (C:5.7491, R:0.0100, T:0.6426(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5978 (C:5.7538, R:0.0099, T:0.5968(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6771 (C:5.7652, R:0.0099, T:0.6761(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6099 (C:5.7387, R:0.0099, T:0.6089(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6020 (C:5.7390, R:0.0099, T:0.6010(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6161 (C:5.7306, R:0.0100, T:0.6151(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6026 (C:5.7054, R:0.0099, T:0.6016(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6303 (C:5.7513, R:0.0100, T:0.6293(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6173 (C:5.7312, R:0.0099, T:0.6163(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6035 (C:5.7256, R:0.0100, T:0.6025(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6447 (C:5.7324, R:0.0100, T:0.6437(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6104 (C:5.7598, R:0.0100, T:0.6094(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6239 (C:5.7708, R:0.0099, T:0.6229(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6204 (C:5.7349, R:0.0100, T:0.6194(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6081 (C:5.7678, R:0.0100, T:0.6071(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 76 TRAINING SUMMARY:
  Total Loss: 0.6275
  Contrastive: 5.7408
  Reconstruction: 0.0100
  Topological: 0.6265 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.7369
  Contrastive: 4.6593
  Reconstruction: 0.0100
  Topological: 4.7359 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 76/100 COMPLETE (89.3s)
Train Loss: 0.6275 (C:5.7408, R:0.0100, T:0.6265)
Val Loss:   4.7369 (C:4.6593, R:0.0100, T:4.7359)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 77 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6137 (C:5.7565, R:0.0100, T:0.6127(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6496 (C:5.7525, R:0.0099, T:0.6486(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6128 (C:5.7241, R:0.0099, T:0.6118(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6466 (C:5.7348, R:0.0100, T:0.6456(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6208 (C:5.7378, R:0.0099, T:0.6198(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6295 (C:5.7221, R:0.0099, T:0.6286(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6161 (C:5.7661, R:0.0100, T:0.6151(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6104 (C:5.7552, R:0.0099, T:0.6094(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6304 (C:5.7566, R:0.0100, T:0.6294(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6422 (C:5.7313, R:0.0099, T:0.6412(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6389 (C:5.7544, R:0.0100, T:0.6379(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6197 (C:5.7668, R:0.0100, T:0.6187(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6233 (C:5.7073, R:0.0099, T:0.6223(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6172 (C:5.7557, R:0.0100, T:0.6162(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6483 (C:5.7255, R:0.0100, T:0.6473(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6153 (C:5.7344, R:0.0099, T:0.6143(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6304 (C:5.7457, R:0.0100, T:0.6294(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6195 (C:5.7679, R:0.0099, T:0.6185(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6172 (C:5.6924, R:0.0099, T:0.6162(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6325 (C:5.7669, R:0.0099, T:0.6315(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6136 (C:5.7342, R:0.0099, T:0.6126(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6242 (C:5.7758, R:0.0100, T:0.6232(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6241

ğŸ“Š EPOCH 77 TRAINING SUMMARY:
  Total Loss: 0.6251
  Contrastive: 5.7419
  Reconstruction: 0.0100
  Topological: 0.6241 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.7174
  Contrastive: 4.6513
  Reconstruction: 0.0100
  Topological: 4.7164 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 77/100 COMPLETE (90.6s)
Train Loss: 0.6251 (C:5.7419, R:0.0100, T:0.6241)
Val Loss:   4.7174 (C:4.6513, R:0.0100, T:4.7164)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 78 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6205 (C:5.7288, R:0.0099, T:0.6195(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6333 (C:5.7184, R:0.0099, T:0.6323(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6379 (C:5.7554, R:0.0100, T:0.6369(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6240 (C:5.7123, R:0.0100, T:0.6230(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6616 (C:5.7553, R:0.0099, T:0.6606(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6455 (C:5.7434, R:0.0099, T:0.6445(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6199 (C:5.7154, R:0.0100, T:0.6189(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6537 (C:5.7467, R:0.0099, T:0.6527(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6509 (C:5.7224, R:0.0100, T:0.6499(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6207 (C:5.7317, R:0.0100, T:0.6197(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5740 (C:5.7226, R:0.0099, T:0.5730(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6648 (C:5.7542, R:0.0100, T:0.6638(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6079 (C:5.7241, R:0.0099, T:0.6069(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6314 (C:5.7659, R:0.0100, T:0.6304(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6508 (C:5.7409, R:0.0100, T:0.6498(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5939 (C:5.7355, R:0.0100, T:0.5929(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6638 (C:5.7504, R:0.0100, T:0.6628(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6269 (C:5.8311, R:0.0100, T:0.6259(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6160 (C:5.7204, R:0.0099, T:0.6150(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6623 (C:5.7561, R:0.0100, T:0.6613(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6161 (C:5.7422, R:0.0099, T:0.6151(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6411 (C:5.7194, R:0.0100, T:0.6401(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 78 TRAINING SUMMARY:
  Total Loss: 0.6260
  Contrastive: 5.7408
  Reconstruction: 0.0100
  Topological: 0.6250 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8126
  Contrastive: 4.6338
  Reconstruction: 0.0100
  Topological: 4.8116 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 78/100 COMPLETE (90.3s)
Train Loss: 0.6260 (C:5.7408, R:0.0100, T:0.6250)
Val Loss:   4.8126 (C:4.6338, R:0.0100, T:4.8116)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 79 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6489 (C:5.7465, R:0.0100, T:0.6479(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6512 (C:5.7202, R:0.0100, T:0.6502(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6229 (C:5.7733, R:0.0099, T:0.6219(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6371 (C:5.6850, R:0.0100, T:0.6361(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6067 (C:5.7742, R:0.0100, T:0.6057(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6214 (C:5.7051, R:0.0100, T:0.6204(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6056 (C:5.7077, R:0.0099, T:0.6046(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6379 (C:5.7607, R:0.0099, T:0.6369(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5950 (C:5.7443, R:0.0099, T:0.5940(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5790 (C:5.7170, R:0.0100, T:0.5780(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6306 (C:5.7426, R:0.0100, T:0.6296(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6245 (C:5.7645, R:0.0099, T:0.6235(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6460 (C:5.7973, R:0.0100, T:0.6451(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6411 (C:5.7113, R:0.0100, T:0.6401(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6381 (C:5.7591, R:0.0100, T:0.6371(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6282 (C:5.6937, R:0.0099, T:0.6272(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6216 (C:5.7280, R:0.0100, T:0.6206(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6673 (C:5.7820, R:0.0099, T:0.6663(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6202 (C:5.7226, R:0.0100, T:0.6192(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6154 (C:5.7163, R:0.0099, T:0.6144(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6154 (C:5.7358, R:0.0100, T:0.6144(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6407 (C:5.7970, R:0.0100, T:0.6397(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 79 TRAINING SUMMARY:
  Total Loss: 0.6256
  Contrastive: 5.7393
  Reconstruction: 0.0100
  Topological: 0.6246 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.6906
  Contrastive: 4.6426
  Reconstruction: 0.0100
  Topological: 4.6896 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 79/100 COMPLETE (89.5s)
Train Loss: 0.6256 (C:5.7393, R:0.0100, T:0.6246)
Val Loss:   4.6906 (C:4.6426, R:0.0100, T:4.6896)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 80 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6165 (C:5.7245, R:0.0100, T:0.6155(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6273 (C:5.6810, R:0.0100, T:0.6263(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6251 (C:5.7649, R:0.0100, T:0.6241(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5850 (C:5.7085, R:0.0099, T:0.5840(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6194 (C:5.8007, R:0.0100, T:0.6184(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6293 (C:5.7206, R:0.0099, T:0.6283(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6196 (C:5.7450, R:0.0100, T:0.6186(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6075 (C:5.7483, R:0.0100, T:0.6066(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6293 (C:5.7711, R:0.0100, T:0.6283(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6108 (C:5.7016, R:0.0100, T:0.6098(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6596 (C:5.7893, R:0.0100, T:0.6586(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6379 (C:5.7460, R:0.0100, T:0.6369(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6276 (C:5.7850, R:0.0100, T:0.6266(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6401 (C:5.7223, R:0.0099, T:0.6391(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6468 (C:5.7381, R:0.0100, T:0.6458(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5941 (C:5.7869, R:0.0100, T:0.5931(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6625 (C:5.7528, R:0.0100, T:0.6616(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6213 (C:5.7263, R:0.0100, T:0.6203(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6407 (C:5.8037, R:0.0100, T:0.6397(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6089 (C:5.6827, R:0.0099, T:0.6079(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6426 (C:5.7579, R:0.0099, T:0.6416(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6250 (C:5.7693, R:0.0099, T:0.6240(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6232

ğŸ“Š EPOCH 80 TRAINING SUMMARY:
  Total Loss: 0.6242
  Contrastive: 5.7415
  Reconstruction: 0.0100
  Topological: 0.6232 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8363
  Contrastive: 4.5911
  Reconstruction: 0.0100
  Topological: 4.8353 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 80/100 COMPLETE (90.0s)
Train Loss: 0.6242 (C:5.7415, R:0.0100, T:0.6232)
Val Loss:   4.8363 (C:4.5911, R:0.0100, T:4.8353)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 81 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6310 (C:5.6796, R:0.0100, T:0.6300(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5926 (C:5.7376, R:0.0099, T:0.5916(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5940 (C:5.7155, R:0.0099, T:0.5931(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6249 (C:5.7188, R:0.0099, T:0.6239(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6462 (C:5.7605, R:0.0099, T:0.6453(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6160 (C:5.7458, R:0.0100, T:0.6150(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6092 (C:5.7591, R:0.0099, T:0.6082(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5861 (C:5.7238, R:0.0100, T:0.5851(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6359 (C:5.7317, R:0.0099, T:0.6349(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6190 (C:5.7075, R:0.0100, T:0.6180(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6318 (C:5.7333, R:0.0099, T:0.6308(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6651 (C:5.7634, R:0.0100, T:0.6641(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6122 (C:5.7787, R:0.0100, T:0.6112(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6078 (C:5.6947, R:0.0100, T:0.6068(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6178 (C:5.7479, R:0.0100, T:0.6168(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6623 (C:5.7317, R:0.0100, T:0.6613(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6246 (C:5.7335, R:0.0099, T:0.6236(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6169 (C:5.7597, R:0.0099, T:0.6159(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6152 (C:5.7143, R:0.0099, T:0.6142(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6248 (C:5.7244, R:0.0100, T:0.6238(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5767 (C:5.7381, R:0.0099, T:0.5757(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6131 (C:5.7247, R:0.0099, T:0.6121(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6221

ğŸ“Š EPOCH 81 TRAINING SUMMARY:
  Total Loss: 0.6231
  Contrastive: 5.7423
  Reconstruction: 0.0100
  Topological: 0.6221 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.6908
  Contrastive: 4.6456
  Reconstruction: 0.0100
  Topological: 4.6898 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 81/100 COMPLETE (89.9s)
Train Loss: 0.6231 (C:5.7423, R:0.0100, T:0.6221)
Val Loss:   4.6908 (C:4.6456, R:0.0100, T:4.6898)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 82 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6445 (C:5.7297, R:0.0100, T:0.6435(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6273 (C:5.7653, R:0.0099, T:0.6263(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5852 (C:5.7466, R:0.0099, T:0.5843(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6313 (C:5.7620, R:0.0100, T:0.6303(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6244 (C:5.7073, R:0.0099, T:0.6234(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6190 (C:5.7709, R:0.0100, T:0.6180(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6116 (C:5.7638, R:0.0099, T:0.6106(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6496 (C:5.7545, R:0.0099, T:0.6486(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6252 (C:5.7599, R:0.0100, T:0.6242(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6227 (C:5.7462, R:0.0099, T:0.6217(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6269 (C:5.7378, R:0.0099, T:0.6259(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5949 (C:5.7575, R:0.0100, T:0.5939(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6095 (C:5.7526, R:0.0099, T:0.6085(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6159 (C:5.7894, R:0.0100, T:0.6149(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6335 (C:5.7201, R:0.0099, T:0.6325(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6068 (C:5.7048, R:0.0100, T:0.6058(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6366 (C:5.7476, R:0.0099, T:0.6356(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6421 (C:5.7384, R:0.0099, T:0.6411(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5921 (C:5.7447, R:0.0099, T:0.5911(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6078 (C:5.7345, R:0.0100, T:0.6068(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6250 (C:5.7228, R:0.0099, T:0.6240(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6282 (C:5.7791, R:0.0099, T:0.6273(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 82 TRAINING SUMMARY:
  Total Loss: 0.6243
  Contrastive: 5.7398
  Reconstruction: 0.0100
  Topological: 0.6233 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.6093
  Contrastive: 4.6656
  Reconstruction: 0.0100
  Topological: 4.6083 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 82/100 COMPLETE (90.3s)
Train Loss: 0.6243 (C:5.7398, R:0.0100, T:0.6233)
Val Loss:   4.6093 (C:4.6656, R:0.0100, T:4.6083)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 83 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5950 (C:5.7593, R:0.0100, T:0.5940(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6269 (C:5.6715, R:0.0099, T:0.6259(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5958 (C:5.7358, R:0.0100, T:0.5948(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5821 (C:5.7444, R:0.0099, T:0.5812(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6421 (C:5.7013, R:0.0099, T:0.6411(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6171 (C:5.7797, R:0.0099, T:0.6161(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6274 (C:5.7154, R:0.0099, T:0.6264(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6031 (C:5.7608, R:0.0100, T:0.6021(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6123 (C:5.7447, R:0.0100, T:0.6113(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6411 (C:5.7775, R:0.0100, T:0.6401(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6616 (C:5.7721, R:0.0100, T:0.6606(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6165 (C:5.6761, R:0.0100, T:0.6155(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5625 (C:5.7627, R:0.0099, T:0.5615(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6189 (C:5.7050, R:0.0099, T:0.6179(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5919 (C:5.7545, R:0.0099, T:0.5909(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6177 (C:5.7383, R:0.0100, T:0.6167(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6390 (C:5.7934, R:0.0100, T:0.6380(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6176 (C:5.7522, R:0.0099, T:0.6166(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6391 (C:5.7276, R:0.0100, T:0.6381(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6286 (C:5.8118, R:0.0100, T:0.6276(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6309 (C:5.7673, R:0.0099, T:0.6299(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6010 (C:5.7593, R:0.0100, T:0.6000(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 83 TRAINING SUMMARY:
  Total Loss: 0.6236
  Contrastive: 5.7412
  Reconstruction: 0.0100
  Topological: 0.6226 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8275
  Contrastive: 4.6051
  Reconstruction: 0.0100
  Topological: 4.8265 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 83/100 COMPLETE (89.7s)
Train Loss: 0.6236 (C:5.7412, R:0.0100, T:0.6226)
Val Loss:   4.8275 (C:4.6051, R:0.0100, T:4.8265)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 84 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6218 (C:5.6925, R:0.0100, T:0.6208(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6082 (C:5.7614, R:0.0099, T:0.6072(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6257 (C:5.7368, R:0.0099, T:0.6247(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6308 (C:5.7342, R:0.0100, T:0.6298(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5959 (C:5.7228, R:0.0099, T:0.5949(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6403 (C:5.8171, R:0.0099, T:0.6393(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6231 (C:5.7308, R:0.0099, T:0.6221(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6351 (C:5.7398, R:0.0100, T:0.6341(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6314 (C:5.6873, R:0.0099, T:0.6304(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6490 (C:5.7519, R:0.0099, T:0.6480(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6028 (C:5.7590, R:0.0100, T:0.6018(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5908 (C:5.7135, R:0.0099, T:0.5898(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6315 (C:5.7421, R:0.0099, T:0.6305(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6092 (C:5.7509, R:0.0100, T:0.6082(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6312 (C:5.7330, R:0.0100, T:0.6302(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6324 (C:5.7417, R:0.0099, T:0.6314(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6197 (C:5.7627, R:0.0099, T:0.6188(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6214 (C:5.7105, R:0.0099, T:0.6204(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6268 (C:5.7578, R:0.0099, T:0.6258(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6008 (C:5.7618, R:0.0100, T:0.5998(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6120 (C:5.7112, R:0.0100, T:0.6110(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6168 (C:5.7703, R:0.0100, T:0.6158(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6210

ğŸ“Š EPOCH 84 TRAINING SUMMARY:
  Total Loss: 0.6220
  Contrastive: 5.7407
  Reconstruction: 0.0100
  Topological: 0.6210 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.6111
  Contrastive: 4.6676
  Reconstruction: 0.0100
  Topological: 4.6101 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 84/100 COMPLETE (89.4s)
Train Loss: 0.6220 (C:5.7407, R:0.0100, T:0.6210)
Val Loss:   4.6111 (C:4.6676, R:0.0100, T:4.6101)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 85 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6460 (C:5.7409, R:0.0099, T:0.6450(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6019 (C:5.7577, R:0.0099, T:0.6009(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6158 (C:5.7381, R:0.0099, T:0.6148(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6500 (C:5.7185, R:0.0099, T:0.6490(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5978 (C:5.7465, R:0.0099, T:0.5968(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6362 (C:5.7155, R:0.0100, T:0.6352(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5981 (C:5.7273, R:0.0099, T:0.5971(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5867 (C:5.6962, R:0.0099, T:0.5857(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6490 (C:5.7383, R:0.0099, T:0.6480(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6842 (C:5.7416, R:0.0100, T:0.6832(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6305 (C:5.7961, R:0.0100, T:0.6295(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6125 (C:5.7258, R:0.0099, T:0.6115(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6115 (C:5.7750, R:0.0099, T:0.6105(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6016 (C:5.7371, R:0.0099, T:0.6006(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6349 (C:5.7288, R:0.0100, T:0.6339(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6240 (C:5.7533, R:0.0099, T:0.6230(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6152 (C:5.7566, R:0.0099, T:0.6143(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6002 (C:5.7363, R:0.0100, T:0.5992(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5987 (C:5.7504, R:0.0100, T:0.5977(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6205 (C:5.7720, R:0.0100, T:0.6195(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6019 (C:5.7667, R:0.0099, T:0.6009(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6180 (C:5.6833, R:0.0099, T:0.6170(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 85 TRAINING SUMMARY:
  Total Loss: 0.6228
  Contrastive: 5.7423
  Reconstruction: 0.0100
  Topological: 0.6218 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.5245
  Contrastive: 4.6964
  Reconstruction: 0.0100
  Topological: 4.5235 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 85/100 COMPLETE (89.6s)
Train Loss: 0.6228 (C:5.7423, R:0.0100, T:0.6218)
Val Loss:   4.5245 (C:4.6964, R:0.0100, T:4.5235)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 86 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6450 (C:5.7900, R:0.0100, T:0.6440(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6375 (C:5.7367, R:0.0099, T:0.6365(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6146 (C:5.7858, R:0.0100, T:0.6136(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5992 (C:5.7806, R:0.0100, T:0.5982(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6163 (C:5.8002, R:0.0100, T:0.6153(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6284 (C:5.7740, R:0.0100, T:0.6274(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6390 (C:5.7061, R:0.0099, T:0.6380(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6400 (C:5.7554, R:0.0100, T:0.6390(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5839 (C:5.7025, R:0.0100, T:0.5829(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6285 (C:5.7803, R:0.0099, T:0.6275(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6671 (C:5.7472, R:0.0100, T:0.6661(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6030 (C:5.7665, R:0.0099, T:0.6020(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5834 (C:5.7237, R:0.0100, T:0.5824(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6349 (C:5.7721, R:0.0099, T:0.6339(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6304 (C:5.7119, R:0.0099, T:0.6294(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6204 (C:5.7529, R:0.0099, T:0.6194(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6551 (C:5.7579, R:0.0100, T:0.6541(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6276 (C:5.7457, R:0.0099, T:0.6266(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6218 (C:5.7506, R:0.0100, T:0.6208(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6425 (C:5.7437, R:0.0100, T:0.6415(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6168 (C:5.7689, R:0.0099, T:0.6158(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5931 (C:5.7410, R:0.0100, T:0.5921(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6198

ğŸ“Š EPOCH 86 TRAINING SUMMARY:
  Total Loss: 0.6208
  Contrastive: 5.7411
  Reconstruction: 0.0100
  Topological: 0.6198 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.7909
  Contrastive: 4.6064
  Reconstruction: 0.0100
  Topological: 4.7899 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 86/100 COMPLETE (89.9s)
Train Loss: 0.6208 (C:5.7411, R:0.0100, T:0.6198)
Val Loss:   4.7909 (C:4.6064, R:0.0100, T:4.7899)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 87 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6369 (C:5.6797, R:0.0099, T:0.6359(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6201 (C:5.7985, R:0.0100, T:0.6191(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5937 (C:5.7359, R:0.0100, T:0.5927(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6421 (C:5.7416, R:0.0100, T:0.6411(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6463 (C:5.8091, R:0.0099, T:0.6453(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6156 (C:5.7901, R:0.0099, T:0.6146(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5913 (C:5.7243, R:0.0100, T:0.5903(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6325 (C:5.7056, R:0.0099, T:0.6315(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6281 (C:5.7445, R:0.0100, T:0.6271(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6129 (C:5.7482, R:0.0099, T:0.6119(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5909 (C:5.7392, R:0.0099, T:0.5899(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5976 (C:5.7649, R:0.0099, T:0.5966(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6167 (C:5.7616, R:0.0100, T:0.6157(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6608 (C:5.7012, R:0.0099, T:0.6599(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6658 (C:5.7531, R:0.0100, T:0.6648(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6286 (C:5.7190, R:0.0100, T:0.6276(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6118 (C:5.7349, R:0.0100, T:0.6108(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6197 (C:5.7540, R:0.0100, T:0.6187(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5842 (C:5.7361, R:0.0099, T:0.5832(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6854 (C:5.7349, R:0.0100, T:0.6844(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6423 (C:5.7389, R:0.0100, T:0.6413(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6196 (C:5.7210, R:0.0099, T:0.6186(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 87 TRAINING SUMMARY:
  Total Loss: 0.6220
  Contrastive: 5.7410
  Reconstruction: 0.0100
  Topological: 0.6210 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.5782
  Contrastive: 4.6446
  Reconstruction: 0.0100
  Topological: 4.5772 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 87/100 COMPLETE (90.8s)
Train Loss: 0.6220 (C:5.7410, R:0.0100, T:0.6210)
Val Loss:   4.5782 (C:4.6446, R:0.0100, T:4.5772)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 88 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6056 (C:5.7318, R:0.0100, T:0.6046(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6000 (C:5.7666, R:0.0100, T:0.5990(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6082 (C:5.7450, R:0.0099, T:0.6072(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6411 (C:5.7380, R:0.0100, T:0.6401(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6331 (C:5.7399, R:0.0099, T:0.6321(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6347 (C:5.7870, R:0.0100, T:0.6337(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6102 (C:5.7412, R:0.0100, T:0.6093(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5827 (C:5.7321, R:0.0099, T:0.5817(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6151 (C:5.6803, R:0.0099, T:0.6141(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6729 (C:5.6871, R:0.0099, T:0.6719(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6542 (C:5.7051, R:0.0100, T:0.6532(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6380 (C:5.7189, R:0.0100, T:0.6370(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6507 (C:5.7788, R:0.0100, T:0.6497(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6288 (C:5.7694, R:0.0100, T:0.6278(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6268 (C:5.7109, R:0.0100, T:0.6258(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6162 (C:5.7549, R:0.0099, T:0.6152(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5910 (C:5.7265, R:0.0099, T:0.5900(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6160 (C:5.7523, R:0.0099, T:0.6150(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6174 (C:5.7151, R:0.0099, T:0.6164(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6249 (C:5.7495, R:0.0099, T:0.6239(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6364 (C:5.7472, R:0.0099, T:0.6354(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6151 (C:5.7200, R:0.0100, T:0.6141(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 88 TRAINING SUMMARY:
  Total Loss: 0.6230
  Contrastive: 5.7416
  Reconstruction: 0.0100
  Topological: 0.6221 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.6992
  Contrastive: 4.6526
  Reconstruction: 0.0100
  Topological: 4.6982 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 88/100 COMPLETE (92.2s)
Train Loss: 0.6230 (C:5.7416, R:0.0100, T:0.6221)
Val Loss:   4.6992 (C:4.6526, R:0.0100, T:4.6982)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 89 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6565 (C:5.7104, R:0.0099, T:0.6555(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6064 (C:5.6943, R:0.0099, T:0.6054(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6030 (C:5.7334, R:0.0099, T:0.6020(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6185 (C:5.7166, R:0.0100, T:0.6175(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6123 (C:5.7043, R:0.0099, T:0.6113(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6322 (C:5.7669, R:0.0100, T:0.6312(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6310 (C:5.7163, R:0.0100, T:0.6300(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6398 (C:5.7596, R:0.0100, T:0.6388(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6139 (C:5.7327, R:0.0099, T:0.6129(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5825 (C:5.7154, R:0.0100, T:0.5815(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6119 (C:5.7460, R:0.0100, T:0.6109(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6302 (C:5.7775, R:0.0099, T:0.6292(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6225 (C:5.6887, R:0.0100, T:0.6215(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6274 (C:5.7495, R:0.0099, T:0.6264(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5849 (C:5.7320, R:0.0100, T:0.5839(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6194 (C:5.7346, R:0.0100, T:0.6184(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6321 (C:5.7401, R:0.0100, T:0.6311(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6228 (C:5.7574, R:0.0099, T:0.6218(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6074 (C:5.7483, R:0.0100, T:0.6064(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6406 (C:5.7242, R:0.0100, T:0.6396(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6349 (C:5.8166, R:0.0100, T:0.6339(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5977 (C:5.7010, R:0.0099, T:0.5967(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 89 TRAINING SUMMARY:
  Total Loss: 0.6209
  Contrastive: 5.7421
  Reconstruction: 0.0100
  Topological: 0.6199 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.5650
  Contrastive: 4.6964
  Reconstruction: 0.0100
  Topological: 4.5640 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 89/100 COMPLETE (99.0s)
Train Loss: 0.6209 (C:5.7421, R:0.0100, T:0.6199)
Val Loss:   4.5650 (C:4.6964, R:0.0100, T:4.5640)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 90 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6311 (C:5.7785, R:0.0099, T:0.6301(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6279 (C:5.7679, R:0.0099, T:0.6269(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6235 (C:5.6952, R:0.0099, T:0.6225(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6090 (C:5.7285, R:0.0100, T:0.6080(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6121 (C:5.7312, R:0.0099, T:0.6111(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6315 (C:5.8150, R:0.0100, T:0.6305(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6417 (C:5.7201, R:0.0099, T:0.6407(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6022 (C:5.7697, R:0.0100, T:0.6012(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6165 (C:5.7290, R:0.0099, T:0.6155(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6478 (C:5.7419, R:0.0099, T:0.6468(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6685 (C:5.7181, R:0.0099, T:0.6675(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6271 (C:5.7806, R:0.0100, T:0.6261(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6378 (C:5.7848, R:0.0100, T:0.6368(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5914 (C:5.7351, R:0.0099, T:0.5904(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6054 (C:5.7929, R:0.0099, T:0.6044(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6183 (C:5.7114, R:0.0099, T:0.6174(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6127 (C:5.7587, R:0.0100, T:0.6117(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6027 (C:5.7337, R:0.0099, T:0.6017(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5961 (C:5.7206, R:0.0100, T:0.5951(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6456 (C:5.7056, R:0.0099, T:0.6446(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6428 (C:5.7752, R:0.0100, T:0.6418(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6103 (C:5.6772, R:0.0099, T:0.6093(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6171

ğŸ“Š EPOCH 90 TRAINING SUMMARY:
  Total Loss: 0.6181
  Contrastive: 5.7415
  Reconstruction: 0.0100
  Topological: 0.6171 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.6384
  Contrastive: 4.6367
  Reconstruction: 0.0100
  Topological: 4.6374 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 90/100 COMPLETE (101.3s)
Train Loss: 0.6181 (C:5.7415, R:0.0100, T:0.6171)
Val Loss:   4.6384 (C:4.6367, R:0.0100, T:4.6374)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 91 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5746 (C:5.7240, R:0.0100, T:0.5736(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6379 (C:5.7401, R:0.0100, T:0.6369(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6458 (C:5.7072, R:0.0099, T:0.6448(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6230 (C:5.7969, R:0.0099, T:0.6220(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6379 (C:5.7013, R:0.0100, T:0.6369(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6138 (C:5.7385, R:0.0100, T:0.6128(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5930 (C:5.7597, R:0.0099, T:0.5920(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6069 (C:5.7504, R:0.0099, T:0.6059(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6065 (C:5.7102, R:0.0099, T:0.6055(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6460 (C:5.7038, R:0.0100, T:0.6450(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6412 (C:5.7877, R:0.0100, T:0.6402(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6205 (C:5.7242, R:0.0100, T:0.6195(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6126 (C:5.7295, R:0.0099, T:0.6116(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5861 (C:5.7685, R:0.0100, T:0.5851(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6231 (C:5.7505, R:0.0099, T:0.6221(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6166 (C:5.7357, R:0.0099, T:0.6156(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6294 (C:5.7307, R:0.0100, T:0.6284(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6563 (C:5.7520, R:0.0100, T:0.6553(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6478 (C:5.6787, R:0.0100, T:0.6468(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5960 (C:5.7712, R:0.0099, T:0.5950(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5966 (C:5.7310, R:0.0099, T:0.5956(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6408 (C:5.7352, R:0.0100, T:0.6398(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 91 TRAINING SUMMARY:
  Total Loss: 0.6217
  Contrastive: 5.7395
  Reconstruction: 0.0100
  Topological: 0.6207 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.6303
  Contrastive: 4.6439
  Reconstruction: 0.0100
  Topological: 4.6293 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 91/100 COMPLETE (90.6s)
Train Loss: 0.6217 (C:5.7395, R:0.0100, T:0.6207)
Val Loss:   4.6303 (C:4.6439, R:0.0100, T:4.6293)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 92 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6362 (C:5.7254, R:0.0100, T:0.6352(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6261 (C:5.8016, R:0.0100, T:0.6251(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6211 (C:5.7081, R:0.0099, T:0.6201(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6187 (C:5.7533, R:0.0099, T:0.6177(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6019 (C:5.7660, R:0.0100, T:0.6009(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5958 (C:5.7700, R:0.0100, T:0.5948(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6294 (C:5.7929, R:0.0100, T:0.6284(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6746 (C:5.7447, R:0.0099, T:0.6736(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6212 (C:5.7441, R:0.0100, T:0.6202(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6499 (C:5.7235, R:0.0100, T:0.6489(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6232 (C:5.7637, R:0.0100, T:0.6222(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6040 (C:5.6807, R:0.0099, T:0.6030(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6254 (C:5.7722, R:0.0099, T:0.6244(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6189 (C:5.7642, R:0.0099, T:0.6179(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6257 (C:5.7710, R:0.0100, T:0.6247(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6428 (C:5.7394, R:0.0099, T:0.6418(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6042 (C:5.7370, R:0.0099, T:0.6032(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6305 (C:5.7518, R:0.0099, T:0.6295(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5994 (C:5.7271, R:0.0099, T:0.5985(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6188 (C:5.7611, R:0.0100, T:0.6178(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6304 (C:5.7899, R:0.0100, T:0.6295(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5894 (C:5.7121, R:0.0100, T:0.5884(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 92 TRAINING SUMMARY:
  Total Loss: 0.6195
  Contrastive: 5.7429
  Reconstruction: 0.0100
  Topological: 0.6185 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.5324
  Contrastive: 4.6804
  Reconstruction: 0.0100
  Topological: 4.5314 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 92/100 COMPLETE (89.5s)
Train Loss: 0.6195 (C:5.7429, R:0.0100, T:0.6185)
Val Loss:   4.5324 (C:4.6804, R:0.0100, T:4.5314)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 93 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6406 (C:5.7914, R:0.0099, T:0.6396(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6055 (C:5.7019, R:0.0099, T:0.6045(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6304 (C:5.7154, R:0.0099, T:0.6294(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6182 (C:5.6799, R:0.0099, T:0.6172(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6187 (C:5.7361, R:0.0099, T:0.6178(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6458 (C:5.7068, R:0.0099, T:0.6448(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6119 (C:5.7533, R:0.0100, T:0.6109(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6454 (C:5.7297, R:0.0099, T:0.6444(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6094 (C:5.7404, R:0.0099, T:0.6084(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6039 (C:5.7311, R:0.0100, T:0.6029(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6470 (C:5.7896, R:0.0100, T:0.6460(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6568 (C:5.7264, R:0.0100, T:0.6558(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6639 (C:5.7647, R:0.0099, T:0.6629(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6549 (C:5.7665, R:0.0099, T:0.6539(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6289 (C:5.7160, R:0.0099, T:0.6279(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6234 (C:5.7419, R:0.0099, T:0.6224(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6510 (C:5.7448, R:0.0099, T:0.6500(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6127 (C:5.7229, R:0.0099, T:0.6117(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5824 (C:5.8092, R:0.0100, T:0.5814(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6186 (C:5.7432, R:0.0100, T:0.6176(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6581 (C:5.6776, R:0.0099, T:0.6571(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6195 (C:5.8198, R:0.0100, T:0.6185(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 93 TRAINING SUMMARY:
  Total Loss: 0.6215
  Contrastive: 5.7418
  Reconstruction: 0.0100
  Topological: 0.6205 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.5562
  Contrastive: 4.6621
  Reconstruction: 0.0100
  Topological: 4.5552 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 93/100 COMPLETE (89.6s)
Train Loss: 0.6215 (C:5.7418, R:0.0100, T:0.6205)
Val Loss:   4.5562 (C:4.6621, R:0.0100, T:4.5552)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 94 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6424 (C:5.7437, R:0.0100, T:0.6414(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6000 (C:5.7554, R:0.0100, T:0.5990(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5986 (C:5.7642, R:0.0099, T:0.5976(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6374 (C:5.7201, R:0.0100, T:0.6364(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6229 (C:5.7301, R:0.0100, T:0.6219(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6354 (C:5.8295, R:0.0100, T:0.6344(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6184 (C:5.7334, R:0.0099, T:0.6174(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5968 (C:5.7029, R:0.0099, T:0.5958(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6005 (C:5.7136, R:0.0100, T:0.5995(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6081 (C:5.7844, R:0.0100, T:0.6071(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6153 (C:5.7160, R:0.0100, T:0.6143(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6334 (C:5.7673, R:0.0100, T:0.6324(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6273 (C:5.7187, R:0.0099, T:0.6264(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6338 (C:5.7556, R:0.0100, T:0.6328(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6062 (C:5.7315, R:0.0100, T:0.6053(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6109 (C:5.7839, R:0.0099, T:0.6099(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6395 (C:5.7128, R:0.0099, T:0.6385(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6242 (C:5.7476, R:0.0099, T:0.6233(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6086 (C:5.7136, R:0.0099, T:0.6076(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6230 (C:5.7465, R:0.0100, T:0.6220(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6165 (C:5.8187, R:0.0100, T:0.6155(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6236 (C:5.6944, R:0.0100, T:0.6226(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 94 TRAINING SUMMARY:
  Total Loss: 0.6198
  Contrastive: 5.7404
  Reconstruction: 0.0100
  Topological: 0.6188 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.3795
  Contrastive: 4.7159
  Reconstruction: 0.0100
  Topological: 4.3785 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 94/100 COMPLETE (89.9s)
Train Loss: 0.6198 (C:5.7404, R:0.0100, T:0.6188)
Val Loss:   4.3795 (C:4.7159, R:0.0100, T:4.3785)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 95 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6202 (C:5.7910, R:0.0099, T:0.6192(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6555 (C:5.7249, R:0.0100, T:0.6545(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6551 (C:5.6972, R:0.0099, T:0.6541(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6004 (C:5.7474, R:0.0099, T:0.5994(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5881 (C:5.6970, R:0.0099, T:0.5871(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6032 (C:5.8001, R:0.0100, T:0.6022(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6331 (C:5.7193, R:0.0099, T:0.6321(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6187 (C:5.7454, R:0.0099, T:0.6177(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6246 (C:5.7231, R:0.0099, T:0.6236(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6285 (C:5.7634, R:0.0100, T:0.6275(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6478 (C:5.7410, R:0.0099, T:0.6468(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6039 (C:5.7215, R:0.0100, T:0.6029(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6531 (C:5.7424, R:0.0099, T:0.6521(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6043 (C:5.7383, R:0.0099, T:0.6033(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6220 (C:5.7482, R:0.0099, T:0.6210(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6240 (C:5.7229, R:0.0100, T:0.6230(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6280 (C:5.7789, R:0.0100, T:0.6270(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5924 (C:5.7281, R:0.0099, T:0.5914(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5851 (C:5.7416, R:0.0100, T:0.5841(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6268 (C:5.6891, R:0.0100, T:0.6258(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6115 (C:5.7699, R:0.0100, T:0.6105(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6100 (C:5.7385, R:0.0100, T:0.6090(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 95 TRAINING SUMMARY:
  Total Loss: 0.6195
  Contrastive: 5.7398
  Reconstruction: 0.0100
  Topological: 0.6185 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.4144
  Contrastive: 4.6932
  Reconstruction: 0.0100
  Topological: 4.4134 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 95/100 COMPLETE (89.6s)
Train Loss: 0.6195 (C:5.7398, R:0.0100, T:0.6185)
Val Loss:   4.4144 (C:4.6932, R:0.0100, T:4.4134)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 96 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6014 (C:5.7808, R:0.0099, T:0.6004(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5803 (C:5.7311, R:0.0099, T:0.5793(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6299 (C:5.6800, R:0.0099, T:0.6289(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6061 (C:5.7535, R:0.0100, T:0.6051(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5956 (C:5.7808, R:0.0100, T:0.5946(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6322 (C:5.6920, R:0.0099, T:0.6312(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6047 (C:5.7937, R:0.0100, T:0.6037(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6084 (C:5.7526, R:0.0100, T:0.6074(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6107 (C:5.7547, R:0.0100, T:0.6097(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6390 (C:5.7510, R:0.0099, T:0.6381(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6409 (C:5.7220, R:0.0099, T:0.6399(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6255 (C:5.7244, R:0.0099, T:0.6245(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6309 (C:5.7637, R:0.0099, T:0.6299(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6077 (C:5.7540, R:0.0099, T:0.6068(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5951 (C:5.6604, R:0.0099, T:0.5941(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6322 (C:5.7336, R:0.0100, T:0.6313(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6063 (C:5.7432, R:0.0100, T:0.6053(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5980 (C:5.7380, R:0.0099, T:0.5970(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6218 (C:5.7310, R:0.0100, T:0.6208(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6162 (C:5.6809, R:0.0100, T:0.6152(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6301 (C:5.7336, R:0.0100, T:0.6291(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5950 (C:5.7531, R:0.0100, T:0.5940(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 96 TRAINING SUMMARY:
  Total Loss: 0.6192
  Contrastive: 5.7391
  Reconstruction: 0.0100
  Topological: 0.6182 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.5764
  Contrastive: 4.6583
  Reconstruction: 0.0100
  Topological: 4.5754 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 96/100 COMPLETE (89.6s)
Train Loss: 0.6192 (C:5.7391, R:0.0100, T:0.6182)
Val Loss:   4.5764 (C:4.6583, R:0.0100, T:4.5754)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 97 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5851 (C:5.7339, R:0.0099, T:0.5841(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6195 (C:5.7402, R:0.0099, T:0.6185(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6463 (C:5.6975, R:0.0099, T:0.6453(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6064 (C:5.7413, R:0.0100, T:0.6054(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6072 (C:5.7439, R:0.0099, T:0.6063(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6007 (C:5.7233, R:0.0100, T:0.5997(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6114 (C:5.7409, R:0.0099, T:0.6104(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6120 (C:5.7622, R:0.0100, T:0.6110(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6313 (C:5.6484, R:0.0100, T:0.6303(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6212 (C:5.7686, R:0.0100, T:0.6202(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6304 (C:5.6981, R:0.0099, T:0.6294(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6597 (C:5.7306, R:0.0100, T:0.6587(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6354 (C:5.7392, R:0.0100, T:0.6344(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6173 (C:5.7111, R:0.0100, T:0.6163(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6000 (C:5.7363, R:0.0099, T:0.5990(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5986 (C:5.7272, R:0.0099, T:0.5976(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5994 (C:5.7357, R:0.0100, T:0.5984(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5778 (C:5.7254, R:0.0100, T:0.5768(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6018 (C:5.7718, R:0.0100, T:0.6008(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6056 (C:5.7231, R:0.0099, T:0.6046(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6338 (C:5.7576, R:0.0099, T:0.6328(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6169 (C:5.7466, R:0.0099, T:0.6159(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 97 TRAINING SUMMARY:
  Total Loss: 0.6188
  Contrastive: 5.7385
  Reconstruction: 0.0100
  Topological: 0.6178 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.5795
  Contrastive: 4.6455
  Reconstruction: 0.0100
  Topological: 4.5785 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 97/100 COMPLETE (90.7s)
Train Loss: 0.6188 (C:5.7385, R:0.0100, T:0.6178)
Val Loss:   4.5795 (C:4.6455, R:0.0100, T:4.5785)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 98 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6246 (C:5.7370, R:0.0099, T:0.6236(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6084 (C:5.7652, R:0.0100, T:0.6074(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6101 (C:5.7220, R:0.0099, T:0.6091(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6068 (C:5.7274, R:0.0099, T:0.6058(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6623 (C:5.8004, R:0.0100, T:0.6614(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6109 (C:5.7297, R:0.0099, T:0.6099(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6317 (C:5.7469, R:0.0100, T:0.6307(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6320 (C:5.7485, R:0.0099, T:0.6310(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6163 (C:5.7254, R:0.0099, T:0.6153(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5865 (C:5.7926, R:0.0099, T:0.5855(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6265 (C:5.7156, R:0.0100, T:0.6255(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6408 (C:5.7307, R:0.0099, T:0.6398(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6183 (C:5.6974, R:0.0100, T:0.6173(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6112 (C:5.7116, R:0.0100, T:0.6102(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5982 (C:5.7697, R:0.0099, T:0.5972(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6160 (C:5.7477, R:0.0100, T:0.6150(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5673 (C:5.7564, R:0.0099, T:0.5663(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5650 (C:5.7064, R:0.0099, T:0.5640(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6294 (C:5.7939, R:0.0100, T:0.6284(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6160 (C:5.7332, R:0.0100, T:0.6150(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5913 (C:5.7638, R:0.0100, T:0.5903(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5804 (C:5.6751, R:0.0099, T:0.5794(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6170

ğŸ“Š EPOCH 98 TRAINING SUMMARY:
  Total Loss: 0.6180
  Contrastive: 5.7398
  Reconstruction: 0.0100
  Topological: 0.6170 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.5358
  Contrastive: 4.6670
  Reconstruction: 0.0100
  Topological: 4.5348 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 98/100 COMPLETE (89.8s)
Train Loss: 0.6180 (C:5.7398, R:0.0100, T:0.6170)
Val Loss:   4.5358 (C:4.6670, R:0.0100, T:4.5348)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 99 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6179 (C:5.7555, R:0.0100, T:0.6169(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6420 (C:5.7400, R:0.0100, T:0.6410(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6164 (C:5.7173, R:0.0100, T:0.6154(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6365 (C:5.7069, R:0.0100, T:0.6355(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6293 (C:5.7500, R:0.0099, T:0.6283(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6153 (C:5.7091, R:0.0100, T:0.6143(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6110 (C:5.7286, R:0.0099, T:0.6100(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6234 (C:5.7106, R:0.0099, T:0.6224(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6266 (C:5.7324, R:0.0099, T:0.6256(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6165 (C:5.7444, R:0.0100, T:0.6155(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5971 (C:5.7565, R:0.0100, T:0.5961(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6258 (C:5.7138, R:0.0100, T:0.6249(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6565 (C:5.7491, R:0.0100, T:0.6555(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6428 (C:5.7352, R:0.0100, T:0.6418(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5945 (C:5.7512, R:0.0100, T:0.5935(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6401 (C:5.7546, R:0.0099, T:0.6391(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6086 (C:5.6828, R:0.0100, T:0.6076(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6095 (C:5.7212, R:0.0099, T:0.6085(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5981 (C:5.7650, R:0.0099, T:0.5971(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6155 (C:5.7763, R:0.0099, T:0.6145(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5963 (C:5.7446, R:0.0099, T:0.5953(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6268 (C:5.7349, R:0.0099, T:0.6258(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 99 TRAINING SUMMARY:
  Total Loss: 0.6185
  Contrastive: 5.7420
  Reconstruction: 0.0100
  Topological: 0.6175 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.6171
  Contrastive: 4.6398
  Reconstruction: 0.0100
  Topological: 4.6161 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 99/100 COMPLETE (87.8s)
Train Loss: 0.6185 (C:5.7420, R:0.0100, T:0.6175)
Val Loss:   4.6171 (C:4.6398, R:0.0100, T:4.6161)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 100 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5719 (C:5.7078, R:0.0099, T:0.5709(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6608 (C:5.7154, R:0.0099, T:0.6598(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6186 (C:5.7229, R:0.0100, T:0.6176(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5875 (C:5.7693, R:0.0099, T:0.5865(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6212 (C:5.6868, R:0.0100, T:0.6202(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6365 (C:5.7430, R:0.0100, T:0.6355(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5709 (C:5.7353, R:0.0099, T:0.5699(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6264 (C:5.7413, R:0.0100, T:0.6254(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6244 (C:5.7065, R:0.0099, T:0.6234(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5940 (C:5.6759, R:0.0099, T:0.5931(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6544 (C:5.7444, R:0.0100, T:0.6534(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6014 (C:5.7254, R:0.0100, T:0.6004(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6579 (C:5.7777, R:0.0100, T:0.6569(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6396 (C:5.7000, R:0.0099, T:0.6386(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6356 (C:5.7408, R:0.0100, T:0.6346(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6487 (C:5.7365, R:0.0100, T:0.6477(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6328 (C:5.7738, R:0.0099, T:0.6318(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6038 (C:5.7097, R:0.0100, T:0.6028(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6505 (C:5.7631, R:0.0100, T:0.6495(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6289 (C:5.7856, R:0.0100, T:0.6279(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6012 (C:5.7448, R:0.0100, T:0.6002(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6372 (C:5.7379, R:0.0099, T:0.6362(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 100 TRAINING SUMMARY:
  Total Loss: 0.6192
  Contrastive: 5.7408
  Reconstruction: 0.0100
  Topological: 0.6182 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.5651
  Contrastive: 4.6596
  Reconstruction: 0.0100
  Topological: 4.5642 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ¯ EPOCH 100/100 COMPLETE (89.1s)
Train Loss: 0.6192 (C:5.7408, R:0.0100, T:0.6182)
Val Loss:   4.5651 (C:4.6596, R:0.0100, T:4.5642)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

======================================================================
ğŸ“ˆ FINAL TOPOLOGICAL LEARNING ANALYSIS
======================================================================
First topological learning: Epoch 1
Epochs with topology: 100/100
Max consecutive topology epochs: 100
Best topological loss: 0.6170
Final topological loss: 0.6182
âœ… SUCCESS: Topological learning achieved!
ğŸš€ EXCELLENT: Very consistent topological learning (>80%)
ğŸ“ˆ Topological learning appears stable

======================================================================
ğŸ¯ TOPOLOGICAL AUTOENCODER TRAINING COMPLETED
======================================================================
âœ… Topological training completed successfully!
Saving results...
Loading best model from entailment_surfaces/supervised_contrastive_autoencoder/experiments/topological_autoencoder_torchph_phase1_20250721_183602/checkpoints/best_model.pt
Starting model evaluation...
========================================
GlobalContrastiveEvaluator initialized on cuda
Starting comprehensive evaluation...
============================================================
Extracting latent representations...
  Processed 1/539 batches
  Processed 51/539 batches
  Processed 101/539 batches
  Processed 151/539 batches
  Processed 201/539 batches
  Processed 251/539 batches
  Processed 301/539 batches
  Processed 351/539 batches
  Processed 401/539 batches
  Processed 451/539 batches
  Processed 501/539 batches
Extracted representations: torch.Size([549367, 75])
Evaluating clustering performance...
Subsampled to 50000 points for clustering evaluation
Clustering Results:
  Silhouette Score: 0.0009
  Adjusted Rand Score: 0.0003
  Clustering Accuracy: 0.3444
Evaluating classification performance...
  Extracting training representations...
Extracting latent representations...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
Extracted representations: torch.Size([547740, 75])
  Extracting validation representations...
Extracting latent representations...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
Extracted representations: torch.Size([547740, 75])
Subsampled training to 50000 samples
Subsampled validation to 10000 samples
  Training on 50000 samples, evaluating on 10000 samples
Classification Results:
  Accuracy: 0.5264
  Per-class F1: [0.5758036236119228, 0.4403900597672224, 0.5508158049931198]
Evaluating reconstruction quality...
Reconstruction Results:
  Average MSE: 0.009954
Evaluating separation quality...
Subsampled to 20000 points for separation evaluation
Separation Results:
  Positive distances: 4.715 Â± 0.486
  Negative distances: 4.734 Â± 0.476
  Separation ratio: 1.00x
  Gap: -6.442
  Perfect separation: No

Comprehensive evaluation completed!

============================================================
EVALUATION SUMMARY
============================================================
Clustering Performance:
  Silhouette Score: 0.0009
  Clustering Accuracy: 0.3444
  Adjusted Rand Score: 0.0003

Classification Performance:
  Accuracy: 0.5264

Separation Quality:
  Separation Ratio: 1.00x
  Gap: -6.442
  Perfect Separation: False

Reconstruction Quality:
  Average MSE: 0.009954
============================================================
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/topological_autoencoder_torchph_phase1_20250721_183602/results/evaluation_results_20250721_210714.json
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/topological_autoencoder_torchph_phase1_20250721_183602/results/evaluation_results_20250721_210714.json

Key Results:
  Separation ratio: 1.00x
  Perfect separation: False
  Classification accuracy: 0.5264

============================================================
TOPOLOGICAL TRAINING ANALYSIS
============================================================

ğŸ“ˆ TOPOLOGICAL LEARNING DIAGNOSIS:
  Total epochs: 100
  Epochs with topological learning: 100
  Current topological loss: 0.6182
  Current topological weight: 1.0000
  âš ï¸  Topological loss is increasing (may need tuning)
ğŸš€ EXCELLENT: Consistent topological learning achieved!
Final topological loss: 0.6182
Epochs with topology: 100/100
âš ï¸  Poor clustering accuracy: 0.344

Final analysis saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/topological_autoencoder_torchph_phase1_20250721_183602/results/final_analysis.json
Experiment saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/topological_autoencoder_torchph_phase1_20250721_183602

Analysis completed with exit code: 0
Time: Mon 21 Jul 21:07:16 BST 2025

=== ANALYSIS SUCCESSFUL ===
Regularization successful!


Job finished.
