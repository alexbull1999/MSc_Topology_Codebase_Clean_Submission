Starting Surface Distance Metric Analysis job...
Job ID: 184821
Node: gpuvm17
Time: Tue 22 Jul 14:16:08 BST 2025
Loading CUDA...
Activating conda environment...
Activated conda environment: /vol/bitbucket/ahb24/tda_entailment_new
Python location: /vol/bitbucket/ahb24/tda_entailment_new/bin/python
Checking GPU availability...
Tue Jul 22 14:16:10 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.133.07             Driver Version: 570.133.07     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla T4                       Off |   00000000:00:06.0 Off |                    0 |
| N/A   29C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+

Testing PyTorch and CUDA...
PyTorch version: 2.4.1
CUDA available: True
CUDA device: Tesla T4
GPU memory: 15.6 GB
PyTorch setup verified!

Starting Topological Training...

============================================================
TOPOLOGICAL AUTOENCODER TRAINING WITH TORCHPH
============================================================
Experiment setup completed:
  Experiment directory: entailment_surfaces/supervised_contrastive_autoencoder/experiments/topological_autoencoder_torchph_phase1_20250722_141618
  Config saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/topological_autoencoder_torchph_phase1_20250722_141618/config.json
Loading data...
========================================
FlexibleEmbedder initialized with type: 'lattice'
Output dimension will be: 768
GlobalDataLoader initialized:
  Embedding type: lattice
  Output dimension: 768
  Sample size: All
Starting data loading pipeline...
============================================================
Loading training data from data/processed/snli_full_standard_SBERT.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 549367 training samples
Loading validation data from data/processed/snli_full_standard_SBERT_validation.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9842 validation samples
Loading test data from data/processed/snli_full_standard_SBERT_test.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9824 test samples
Generating embeddings for training...
Generating lattice embeddings on cuda
Processing 549367 samples in batches of 1000
  Processing batch 1/550
  Processing batch 6/550
  Processing batch 11/550
  Processing batch 16/550
  Processing batch 21/550
  Processing batch 26/550
  Processing batch 31/550
  Processing batch 36/550
  Processing batch 41/550
  Processing batch 46/550
  Processing batch 51/550
  Processing batch 56/550
  Processing batch 61/550
  Processing batch 66/550
  Processing batch 71/550
  Processing batch 76/550
  Processing batch 81/550
  Processing batch 86/550
  Processing batch 91/550
  Processing batch 96/550
  Processing batch 101/550
  Processing batch 106/550
  Processing batch 111/550
  Processing batch 116/550
  Processing batch 121/550
  Processing batch 126/550
  Processing batch 131/550
  Processing batch 136/550
  Processing batch 141/550
  Processing batch 146/550
  Processing batch 151/550
  Processing batch 156/550
  Processing batch 161/550
  Processing batch 166/550
  Processing batch 171/550
  Processing batch 176/550
  Processing batch 181/550
  Processing batch 186/550
  Processing batch 191/550
  Processing batch 196/550
  Processing batch 201/550
  Processing batch 206/550
  Processing batch 211/550
  Processing batch 216/550
  Processing batch 221/550
  Processing batch 226/550
  Processing batch 231/550
  Processing batch 236/550
  Processing batch 241/550
  Processing batch 246/550
  Processing batch 251/550
  Processing batch 256/550
  Processing batch 261/550
  Processing batch 266/550
  Processing batch 271/550
  Processing batch 276/550
  Processing batch 281/550
  Processing batch 286/550
  Processing batch 291/550
  Processing batch 296/550
  Processing batch 301/550
  Processing batch 306/550
  Processing batch 311/550
  Processing batch 316/550
  Processing batch 321/550
  Processing batch 326/550
  Processing batch 331/550
  Processing batch 336/550
  Processing batch 341/550
  Processing batch 346/550
  Processing batch 351/550
  Processing batch 356/550
  Processing batch 361/550
  Processing batch 366/550
  Processing batch 371/550
  Processing batch 376/550
  Processing batch 381/550
  Processing batch 386/550
  Processing batch 391/550
  Processing batch 396/550
  Processing batch 401/550
  Processing batch 406/550
  Processing batch 411/550
  Processing batch 416/550
  Processing batch 421/550
  Processing batch 426/550
  Processing batch 431/550
  Processing batch 436/550
  Processing batch 441/550
  Processing batch 446/550
  Processing batch 451/550
  Processing batch 456/550
  Processing batch 461/550
  Processing batch 466/550
  Processing batch 471/550
  Processing batch 476/550
  Processing batch 481/550
  Processing batch 486/550
  Processing batch 491/550
  Processing batch 496/550
  Processing batch 501/550
  Processing batch 506/550
  Processing batch 511/550
  Processing batch 516/550
  Processing batch 521/550
  Processing batch 526/550
  Processing batch 531/550
  Processing batch 536/550
  Processing batch 541/550
  Processing batch 546/550
Generated lattice embeddings: torch.Size([549367, 768])
Generating embeddings for validation...
Generating lattice embeddings on cuda
Processing 9842 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated lattice embeddings: torch.Size([9842, 768])
Generating embeddings for test...
Generating lattice embeddings on cuda
Processing 9824 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated lattice embeddings: torch.Size([9824, 768])
EntailmentDataset created: 549367 samples
  Embedding shape: torch.Size([549367, 768])
  Class distribution: {'entailment': 183416, 'neutral': 182764, 'contradiction': 183187}
EntailmentDataset created: 9842 samples
  Embedding shape: torch.Size([9842, 768])
  Class distribution: {'entailment': 3329, 'neutral': 3235, 'contradiction': 3278}
EntailmentDataset created: 9824 samples
  Embedding shape: torch.Size([9824, 768])
  Class distribution: {'entailment': 3368, 'neutral': 3219, 'contradiction': 3237}

Data loading pipeline completed!
Output embedding dimension: 768
Updated model input_dim to: 768
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 537
  Class 2: 183187 samples
  Class 0: 183416 samples
  Class 1: 182764 samples
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 9
  Class 2: 3278 samples
  Class 0: 3329 samples
  Class 1: 3235 samples
DataLoaders created:
  Batch size: 1020
  Balanced sampling: True
  Train batches: 537
  Val batches: 9
  Test batches: 10
Data loading completed!
  Train: 549367 samples, 537 batches
  Val: 9842 samples, 9 batches
  Test: 9824 samples, 10 batches
AttentionAutoencoder initialized:
  Input dim: 768
  Latent dim: 75
  Hidden dims: [1024, 768, 512, 256, 128]
  Attention Heads: 5
  Total parameters: 4,308,209
FullDatasetContrastiveLoss initialized:
  Margin: 2.0
  Update frequency: 3 epochs
  Max global samples: 5000
FullDatasetCombinedLoss initialized:
  Contrastive weight: 0.0
  Base reconstruction weight: 0.1
  Scheduled reconstruction: warmup=10 epochs, max_weight=0.3
MoorTopologicalLoss Initialized: Using 0-dimensional persistence pairings (MST edges).
No prototypes being used for topological loss - whole dataset instead.
TopologicalTrainer initialized on device: cuda
Model parameters: 4,308,209
Enhanced with topological loss monitoring
Starting Phase 1: Pure Topological Training
  Contrastive weight: 0.0
  Topological weight: 1.0
  Reconstruction weight: 0.1

======================================================================
ğŸ§  TOPOLOGICAL AUTOENCODER TRAINING STARTED
======================================================================

============================================================
EPOCH 1 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=2.5818 (C:2.7473, R:0.0023, T:2.5816(w:1.000)ğŸš€)
Batch  25/537: Loss=0.2187 (C:1.9957, R:0.0014, T:0.2185(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.1740 (C:1.9923, R:0.0014, T:0.1738(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.1588 (C:1.9808, R:0.0014, T:0.1587(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.1469 (C:1.9776, R:0.0014, T:0.1468(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.1333 (C:1.9788, R:0.0014, T:0.1332(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.1334 (C:1.9856, R:0.0014, T:0.1333(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.1298 (C:1.9828, R:0.0014, T:0.1296(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.1200 (C:1.9802, R:0.0014, T:0.1199(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.1213 (C:1.9858, R:0.0014, T:0.1211(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.1175 (C:1.9851, R:0.0014, T:0.1174(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.1137 (C:1.9853, R:0.0014, T:0.1135(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.1070 (C:1.9848, R:0.0014, T:0.1069(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.1094 (C:1.9817, R:0.0014, T:0.1093(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.1107 (C:1.9861, R:0.0014, T:0.1106(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.1034 (C:1.9829, R:0.0014, T:0.1033(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.1049 (C:1.9880, R:0.0014, T:0.1048(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.1042 (C:1.9850, R:0.0014, T:0.1041(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.1056 (C:1.9865, R:0.0014, T:0.1054(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.1056 (C:1.9860, R:0.0014, T:0.1054(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.1094 (C:1.9874, R:0.0014, T:0.1092(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0989 (C:1.9862, R:0.0014, T:0.0988(w:1.000)ğŸ‰)
ğŸ‰ MILESTONE: First topological learning detected at epoch 1!
   Initial topological loss: 0.1392
ğŸ“ˆ New best topological loss: 0.1392

ğŸ“Š EPOCH 1 TRAINING SUMMARY:
  Total Loss: 0.1393
  Contrastive: 1.9875
  Reconstruction: 0.0014
  Topological: 0.1392 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.8645
  Contrastive: 1.9362
  Reconstruction: 0.0014
  Topological: 2.8644 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 1/300 COMPLETE (44.2s)
Train Loss: 0.1393 (C:1.9875, R:0.0014, T:0.1392)
Val Loss:   2.8645 (C:1.9362, R:0.0014, T:2.8644)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 2 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.1014 (C:1.9817, R:0.0014, T:0.1013(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0990 (C:1.9824, R:0.0014, T:0.0989(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0980 (C:1.9900, R:0.0014, T:0.0979(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0968 (C:1.9830, R:0.0014, T:0.0966(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0929 (C:1.9876, R:0.0014, T:0.0928(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0954 (C:1.9896, R:0.0014, T:0.0953(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0958 (C:1.9862, R:0.0014, T:0.0956(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0944 (C:1.9877, R:0.0014, T:0.0943(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0919 (C:1.9856, R:0.0014, T:0.0917(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0928 (C:1.9882, R:0.0014, T:0.0927(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0925 (C:1.9851, R:0.0014, T:0.0924(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0891 (C:1.9860, R:0.0014, T:0.0890(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0946 (C:1.9837, R:0.0014, T:0.0945(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0878 (C:1.9846, R:0.0014, T:0.0876(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0891 (C:1.9881, R:0.0014, T:0.0890(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0913 (C:1.9878, R:0.0014, T:0.0912(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0888 (C:1.9871, R:0.0014, T:0.0886(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0889 (C:1.9876, R:0.0014, T:0.0888(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0844 (C:1.9862, R:0.0014, T:0.0842(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0895 (C:1.9844, R:0.0014, T:0.0894(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0864 (C:1.9872, R:0.0014, T:0.0862(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0894 (C:1.9846, R:0.0014, T:0.0893(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0915

ğŸ“Š EPOCH 2 TRAINING SUMMARY:
  Total Loss: 0.0916
  Contrastive: 1.9857
  Reconstruction: 0.0014
  Topological: 0.0915 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.4571
  Contrastive: 1.9568
  Reconstruction: 0.0014
  Topological: 2.4569 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 2/300 COMPLETE (43.3s)
Train Loss: 0.0916 (C:1.9857, R:0.0014, T:0.0915)
Val Loss:   2.4571 (C:1.9568, R:0.0014, T:2.4569)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 3 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0841 (C:1.9862, R:0.0014, T:0.0840(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0844 (C:1.9893, R:0.0014, T:0.0843(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0825 (C:1.9853, R:0.0014, T:0.0823(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0835 (C:1.9900, R:0.0014, T:0.0833(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0833 (C:1.9881, R:0.0014, T:0.0832(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0810 (C:1.9861, R:0.0014, T:0.0809(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0899 (C:1.9854, R:0.0014, T:0.0897(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0889 (C:1.9880, R:0.0014, T:0.0887(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0850 (C:1.9835, R:0.0014, T:0.0848(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0803 (C:1.9872, R:0.0014, T:0.0802(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0813 (C:1.9851, R:0.0014, T:0.0812(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0838 (C:1.9846, R:0.0014, T:0.0837(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0854 (C:1.9867, R:0.0014, T:0.0853(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0815 (C:1.9848, R:0.0014, T:0.0813(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0776 (C:1.9882, R:0.0014, T:0.0774(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0783 (C:1.9859, R:0.0014, T:0.0782(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0814 (C:1.9818, R:0.0014, T:0.0813(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0855 (C:1.9864, R:0.0014, T:0.0854(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0785 (C:1.9832, R:0.0014, T:0.0784(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0747 (C:1.9866, R:0.0014, T:0.0746(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0871 (C:1.9861, R:0.0014, T:0.0870(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0816 (C:1.9870, R:0.0014, T:0.0815(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0817

ğŸ“Š EPOCH 3 TRAINING SUMMARY:
  Total Loss: 0.0818
  Contrastive: 1.9864
  Reconstruction: 0.0014
  Topological: 0.0817 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.2684
  Contrastive: 1.9535
  Reconstruction: 0.0014
  Topological: 2.2682 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 3/300 COMPLETE (43.2s)
Train Loss: 0.0818 (C:1.9864, R:0.0014, T:0.0817)
Val Loss:   2.2684 (C:1.9535, R:0.0014, T:2.2682)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 4 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0772 (C:1.9827, R:0.0014, T:0.0771(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0828 (C:1.9874, R:0.0014, T:0.0827(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0820 (C:1.9874, R:0.0014, T:0.0819(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0757 (C:1.9817, R:0.0014, T:0.0756(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0772 (C:1.9849, R:0.0014, T:0.0770(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0772 (C:1.9837, R:0.0014, T:0.0771(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0757 (C:1.9859, R:0.0014, T:0.0756(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0782 (C:1.9841, R:0.0014, T:0.0780(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0793 (C:1.9843, R:0.0014, T:0.0792(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0775 (C:1.9846, R:0.0014, T:0.0773(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0730 (C:1.9849, R:0.0014, T:0.0728(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0764 (C:1.9847, R:0.0014, T:0.0763(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0746 (C:1.9865, R:0.0014, T:0.0745(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0749 (C:1.9832, R:0.0014, T:0.0747(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0740 (C:1.9830, R:0.0014, T:0.0739(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0763 (C:1.9862, R:0.0014, T:0.0762(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0786 (C:1.9854, R:0.0014, T:0.0784(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0757 (C:1.9838, R:0.0014, T:0.0756(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0682 (C:1.9797, R:0.0014, T:0.0681(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0765 (C:1.9850, R:0.0014, T:0.0763(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0738 (C:1.9883, R:0.0014, T:0.0737(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0758 (C:1.9849, R:0.0014, T:0.0757(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0765

ğŸ“Š EPOCH 4 TRAINING SUMMARY:
  Total Loss: 0.0766
  Contrastive: 1.9852
  Reconstruction: 0.0014
  Topological: 0.0765 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 2.1145
  Contrastive: 1.9551
  Reconstruction: 0.0014
  Topological: 2.1143 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 4/300 COMPLETE (42.9s)
Train Loss: 0.0766 (C:1.9852, R:0.0014, T:0.0765)
Val Loss:   2.1145 (C:1.9551, R:0.0014, T:2.1143)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 5 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0776 (C:1.9850, R:0.0014, T:0.0775(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0773 (C:1.9862, R:0.0014, T:0.0772(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0763 (C:1.9859, R:0.0014, T:0.0762(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0733 (C:1.9866, R:0.0014, T:0.0731(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0722 (C:1.9894, R:0.0014, T:0.0721(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0730 (C:1.9845, R:0.0014, T:0.0729(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0737 (C:1.9862, R:0.0014, T:0.0736(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0701 (C:1.9878, R:0.0014, T:0.0699(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0723 (C:1.9844, R:0.0014, T:0.0722(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0712 (C:1.9824, R:0.0014, T:0.0710(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0694 (C:1.9847, R:0.0014, T:0.0692(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0777 (C:1.9820, R:0.0014, T:0.0775(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0731 (C:1.9821, R:0.0014, T:0.0729(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0741 (C:1.9825, R:0.0014, T:0.0740(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0727 (C:1.9796, R:0.0014, T:0.0726(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0673 (C:1.9790, R:0.0014, T:0.0672(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0708 (C:1.9817, R:0.0014, T:0.0707(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0730 (C:1.9844, R:0.0014, T:0.0729(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0717 (C:1.9816, R:0.0014, T:0.0715(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0708 (C:1.9836, R:0.0014, T:0.0707(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0679 (C:1.9819, R:0.0014, T:0.0678(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0700 (C:1.9837, R:0.0014, T:0.0698(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0728

ğŸ“Š EPOCH 5 TRAINING SUMMARY:
  Total Loss: 0.0729
  Contrastive: 1.9833
  Reconstruction: 0.0014
  Topological: 0.0728 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.9593
  Contrastive: 1.9551
  Reconstruction: 0.0014
  Topological: 1.9591 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 5/300 COMPLETE (44.9s)
Train Loss: 0.0729 (C:1.9833, R:0.0014, T:0.0728)
Val Loss:   1.9593 (C:1.9551, R:0.0014, T:1.9591)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 6 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0715 (C:1.9834, R:0.0014, T:0.0713(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0703 (C:1.9809, R:0.0014, T:0.0702(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0680 (C:1.9808, R:0.0014, T:0.0678(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0676 (C:1.9823, R:0.0014, T:0.0675(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0714 (C:1.9803, R:0.0014, T:0.0713(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0687 (C:1.9828, R:0.0014, T:0.0685(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0681 (C:1.9800, R:0.0014, T:0.0679(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0720 (C:1.9804, R:0.0014, T:0.0719(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0709 (C:1.9769, R:0.0014, T:0.0707(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0709 (C:1.9742, R:0.0014, T:0.0708(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0731 (C:1.9785, R:0.0014, T:0.0730(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0699 (C:1.9762, R:0.0014, T:0.0697(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0653 (C:1.9809, R:0.0014, T:0.0652(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0689 (C:1.9822, R:0.0014, T:0.0687(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0723 (C:1.9820, R:0.0014, T:0.0721(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0730 (C:1.9832, R:0.0014, T:0.0728(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0680 (C:1.9796, R:0.0014, T:0.0679(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0703 (C:1.9806, R:0.0014, T:0.0701(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0682 (C:1.9793, R:0.0014, T:0.0680(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0701 (C:1.9791, R:0.0014, T:0.0699(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0719 (C:1.9821, R:0.0014, T:0.0717(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0712 (C:1.9828, R:0.0014, T:0.0711(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0699

ğŸ“Š EPOCH 6 TRAINING SUMMARY:
  Total Loss: 0.0700
  Contrastive: 1.9806
  Reconstruction: 0.0014
  Topological: 0.0699 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.8690
  Contrastive: 1.9558
  Reconstruction: 0.0014
  Topological: 1.8688 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 6/300 COMPLETE (46.0s)
Train Loss: 0.0700 (C:1.9806, R:0.0014, T:0.0699)
Val Loss:   1.8690 (C:1.9558, R:0.0014, T:1.8688)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 7 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0671 (C:1.9793, R:0.0014, T:0.0670(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0673 (C:1.9825, R:0.0014, T:0.0672(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0682 (C:1.9811, R:0.0014, T:0.0680(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0701 (C:1.9823, R:0.0014, T:0.0700(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0700 (C:1.9841, R:0.0014, T:0.0699(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0663 (C:1.9801, R:0.0014, T:0.0661(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0674 (C:1.9771, R:0.0014, T:0.0673(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0671 (C:1.9778, R:0.0014, T:0.0670(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0681 (C:1.9798, R:0.0014, T:0.0679(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0677 (C:1.9779, R:0.0014, T:0.0676(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0660 (C:1.9753, R:0.0014, T:0.0659(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0665 (C:1.9847, R:0.0014, T:0.0664(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0624 (C:1.9841, R:0.0014, T:0.0623(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0695 (C:1.9752, R:0.0014, T:0.0694(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0668 (C:1.9805, R:0.0014, T:0.0666(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0667 (C:1.9778, R:0.0014, T:0.0665(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0713 (C:1.9821, R:0.0014, T:0.0711(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0667 (C:1.9742, R:0.0014, T:0.0665(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0651 (C:1.9800, R:0.0014, T:0.0650(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0696 (C:1.9796, R:0.0014, T:0.0695(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0664 (C:1.9805, R:0.0014, T:0.0662(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0728 (C:1.9778, R:0.0014, T:0.0727(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0674

ğŸ“Š EPOCH 7 TRAINING SUMMARY:
  Total Loss: 0.0676
  Contrastive: 1.9804
  Reconstruction: 0.0014
  Topological: 0.0674 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.8175
  Contrastive: 1.9501
  Reconstruction: 0.0014
  Topological: 1.8174 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 7/300 COMPLETE (47.2s)
Train Loss: 0.0676 (C:1.9804, R:0.0014, T:0.0674)
Val Loss:   1.8175 (C:1.9501, R:0.0014, T:1.8174)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 8 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0675 (C:1.9755, R:0.0014, T:0.0673(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0666 (C:1.9832, R:0.0014, T:0.0665(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0670 (C:1.9793, R:0.0014, T:0.0669(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0712 (C:1.9774, R:0.0014, T:0.0711(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0624 (C:1.9822, R:0.0014, T:0.0622(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0648 (C:1.9805, R:0.0014, T:0.0647(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0673 (C:1.9772, R:0.0014, T:0.0672(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0707 (C:1.9740, R:0.0014, T:0.0706(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0626 (C:1.9803, R:0.0014, T:0.0625(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0666 (C:1.9748, R:0.0014, T:0.0665(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0627 (C:1.9844, R:0.0014, T:0.0626(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0692 (C:1.9789, R:0.0014, T:0.0691(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0674 (C:1.9818, R:0.0014, T:0.0673(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0647 (C:1.9733, R:0.0014, T:0.0646(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0682 (C:1.9796, R:0.0014, T:0.0680(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0686 (C:1.9824, R:0.0014, T:0.0685(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0637 (C:1.9797, R:0.0014, T:0.0635(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0647 (C:1.9844, R:0.0014, T:0.0645(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0650 (C:1.9787, R:0.0014, T:0.0648(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0660 (C:1.9829, R:0.0014, T:0.0658(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0629 (C:1.9787, R:0.0014, T:0.0628(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0652 (C:1.9795, R:0.0014, T:0.0651(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0660

ğŸ“Š EPOCH 8 TRAINING SUMMARY:
  Total Loss: 0.0662
  Contrastive: 1.9796
  Reconstruction: 0.0014
  Topological: 0.0660 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.7471
  Contrastive: 1.9559
  Reconstruction: 0.0014
  Topological: 1.7470 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 8/300 COMPLETE (44.8s)
Train Loss: 0.0662 (C:1.9796, R:0.0014, T:0.0660)
Val Loss:   1.7471 (C:1.9559, R:0.0014, T:1.7470)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 9 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0650 (C:1.9838, R:0.0014, T:0.0648(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0668 (C:1.9790, R:0.0014, T:0.0667(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0647 (C:1.9837, R:0.0014, T:0.0645(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0663 (C:1.9794, R:0.0014, T:0.0662(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0651 (C:1.9778, R:0.0014, T:0.0649(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0735 (C:1.9774, R:0.0014, T:0.0733(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0653 (C:1.9775, R:0.0014, T:0.0652(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0594 (C:1.9758, R:0.0014, T:0.0592(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0649 (C:1.9809, R:0.0014, T:0.0647(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0652 (C:1.9817, R:0.0014, T:0.0650(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0632 (C:1.9830, R:0.0014, T:0.0630(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0626 (C:1.9770, R:0.0014, T:0.0625(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0631 (C:1.9775, R:0.0014, T:0.0630(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0668 (C:1.9707, R:0.0014, T:0.0667(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0657 (C:1.9796, R:0.0014, T:0.0656(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0656 (C:1.9806, R:0.0014, T:0.0654(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0698 (C:1.9796, R:0.0014, T:0.0697(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0659 (C:1.9851, R:0.0014, T:0.0657(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0655 (C:1.9776, R:0.0014, T:0.0654(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0630 (C:1.9796, R:0.0014, T:0.0629(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0624 (C:1.9838, R:0.0014, T:0.0623(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0661 (C:1.9830, R:0.0014, T:0.0660(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0646

ğŸ“Š EPOCH 9 TRAINING SUMMARY:
  Total Loss: 0.0647
  Contrastive: 1.9792
  Reconstruction: 0.0014
  Topological: 0.0646 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.7353
  Contrastive: 1.9499
  Reconstruction: 0.0014
  Topological: 1.7352 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 9/300 COMPLETE (41.9s)
Train Loss: 0.0647 (C:1.9792, R:0.0014, T:0.0646)
Val Loss:   1.7353 (C:1.9499, R:0.0014, T:1.7352)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 10 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0658 (C:1.9752, R:0.0014, T:0.0656(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0623 (C:1.9824, R:0.0014, T:0.0621(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0623 (C:1.9770, R:0.0014, T:0.0622(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0615 (C:1.9755, R:0.0014, T:0.0614(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0592 (C:1.9847, R:0.0014, T:0.0590(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0611 (C:1.9772, R:0.0014, T:0.0610(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0615 (C:1.9797, R:0.0014, T:0.0614(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0620 (C:1.9790, R:0.0014, T:0.0619(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0645 (C:1.9773, R:0.0014, T:0.0643(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0623 (C:1.9804, R:0.0014, T:0.0622(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0635 (C:1.9830, R:0.0014, T:0.0634(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0658 (C:1.9780, R:0.0014, T:0.0656(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0586 (C:1.9791, R:0.0014, T:0.0585(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0611 (C:1.9776, R:0.0014, T:0.0609(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0644 (C:1.9824, R:0.0014, T:0.0643(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0670 (C:1.9775, R:0.0014, T:0.0668(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0603 (C:1.9798, R:0.0014, T:0.0601(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0623 (C:1.9814, R:0.0014, T:0.0622(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0641 (C:1.9811, R:0.0014, T:0.0639(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0639 (C:1.9783, R:0.0014, T:0.0638(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0624 (C:1.9745, R:0.0014, T:0.0622(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0655 (C:1.9771, R:0.0014, T:0.0653(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0635

ğŸ“Š EPOCH 10 TRAINING SUMMARY:
  Total Loss: 0.0636
  Contrastive: 1.9788
  Reconstruction: 0.0014
  Topological: 0.0635 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.6567
  Contrastive: 1.9475
  Reconstruction: 0.0014
  Topological: 1.6566 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 10/300 COMPLETE (42.2s)
Train Loss: 0.0636 (C:1.9788, R:0.0014, T:0.0635)
Val Loss:   1.6567 (C:1.9475, R:0.0014, T:1.6566)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 11 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0652 (C:1.9770, R:0.0014, T:0.0651(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0665 (C:1.9770, R:0.0014, T:0.0664(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0624 (C:1.9792, R:0.0014, T:0.0623(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0622 (C:1.9702, R:0.0014, T:0.0621(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0631 (C:1.9761, R:0.0014, T:0.0630(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0613 (C:1.9780, R:0.0014, T:0.0612(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0672 (C:1.9783, R:0.0014, T:0.0670(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0630 (C:1.9800, R:0.0014, T:0.0629(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0574 (C:1.9748, R:0.0014, T:0.0573(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0628 (C:1.9787, R:0.0014, T:0.0627(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0621 (C:1.9747, R:0.0014, T:0.0619(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0623 (C:1.9781, R:0.0014, T:0.0622(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0555 (C:1.9774, R:0.0014, T:0.0553(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0598 (C:1.9821, R:0.0014, T:0.0597(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0640 (C:1.9749, R:0.0014, T:0.0638(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0620 (C:1.9808, R:0.0014, T:0.0619(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0644 (C:1.9774, R:0.0014, T:0.0642(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0582 (C:1.9800, R:0.0014, T:0.0581(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0608 (C:1.9772, R:0.0014, T:0.0607(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0648 (C:1.9766, R:0.0014, T:0.0647(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0601 (C:1.9760, R:0.0014, T:0.0600(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0648 (C:1.9751, R:0.0014, T:0.0647(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0627

ğŸ“Š EPOCH 11 TRAINING SUMMARY:
  Total Loss: 0.0628
  Contrastive: 1.9779
  Reconstruction: 0.0014
  Topological: 0.0627 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.6095
  Contrastive: 1.9534
  Reconstruction: 0.0014
  Topological: 1.6094 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 11/300 COMPLETE (42.4s)
Train Loss: 0.0628 (C:1.9779, R:0.0014, T:0.0627)
Val Loss:   1.6095 (C:1.9534, R:0.0014, T:1.6094)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 12 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0645 (C:1.9800, R:0.0014, T:0.0644(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0571 (C:1.9806, R:0.0014, T:0.0570(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0616 (C:1.9788, R:0.0014, T:0.0614(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0596 (C:1.9781, R:0.0014, T:0.0595(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0629 (C:1.9754, R:0.0014, T:0.0628(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0664 (C:1.9789, R:0.0014, T:0.0662(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0570 (C:1.9774, R:0.0014, T:0.0569(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0602 (C:1.9794, R:0.0014, T:0.0601(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0622 (C:1.9745, R:0.0014, T:0.0621(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0601 (C:1.9779, R:0.0014, T:0.0600(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0609 (C:1.9741, R:0.0014, T:0.0608(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0615 (C:1.9798, R:0.0014, T:0.0614(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0597 (C:1.9774, R:0.0014, T:0.0595(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0609 (C:1.9773, R:0.0014, T:0.0608(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0640 (C:1.9791, R:0.0014, T:0.0639(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0606 (C:1.9777, R:0.0014, T:0.0604(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0600 (C:1.9768, R:0.0014, T:0.0598(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0595 (C:1.9758, R:0.0014, T:0.0594(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0612 (C:1.9760, R:0.0014, T:0.0611(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0654 (C:1.9754, R:0.0014, T:0.0652(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0575 (C:1.9819, R:0.0014, T:0.0574(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0633 (C:1.9786, R:0.0014, T:0.0632(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0618

ğŸ“Š EPOCH 12 TRAINING SUMMARY:
  Total Loss: 0.0619
  Contrastive: 1.9772
  Reconstruction: 0.0014
  Topological: 0.0618 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.6197
  Contrastive: 1.9516
  Reconstruction: 0.0014
  Topological: 1.6196 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 12/300 COMPLETE (42.1s)
Train Loss: 0.0619 (C:1.9772, R:0.0014, T:0.0618)
Val Loss:   1.6197 (C:1.9516, R:0.0014, T:1.6196)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 13 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0667 (C:1.9763, R:0.0014, T:0.0665(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0628 (C:1.9750, R:0.0014, T:0.0627(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0591 (C:1.9784, R:0.0014, T:0.0590(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0605 (C:1.9765, R:0.0014, T:0.0604(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0606 (C:1.9773, R:0.0014, T:0.0605(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0586 (C:1.9785, R:0.0014, T:0.0585(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0613 (C:1.9780, R:0.0014, T:0.0612(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0647 (C:1.9753, R:0.0014, T:0.0645(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0619 (C:1.9743, R:0.0014, T:0.0618(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0612 (C:1.9774, R:0.0014, T:0.0611(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0623 (C:1.9704, R:0.0014, T:0.0621(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0671 (C:1.9743, R:0.0014, T:0.0670(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0588 (C:1.9733, R:0.0014, T:0.0586(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0627 (C:1.9764, R:0.0014, T:0.0626(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0611 (C:1.9754, R:0.0014, T:0.0610(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0635 (C:1.9724, R:0.0014, T:0.0634(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0607 (C:1.9790, R:0.0014, T:0.0606(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0616 (C:1.9773, R:0.0014, T:0.0614(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0584 (C:1.9779, R:0.0014, T:0.0583(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0627 (C:1.9784, R:0.0014, T:0.0626(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0638 (C:1.9813, R:0.0014, T:0.0637(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0607 (C:1.9721, R:0.0014, T:0.0606(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0611

ğŸ“Š EPOCH 13 TRAINING SUMMARY:
  Total Loss: 0.0612
  Contrastive: 1.9768
  Reconstruction: 0.0014
  Topological: 0.0611 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.5265
  Contrastive: 1.9562
  Reconstruction: 0.0014
  Topological: 1.5264 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 13/300 COMPLETE (41.7s)
Train Loss: 0.0612 (C:1.9768, R:0.0014, T:0.0611)
Val Loss:   1.5265 (C:1.9562, R:0.0014, T:1.5264)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 14 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0584 (C:1.9793, R:0.0014, T:0.0582(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0585 (C:1.9739, R:0.0014, T:0.0584(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0613 (C:1.9713, R:0.0014, T:0.0611(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0583 (C:1.9796, R:0.0014, T:0.0581(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0604 (C:1.9744, R:0.0014, T:0.0603(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0595 (C:1.9765, R:0.0014, T:0.0594(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0622 (C:1.9758, R:0.0014, T:0.0620(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0609 (C:1.9808, R:0.0014, T:0.0607(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0577 (C:1.9769, R:0.0014, T:0.0576(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0621 (C:1.9761, R:0.0014, T:0.0620(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0565 (C:1.9796, R:0.0014, T:0.0564(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0618 (C:1.9765, R:0.0014, T:0.0617(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0585 (C:1.9755, R:0.0014, T:0.0584(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0648 (C:1.9781, R:0.0014, T:0.0647(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0602 (C:1.9807, R:0.0014, T:0.0601(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0601 (C:1.9749, R:0.0014, T:0.0600(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0587 (C:1.9804, R:0.0014, T:0.0585(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0644 (C:1.9775, R:0.0014, T:0.0642(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0669 (C:1.9782, R:0.0014, T:0.0668(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0587 (C:1.9758, R:0.0014, T:0.0586(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0599 (C:1.9782, R:0.0014, T:0.0597(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0615 (C:1.9803, R:0.0014, T:0.0613(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0604

ğŸ“Š EPOCH 14 TRAINING SUMMARY:
  Total Loss: 0.0605
  Contrastive: 1.9766
  Reconstruction: 0.0014
  Topological: 0.0604 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.5242
  Contrastive: 1.9471
  Reconstruction: 0.0014
  Topological: 1.5240 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 14/300 COMPLETE (42.7s)
Train Loss: 0.0605 (C:1.9766, R:0.0014, T:0.0604)
Val Loss:   1.5242 (C:1.9471, R:0.0014, T:1.5240)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 15 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0610 (C:1.9795, R:0.0014, T:0.0609(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0547 (C:1.9753, R:0.0014, T:0.0546(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0591 (C:1.9793, R:0.0014, T:0.0590(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0633 (C:1.9720, R:0.0014, T:0.0631(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0613 (C:1.9802, R:0.0014, T:0.0612(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0588 (C:1.9745, R:0.0014, T:0.0586(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0611 (C:1.9780, R:0.0014, T:0.0609(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0595 (C:1.9781, R:0.0014, T:0.0593(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0587 (C:1.9766, R:0.0014, T:0.0585(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0591 (C:1.9797, R:0.0014, T:0.0590(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0589 (C:1.9734, R:0.0014, T:0.0587(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0588 (C:1.9730, R:0.0014, T:0.0587(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0570 (C:1.9801, R:0.0014, T:0.0568(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0584 (C:1.9789, R:0.0014, T:0.0582(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0593 (C:1.9790, R:0.0014, T:0.0592(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0613 (C:1.9779, R:0.0014, T:0.0612(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0579 (C:1.9782, R:0.0014, T:0.0578(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0645 (C:1.9763, R:0.0014, T:0.0643(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0599 (C:1.9784, R:0.0014, T:0.0598(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0610 (C:1.9813, R:0.0014, T:0.0609(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0631 (C:1.9758, R:0.0014, T:0.0629(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0621 (C:1.9726, R:0.0014, T:0.0620(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0596

ğŸ“Š EPOCH 15 TRAINING SUMMARY:
  Total Loss: 0.0598
  Contrastive: 1.9768
  Reconstruction: 0.0014
  Topological: 0.0596 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.5138
  Contrastive: 1.9528
  Reconstruction: 0.0014
  Topological: 1.5136 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 15/300 COMPLETE (43.2s)
Train Loss: 0.0598 (C:1.9768, R:0.0014, T:0.0596)
Val Loss:   1.5138 (C:1.9528, R:0.0014, T:1.5136)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 16 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0605 (C:1.9780, R:0.0014, T:0.0604(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0615 (C:1.9756, R:0.0014, T:0.0614(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0623 (C:1.9731, R:0.0014, T:0.0622(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0610 (C:1.9790, R:0.0014, T:0.0609(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0608 (C:1.9767, R:0.0014, T:0.0606(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0568 (C:1.9778, R:0.0014, T:0.0566(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0564 (C:1.9779, R:0.0014, T:0.0563(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0647 (C:1.9744, R:0.0014, T:0.0646(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0622 (C:1.9736, R:0.0014, T:0.0621(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0648 (C:1.9709, R:0.0014, T:0.0646(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0615 (C:1.9755, R:0.0014, T:0.0614(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0591 (C:1.9774, R:0.0014, T:0.0589(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0580 (C:1.9795, R:0.0014, T:0.0578(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0561 (C:1.9773, R:0.0014, T:0.0560(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0571 (C:1.9773, R:0.0014, T:0.0570(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0573 (C:1.9762, R:0.0014, T:0.0572(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0640 (C:1.9745, R:0.0014, T:0.0639(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0554 (C:1.9767, R:0.0014, T:0.0553(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0581 (C:1.9730, R:0.0014, T:0.0580(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0576 (C:1.9765, R:0.0014, T:0.0574(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0601 (C:1.9708, R:0.0014, T:0.0599(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0625 (C:1.9680, R:0.0014, T:0.0624(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0596

ğŸ“Š EPOCH 16 TRAINING SUMMARY:
  Total Loss: 0.0597
  Contrastive: 1.9763
  Reconstruction: 0.0014
  Topological: 0.0596 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.5079
  Contrastive: 1.9500
  Reconstruction: 0.0014
  Topological: 1.5078 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 16/300 COMPLETE (42.3s)
Train Loss: 0.0597 (C:1.9763, R:0.0014, T:0.0596)
Val Loss:   1.5079 (C:1.9500, R:0.0014, T:1.5078)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 17 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0589 (C:1.9781, R:0.0014, T:0.0587(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0609 (C:1.9766, R:0.0014, T:0.0607(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0580 (C:1.9763, R:0.0014, T:0.0578(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0612 (C:1.9738, R:0.0014, T:0.0611(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0567 (C:1.9766, R:0.0014, T:0.0566(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0620 (C:1.9712, R:0.0014, T:0.0618(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0617 (C:1.9800, R:0.0014, T:0.0615(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0538 (C:1.9798, R:0.0014, T:0.0536(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0571 (C:1.9770, R:0.0014, T:0.0569(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0560 (C:1.9711, R:0.0014, T:0.0559(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0588 (C:1.9740, R:0.0014, T:0.0586(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0607 (C:1.9791, R:0.0014, T:0.0605(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0576 (C:1.9744, R:0.0014, T:0.0574(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0586 (C:1.9747, R:0.0014, T:0.0584(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0628 (C:1.9762, R:0.0014, T:0.0627(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0734 (C:1.9744, R:0.0014, T:0.0732(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0598 (C:1.9724, R:0.0014, T:0.0597(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0589 (C:1.9717, R:0.0014, T:0.0587(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0583 (C:1.9723, R:0.0014, T:0.0582(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0578 (C:1.9754, R:0.0014, T:0.0577(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0578 (C:1.9786, R:0.0014, T:0.0576(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0635 (C:1.9737, R:0.0014, T:0.0633(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0588

ğŸ“Š EPOCH 17 TRAINING SUMMARY:
  Total Loss: 0.0590
  Contrastive: 1.9755
  Reconstruction: 0.0014
  Topological: 0.0588 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.4429
  Contrastive: 1.9467
  Reconstruction: 0.0014
  Topological: 1.4428 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 17/300 COMPLETE (42.0s)
Train Loss: 0.0590 (C:1.9755, R:0.0014, T:0.0588)
Val Loss:   1.4429 (C:1.9467, R:0.0014, T:1.4428)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 18 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0615 (C:1.9766, R:0.0014, T:0.0614(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0572 (C:1.9707, R:0.0014, T:0.0571(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0596 (C:1.9794, R:0.0014, T:0.0595(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0620 (C:1.9802, R:0.0014, T:0.0619(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0572 (C:1.9742, R:0.0014, T:0.0570(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0641 (C:1.9713, R:0.0014, T:0.0639(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0610 (C:1.9756, R:0.0014, T:0.0608(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0616 (C:1.9688, R:0.0014, T:0.0615(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0547 (C:1.9756, R:0.0014, T:0.0545(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0596 (C:1.9732, R:0.0014, T:0.0595(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0600 (C:1.9701, R:0.0014, T:0.0599(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0598 (C:1.9803, R:0.0014, T:0.0596(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0575 (C:1.9745, R:0.0014, T:0.0574(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0586 (C:1.9754, R:0.0014, T:0.0584(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0591 (C:1.9754, R:0.0014, T:0.0589(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0601 (C:1.9775, R:0.0014, T:0.0600(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0569 (C:1.9738, R:0.0014, T:0.0567(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0567 (C:1.9732, R:0.0014, T:0.0566(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0561 (C:1.9775, R:0.0014, T:0.0559(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0570 (C:1.9763, R:0.0014, T:0.0569(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0584 (C:1.9743, R:0.0014, T:0.0583(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0622 (C:1.9781, R:0.0014, T:0.0621(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0584

ğŸ“Š EPOCH 18 TRAINING SUMMARY:
  Total Loss: 0.0586
  Contrastive: 1.9754
  Reconstruction: 0.0014
  Topological: 0.0584 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.4379
  Contrastive: 1.9495
  Reconstruction: 0.0014
  Topological: 1.4378 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 18/300 COMPLETE (42.2s)
Train Loss: 0.0586 (C:1.9754, R:0.0014, T:0.0584)
Val Loss:   1.4379 (C:1.9495, R:0.0014, T:1.4378)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 19 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0566 (C:1.9765, R:0.0014, T:0.0565(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0579 (C:1.9729, R:0.0014, T:0.0578(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0559 (C:1.9771, R:0.0014, T:0.0558(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0603 (C:1.9806, R:0.0014, T:0.0602(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0558 (C:1.9757, R:0.0014, T:0.0556(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0561 (C:1.9754, R:0.0014, T:0.0559(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0592 (C:1.9783, R:0.0014, T:0.0591(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0588 (C:1.9783, R:0.0014, T:0.0586(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0624 (C:1.9713, R:0.0014, T:0.0622(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0607 (C:1.9729, R:0.0014, T:0.0606(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0590 (C:1.9787, R:0.0014, T:0.0589(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0571 (C:1.9720, R:0.0014, T:0.0569(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0616 (C:1.9768, R:0.0014, T:0.0615(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0565 (C:1.9754, R:0.0014, T:0.0563(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0574 (C:1.9712, R:0.0014, T:0.0573(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0573 (C:1.9760, R:0.0014, T:0.0572(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0567 (C:1.9782, R:0.0014, T:0.0565(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0607 (C:1.9817, R:0.0014, T:0.0605(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0645 (C:1.9747, R:0.0014, T:0.0644(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0622 (C:1.9718, R:0.0014, T:0.0620(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0618 (C:1.9770, R:0.0014, T:0.0617(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0582 (C:1.9789, R:0.0014, T:0.0580(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0580

ğŸ“Š EPOCH 19 TRAINING SUMMARY:
  Total Loss: 0.0581
  Contrastive: 1.9756
  Reconstruction: 0.0014
  Topological: 0.0580 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.4489
  Contrastive: 1.9496
  Reconstruction: 0.0014
  Topological: 1.4488 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 19/300 COMPLETE (42.5s)
Train Loss: 0.0581 (C:1.9756, R:0.0014, T:0.0580)
Val Loss:   1.4489 (C:1.9496, R:0.0014, T:1.4488)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 20 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0605 (C:1.9755, R:0.0014, T:0.0604(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0570 (C:1.9703, R:0.0014, T:0.0568(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0544 (C:1.9752, R:0.0014, T:0.0543(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0578 (C:1.9755, R:0.0014, T:0.0577(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0569 (C:1.9724, R:0.0014, T:0.0568(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0565 (C:1.9767, R:0.0014, T:0.0564(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0601 (C:1.9769, R:0.0014, T:0.0600(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0591 (C:1.9778, R:0.0014, T:0.0589(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0594 (C:1.9729, R:0.0014, T:0.0593(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0582 (C:1.9767, R:0.0014, T:0.0581(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0592 (C:1.9721, R:0.0014, T:0.0590(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0575 (C:1.9736, R:0.0014, T:0.0573(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0586 (C:1.9752, R:0.0014, T:0.0584(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0569 (C:1.9748, R:0.0014, T:0.0568(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0594 (C:1.9724, R:0.0014, T:0.0593(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0611 (C:1.9808, R:0.0014, T:0.0609(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0587 (C:1.9747, R:0.0014, T:0.0585(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0578 (C:1.9793, R:0.0014, T:0.0576(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0576 (C:1.9807, R:0.0014, T:0.0575(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0549 (C:1.9761, R:0.0014, T:0.0548(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0619 (C:1.9745, R:0.0014, T:0.0617(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0581 (C:1.9762, R:0.0014, T:0.0580(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0577

ğŸ“Š EPOCH 20 TRAINING SUMMARY:
  Total Loss: 0.0579
  Contrastive: 1.9751
  Reconstruction: 0.0014
  Topological: 0.0577 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.4026
  Contrastive: 1.9465
  Reconstruction: 0.0014
  Topological: 1.4025 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 20/300 COMPLETE (42.8s)
Train Loss: 0.0579 (C:1.9751, R:0.0014, T:0.0577)
Val Loss:   1.4026 (C:1.9465, R:0.0014, T:1.4025)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 21 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0616 (C:1.9768, R:0.0014, T:0.0615(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0606 (C:1.9759, R:0.0014, T:0.0604(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0559 (C:1.9724, R:0.0014, T:0.0558(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0607 (C:1.9780, R:0.0014, T:0.0606(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0578 (C:1.9751, R:0.0014, T:0.0577(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0592 (C:1.9752, R:0.0014, T:0.0591(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0551 (C:1.9747, R:0.0014, T:0.0549(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0605 (C:1.9769, R:0.0014, T:0.0604(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0585 (C:1.9746, R:0.0014, T:0.0584(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0552 (C:1.9761, R:0.0014, T:0.0550(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0612 (C:1.9768, R:0.0014, T:0.0610(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0562 (C:1.9742, R:0.0014, T:0.0561(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0571 (C:1.9750, R:0.0014, T:0.0570(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0590 (C:1.9730, R:0.0014, T:0.0589(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0571 (C:1.9725, R:0.0014, T:0.0569(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0605 (C:1.9745, R:0.0014, T:0.0604(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0557 (C:1.9728, R:0.0014, T:0.0555(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0542 (C:1.9732, R:0.0014, T:0.0540(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0570 (C:1.9776, R:0.0014, T:0.0569(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0533 (C:1.9745, R:0.0014, T:0.0532(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0567 (C:1.9676, R:0.0014, T:0.0565(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0603 (C:1.9775, R:0.0014, T:0.0602(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0577

ğŸ“Š EPOCH 21 TRAINING SUMMARY:
  Total Loss: 0.0579
  Contrastive: 1.9753
  Reconstruction: 0.0014
  Topological: 0.0577 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.4210
  Contrastive: 1.9540
  Reconstruction: 0.0014
  Topological: 1.4209 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 21/300 COMPLETE (41.8s)
Train Loss: 0.0579 (C:1.9753, R:0.0014, T:0.0577)
Val Loss:   1.4210 (C:1.9540, R:0.0014, T:1.4209)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 22 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0575 (C:1.9769, R:0.0014, T:0.0574(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0550 (C:1.9725, R:0.0014, T:0.0548(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0607 (C:1.9749, R:0.0014, T:0.0606(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0570 (C:1.9728, R:0.0014, T:0.0569(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0590 (C:1.9795, R:0.0014, T:0.0589(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0525 (C:1.9793, R:0.0014, T:0.0524(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0584 (C:1.9772, R:0.0014, T:0.0582(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0564 (C:1.9811, R:0.0014, T:0.0563(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0578 (C:1.9766, R:0.0014, T:0.0577(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0614 (C:1.9725, R:0.0014, T:0.0613(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0578 (C:1.9740, R:0.0014, T:0.0576(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0601 (C:1.9774, R:0.0014, T:0.0600(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0554 (C:1.9763, R:0.0014, T:0.0552(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0574 (C:1.9782, R:0.0014, T:0.0573(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0581 (C:1.9718, R:0.0014, T:0.0580(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0570 (C:1.9725, R:0.0014, T:0.0569(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0583 (C:1.9766, R:0.0014, T:0.0582(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0562 (C:1.9775, R:0.0014, T:0.0561(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0558 (C:1.9783, R:0.0014, T:0.0557(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0570 (C:1.9730, R:0.0014, T:0.0568(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0613 (C:1.9716, R:0.0014, T:0.0612(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0589 (C:1.9712, R:0.0014, T:0.0587(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0575

ğŸ“Š EPOCH 22 TRAINING SUMMARY:
  Total Loss: 0.0577
  Contrastive: 1.9756
  Reconstruction: 0.0014
  Topological: 0.0575 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.3842
  Contrastive: 1.9495
  Reconstruction: 0.0014
  Topological: 1.3840 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 22/300 COMPLETE (42.5s)
Train Loss: 0.0577 (C:1.9756, R:0.0014, T:0.0575)
Val Loss:   1.3842 (C:1.9495, R:0.0014, T:1.3840)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 23 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0571 (C:1.9738, R:0.0014, T:0.0569(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0570 (C:1.9759, R:0.0014, T:0.0569(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0528 (C:1.9776, R:0.0014, T:0.0526(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0525 (C:1.9774, R:0.0014, T:0.0524(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0594 (C:1.9708, R:0.0014, T:0.0593(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0564 (C:1.9799, R:0.0014, T:0.0563(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0606 (C:1.9766, R:0.0014, T:0.0604(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0564 (C:1.9773, R:0.0014, T:0.0563(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0566 (C:1.9773, R:0.0014, T:0.0564(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0564 (C:1.9787, R:0.0014, T:0.0563(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0585 (C:1.9771, R:0.0014, T:0.0583(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0550 (C:1.9829, R:0.0014, T:0.0549(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0576 (C:1.9750, R:0.0014, T:0.0574(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0568 (C:1.9742, R:0.0014, T:0.0566(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0590 (C:1.9747, R:0.0014, T:0.0588(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0569 (C:1.9805, R:0.0014, T:0.0568(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0581 (C:1.9763, R:0.0014, T:0.0580(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0578 (C:1.9756, R:0.0014, T:0.0577(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0584 (C:1.9744, R:0.0014, T:0.0582(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0569 (C:1.9734, R:0.0014, T:0.0568(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0549 (C:1.9747, R:0.0014, T:0.0548(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0594 (C:1.9763, R:0.0014, T:0.0592(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0571

ğŸ“Š EPOCH 23 TRAINING SUMMARY:
  Total Loss: 0.0572
  Contrastive: 1.9756
  Reconstruction: 0.0014
  Topological: 0.0571 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.3868
  Contrastive: 1.9462
  Reconstruction: 0.0014
  Topological: 1.3867 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 23/300 COMPLETE (42.0s)
Train Loss: 0.0572 (C:1.9756, R:0.0014, T:0.0571)
Val Loss:   1.3868 (C:1.9462, R:0.0014, T:1.3867)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 24 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0541 (C:1.9746, R:0.0014, T:0.0539(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0556 (C:1.9783, R:0.0014, T:0.0555(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0528 (C:1.9694, R:0.0014, T:0.0526(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0566 (C:1.9802, R:0.0014, T:0.0564(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0568 (C:1.9761, R:0.0014, T:0.0567(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0567 (C:1.9777, R:0.0014, T:0.0566(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0573 (C:1.9743, R:0.0014, T:0.0571(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0579 (C:1.9793, R:0.0014, T:0.0578(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0550 (C:1.9710, R:0.0014, T:0.0549(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0582 (C:1.9778, R:0.0014, T:0.0581(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0589 (C:1.9759, R:0.0014, T:0.0588(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0581 (C:1.9758, R:0.0014, T:0.0579(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0553 (C:1.9773, R:0.0014, T:0.0552(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0567 (C:1.9706, R:0.0014, T:0.0565(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0570 (C:1.9775, R:0.0014, T:0.0568(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0592 (C:1.9738, R:0.0014, T:0.0590(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0594 (C:1.9746, R:0.0014, T:0.0592(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0574 (C:1.9728, R:0.0014, T:0.0573(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0562 (C:1.9768, R:0.0014, T:0.0561(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0554 (C:1.9678, R:0.0014, T:0.0552(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0586 (C:1.9794, R:0.0014, T:0.0585(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0577 (C:1.9723, R:0.0014, T:0.0576(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0567

ğŸ“Š EPOCH 24 TRAINING SUMMARY:
  Total Loss: 0.0569
  Contrastive: 1.9753
  Reconstruction: 0.0014
  Topological: 0.0567 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.3453
  Contrastive: 1.9465
  Reconstruction: 0.0014
  Topological: 1.3451 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 24/300 COMPLETE (42.4s)
Train Loss: 0.0569 (C:1.9753, R:0.0014, T:0.0567)
Val Loss:   1.3453 (C:1.9465, R:0.0014, T:1.3451)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 25 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0567 (C:1.9783, R:0.0014, T:0.0565(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0577 (C:1.9728, R:0.0014, T:0.0576(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0566 (C:1.9741, R:0.0014, T:0.0565(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0594 (C:1.9791, R:0.0014, T:0.0593(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0527 (C:1.9785, R:0.0014, T:0.0526(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0565 (C:1.9786, R:0.0014, T:0.0564(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0561 (C:1.9748, R:0.0014, T:0.0560(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0561 (C:1.9742, R:0.0014, T:0.0559(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0567 (C:1.9752, R:0.0014, T:0.0566(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0560 (C:1.9788, R:0.0014, T:0.0559(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0572 (C:1.9768, R:0.0014, T:0.0570(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0554 (C:1.9725, R:0.0014, T:0.0553(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0597 (C:1.9678, R:0.0014, T:0.0596(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0572 (C:1.9773, R:0.0014, T:0.0571(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0567 (C:1.9734, R:0.0014, T:0.0565(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0549 (C:1.9735, R:0.0014, T:0.0547(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0602 (C:1.9778, R:0.0014, T:0.0600(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0595 (C:1.9774, R:0.0014, T:0.0594(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0552 (C:1.9801, R:0.0014, T:0.0550(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0609 (C:1.9738, R:0.0014, T:0.0608(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0565 (C:1.9739, R:0.0014, T:0.0563(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0528 (C:1.9805, R:0.0014, T:0.0527(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 25 TRAINING SUMMARY:
  Total Loss: 0.0570
  Contrastive: 1.9756
  Reconstruction: 0.0014
  Topological: 0.0568 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.3444
  Contrastive: 1.9519
  Reconstruction: 0.0014
  Topological: 1.3443 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 25/300 COMPLETE (41.9s)
Train Loss: 0.0570 (C:1.9756, R:0.0014, T:0.0568)
Val Loss:   1.3444 (C:1.9519, R:0.0014, T:1.3443)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 26 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0538 (C:1.9777, R:0.0014, T:0.0537(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0571 (C:1.9660, R:0.0014, T:0.0570(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0521 (C:1.9720, R:0.0014, T:0.0520(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0562 (C:1.9750, R:0.0014, T:0.0561(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0605 (C:1.9753, R:0.0014, T:0.0603(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0569 (C:1.9766, R:0.0014, T:0.0567(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0577 (C:1.9764, R:0.0014, T:0.0576(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0576 (C:1.9773, R:0.0014, T:0.0574(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0561 (C:1.9746, R:0.0014, T:0.0560(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0539 (C:1.9753, R:0.0014, T:0.0538(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0549 (C:1.9772, R:0.0014, T:0.0548(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0601 (C:1.9770, R:0.0014, T:0.0599(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0568 (C:1.9742, R:0.0014, T:0.0567(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0605 (C:1.9777, R:0.0014, T:0.0604(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0578 (C:1.9721, R:0.0014, T:0.0577(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0589 (C:1.9735, R:0.0014, T:0.0588(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0590 (C:1.9754, R:0.0014, T:0.0589(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0541 (C:1.9780, R:0.0014, T:0.0540(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0545 (C:1.9760, R:0.0014, T:0.0544(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0564 (C:1.9750, R:0.0014, T:0.0563(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0578 (C:1.9783, R:0.0014, T:0.0577(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0556 (C:1.9768, R:0.0014, T:0.0554(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0565

ğŸ“Š EPOCH 26 TRAINING SUMMARY:
  Total Loss: 0.0566
  Contrastive: 1.9755
  Reconstruction: 0.0014
  Topological: 0.0565 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.3523
  Contrastive: 1.9514
  Reconstruction: 0.0014
  Topological: 1.3521 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 26/300 COMPLETE (41.6s)
Train Loss: 0.0566 (C:1.9755, R:0.0014, T:0.0565)
Val Loss:   1.3523 (C:1.9514, R:0.0014, T:1.3521)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 27 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0564 (C:1.9779, R:0.0014, T:0.0563(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0532 (C:1.9712, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0582 (C:1.9756, R:0.0014, T:0.0581(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0543 (C:1.9777, R:0.0014, T:0.0542(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0569 (C:1.9811, R:0.0014, T:0.0567(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0585 (C:1.9774, R:0.0014, T:0.0584(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0562 (C:1.9761, R:0.0014, T:0.0561(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0565 (C:1.9731, R:0.0014, T:0.0563(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0577 (C:1.9803, R:0.0014, T:0.0576(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0572 (C:1.9701, R:0.0014, T:0.0571(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0571 (C:1.9746, R:0.0014, T:0.0570(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0560 (C:1.9768, R:0.0014, T:0.0559(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0555 (C:1.9769, R:0.0014, T:0.0554(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0561 (C:1.9776, R:0.0014, T:0.0560(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0598 (C:1.9770, R:0.0014, T:0.0597(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0564 (C:1.9715, R:0.0014, T:0.0563(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0548 (C:1.9746, R:0.0014, T:0.0547(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0565 (C:1.9726, R:0.0014, T:0.0564(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0571 (C:1.9782, R:0.0014, T:0.0569(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0573 (C:1.9754, R:0.0014, T:0.0571(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0561 (C:1.9748, R:0.0014, T:0.0560(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0548 (C:1.9789, R:0.0014, T:0.0547(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 27 TRAINING SUMMARY:
  Total Loss: 0.0566
  Contrastive: 1.9752
  Reconstruction: 0.0014
  Topological: 0.0565 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.3661
  Contrastive: 1.9513
  Reconstruction: 0.0014
  Topological: 1.3659 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 27/300 COMPLETE (42.3s)
Train Loss: 0.0566 (C:1.9752, R:0.0014, T:0.0565)
Val Loss:   1.3661 (C:1.9513, R:0.0014, T:1.3659)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 28 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0534 (C:1.9785, R:0.0014, T:0.0533(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0540 (C:1.9726, R:0.0014, T:0.0539(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0569 (C:1.9731, R:0.0014, T:0.0567(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0598 (C:1.9745, R:0.0014, T:0.0597(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0580 (C:1.9724, R:0.0014, T:0.0578(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0616 (C:1.9769, R:0.0014, T:0.0614(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0572 (C:1.9829, R:0.0014, T:0.0571(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0559 (C:1.9777, R:0.0014, T:0.0557(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0575 (C:1.9741, R:0.0014, T:0.0574(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0573 (C:1.9776, R:0.0014, T:0.0572(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0587 (C:1.9712, R:0.0014, T:0.0586(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0571 (C:1.9770, R:0.0014, T:0.0569(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0576 (C:1.9772, R:0.0014, T:0.0575(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0581 (C:1.9751, R:0.0014, T:0.0580(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0590 (C:1.9774, R:0.0014, T:0.0588(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0582 (C:1.9760, R:0.0014, T:0.0581(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0525 (C:1.9756, R:0.0014, T:0.0523(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0557 (C:1.9789, R:0.0014, T:0.0555(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0567 (C:1.9743, R:0.0014, T:0.0565(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0546 (C:1.9741, R:0.0014, T:0.0544(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0562 (C:1.9749, R:0.0014, T:0.0561(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0560 (C:1.9707, R:0.0014, T:0.0558(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0562

ğŸ“Š EPOCH 28 TRAINING SUMMARY:
  Total Loss: 0.0564
  Contrastive: 1.9753
  Reconstruction: 0.0014
  Topological: 0.0562 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.3041
  Contrastive: 1.9482
  Reconstruction: 0.0014
  Topological: 1.3040 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 28/300 COMPLETE (42.7s)
Train Loss: 0.0564 (C:1.9753, R:0.0014, T:0.0562)
Val Loss:   1.3041 (C:1.9482, R:0.0014, T:1.3040)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 29 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0538 (C:1.9741, R:0.0014, T:0.0536(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0570 (C:1.9726, R:0.0014, T:0.0569(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0562 (C:1.9731, R:0.0014, T:0.0561(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0675 (C:1.9745, R:0.0014, T:0.0674(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0606 (C:1.9788, R:0.0014, T:0.0605(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0561 (C:1.9729, R:0.0014, T:0.0560(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0573 (C:1.9753, R:0.0014, T:0.0572(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0553 (C:1.9785, R:0.0014, T:0.0551(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0545 (C:1.9707, R:0.0014, T:0.0544(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0570 (C:1.9777, R:0.0014, T:0.0568(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0551 (C:1.9777, R:0.0014, T:0.0549(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0585 (C:1.9767, R:0.0014, T:0.0583(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0540 (C:1.9752, R:0.0014, T:0.0539(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0596 (C:1.9757, R:0.0014, T:0.0594(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0619 (C:1.9747, R:0.0014, T:0.0618(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0526 (C:1.9766, R:0.0014, T:0.0525(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0562 (C:1.9737, R:0.0014, T:0.0561(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0542 (C:1.9777, R:0.0014, T:0.0540(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0586 (C:1.9734, R:0.0014, T:0.0585(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0545 (C:1.9746, R:0.0014, T:0.0543(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0570 (C:1.9697, R:0.0014, T:0.0569(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0577 (C:1.9812, R:0.0014, T:0.0575(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 29 TRAINING SUMMARY:
  Total Loss: 0.0564
  Contrastive: 1.9755
  Reconstruction: 0.0014
  Topological: 0.0563 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.3229
  Contrastive: 1.9504
  Reconstruction: 0.0014
  Topological: 1.3228 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 29/300 COMPLETE (44.1s)
Train Loss: 0.0564 (C:1.9755, R:0.0014, T:0.0563)
Val Loss:   1.3229 (C:1.9504, R:0.0014, T:1.3228)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 30 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0560 (C:1.9699, R:0.0014, T:0.0558(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0566 (C:1.9734, R:0.0014, T:0.0564(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0517 (C:1.9787, R:0.0014, T:0.0516(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0563 (C:1.9748, R:0.0014, T:0.0562(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0576 (C:1.9747, R:0.0014, T:0.0574(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0569 (C:1.9770, R:0.0014, T:0.0568(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0530 (C:1.9770, R:0.0014, T:0.0528(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0568 (C:1.9794, R:0.0014, T:0.0567(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0562 (C:1.9715, R:0.0014, T:0.0560(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0563 (C:1.9751, R:0.0014, T:0.0561(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0544 (C:1.9774, R:0.0014, T:0.0542(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0534 (C:1.9780, R:0.0014, T:0.0533(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0575 (C:1.9763, R:0.0014, T:0.0574(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0582 (C:1.9774, R:0.0014, T:0.0580(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0564 (C:1.9740, R:0.0014, T:0.0563(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0598 (C:1.9749, R:0.0014, T:0.0597(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0586 (C:1.9766, R:0.0014, T:0.0584(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0577 (C:1.9752, R:0.0014, T:0.0576(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0550 (C:1.9740, R:0.0014, T:0.0548(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0573 (C:1.9761, R:0.0014, T:0.0572(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0564 (C:1.9733, R:0.0014, T:0.0563(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0531 (C:1.9776, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0558

ğŸ“Š EPOCH 30 TRAINING SUMMARY:
  Total Loss: 0.0559
  Contrastive: 1.9753
  Reconstruction: 0.0014
  Topological: 0.0558 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.3122
  Contrastive: 1.9442
  Reconstruction: 0.0014
  Topological: 1.3121 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 30/300 COMPLETE (45.2s)
Train Loss: 0.0559 (C:1.9753, R:0.0014, T:0.0558)
Val Loss:   1.3122 (C:1.9442, R:0.0014, T:1.3121)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 31 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0533 (C:1.9669, R:0.0014, T:0.0531(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0554 (C:1.9783, R:0.0014, T:0.0553(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0542 (C:1.9775, R:0.0014, T:0.0541(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0576 (C:1.9795, R:0.0014, T:0.0575(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0536 (C:1.9779, R:0.0014, T:0.0534(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0571 (C:1.9694, R:0.0014, T:0.0569(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0559 (C:1.9787, R:0.0014, T:0.0558(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0590 (C:1.9784, R:0.0014, T:0.0589(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0556 (C:1.9784, R:0.0014, T:0.0555(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0547 (C:1.9752, R:0.0014, T:0.0545(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0522 (C:1.9784, R:0.0014, T:0.0521(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0570 (C:1.9703, R:0.0014, T:0.0569(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0531 (C:1.9768, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0562 (C:1.9767, R:0.0014, T:0.0561(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0562 (C:1.9773, R:0.0014, T:0.0561(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0567 (C:1.9759, R:0.0014, T:0.0566(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0565 (C:1.9774, R:0.0014, T:0.0564(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0592 (C:1.9806, R:0.0014, T:0.0590(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0542 (C:1.9779, R:0.0014, T:0.0541(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0554 (C:1.9722, R:0.0014, T:0.0553(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0530 (C:1.9772, R:0.0014, T:0.0528(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0583 (C:1.9703, R:0.0014, T:0.0581(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0554

ğŸ“Š EPOCH 31 TRAINING SUMMARY:
  Total Loss: 0.0556
  Contrastive: 1.9756
  Reconstruction: 0.0014
  Topological: 0.0554 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.2916
  Contrastive: 1.9556
  Reconstruction: 0.0014
  Topological: 1.2915 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 31/300 COMPLETE (45.7s)
Train Loss: 0.0556 (C:1.9756, R:0.0014, T:0.0554)
Val Loss:   1.2916 (C:1.9556, R:0.0014, T:1.2915)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 32 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0554 (C:1.9777, R:0.0014, T:0.0553(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0588 (C:1.9707, R:0.0014, T:0.0587(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0542 (C:1.9686, R:0.0014, T:0.0540(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0576 (C:1.9740, R:0.0014, T:0.0575(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0546 (C:1.9748, R:0.0014, T:0.0544(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0552 (C:1.9753, R:0.0014, T:0.0551(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0578 (C:1.9720, R:0.0014, T:0.0576(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0558 (C:1.9727, R:0.0014, T:0.0556(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0583 (C:1.9760, R:0.0014, T:0.0582(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0565 (C:1.9779, R:0.0014, T:0.0564(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0524 (C:1.9676, R:0.0014, T:0.0522(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0593 (C:1.9721, R:0.0014, T:0.0592(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0534 (C:1.9742, R:0.0014, T:0.0533(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0560 (C:1.9730, R:0.0014, T:0.0558(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0551 (C:1.9796, R:0.0014, T:0.0550(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0560 (C:1.9704, R:0.0014, T:0.0558(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0563 (C:1.9791, R:0.0014, T:0.0562(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0554 (C:1.9752, R:0.0014, T:0.0552(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0564 (C:1.9751, R:0.0014, T:0.0563(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0586 (C:1.9759, R:0.0014, T:0.0584(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0551 (C:1.9751, R:0.0014, T:0.0549(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0555 (C:1.9803, R:0.0014, T:0.0554(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0554

ğŸ“Š EPOCH 32 TRAINING SUMMARY:
  Total Loss: 0.0555
  Contrastive: 1.9751
  Reconstruction: 0.0014
  Topological: 0.0554 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.2988
  Contrastive: 1.9519
  Reconstruction: 0.0014
  Topological: 1.2987 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 32/300 COMPLETE (44.7s)
Train Loss: 0.0555 (C:1.9751, R:0.0014, T:0.0554)
Val Loss:   1.2988 (C:1.9519, R:0.0014, T:1.2987)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 33 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0569 (C:1.9746, R:0.0014, T:0.0568(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0567 (C:1.9775, R:0.0014, T:0.0565(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0546 (C:1.9717, R:0.0014, T:0.0544(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0516 (C:1.9784, R:0.0014, T:0.0515(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0564 (C:1.9779, R:0.0014, T:0.0563(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0560 (C:1.9751, R:0.0014, T:0.0559(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0587 (C:1.9730, R:0.0014, T:0.0586(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0566 (C:1.9763, R:0.0014, T:0.0564(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0559 (C:1.9786, R:0.0014, T:0.0557(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0564 (C:1.9755, R:0.0014, T:0.0563(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0555 (C:1.9766, R:0.0014, T:0.0553(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0564 (C:1.9742, R:0.0014, T:0.0563(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0578 (C:1.9738, R:0.0014, T:0.0577(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0559 (C:1.9784, R:0.0014, T:0.0558(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0537 (C:1.9748, R:0.0014, T:0.0536(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0544 (C:1.9781, R:0.0014, T:0.0542(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0597 (C:1.9743, R:0.0014, T:0.0595(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0543 (C:1.9751, R:0.0014, T:0.0541(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0562 (C:1.9765, R:0.0014, T:0.0561(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0586 (C:1.9781, R:0.0014, T:0.0585(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0518 (C:1.9799, R:0.0014, T:0.0517(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0572 (C:1.9720, R:0.0014, T:0.0571(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 33 TRAINING SUMMARY:
  Total Loss: 0.0557
  Contrastive: 1.9754
  Reconstruction: 0.0014
  Topological: 0.0555 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.2807
  Contrastive: 1.9555
  Reconstruction: 0.0014
  Topological: 1.2805 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 33/300 COMPLETE (44.0s)
Train Loss: 0.0557 (C:1.9754, R:0.0014, T:0.0555)
Val Loss:   1.2807 (C:1.9555, R:0.0014, T:1.2805)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 34 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0518 (C:1.9782, R:0.0014, T:0.0517(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0535 (C:1.9735, R:0.0014, T:0.0534(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0582 (C:1.9737, R:0.0014, T:0.0581(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0585 (C:1.9767, R:0.0014, T:0.0583(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0579 (C:1.9782, R:0.0014, T:0.0578(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0551 (C:1.9762, R:0.0014, T:0.0550(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0548 (C:1.9761, R:0.0014, T:0.0547(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0571 (C:1.9724, R:0.0014, T:0.0569(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0565 (C:1.9759, R:0.0014, T:0.0564(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0548 (C:1.9767, R:0.0014, T:0.0547(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0523 (C:1.9775, R:0.0014, T:0.0521(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0585 (C:1.9745, R:0.0014, T:0.0583(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0603 (C:1.9738, R:0.0014, T:0.0602(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0547 (C:1.9797, R:0.0014, T:0.0546(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0566 (C:1.9761, R:0.0014, T:0.0565(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0532 (C:1.9756, R:0.0014, T:0.0531(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0557 (C:1.9783, R:0.0014, T:0.0555(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0569 (C:1.9770, R:0.0014, T:0.0568(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0570 (C:1.9723, R:0.0014, T:0.0569(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0549 (C:1.9804, R:0.0014, T:0.0548(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0499 (C:1.9742, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0539 (C:1.9802, R:0.0014, T:0.0537(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 34 TRAINING SUMMARY:
  Total Loss: 0.0557
  Contrastive: 1.9754
  Reconstruction: 0.0014
  Topological: 0.0556 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.2294
  Contrastive: 1.9499
  Reconstruction: 0.0014
  Topological: 1.2292 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 34/300 COMPLETE (46.5s)
Train Loss: 0.0557 (C:1.9754, R:0.0014, T:0.0556)
Val Loss:   1.2294 (C:1.9499, R:0.0014, T:1.2292)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 35 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0538 (C:1.9737, R:0.0014, T:0.0537(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0590 (C:1.9763, R:0.0014, T:0.0588(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0551 (C:1.9804, R:0.0014, T:0.0550(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0526 (C:1.9761, R:0.0014, T:0.0524(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0583 (C:1.9733, R:0.0014, T:0.0581(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0550 (C:1.9753, R:0.0014, T:0.0548(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0600 (C:1.9753, R:0.0014, T:0.0599(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0545 (C:1.9743, R:0.0014, T:0.0543(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0589 (C:1.9742, R:0.0014, T:0.0588(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0558 (C:1.9718, R:0.0014, T:0.0557(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0569 (C:1.9744, R:0.0014, T:0.0567(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0510 (C:1.9811, R:0.0014, T:0.0509(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0559 (C:1.9783, R:0.0014, T:0.0558(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0536 (C:1.9769, R:0.0014, T:0.0535(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0514 (C:1.9776, R:0.0014, T:0.0512(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0557 (C:1.9769, R:0.0014, T:0.0555(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0527 (C:1.9775, R:0.0014, T:0.0526(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0549 (C:1.9781, R:0.0014, T:0.0548(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0585 (C:1.9731, R:0.0014, T:0.0584(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0571 (C:1.9768, R:0.0014, T:0.0570(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0568 (C:1.9769, R:0.0014, T:0.0567(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0546 (C:1.9744, R:0.0014, T:0.0544(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0550

ğŸ“Š EPOCH 35 TRAINING SUMMARY:
  Total Loss: 0.0552
  Contrastive: 1.9756
  Reconstruction: 0.0014
  Topological: 0.0550 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.2320
  Contrastive: 1.9512
  Reconstruction: 0.0014
  Topological: 1.2319 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 35/300 COMPLETE (44.6s)
Train Loss: 0.0552 (C:1.9756, R:0.0014, T:0.0550)
Val Loss:   1.2320 (C:1.9512, R:0.0014, T:1.2319)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 36 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0555 (C:1.9762, R:0.0014, T:0.0554(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0554 (C:1.9760, R:0.0014, T:0.0553(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0568 (C:1.9700, R:0.0014, T:0.0566(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0518 (C:1.9766, R:0.0014, T:0.0516(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0580 (C:1.9786, R:0.0014, T:0.0579(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0523 (C:1.9751, R:0.0014, T:0.0522(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0525 (C:1.9802, R:0.0014, T:0.0524(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0540 (C:1.9784, R:0.0014, T:0.0539(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0599 (C:1.9703, R:0.0014, T:0.0598(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0541 (C:1.9743, R:0.0014, T:0.0540(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0574 (C:1.9773, R:0.0014, T:0.0572(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0535 (C:1.9719, R:0.0014, T:0.0534(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0549 (C:1.9760, R:0.0014, T:0.0548(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0545 (C:1.9715, R:0.0014, T:0.0543(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0560 (C:1.9734, R:0.0014, T:0.0558(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0545 (C:1.9751, R:0.0014, T:0.0543(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0555 (C:1.9758, R:0.0014, T:0.0554(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0569 (C:1.9706, R:0.0014, T:0.0567(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0536 (C:1.9746, R:0.0014, T:0.0534(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0536 (C:1.9713, R:0.0014, T:0.0535(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0573 (C:1.9724, R:0.0014, T:0.0571(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0552 (C:1.9752, R:0.0014, T:0.0550(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0549

ğŸ“Š EPOCH 36 TRAINING SUMMARY:
  Total Loss: 0.0550
  Contrastive: 1.9752
  Reconstruction: 0.0014
  Topological: 0.0549 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.2629
  Contrastive: 1.9546
  Reconstruction: 0.0014
  Topological: 1.2628 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 36/300 COMPLETE (43.5s)
Train Loss: 0.0550 (C:1.9752, R:0.0014, T:0.0549)
Val Loss:   1.2629 (C:1.9546, R:0.0014, T:1.2628)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 37 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0568 (C:1.9778, R:0.0014, T:0.0566(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0542 (C:1.9746, R:0.0014, T:0.0540(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0539 (C:1.9685, R:0.0014, T:0.0538(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0586 (C:1.9759, R:0.0014, T:0.0585(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0549 (C:1.9750, R:0.0014, T:0.0548(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0549 (C:1.9750, R:0.0014, T:0.0548(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0536 (C:1.9709, R:0.0014, T:0.0535(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0531 (C:1.9740, R:0.0014, T:0.0529(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0537 (C:1.9730, R:0.0014, T:0.0535(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0547 (C:1.9724, R:0.0014, T:0.0546(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0587 (C:1.9762, R:0.0014, T:0.0586(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0514 (C:1.9771, R:0.0014, T:0.0513(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0582 (C:1.9734, R:0.0014, T:0.0581(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0569 (C:1.9754, R:0.0014, T:0.0567(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0530 (C:1.9731, R:0.0014, T:0.0529(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0566 (C:1.9747, R:0.0014, T:0.0565(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0563 (C:1.9779, R:0.0014, T:0.0562(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0548 (C:1.9767, R:0.0014, T:0.0547(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0579 (C:1.9693, R:0.0014, T:0.0577(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0556 (C:1.9770, R:0.0014, T:0.0554(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0567 (C:1.9753, R:0.0014, T:0.0566(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0551 (C:1.9776, R:0.0014, T:0.0549(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0548

ğŸ“Š EPOCH 37 TRAINING SUMMARY:
  Total Loss: 0.0550
  Contrastive: 1.9751
  Reconstruction: 0.0014
  Topological: 0.0548 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.2527
  Contrastive: 1.9591
  Reconstruction: 0.0014
  Topological: 1.2525 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 37/300 COMPLETE (40.8s)
Train Loss: 0.0550 (C:1.9751, R:0.0014, T:0.0548)
Val Loss:   1.2527 (C:1.9591, R:0.0014, T:1.2525)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 38 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0571 (C:1.9799, R:0.0014, T:0.0570(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0533 (C:1.9794, R:0.0014, T:0.0531(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0530 (C:1.9707, R:0.0014, T:0.0528(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0558 (C:1.9748, R:0.0014, T:0.0556(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0534 (C:1.9736, R:0.0014, T:0.0532(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0529 (C:1.9762, R:0.0014, T:0.0528(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0566 (C:1.9772, R:0.0014, T:0.0565(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0527 (C:1.9804, R:0.0014, T:0.0526(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0547 (C:1.9714, R:0.0014, T:0.0546(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0542 (C:1.9727, R:0.0014, T:0.0541(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0550 (C:1.9741, R:0.0014, T:0.0549(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0561 (C:1.9793, R:0.0014, T:0.0560(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0536 (C:1.9770, R:0.0014, T:0.0534(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0571 (C:1.9777, R:0.0014, T:0.0569(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0550 (C:1.9781, R:0.0014, T:0.0549(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0570 (C:1.9752, R:0.0014, T:0.0568(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0553 (C:1.9761, R:0.0014, T:0.0552(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0540 (C:1.9751, R:0.0014, T:0.0538(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0578 (C:1.9773, R:0.0014, T:0.0576(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0561 (C:1.9745, R:0.0014, T:0.0559(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0576 (C:1.9769, R:0.0014, T:0.0575(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0531 (C:1.9686, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0545

ğŸ“Š EPOCH 38 TRAINING SUMMARY:
  Total Loss: 0.0546
  Contrastive: 1.9751
  Reconstruction: 0.0014
  Topological: 0.0545 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.2436
  Contrastive: 1.9491
  Reconstruction: 0.0014
  Topological: 1.2435 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 38/300 COMPLETE (41.9s)
Train Loss: 0.0546 (C:1.9751, R:0.0014, T:0.0545)
Val Loss:   1.2436 (C:1.9491, R:0.0014, T:1.2435)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 39 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0554 (C:1.9703, R:0.0014, T:0.0553(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0541 (C:1.9772, R:0.0014, T:0.0540(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0516 (C:1.9747, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0543 (C:1.9709, R:0.0014, T:0.0541(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0524 (C:1.9755, R:0.0014, T:0.0523(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0538 (C:1.9740, R:0.0014, T:0.0536(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0539 (C:1.9741, R:0.0014, T:0.0538(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0569 (C:1.9793, R:0.0014, T:0.0568(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0542 (C:1.9726, R:0.0014, T:0.0541(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0552 (C:1.9757, R:0.0014, T:0.0551(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0521 (C:1.9731, R:0.0014, T:0.0520(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0548 (C:1.9760, R:0.0014, T:0.0547(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0558 (C:1.9745, R:0.0014, T:0.0557(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0564 (C:1.9751, R:0.0014, T:0.0563(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0541 (C:1.9779, R:0.0014, T:0.0540(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0541 (C:1.9753, R:0.0014, T:0.0540(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0554 (C:1.9764, R:0.0014, T:0.0552(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0555 (C:1.9716, R:0.0014, T:0.0554(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0533 (C:1.9726, R:0.0014, T:0.0531(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0545 (C:1.9778, R:0.0014, T:0.0543(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0537 (C:1.9736, R:0.0014, T:0.0535(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0560 (C:1.9701, R:0.0014, T:0.0559(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 39 TRAINING SUMMARY:
  Total Loss: 0.0546
  Contrastive: 1.9751
  Reconstruction: 0.0014
  Topological: 0.0545 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.2315
  Contrastive: 1.9568
  Reconstruction: 0.0014
  Topological: 1.2314 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 39/300 COMPLETE (45.2s)
Train Loss: 0.0546 (C:1.9751, R:0.0014, T:0.0545)
Val Loss:   1.2315 (C:1.9568, R:0.0014, T:1.2314)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 40 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0560 (C:1.9788, R:0.0014, T:0.0559(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0555 (C:1.9737, R:0.0014, T:0.0554(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0555 (C:1.9757, R:0.0014, T:0.0554(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0545 (C:1.9754, R:0.0014, T:0.0544(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0545 (C:1.9784, R:0.0014, T:0.0544(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0531 (C:1.9740, R:0.0014, T:0.0529(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0533 (C:1.9759, R:0.0014, T:0.0531(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0547 (C:1.9736, R:0.0014, T:0.0546(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0552 (C:1.9768, R:0.0014, T:0.0551(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0550 (C:1.9763, R:0.0014, T:0.0548(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0552 (C:1.9787, R:0.0014, T:0.0551(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0574 (C:1.9731, R:0.0014, T:0.0572(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0529 (C:1.9770, R:0.0014, T:0.0527(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0531 (C:1.9763, R:0.0014, T:0.0529(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0534 (C:1.9741, R:0.0014, T:0.0533(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0550 (C:1.9759, R:0.0014, T:0.0549(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0568 (C:1.9741, R:0.0014, T:0.0566(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0542 (C:1.9742, R:0.0014, T:0.0541(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0560 (C:1.9765, R:0.0014, T:0.0559(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0565 (C:1.9731, R:0.0014, T:0.0564(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0553 (C:1.9768, R:0.0014, T:0.0552(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0562 (C:1.9751, R:0.0014, T:0.0561(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0542

ğŸ“Š EPOCH 40 TRAINING SUMMARY:
  Total Loss: 0.0544
  Contrastive: 1.9751
  Reconstruction: 0.0014
  Topological: 0.0542 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.2350
  Contrastive: 1.9588
  Reconstruction: 0.0014
  Topological: 1.2349 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 40/300 COMPLETE (45.2s)
Train Loss: 0.0544 (C:1.9751, R:0.0014, T:0.0542)
Val Loss:   1.2350 (C:1.9588, R:0.0014, T:1.2349)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 41 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0524 (C:1.9734, R:0.0014, T:0.0523(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0552 (C:1.9765, R:0.0014, T:0.0550(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0507 (C:1.9724, R:0.0014, T:0.0505(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0523 (C:1.9774, R:0.0014, T:0.0521(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0547 (C:1.9767, R:0.0014, T:0.0546(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0540 (C:1.9783, R:0.0014, T:0.0538(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0563 (C:1.9730, R:0.0014, T:0.0562(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0533 (C:1.9735, R:0.0014, T:0.0532(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0544 (C:1.9727, R:0.0014, T:0.0542(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0521 (C:1.9727, R:0.0014, T:0.0519(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0540 (C:1.9773, R:0.0014, T:0.0539(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0544 (C:1.9774, R:0.0014, T:0.0542(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0520 (C:1.9725, R:0.0014, T:0.0518(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0529 (C:1.9757, R:0.0014, T:0.0528(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0564 (C:1.9718, R:0.0014, T:0.0562(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0511 (C:1.9785, R:0.0014, T:0.0509(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0514 (C:1.9761, R:0.0014, T:0.0513(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0502 (C:1.9757, R:0.0014, T:0.0501(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0534 (C:1.9727, R:0.0014, T:0.0533(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0541 (C:1.9721, R:0.0014, T:0.0540(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0540 (C:1.9713, R:0.0014, T:0.0539(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0542 (C:1.9756, R:0.0014, T:0.0541(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 41 TRAINING SUMMARY:
  Total Loss: 0.0545
  Contrastive: 1.9752
  Reconstruction: 0.0014
  Topological: 0.0544 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.2663
  Contrastive: 1.9534
  Reconstruction: 0.0014
  Topological: 1.2661 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 41/300 COMPLETE (45.1s)
Train Loss: 0.0545 (C:1.9752, R:0.0014, T:0.0544)
Val Loss:   1.2663 (C:1.9534, R:0.0014, T:1.2661)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 42 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0569 (C:1.9747, R:0.0014, T:0.0568(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0554 (C:1.9702, R:0.0014, T:0.0553(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0536 (C:1.9732, R:0.0014, T:0.0535(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0530 (C:1.9736, R:0.0014, T:0.0528(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0536 (C:1.9770, R:0.0014, T:0.0534(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0559 (C:1.9717, R:0.0014, T:0.0558(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0498 (C:1.9784, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0503 (C:1.9735, R:0.0014, T:0.0501(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0542 (C:1.9716, R:0.0014, T:0.0541(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0543 (C:1.9766, R:0.0014, T:0.0542(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0558 (C:1.9719, R:0.0014, T:0.0557(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0541 (C:1.9770, R:0.0014, T:0.0540(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0550 (C:1.9756, R:0.0014, T:0.0548(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0574 (C:1.9814, R:0.0014, T:0.0573(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0524 (C:1.9736, R:0.0014, T:0.0523(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0523 (C:1.9695, R:0.0014, T:0.0522(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0596 (C:1.9759, R:0.0014, T:0.0594(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0542 (C:1.9732, R:0.0014, T:0.0541(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0613 (C:1.9764, R:0.0014, T:0.0611(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0573 (C:1.9771, R:0.0014, T:0.0572(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0563 (C:1.9755, R:0.0014, T:0.0562(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0550 (C:1.9748, R:0.0014, T:0.0549(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 42 TRAINING SUMMARY:
  Total Loss: 0.0548
  Contrastive: 1.9749
  Reconstruction: 0.0014
  Topological: 0.0547 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.2367
  Contrastive: 1.9504
  Reconstruction: 0.0014
  Topological: 1.2366 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 42/300 COMPLETE (45.7s)
Train Loss: 0.0548 (C:1.9749, R:0.0014, T:0.0547)
Val Loss:   1.2367 (C:1.9504, R:0.0014, T:1.2366)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 43 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0567 (C:1.9755, R:0.0014, T:0.0565(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0547 (C:1.9773, R:0.0014, T:0.0546(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0530 (C:1.9724, R:0.0014, T:0.0528(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0535 (C:1.9735, R:0.0014, T:0.0533(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0523 (C:1.9754, R:0.0014, T:0.0522(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0543 (C:1.9796, R:0.0014, T:0.0542(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0548 (C:1.9776, R:0.0014, T:0.0546(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0538 (C:1.9753, R:0.0014, T:0.0536(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0567 (C:1.9825, R:0.0014, T:0.0566(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0556 (C:1.9782, R:0.0014, T:0.0554(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0553 (C:1.9761, R:0.0014, T:0.0552(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0530 (C:1.9736, R:0.0014, T:0.0528(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0548 (C:1.9799, R:0.0014, T:0.0547(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0534 (C:1.9733, R:0.0014, T:0.0532(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0535 (C:1.9725, R:0.0014, T:0.0533(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0552 (C:1.9762, R:0.0014, T:0.0551(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0554 (C:1.9742, R:0.0014, T:0.0552(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0542 (C:1.9774, R:0.0014, T:0.0540(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0558 (C:1.9765, R:0.0014, T:0.0556(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0509 (C:1.9745, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0531 (C:1.9733, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0543 (C:1.9757, R:0.0014, T:0.0541(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0540

ğŸ“Š EPOCH 43 TRAINING SUMMARY:
  Total Loss: 0.0541
  Contrastive: 1.9755
  Reconstruction: 0.0014
  Topological: 0.0540 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.2090
  Contrastive: 1.9508
  Reconstruction: 0.0014
  Topological: 1.2089 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 43/300 COMPLETE (44.2s)
Train Loss: 0.0541 (C:1.9755, R:0.0014, T:0.0540)
Val Loss:   1.2090 (C:1.9508, R:0.0014, T:1.2089)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 44 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0500 (C:1.9762, R:0.0014, T:0.0499(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0557 (C:1.9779, R:0.0014, T:0.0556(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0521 (C:1.9699, R:0.0014, T:0.0519(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0560 (C:1.9761, R:0.0014, T:0.0558(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0525 (C:1.9788, R:0.0014, T:0.0524(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0530 (C:1.9786, R:0.0014, T:0.0529(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0560 (C:1.9761, R:0.0014, T:0.0558(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0562 (C:1.9741, R:0.0014, T:0.0561(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0542 (C:1.9773, R:0.0014, T:0.0541(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0544 (C:1.9716, R:0.0014, T:0.0543(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0510 (C:1.9805, R:0.0014, T:0.0508(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0511 (C:1.9793, R:0.0014, T:0.0510(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0571 (C:1.9769, R:0.0014, T:0.0570(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0537 (C:1.9768, R:0.0014, T:0.0536(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0540 (C:1.9765, R:0.0014, T:0.0539(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0581 (C:1.9787, R:0.0014, T:0.0579(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0538 (C:1.9723, R:0.0014, T:0.0537(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0570 (C:1.9775, R:0.0014, T:0.0568(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0525 (C:1.9779, R:0.0014, T:0.0524(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0547 (C:1.9742, R:0.0014, T:0.0545(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0523 (C:1.9766, R:0.0014, T:0.0521(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0533 (C:1.9755, R:0.0014, T:0.0532(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 44 TRAINING SUMMARY:
  Total Loss: 0.0543
  Contrastive: 1.9754
  Reconstruction: 0.0014
  Topological: 0.0542 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.2046
  Contrastive: 1.9546
  Reconstruction: 0.0014
  Topological: 1.2045 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 44/300 COMPLETE (43.7s)
Train Loss: 0.0543 (C:1.9754, R:0.0014, T:0.0542)
Val Loss:   1.2046 (C:1.9546, R:0.0014, T:1.2045)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 45 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0525 (C:1.9780, R:0.0014, T:0.0524(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0569 (C:1.9699, R:0.0014, T:0.0568(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0531 (C:1.9747, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0552 (C:1.9710, R:0.0014, T:0.0551(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0539 (C:1.9775, R:0.0014, T:0.0537(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0532 (C:1.9737, R:0.0014, T:0.0531(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0528 (C:1.9761, R:0.0014, T:0.0527(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0528 (C:1.9786, R:0.0014, T:0.0526(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0551 (C:1.9769, R:0.0014, T:0.0550(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0537 (C:1.9785, R:0.0014, T:0.0536(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0536 (C:1.9747, R:0.0014, T:0.0534(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0532 (C:1.9744, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0544 (C:1.9757, R:0.0014, T:0.0543(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0530 (C:1.9757, R:0.0014, T:0.0528(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0555 (C:1.9762, R:0.0014, T:0.0554(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0563 (C:1.9725, R:0.0014, T:0.0561(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0528 (C:1.9729, R:0.0014, T:0.0526(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0559 (C:1.9776, R:0.0014, T:0.0557(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0555 (C:1.9745, R:0.0014, T:0.0553(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0527 (C:1.9788, R:0.0014, T:0.0525(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0504 (C:1.9725, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0566 (C:1.9789, R:0.0014, T:0.0565(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0539

ğŸ“Š EPOCH 45 TRAINING SUMMARY:
  Total Loss: 0.0540
  Contrastive: 1.9752
  Reconstruction: 0.0014
  Topological: 0.0539 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.1704
  Contrastive: 1.9537
  Reconstruction: 0.0014
  Topological: 1.1703 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 45/300 COMPLETE (43.6s)
Train Loss: 0.0540 (C:1.9752, R:0.0014, T:0.0539)
Val Loss:   1.1704 (C:1.9537, R:0.0014, T:1.1703)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 46 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0568 (C:1.9789, R:0.0014, T:0.0567(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0524 (C:1.9767, R:0.0014, T:0.0522(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0540 (C:1.9678, R:0.0014, T:0.0538(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0532 (C:1.9779, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0522 (C:1.9740, R:0.0014, T:0.0521(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0574 (C:1.9742, R:0.0014, T:0.0573(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0536 (C:1.9719, R:0.0014, T:0.0535(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0511 (C:1.9744, R:0.0014, T:0.0509(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0515 (C:1.9783, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0535 (C:1.9757, R:0.0014, T:0.0534(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0532 (C:1.9708, R:0.0014, T:0.0531(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0529 (C:1.9708, R:0.0014, T:0.0527(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0553 (C:1.9779, R:0.0014, T:0.0551(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0511 (C:1.9763, R:0.0014, T:0.0510(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0528 (C:1.9788, R:0.0014, T:0.0527(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0511 (C:1.9732, R:0.0014, T:0.0509(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0521 (C:1.9788, R:0.0014, T:0.0520(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0577 (C:1.9734, R:0.0014, T:0.0576(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0530 (C:1.9711, R:0.0014, T:0.0529(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0583 (C:1.9722, R:0.0014, T:0.0582(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0528 (C:1.9722, R:0.0014, T:0.0526(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0533 (C:1.9751, R:0.0014, T:0.0532(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0539

ğŸ“Š EPOCH 46 TRAINING SUMMARY:
  Total Loss: 0.0540
  Contrastive: 1.9751
  Reconstruction: 0.0014
  Topological: 0.0539 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.1747
  Contrastive: 1.9519
  Reconstruction: 0.0014
  Topological: 1.1746 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 46/300 COMPLETE (46.7s)
Train Loss: 0.0540 (C:1.9751, R:0.0014, T:0.0539)
Val Loss:   1.1747 (C:1.9519, R:0.0014, T:1.1746)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 47 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0506 (C:1.9737, R:0.0014, T:0.0504(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0519 (C:1.9737, R:0.0014, T:0.0518(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0544 (C:1.9712, R:0.0014, T:0.0543(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0549 (C:1.9809, R:0.0014, T:0.0548(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0518 (C:1.9769, R:0.0014, T:0.0517(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0540 (C:1.9735, R:0.0014, T:0.0539(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0526 (C:1.9759, R:0.0014, T:0.0525(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0547 (C:1.9792, R:0.0014, T:0.0545(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0525 (C:1.9736, R:0.0014, T:0.0523(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0551 (C:1.9763, R:0.0014, T:0.0550(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0501 (C:1.9739, R:0.0014, T:0.0499(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0519 (C:1.9710, R:0.0014, T:0.0518(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0549 (C:1.9769, R:0.0014, T:0.0548(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0550 (C:1.9773, R:0.0014, T:0.0549(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0519 (C:1.9724, R:0.0014, T:0.0518(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0563 (C:1.9760, R:0.0014, T:0.0561(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0541 (C:1.9708, R:0.0014, T:0.0540(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0567 (C:1.9790, R:0.0014, T:0.0566(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0559 (C:1.9752, R:0.0014, T:0.0558(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0501 (C:1.9757, R:0.0014, T:0.0499(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0574 (C:1.9721, R:0.0014, T:0.0572(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0532 (C:1.9742, R:0.0014, T:0.0530(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 47 TRAINING SUMMARY:
  Total Loss: 0.0540
  Contrastive: 1.9750
  Reconstruction: 0.0014
  Topological: 0.0539 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.1827
  Contrastive: 1.9493
  Reconstruction: 0.0014
  Topological: 1.1826 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 47/300 COMPLETE (47.2s)
Train Loss: 0.0540 (C:1.9750, R:0.0014, T:0.0539)
Val Loss:   1.1827 (C:1.9493, R:0.0014, T:1.1826)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 48 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0519 (C:1.9717, R:0.0014, T:0.0518(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0543 (C:1.9765, R:0.0014, T:0.0541(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0530 (C:1.9758, R:0.0014, T:0.0529(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0543 (C:1.9796, R:0.0014, T:0.0542(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0560 (C:1.9762, R:0.0014, T:0.0559(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0532 (C:1.9707, R:0.0014, T:0.0531(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0542 (C:1.9747, R:0.0014, T:0.0540(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0570 (C:1.9728, R:0.0014, T:0.0569(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0543 (C:1.9737, R:0.0014, T:0.0542(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0567 (C:1.9742, R:0.0014, T:0.0566(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0539 (C:1.9761, R:0.0014, T:0.0538(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0543 (C:1.9744, R:0.0014, T:0.0541(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0561 (C:1.9745, R:0.0014, T:0.0560(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0604 (C:1.9705, R:0.0014, T:0.0603(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0564 (C:1.9710, R:0.0014, T:0.0562(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0561 (C:1.9727, R:0.0014, T:0.0559(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0528 (C:1.9724, R:0.0014, T:0.0527(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0557 (C:1.9704, R:0.0014, T:0.0555(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0538 (C:1.9726, R:0.0014, T:0.0536(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0521 (C:1.9727, R:0.0014, T:0.0519(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0524 (C:1.9761, R:0.0014, T:0.0523(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0547 (C:1.9713, R:0.0014, T:0.0546(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0536

ğŸ“Š EPOCH 48 TRAINING SUMMARY:
  Total Loss: 0.0538
  Contrastive: 1.9746
  Reconstruction: 0.0014
  Topological: 0.0536 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.1884
  Contrastive: 1.9526
  Reconstruction: 0.0014
  Topological: 1.1883 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 48/300 COMPLETE (48.7s)
Train Loss: 0.0538 (C:1.9746, R:0.0014, T:0.0536)
Val Loss:   1.1884 (C:1.9526, R:0.0014, T:1.1883)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 49 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0546 (C:1.9747, R:0.0014, T:0.0545(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0564 (C:1.9692, R:0.0014, T:0.0563(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0531 (C:1.9743, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0517 (C:1.9766, R:0.0014, T:0.0516(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0564 (C:1.9775, R:0.0014, T:0.0563(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0551 (C:1.9753, R:0.0014, T:0.0549(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0527 (C:1.9721, R:0.0014, T:0.0526(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0523 (C:1.9766, R:0.0014, T:0.0522(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0524 (C:1.9738, R:0.0014, T:0.0522(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0544 (C:1.9775, R:0.0014, T:0.0543(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0552 (C:1.9775, R:0.0014, T:0.0551(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0571 (C:1.9745, R:0.0014, T:0.0569(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0543 (C:1.9723, R:0.0014, T:0.0542(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0537 (C:1.9764, R:0.0014, T:0.0536(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0566 (C:1.9699, R:0.0014, T:0.0565(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0539 (C:1.9791, R:0.0014, T:0.0538(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0546 (C:1.9761, R:0.0014, T:0.0545(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0526 (C:1.9735, R:0.0014, T:0.0524(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0531 (C:1.9743, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0540 (C:1.9697, R:0.0014, T:0.0538(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0523 (C:1.9775, R:0.0014, T:0.0521(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0515 (C:1.9728, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0533

ğŸ“Š EPOCH 49 TRAINING SUMMARY:
  Total Loss: 0.0534
  Contrastive: 1.9741
  Reconstruction: 0.0014
  Topological: 0.0533 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.1953
  Contrastive: 1.9462
  Reconstruction: 0.0014
  Topological: 1.1951 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 49/300 COMPLETE (46.3s)
Train Loss: 0.0534 (C:1.9741, R:0.0014, T:0.0533)
Val Loss:   1.1953 (C:1.9462, R:0.0014, T:1.1951)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 50 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0514 (C:1.9723, R:0.0014, T:0.0513(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0566 (C:1.9776, R:0.0014, T:0.0565(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0541 (C:1.9731, R:0.0014, T:0.0539(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0536 (C:1.9745, R:0.0014, T:0.0535(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0537 (C:1.9782, R:0.0014, T:0.0535(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0555 (C:1.9732, R:0.0014, T:0.0553(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0560 (C:1.9757, R:0.0014, T:0.0559(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0570 (C:1.9746, R:0.0014, T:0.0568(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0530 (C:1.9731, R:0.0014, T:0.0528(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0527 (C:1.9796, R:0.0014, T:0.0526(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0523 (C:1.9689, R:0.0014, T:0.0521(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0534 (C:1.9799, R:0.0014, T:0.0532(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0568 (C:1.9725, R:0.0014, T:0.0566(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0545 (C:1.9750, R:0.0014, T:0.0544(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0535 (C:1.9749, R:0.0014, T:0.0533(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0573 (C:1.9769, R:0.0014, T:0.0572(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0511 (C:1.9713, R:0.0014, T:0.0509(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0561 (C:1.9738, R:0.0014, T:0.0560(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0570 (C:1.9761, R:0.0014, T:0.0568(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0541 (C:1.9768, R:0.0014, T:0.0540(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0546 (C:1.9702, R:0.0014, T:0.0545(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0549 (C:1.9750, R:0.0014, T:0.0548(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 50 TRAINING SUMMARY:
  Total Loss: 0.0536
  Contrastive: 1.9741
  Reconstruction: 0.0014
  Topological: 0.0535 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.1878
  Contrastive: 1.9470
  Reconstruction: 0.0014
  Topological: 1.1877 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 50/300 COMPLETE (47.7s)
Train Loss: 0.0536 (C:1.9741, R:0.0014, T:0.0535)
Val Loss:   1.1878 (C:1.9470, R:0.0014, T:1.1877)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 51 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0546 (C:1.9712, R:0.0014, T:0.0544(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0572 (C:1.9733, R:0.0014, T:0.0570(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0498 (C:1.9712, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0527 (C:1.9783, R:0.0014, T:0.0525(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0530 (C:1.9741, R:0.0014, T:0.0529(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0520 (C:1.9744, R:0.0014, T:0.0519(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0539 (C:1.9755, R:0.0014, T:0.0537(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0527 (C:1.9693, R:0.0014, T:0.0525(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0521 (C:1.9723, R:0.0014, T:0.0520(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0532 (C:1.9795, R:0.0014, T:0.0531(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0529 (C:1.9739, R:0.0014, T:0.0527(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0537 (C:1.9702, R:0.0014, T:0.0536(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0562 (C:1.9739, R:0.0014, T:0.0560(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0577 (C:1.9664, R:0.0014, T:0.0576(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0516 (C:1.9731, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0572 (C:1.9733, R:0.0014, T:0.0571(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0521 (C:1.9713, R:0.0014, T:0.0520(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0538 (C:1.9749, R:0.0014, T:0.0536(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0536 (C:1.9784, R:0.0014, T:0.0534(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0534 (C:1.9736, R:0.0014, T:0.0533(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0530 (C:1.9767, R:0.0014, T:0.0529(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0521 (C:1.9779, R:0.0014, T:0.0519(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 51 TRAINING SUMMARY:
  Total Loss: 0.0534
  Contrastive: 1.9745
  Reconstruction: 0.0014
  Topological: 0.0533 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.1768
  Contrastive: 1.9552
  Reconstruction: 0.0014
  Topological: 1.1767 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 51/300 COMPLETE (48.5s)
Train Loss: 0.0534 (C:1.9745, R:0.0014, T:0.0533)
Val Loss:   1.1768 (C:1.9552, R:0.0014, T:1.1767)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 52 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0535 (C:1.9749, R:0.0014, T:0.0533(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0561 (C:1.9744, R:0.0014, T:0.0560(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0559 (C:1.9782, R:0.0014, T:0.0558(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0521 (C:1.9727, R:0.0014, T:0.0519(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0546 (C:1.9733, R:0.0014, T:0.0545(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0574 (C:1.9774, R:0.0014, T:0.0573(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0543 (C:1.9804, R:0.0014, T:0.0542(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0505 (C:1.9734, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0551 (C:1.9778, R:0.0014, T:0.0550(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0526 (C:1.9745, R:0.0014, T:0.0525(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0541 (C:1.9746, R:0.0014, T:0.0540(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0575 (C:1.9709, R:0.0014, T:0.0573(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0560 (C:1.9752, R:0.0014, T:0.0558(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0524 (C:1.9717, R:0.0014, T:0.0523(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0546 (C:1.9761, R:0.0014, T:0.0544(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0544 (C:1.9726, R:0.0014, T:0.0543(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0553 (C:1.9784, R:0.0014, T:0.0552(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0534 (C:1.9785, R:0.0014, T:0.0533(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0540 (C:1.9733, R:0.0014, T:0.0538(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0536 (C:1.9711, R:0.0014, T:0.0535(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0549 (C:1.9709, R:0.0014, T:0.0548(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0544 (C:1.9766, R:0.0014, T:0.0543(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 52 TRAINING SUMMARY:
  Total Loss: 0.0536
  Contrastive: 1.9746
  Reconstruction: 0.0014
  Topological: 0.0535 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.1724
  Contrastive: 1.9554
  Reconstruction: 0.0014
  Topological: 1.1722 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 52/300 COMPLETE (49.7s)
Train Loss: 0.0536 (C:1.9746, R:0.0014, T:0.0535)
Val Loss:   1.1724 (C:1.9554, R:0.0014, T:1.1722)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 53 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0492 (C:1.9752, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0554 (C:1.9750, R:0.0014, T:0.0553(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0502 (C:1.9692, R:0.0014, T:0.0501(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0518 (C:1.9707, R:0.0014, T:0.0516(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0538 (C:1.9752, R:0.0014, T:0.0536(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0534 (C:1.9735, R:0.0014, T:0.0532(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0525 (C:1.9778, R:0.0014, T:0.0524(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0544 (C:1.9747, R:0.0014, T:0.0543(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0544 (C:1.9713, R:0.0014, T:0.0543(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0541 (C:1.9750, R:0.0014, T:0.0540(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0518 (C:1.9743, R:0.0014, T:0.0516(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0535 (C:1.9752, R:0.0014, T:0.0533(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0547 (C:1.9687, R:0.0014, T:0.0546(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0535 (C:1.9745, R:0.0014, T:0.0533(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0511 (C:1.9750, R:0.0014, T:0.0510(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0532 (C:1.9709, R:0.0014, T:0.0531(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0535 (C:1.9721, R:0.0014, T:0.0533(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0536 (C:1.9658, R:0.0014, T:0.0534(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0532 (C:1.9713, R:0.0014, T:0.0531(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0550 (C:1.9737, R:0.0014, T:0.0548(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0544 (C:1.9819, R:0.0014, T:0.0543(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0538 (C:1.9727, R:0.0014, T:0.0536(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 53 TRAINING SUMMARY:
  Total Loss: 0.0534
  Contrastive: 1.9742
  Reconstruction: 0.0014
  Topological: 0.0533 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.1345
  Contrastive: 1.9435
  Reconstruction: 0.0014
  Topological: 1.1344 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 53/300 COMPLETE (49.1s)
Train Loss: 0.0534 (C:1.9742, R:0.0014, T:0.0533)
Val Loss:   1.1345 (C:1.9435, R:0.0014, T:1.1344)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 54 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0540 (C:1.9695, R:0.0014, T:0.0539(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0505 (C:1.9775, R:0.0014, T:0.0504(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0538 (C:1.9782, R:0.0014, T:0.0537(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0524 (C:1.9774, R:0.0014, T:0.0522(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0541 (C:1.9754, R:0.0014, T:0.0540(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0544 (C:1.9711, R:0.0014, T:0.0542(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0527 (C:1.9742, R:0.0014, T:0.0525(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0552 (C:1.9727, R:0.0014, T:0.0550(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0498 (C:1.9767, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0560 (C:1.9726, R:0.0014, T:0.0558(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0521 (C:1.9731, R:0.0014, T:0.0520(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0519 (C:1.9773, R:0.0014, T:0.0518(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0534 (C:1.9714, R:0.0014, T:0.0532(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0519 (C:1.9781, R:0.0014, T:0.0518(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0542 (C:1.9764, R:0.0014, T:0.0540(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0514 (C:1.9728, R:0.0014, T:0.0513(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0509 (C:1.9766, R:0.0014, T:0.0508(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0541 (C:1.9727, R:0.0014, T:0.0540(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0553 (C:1.9727, R:0.0014, T:0.0551(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0560 (C:1.9698, R:0.0014, T:0.0559(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0516 (C:1.9734, R:0.0014, T:0.0515(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0555 (C:1.9741, R:0.0014, T:0.0554(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0531

ğŸ“Š EPOCH 54 TRAINING SUMMARY:
  Total Loss: 0.0533
  Contrastive: 1.9742
  Reconstruction: 0.0014
  Topological: 0.0531 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.1211
  Contrastive: 1.9496
  Reconstruction: 0.0014
  Topological: 1.1210 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 54/300 COMPLETE (45.6s)
Train Loss: 0.0533 (C:1.9742, R:0.0014, T:0.0531)
Val Loss:   1.1211 (C:1.9496, R:0.0014, T:1.1210)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 55 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0536 (C:1.9726, R:0.0014, T:0.0535(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0529 (C:1.9762, R:0.0014, T:0.0528(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0538 (C:1.9770, R:0.0014, T:0.0536(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0509 (C:1.9759, R:0.0014, T:0.0508(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0541 (C:1.9746, R:0.0014, T:0.0539(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0568 (C:1.9777, R:0.0014, T:0.0567(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0489 (C:1.9765, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0532 (C:1.9716, R:0.0014, T:0.0531(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0511 (C:1.9794, R:0.0014, T:0.0509(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0544 (C:1.9713, R:0.0014, T:0.0542(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0509 (C:1.9727, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0554 (C:1.9717, R:0.0014, T:0.0553(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0558 (C:1.9792, R:0.0014, T:0.0557(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0508 (C:1.9706, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0494 (C:1.9725, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0519 (C:1.9718, R:0.0014, T:0.0517(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0499 (C:1.9702, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0508 (C:1.9788, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0548 (C:1.9772, R:0.0014, T:0.0547(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0525 (C:1.9751, R:0.0014, T:0.0524(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0531 (C:1.9720, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0543 (C:1.9790, R:0.0014, T:0.0542(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 55 TRAINING SUMMARY:
  Total Loss: 0.0533
  Contrastive: 1.9743
  Reconstruction: 0.0014
  Topological: 0.0531 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.1384
  Contrastive: 1.9521
  Reconstruction: 0.0014
  Topological: 1.1383 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 55/300 COMPLETE (45.0s)
Train Loss: 0.0533 (C:1.9743, R:0.0014, T:0.0531)
Val Loss:   1.1384 (C:1.9521, R:0.0014, T:1.1383)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 56 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0517 (C:1.9730, R:0.0014, T:0.0515(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0505 (C:1.9779, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0512 (C:1.9711, R:0.0014, T:0.0511(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0542 (C:1.9764, R:0.0014, T:0.0540(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0526 (C:1.9775, R:0.0014, T:0.0524(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0522 (C:1.9754, R:0.0014, T:0.0521(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0547 (C:1.9742, R:0.0014, T:0.0546(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0508 (C:1.9751, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0507 (C:1.9736, R:0.0014, T:0.0506(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0539 (C:1.9705, R:0.0014, T:0.0538(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0546 (C:1.9719, R:0.0014, T:0.0544(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0534 (C:1.9700, R:0.0014, T:0.0533(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0570 (C:1.9726, R:0.0014, T:0.0568(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0526 (C:1.9756, R:0.0014, T:0.0524(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0506 (C:1.9717, R:0.0014, T:0.0504(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0514 (C:1.9683, R:0.0014, T:0.0513(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0525 (C:1.9782, R:0.0014, T:0.0524(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0536 (C:1.9679, R:0.0014, T:0.0534(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0520 (C:1.9754, R:0.0014, T:0.0519(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0540 (C:1.9778, R:0.0014, T:0.0539(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0531 (C:1.9785, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0557 (C:1.9736, R:0.0014, T:0.0555(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0531

ğŸ“Š EPOCH 56 TRAINING SUMMARY:
  Total Loss: 0.0532
  Contrastive: 1.9742
  Reconstruction: 0.0014
  Topological: 0.0531 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.1181
  Contrastive: 1.9500
  Reconstruction: 0.0014
  Topological: 1.1180 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 56/300 COMPLETE (44.2s)
Train Loss: 0.0532 (C:1.9742, R:0.0014, T:0.0531)
Val Loss:   1.1181 (C:1.9500, R:0.0014, T:1.1180)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 57 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0488 (C:1.9756, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0510 (C:1.9735, R:0.0014, T:0.0508(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0536 (C:1.9689, R:0.0014, T:0.0535(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0535 (C:1.9753, R:0.0014, T:0.0534(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0530 (C:1.9804, R:0.0014, T:0.0529(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0536 (C:1.9766, R:0.0014, T:0.0535(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0508 (C:1.9762, R:0.0014, T:0.0506(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0544 (C:1.9722, R:0.0014, T:0.0543(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0515 (C:1.9778, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0541 (C:1.9758, R:0.0014, T:0.0540(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0535 (C:1.9767, R:0.0014, T:0.0534(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0548 (C:1.9781, R:0.0014, T:0.0547(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0534 (C:1.9726, R:0.0014, T:0.0533(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0525 (C:1.9686, R:0.0014, T:0.0523(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0535 (C:1.9765, R:0.0014, T:0.0534(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0525 (C:1.9700, R:0.0014, T:0.0523(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0557 (C:1.9768, R:0.0014, T:0.0555(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0514 (C:1.9731, R:0.0014, T:0.0513(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0522 (C:1.9721, R:0.0014, T:0.0521(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0532 (C:1.9701, R:0.0014, T:0.0531(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0579 (C:1.9725, R:0.0014, T:0.0577(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0540 (C:1.9815, R:0.0014, T:0.0538(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0528

ğŸ“Š EPOCH 57 TRAINING SUMMARY:
  Total Loss: 0.0530
  Contrastive: 1.9744
  Reconstruction: 0.0014
  Topological: 0.0528 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.1645
  Contrastive: 1.9495
  Reconstruction: 0.0014
  Topological: 1.1643 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 57/300 COMPLETE (44.1s)
Train Loss: 0.0530 (C:1.9744, R:0.0014, T:0.0528)
Val Loss:   1.1645 (C:1.9495, R:0.0014, T:1.1643)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 58 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0516 (C:1.9724, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0546 (C:1.9744, R:0.0014, T:0.0545(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0507 (C:1.9761, R:0.0014, T:0.0506(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0493 (C:1.9756, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0542 (C:1.9810, R:0.0014, T:0.0541(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0522 (C:1.9676, R:0.0014, T:0.0521(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0545 (C:1.9723, R:0.0014, T:0.0543(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0499 (C:1.9748, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0552 (C:1.9769, R:0.0014, T:0.0551(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0520 (C:1.9734, R:0.0014, T:0.0519(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0555 (C:1.9748, R:0.0014, T:0.0553(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0510 (C:1.9686, R:0.0014, T:0.0508(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0513 (C:1.9712, R:0.0014, T:0.0512(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0540 (C:1.9768, R:0.0014, T:0.0539(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0546 (C:1.9734, R:0.0014, T:0.0545(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0541 (C:1.9733, R:0.0014, T:0.0540(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0533 (C:1.9688, R:0.0014, T:0.0532(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0551 (C:1.9753, R:0.0014, T:0.0549(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0515 (C:1.9755, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0533 (C:1.9711, R:0.0014, T:0.0532(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0521 (C:1.9734, R:0.0014, T:0.0520(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0498 (C:1.9766, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0528

ğŸ“Š EPOCH 58 TRAINING SUMMARY:
  Total Loss: 0.0530
  Contrastive: 1.9746
  Reconstruction: 0.0014
  Topological: 0.0528 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.1313
  Contrastive: 1.9546
  Reconstruction: 0.0014
  Topological: 1.1311 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 58/300 COMPLETE (43.4s)
Train Loss: 0.0530 (C:1.9746, R:0.0014, T:0.0528)
Val Loss:   1.1313 (C:1.9546, R:0.0014, T:1.1311)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 59 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0539 (C:1.9734, R:0.0014, T:0.0538(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0530 (C:1.9710, R:0.0014, T:0.0529(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0542 (C:1.9707, R:0.0014, T:0.0541(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0519 (C:1.9694, R:0.0014, T:0.0518(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0535 (C:1.9712, R:0.0014, T:0.0534(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0504 (C:1.9795, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0535 (C:1.9732, R:0.0014, T:0.0534(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0539 (C:1.9774, R:0.0014, T:0.0538(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0526 (C:1.9766, R:0.0014, T:0.0525(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0533 (C:1.9759, R:0.0014, T:0.0531(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0487 (C:1.9734, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0556 (C:1.9779, R:0.0014, T:0.0554(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0547 (C:1.9778, R:0.0014, T:0.0545(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0546 (C:1.9718, R:0.0014, T:0.0545(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0509 (C:1.9782, R:0.0014, T:0.0508(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0494 (C:1.9763, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0519 (C:1.9667, R:0.0014, T:0.0518(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0536 (C:1.9749, R:0.0014, T:0.0535(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0539 (C:1.9738, R:0.0014, T:0.0538(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0539 (C:1.9764, R:0.0014, T:0.0538(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0533 (C:1.9763, R:0.0014, T:0.0531(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0524 (C:1.9734, R:0.0014, T:0.0523(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0527

ğŸ“Š EPOCH 59 TRAINING SUMMARY:
  Total Loss: 0.0529
  Contrastive: 1.9744
  Reconstruction: 0.0014
  Topological: 0.0527 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.1317
  Contrastive: 1.9506
  Reconstruction: 0.0014
  Topological: 1.1315 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 59/300 COMPLETE (44.2s)
Train Loss: 0.0529 (C:1.9744, R:0.0014, T:0.0527)
Val Loss:   1.1317 (C:1.9506, R:0.0014, T:1.1315)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 60 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0535 (C:1.9739, R:0.0014, T:0.0533(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0521 (C:1.9730, R:0.0014, T:0.0520(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0487 (C:1.9736, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0554 (C:1.9739, R:0.0014, T:0.0552(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0530 (C:1.9770, R:0.0014, T:0.0529(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0510 (C:1.9750, R:0.0014, T:0.0509(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0529 (C:1.9751, R:0.0014, T:0.0528(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0519 (C:1.9710, R:0.0014, T:0.0518(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0529 (C:1.9744, R:0.0014, T:0.0528(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0545 (C:1.9729, R:0.0014, T:0.0543(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0526 (C:1.9734, R:0.0014, T:0.0525(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0566 (C:1.9758, R:0.0014, T:0.0564(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0511 (C:1.9683, R:0.0014, T:0.0510(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0555 (C:1.9733, R:0.0014, T:0.0554(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0498 (C:1.9696, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0558 (C:1.9711, R:0.0014, T:0.0556(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0531 (C:1.9770, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0528 (C:1.9760, R:0.0014, T:0.0526(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0533 (C:1.9776, R:0.0014, T:0.0531(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0526 (C:1.9784, R:0.0014, T:0.0524(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0543 (C:1.9784, R:0.0014, T:0.0541(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0564 (C:1.9698, R:0.0014, T:0.0563(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 60 TRAINING SUMMARY:
  Total Loss: 0.0529
  Contrastive: 1.9742
  Reconstruction: 0.0014
  Topological: 0.0527 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.1387
  Contrastive: 1.9494
  Reconstruction: 0.0014
  Topological: 1.1385 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 60/300 COMPLETE (44.0s)
Train Loss: 0.0529 (C:1.9742, R:0.0014, T:0.0527)
Val Loss:   1.1387 (C:1.9494, R:0.0014, T:1.1385)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 61 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0558 (C:1.9730, R:0.0014, T:0.0556(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0540 (C:1.9774, R:0.0014, T:0.0538(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0476 (C:1.9635, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0543 (C:1.9764, R:0.0014, T:0.0542(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0551 (C:1.9766, R:0.0014, T:0.0550(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0501 (C:1.9759, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0550 (C:1.9717, R:0.0014, T:0.0549(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0543 (C:1.9770, R:0.0014, T:0.0542(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0521 (C:1.9730, R:0.0014, T:0.0519(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0522 (C:1.9754, R:0.0014, T:0.0521(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0540 (C:1.9708, R:0.0014, T:0.0539(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0529 (C:1.9755, R:0.0014, T:0.0528(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0496 (C:1.9769, R:0.0014, T:0.0495(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0527 (C:1.9664, R:0.0014, T:0.0526(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0539 (C:1.9754, R:0.0014, T:0.0538(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0534 (C:1.9765, R:0.0014, T:0.0533(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0525 (C:1.9728, R:0.0014, T:0.0524(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0514 (C:1.9721, R:0.0014, T:0.0512(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0565 (C:1.9731, R:0.0014, T:0.0564(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0534 (C:1.9733, R:0.0014, T:0.0533(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0497 (C:1.9767, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0570 (C:1.9703, R:0.0014, T:0.0569(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0526

ğŸ“Š EPOCH 61 TRAINING SUMMARY:
  Total Loss: 0.0528
  Contrastive: 1.9739
  Reconstruction: 0.0014
  Topological: 0.0526 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.1295
  Contrastive: 1.9484
  Reconstruction: 0.0014
  Topological: 1.1293 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 61/300 COMPLETE (44.4s)
Train Loss: 0.0528 (C:1.9739, R:0.0014, T:0.0526)
Val Loss:   1.1295 (C:1.9484, R:0.0014, T:1.1293)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 62 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0517 (C:1.9705, R:0.0014, T:0.0515(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0561 (C:1.9708, R:0.0014, T:0.0560(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0542 (C:1.9735, R:0.0014, T:0.0540(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0530 (C:1.9728, R:0.0014, T:0.0529(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0504 (C:1.9711, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0534 (C:1.9776, R:0.0014, T:0.0532(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0551 (C:1.9717, R:0.0014, T:0.0550(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0532 (C:1.9758, R:0.0014, T:0.0531(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0512 (C:1.9722, R:0.0014, T:0.0510(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0530 (C:1.9768, R:0.0014, T:0.0528(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0523 (C:1.9759, R:0.0014, T:0.0521(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0527 (C:1.9754, R:0.0014, T:0.0526(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0552 (C:1.9745, R:0.0014, T:0.0551(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0541 (C:1.9719, R:0.0014, T:0.0540(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0525 (C:1.9749, R:0.0014, T:0.0523(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0521 (C:1.9728, R:0.0014, T:0.0520(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0515 (C:1.9738, R:0.0014, T:0.0513(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0531 (C:1.9737, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0553 (C:1.9721, R:0.0014, T:0.0551(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0507 (C:1.9752, R:0.0014, T:0.0505(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0528 (C:1.9720, R:0.0014, T:0.0527(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0518 (C:1.9790, R:0.0014, T:0.0516(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0525

ğŸ“Š EPOCH 62 TRAINING SUMMARY:
  Total Loss: 0.0527
  Contrastive: 1.9737
  Reconstruction: 0.0014
  Topological: 0.0525 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.1193
  Contrastive: 1.9523
  Reconstruction: 0.0014
  Topological: 1.1192 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 62/300 COMPLETE (44.8s)
Train Loss: 0.0527 (C:1.9737, R:0.0014, T:0.0525)
Val Loss:   1.1193 (C:1.9523, R:0.0014, T:1.1192)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 63 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0560 (C:1.9720, R:0.0014, T:0.0558(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0530 (C:1.9741, R:0.0014, T:0.0528(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0529 (C:1.9741, R:0.0014, T:0.0528(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0523 (C:1.9744, R:0.0014, T:0.0521(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0517 (C:1.9750, R:0.0014, T:0.0516(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0513 (C:1.9692, R:0.0014, T:0.0511(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0536 (C:1.9760, R:0.0014, T:0.0535(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0543 (C:1.9748, R:0.0014, T:0.0541(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0517 (C:1.9745, R:0.0014, T:0.0515(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0521 (C:1.9763, R:0.0014, T:0.0519(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0501 (C:1.9738, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0506 (C:1.9774, R:0.0014, T:0.0505(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0503 (C:1.9764, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0517 (C:1.9725, R:0.0014, T:0.0516(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0518 (C:1.9760, R:0.0014, T:0.0517(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0540 (C:1.9704, R:0.0014, T:0.0538(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0528 (C:1.9738, R:0.0014, T:0.0527(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0512 (C:1.9731, R:0.0014, T:0.0511(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0549 (C:1.9703, R:0.0014, T:0.0548(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0541 (C:1.9753, R:0.0014, T:0.0539(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0532 (C:1.9728, R:0.0014, T:0.0531(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0520 (C:1.9735, R:0.0014, T:0.0519(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0524

ğŸ“Š EPOCH 63 TRAINING SUMMARY:
  Total Loss: 0.0526
  Contrastive: 1.9737
  Reconstruction: 0.0014
  Topological: 0.0524 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.1085
  Contrastive: 1.9530
  Reconstruction: 0.0014
  Topological: 1.1084 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 63/300 COMPLETE (44.7s)
Train Loss: 0.0526 (C:1.9737, R:0.0014, T:0.0524)
Val Loss:   1.1085 (C:1.9530, R:0.0014, T:1.1084)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 64 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0489 (C:1.9720, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0506 (C:1.9761, R:0.0014, T:0.0505(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0503 (C:1.9757, R:0.0014, T:0.0501(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0531 (C:1.9726, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0526 (C:1.9747, R:0.0014, T:0.0525(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0532 (C:1.9794, R:0.0014, T:0.0531(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0528 (C:1.9704, R:0.0014, T:0.0526(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0534 (C:1.9744, R:0.0014, T:0.0532(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0508 (C:1.9732, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0515 (C:1.9755, R:0.0014, T:0.0513(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0535 (C:1.9702, R:0.0014, T:0.0534(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0567 (C:1.9718, R:0.0014, T:0.0565(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0537 (C:1.9794, R:0.0014, T:0.0536(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0524 (C:1.9749, R:0.0014, T:0.0523(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0533 (C:1.9755, R:0.0014, T:0.0532(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0534 (C:1.9726, R:0.0014, T:0.0533(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0491 (C:1.9742, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0551 (C:1.9733, R:0.0014, T:0.0550(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0517 (C:1.9725, R:0.0014, T:0.0515(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0531 (C:1.9724, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0549 (C:1.9735, R:0.0014, T:0.0547(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0551 (C:1.9763, R:0.0014, T:0.0549(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0522

ğŸ“Š EPOCH 64 TRAINING SUMMARY:
  Total Loss: 0.0524
  Contrastive: 1.9733
  Reconstruction: 0.0014
  Topological: 0.0522 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.1231
  Contrastive: 1.9511
  Reconstruction: 0.0014
  Topological: 1.1230 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 64/300 COMPLETE (45.0s)
Train Loss: 0.0524 (C:1.9733, R:0.0014, T:0.0522)
Val Loss:   1.1231 (C:1.9511, R:0.0014, T:1.1230)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 65 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0543 (C:1.9739, R:0.0014, T:0.0541(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0506 (C:1.9730, R:0.0014, T:0.0505(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0525 (C:1.9765, R:0.0014, T:0.0524(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0551 (C:1.9720, R:0.0014, T:0.0550(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0498 (C:1.9705, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0511 (C:1.9734, R:0.0014, T:0.0509(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0510 (C:1.9753, R:0.0014, T:0.0508(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0489 (C:1.9761, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0491 (C:1.9787, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0532 (C:1.9737, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0516 (C:1.9758, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0528 (C:1.9735, R:0.0014, T:0.0526(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0519 (C:1.9704, R:0.0014, T:0.0518(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0528 (C:1.9745, R:0.0014, T:0.0527(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0540 (C:1.9732, R:0.0014, T:0.0539(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0541 (C:1.9736, R:0.0014, T:0.0539(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0525 (C:1.9701, R:0.0014, T:0.0524(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0538 (C:1.9743, R:0.0014, T:0.0537(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0489 (C:1.9731, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0530 (C:1.9717, R:0.0014, T:0.0529(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0545 (C:1.9771, R:0.0014, T:0.0544(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0541 (C:1.9754, R:0.0014, T:0.0539(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 65 TRAINING SUMMARY:
  Total Loss: 0.0524
  Contrastive: 1.9736
  Reconstruction: 0.0014
  Topological: 0.0523 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.1055
  Contrastive: 1.9521
  Reconstruction: 0.0014
  Topological: 1.1053 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 65/300 COMPLETE (45.5s)
Train Loss: 0.0524 (C:1.9736, R:0.0014, T:0.0523)
Val Loss:   1.1055 (C:1.9521, R:0.0014, T:1.1053)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 66 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0486 (C:1.9731, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0529 (C:1.9774, R:0.0014, T:0.0527(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0507 (C:1.9747, R:0.0014, T:0.0505(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0528 (C:1.9729, R:0.0014, T:0.0526(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0525 (C:1.9711, R:0.0014, T:0.0524(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0516 (C:1.9739, R:0.0014, T:0.0515(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0531 (C:1.9720, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0550 (C:1.9747, R:0.0014, T:0.0549(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0524 (C:1.9749, R:0.0014, T:0.0523(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0558 (C:1.9717, R:0.0014, T:0.0556(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0493 (C:1.9755, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0527 (C:1.9746, R:0.0014, T:0.0525(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0509 (C:1.9706, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0519 (C:1.9752, R:0.0014, T:0.0517(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0529 (C:1.9813, R:0.0014, T:0.0528(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0539 (C:1.9758, R:0.0014, T:0.0537(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0507 (C:1.9732, R:0.0014, T:0.0506(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0517 (C:1.9749, R:0.0014, T:0.0516(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0526 (C:1.9779, R:0.0014, T:0.0524(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0552 (C:1.9741, R:0.0014, T:0.0551(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0514 (C:1.9735, R:0.0014, T:0.0513(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0539 (C:1.9715, R:0.0014, T:0.0537(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0521

ğŸ“Š EPOCH 66 TRAINING SUMMARY:
  Total Loss: 0.0522
  Contrastive: 1.9737
  Reconstruction: 0.0014
  Topological: 0.0521 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.1472
  Contrastive: 1.9536
  Reconstruction: 0.0014
  Topological: 1.1471 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 66/300 COMPLETE (44.6s)
Train Loss: 0.0522 (C:1.9737, R:0.0014, T:0.0521)
Val Loss:   1.1472 (C:1.9536, R:0.0014, T:1.1471)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 67 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0530 (C:1.9727, R:0.0014, T:0.0529(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0526 (C:1.9714, R:0.0014, T:0.0525(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0531 (C:1.9703, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0500 (C:1.9737, R:0.0014, T:0.0499(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0517 (C:1.9705, R:0.0014, T:0.0516(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0509 (C:1.9744, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0527 (C:1.9725, R:0.0014, T:0.0526(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0508 (C:1.9700, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0502 (C:1.9731, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0524 (C:1.9673, R:0.0014, T:0.0522(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0490 (C:1.9737, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0516 (C:1.9734, R:0.0014, T:0.0515(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0534 (C:1.9778, R:0.0014, T:0.0533(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0539 (C:1.9748, R:0.0014, T:0.0537(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0544 (C:1.9713, R:0.0014, T:0.0542(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0502 (C:1.9733, R:0.0014, T:0.0501(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0560 (C:1.9790, R:0.0014, T:0.0559(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0531 (C:1.9742, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0534 (C:1.9748, R:0.0014, T:0.0533(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0523 (C:1.9747, R:0.0014, T:0.0522(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0518 (C:1.9731, R:0.0014, T:0.0517(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0534 (C:1.9739, R:0.0014, T:0.0532(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 67 TRAINING SUMMARY:
  Total Loss: 0.0524
  Contrastive: 1.9738
  Reconstruction: 0.0014
  Topological: 0.0523 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.0935
  Contrastive: 1.9502
  Reconstruction: 0.0014
  Topological: 1.0934 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 67/300 COMPLETE (43.6s)
Train Loss: 0.0524 (C:1.9738, R:0.0014, T:0.0523)
Val Loss:   1.0935 (C:1.9502, R:0.0014, T:1.0934)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 68 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0522 (C:1.9743, R:0.0014, T:0.0521(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0514 (C:1.9798, R:0.0014, T:0.0513(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0536 (C:1.9747, R:0.0014, T:0.0534(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0522 (C:1.9716, R:0.0014, T:0.0520(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0526 (C:1.9746, R:0.0014, T:0.0525(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0516 (C:1.9693, R:0.0014, T:0.0515(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0513 (C:1.9710, R:0.0014, T:0.0512(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0549 (C:1.9740, R:0.0014, T:0.0547(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0519 (C:1.9771, R:0.0014, T:0.0517(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0534 (C:1.9698, R:0.0014, T:0.0533(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0521 (C:1.9752, R:0.0014, T:0.0520(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0501 (C:1.9686, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0518 (C:1.9733, R:0.0014, T:0.0517(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0499 (C:1.9793, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0502 (C:1.9714, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0529 (C:1.9756, R:0.0014, T:0.0527(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0538 (C:1.9710, R:0.0014, T:0.0536(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0537 (C:1.9698, R:0.0014, T:0.0536(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0519 (C:1.9715, R:0.0014, T:0.0517(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0512 (C:1.9750, R:0.0014, T:0.0511(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0477 (C:1.9734, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0531 (C:1.9789, R:0.0014, T:0.0530(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 68 TRAINING SUMMARY:
  Total Loss: 0.0523
  Contrastive: 1.9733
  Reconstruction: 0.0014
  Topological: 0.0521 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.1430
  Contrastive: 1.9550
  Reconstruction: 0.0014
  Topological: 1.1428 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 68/300 COMPLETE (43.1s)
Train Loss: 0.0523 (C:1.9733, R:0.0014, T:0.0521)
Val Loss:   1.1430 (C:1.9550, R:0.0014, T:1.1428)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 69 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0555 (C:1.9766, R:0.0014, T:0.0553(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0485 (C:1.9715, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0496 (C:1.9730, R:0.0014, T:0.0495(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0531 (C:1.9766, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0533 (C:1.9708, R:0.0014, T:0.0532(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0535 (C:1.9727, R:0.0014, T:0.0534(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0492 (C:1.9756, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0528 (C:1.9713, R:0.0014, T:0.0526(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0519 (C:1.9781, R:0.0014, T:0.0517(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0545 (C:1.9769, R:0.0014, T:0.0544(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0512 (C:1.9760, R:0.0014, T:0.0511(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0507 (C:1.9739, R:0.0014, T:0.0506(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0517 (C:1.9810, R:0.0014, T:0.0516(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0520 (C:1.9752, R:0.0014, T:0.0519(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0517 (C:1.9693, R:0.0014, T:0.0516(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0517 (C:1.9713, R:0.0014, T:0.0515(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0488 (C:1.9790, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0522 (C:1.9760, R:0.0014, T:0.0521(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0520 (C:1.9779, R:0.0014, T:0.0518(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0502 (C:1.9771, R:0.0014, T:0.0501(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0525 (C:1.9810, R:0.0014, T:0.0523(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0514 (C:1.9786, R:0.0014, T:0.0513(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0519

ğŸ“Š EPOCH 69 TRAINING SUMMARY:
  Total Loss: 0.0520
  Contrastive: 1.9734
  Reconstruction: 0.0014
  Topological: 0.0519 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.1203
  Contrastive: 1.9506
  Reconstruction: 0.0014
  Topological: 1.1202 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 69/300 COMPLETE (45.9s)
Train Loss: 0.0520 (C:1.9734, R:0.0014, T:0.0519)
Val Loss:   1.1203 (C:1.9506, R:0.0014, T:1.1202)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 70 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0522 (C:1.9749, R:0.0014, T:0.0521(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0492 (C:1.9703, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0516 (C:1.9641, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0495 (C:1.9744, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0489 (C:1.9726, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0528 (C:1.9721, R:0.0014, T:0.0527(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0516 (C:1.9737, R:0.0014, T:0.0515(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0505 (C:1.9732, R:0.0014, T:0.0504(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0478 (C:1.9767, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0522 (C:1.9759, R:0.0014, T:0.0520(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0507 (C:1.9726, R:0.0014, T:0.0506(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0514 (C:1.9765, R:0.0014, T:0.0512(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0498 (C:1.9783, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0490 (C:1.9704, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0517 (C:1.9690, R:0.0014, T:0.0515(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0498 (C:1.9745, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0581 (C:1.9792, R:0.0014, T:0.0580(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0494 (C:1.9755, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0496 (C:1.9764, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0537 (C:1.9759, R:0.0014, T:0.0535(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0525 (C:1.9753, R:0.0014, T:0.0524(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0519 (C:1.9762, R:0.0014, T:0.0517(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 70 TRAINING SUMMARY:
  Total Loss: 0.0521
  Contrastive: 1.9736
  Reconstruction: 0.0014
  Topological: 0.0519 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.0739
  Contrastive: 1.9499
  Reconstruction: 0.0014
  Topological: 1.0737 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 70/300 COMPLETE (47.4s)
Train Loss: 0.0521 (C:1.9736, R:0.0014, T:0.0519)
Val Loss:   1.0739 (C:1.9499, R:0.0014, T:1.0737)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 71 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0485 (C:1.9720, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0509 (C:1.9747, R:0.0014, T:0.0508(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0531 (C:1.9693, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0472 (C:1.9739, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0533 (C:1.9754, R:0.0014, T:0.0531(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0507 (C:1.9717, R:0.0014, T:0.0506(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0515 (C:1.9704, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0542 (C:1.9749, R:0.0014, T:0.0541(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0458 (C:1.9762, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0540 (C:1.9727, R:0.0014, T:0.0538(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0500 (C:1.9661, R:0.0014, T:0.0499(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0466 (C:1.9710, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0518 (C:1.9718, R:0.0014, T:0.0517(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0541 (C:1.9715, R:0.0014, T:0.0539(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0504 (C:1.9725, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0489 (C:1.9718, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0509 (C:1.9723, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0503 (C:1.9745, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0523 (C:1.9714, R:0.0014, T:0.0521(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0524 (C:1.9668, R:0.0014, T:0.0522(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0489 (C:1.9766, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0523 (C:1.9759, R:0.0014, T:0.0521(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0517

ğŸ“Š EPOCH 71 TRAINING SUMMARY:
  Total Loss: 0.0519
  Contrastive: 1.9734
  Reconstruction: 0.0014
  Topological: 0.0517 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.0907
  Contrastive: 1.9526
  Reconstruction: 0.0014
  Topological: 1.0906 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 71/300 COMPLETE (46.3s)
Train Loss: 0.0519 (C:1.9734, R:0.0014, T:0.0517)
Val Loss:   1.0907 (C:1.9526, R:0.0014, T:1.0906)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 72 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0527 (C:1.9727, R:0.0014, T:0.0526(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0500 (C:1.9713, R:0.0014, T:0.0499(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0516 (C:1.9769, R:0.0014, T:0.0515(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0514 (C:1.9755, R:0.0014, T:0.0513(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0514 (C:1.9709, R:0.0014, T:0.0513(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0502 (C:1.9745, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0532 (C:1.9757, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0516 (C:1.9749, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0541 (C:1.9721, R:0.0014, T:0.0540(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0481 (C:1.9780, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0522 (C:1.9753, R:0.0014, T:0.0520(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0519 (C:1.9797, R:0.0014, T:0.0518(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0512 (C:1.9723, R:0.0014, T:0.0511(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0526 (C:1.9726, R:0.0014, T:0.0525(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0515 (C:1.9740, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0517 (C:1.9716, R:0.0014, T:0.0516(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0530 (C:1.9707, R:0.0014, T:0.0529(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0517 (C:1.9750, R:0.0014, T:0.0515(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0518 (C:1.9726, R:0.0014, T:0.0517(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0553 (C:1.9718, R:0.0014, T:0.0552(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0485 (C:1.9770, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0509 (C:1.9724, R:0.0014, T:0.0508(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 72 TRAINING SUMMARY:
  Total Loss: 0.0523
  Contrastive: 1.9734
  Reconstruction: 0.0014
  Topological: 0.0521 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.0939
  Contrastive: 1.9524
  Reconstruction: 0.0014
  Topological: 1.0938 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 72/300 COMPLETE (45.6s)
Train Loss: 0.0523 (C:1.9734, R:0.0014, T:0.0521)
Val Loss:   1.0939 (C:1.9524, R:0.0014, T:1.0938)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 73 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0533 (C:1.9788, R:0.0014, T:0.0531(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0541 (C:1.9732, R:0.0014, T:0.0539(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0537 (C:1.9738, R:0.0014, T:0.0535(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0498 (C:1.9726, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0516 (C:1.9695, R:0.0014, T:0.0515(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0506 (C:1.9696, R:0.0014, T:0.0505(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0515 (C:1.9769, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0516 (C:1.9747, R:0.0014, T:0.0515(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0508 (C:1.9715, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0521 (C:1.9770, R:0.0014, T:0.0520(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0515 (C:1.9741, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0489 (C:1.9747, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0508 (C:1.9731, R:0.0014, T:0.0506(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0516 (C:1.9694, R:0.0014, T:0.0515(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0530 (C:1.9791, R:0.0014, T:0.0529(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0527 (C:1.9738, R:0.0014, T:0.0526(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0514 (C:1.9733, R:0.0014, T:0.0512(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0528 (C:1.9771, R:0.0014, T:0.0527(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0513 (C:1.9726, R:0.0014, T:0.0511(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0487 (C:1.9734, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0549 (C:1.9748, R:0.0014, T:0.0548(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0540 (C:1.9670, R:0.0014, T:0.0539(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0516

ğŸ“Š EPOCH 73 TRAINING SUMMARY:
  Total Loss: 0.0517
  Contrastive: 1.9739
  Reconstruction: 0.0014
  Topological: 0.0516 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.0928
  Contrastive: 1.9556
  Reconstruction: 0.0014
  Topological: 1.0927 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 73/300 COMPLETE (44.4s)
Train Loss: 0.0517 (C:1.9739, R:0.0014, T:0.0516)
Val Loss:   1.0928 (C:1.9556, R:0.0014, T:1.0927)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 74 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0512 (C:1.9764, R:0.0014, T:0.0510(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0522 (C:1.9740, R:0.0014, T:0.0521(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0531 (C:1.9751, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0543 (C:1.9715, R:0.0014, T:0.0542(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0508 (C:1.9757, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0474 (C:1.9777, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0486 (C:1.9700, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0545 (C:1.9738, R:0.0014, T:0.0543(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0507 (C:1.9754, R:0.0014, T:0.0505(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0521 (C:1.9752, R:0.0014, T:0.0520(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0532 (C:1.9759, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0520 (C:1.9669, R:0.0014, T:0.0519(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0529 (C:1.9770, R:0.0014, T:0.0528(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0527 (C:1.9747, R:0.0014, T:0.0526(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0517 (C:1.9735, R:0.0014, T:0.0516(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0483 (C:1.9766, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0483 (C:1.9739, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0506 (C:1.9769, R:0.0014, T:0.0505(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0513 (C:1.9753, R:0.0014, T:0.0511(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0515 (C:1.9719, R:0.0014, T:0.0513(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0491 (C:1.9718, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0532 (C:1.9630, R:0.0014, T:0.0531(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0516

ğŸ“Š EPOCH 74 TRAINING SUMMARY:
  Total Loss: 0.0517
  Contrastive: 1.9736
  Reconstruction: 0.0014
  Topological: 0.0516 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.1422
  Contrastive: 1.9551
  Reconstruction: 0.0014
  Topological: 1.1421 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 74/300 COMPLETE (45.5s)
Train Loss: 0.0517 (C:1.9736, R:0.0014, T:0.0516)
Val Loss:   1.1422 (C:1.9551, R:0.0014, T:1.1421)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 75 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0507 (C:1.9790, R:0.0014, T:0.0506(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0519 (C:1.9788, R:0.0014, T:0.0518(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0494 (C:1.9734, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0517 (C:1.9778, R:0.0014, T:0.0516(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0511 (C:1.9729, R:0.0014, T:0.0509(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0505 (C:1.9763, R:0.0014, T:0.0504(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0479 (C:1.9738, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0473 (C:1.9753, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0525 (C:1.9670, R:0.0014, T:0.0523(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0559 (C:1.9660, R:0.0014, T:0.0558(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0519 (C:1.9707, R:0.0014, T:0.0517(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0532 (C:1.9765, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0518 (C:1.9739, R:0.0014, T:0.0517(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0496 (C:1.9716, R:0.0014, T:0.0495(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0553 (C:1.9739, R:0.0014, T:0.0552(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0509 (C:1.9769, R:0.0014, T:0.0508(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0516 (C:1.9745, R:0.0014, T:0.0515(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0504 (C:1.9776, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0527 (C:1.9762, R:0.0014, T:0.0526(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0501 (C:1.9769, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0537 (C:1.9734, R:0.0014, T:0.0536(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0533 (C:1.9712, R:0.0014, T:0.0532(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0514

ğŸ“Š EPOCH 75 TRAINING SUMMARY:
  Total Loss: 0.0516
  Contrastive: 1.9738
  Reconstruction: 0.0014
  Topological: 0.0514 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.1026
  Contrastive: 1.9506
  Reconstruction: 0.0014
  Topological: 1.1025 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 75/300 COMPLETE (45.7s)
Train Loss: 0.0516 (C:1.9738, R:0.0014, T:0.0514)
Val Loss:   1.1026 (C:1.9506, R:0.0014, T:1.1025)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 76 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0511 (C:1.9754, R:0.0014, T:0.0509(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0531 (C:1.9749, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0506 (C:1.9712, R:0.0014, T:0.0505(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0516 (C:1.9762, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0534 (C:1.9713, R:0.0014, T:0.0533(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0516 (C:1.9754, R:0.0014, T:0.0515(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0508 (C:1.9708, R:0.0014, T:0.0506(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0516 (C:1.9759, R:0.0014, T:0.0515(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0522 (C:1.9753, R:0.0014, T:0.0520(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0520 (C:1.9733, R:0.0014, T:0.0519(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0501 (C:1.9777, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0478 (C:1.9733, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0537 (C:1.9745, R:0.0014, T:0.0536(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0529 (C:1.9758, R:0.0014, T:0.0527(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0522 (C:1.9707, R:0.0014, T:0.0521(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0500 (C:1.9777, R:0.0014, T:0.0499(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0475 (C:1.9720, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0503 (C:1.9718, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0507 (C:1.9754, R:0.0014, T:0.0505(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0506 (C:1.9733, R:0.0014, T:0.0504(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0531 (C:1.9714, R:0.0014, T:0.0529(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0532 (C:1.9698, R:0.0014, T:0.0531(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0514

ğŸ“Š EPOCH 76 TRAINING SUMMARY:
  Total Loss: 0.0515
  Contrastive: 1.9735
  Reconstruction: 0.0014
  Topological: 0.0514 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.0745
  Contrastive: 1.9527
  Reconstruction: 0.0014
  Topological: 1.0743 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 76/300 COMPLETE (45.1s)
Train Loss: 0.0515 (C:1.9735, R:0.0014, T:0.0514)
Val Loss:   1.0745 (C:1.9527, R:0.0014, T:1.0743)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 77 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0518 (C:1.9754, R:0.0014, T:0.0516(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0518 (C:1.9732, R:0.0014, T:0.0516(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0540 (C:1.9774, R:0.0014, T:0.0538(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0527 (C:1.9757, R:0.0014, T:0.0525(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0539 (C:1.9738, R:0.0014, T:0.0538(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0515 (C:1.9748, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0511 (C:1.9688, R:0.0014, T:0.0510(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0518 (C:1.9700, R:0.0014, T:0.0516(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0532 (C:1.9749, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0493 (C:1.9749, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0505 (C:1.9731, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0504 (C:1.9722, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0528 (C:1.9735, R:0.0014, T:0.0526(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0513 (C:1.9728, R:0.0014, T:0.0511(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0490 (C:1.9689, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0527 (C:1.9735, R:0.0014, T:0.0526(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0492 (C:1.9755, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0496 (C:1.9717, R:0.0014, T:0.0495(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0528 (C:1.9735, R:0.0014, T:0.0527(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0512 (C:1.9668, R:0.0014, T:0.0511(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0500 (C:1.9771, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0529 (C:1.9733, R:0.0014, T:0.0527(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 77 TRAINING SUMMARY:
  Total Loss: 0.0516
  Contrastive: 1.9737
  Reconstruction: 0.0014
  Topological: 0.0515 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.0524
  Contrastive: 1.9536
  Reconstruction: 0.0014
  Topological: 1.0523 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 77/300 COMPLETE (46.2s)
Train Loss: 0.0516 (C:1.9737, R:0.0014, T:0.0515)
Val Loss:   1.0524 (C:1.9536, R:0.0014, T:1.0523)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 78 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0513 (C:1.9756, R:0.0014, T:0.0512(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0500 (C:1.9710, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0521 (C:1.9767, R:0.0014, T:0.0519(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0516 (C:1.9697, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0508 (C:1.9790, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0546 (C:1.9750, R:0.0014, T:0.0545(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0532 (C:1.9707, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0520 (C:1.9725, R:0.0014, T:0.0519(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0516 (C:1.9732, R:0.0014, T:0.0515(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0540 (C:1.9746, R:0.0014, T:0.0539(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0487 (C:1.9721, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0543 (C:1.9719, R:0.0014, T:0.0541(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0499 (C:1.9763, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0503 (C:1.9748, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0522 (C:1.9705, R:0.0014, T:0.0521(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0507 (C:1.9763, R:0.0014, T:0.0506(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0491 (C:1.9753, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0526 (C:1.9739, R:0.0014, T:0.0525(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0469 (C:1.9746, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0498 (C:1.9743, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0504 (C:1.9728, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0514 (C:1.9759, R:0.0014, T:0.0513(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 78 TRAINING SUMMARY:
  Total Loss: 0.0517
  Contrastive: 1.9735
  Reconstruction: 0.0014
  Topological: 0.0515 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.0537
  Contrastive: 1.9508
  Reconstruction: 0.0014
  Topological: 1.0536 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 78/300 COMPLETE (44.9s)
Train Loss: 0.0517 (C:1.9735, R:0.0014, T:0.0515)
Val Loss:   1.0537 (C:1.9508, R:0.0014, T:1.0536)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 79 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0488 (C:1.9691, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0490 (C:1.9727, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0515 (C:1.9725, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0500 (C:1.9735, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0524 (C:1.9751, R:0.0014, T:0.0522(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0502 (C:1.9755, R:0.0014, T:0.0501(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0492 (C:1.9713, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0500 (C:1.9756, R:0.0014, T:0.0499(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0520 (C:1.9704, R:0.0014, T:0.0519(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0540 (C:1.9764, R:0.0014, T:0.0538(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0491 (C:1.9716, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0485 (C:1.9732, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0524 (C:1.9784, R:0.0014, T:0.0523(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0510 (C:1.9752, R:0.0014, T:0.0509(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0516 (C:1.9737, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0513 (C:1.9704, R:0.0014, T:0.0512(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0502 (C:1.9705, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0547 (C:1.9686, R:0.0014, T:0.0546(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0515 (C:1.9649, R:0.0014, T:0.0513(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0505 (C:1.9717, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0547 (C:1.9762, R:0.0014, T:0.0546(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0514 (C:1.9687, R:0.0014, T:0.0513(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0513

ğŸ“Š EPOCH 79 TRAINING SUMMARY:
  Total Loss: 0.0514
  Contrastive: 1.9731
  Reconstruction: 0.0014
  Topological: 0.0513 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.1237
  Contrastive: 1.9450
  Reconstruction: 0.0014
  Topological: 1.1235 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 79/300 COMPLETE (42.9s)
Train Loss: 0.0514 (C:1.9731, R:0.0014, T:0.0513)
Val Loss:   1.1237 (C:1.9450, R:0.0014, T:1.1235)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 80 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0545 (C:1.9728, R:0.0014, T:0.0543(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0543 (C:1.9767, R:0.0014, T:0.0542(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0518 (C:1.9731, R:0.0014, T:0.0516(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0495 (C:1.9693, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0572 (C:1.9749, R:0.0014, T:0.0570(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0502 (C:1.9733, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0534 (C:1.9724, R:0.0014, T:0.0532(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0548 (C:1.9729, R:0.0014, T:0.0546(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0552 (C:1.9715, R:0.0014, T:0.0550(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0519 (C:1.9780, R:0.0014, T:0.0517(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0493 (C:1.9779, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0541 (C:1.9746, R:0.0014, T:0.0539(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0517 (C:1.9706, R:0.0014, T:0.0516(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0481 (C:1.9746, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0515 (C:1.9730, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0519 (C:1.9707, R:0.0014, T:0.0518(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0516 (C:1.9670, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0491 (C:1.9742, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0532 (C:1.9727, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0548 (C:1.9771, R:0.0014, T:0.0547(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0523 (C:1.9748, R:0.0014, T:0.0522(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0531 (C:1.9778, R:0.0014, T:0.0529(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 80 TRAINING SUMMARY:
  Total Loss: 0.0516
  Contrastive: 1.9732
  Reconstruction: 0.0014
  Topological: 0.0515 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.0693
  Contrastive: 1.9505
  Reconstruction: 0.0014
  Topological: 1.0692 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 80/300 COMPLETE (42.9s)
Train Loss: 0.0516 (C:1.9732, R:0.0014, T:0.0515)
Val Loss:   1.0693 (C:1.9505, R:0.0014, T:1.0692)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 81 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0515 (C:1.9692, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0498 (C:1.9677, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0490 (C:1.9763, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0490 (C:1.9765, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0501 (C:1.9712, R:0.0014, T:0.0499(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0491 (C:1.9727, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0524 (C:1.9734, R:0.0014, T:0.0522(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0541 (C:1.9706, R:0.0014, T:0.0540(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0487 (C:1.9740, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0518 (C:1.9728, R:0.0014, T:0.0516(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0495 (C:1.9741, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0502 (C:1.9748, R:0.0014, T:0.0501(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0523 (C:1.9722, R:0.0014, T:0.0522(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0471 (C:1.9712, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0533 (C:1.9681, R:0.0014, T:0.0531(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0495 (C:1.9693, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0525 (C:1.9751, R:0.0014, T:0.0524(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0512 (C:1.9729, R:0.0014, T:0.0511(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0513 (C:1.9786, R:0.0014, T:0.0512(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0524 (C:1.9751, R:0.0014, T:0.0523(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0514 (C:1.9754, R:0.0014, T:0.0513(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0494 (C:1.9749, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0510

ğŸ“Š EPOCH 81 TRAINING SUMMARY:
  Total Loss: 0.0512
  Contrastive: 1.9732
  Reconstruction: 0.0014
  Topological: 0.0510 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.0668
  Contrastive: 1.9526
  Reconstruction: 0.0014
  Topological: 1.0666 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 81/300 COMPLETE (43.6s)
Train Loss: 0.0512 (C:1.9732, R:0.0014, T:0.0510)
Val Loss:   1.0668 (C:1.9526, R:0.0014, T:1.0666)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 82 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0528 (C:1.9781, R:0.0014, T:0.0526(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0521 (C:1.9764, R:0.0014, T:0.0520(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0511 (C:1.9711, R:0.0014, T:0.0509(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0503 (C:1.9745, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0497 (C:1.9746, R:0.0014, T:0.0495(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0479 (C:1.9738, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0497 (C:1.9686, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0557 (C:1.9767, R:0.0014, T:0.0556(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0519 (C:1.9701, R:0.0014, T:0.0518(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0500 (C:1.9709, R:0.0014, T:0.0499(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0501 (C:1.9689, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0487 (C:1.9735, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0539 (C:1.9709, R:0.0014, T:0.0538(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0495 (C:1.9719, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0542 (C:1.9718, R:0.0014, T:0.0541(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0515 (C:1.9759, R:0.0014, T:0.0513(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0500 (C:1.9747, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0543 (C:1.9733, R:0.0014, T:0.0542(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0508 (C:1.9755, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0502 (C:1.9729, R:0.0014, T:0.0501(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0528 (C:1.9674, R:0.0014, T:0.0527(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0508 (C:1.9704, R:0.0014, T:0.0506(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 82 TRAINING SUMMARY:
  Total Loss: 0.0513
  Contrastive: 1.9733
  Reconstruction: 0.0014
  Topological: 0.0512 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.0549
  Contrastive: 1.9516
  Reconstruction: 0.0014
  Topological: 1.0548 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 82/300 COMPLETE (45.0s)
Train Loss: 0.0513 (C:1.9733, R:0.0014, T:0.0512)
Val Loss:   1.0549 (C:1.9516, R:0.0014, T:1.0548)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 83 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0522 (C:1.9742, R:0.0014, T:0.0521(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0480 (C:1.9774, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0498 (C:1.9736, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0519 (C:1.9698, R:0.0014, T:0.0518(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0483 (C:1.9745, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0539 (C:1.9720, R:0.0014, T:0.0538(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0501 (C:1.9716, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0484 (C:1.9715, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0519 (C:1.9758, R:0.0014, T:0.0518(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0536 (C:1.9734, R:0.0014, T:0.0535(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0509 (C:1.9710, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0471 (C:1.9681, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0509 (C:1.9740, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0543 (C:1.9736, R:0.0014, T:0.0541(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0476 (C:1.9716, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0560 (C:1.9697, R:0.0014, T:0.0559(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0501 (C:1.9780, R:0.0014, T:0.0499(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0480 (C:1.9693, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0505 (C:1.9722, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0499 (C:1.9723, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0501 (C:1.9746, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0529 (C:1.9778, R:0.0014, T:0.0527(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 83 TRAINING SUMMARY:
  Total Loss: 0.0512
  Contrastive: 1.9731
  Reconstruction: 0.0014
  Topological: 0.0511 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.0649
  Contrastive: 1.9512
  Reconstruction: 0.0014
  Topological: 1.0648 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 83/300 COMPLETE (43.8s)
Train Loss: 0.0512 (C:1.9731, R:0.0014, T:0.0511)
Val Loss:   1.0649 (C:1.9512, R:0.0014, T:1.0648)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 84 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0506 (C:1.9724, R:0.0014, T:0.0505(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0531 (C:1.9766, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0551 (C:1.9782, R:0.0014, T:0.0549(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0504 (C:1.9711, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0494 (C:1.9736, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0512 (C:1.9730, R:0.0014, T:0.0510(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0514 (C:1.9711, R:0.0014, T:0.0512(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0480 (C:1.9740, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0522 (C:1.9718, R:0.0014, T:0.0521(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0479 (C:1.9641, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0492 (C:1.9733, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0503 (C:1.9750, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0515 (C:1.9737, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0509 (C:1.9679, R:0.0014, T:0.0508(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0551 (C:1.9719, R:0.0014, T:0.0550(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0508 (C:1.9749, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0505 (C:1.9701, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0514 (C:1.9705, R:0.0014, T:0.0513(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0510 (C:1.9819, R:0.0014, T:0.0509(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0508 (C:1.9778, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0515 (C:1.9720, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0486 (C:1.9729, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0510

ğŸ“Š EPOCH 84 TRAINING SUMMARY:
  Total Loss: 0.0511
  Contrastive: 1.9729
  Reconstruction: 0.0014
  Topological: 0.0510 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.0532
  Contrastive: 1.9526
  Reconstruction: 0.0014
  Topological: 1.0531 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 84/300 COMPLETE (43.7s)
Train Loss: 0.0511 (C:1.9729, R:0.0014, T:0.0510)
Val Loss:   1.0532 (C:1.9526, R:0.0014, T:1.0531)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 85 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0501 (C:1.9735, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0523 (C:1.9740, R:0.0014, T:0.0522(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0532 (C:1.9770, R:0.0014, T:0.0531(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0495 (C:1.9730, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0487 (C:1.9707, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0527 (C:1.9693, R:0.0014, T:0.0526(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0497 (C:1.9711, R:0.0014, T:0.0495(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0519 (C:1.9719, R:0.0014, T:0.0517(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0484 (C:1.9737, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0491 (C:1.9742, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0495 (C:1.9730, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0509 (C:1.9719, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0494 (C:1.9759, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0509 (C:1.9699, R:0.0014, T:0.0508(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0498 (C:1.9704, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0531 (C:1.9733, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0519 (C:1.9708, R:0.0014, T:0.0518(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0542 (C:1.9736, R:0.0014, T:0.0540(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0523 (C:1.9786, R:0.0014, T:0.0522(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0513 (C:1.9745, R:0.0014, T:0.0512(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0509 (C:1.9726, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0504 (C:1.9724, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0507

ğŸ“Š EPOCH 85 TRAINING SUMMARY:
  Total Loss: 0.0508
  Contrastive: 1.9730
  Reconstruction: 0.0014
  Topological: 0.0507 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.0264
  Contrastive: 1.9479
  Reconstruction: 0.0014
  Topological: 1.0263 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 85/300 COMPLETE (43.8s)
Train Loss: 0.0508 (C:1.9730, R:0.0014, T:0.0507)
Val Loss:   1.0264 (C:1.9479, R:0.0014, T:1.0263)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 86 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0520 (C:1.9719, R:0.0014, T:0.0518(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0510 (C:1.9785, R:0.0014, T:0.0509(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0500 (C:1.9696, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0514 (C:1.9683, R:0.0014, T:0.0512(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0511 (C:1.9747, R:0.0014, T:0.0510(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0573 (C:1.9754, R:0.0014, T:0.0572(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0495 (C:1.9708, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0504 (C:1.9712, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0499 (C:1.9730, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0488 (C:1.9718, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0492 (C:1.9748, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0510 (C:1.9727, R:0.0014, T:0.0509(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0527 (C:1.9726, R:0.0014, T:0.0526(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0517 (C:1.9703, R:0.0014, T:0.0516(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0521 (C:1.9742, R:0.0014, T:0.0520(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0532 (C:1.9724, R:0.0014, T:0.0531(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0513 (C:1.9731, R:0.0014, T:0.0512(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0513 (C:1.9754, R:0.0014, T:0.0511(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0582 (C:1.9767, R:0.0014, T:0.0581(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0498 (C:1.9763, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0500 (C:1.9739, R:0.0014, T:0.0499(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0520 (C:1.9715, R:0.0014, T:0.0518(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 86 TRAINING SUMMARY:
  Total Loss: 0.0510
  Contrastive: 1.9730
  Reconstruction: 0.0014
  Topological: 0.0509 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.0498
  Contrastive: 1.9467
  Reconstruction: 0.0014
  Topological: 1.0497 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 86/300 COMPLETE (44.7s)
Train Loss: 0.0510 (C:1.9730, R:0.0014, T:0.0509)
Val Loss:   1.0498 (C:1.9467, R:0.0014, T:1.0497)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 87 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0515 (C:1.9724, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0536 (C:1.9704, R:0.0014, T:0.0534(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0527 (C:1.9700, R:0.0014, T:0.0525(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0500 (C:1.9741, R:0.0014, T:0.0499(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0500 (C:1.9772, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0519 (C:1.9700, R:0.0014, T:0.0517(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0518 (C:1.9735, R:0.0014, T:0.0517(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0511 (C:1.9727, R:0.0014, T:0.0510(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0501 (C:1.9671, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0535 (C:1.9736, R:0.0014, T:0.0534(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0515 (C:1.9712, R:0.0014, T:0.0513(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0516 (C:1.9773, R:0.0014, T:0.0515(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0472 (C:1.9708, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0516 (C:1.9710, R:0.0014, T:0.0515(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0530 (C:1.9779, R:0.0014, T:0.0529(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0534 (C:1.9705, R:0.0014, T:0.0532(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0476 (C:1.9748, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0520 (C:1.9739, R:0.0014, T:0.0519(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0493 (C:1.9735, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0499 (C:1.9749, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0512 (C:1.9699, R:0.0014, T:0.0511(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0517 (C:1.9747, R:0.0014, T:0.0516(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 87 TRAINING SUMMARY:
  Total Loss: 0.0508
  Contrastive: 1.9731
  Reconstruction: 0.0014
  Topological: 0.0507 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.0624
  Contrastive: 1.9459
  Reconstruction: 0.0014
  Topological: 1.0622 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 87/300 COMPLETE (43.5s)
Train Loss: 0.0508 (C:1.9731, R:0.0014, T:0.0507)
Val Loss:   1.0624 (C:1.9459, R:0.0014, T:1.0622)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 88 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0520 (C:1.9728, R:0.0014, T:0.0518(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0531 (C:1.9761, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0542 (C:1.9714, R:0.0014, T:0.0541(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0492 (C:1.9756, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0510 (C:1.9713, R:0.0014, T:0.0509(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0522 (C:1.9741, R:0.0014, T:0.0521(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0523 (C:1.9718, R:0.0014, T:0.0522(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0505 (C:1.9717, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0520 (C:1.9709, R:0.0014, T:0.0518(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0522 (C:1.9749, R:0.0014, T:0.0521(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0531 (C:1.9720, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0523 (C:1.9673, R:0.0014, T:0.0522(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0526 (C:1.9720, R:0.0014, T:0.0525(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0525 (C:1.9682, R:0.0014, T:0.0523(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0510 (C:1.9690, R:0.0014, T:0.0508(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0509 (C:1.9767, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0504 (C:1.9705, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0528 (C:1.9719, R:0.0014, T:0.0527(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0534 (C:1.9718, R:0.0014, T:0.0532(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0493 (C:1.9756, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0509 (C:1.9733, R:0.0014, T:0.0508(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0498 (C:1.9732, R:0.0014, T:0.0497(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 88 TRAINING SUMMARY:
  Total Loss: 0.0512
  Contrastive: 1.9729
  Reconstruction: 0.0014
  Topological: 0.0511 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.0266
  Contrastive: 1.9477
  Reconstruction: 0.0014
  Topological: 1.0264 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 88/300 COMPLETE (44.1s)
Train Loss: 0.0512 (C:1.9729, R:0.0014, T:0.0511)
Val Loss:   1.0266 (C:1.9477, R:0.0014, T:1.0264)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 89 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0516 (C:1.9719, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0482 (C:1.9716, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0483 (C:1.9784, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0536 (C:1.9718, R:0.0014, T:0.0535(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0509 (C:1.9704, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0498 (C:1.9710, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0499 (C:1.9766, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0497 (C:1.9748, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0509 (C:1.9691, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0520 (C:1.9752, R:0.0014, T:0.0519(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0508 (C:1.9735, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0503 (C:1.9726, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0484 (C:1.9736, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0532 (C:1.9732, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0504 (C:1.9683, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0511 (C:1.9693, R:0.0014, T:0.0509(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0520 (C:1.9747, R:0.0014, T:0.0519(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0529 (C:1.9748, R:0.0014, T:0.0527(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0535 (C:1.9733, R:0.0014, T:0.0534(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0516 (C:1.9697, R:0.0014, T:0.0515(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0489 (C:1.9776, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0491 (C:1.9750, R:0.0014, T:0.0490(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 89 TRAINING SUMMARY:
  Total Loss: 0.0509
  Contrastive: 1.9731
  Reconstruction: 0.0014
  Topological: 0.0507 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.0477
  Contrastive: 1.9486
  Reconstruction: 0.0014
  Topological: 1.0476 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 89/300 COMPLETE (44.7s)
Train Loss: 0.0509 (C:1.9731, R:0.0014, T:0.0507)
Val Loss:   1.0477 (C:1.9486, R:0.0014, T:1.0476)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 90 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0508 (C:1.9734, R:0.0014, T:0.0506(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0530 (C:1.9777, R:0.0014, T:0.0529(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0509 (C:1.9714, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0545 (C:1.9707, R:0.0014, T:0.0544(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0514 (C:1.9727, R:0.0014, T:0.0512(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0511 (C:1.9747, R:0.0014, T:0.0510(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0515 (C:1.9736, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0503 (C:1.9645, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0528 (C:1.9695, R:0.0014, T:0.0527(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0516 (C:1.9726, R:0.0014, T:0.0515(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0518 (C:1.9766, R:0.0014, T:0.0516(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0516 (C:1.9769, R:0.0014, T:0.0515(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0505 (C:1.9729, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0517 (C:1.9767, R:0.0014, T:0.0516(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0505 (C:1.9683, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0496 (C:1.9716, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0508 (C:1.9706, R:0.0014, T:0.0506(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0501 (C:1.9732, R:0.0014, T:0.0499(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0516 (C:1.9747, R:0.0014, T:0.0515(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0501 (C:1.9705, R:0.0014, T:0.0499(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0499 (C:1.9711, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0534 (C:1.9727, R:0.0014, T:0.0532(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0506

ğŸ“Š EPOCH 90 TRAINING SUMMARY:
  Total Loss: 0.0508
  Contrastive: 1.9730
  Reconstruction: 0.0014
  Topological: 0.0506 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.0471
  Contrastive: 1.9452
  Reconstruction: 0.0014
  Topological: 1.0470 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 90/300 COMPLETE (44.8s)
Train Loss: 0.0508 (C:1.9730, R:0.0014, T:0.0506)
Val Loss:   1.0471 (C:1.9452, R:0.0014, T:1.0470)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 91 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0506 (C:1.9708, R:0.0014, T:0.0505(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0501 (C:1.9747, R:0.0014, T:0.0499(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0509 (C:1.9733, R:0.0014, T:0.0508(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0490 (C:1.9755, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0506 (C:1.9759, R:0.0014, T:0.0504(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0502 (C:1.9757, R:0.0014, T:0.0501(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0510 (C:1.9692, R:0.0014, T:0.0509(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0487 (C:1.9729, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0504 (C:1.9717, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0512 (C:1.9772, R:0.0014, T:0.0511(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0495 (C:1.9730, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0511 (C:1.9731, R:0.0014, T:0.0510(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0486 (C:1.9762, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0495 (C:1.9668, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0476 (C:1.9733, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0526 (C:1.9748, R:0.0014, T:0.0525(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0510 (C:1.9740, R:0.0014, T:0.0509(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0518 (C:1.9746, R:0.0014, T:0.0517(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0499 (C:1.9733, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0514 (C:1.9700, R:0.0014, T:0.0512(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0485 (C:1.9782, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0526 (C:1.9736, R:0.0014, T:0.0524(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 91 TRAINING SUMMARY:
  Total Loss: 0.0508
  Contrastive: 1.9732
  Reconstruction: 0.0014
  Topological: 0.0507 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.0849
  Contrastive: 1.9504
  Reconstruction: 0.0014
  Topological: 1.0847 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 91/300 COMPLETE (43.7s)
Train Loss: 0.0508 (C:1.9732, R:0.0014, T:0.0507)
Val Loss:   1.0849 (C:1.9504, R:0.0014, T:1.0847)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 92 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0546 (C:1.9714, R:0.0014, T:0.0545(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0517 (C:1.9715, R:0.0014, T:0.0516(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0507 (C:1.9778, R:0.0014, T:0.0506(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0499 (C:1.9713, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0506 (C:1.9690, R:0.0014, T:0.0504(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0513 (C:1.9743, R:0.0014, T:0.0511(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0476 (C:1.9726, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0470 (C:1.9749, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0482 (C:1.9715, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0518 (C:1.9738, R:0.0014, T:0.0516(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0553 (C:1.9760, R:0.0014, T:0.0551(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0529 (C:1.9763, R:0.0014, T:0.0527(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0482 (C:1.9740, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0504 (C:1.9702, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0473 (C:1.9701, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0482 (C:1.9700, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0495 (C:1.9748, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0500 (C:1.9710, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0547 (C:1.9686, R:0.0014, T:0.0546(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0517 (C:1.9681, R:0.0014, T:0.0516(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0520 (C:1.9754, R:0.0014, T:0.0518(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0531 (C:1.9759, R:0.0014, T:0.0529(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0505

ğŸ“Š EPOCH 92 TRAINING SUMMARY:
  Total Loss: 0.0507
  Contrastive: 1.9729
  Reconstruction: 0.0014
  Topological: 0.0505 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.0493
  Contrastive: 1.9438
  Reconstruction: 0.0014
  Topological: 1.0491 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 92/300 COMPLETE (44.2s)
Train Loss: 0.0507 (C:1.9729, R:0.0014, T:0.0505)
Val Loss:   1.0493 (C:1.9438, R:0.0014, T:1.0491)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 93 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0493 (C:1.9717, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0509 (C:1.9677, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0478 (C:1.9732, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0498 (C:1.9753, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0474 (C:1.9728, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0491 (C:1.9772, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0477 (C:1.9715, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0475 (C:1.9718, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0495 (C:1.9741, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0498 (C:1.9696, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0505 (C:1.9752, R:0.0014, T:0.0504(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0531 (C:1.9715, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0504 (C:1.9721, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0524 (C:1.9694, R:0.0014, T:0.0523(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0509 (C:1.9757, R:0.0014, T:0.0508(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0496 (C:1.9723, R:0.0014, T:0.0495(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0493 (C:1.9744, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0515 (C:1.9670, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0509 (C:1.9681, R:0.0014, T:0.0508(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0516 (C:1.9753, R:0.0014, T:0.0515(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0523 (C:1.9779, R:0.0014, T:0.0522(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0531 (C:1.9750, R:0.0014, T:0.0530(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0505

ğŸ“Š EPOCH 93 TRAINING SUMMARY:
  Total Loss: 0.0506
  Contrastive: 1.9723
  Reconstruction: 0.0014
  Topological: 0.0505 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.0250
  Contrastive: 1.9515
  Reconstruction: 0.0014
  Topological: 1.0249 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 93/300 COMPLETE (43.8s)
Train Loss: 0.0506 (C:1.9723, R:0.0014, T:0.0505)
Val Loss:   1.0250 (C:1.9515, R:0.0014, T:1.0249)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 94 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0498 (C:1.9722, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0489 (C:1.9705, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0485 (C:1.9748, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0499 (C:1.9707, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0485 (C:1.9681, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0488 (C:1.9731, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0499 (C:1.9703, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0496 (C:1.9704, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0499 (C:1.9772, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0471 (C:1.9758, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0483 (C:1.9714, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0517 (C:1.9733, R:0.0014, T:0.0516(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0525 (C:1.9704, R:0.0014, T:0.0524(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0514 (C:1.9699, R:0.0014, T:0.0513(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0484 (C:1.9768, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0502 (C:1.9728, R:0.0014, T:0.0501(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0494 (C:1.9742, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0503 (C:1.9714, R:0.0014, T:0.0501(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0501 (C:1.9755, R:0.0014, T:0.0499(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0561 (C:1.9717, R:0.0014, T:0.0560(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0483 (C:1.9761, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0480 (C:1.9714, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0501

ğŸ“Š EPOCH 94 TRAINING SUMMARY:
  Total Loss: 0.0502
  Contrastive: 1.9726
  Reconstruction: 0.0014
  Topological: 0.0501 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.0054
  Contrastive: 1.9501
  Reconstruction: 0.0014
  Topological: 1.0052 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 94/300 COMPLETE (43.5s)
Train Loss: 0.0502 (C:1.9726, R:0.0014, T:0.0501)
Val Loss:   1.0054 (C:1.9501, R:0.0014, T:1.0052)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 95 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0464 (C:1.9721, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0513 (C:1.9660, R:0.0014, T:0.0512(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0479 (C:1.9713, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0504 (C:1.9733, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0492 (C:1.9692, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0462 (C:1.9734, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0500 (C:1.9746, R:0.0014, T:0.0499(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0499 (C:1.9754, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0493 (C:1.9726, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0485 (C:1.9629, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0500 (C:1.9690, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0498 (C:1.9715, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0483 (C:1.9737, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0493 (C:1.9724, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0483 (C:1.9673, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0518 (C:1.9751, R:0.0014, T:0.0517(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0528 (C:1.9704, R:0.0014, T:0.0527(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0513 (C:1.9712, R:0.0014, T:0.0511(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0496 (C:1.9713, R:0.0014, T:0.0495(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0527 (C:1.9727, R:0.0014, T:0.0526(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0509 (C:1.9728, R:0.0014, T:0.0508(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0514 (C:1.9702, R:0.0014, T:0.0513(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0500

ğŸ“Š EPOCH 95 TRAINING SUMMARY:
  Total Loss: 0.0501
  Contrastive: 1.9719
  Reconstruction: 0.0014
  Topological: 0.0500 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.0172
  Contrastive: 1.9465
  Reconstruction: 0.0014
  Topological: 1.0171 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 95/300 COMPLETE (43.6s)
Train Loss: 0.0501 (C:1.9719, R:0.0014, T:0.0500)
Val Loss:   1.0172 (C:1.9465, R:0.0014, T:1.0171)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 96 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0510 (C:1.9707, R:0.0014, T:0.0508(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0523 (C:1.9727, R:0.0014, T:0.0521(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0500 (C:1.9658, R:0.0014, T:0.0499(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0520 (C:1.9719, R:0.0014, T:0.0518(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0475 (C:1.9768, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0502 (C:1.9736, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0493 (C:1.9739, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0510 (C:1.9752, R:0.0014, T:0.0509(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0483 (C:1.9714, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0491 (C:1.9685, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0470 (C:1.9708, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0462 (C:1.9721, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0513 (C:1.9682, R:0.0014, T:0.0512(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0500 (C:1.9708, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0539 (C:1.9725, R:0.0014, T:0.0537(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0511 (C:1.9713, R:0.0014, T:0.0510(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0453 (C:1.9744, R:0.0014, T:0.0451(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0500 (C:1.9761, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0484 (C:1.9738, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0533 (C:1.9719, R:0.0014, T:0.0532(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0532 (C:1.9761, R:0.0014, T:0.0531(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0517 (C:1.9683, R:0.0014, T:0.0516(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 96 TRAINING SUMMARY:
  Total Loss: 0.0503
  Contrastive: 1.9723
  Reconstruction: 0.0014
  Topological: 0.0502 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.0169
  Contrastive: 1.9454
  Reconstruction: 0.0014
  Topological: 1.0167 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 96/300 COMPLETE (44.3s)
Train Loss: 0.0503 (C:1.9723, R:0.0014, T:0.0502)
Val Loss:   1.0169 (C:1.9454, R:0.0014, T:1.0167)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 97 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0502 (C:1.9657, R:0.0014, T:0.0501(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0492 (C:1.9692, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0533 (C:1.9721, R:0.0014, T:0.0532(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0501 (C:1.9667, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0495 (C:1.9781, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0488 (C:1.9717, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0493 (C:1.9704, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0532 (C:1.9755, R:0.0014, T:0.0531(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0517 (C:1.9694, R:0.0014, T:0.0516(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0521 (C:1.9738, R:0.0014, T:0.0520(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0482 (C:1.9758, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0515 (C:1.9694, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0511 (C:1.9712, R:0.0014, T:0.0509(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0502 (C:1.9710, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0496 (C:1.9719, R:0.0014, T:0.0495(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0512 (C:1.9758, R:0.0014, T:0.0511(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0492 (C:1.9718, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0512 (C:1.9757, R:0.0014, T:0.0511(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0518 (C:1.9706, R:0.0014, T:0.0517(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0491 (C:1.9754, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0499 (C:1.9700, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0483 (C:1.9774, R:0.0014, T:0.0482(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 97 TRAINING SUMMARY:
  Total Loss: 0.0502
  Contrastive: 1.9723
  Reconstruction: 0.0014
  Topological: 0.0501 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 1.0098
  Contrastive: 1.9524
  Reconstruction: 0.0014
  Topological: 1.0096 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 97/300 COMPLETE (43.8s)
Train Loss: 0.0502 (C:1.9723, R:0.0014, T:0.0501)
Val Loss:   1.0098 (C:1.9524, R:0.0014, T:1.0096)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 98 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0470 (C:1.9753, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0528 (C:1.9718, R:0.0014, T:0.0527(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0509 (C:1.9696, R:0.0014, T:0.0508(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0488 (C:1.9719, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0515 (C:1.9786, R:0.0014, T:0.0513(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0530 (C:1.9717, R:0.0014, T:0.0529(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0551 (C:1.9716, R:0.0014, T:0.0550(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0532 (C:1.9722, R:0.0014, T:0.0531(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0490 (C:1.9707, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0503 (C:1.9715, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0497 (C:1.9750, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0504 (C:1.9752, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0507 (C:1.9714, R:0.0014, T:0.0506(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0476 (C:1.9710, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0476 (C:1.9764, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0481 (C:1.9746, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0487 (C:1.9706, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0500 (C:1.9691, R:0.0014, T:0.0499(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0506 (C:1.9643, R:0.0014, T:0.0505(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0456 (C:1.9679, R:0.0014, T:0.0454(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0487 (C:1.9744, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0492 (C:1.9720, R:0.0014, T:0.0491(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 98 TRAINING SUMMARY:
  Total Loss: 0.0503
  Contrastive: 1.9724
  Reconstruction: 0.0014
  Topological: 0.0501 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.9689
  Contrastive: 1.9511
  Reconstruction: 0.0014
  Topological: 0.9687 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 98/300 COMPLETE (44.4s)
Train Loss: 0.0503 (C:1.9724, R:0.0014, T:0.0501)
Val Loss:   0.9689 (C:1.9511, R:0.0014, T:0.9687)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 99 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0455 (C:1.9727, R:0.0014, T:0.0453(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0524 (C:1.9735, R:0.0014, T:0.0522(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0519 (C:1.9676, R:0.0014, T:0.0517(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0520 (C:1.9670, R:0.0014, T:0.0518(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0514 (C:1.9724, R:0.0014, T:0.0512(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0527 (C:1.9706, R:0.0014, T:0.0526(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0459 (C:1.9762, R:0.0014, T:0.0458(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0476 (C:1.9730, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0481 (C:1.9752, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0481 (C:1.9722, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0475 (C:1.9684, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0503 (C:1.9770, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0527 (C:1.9756, R:0.0014, T:0.0525(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0481 (C:1.9713, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0505 (C:1.9738, R:0.0014, T:0.0504(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0480 (C:1.9698, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0499 (C:1.9766, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0474 (C:1.9695, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0496 (C:1.9740, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0520 (C:1.9726, R:0.0014, T:0.0519(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0509 (C:1.9663, R:0.0014, T:0.0508(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0513 (C:1.9753, R:0.0014, T:0.0511(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0500

ğŸ“Š EPOCH 99 TRAINING SUMMARY:
  Total Loss: 0.0501
  Contrastive: 1.9722
  Reconstruction: 0.0014
  Topological: 0.0500 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.9637
  Contrastive: 1.9488
  Reconstruction: 0.0014
  Topological: 0.9635 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 99/300 COMPLETE (43.9s)
Train Loss: 0.0501 (C:1.9722, R:0.0014, T:0.0500)
Val Loss:   0.9637 (C:1.9488, R:0.0014, T:0.9635)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 100 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0498 (C:1.9728, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0490 (C:1.9718, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0496 (C:1.9758, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0494 (C:1.9694, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0495 (C:1.9760, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0477 (C:1.9740, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0533 (C:1.9660, R:0.0014, T:0.0531(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0523 (C:1.9742, R:0.0014, T:0.0522(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0505 (C:1.9712, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0503 (C:1.9706, R:0.0014, T:0.0501(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0514 (C:1.9737, R:0.0014, T:0.0512(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0518 (C:1.9740, R:0.0014, T:0.0517(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0526 (C:1.9702, R:0.0014, T:0.0524(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0517 (C:1.9724, R:0.0014, T:0.0516(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0485 (C:1.9696, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0469 (C:1.9726, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0486 (C:1.9741, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0553 (C:1.9722, R:0.0014, T:0.0551(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0485 (C:1.9687, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0505 (C:1.9659, R:0.0014, T:0.0504(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0488 (C:1.9704, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0490 (C:1.9757, R:0.0014, T:0.0489(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 100 TRAINING SUMMARY:
  Total Loss: 0.0503
  Contrastive: 1.9724
  Reconstruction: 0.0014
  Topological: 0.0502 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.9903
  Contrastive: 1.9492
  Reconstruction: 0.0014
  Topological: 0.9901 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 100/300 COMPLETE (44.7s)
Train Loss: 0.0503 (C:1.9724, R:0.0014, T:0.0502)
Val Loss:   0.9903 (C:1.9492, R:0.0014, T:0.9901)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 101 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0477 (C:1.9766, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0516 (C:1.9715, R:0.0014, T:0.0515(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0525 (C:1.9687, R:0.0014, T:0.0523(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0486 (C:1.9707, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0487 (C:1.9756, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0525 (C:1.9733, R:0.0014, T:0.0524(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0482 (C:1.9723, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0513 (C:1.9740, R:0.0014, T:0.0512(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0471 (C:1.9770, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0527 (C:1.9711, R:0.0014, T:0.0525(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0506 (C:1.9732, R:0.0014, T:0.0504(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0489 (C:1.9754, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0475 (C:1.9687, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0498 (C:1.9710, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0521 (C:1.9733, R:0.0014, T:0.0519(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0523 (C:1.9724, R:0.0014, T:0.0521(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0484 (C:1.9720, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0490 (C:1.9719, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0482 (C:1.9711, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0517 (C:1.9732, R:0.0014, T:0.0516(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0502 (C:1.9693, R:0.0014, T:0.0501(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0492 (C:1.9730, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0499

ğŸ“Š EPOCH 101 TRAINING SUMMARY:
  Total Loss: 0.0500
  Contrastive: 1.9722
  Reconstruction: 0.0014
  Topological: 0.0499 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.9963
  Contrastive: 1.9514
  Reconstruction: 0.0014
  Topological: 0.9962 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 101/300 COMPLETE (44.9s)
Train Loss: 0.0500 (C:1.9722, R:0.0014, T:0.0499)
Val Loss:   0.9963 (C:1.9514, R:0.0014, T:0.9962)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 102 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0464 (C:1.9751, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0495 (C:1.9716, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0488 (C:1.9772, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0475 (C:1.9673, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0482 (C:1.9676, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0496 (C:1.9738, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0487 (C:1.9642, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0512 (C:1.9664, R:0.0014, T:0.0510(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0499 (C:1.9755, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0503 (C:1.9711, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0495 (C:1.9755, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0515 (C:1.9710, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0504 (C:1.9770, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0507 (C:1.9757, R:0.0014, T:0.0506(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0477 (C:1.9732, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0459 (C:1.9748, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0492 (C:1.9735, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0470 (C:1.9748, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0526 (C:1.9714, R:0.0014, T:0.0524(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0498 (C:1.9671, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0459 (C:1.9713, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0491 (C:1.9715, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0499

ğŸ“Š EPOCH 102 TRAINING SUMMARY:
  Total Loss: 0.0500
  Contrastive: 1.9722
  Reconstruction: 0.0014
  Topological: 0.0499 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.9746
  Contrastive: 1.9504
  Reconstruction: 0.0014
  Topological: 0.9745 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 102/300 COMPLETE (43.7s)
Train Loss: 0.0500 (C:1.9722, R:0.0014, T:0.0499)
Val Loss:   0.9746 (C:1.9504, R:0.0014, T:0.9745)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 103 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0474 (C:1.9789, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0483 (C:1.9727, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0473 (C:1.9711, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0524 (C:1.9763, R:0.0014, T:0.0523(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0497 (C:1.9716, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0479 (C:1.9742, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0510 (C:1.9744, R:0.0014, T:0.0509(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0484 (C:1.9739, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0480 (C:1.9735, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0490 (C:1.9697, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0512 (C:1.9726, R:0.0014, T:0.0510(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0488 (C:1.9701, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0504 (C:1.9722, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0531 (C:1.9741, R:0.0014, T:0.0529(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0494 (C:1.9726, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0515 (C:1.9679, R:0.0014, T:0.0513(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0518 (C:1.9744, R:0.0014, T:0.0517(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0512 (C:1.9719, R:0.0014, T:0.0511(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0520 (C:1.9769, R:0.0014, T:0.0518(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0503 (C:1.9720, R:0.0014, T:0.0501(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0530 (C:1.9694, R:0.0014, T:0.0529(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0475 (C:1.9764, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0497

ğŸ“Š EPOCH 103 TRAINING SUMMARY:
  Total Loss: 0.0498
  Contrastive: 1.9726
  Reconstruction: 0.0014
  Topological: 0.0497 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.9730
  Contrastive: 1.9453
  Reconstruction: 0.0014
  Topological: 0.9729 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 103/300 COMPLETE (43.8s)
Train Loss: 0.0498 (C:1.9726, R:0.0014, T:0.0497)
Val Loss:   0.9730 (C:1.9453, R:0.0014, T:0.9729)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 104 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0487 (C:1.9696, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0480 (C:1.9721, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0511 (C:1.9755, R:0.0014, T:0.0509(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0485 (C:1.9736, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0492 (C:1.9674, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0484 (C:1.9734, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0482 (C:1.9733, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0509 (C:1.9706, R:0.0014, T:0.0508(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0514 (C:1.9695, R:0.0014, T:0.0513(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0521 (C:1.9704, R:0.0014, T:0.0519(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0474 (C:1.9763, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0489 (C:1.9742, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0485 (C:1.9766, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0527 (C:1.9691, R:0.0014, T:0.0526(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0483 (C:1.9728, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0489 (C:1.9728, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0533 (C:1.9684, R:0.0014, T:0.0532(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0495 (C:1.9760, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0483 (C:1.9686, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0463 (C:1.9756, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0504 (C:1.9759, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0505 (C:1.9781, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0494

ğŸ“Š EPOCH 104 TRAINING SUMMARY:
  Total Loss: 0.0496
  Contrastive: 1.9727
  Reconstruction: 0.0014
  Topological: 0.0494 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.9448
  Contrastive: 1.9512
  Reconstruction: 0.0014
  Topological: 0.9447 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 104/300 COMPLETE (45.9s)
Train Loss: 0.0496 (C:1.9727, R:0.0014, T:0.0494)
Val Loss:   0.9448 (C:1.9512, R:0.0014, T:0.9447)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 105 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0481 (C:1.9745, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0471 (C:1.9666, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0481 (C:1.9775, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0506 (C:1.9741, R:0.0014, T:0.0505(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0453 (C:1.9668, R:0.0014, T:0.0451(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0478 (C:1.9721, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0492 (C:1.9700, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0506 (C:1.9734, R:0.0014, T:0.0505(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0515 (C:1.9726, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0500 (C:1.9734, R:0.0014, T:0.0499(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0515 (C:1.9723, R:0.0014, T:0.0513(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0510 (C:1.9721, R:0.0014, T:0.0509(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0491 (C:1.9754, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0485 (C:1.9746, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0492 (C:1.9700, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0455 (C:1.9737, R:0.0014, T:0.0453(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0517 (C:1.9736, R:0.0014, T:0.0515(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0496 (C:1.9709, R:0.0014, T:0.0495(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0502 (C:1.9685, R:0.0014, T:0.0501(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0481 (C:1.9785, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0513 (C:1.9699, R:0.0014, T:0.0511(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0497 (C:1.9714, R:0.0014, T:0.0496(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 105 TRAINING SUMMARY:
  Total Loss: 0.0497
  Contrastive: 1.9725
  Reconstruction: 0.0014
  Topological: 0.0495 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.9498
  Contrastive: 1.9519
  Reconstruction: 0.0014
  Topological: 0.9497 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 105/300 COMPLETE (46.3s)
Train Loss: 0.0497 (C:1.9725, R:0.0014, T:0.0495)
Val Loss:   0.9498 (C:1.9519, R:0.0014, T:0.9497)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 106 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0487 (C:1.9746, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0493 (C:1.9726, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0485 (C:1.9734, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0475 (C:1.9730, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0504 (C:1.9764, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0497 (C:1.9741, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0494 (C:1.9748, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0509 (C:1.9723, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0500 (C:1.9749, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0489 (C:1.9723, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0497 (C:1.9687, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0493 (C:1.9765, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0507 (C:1.9719, R:0.0014, T:0.0505(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0483 (C:1.9753, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0478 (C:1.9734, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0507 (C:1.9721, R:0.0014, T:0.0506(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0512 (C:1.9725, R:0.0014, T:0.0511(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0505 (C:1.9695, R:0.0014, T:0.0504(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0498 (C:1.9742, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0482 (C:1.9749, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0526 (C:1.9705, R:0.0014, T:0.0525(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0499 (C:1.9681, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0494

ğŸ“Š EPOCH 106 TRAINING SUMMARY:
  Total Loss: 0.0495
  Contrastive: 1.9724
  Reconstruction: 0.0014
  Topological: 0.0494 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.9023
  Contrastive: 1.9481
  Reconstruction: 0.0014
  Topological: 0.9021 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 106/300 COMPLETE (44.1s)
Train Loss: 0.0495 (C:1.9724, R:0.0014, T:0.0494)
Val Loss:   0.9023 (C:1.9481, R:0.0014, T:0.9021)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 107 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0528 (C:1.9754, R:0.0014, T:0.0527(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0529 (C:1.9676, R:0.0014, T:0.0528(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0522 (C:1.9678, R:0.0014, T:0.0520(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0486 (C:1.9695, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0521 (C:1.9722, R:0.0014, T:0.0520(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0476 (C:1.9670, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0489 (C:1.9720, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0507 (C:1.9747, R:0.0014, T:0.0506(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0505 (C:1.9749, R:0.0014, T:0.0504(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0493 (C:1.9709, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0518 (C:1.9762, R:0.0014, T:0.0517(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0483 (C:1.9718, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0489 (C:1.9771, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0475 (C:1.9683, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0473 (C:1.9761, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0462 (C:1.9729, R:0.0014, T:0.0460(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0480 (C:1.9744, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0489 (C:1.9713, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0517 (C:1.9744, R:0.0014, T:0.0515(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0466 (C:1.9728, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0472 (C:1.9747, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0471 (C:1.9714, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0493

ğŸ“Š EPOCH 107 TRAINING SUMMARY:
  Total Loss: 0.0495
  Contrastive: 1.9728
  Reconstruction: 0.0014
  Topological: 0.0493 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.9019
  Contrastive: 1.9463
  Reconstruction: 0.0014
  Topological: 0.9017 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 107/300 COMPLETE (43.7s)
Train Loss: 0.0495 (C:1.9728, R:0.0014, T:0.0493)
Val Loss:   0.9019 (C:1.9463, R:0.0014, T:0.9017)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 108 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0481 (C:1.9716, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0470 (C:1.9717, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0498 (C:1.9714, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0489 (C:1.9792, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0486 (C:1.9733, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0521 (C:1.9709, R:0.0014, T:0.0519(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0456 (C:1.9740, R:0.0014, T:0.0455(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0497 (C:1.9688, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0476 (C:1.9643, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0512 (C:1.9648, R:0.0014, T:0.0511(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0507 (C:1.9738, R:0.0014, T:0.0506(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0505 (C:1.9712, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0502 (C:1.9761, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0496 (C:1.9750, R:0.0014, T:0.0495(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0504 (C:1.9653, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0454 (C:1.9756, R:0.0014, T:0.0453(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0508 (C:1.9742, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0501 (C:1.9745, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0473 (C:1.9759, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0476 (C:1.9725, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0526 (C:1.9721, R:0.0014, T:0.0524(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0504 (C:1.9735, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0491

ğŸ“Š EPOCH 108 TRAINING SUMMARY:
  Total Loss: 0.0493
  Contrastive: 1.9727
  Reconstruction: 0.0014
  Topological: 0.0491 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.9091
  Contrastive: 1.9460
  Reconstruction: 0.0014
  Topological: 0.9090 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 108/300 COMPLETE (43.6s)
Train Loss: 0.0493 (C:1.9727, R:0.0014, T:0.0491)
Val Loss:   0.9091 (C:1.9460, R:0.0014, T:0.9090)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 109 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0496 (C:1.9709, R:0.0014, T:0.0495(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0512 (C:1.9737, R:0.0014, T:0.0511(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0503 (C:1.9695, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0484 (C:1.9747, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0496 (C:1.9713, R:0.0014, T:0.0495(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0499 (C:1.9786, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0510 (C:1.9731, R:0.0014, T:0.0508(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0474 (C:1.9639, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0509 (C:1.9665, R:0.0014, T:0.0508(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0495 (C:1.9711, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0496 (C:1.9716, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0482 (C:1.9719, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0449 (C:1.9748, R:0.0014, T:0.0447(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0504 (C:1.9718, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0458 (C:1.9691, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0501 (C:1.9685, R:0.0014, T:0.0499(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0476 (C:1.9746, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0497 (C:1.9702, R:0.0014, T:0.0495(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0509 (C:1.9714, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0503 (C:1.9680, R:0.0014, T:0.0501(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0466 (C:1.9728, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0517 (C:1.9716, R:0.0014, T:0.0516(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 109 TRAINING SUMMARY:
  Total Loss: 0.0493
  Contrastive: 1.9727
  Reconstruction: 0.0014
  Topological: 0.0492 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.8488
  Contrastive: 1.9425
  Reconstruction: 0.0014
  Topological: 0.8487 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 109/300 COMPLETE (44.6s)
Train Loss: 0.0493 (C:1.9727, R:0.0014, T:0.0492)
Val Loss:   0.8488 (C:1.9425, R:0.0014, T:0.8487)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 110 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0502 (C:1.9723, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0447 (C:1.9726, R:0.0014, T:0.0446(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0487 (C:1.9775, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0484 (C:1.9754, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0496 (C:1.9730, R:0.0014, T:0.0495(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0493 (C:1.9715, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0486 (C:1.9770, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0466 (C:1.9723, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0497 (C:1.9754, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0456 (C:1.9734, R:0.0014, T:0.0455(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0500 (C:1.9771, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0479 (C:1.9724, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0504 (C:1.9741, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0500 (C:1.9700, R:0.0014, T:0.0499(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0465 (C:1.9753, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0475 (C:1.9763, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0492 (C:1.9768, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0500 (C:1.9750, R:0.0014, T:0.0499(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0468 (C:1.9727, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0484 (C:1.9737, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0515 (C:1.9717, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0487 (C:1.9720, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0488

ğŸ“Š EPOCH 110 TRAINING SUMMARY:
  Total Loss: 0.0489
  Contrastive: 1.9730
  Reconstruction: 0.0014
  Topological: 0.0488 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.8643
  Contrastive: 1.9436
  Reconstruction: 0.0014
  Topological: 0.8642 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 110/300 COMPLETE (43.6s)
Train Loss: 0.0489 (C:1.9730, R:0.0014, T:0.0488)
Val Loss:   0.8643 (C:1.9436, R:0.0014, T:0.8642)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 111 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0495 (C:1.9724, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0511 (C:1.9758, R:0.0014, T:0.0510(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0471 (C:1.9755, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0472 (C:1.9729, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0465 (C:1.9693, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0503 (C:1.9731, R:0.0014, T:0.0501(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0486 (C:1.9759, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0508 (C:1.9730, R:0.0014, T:0.0506(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0488 (C:1.9763, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0496 (C:1.9781, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0468 (C:1.9770, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0488 (C:1.9731, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0493 (C:1.9715, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0520 (C:1.9723, R:0.0014, T:0.0519(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0482 (C:1.9721, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0487 (C:1.9696, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0496 (C:1.9689, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0516 (C:1.9789, R:0.0014, T:0.0515(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0477 (C:1.9693, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0484 (C:1.9773, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0484 (C:1.9740, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0505 (C:1.9764, R:0.0014, T:0.0503(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 111 TRAINING SUMMARY:
  Total Loss: 0.0490
  Contrastive: 1.9730
  Reconstruction: 0.0014
  Topological: 0.0489 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.8292
  Contrastive: 1.9458
  Reconstruction: 0.0014
  Topological: 0.8291 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 111/300 COMPLETE (42.9s)
Train Loss: 0.0490 (C:1.9730, R:0.0014, T:0.0489)
Val Loss:   0.8292 (C:1.9458, R:0.0014, T:0.8291)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 112 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0493 (C:1.9713, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0454 (C:1.9665, R:0.0014, T:0.0453(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0477 (C:1.9713, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0515 (C:1.9708, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0527 (C:1.9747, R:0.0014, T:0.0526(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0494 (C:1.9764, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0496 (C:1.9734, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0479 (C:1.9700, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0493 (C:1.9733, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0489 (C:1.9735, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0486 (C:1.9726, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0499 (C:1.9772, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0489 (C:1.9715, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0473 (C:1.9761, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0571 (C:1.9745, R:0.0014, T:0.0570(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0494 (C:1.9738, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0492 (C:1.9695, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0501 (C:1.9715, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0493 (C:1.9737, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0484 (C:1.9747, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0510 (C:1.9681, R:0.0014, T:0.0509(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0477 (C:1.9747, R:0.0014, T:0.0475(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 112 TRAINING SUMMARY:
  Total Loss: 0.0491
  Contrastive: 1.9729
  Reconstruction: 0.0014
  Topological: 0.0489 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.7886
  Contrastive: 1.9411
  Reconstruction: 0.0014
  Topological: 0.7885 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 112/300 COMPLETE (44.2s)
Train Loss: 0.0491 (C:1.9729, R:0.0014, T:0.0489)
Val Loss:   0.7886 (C:1.9411, R:0.0014, T:0.7885)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 113 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0485 (C:1.9690, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0491 (C:1.9751, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0517 (C:1.9703, R:0.0014, T:0.0516(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0474 (C:1.9719, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0512 (C:1.9752, R:0.0014, T:0.0510(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0490 (C:1.9691, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0496 (C:1.9732, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0486 (C:1.9741, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0482 (C:1.9754, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0506 (C:1.9760, R:0.0014, T:0.0505(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0489 (C:1.9712, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0486 (C:1.9792, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0502 (C:1.9739, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0504 (C:1.9718, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0499 (C:1.9732, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0521 (C:1.9767, R:0.0014, T:0.0519(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0494 (C:1.9782, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0499 (C:1.9708, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0492 (C:1.9754, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0479 (C:1.9736, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0472 (C:1.9719, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0512 (C:1.9709, R:0.0014, T:0.0510(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0487

ğŸ“Š EPOCH 113 TRAINING SUMMARY:
  Total Loss: 0.0488
  Contrastive: 1.9735
  Reconstruction: 0.0014
  Topological: 0.0487 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.7773
  Contrastive: 1.9458
  Reconstruction: 0.0014
  Topological: 0.7772 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 113/300 COMPLETE (43.7s)
Train Loss: 0.0488 (C:1.9735, R:0.0014, T:0.0487)
Val Loss:   0.7773 (C:1.9458, R:0.0014, T:0.7772)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 114 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0475 (C:1.9732, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0494 (C:1.9792, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0473 (C:1.9723, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0513 (C:1.9717, R:0.0014, T:0.0512(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0477 (C:1.9709, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0457 (C:1.9755, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0478 (C:1.9741, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0490 (C:1.9717, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0502 (C:1.9716, R:0.0014, T:0.0501(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0496 (C:1.9735, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0489 (C:1.9805, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0469 (C:1.9700, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0476 (C:1.9708, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0510 (C:1.9723, R:0.0014, T:0.0508(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0459 (C:1.9776, R:0.0014, T:0.0458(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0494 (C:1.9736, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0488 (C:1.9795, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0470 (C:1.9664, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0527 (C:1.9745, R:0.0014, T:0.0526(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0457 (C:1.9753, R:0.0014, T:0.0455(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0514 (C:1.9766, R:0.0014, T:0.0513(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0509 (C:1.9753, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0485

ğŸ“Š EPOCH 114 TRAINING SUMMARY:
  Total Loss: 0.0486
  Contrastive: 1.9737
  Reconstruction: 0.0014
  Topological: 0.0485 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.7165
  Contrastive: 1.9427
  Reconstruction: 0.0014
  Topological: 0.7164 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 114/300 COMPLETE (44.3s)
Train Loss: 0.0486 (C:1.9737, R:0.0014, T:0.0485)
Val Loss:   0.7165 (C:1.9427, R:0.0014, T:0.7164)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 115 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0482 (C:1.9711, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0472 (C:1.9727, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0486 (C:1.9770, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0481 (C:1.9716, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0473 (C:1.9796, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0486 (C:1.9732, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0501 (C:1.9724, R:0.0014, T:0.0499(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0479 (C:1.9745, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0480 (C:1.9749, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0474 (C:1.9731, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0459 (C:1.9741, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0483 (C:1.9712, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0465 (C:1.9728, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0520 (C:1.9769, R:0.0014, T:0.0518(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0475 (C:1.9715, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0482 (C:1.9743, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0477 (C:1.9721, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0468 (C:1.9723, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0436 (C:1.9742, R:0.0014, T:0.0435(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0505 (C:1.9730, R:0.0014, T:0.0504(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0475 (C:1.9741, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0477 (C:1.9745, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0483

ğŸ“Š EPOCH 115 TRAINING SUMMARY:
  Total Loss: 0.0484
  Contrastive: 1.9734
  Reconstruction: 0.0014
  Topological: 0.0483 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.7196
  Contrastive: 1.9408
  Reconstruction: 0.0014
  Topological: 0.7195 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 115/300 COMPLETE (44.8s)
Train Loss: 0.0484 (C:1.9734, R:0.0014, T:0.0483)
Val Loss:   0.7196 (C:1.9408, R:0.0014, T:0.7195)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 116 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0449 (C:1.9728, R:0.0014, T:0.0447(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0487 (C:1.9728, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0503 (C:1.9735, R:0.0014, T:0.0501(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0493 (C:1.9707, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0473 (C:1.9714, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0477 (C:1.9726, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0465 (C:1.9767, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0485 (C:1.9744, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0520 (C:1.9747, R:0.0014, T:0.0519(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0504 (C:1.9741, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0465 (C:1.9768, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0477 (C:1.9744, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0509 (C:1.9731, R:0.0014, T:0.0508(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0467 (C:1.9719, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0478 (C:1.9759, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0480 (C:1.9756, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0478 (C:1.9750, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0499 (C:1.9729, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0485 (C:1.9787, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0463 (C:1.9765, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0477 (C:1.9765, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0475 (C:1.9697, R:0.0014, T:0.0474(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 116 TRAINING SUMMARY:
  Total Loss: 0.0485
  Contrastive: 1.9735
  Reconstruction: 0.0014
  Topological: 0.0483 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.6613
  Contrastive: 1.9424
  Reconstruction: 0.0014
  Topological: 0.6612 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 116/300 COMPLETE (46.6s)
Train Loss: 0.0485 (C:1.9735, R:0.0014, T:0.0483)
Val Loss:   0.6613 (C:1.9424, R:0.0014, T:0.6612)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 117 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0504 (C:1.9786, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0467 (C:1.9717, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0478 (C:1.9731, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0476 (C:1.9736, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0498 (C:1.9733, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0497 (C:1.9732, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0485 (C:1.9687, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0463 (C:1.9729, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0491 (C:1.9763, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0468 (C:1.9702, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0457 (C:1.9755, R:0.0014, T:0.0455(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0505 (C:1.9723, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0487 (C:1.9731, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0473 (C:1.9718, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0478 (C:1.9770, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0488 (C:1.9694, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0494 (C:1.9727, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0492 (C:1.9733, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0463 (C:1.9742, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0493 (C:1.9741, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0451 (C:1.9759, R:0.0014, T:0.0450(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0462 (C:1.9795, R:0.0014, T:0.0461(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 117 TRAINING SUMMARY:
  Total Loss: 0.0485
  Contrastive: 1.9736
  Reconstruction: 0.0014
  Topological: 0.0483 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.6849
  Contrastive: 1.9419
  Reconstruction: 0.0014
  Topological: 0.6848 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 117/300 COMPLETE (47.0s)
Train Loss: 0.0485 (C:1.9736, R:0.0014, T:0.0483)
Val Loss:   0.6849 (C:1.9419, R:0.0014, T:0.6848)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 118 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0493 (C:1.9803, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0491 (C:1.9724, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0482 (C:1.9730, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0459 (C:1.9682, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0497 (C:1.9746, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0501 (C:1.9748, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0460 (C:1.9797, R:0.0014, T:0.0458(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0498 (C:1.9722, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0482 (C:1.9756, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0478 (C:1.9711, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0486 (C:1.9783, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0495 (C:1.9737, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0492 (C:1.9691, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0480 (C:1.9733, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0503 (C:1.9709, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0487 (C:1.9722, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0473 (C:1.9733, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0471 (C:1.9662, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0437 (C:1.9728, R:0.0014, T:0.0435(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0470 (C:1.9757, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0485 (C:1.9729, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0467 (C:1.9732, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0481

ğŸ“Š EPOCH 118 TRAINING SUMMARY:
  Total Loss: 0.0482
  Contrastive: 1.9735
  Reconstruction: 0.0014
  Topological: 0.0481 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.6502
  Contrastive: 1.9382
  Reconstruction: 0.0014
  Topological: 0.6501 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 118/300 COMPLETE (47.2s)
Train Loss: 0.0482 (C:1.9735, R:0.0014, T:0.0481)
Val Loss:   0.6502 (C:1.9382, R:0.0014, T:0.6501)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 119 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0505 (C:1.9752, R:0.0014, T:0.0504(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0489 (C:1.9729, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0499 (C:1.9793, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0478 (C:1.9741, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0477 (C:1.9710, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0473 (C:1.9717, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0488 (C:1.9721, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0487 (C:1.9746, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0482 (C:1.9757, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0457 (C:1.9726, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0467 (C:1.9731, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0474 (C:1.9752, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0480 (C:1.9753, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0476 (C:1.9705, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0471 (C:1.9765, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0477 (C:1.9743, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0488 (C:1.9737, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0479 (C:1.9759, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0508 (C:1.9748, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0507 (C:1.9767, R:0.0014, T:0.0505(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0508 (C:1.9731, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0476 (C:1.9742, R:0.0014, T:0.0475(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 119 TRAINING SUMMARY:
  Total Loss: 0.0484
  Contrastive: 1.9735
  Reconstruction: 0.0014
  Topological: 0.0482 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.6394
  Contrastive: 1.9430
  Reconstruction: 0.0014
  Topological: 0.6392 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 119/300 COMPLETE (47.2s)
Train Loss: 0.0484 (C:1.9735, R:0.0014, T:0.0482)
Val Loss:   0.6394 (C:1.9430, R:0.0014, T:0.6392)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 120 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0469 (C:1.9769, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0446 (C:1.9775, R:0.0014, T:0.0445(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0469 (C:1.9747, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0483 (C:1.9746, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0472 (C:1.9715, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0486 (C:1.9677, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0451 (C:1.9711, R:0.0014, T:0.0450(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0487 (C:1.9738, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0489 (C:1.9827, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0490 (C:1.9732, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0480 (C:1.9768, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0472 (C:1.9734, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0475 (C:1.9769, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0496 (C:1.9735, R:0.0014, T:0.0495(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0480 (C:1.9727, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0472 (C:1.9769, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0502 (C:1.9723, R:0.0014, T:0.0501(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0496 (C:1.9688, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0477 (C:1.9715, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0484 (C:1.9754, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0507 (C:1.9775, R:0.0014, T:0.0505(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0475 (C:1.9691, R:0.0014, T:0.0473(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 120 TRAINING SUMMARY:
  Total Loss: 0.0483
  Contrastive: 1.9739
  Reconstruction: 0.0014
  Topological: 0.0482 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.6144
  Contrastive: 1.9436
  Reconstruction: 0.0014
  Topological: 0.6143 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 120/300 COMPLETE (45.7s)
Train Loss: 0.0483 (C:1.9739, R:0.0014, T:0.0482)
Val Loss:   0.6144 (C:1.9436, R:0.0014, T:0.6143)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 121 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0550 (C:1.9769, R:0.0014, T:0.0548(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0492 (C:1.9700, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0453 (C:1.9721, R:0.0014, T:0.0451(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0494 (C:1.9735, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0517 (C:1.9697, R:0.0014, T:0.0515(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0472 (C:1.9731, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0496 (C:1.9737, R:0.0014, T:0.0495(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0475 (C:1.9749, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0461 (C:1.9698, R:0.0014, T:0.0459(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0478 (C:1.9783, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0483 (C:1.9732, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0483 (C:1.9743, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0501 (C:1.9678, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0481 (C:1.9683, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0463 (C:1.9782, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0469 (C:1.9739, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0487 (C:1.9725, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0506 (C:1.9734, R:0.0014, T:0.0505(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0474 (C:1.9745, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0505 (C:1.9761, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0470 (C:1.9757, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0495 (C:1.9778, R:0.0014, T:0.0493(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 121 TRAINING SUMMARY:
  Total Loss: 0.0484
  Contrastive: 1.9736
  Reconstruction: 0.0014
  Topological: 0.0483 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.6177
  Contrastive: 1.9418
  Reconstruction: 0.0014
  Topological: 0.6176 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 121/300 COMPLETE (44.6s)
Train Loss: 0.0484 (C:1.9736, R:0.0014, T:0.0483)
Val Loss:   0.6177 (C:1.9418, R:0.0014, T:0.6176)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 122 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0490 (C:1.9739, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0469 (C:1.9766, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0467 (C:1.9728, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0474 (C:1.9768, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0472 (C:1.9769, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0498 (C:1.9738, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0450 (C:1.9722, R:0.0014, T:0.0449(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0476 (C:1.9708, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0503 (C:1.9714, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0469 (C:1.9745, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0424 (C:1.9730, R:0.0014, T:0.0423(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0483 (C:1.9745, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0505 (C:1.9793, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0494 (C:1.9739, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0486 (C:1.9772, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0522 (C:1.9700, R:0.0014, T:0.0520(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0449 (C:1.9731, R:0.0014, T:0.0447(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0499 (C:1.9776, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0499 (C:1.9786, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0518 (C:1.9722, R:0.0014, T:0.0516(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0474 (C:1.9728, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0494 (C:1.9784, R:0.0014, T:0.0493(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 122 TRAINING SUMMARY:
  Total Loss: 0.0483
  Contrastive: 1.9738
  Reconstruction: 0.0014
  Topological: 0.0481 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.6551
  Contrastive: 1.9362
  Reconstruction: 0.0014
  Topological: 0.6550 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 122/300 COMPLETE (44.5s)
Train Loss: 0.0483 (C:1.9738, R:0.0014, T:0.0481)
Val Loss:   0.6551 (C:1.9362, R:0.0014, T:0.6550)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 123 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0469 (C:1.9707, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0494 (C:1.9770, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0477 (C:1.9713, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0464 (C:1.9752, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0480 (C:1.9730, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0473 (C:1.9762, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0483 (C:1.9746, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0471 (C:1.9795, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0470 (C:1.9754, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0433 (C:1.9726, R:0.0014, T:0.0431(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0497 (C:1.9724, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0497 (C:1.9755, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0524 (C:1.9763, R:0.0014, T:0.0522(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0498 (C:1.9684, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0501 (C:1.9787, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0472 (C:1.9734, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0463 (C:1.9686, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0482 (C:1.9678, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0470 (C:1.9716, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0472 (C:1.9717, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0483 (C:1.9689, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0464 (C:1.9773, R:0.0014, T:0.0463(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 123 TRAINING SUMMARY:
  Total Loss: 0.0482
  Contrastive: 1.9739
  Reconstruction: 0.0014
  Topological: 0.0481 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.6428
  Contrastive: 1.9381
  Reconstruction: 0.0014
  Topological: 0.6426 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 123/300 COMPLETE (44.3s)
Train Loss: 0.0482 (C:1.9739, R:0.0014, T:0.0481)
Val Loss:   0.6428 (C:1.9381, R:0.0014, T:0.6426)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 124 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0496 (C:1.9740, R:0.0014, T:0.0495(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0495 (C:1.9739, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0457 (C:1.9679, R:0.0014, T:0.0455(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0514 (C:1.9755, R:0.0014, T:0.0513(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0513 (C:1.9688, R:0.0014, T:0.0511(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0473 (C:1.9781, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0488 (C:1.9751, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0475 (C:1.9759, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0498 (C:1.9769, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0465 (C:1.9711, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0451 (C:1.9711, R:0.0014, T:0.0450(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0453 (C:1.9729, R:0.0014, T:0.0451(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0475 (C:1.9741, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0498 (C:1.9764, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0465 (C:1.9737, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0527 (C:1.9735, R:0.0014, T:0.0525(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0467 (C:1.9806, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0525 (C:1.9721, R:0.0014, T:0.0524(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0496 (C:1.9745, R:0.0014, T:0.0495(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0473 (C:1.9779, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0494 (C:1.9710, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0487 (C:1.9694, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0480

ğŸ“Š EPOCH 124 TRAINING SUMMARY:
  Total Loss: 0.0481
  Contrastive: 1.9742
  Reconstruction: 0.0014
  Topological: 0.0480 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.6379
  Contrastive: 1.9312
  Reconstruction: 0.0014
  Topological: 0.6378 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 124/300 COMPLETE (43.1s)
Train Loss: 0.0481 (C:1.9742, R:0.0014, T:0.0480)
Val Loss:   0.6379 (C:1.9312, R:0.0014, T:0.6378)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 125 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0480 (C:1.9747, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0489 (C:1.9710, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0470 (C:1.9723, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0501 (C:1.9750, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0484 (C:1.9725, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0468 (C:1.9763, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0499 (C:1.9741, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0452 (C:1.9743, R:0.0014, T:0.0451(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0470 (C:1.9712, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0489 (C:1.9726, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0494 (C:1.9750, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0499 (C:1.9780, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0545 (C:1.9724, R:0.0014, T:0.0544(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0493 (C:1.9708, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0503 (C:1.9763, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0479 (C:1.9751, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0488 (C:1.9697, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0476 (C:1.9790, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0466 (C:1.9730, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0469 (C:1.9753, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0506 (C:1.9768, R:0.0014, T:0.0504(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0475 (C:1.9716, R:0.0014, T:0.0473(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 125 TRAINING SUMMARY:
  Total Loss: 0.0485
  Contrastive: 1.9742
  Reconstruction: 0.0014
  Topological: 0.0483 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.6098
  Contrastive: 1.9353
  Reconstruction: 0.0014
  Topological: 0.6097 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 125/300 COMPLETE (43.1s)
Train Loss: 0.0485 (C:1.9742, R:0.0014, T:0.0483)
Val Loss:   0.6098 (C:1.9353, R:0.0014, T:0.6097)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 126 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0492 (C:1.9731, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0514 (C:1.9704, R:0.0014, T:0.0512(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0474 (C:1.9759, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0478 (C:1.9735, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0504 (C:1.9756, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0468 (C:1.9715, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0487 (C:1.9755, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0491 (C:1.9771, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0449 (C:1.9752, R:0.0014, T:0.0448(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0482 (C:1.9723, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0486 (C:1.9701, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0510 (C:1.9730, R:0.0014, T:0.0509(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0491 (C:1.9775, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0487 (C:1.9735, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0498 (C:1.9758, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0495 (C:1.9704, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0485 (C:1.9748, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0495 (C:1.9708, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0487 (C:1.9729, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0481 (C:1.9741, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0445 (C:1.9732, R:0.0014, T:0.0443(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0497 (C:1.9722, R:0.0014, T:0.0496(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 126 TRAINING SUMMARY:
  Total Loss: 0.0484
  Contrastive: 1.9743
  Reconstruction: 0.0014
  Topological: 0.0482 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.6094
  Contrastive: 1.9381
  Reconstruction: 0.0014
  Topological: 0.6092 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 126/300 COMPLETE (43.6s)
Train Loss: 0.0484 (C:1.9743, R:0.0014, T:0.0482)
Val Loss:   0.6094 (C:1.9381, R:0.0014, T:0.6092)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 127 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0499 (C:1.9698, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0486 (C:1.9782, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0496 (C:1.9757, R:0.0014, T:0.0495(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0485 (C:1.9689, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0496 (C:1.9737, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0452 (C:1.9781, R:0.0014, T:0.0450(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0458 (C:1.9758, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0476 (C:1.9748, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0454 (C:1.9717, R:0.0014, T:0.0453(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0498 (C:1.9751, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0498 (C:1.9738, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0498 (C:1.9767, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0486 (C:1.9716, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0491 (C:1.9739, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0483 (C:1.9755, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0486 (C:1.9702, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0487 (C:1.9672, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0479 (C:1.9721, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0479 (C:1.9759, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0489 (C:1.9718, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0465 (C:1.9766, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0475 (C:1.9719, R:0.0014, T:0.0474(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 127 TRAINING SUMMARY:
  Total Loss: 0.0484
  Contrastive: 1.9739
  Reconstruction: 0.0014
  Topological: 0.0482 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.6256
  Contrastive: 1.9401
  Reconstruction: 0.0014
  Topological: 0.6255 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 127/300 COMPLETE (43.6s)
Train Loss: 0.0484 (C:1.9739, R:0.0014, T:0.0482)
Val Loss:   0.6256 (C:1.9401, R:0.0014, T:0.6255)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 128 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0484 (C:1.9757, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0492 (C:1.9727, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0481 (C:1.9725, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0485 (C:1.9762, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0482 (C:1.9759, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0512 (C:1.9729, R:0.0014, T:0.0510(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0508 (C:1.9740, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0482 (C:1.9724, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0491 (C:1.9750, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0497 (C:1.9743, R:0.0014, T:0.0495(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0491 (C:1.9714, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0483 (C:1.9704, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0485 (C:1.9697, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0488 (C:1.9741, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0481 (C:1.9716, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0470 (C:1.9757, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0501 (C:1.9732, R:0.0014, T:0.0499(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0468 (C:1.9705, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0508 (C:1.9731, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0491 (C:1.9731, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0482 (C:1.9706, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0477 (C:1.9745, R:0.0014, T:0.0476(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 128 TRAINING SUMMARY:
  Total Loss: 0.0482
  Contrastive: 1.9736
  Reconstruction: 0.0014
  Topological: 0.0480 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.6061
  Contrastive: 1.9435
  Reconstruction: 0.0014
  Topological: 0.6060 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 128/300 COMPLETE (43.5s)
Train Loss: 0.0482 (C:1.9736, R:0.0014, T:0.0480)
Val Loss:   0.6061 (C:1.9435, R:0.0014, T:0.6060)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 129 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0449 (C:1.9730, R:0.0014, T:0.0448(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0459 (C:1.9699, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0489 (C:1.9719, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0459 (C:1.9736, R:0.0014, T:0.0458(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0472 (C:1.9711, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0465 (C:1.9707, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0477 (C:1.9799, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0478 (C:1.9716, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0505 (C:1.9751, R:0.0014, T:0.0504(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0464 (C:1.9728, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0488 (C:1.9705, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0493 (C:1.9716, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0466 (C:1.9768, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0499 (C:1.9748, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0489 (C:1.9727, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0493 (C:1.9743, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0465 (C:1.9696, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0503 (C:1.9683, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0493 (C:1.9704, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0503 (C:1.9797, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0457 (C:1.9727, R:0.0014, T:0.0455(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0477 (C:1.9760, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0480

ğŸ“Š EPOCH 129 TRAINING SUMMARY:
  Total Loss: 0.0481
  Contrastive: 1.9738
  Reconstruction: 0.0014
  Topological: 0.0480 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.6333
  Contrastive: 1.9403
  Reconstruction: 0.0014
  Topological: 0.6332 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 129/300 COMPLETE (43.2s)
Train Loss: 0.0481 (C:1.9738, R:0.0014, T:0.0480)
Val Loss:   0.6333 (C:1.9403, R:0.0014, T:0.6332)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 130 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0480 (C:1.9763, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0457 (C:1.9720, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0501 (C:1.9753, R:0.0014, T:0.0499(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0477 (C:1.9692, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0466 (C:1.9725, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0449 (C:1.9768, R:0.0014, T:0.0448(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0485 (C:1.9722, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0471 (C:1.9739, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0494 (C:1.9778, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0503 (C:1.9746, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0489 (C:1.9775, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0488 (C:1.9737, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0472 (C:1.9758, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0488 (C:1.9728, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0463 (C:1.9741, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0466 (C:1.9709, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0463 (C:1.9773, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0464 (C:1.9728, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0466 (C:1.9692, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0467 (C:1.9760, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0472 (C:1.9709, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0476 (C:1.9756, R:0.0014, T:0.0475(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 130 TRAINING SUMMARY:
  Total Loss: 0.0481
  Contrastive: 1.9737
  Reconstruction: 0.0014
  Topological: 0.0480 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.5934
  Contrastive: 1.9352
  Reconstruction: 0.0014
  Topological: 0.5933 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 130/300 COMPLETE (43.9s)
Train Loss: 0.0481 (C:1.9737, R:0.0014, T:0.0480)
Val Loss:   0.5934 (C:1.9352, R:0.0014, T:0.5933)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 131 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0495 (C:1.9704, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0509 (C:1.9777, R:0.0014, T:0.0508(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0482 (C:1.9705, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0468 (C:1.9718, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0479 (C:1.9761, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0468 (C:1.9703, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0466 (C:1.9729, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0489 (C:1.9770, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0469 (C:1.9792, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0489 (C:1.9754, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0483 (C:1.9671, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0467 (C:1.9678, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0494 (C:1.9783, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0468 (C:1.9744, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0490 (C:1.9766, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0468 (C:1.9749, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0492 (C:1.9713, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0451 (C:1.9792, R:0.0014, T:0.0450(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0482 (C:1.9733, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0490 (C:1.9769, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0485 (C:1.9692, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0483 (C:1.9724, R:0.0014, T:0.0481(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 131 TRAINING SUMMARY:
  Total Loss: 0.0483
  Contrastive: 1.9736
  Reconstruction: 0.0014
  Topological: 0.0481 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.6224
  Contrastive: 1.9387
  Reconstruction: 0.0014
  Topological: 0.6223 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 131/300 COMPLETE (42.9s)
Train Loss: 0.0483 (C:1.9736, R:0.0014, T:0.0481)
Val Loss:   0.6224 (C:1.9387, R:0.0014, T:0.6223)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 132 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0483 (C:1.9753, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0463 (C:1.9715, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0483 (C:1.9774, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0501 (C:1.9665, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0489 (C:1.9719, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0463 (C:1.9676, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0459 (C:1.9745, R:0.0014, T:0.0458(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0478 (C:1.9754, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0483 (C:1.9715, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0483 (C:1.9717, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0485 (C:1.9741, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0472 (C:1.9746, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0501 (C:1.9765, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0460 (C:1.9744, R:0.0014, T:0.0458(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0490 (C:1.9752, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0496 (C:1.9682, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0462 (C:1.9759, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0497 (C:1.9784, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0463 (C:1.9756, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0465 (C:1.9750, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0506 (C:1.9732, R:0.0014, T:0.0505(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0493 (C:1.9740, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0478

ğŸ“Š EPOCH 132 TRAINING SUMMARY:
  Total Loss: 0.0480
  Contrastive: 1.9735
  Reconstruction: 0.0014
  Topological: 0.0478 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.6103
  Contrastive: 1.9358
  Reconstruction: 0.0014
  Topological: 0.6101 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 132/300 COMPLETE (43.1s)
Train Loss: 0.0480 (C:1.9735, R:0.0014, T:0.0478)
Val Loss:   0.6103 (C:1.9358, R:0.0014, T:0.6101)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 133 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0464 (C:1.9741, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0500 (C:1.9776, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0499 (C:1.9724, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0467 (C:1.9689, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0497 (C:1.9731, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0458 (C:1.9721, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0484 (C:1.9758, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0499 (C:1.9770, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0460 (C:1.9683, R:0.0014, T:0.0459(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0491 (C:1.9734, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0497 (C:1.9759, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0499 (C:1.9765, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0501 (C:1.9750, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0452 (C:1.9715, R:0.0014, T:0.0451(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0481 (C:1.9730, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0498 (C:1.9743, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0493 (C:1.9759, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0459 (C:1.9762, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0458 (C:1.9733, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0464 (C:1.9760, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0524 (C:1.9746, R:0.0014, T:0.0523(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0485 (C:1.9706, R:0.0014, T:0.0484(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 133 TRAINING SUMMARY:
  Total Loss: 0.0482
  Contrastive: 1.9735
  Reconstruction: 0.0014
  Topological: 0.0480 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.6467
  Contrastive: 1.9371
  Reconstruction: 0.0014
  Topological: 0.6465 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 133/300 COMPLETE (44.9s)
Train Loss: 0.0482 (C:1.9735, R:0.0014, T:0.0480)
Val Loss:   0.6467 (C:1.9371, R:0.0014, T:0.6465)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 134 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0499 (C:1.9681, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0474 (C:1.9704, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0495 (C:1.9738, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0471 (C:1.9762, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0491 (C:1.9754, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0477 (C:1.9750, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0481 (C:1.9728, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0523 (C:1.9773, R:0.0014, T:0.0522(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0461 (C:1.9725, R:0.0014, T:0.0459(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0496 (C:1.9722, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0482 (C:1.9689, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0475 (C:1.9712, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0465 (C:1.9719, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0487 (C:1.9758, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0497 (C:1.9704, R:0.0014, T:0.0495(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0467 (C:1.9718, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0453 (C:1.9731, R:0.0014, T:0.0451(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0489 (C:1.9725, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0480 (C:1.9729, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0498 (C:1.9721, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0495 (C:1.9774, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0480 (C:1.9761, R:0.0014, T:0.0478(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 134 TRAINING SUMMARY:
  Total Loss: 0.0481
  Contrastive: 1.9732
  Reconstruction: 0.0014
  Topological: 0.0479 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.5728
  Contrastive: 1.9387
  Reconstruction: 0.0014
  Topological: 0.5727 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 134/300 COMPLETE (44.5s)
Train Loss: 0.0481 (C:1.9732, R:0.0014, T:0.0479)
Val Loss:   0.5728 (C:1.9387, R:0.0014, T:0.5727)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 135 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0510 (C:1.9759, R:0.0014, T:0.0508(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0484 (C:1.9747, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0465 (C:1.9734, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0483 (C:1.9737, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0478 (C:1.9735, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0498 (C:1.9696, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0514 (C:1.9741, R:0.0014, T:0.0512(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0502 (C:1.9728, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0499 (C:1.9763, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0481 (C:1.9750, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0470 (C:1.9691, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0476 (C:1.9770, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0496 (C:1.9682, R:0.0014, T:0.0495(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0502 (C:1.9732, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0488 (C:1.9694, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0462 (C:1.9743, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0495 (C:1.9678, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0488 (C:1.9730, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0462 (C:1.9752, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0477 (C:1.9753, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0466 (C:1.9709, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0490 (C:1.9701, R:0.0014, T:0.0489(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 135 TRAINING SUMMARY:
  Total Loss: 0.0483
  Contrastive: 1.9732
  Reconstruction: 0.0014
  Topological: 0.0481 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.6034
  Contrastive: 1.9378
  Reconstruction: 0.0014
  Topological: 0.6033 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 135/300 COMPLETE (44.1s)
Train Loss: 0.0483 (C:1.9732, R:0.0014, T:0.0481)
Val Loss:   0.6034 (C:1.9378, R:0.0014, T:0.6033)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 136 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0459 (C:1.9781, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0463 (C:1.9706, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0468 (C:1.9731, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0469 (C:1.9706, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0456 (C:1.9711, R:0.0014, T:0.0455(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0449 (C:1.9749, R:0.0014, T:0.0447(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0495 (C:1.9754, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0457 (C:1.9737, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0477 (C:1.9714, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0461 (C:1.9723, R:0.0014, T:0.0460(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0474 (C:1.9774, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0494 (C:1.9747, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0468 (C:1.9720, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0451 (C:1.9755, R:0.0014, T:0.0450(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0461 (C:1.9741, R:0.0014, T:0.0459(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0464 (C:1.9696, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0455 (C:1.9681, R:0.0014, T:0.0453(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0454 (C:1.9670, R:0.0014, T:0.0453(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0475 (C:1.9713, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0430 (C:1.9734, R:0.0014, T:0.0429(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0498 (C:1.9718, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0463 (C:1.9744, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0477

ğŸ“Š EPOCH 136 TRAINING SUMMARY:
  Total Loss: 0.0478
  Contrastive: 1.9733
  Reconstruction: 0.0014
  Topological: 0.0477 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.5793
  Contrastive: 1.9325
  Reconstruction: 0.0014
  Topological: 0.5792 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 136/300 COMPLETE (44.3s)
Train Loss: 0.0478 (C:1.9733, R:0.0014, T:0.0477)
Val Loss:   0.5793 (C:1.9325, R:0.0014, T:0.5792)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 137 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0474 (C:1.9730, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0468 (C:1.9769, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0480 (C:1.9731, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0495 (C:1.9757, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0492 (C:1.9670, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0506 (C:1.9688, R:0.0014, T:0.0505(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0479 (C:1.9776, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0488 (C:1.9711, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0483 (C:1.9742, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0479 (C:1.9765, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0492 (C:1.9761, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0469 (C:1.9718, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0479 (C:1.9732, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0450 (C:1.9651, R:0.0014, T:0.0449(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0501 (C:1.9754, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0467 (C:1.9727, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0455 (C:1.9728, R:0.0014, T:0.0453(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0469 (C:1.9716, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0494 (C:1.9754, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0501 (C:1.9778, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0490 (C:1.9709, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0458 (C:1.9723, R:0.0014, T:0.0456(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 137 TRAINING SUMMARY:
  Total Loss: 0.0481
  Contrastive: 1.9735
  Reconstruction: 0.0014
  Topological: 0.0480 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.5594
  Contrastive: 1.9318
  Reconstruction: 0.0014
  Topological: 0.5592 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 137/300 COMPLETE (44.7s)
Train Loss: 0.0481 (C:1.9735, R:0.0014, T:0.0480)
Val Loss:   0.5594 (C:1.9318, R:0.0014, T:0.5592)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 138 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0488 (C:1.9716, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0486 (C:1.9719, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0461 (C:1.9715, R:0.0014, T:0.0460(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0467 (C:1.9742, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0503 (C:1.9766, R:0.0014, T:0.0501(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0494 (C:1.9686, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0508 (C:1.9781, R:0.0014, T:0.0506(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0478 (C:1.9728, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0489 (C:1.9685, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0491 (C:1.9700, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0490 (C:1.9743, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0510 (C:1.9708, R:0.0014, T:0.0509(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0473 (C:1.9738, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0508 (C:1.9789, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0470 (C:1.9683, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0471 (C:1.9768, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0485 (C:1.9704, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0491 (C:1.9690, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0485 (C:1.9680, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0501 (C:1.9673, R:0.0014, T:0.0499(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0499 (C:1.9702, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0484 (C:1.9730, R:0.0014, T:0.0483(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 138 TRAINING SUMMARY:
  Total Loss: 0.0480
  Contrastive: 1.9735
  Reconstruction: 0.0014
  Topological: 0.0479 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.5975
  Contrastive: 1.9334
  Reconstruction: 0.0014
  Topological: 0.5974 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 138/300 COMPLETE (44.0s)
Train Loss: 0.0480 (C:1.9735, R:0.0014, T:0.0479)
Val Loss:   0.5975 (C:1.9334, R:0.0014, T:0.5974)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 139 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0501 (C:1.9707, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0513 (C:1.9731, R:0.0014, T:0.0511(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0498 (C:1.9755, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0473 (C:1.9691, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0468 (C:1.9755, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0491 (C:1.9717, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0478 (C:1.9681, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0467 (C:1.9672, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0458 (C:1.9701, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0502 (C:1.9712, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0504 (C:1.9746, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0477 (C:1.9700, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0446 (C:1.9791, R:0.0014, T:0.0445(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0470 (C:1.9698, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0466 (C:1.9757, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0500 (C:1.9711, R:0.0014, T:0.0499(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0459 (C:1.9754, R:0.0014, T:0.0458(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0523 (C:1.9734, R:0.0014, T:0.0522(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0444 (C:1.9712, R:0.0014, T:0.0443(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0482 (C:1.9706, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0469 (C:1.9713, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0498 (C:1.9720, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0476

ğŸ“Š EPOCH 139 TRAINING SUMMARY:
  Total Loss: 0.0478
  Contrastive: 1.9729
  Reconstruction: 0.0014
  Topological: 0.0476 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.5913
  Contrastive: 1.9397
  Reconstruction: 0.0014
  Topological: 0.5911 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 139/300 COMPLETE (43.7s)
Train Loss: 0.0478 (C:1.9729, R:0.0014, T:0.0476)
Val Loss:   0.5913 (C:1.9397, R:0.0014, T:0.5911)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 140 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0464 (C:1.9730, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0463 (C:1.9744, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0470 (C:1.9700, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0482 (C:1.9738, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0461 (C:1.9704, R:0.0014, T:0.0460(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0484 (C:1.9767, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0472 (C:1.9756, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0492 (C:1.9733, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0489 (C:1.9739, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0486 (C:1.9835, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0476 (C:1.9767, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0476 (C:1.9694, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0481 (C:1.9738, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0497 (C:1.9718, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0516 (C:1.9739, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0491 (C:1.9730, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0494 (C:1.9795, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0477 (C:1.9732, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0465 (C:1.9713, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0487 (C:1.9745, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0459 (C:1.9706, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0466 (C:1.9771, R:0.0014, T:0.0465(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 140 TRAINING SUMMARY:
  Total Loss: 0.0480
  Contrastive: 1.9732
  Reconstruction: 0.0014
  Topological: 0.0478 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.5763
  Contrastive: 1.9395
  Reconstruction: 0.0014
  Topological: 0.5762 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 140/300 COMPLETE (43.9s)
Train Loss: 0.0480 (C:1.9732, R:0.0014, T:0.0478)
Val Loss:   0.5763 (C:1.9395, R:0.0014, T:0.5762)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 141 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0445 (C:1.9736, R:0.0014, T:0.0444(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0490 (C:1.9727, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0485 (C:1.9743, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0508 (C:1.9722, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0504 (C:1.9769, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0487 (C:1.9720, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0471 (C:1.9711, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0502 (C:1.9757, R:0.0014, T:0.0501(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0518 (C:1.9743, R:0.0014, T:0.0517(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0467 (C:1.9729, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0511 (C:1.9736, R:0.0014, T:0.0510(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0484 (C:1.9715, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0448 (C:1.9722, R:0.0014, T:0.0447(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0480 (C:1.9754, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0475 (C:1.9746, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0465 (C:1.9726, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0504 (C:1.9728, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0480 (C:1.9776, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0474 (C:1.9743, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0439 (C:1.9694, R:0.0014, T:0.0437(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0458 (C:1.9681, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0500 (C:1.9754, R:0.0014, T:0.0498(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 141 TRAINING SUMMARY:
  Total Loss: 0.0478
  Contrastive: 1.9728
  Reconstruction: 0.0014
  Topological: 0.0477 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.5495
  Contrastive: 1.9362
  Reconstruction: 0.0014
  Topological: 0.5494 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 141/300 COMPLETE (44.0s)
Train Loss: 0.0478 (C:1.9728, R:0.0014, T:0.0477)
Val Loss:   0.5495 (C:1.9362, R:0.0014, T:0.5494)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 142 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0476 (C:1.9741, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0454 (C:1.9730, R:0.0014, T:0.0452(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0499 (C:1.9763, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0469 (C:1.9712, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0489 (C:1.9708, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0450 (C:1.9720, R:0.0014, T:0.0448(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0464 (C:1.9743, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0466 (C:1.9741, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0450 (C:1.9752, R:0.0014, T:0.0449(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0481 (C:1.9721, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0465 (C:1.9731, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0474 (C:1.9775, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0467 (C:1.9762, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0464 (C:1.9708, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0498 (C:1.9700, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0481 (C:1.9748, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0475 (C:1.9721, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0458 (C:1.9777, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0480 (C:1.9759, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0475 (C:1.9692, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0498 (C:1.9759, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0481 (C:1.9758, R:0.0014, T:0.0480(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 142 TRAINING SUMMARY:
  Total Loss: 0.0479
  Contrastive: 1.9732
  Reconstruction: 0.0014
  Topological: 0.0477 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.5585
  Contrastive: 1.9327
  Reconstruction: 0.0014
  Topological: 0.5583 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 142/300 COMPLETE (43.5s)
Train Loss: 0.0479 (C:1.9732, R:0.0014, T:0.0477)
Val Loss:   0.5585 (C:1.9327, R:0.0014, T:0.5583)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 143 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0480 (C:1.9700, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0471 (C:1.9759, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0478 (C:1.9781, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0489 (C:1.9746, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0499 (C:1.9724, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0475 (C:1.9746, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0479 (C:1.9717, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0487 (C:1.9654, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0467 (C:1.9751, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0487 (C:1.9716, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0475 (C:1.9695, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0472 (C:1.9744, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0472 (C:1.9714, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0458 (C:1.9737, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0453 (C:1.9727, R:0.0014, T:0.0452(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0457 (C:1.9682, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0461 (C:1.9699, R:0.0014, T:0.0459(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0483 (C:1.9760, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0460 (C:1.9709, R:0.0014, T:0.0459(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0481 (C:1.9741, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0481 (C:1.9736, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0477 (C:1.9750, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0476

ğŸ“Š EPOCH 143 TRAINING SUMMARY:
  Total Loss: 0.0477
  Contrastive: 1.9730
  Reconstruction: 0.0014
  Topological: 0.0476 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.5600
  Contrastive: 1.9348
  Reconstruction: 0.0014
  Topological: 0.5598 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 143/300 COMPLETE (43.2s)
Train Loss: 0.0477 (C:1.9730, R:0.0014, T:0.0476)
Val Loss:   0.5600 (C:1.9348, R:0.0014, T:0.5598)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 144 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0458 (C:1.9711, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0484 (C:1.9700, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0458 (C:1.9744, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0462 (C:1.9689, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0492 (C:1.9752, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0489 (C:1.9768, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0471 (C:1.9726, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0470 (C:1.9730, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0497 (C:1.9737, R:0.0014, T:0.0495(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0467 (C:1.9729, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0444 (C:1.9720, R:0.0014, T:0.0443(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0477 (C:1.9746, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0473 (C:1.9737, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0467 (C:1.9679, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0469 (C:1.9692, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0467 (C:1.9704, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0489 (C:1.9739, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0442 (C:1.9727, R:0.0014, T:0.0441(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0467 (C:1.9699, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0454 (C:1.9693, R:0.0014, T:0.0453(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0477 (C:1.9690, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0506 (C:1.9707, R:0.0014, T:0.0505(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0475

ğŸ“Š EPOCH 144 TRAINING SUMMARY:
  Total Loss: 0.0476
  Contrastive: 1.9729
  Reconstruction: 0.0014
  Topological: 0.0475 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.5625
  Contrastive: 1.9368
  Reconstruction: 0.0014
  Topological: 0.5624 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 144/300 COMPLETE (43.6s)
Train Loss: 0.0476 (C:1.9729, R:0.0014, T:0.0475)
Val Loss:   0.5625 (C:1.9368, R:0.0014, T:0.5624)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 145 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0486 (C:1.9748, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0457 (C:1.9730, R:0.0014, T:0.0455(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0492 (C:1.9757, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0456 (C:1.9776, R:0.0014, T:0.0455(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0469 (C:1.9741, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0476 (C:1.9761, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0457 (C:1.9745, R:0.0014, T:0.0455(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0474 (C:1.9752, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0476 (C:1.9758, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0475 (C:1.9766, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0455 (C:1.9714, R:0.0014, T:0.0453(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0486 (C:1.9678, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0479 (C:1.9717, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0495 (C:1.9771, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0496 (C:1.9761, R:0.0014, T:0.0495(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0493 (C:1.9695, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0500 (C:1.9723, R:0.0014, T:0.0499(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0447 (C:1.9689, R:0.0014, T:0.0446(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0525 (C:1.9736, R:0.0014, T:0.0524(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0464 (C:1.9750, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0501 (C:1.9730, R:0.0014, T:0.0499(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0482 (C:1.9711, R:0.0014, T:0.0481(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 145 TRAINING SUMMARY:
  Total Loss: 0.0479
  Contrastive: 1.9728
  Reconstruction: 0.0014
  Topological: 0.0477 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.5698
  Contrastive: 1.9331
  Reconstruction: 0.0014
  Topological: 0.5697 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 145/300 COMPLETE (43.2s)
Train Loss: 0.0479 (C:1.9728, R:0.0014, T:0.0477)
Val Loss:   0.5698 (C:1.9331, R:0.0014, T:0.5697)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 146 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0477 (C:1.9718, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0497 (C:1.9774, R:0.0014, T:0.0495(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0464 (C:1.9683, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0442 (C:1.9661, R:0.0014, T:0.0440(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0492 (C:1.9701, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0461 (C:1.9754, R:0.0014, T:0.0460(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0491 (C:1.9711, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0471 (C:1.9751, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0492 (C:1.9744, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0480 (C:1.9738, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0491 (C:1.9757, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0488 (C:1.9722, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0475 (C:1.9757, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0458 (C:1.9745, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0477 (C:1.9770, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0490 (C:1.9750, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0481 (C:1.9758, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0477 (C:1.9676, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0462 (C:1.9748, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0500 (C:1.9726, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0503 (C:1.9775, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0463 (C:1.9770, R:0.0014, T:0.0462(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 146 TRAINING SUMMARY:
  Total Loss: 0.0478
  Contrastive: 1.9731
  Reconstruction: 0.0014
  Topological: 0.0476 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.5363
  Contrastive: 1.9331
  Reconstruction: 0.0014
  Topological: 0.5362 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 146/300 COMPLETE (43.2s)
Train Loss: 0.0478 (C:1.9731, R:0.0014, T:0.0476)
Val Loss:   0.5363 (C:1.9331, R:0.0014, T:0.5362)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 147 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0469 (C:1.9739, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0469 (C:1.9716, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0470 (C:1.9760, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0487 (C:1.9760, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0437 (C:1.9718, R:0.0014, T:0.0435(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0498 (C:1.9670, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0480 (C:1.9703, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0491 (C:1.9698, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0462 (C:1.9733, R:0.0014, T:0.0460(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0481 (C:1.9717, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0463 (C:1.9746, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0461 (C:1.9741, R:0.0014, T:0.0459(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0466 (C:1.9742, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0483 (C:1.9734, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0482 (C:1.9762, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0479 (C:1.9750, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0501 (C:1.9710, R:0.0014, T:0.0499(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0481 (C:1.9757, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0513 (C:1.9739, R:0.0014, T:0.0511(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0477 (C:1.9747, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0466 (C:1.9765, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0483 (C:1.9746, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0474

ğŸ“Š EPOCH 147 TRAINING SUMMARY:
  Total Loss: 0.0476
  Contrastive: 1.9729
  Reconstruction: 0.0014
  Topological: 0.0474 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.5623
  Contrastive: 1.9301
  Reconstruction: 0.0014
  Topological: 0.5621 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 147/300 COMPLETE (43.3s)
Train Loss: 0.0476 (C:1.9729, R:0.0014, T:0.0474)
Val Loss:   0.5623 (C:1.9301, R:0.0014, T:0.5621)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 148 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0499 (C:1.9744, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0458 (C:1.9750, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0488 (C:1.9765, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0448 (C:1.9679, R:0.0014, T:0.0447(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0478 (C:1.9679, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0493 (C:1.9736, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0455 (C:1.9720, R:0.0014, T:0.0453(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0477 (C:1.9758, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0490 (C:1.9734, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0481 (C:1.9734, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0504 (C:1.9770, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0457 (C:1.9718, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0477 (C:1.9775, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0460 (C:1.9761, R:0.0014, T:0.0459(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0462 (C:1.9725, R:0.0014, T:0.0460(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0506 (C:1.9747, R:0.0014, T:0.0505(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0486 (C:1.9709, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0457 (C:1.9766, R:0.0014, T:0.0455(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0482 (C:1.9761, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0449 (C:1.9720, R:0.0014, T:0.0448(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0508 (C:1.9797, R:0.0014, T:0.0506(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0510 (C:1.9675, R:0.0014, T:0.0509(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 148 TRAINING SUMMARY:
  Total Loss: 0.0477
  Contrastive: 1.9729
  Reconstruction: 0.0014
  Topological: 0.0476 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.5593
  Contrastive: 1.9386
  Reconstruction: 0.0014
  Topological: 0.5591 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 148/300 COMPLETE (43.3s)
Train Loss: 0.0477 (C:1.9729, R:0.0014, T:0.0476)
Val Loss:   0.5593 (C:1.9386, R:0.0014, T:0.5591)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 149 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0448 (C:1.9713, R:0.0014, T:0.0447(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0472 (C:1.9772, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0503 (C:1.9676, R:0.0014, T:0.0501(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0485 (C:1.9748, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0459 (C:1.9748, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0441 (C:1.9768, R:0.0014, T:0.0440(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0470 (C:1.9692, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0469 (C:1.9712, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0469 (C:1.9740, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0468 (C:1.9742, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0510 (C:1.9773, R:0.0014, T:0.0509(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0447 (C:1.9760, R:0.0014, T:0.0446(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0483 (C:1.9716, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0488 (C:1.9686, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0466 (C:1.9730, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0480 (C:1.9738, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0485 (C:1.9708, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0495 (C:1.9735, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0476 (C:1.9718, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0468 (C:1.9706, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0483 (C:1.9767, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0509 (C:1.9721, R:0.0014, T:0.0508(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0474

ğŸ“Š EPOCH 149 TRAINING SUMMARY:
  Total Loss: 0.0475
  Contrastive: 1.9732
  Reconstruction: 0.0014
  Topological: 0.0474 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.5215
  Contrastive: 1.9363
  Reconstruction: 0.0014
  Topological: 0.5214 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 149/300 COMPLETE (44.1s)
Train Loss: 0.0475 (C:1.9732, R:0.0014, T:0.0474)
Val Loss:   0.5215 (C:1.9363, R:0.0014, T:0.5214)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 150 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0481 (C:1.9763, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0465 (C:1.9778, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0467 (C:1.9699, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0444 (C:1.9698, R:0.0014, T:0.0443(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0485 (C:1.9719, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0490 (C:1.9699, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0438 (C:1.9724, R:0.0014, T:0.0437(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0491 (C:1.9671, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0470 (C:1.9738, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0458 (C:1.9743, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0487 (C:1.9758, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0513 (C:1.9728, R:0.0014, T:0.0512(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0474 (C:1.9744, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0476 (C:1.9729, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0470 (C:1.9730, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0462 (C:1.9727, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0473 (C:1.9726, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0474 (C:1.9711, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0500 (C:1.9759, R:0.0014, T:0.0499(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0467 (C:1.9769, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0471 (C:1.9772, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0473 (C:1.9714, R:0.0014, T:0.0472(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 150 TRAINING SUMMARY:
  Total Loss: 0.0475
  Contrastive: 1.9726
  Reconstruction: 0.0014
  Topological: 0.0474 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.5216
  Contrastive: 1.9418
  Reconstruction: 0.0014
  Topological: 0.5214 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 150/300 COMPLETE (43.8s)
Train Loss: 0.0475 (C:1.9726, R:0.0014, T:0.0474)
Val Loss:   0.5216 (C:1.9418, R:0.0014, T:0.5214)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 151 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0504 (C:1.9743, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0466 (C:1.9720, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0487 (C:1.9750, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0468 (C:1.9736, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0461 (C:1.9730, R:0.0014, T:0.0460(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0483 (C:1.9741, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0465 (C:1.9715, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0452 (C:1.9724, R:0.0014, T:0.0450(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0484 (C:1.9718, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0478 (C:1.9685, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0485 (C:1.9781, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0453 (C:1.9726, R:0.0014, T:0.0451(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0476 (C:1.9739, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0490 (C:1.9757, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0461 (C:1.9708, R:0.0014, T:0.0459(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0482 (C:1.9760, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0492 (C:1.9764, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0461 (C:1.9686, R:0.0014, T:0.0459(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0474 (C:1.9755, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0481 (C:1.9732, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0467 (C:1.9629, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0497 (C:1.9696, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0472

ğŸ“Š EPOCH 151 TRAINING SUMMARY:
  Total Loss: 0.0474
  Contrastive: 1.9728
  Reconstruction: 0.0014
  Topological: 0.0472 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.5252
  Contrastive: 1.9368
  Reconstruction: 0.0014
  Topological: 0.5250 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 151/300 COMPLETE (43.3s)
Train Loss: 0.0474 (C:1.9728, R:0.0014, T:0.0472)
Val Loss:   0.5252 (C:1.9368, R:0.0014, T:0.5250)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 152 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0457 (C:1.9697, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0477 (C:1.9723, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0498 (C:1.9732, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0460 (C:1.9719, R:0.0014, T:0.0459(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0490 (C:1.9720, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0504 (C:1.9697, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0479 (C:1.9781, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0505 (C:1.9726, R:0.0014, T:0.0504(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0479 (C:1.9694, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0459 (C:1.9692, R:0.0014, T:0.0458(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0487 (C:1.9675, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0477 (C:1.9700, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0449 (C:1.9733, R:0.0014, T:0.0448(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0466 (C:1.9695, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0492 (C:1.9739, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0483 (C:1.9721, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0470 (C:1.9740, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0452 (C:1.9736, R:0.0014, T:0.0450(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0499 (C:1.9739, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0463 (C:1.9641, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0451 (C:1.9729, R:0.0014, T:0.0449(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0467 (C:1.9694, R:0.0014, T:0.0466(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 152 TRAINING SUMMARY:
  Total Loss: 0.0476
  Contrastive: 1.9721
  Reconstruction: 0.0014
  Topological: 0.0474 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.5629
  Contrastive: 1.9309
  Reconstruction: 0.0014
  Topological: 0.5628 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 152/300 COMPLETE (43.9s)
Train Loss: 0.0476 (C:1.9721, R:0.0014, T:0.0474)
Val Loss:   0.5629 (C:1.9309, R:0.0014, T:0.5628)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 153 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0489 (C:1.9675, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0466 (C:1.9745, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0487 (C:1.9750, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0466 (C:1.9689, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0479 (C:1.9681, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0519 (C:1.9690, R:0.0014, T:0.0517(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0443 (C:1.9778, R:0.0014, T:0.0442(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0480 (C:1.9743, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0491 (C:1.9728, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0463 (C:1.9751, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0493 (C:1.9711, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0502 (C:1.9674, R:0.0014, T:0.0501(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0452 (C:1.9740, R:0.0014, T:0.0451(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0452 (C:1.9647, R:0.0014, T:0.0451(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0488 (C:1.9635, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0449 (C:1.9741, R:0.0014, T:0.0448(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0466 (C:1.9746, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0460 (C:1.9728, R:0.0014, T:0.0458(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0474 (C:1.9736, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0504 (C:1.9686, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0461 (C:1.9730, R:0.0014, T:0.0459(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0520 (C:1.9771, R:0.0014, T:0.0519(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0472

ğŸ“Š EPOCH 153 TRAINING SUMMARY:
  Total Loss: 0.0474
  Contrastive: 1.9720
  Reconstruction: 0.0014
  Topological: 0.0472 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.5082
  Contrastive: 1.9274
  Reconstruction: 0.0014
  Topological: 0.5080 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 153/300 COMPLETE (44.5s)
Train Loss: 0.0474 (C:1.9720, R:0.0014, T:0.0472)
Val Loss:   0.5082 (C:1.9274, R:0.0014, T:0.5080)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 154 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0464 (C:1.9712, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0447 (C:1.9667, R:0.0014, T:0.0446(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0479 (C:1.9701, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0477 (C:1.9699, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0458 (C:1.9645, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0480 (C:1.9773, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0472 (C:1.9708, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0473 (C:1.9723, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0468 (C:1.9726, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0449 (C:1.9766, R:0.0014, T:0.0448(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0468 (C:1.9761, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0479 (C:1.9694, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0445 (C:1.9730, R:0.0014, T:0.0444(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0448 (C:1.9737, R:0.0014, T:0.0447(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0479 (C:1.9740, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0511 (C:1.9731, R:0.0014, T:0.0509(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0473 (C:1.9734, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0477 (C:1.9752, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0460 (C:1.9734, R:0.0014, T:0.0458(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0465 (C:1.9743, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0487 (C:1.9719, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0459 (C:1.9727, R:0.0014, T:0.0458(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0470

ğŸ“Š EPOCH 154 TRAINING SUMMARY:
  Total Loss: 0.0471
  Contrastive: 1.9723
  Reconstruction: 0.0014
  Topological: 0.0470 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.5229
  Contrastive: 1.9346
  Reconstruction: 0.0014
  Topological: 0.5227 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 154/300 COMPLETE (43.4s)
Train Loss: 0.0471 (C:1.9723, R:0.0014, T:0.0470)
Val Loss:   0.5229 (C:1.9346, R:0.0014, T:0.5227)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 155 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0485 (C:1.9708, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0480 (C:1.9758, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0494 (C:1.9727, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0466 (C:1.9687, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0466 (C:1.9689, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0504 (C:1.9718, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0494 (C:1.9729, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0479 (C:1.9677, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0454 (C:1.9739, R:0.0014, T:0.0452(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0490 (C:1.9755, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0467 (C:1.9728, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0459 (C:1.9739, R:0.0014, T:0.0458(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0476 (C:1.9796, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0481 (C:1.9719, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0487 (C:1.9730, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0513 (C:1.9693, R:0.0014, T:0.0512(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0455 (C:1.9678, R:0.0014, T:0.0454(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0467 (C:1.9718, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0490 (C:1.9696, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0498 (C:1.9768, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0477 (C:1.9725, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0475 (C:1.9762, R:0.0014, T:0.0474(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 155 TRAINING SUMMARY:
  Total Loss: 0.0474
  Contrastive: 1.9721
  Reconstruction: 0.0014
  Topological: 0.0473 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4801
  Contrastive: 1.9328
  Reconstruction: 0.0014
  Topological: 0.4800 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 155/300 COMPLETE (43.7s)
Train Loss: 0.0474 (C:1.9721, R:0.0014, T:0.0473)
Val Loss:   0.4801 (C:1.9328, R:0.0014, T:0.4800)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 156 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0500 (C:1.9721, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0462 (C:1.9740, R:0.0014, T:0.0460(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0452 (C:1.9751, R:0.0014, T:0.0451(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0447 (C:1.9732, R:0.0014, T:0.0446(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0494 (C:1.9681, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0471 (C:1.9708, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0462 (C:1.9671, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0487 (C:1.9679, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0459 (C:1.9714, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0482 (C:1.9745, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0468 (C:1.9741, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0468 (C:1.9689, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0500 (C:1.9695, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0463 (C:1.9695, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0453 (C:1.9708, R:0.0014, T:0.0452(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0456 (C:1.9689, R:0.0014, T:0.0455(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0470 (C:1.9751, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0494 (C:1.9740, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0446 (C:1.9676, R:0.0014, T:0.0444(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0465 (C:1.9737, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0478 (C:1.9714, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0492 (C:1.9734, R:0.0014, T:0.0491(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 156 TRAINING SUMMARY:
  Total Loss: 0.0472
  Contrastive: 1.9720
  Reconstruction: 0.0014
  Topological: 0.0471 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.5033
  Contrastive: 1.9319
  Reconstruction: 0.0014
  Topological: 0.5032 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 156/300 COMPLETE (43.6s)
Train Loss: 0.0472 (C:1.9720, R:0.0014, T:0.0471)
Val Loss:   0.5033 (C:1.9319, R:0.0014, T:0.5032)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 157 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0448 (C:1.9752, R:0.0014, T:0.0447(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0506 (C:1.9753, R:0.0014, T:0.0504(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0447 (C:1.9753, R:0.0014, T:0.0446(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0434 (C:1.9756, R:0.0014, T:0.0433(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0470 (C:1.9729, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0469 (C:1.9698, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0457 (C:1.9702, R:0.0014, T:0.0455(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0499 (C:1.9740, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0465 (C:1.9779, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0456 (C:1.9748, R:0.0014, T:0.0455(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0507 (C:1.9692, R:0.0014, T:0.0506(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0456 (C:1.9728, R:0.0014, T:0.0455(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0470 (C:1.9685, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0467 (C:1.9719, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0445 (C:1.9753, R:0.0014, T:0.0443(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0489 (C:1.9721, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0453 (C:1.9722, R:0.0014, T:0.0452(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0461 (C:1.9737, R:0.0014, T:0.0460(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0493 (C:1.9736, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0497 (C:1.9706, R:0.0014, T:0.0495(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0466 (C:1.9742, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0489 (C:1.9691, R:0.0014, T:0.0488(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 157 TRAINING SUMMARY:
  Total Loss: 0.0474
  Contrastive: 1.9720
  Reconstruction: 0.0014
  Topological: 0.0472 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.5055
  Contrastive: 1.9382
  Reconstruction: 0.0014
  Topological: 0.5054 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 157/300 COMPLETE (42.9s)
Train Loss: 0.0474 (C:1.9720, R:0.0014, T:0.0472)
Val Loss:   0.5055 (C:1.9382, R:0.0014, T:0.5054)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 158 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0468 (C:1.9744, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0488 (C:1.9724, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0451 (C:1.9688, R:0.0014, T:0.0450(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0440 (C:1.9770, R:0.0014, T:0.0439(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0474 (C:1.9745, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0474 (C:1.9749, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0477 (C:1.9710, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0451 (C:1.9689, R:0.0014, T:0.0450(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0440 (C:1.9701, R:0.0014, T:0.0439(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0441 (C:1.9735, R:0.0014, T:0.0440(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0478 (C:1.9736, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0478 (C:1.9725, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0458 (C:1.9725, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0499 (C:1.9698, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0447 (C:1.9725, R:0.0014, T:0.0445(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0482 (C:1.9731, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0470 (C:1.9734, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0484 (C:1.9692, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0495 (C:1.9762, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0473 (C:1.9732, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0463 (C:1.9654, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0473 (C:1.9716, R:0.0014, T:0.0471(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 158 TRAINING SUMMARY:
  Total Loss: 0.0472
  Contrastive: 1.9718
  Reconstruction: 0.0014
  Topological: 0.0470 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4746
  Contrastive: 1.9372
  Reconstruction: 0.0014
  Topological: 0.4744 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 158/300 COMPLETE (42.1s)
Train Loss: 0.0472 (C:1.9718, R:0.0014, T:0.0470)
Val Loss:   0.4746 (C:1.9372, R:0.0014, T:0.4744)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 159 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0468 (C:1.9744, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0460 (C:1.9736, R:0.0014, T:0.0459(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0471 (C:1.9715, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0472 (C:1.9716, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0467 (C:1.9760, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0452 (C:1.9701, R:0.0014, T:0.0450(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0442 (C:1.9770, R:0.0014, T:0.0441(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0471 (C:1.9704, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0501 (C:1.9714, R:0.0014, T:0.0499(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0474 (C:1.9729, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0464 (C:1.9698, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0488 (C:1.9738, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0486 (C:1.9714, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0482 (C:1.9691, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0488 (C:1.9690, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0489 (C:1.9716, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0464 (C:1.9789, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0482 (C:1.9690, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0473 (C:1.9759, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0451 (C:1.9703, R:0.0014, T:0.0449(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0460 (C:1.9760, R:0.0014, T:0.0459(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0459 (C:1.9670, R:0.0014, T:0.0457(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 159 TRAINING SUMMARY:
  Total Loss: 0.0472
  Contrastive: 1.9718
  Reconstruction: 0.0014
  Topological: 0.0470 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.5095
  Contrastive: 1.9352
  Reconstruction: 0.0014
  Topological: 0.5093 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 159/300 COMPLETE (42.5s)
Train Loss: 0.0472 (C:1.9718, R:0.0014, T:0.0470)
Val Loss:   0.5095 (C:1.9352, R:0.0014, T:0.5093)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 160 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0495 (C:1.9740, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0437 (C:1.9760, R:0.0014, T:0.0435(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0441 (C:1.9706, R:0.0014, T:0.0440(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0464 (C:1.9755, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0475 (C:1.9670, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0469 (C:1.9743, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0444 (C:1.9757, R:0.0014, T:0.0443(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0458 (C:1.9726, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0464 (C:1.9712, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0474 (C:1.9721, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0447 (C:1.9744, R:0.0014, T:0.0446(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0469 (C:1.9734, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0491 (C:1.9751, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0477 (C:1.9744, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0485 (C:1.9693, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0450 (C:1.9728, R:0.0014, T:0.0448(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0493 (C:1.9736, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0500 (C:1.9725, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0462 (C:1.9739, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0493 (C:1.9741, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0473 (C:1.9706, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0477 (C:1.9638, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0470

ğŸ“Š EPOCH 160 TRAINING SUMMARY:
  Total Loss: 0.0471
  Contrastive: 1.9719
  Reconstruction: 0.0014
  Topological: 0.0470 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4758
  Contrastive: 1.9298
  Reconstruction: 0.0014
  Topological: 0.4756 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 160/300 COMPLETE (42.6s)
Train Loss: 0.0471 (C:1.9719, R:0.0014, T:0.0470)
Val Loss:   0.4758 (C:1.9298, R:0.0014, T:0.4756)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 161 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0455 (C:1.9695, R:0.0014, T:0.0454(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0438 (C:1.9669, R:0.0014, T:0.0436(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0478 (C:1.9725, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0469 (C:1.9707, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0479 (C:1.9725, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0458 (C:1.9727, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0465 (C:1.9760, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0471 (C:1.9702, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0477 (C:1.9703, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0456 (C:1.9755, R:0.0014, T:0.0455(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0495 (C:1.9747, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0450 (C:1.9693, R:0.0014, T:0.0449(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0470 (C:1.9738, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0496 (C:1.9714, R:0.0014, T:0.0495(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0513 (C:1.9698, R:0.0014, T:0.0512(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0473 (C:1.9700, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0447 (C:1.9727, R:0.0014, T:0.0445(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0491 (C:1.9744, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0473 (C:1.9663, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0436 (C:1.9702, R:0.0014, T:0.0435(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0474 (C:1.9727, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0469 (C:1.9755, R:0.0014, T:0.0467(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 161 TRAINING SUMMARY:
  Total Loss: 0.0472
  Contrastive: 1.9718
  Reconstruction: 0.0014
  Topological: 0.0471 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.5022
  Contrastive: 1.9312
  Reconstruction: 0.0014
  Topological: 0.5020 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 161/300 COMPLETE (42.8s)
Train Loss: 0.0472 (C:1.9718, R:0.0014, T:0.0471)
Val Loss:   0.5022 (C:1.9312, R:0.0014, T:0.5020)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 162 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0469 (C:1.9705, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0476 (C:1.9711, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0436 (C:1.9766, R:0.0014, T:0.0435(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0463 (C:1.9750, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0480 (C:1.9643, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0474 (C:1.9686, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0487 (C:1.9720, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0493 (C:1.9729, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0473 (C:1.9708, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0499 (C:1.9721, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0472 (C:1.9710, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0462 (C:1.9721, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0460 (C:1.9691, R:0.0014, T:0.0458(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0451 (C:1.9725, R:0.0014, T:0.0450(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0453 (C:1.9716, R:0.0014, T:0.0452(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0471 (C:1.9728, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0476 (C:1.9700, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0446 (C:1.9721, R:0.0014, T:0.0445(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0473 (C:1.9757, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0471 (C:1.9698, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0492 (C:1.9680, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0479 (C:1.9695, R:0.0014, T:0.0477(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 162 TRAINING SUMMARY:
  Total Loss: 0.0471
  Contrastive: 1.9719
  Reconstruction: 0.0014
  Topological: 0.0470 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4968
  Contrastive: 1.9367
  Reconstruction: 0.0014
  Topological: 0.4967 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 162/300 COMPLETE (43.2s)
Train Loss: 0.0471 (C:1.9719, R:0.0014, T:0.0470)
Val Loss:   0.4968 (C:1.9367, R:0.0014, T:0.4967)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 163 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0454 (C:1.9677, R:0.0014, T:0.0453(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0459 (C:1.9702, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0471 (C:1.9739, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0444 (C:1.9770, R:0.0014, T:0.0442(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0439 (C:1.9749, R:0.0014, T:0.0438(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0441 (C:1.9762, R:0.0014, T:0.0439(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0477 (C:1.9752, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0475 (C:1.9754, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0460 (C:1.9670, R:0.0014, T:0.0459(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0485 (C:1.9730, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0446 (C:1.9725, R:0.0014, T:0.0445(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0468 (C:1.9751, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0480 (C:1.9729, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0489 (C:1.9716, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0463 (C:1.9672, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0461 (C:1.9740, R:0.0014, T:0.0459(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0479 (C:1.9704, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0496 (C:1.9666, R:0.0014, T:0.0495(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0471 (C:1.9758, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0488 (C:1.9722, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0502 (C:1.9675, R:0.0014, T:0.0501(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0507 (C:1.9671, R:0.0014, T:0.0506(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 163 TRAINING SUMMARY:
  Total Loss: 0.0472
  Contrastive: 1.9719
  Reconstruction: 0.0014
  Topological: 0.0470 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4721
  Contrastive: 1.9304
  Reconstruction: 0.0014
  Topological: 0.4719 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 163/300 COMPLETE (43.2s)
Train Loss: 0.0472 (C:1.9719, R:0.0014, T:0.0470)
Val Loss:   0.4721 (C:1.9304, R:0.0014, T:0.4719)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 164 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0440 (C:1.9707, R:0.0014, T:0.0439(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0476 (C:1.9674, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0459 (C:1.9705, R:0.0014, T:0.0458(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0481 (C:1.9720, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0483 (C:1.9706, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0478 (C:1.9712, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0498 (C:1.9687, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0453 (C:1.9739, R:0.0014, T:0.0452(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0466 (C:1.9736, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0461 (C:1.9723, R:0.0014, T:0.0460(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0458 (C:1.9733, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0472 (C:1.9738, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0506 (C:1.9699, R:0.0014, T:0.0505(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0494 (C:1.9752, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0450 (C:1.9749, R:0.0014, T:0.0448(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0473 (C:1.9704, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0480 (C:1.9766, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0489 (C:1.9684, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0454 (C:1.9746, R:0.0014, T:0.0453(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0471 (C:1.9762, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0482 (C:1.9717, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0487 (C:1.9735, R:0.0014, T:0.0486(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 164 TRAINING SUMMARY:
  Total Loss: 0.0471
  Contrastive: 1.9718
  Reconstruction: 0.0014
  Topological: 0.0470 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4905
  Contrastive: 1.9251
  Reconstruction: 0.0014
  Topological: 0.4904 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 164/300 COMPLETE (42.5s)
Train Loss: 0.0471 (C:1.9718, R:0.0014, T:0.0470)
Val Loss:   0.4905 (C:1.9251, R:0.0014, T:0.4904)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 165 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0480 (C:1.9702, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0431 (C:1.9727, R:0.0014, T:0.0429(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0476 (C:1.9684, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0460 (C:1.9693, R:0.0014, T:0.0459(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0456 (C:1.9702, R:0.0014, T:0.0454(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0464 (C:1.9702, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0468 (C:1.9773, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0490 (C:1.9776, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0486 (C:1.9737, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0475 (C:1.9735, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0466 (C:1.9722, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0471 (C:1.9683, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0490 (C:1.9702, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0458 (C:1.9688, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0473 (C:1.9696, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0479 (C:1.9711, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0451 (C:1.9705, R:0.0014, T:0.0450(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0492 (C:1.9731, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0466 (C:1.9764, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0479 (C:1.9676, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0451 (C:1.9726, R:0.0014, T:0.0450(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0471 (C:1.9676, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0469

ğŸ“Š EPOCH 165 TRAINING SUMMARY:
  Total Loss: 0.0471
  Contrastive: 1.9721
  Reconstruction: 0.0014
  Topological: 0.0469 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4472
  Contrastive: 1.9322
  Reconstruction: 0.0014
  Topological: 0.4470 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 165/300 COMPLETE (43.3s)
Train Loss: 0.0471 (C:1.9721, R:0.0014, T:0.0469)
Val Loss:   0.4472 (C:1.9322, R:0.0014, T:0.4470)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 166 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0474 (C:1.9747, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0456 (C:1.9761, R:0.0014, T:0.0454(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0469 (C:1.9698, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0454 (C:1.9690, R:0.0014, T:0.0453(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0440 (C:1.9686, R:0.0014, T:0.0438(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0494 (C:1.9718, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0471 (C:1.9718, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0473 (C:1.9677, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0472 (C:1.9726, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0446 (C:1.9748, R:0.0014, T:0.0444(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0487 (C:1.9696, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0488 (C:1.9739, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0491 (C:1.9756, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0507 (C:1.9721, R:0.0014, T:0.0506(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0464 (C:1.9723, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0480 (C:1.9690, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0483 (C:1.9733, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0467 (C:1.9718, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0470 (C:1.9700, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0483 (C:1.9728, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0475 (C:1.9647, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0490 (C:1.9706, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0469

ğŸ“Š EPOCH 166 TRAINING SUMMARY:
  Total Loss: 0.0470
  Contrastive: 1.9722
  Reconstruction: 0.0014
  Topological: 0.0469 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4808
  Contrastive: 1.9300
  Reconstruction: 0.0014
  Topological: 0.4806 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 166/300 COMPLETE (44.3s)
Train Loss: 0.0470 (C:1.9722, R:0.0014, T:0.0469)
Val Loss:   0.4808 (C:1.9300, R:0.0014, T:0.4806)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 167 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0474 (C:1.9717, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0473 (C:1.9716, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0503 (C:1.9756, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0458 (C:1.9697, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0477 (C:1.9743, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0458 (C:1.9682, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0440 (C:1.9722, R:0.0014, T:0.0439(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0487 (C:1.9779, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0485 (C:1.9680, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0478 (C:1.9758, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0478 (C:1.9729, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0451 (C:1.9758, R:0.0014, T:0.0450(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0484 (C:1.9713, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0467 (C:1.9708, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0460 (C:1.9731, R:0.0014, T:0.0458(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0457 (C:1.9752, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0493 (C:1.9741, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0462 (C:1.9750, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0443 (C:1.9694, R:0.0014, T:0.0441(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0489 (C:1.9690, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0471 (C:1.9753, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0479 (C:1.9712, R:0.0014, T:0.0478(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 167 TRAINING SUMMARY:
  Total Loss: 0.0471
  Contrastive: 1.9716
  Reconstruction: 0.0014
  Topological: 0.0469 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4508
  Contrastive: 1.9283
  Reconstruction: 0.0014
  Topological: 0.4507 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 167/300 COMPLETE (43.3s)
Train Loss: 0.0471 (C:1.9716, R:0.0014, T:0.0469)
Val Loss:   0.4508 (C:1.9283, R:0.0014, T:0.4507)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 168 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0471 (C:1.9724, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0447 (C:1.9718, R:0.0014, T:0.0446(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0464 (C:1.9695, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0473 (C:1.9759, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0474 (C:1.9727, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0462 (C:1.9721, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0455 (C:1.9713, R:0.0014, T:0.0453(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0455 (C:1.9696, R:0.0014, T:0.0454(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0432 (C:1.9754, R:0.0014, T:0.0431(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0463 (C:1.9745, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0508 (C:1.9685, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0481 (C:1.9720, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0478 (C:1.9750, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0481 (C:1.9725, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0460 (C:1.9762, R:0.0014, T:0.0458(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0469 (C:1.9726, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0467 (C:1.9664, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0496 (C:1.9697, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0500 (C:1.9717, R:0.0014, T:0.0499(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0485 (C:1.9731, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0487 (C:1.9719, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0479 (C:1.9678, R:0.0014, T:0.0477(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 168 TRAINING SUMMARY:
  Total Loss: 0.0472
  Contrastive: 1.9717
  Reconstruction: 0.0014
  Topological: 0.0471 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4692
  Contrastive: 1.9299
  Reconstruction: 0.0014
  Topological: 0.4691 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 168/300 COMPLETE (43.6s)
Train Loss: 0.0472 (C:1.9717, R:0.0014, T:0.0471)
Val Loss:   0.4692 (C:1.9299, R:0.0014, T:0.4691)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 169 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0435 (C:1.9697, R:0.0014, T:0.0434(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0448 (C:1.9728, R:0.0014, T:0.0447(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0481 (C:1.9710, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0456 (C:1.9724, R:0.0014, T:0.0454(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0478 (C:1.9726, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0454 (C:1.9753, R:0.0014, T:0.0452(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0434 (C:1.9727, R:0.0014, T:0.0433(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0484 (C:1.9688, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0454 (C:1.9739, R:0.0014, T:0.0452(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0502 (C:1.9692, R:0.0014, T:0.0501(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0481 (C:1.9712, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0471 (C:1.9690, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0480 (C:1.9725, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0488 (C:1.9724, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0451 (C:1.9760, R:0.0014, T:0.0449(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0458 (C:1.9690, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0469 (C:1.9735, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0473 (C:1.9733, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0498 (C:1.9699, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0467 (C:1.9717, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0476 (C:1.9739, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0484 (C:1.9781, R:0.0014, T:0.0483(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 169 TRAINING SUMMARY:
  Total Loss: 0.0470
  Contrastive: 1.9717
  Reconstruction: 0.0014
  Topological: 0.0469 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4750
  Contrastive: 1.9353
  Reconstruction: 0.0014
  Topological: 0.4748 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 169/300 COMPLETE (43.8s)
Train Loss: 0.0470 (C:1.9717, R:0.0014, T:0.0469)
Val Loss:   0.4750 (C:1.9353, R:0.0014, T:0.4748)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 170 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0482 (C:1.9737, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0488 (C:1.9718, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0453 (C:1.9714, R:0.0014, T:0.0452(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0451 (C:1.9690, R:0.0014, T:0.0449(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0478 (C:1.9736, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0477 (C:1.9745, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0478 (C:1.9715, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0460 (C:1.9744, R:0.0014, T:0.0459(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0487 (C:1.9732, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0473 (C:1.9720, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0490 (C:1.9686, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0447 (C:1.9730, R:0.0014, T:0.0446(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0457 (C:1.9717, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0491 (C:1.9645, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0480 (C:1.9692, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0471 (C:1.9727, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0460 (C:1.9671, R:0.0014, T:0.0459(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0492 (C:1.9722, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0447 (C:1.9771, R:0.0014, T:0.0445(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0463 (C:1.9718, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0487 (C:1.9738, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0515 (C:1.9723, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0467

ğŸ“Š EPOCH 170 TRAINING SUMMARY:
  Total Loss: 0.0469
  Contrastive: 1.9717
  Reconstruction: 0.0014
  Topological: 0.0467 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4828
  Contrastive: 1.9338
  Reconstruction: 0.0014
  Topological: 0.4826 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 170/300 COMPLETE (44.3s)
Train Loss: 0.0469 (C:1.9717, R:0.0014, T:0.0467)
Val Loss:   0.4828 (C:1.9338, R:0.0014, T:0.4826)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 171 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0475 (C:1.9712, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0447 (C:1.9732, R:0.0014, T:0.0446(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0448 (C:1.9736, R:0.0014, T:0.0446(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0466 (C:1.9671, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0468 (C:1.9711, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0462 (C:1.9693, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0475 (C:1.9691, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0484 (C:1.9722, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0464 (C:1.9776, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0479 (C:1.9714, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0470 (C:1.9674, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0473 (C:1.9683, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0470 (C:1.9699, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0430 (C:1.9659, R:0.0014, T:0.0429(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0493 (C:1.9691, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0469 (C:1.9726, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0471 (C:1.9726, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0460 (C:1.9715, R:0.0014, T:0.0459(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0464 (C:1.9707, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0458 (C:1.9644, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0463 (C:1.9663, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0481 (C:1.9705, R:0.0014, T:0.0479(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 171 TRAINING SUMMARY:
  Total Loss: 0.0471
  Contrastive: 1.9717
  Reconstruction: 0.0014
  Topological: 0.0470 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4603
  Contrastive: 1.9321
  Reconstruction: 0.0014
  Topological: 0.4601 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 171/300 COMPLETE (43.1s)
Train Loss: 0.0471 (C:1.9717, R:0.0014, T:0.0470)
Val Loss:   0.4603 (C:1.9321, R:0.0014, T:0.4601)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 172 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0476 (C:1.9762, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0489 (C:1.9739, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0451 (C:1.9706, R:0.0014, T:0.0449(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0471 (C:1.9707, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0473 (C:1.9661, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0515 (C:1.9746, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0463 (C:1.9765, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0492 (C:1.9689, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0489 (C:1.9702, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0469 (C:1.9770, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0489 (C:1.9705, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0478 (C:1.9695, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0471 (C:1.9714, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0481 (C:1.9718, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0443 (C:1.9739, R:0.0014, T:0.0441(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0446 (C:1.9787, R:0.0014, T:0.0445(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0463 (C:1.9711, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0485 (C:1.9709, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0487 (C:1.9747, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0487 (C:1.9660, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0474 (C:1.9722, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0497 (C:1.9688, R:0.0014, T:0.0496(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 172 TRAINING SUMMARY:
  Total Loss: 0.0471
  Contrastive: 1.9716
  Reconstruction: 0.0014
  Topological: 0.0470 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4626
  Contrastive: 1.9316
  Reconstruction: 0.0014
  Topological: 0.4624 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 172/300 COMPLETE (44.1s)
Train Loss: 0.0471 (C:1.9716, R:0.0014, T:0.0470)
Val Loss:   0.4626 (C:1.9316, R:0.0014, T:0.4624)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 173 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0462 (C:1.9684, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0449 (C:1.9636, R:0.0014, T:0.0448(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0476 (C:1.9738, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0504 (C:1.9707, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0465 (C:1.9643, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0476 (C:1.9689, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0467 (C:1.9663, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0462 (C:1.9703, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0455 (C:1.9648, R:0.0014, T:0.0454(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0491 (C:1.9656, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0453 (C:1.9694, R:0.0014, T:0.0452(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0470 (C:1.9703, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0495 (C:1.9693, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0459 (C:1.9712, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0474 (C:1.9721, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0460 (C:1.9733, R:0.0014, T:0.0459(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0445 (C:1.9741, R:0.0014, T:0.0443(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0455 (C:1.9700, R:0.0014, T:0.0454(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0453 (C:1.9699, R:0.0014, T:0.0451(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0496 (C:1.9781, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0482 (C:1.9727, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0483 (C:1.9704, R:0.0014, T:0.0482(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 173 TRAINING SUMMARY:
  Total Loss: 0.0470
  Contrastive: 1.9715
  Reconstruction: 0.0014
  Topological: 0.0468 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4946
  Contrastive: 1.9313
  Reconstruction: 0.0014
  Topological: 0.4944 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 173/300 COMPLETE (43.7s)
Train Loss: 0.0470 (C:1.9715, R:0.0014, T:0.0468)
Val Loss:   0.4946 (C:1.9313, R:0.0014, T:0.4944)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 174 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0462 (C:1.9713, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0467 (C:1.9753, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0458 (C:1.9704, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0472 (C:1.9709, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0500 (C:1.9724, R:0.0014, T:0.0499(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0505 (C:1.9757, R:0.0014, T:0.0504(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0481 (C:1.9679, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0469 (C:1.9725, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0491 (C:1.9741, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0481 (C:1.9720, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0467 (C:1.9718, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0448 (C:1.9748, R:0.0014, T:0.0447(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0455 (C:1.9692, R:0.0014, T:0.0454(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0489 (C:1.9671, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0480 (C:1.9662, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0494 (C:1.9754, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0443 (C:1.9670, R:0.0014, T:0.0442(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0488 (C:1.9702, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0493 (C:1.9674, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0473 (C:1.9694, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0491 (C:1.9741, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0470 (C:1.9687, R:0.0014, T:0.0469(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 174 TRAINING SUMMARY:
  Total Loss: 0.0471
  Contrastive: 1.9714
  Reconstruction: 0.0014
  Topological: 0.0469 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4340
  Contrastive: 1.9302
  Reconstruction: 0.0014
  Topological: 0.4339 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 174/300 COMPLETE (43.1s)
Train Loss: 0.0471 (C:1.9714, R:0.0014, T:0.0469)
Val Loss:   0.4340 (C:1.9302, R:0.0014, T:0.4339)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 175 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0471 (C:1.9733, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0484 (C:1.9737, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0440 (C:1.9674, R:0.0014, T:0.0438(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0460 (C:1.9680, R:0.0014, T:0.0458(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0447 (C:1.9690, R:0.0014, T:0.0446(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0473 (C:1.9773, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0508 (C:1.9737, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0465 (C:1.9714, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0463 (C:1.9739, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0498 (C:1.9731, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0455 (C:1.9767, R:0.0014, T:0.0453(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0491 (C:1.9671, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0440 (C:1.9693, R:0.0014, T:0.0438(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0453 (C:1.9738, R:0.0014, T:0.0452(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0459 (C:1.9768, R:0.0014, T:0.0458(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0480 (C:1.9717, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0498 (C:1.9719, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0459 (C:1.9660, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0463 (C:1.9724, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0474 (C:1.9758, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0464 (C:1.9705, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0497 (C:1.9713, R:0.0014, T:0.0495(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0467

ğŸ“Š EPOCH 175 TRAINING SUMMARY:
  Total Loss: 0.0468
  Contrastive: 1.9718
  Reconstruction: 0.0014
  Topological: 0.0467 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4847
  Contrastive: 1.9345
  Reconstruction: 0.0014
  Topological: 0.4845 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 175/300 COMPLETE (43.0s)
Train Loss: 0.0468 (C:1.9718, R:0.0014, T:0.0467)
Val Loss:   0.4847 (C:1.9345, R:0.0014, T:0.4845)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 176 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0489 (C:1.9704, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0475 (C:1.9726, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0436 (C:1.9730, R:0.0014, T:0.0435(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0472 (C:1.9728, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0492 (C:1.9666, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0480 (C:1.9753, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0453 (C:1.9686, R:0.0014, T:0.0452(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0512 (C:1.9711, R:0.0014, T:0.0511(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0477 (C:1.9735, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0452 (C:1.9749, R:0.0014, T:0.0451(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0467 (C:1.9708, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0451 (C:1.9759, R:0.0014, T:0.0450(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0470 (C:1.9740, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0483 (C:1.9614, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0489 (C:1.9712, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0464 (C:1.9684, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0497 (C:1.9667, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0426 (C:1.9751, R:0.0014, T:0.0424(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0474 (C:1.9738, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0495 (C:1.9706, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0449 (C:1.9733, R:0.0014, T:0.0448(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0446 (C:1.9687, R:0.0014, T:0.0445(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 176 TRAINING SUMMARY:
  Total Loss: 0.0469
  Contrastive: 1.9714
  Reconstruction: 0.0014
  Topological: 0.0468 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4434
  Contrastive: 1.9311
  Reconstruction: 0.0014
  Topological: 0.4433 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 176/300 COMPLETE (43.0s)
Train Loss: 0.0469 (C:1.9714, R:0.0014, T:0.0468)
Val Loss:   0.4434 (C:1.9311, R:0.0014, T:0.4433)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 177 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0482 (C:1.9741, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0435 (C:1.9736, R:0.0014, T:0.0434(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0493 (C:1.9718, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0469 (C:1.9722, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0493 (C:1.9743, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0481 (C:1.9745, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0482 (C:1.9755, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0456 (C:1.9711, R:0.0014, T:0.0455(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0472 (C:1.9690, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0456 (C:1.9698, R:0.0014, T:0.0455(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0471 (C:1.9732, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0486 (C:1.9731, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0457 (C:1.9723, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0471 (C:1.9698, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0477 (C:1.9781, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0459 (C:1.9668, R:0.0014, T:0.0458(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0457 (C:1.9731, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0480 (C:1.9678, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0453 (C:1.9640, R:0.0014, T:0.0452(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0454 (C:1.9714, R:0.0014, T:0.0452(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0471 (C:1.9768, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0488 (C:1.9700, R:0.0014, T:0.0487(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 177 TRAINING SUMMARY:
  Total Loss: 0.0470
  Contrastive: 1.9716
  Reconstruction: 0.0014
  Topological: 0.0468 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4503
  Contrastive: 1.9307
  Reconstruction: 0.0014
  Topological: 0.4502 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 177/300 COMPLETE (42.9s)
Train Loss: 0.0470 (C:1.9716, R:0.0014, T:0.0468)
Val Loss:   0.4503 (C:1.9307, R:0.0014, T:0.4502)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 178 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0504 (C:1.9713, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0448 (C:1.9701, R:0.0014, T:0.0447(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0438 (C:1.9712, R:0.0014, T:0.0436(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0510 (C:1.9714, R:0.0014, T:0.0509(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0471 (C:1.9654, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0462 (C:1.9653, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0462 (C:1.9711, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0465 (C:1.9769, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0495 (C:1.9705, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0479 (C:1.9732, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0467 (C:1.9704, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0447 (C:1.9724, R:0.0014, T:0.0446(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0452 (C:1.9744, R:0.0014, T:0.0451(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0486 (C:1.9731, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0461 (C:1.9729, R:0.0014, T:0.0459(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0451 (C:1.9775, R:0.0014, T:0.0450(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0451 (C:1.9722, R:0.0014, T:0.0449(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0479 (C:1.9727, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0457 (C:1.9657, R:0.0014, T:0.0455(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0483 (C:1.9772, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0449 (C:1.9720, R:0.0014, T:0.0448(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0464 (C:1.9756, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0465

ğŸ“Š EPOCH 178 TRAINING SUMMARY:
  Total Loss: 0.0467
  Contrastive: 1.9714
  Reconstruction: 0.0014
  Topological: 0.0465 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4123
  Contrastive: 1.9312
  Reconstruction: 0.0014
  Topological: 0.4122 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 178/300 COMPLETE (42.7s)
Train Loss: 0.0467 (C:1.9714, R:0.0014, T:0.0465)
Val Loss:   0.4123 (C:1.9312, R:0.0014, T:0.4122)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 179 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0516 (C:1.9728, R:0.0014, T:0.0514(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0436 (C:1.9685, R:0.0014, T:0.0435(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0470 (C:1.9735, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0465 (C:1.9721, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0468 (C:1.9727, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0467 (C:1.9729, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0496 (C:1.9724, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0458 (C:1.9671, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0463 (C:1.9682, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0428 (C:1.9702, R:0.0014, T:0.0427(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0479 (C:1.9741, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0434 (C:1.9731, R:0.0014, T:0.0432(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0481 (C:1.9715, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0479 (C:1.9693, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0457 (C:1.9745, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0438 (C:1.9751, R:0.0014, T:0.0436(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0463 (C:1.9733, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0494 (C:1.9729, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0455 (C:1.9695, R:0.0014, T:0.0454(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0502 (C:1.9716, R:0.0014, T:0.0501(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0506 (C:1.9706, R:0.0014, T:0.0505(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0423 (C:1.9725, R:0.0014, T:0.0422(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 179 TRAINING SUMMARY:
  Total Loss: 0.0469
  Contrastive: 1.9716
  Reconstruction: 0.0014
  Topological: 0.0468 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4744
  Contrastive: 1.9273
  Reconstruction: 0.0014
  Topological: 0.4743 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 179/300 COMPLETE (43.1s)
Train Loss: 0.0469 (C:1.9716, R:0.0014, T:0.0468)
Val Loss:   0.4744 (C:1.9273, R:0.0014, T:0.4743)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 180 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0461 (C:1.9658, R:0.0014, T:0.0460(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0475 (C:1.9669, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0478 (C:1.9764, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0490 (C:1.9742, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0482 (C:1.9730, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0458 (C:1.9739, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0449 (C:1.9721, R:0.0014, T:0.0447(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0481 (C:1.9706, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0474 (C:1.9685, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0465 (C:1.9673, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0453 (C:1.9664, R:0.0014, T:0.0452(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0493 (C:1.9688, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0458 (C:1.9768, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0479 (C:1.9712, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0477 (C:1.9670, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0503 (C:1.9686, R:0.0014, T:0.0501(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0480 (C:1.9725, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0424 (C:1.9745, R:0.0014, T:0.0423(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0513 (C:1.9735, R:0.0014, T:0.0512(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0469 (C:1.9792, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0441 (C:1.9719, R:0.0014, T:0.0440(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0466 (C:1.9706, R:0.0014, T:0.0465(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 180 TRAINING SUMMARY:
  Total Loss: 0.0469
  Contrastive: 1.9714
  Reconstruction: 0.0014
  Topological: 0.0467 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4230
  Contrastive: 1.9311
  Reconstruction: 0.0014
  Topological: 0.4229 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 180/300 COMPLETE (44.0s)
Train Loss: 0.0469 (C:1.9714, R:0.0014, T:0.0467)
Val Loss:   0.4230 (C:1.9311, R:0.0014, T:0.4229)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 181 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0408 (C:1.9684, R:0.0014, T:0.0407(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0464 (C:1.9709, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0482 (C:1.9753, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0464 (C:1.9699, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0492 (C:1.9745, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0437 (C:1.9682, R:0.0014, T:0.0436(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0474 (C:1.9707, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0468 (C:1.9733, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0440 (C:1.9727, R:0.0014, T:0.0438(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0469 (C:1.9702, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0431 (C:1.9706, R:0.0014, T:0.0430(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0477 (C:1.9674, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0487 (C:1.9724, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0440 (C:1.9708, R:0.0014, T:0.0438(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0467 (C:1.9776, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0465 (C:1.9722, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0485 (C:1.9711, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0475 (C:1.9711, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0490 (C:1.9726, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0474 (C:1.9692, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0435 (C:1.9704, R:0.0014, T:0.0434(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0452 (C:1.9716, R:0.0014, T:0.0450(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 181 TRAINING SUMMARY:
  Total Loss: 0.0467
  Contrastive: 1.9715
  Reconstruction: 0.0014
  Topological: 0.0466 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4490
  Contrastive: 1.9317
  Reconstruction: 0.0014
  Topological: 0.4489 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 181/300 COMPLETE (43.2s)
Train Loss: 0.0467 (C:1.9715, R:0.0014, T:0.0466)
Val Loss:   0.4490 (C:1.9317, R:0.0014, T:0.4489)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 182 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0497 (C:1.9761, R:0.0014, T:0.0495(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0447 (C:1.9691, R:0.0014, T:0.0445(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0494 (C:1.9728, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0477 (C:1.9704, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0405 (C:1.9676, R:0.0014, T:0.0403(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0482 (C:1.9742, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0472 (C:1.9746, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0465 (C:1.9672, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0487 (C:1.9725, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0471 (C:1.9706, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0455 (C:1.9747, R:0.0014, T:0.0454(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0456 (C:1.9659, R:0.0014, T:0.0454(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0445 (C:1.9747, R:0.0014, T:0.0444(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0451 (C:1.9716, R:0.0014, T:0.0450(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0484 (C:1.9715, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0455 (C:1.9694, R:0.0014, T:0.0453(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0467 (C:1.9744, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0452 (C:1.9720, R:0.0014, T:0.0451(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0445 (C:1.9638, R:0.0014, T:0.0443(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0470 (C:1.9683, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0490 (C:1.9724, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0471 (C:1.9701, R:0.0014, T:0.0470(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 182 TRAINING SUMMARY:
  Total Loss: 0.0468
  Contrastive: 1.9712
  Reconstruction: 0.0014
  Topological: 0.0467 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4566
  Contrastive: 1.9353
  Reconstruction: 0.0014
  Topological: 0.4564 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 182/300 COMPLETE (43.6s)
Train Loss: 0.0468 (C:1.9712, R:0.0014, T:0.0467)
Val Loss:   0.4566 (C:1.9353, R:0.0014, T:0.4564)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 183 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0477 (C:1.9738, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0466 (C:1.9658, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0444 (C:1.9726, R:0.0014, T:0.0443(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0466 (C:1.9643, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0463 (C:1.9758, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0427 (C:1.9704, R:0.0014, T:0.0426(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0478 (C:1.9709, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0469 (C:1.9684, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0491 (C:1.9683, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0466 (C:1.9651, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0477 (C:1.9678, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0440 (C:1.9734, R:0.0014, T:0.0438(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0458 (C:1.9738, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0450 (C:1.9754, R:0.0014, T:0.0449(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0461 (C:1.9720, R:0.0014, T:0.0460(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0453 (C:1.9639, R:0.0014, T:0.0451(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0475 (C:1.9680, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0463 (C:1.9708, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0455 (C:1.9722, R:0.0014, T:0.0454(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0484 (C:1.9708, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0475 (C:1.9700, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0402 (C:1.9714, R:0.0014, T:0.0401(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0465

ğŸ“Š EPOCH 183 TRAINING SUMMARY:
  Total Loss: 0.0466
  Contrastive: 1.9708
  Reconstruction: 0.0014
  Topological: 0.0465 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4408
  Contrastive: 1.9303
  Reconstruction: 0.0014
  Topological: 0.4407 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 183/300 COMPLETE (45.8s)
Train Loss: 0.0466 (C:1.9708, R:0.0014, T:0.0465)
Val Loss:   0.4408 (C:1.9303, R:0.0014, T:0.4407)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 184 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0489 (C:1.9705, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0457 (C:1.9731, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0458 (C:1.9653, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0465 (C:1.9744, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0452 (C:1.9658, R:0.0014, T:0.0451(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0446 (C:1.9642, R:0.0014, T:0.0444(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0505 (C:1.9665, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0475 (C:1.9750, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0505 (C:1.9729, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0459 (C:1.9754, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0450 (C:1.9723, R:0.0014, T:0.0448(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0458 (C:1.9740, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0443 (C:1.9658, R:0.0014, T:0.0441(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0478 (C:1.9748, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0470 (C:1.9671, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0464 (C:1.9690, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0473 (C:1.9692, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0441 (C:1.9775, R:0.0014, T:0.0439(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0489 (C:1.9693, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0479 (C:1.9722, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0482 (C:1.9704, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0466 (C:1.9685, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0464

ğŸ“Š EPOCH 184 TRAINING SUMMARY:
  Total Loss: 0.0465
  Contrastive: 1.9709
  Reconstruction: 0.0014
  Topological: 0.0464 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4314
  Contrastive: 1.9203
  Reconstruction: 0.0014
  Topological: 0.4313 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 184/300 COMPLETE (45.6s)
Train Loss: 0.0465 (C:1.9709, R:0.0014, T:0.0464)
Val Loss:   0.4314 (C:1.9203, R:0.0014, T:0.4313)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 185 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0472 (C:1.9635, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0446 (C:1.9729, R:0.0014, T:0.0444(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0456 (C:1.9698, R:0.0014, T:0.0454(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0473 (C:1.9697, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0458 (C:1.9726, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0457 (C:1.9697, R:0.0014, T:0.0455(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0494 (C:1.9707, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0465 (C:1.9676, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0477 (C:1.9734, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0458 (C:1.9676, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0433 (C:1.9731, R:0.0014, T:0.0431(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0446 (C:1.9756, R:0.0014, T:0.0444(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0463 (C:1.9739, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0450 (C:1.9705, R:0.0014, T:0.0448(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0449 (C:1.9721, R:0.0014, T:0.0448(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0473 (C:1.9752, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0468 (C:1.9716, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0480 (C:1.9704, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0479 (C:1.9648, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0446 (C:1.9703, R:0.0014, T:0.0445(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0467 (C:1.9699, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0451 (C:1.9678, R:0.0014, T:0.0449(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 185 TRAINING SUMMARY:
  Total Loss: 0.0466
  Contrastive: 1.9711
  Reconstruction: 0.0014
  Topological: 0.0465 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4566
  Contrastive: 1.9327
  Reconstruction: 0.0014
  Topological: 0.4564 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 185/300 COMPLETE (47.3s)
Train Loss: 0.0466 (C:1.9711, R:0.0014, T:0.0465)
Val Loss:   0.4566 (C:1.9327, R:0.0014, T:0.4564)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 186 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0455 (C:1.9714, R:0.0014, T:0.0454(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0505 (C:1.9728, R:0.0014, T:0.0504(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0468 (C:1.9734, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0464 (C:1.9735, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0491 (C:1.9761, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0465 (C:1.9689, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0443 (C:1.9713, R:0.0014, T:0.0442(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0441 (C:1.9736, R:0.0014, T:0.0440(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0493 (C:1.9732, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0476 (C:1.9663, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0492 (C:1.9722, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0493 (C:1.9732, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0471 (C:1.9720, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0448 (C:1.9724, R:0.0014, T:0.0447(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0478 (C:1.9759, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0486 (C:1.9750, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0483 (C:1.9723, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0496 (C:1.9748, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0471 (C:1.9724, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0478 (C:1.9729, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0465 (C:1.9770, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0497 (C:1.9672, R:0.0014, T:0.0495(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 186 TRAINING SUMMARY:
  Total Loss: 0.0467
  Contrastive: 1.9711
  Reconstruction: 0.0014
  Topological: 0.0466 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4409
  Contrastive: 1.9342
  Reconstruction: 0.0014
  Topological: 0.4408 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 186/300 COMPLETE (45.9s)
Train Loss: 0.0467 (C:1.9711, R:0.0014, T:0.0466)
Val Loss:   0.4409 (C:1.9342, R:0.0014, T:0.4408)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 187 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0494 (C:1.9729, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0465 (C:1.9758, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0475 (C:1.9692, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0455 (C:1.9702, R:0.0014, T:0.0453(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0461 (C:1.9701, R:0.0014, T:0.0459(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0477 (C:1.9691, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0444 (C:1.9686, R:0.0014, T:0.0443(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0509 (C:1.9722, R:0.0014, T:0.0507(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0448 (C:1.9719, R:0.0014, T:0.0447(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0481 (C:1.9709, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0427 (C:1.9726, R:0.0014, T:0.0425(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0480 (C:1.9684, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0464 (C:1.9728, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0481 (C:1.9759, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0449 (C:1.9700, R:0.0014, T:0.0447(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0488 (C:1.9702, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0476 (C:1.9690, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0472 (C:1.9715, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0463 (C:1.9713, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0450 (C:1.9734, R:0.0014, T:0.0448(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0469 (C:1.9700, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0451 (C:1.9705, R:0.0014, T:0.0449(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 187 TRAINING SUMMARY:
  Total Loss: 0.0467
  Contrastive: 1.9709
  Reconstruction: 0.0014
  Topological: 0.0466 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4152
  Contrastive: 1.9265
  Reconstruction: 0.0014
  Topological: 0.4151 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 187/300 COMPLETE (45.9s)
Train Loss: 0.0467 (C:1.9709, R:0.0014, T:0.0466)
Val Loss:   0.4152 (C:1.9265, R:0.0014, T:0.4151)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 188 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0482 (C:1.9645, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0482 (C:1.9729, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0463 (C:1.9619, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0486 (C:1.9728, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0459 (C:1.9629, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0446 (C:1.9729, R:0.0014, T:0.0444(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0464 (C:1.9702, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0458 (C:1.9638, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0501 (C:1.9674, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0463 (C:1.9699, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0459 (C:1.9669, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0450 (C:1.9694, R:0.0014, T:0.0449(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0447 (C:1.9716, R:0.0014, T:0.0445(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0478 (C:1.9704, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0452 (C:1.9732, R:0.0014, T:0.0451(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0465 (C:1.9678, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0490 (C:1.9674, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0458 (C:1.9702, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0448 (C:1.9740, R:0.0014, T:0.0446(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0457 (C:1.9659, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0449 (C:1.9689, R:0.0014, T:0.0448(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0474 (C:1.9699, R:0.0014, T:0.0473(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 188 TRAINING SUMMARY:
  Total Loss: 0.0467
  Contrastive: 1.9708
  Reconstruction: 0.0014
  Topological: 0.0466 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4243
  Contrastive: 1.9349
  Reconstruction: 0.0014
  Topological: 0.4242 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 188/300 COMPLETE (43.4s)
Train Loss: 0.0467 (C:1.9708, R:0.0014, T:0.0466)
Val Loss:   0.4243 (C:1.9349, R:0.0014, T:0.4242)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 189 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0479 (C:1.9756, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0481 (C:1.9743, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0456 (C:1.9743, R:0.0014, T:0.0455(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0471 (C:1.9664, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0459 (C:1.9772, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0486 (C:1.9699, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0446 (C:1.9711, R:0.0014, T:0.0445(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0430 (C:1.9714, R:0.0014, T:0.0429(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0443 (C:1.9703, R:0.0014, T:0.0442(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0454 (C:1.9737, R:0.0014, T:0.0452(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0446 (C:1.9682, R:0.0014, T:0.0444(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0494 (C:1.9698, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0463 (C:1.9713, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0452 (C:1.9721, R:0.0014, T:0.0450(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0480 (C:1.9684, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0487 (C:1.9707, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0462 (C:1.9742, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0479 (C:1.9731, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0476 (C:1.9732, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0452 (C:1.9715, R:0.0014, T:0.0451(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0504 (C:1.9694, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0481 (C:1.9786, R:0.0014, T:0.0479(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 189 TRAINING SUMMARY:
  Total Loss: 0.0465
  Contrastive: 1.9710
  Reconstruction: 0.0014
  Topological: 0.0464 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4208
  Contrastive: 1.9261
  Reconstruction: 0.0014
  Topological: 0.4207 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 189/300 COMPLETE (43.3s)
Train Loss: 0.0465 (C:1.9710, R:0.0014, T:0.0464)
Val Loss:   0.4208 (C:1.9261, R:0.0014, T:0.4207)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 190 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0486 (C:1.9703, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0456 (C:1.9752, R:0.0014, T:0.0455(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0465 (C:1.9701, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0470 (C:1.9729, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0473 (C:1.9714, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0459 (C:1.9685, R:0.0014, T:0.0458(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0458 (C:1.9734, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0485 (C:1.9727, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0444 (C:1.9689, R:0.0014, T:0.0443(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0495 (C:1.9717, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0462 (C:1.9725, R:0.0014, T:0.0460(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0466 (C:1.9711, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0439 (C:1.9739, R:0.0014, T:0.0437(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0465 (C:1.9700, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0483 (C:1.9667, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0422 (C:1.9721, R:0.0014, T:0.0421(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0465 (C:1.9684, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0476 (C:1.9711, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0442 (C:1.9725, R:0.0014, T:0.0441(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0490 (C:1.9711, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0472 (C:1.9723, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0486 (C:1.9688, R:0.0014, T:0.0485(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 190 TRAINING SUMMARY:
  Total Loss: 0.0467
  Contrastive: 1.9711
  Reconstruction: 0.0014
  Topological: 0.0466 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4370
  Contrastive: 1.9396
  Reconstruction: 0.0014
  Topological: 0.4369 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 190/300 COMPLETE (42.9s)
Train Loss: 0.0467 (C:1.9711, R:0.0014, T:0.0466)
Val Loss:   0.4370 (C:1.9396, R:0.0014, T:0.4369)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 191 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0479 (C:1.9735, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0474 (C:1.9707, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0459 (C:1.9643, R:0.0014, T:0.0458(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0462 (C:1.9719, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0472 (C:1.9685, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0479 (C:1.9719, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0466 (C:1.9739, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0466 (C:1.9668, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0445 (C:1.9694, R:0.0014, T:0.0443(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0460 (C:1.9697, R:0.0014, T:0.0458(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0479 (C:1.9718, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0496 (C:1.9704, R:0.0014, T:0.0495(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0464 (C:1.9731, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0459 (C:1.9698, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0461 (C:1.9744, R:0.0014, T:0.0460(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0461 (C:1.9701, R:0.0014, T:0.0460(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0447 (C:1.9736, R:0.0014, T:0.0445(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0457 (C:1.9724, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0470 (C:1.9695, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0448 (C:1.9658, R:0.0014, T:0.0446(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0477 (C:1.9715, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0443 (C:1.9734, R:0.0014, T:0.0441(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 191 TRAINING SUMMARY:
  Total Loss: 0.0466
  Contrastive: 1.9710
  Reconstruction: 0.0014
  Topological: 0.0465 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4316
  Contrastive: 1.9250
  Reconstruction: 0.0014
  Topological: 0.4314 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 191/300 COMPLETE (43.1s)
Train Loss: 0.0466 (C:1.9710, R:0.0014, T:0.0465)
Val Loss:   0.4316 (C:1.9250, R:0.0014, T:0.4314)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 192 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0421 (C:1.9665, R:0.0014, T:0.0420(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0428 (C:1.9712, R:0.0014, T:0.0427(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0457 (C:1.9679, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0410 (C:1.9705, R:0.0014, T:0.0408(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0452 (C:1.9688, R:0.0014, T:0.0451(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0495 (C:1.9725, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0464 (C:1.9711, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0456 (C:1.9725, R:0.0014, T:0.0454(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0453 (C:1.9703, R:0.0014, T:0.0452(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0477 (C:1.9741, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0484 (C:1.9708, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0459 (C:1.9704, R:0.0014, T:0.0458(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0471 (C:1.9692, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0473 (C:1.9695, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0467 (C:1.9705, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0450 (C:1.9727, R:0.0014, T:0.0448(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0487 (C:1.9753, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0476 (C:1.9648, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0454 (C:1.9688, R:0.0014, T:0.0453(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0462 (C:1.9750, R:0.0014, T:0.0460(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0479 (C:1.9714, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0461 (C:1.9681, R:0.0014, T:0.0459(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 192 TRAINING SUMMARY:
  Total Loss: 0.0467
  Contrastive: 1.9709
  Reconstruction: 0.0014
  Topological: 0.0465 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4352
  Contrastive: 1.9261
  Reconstruction: 0.0014
  Topological: 0.4351 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 192/300 COMPLETE (42.8s)
Train Loss: 0.0467 (C:1.9709, R:0.0014, T:0.0465)
Val Loss:   0.4352 (C:1.9261, R:0.0014, T:0.4351)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 193 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0469 (C:1.9690, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0448 (C:1.9726, R:0.0014, T:0.0446(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0483 (C:1.9639, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0479 (C:1.9666, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0490 (C:1.9686, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0452 (C:1.9714, R:0.0014, T:0.0451(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0466 (C:1.9713, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0448 (C:1.9706, R:0.0014, T:0.0446(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0453 (C:1.9696, R:0.0014, T:0.0451(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0451 (C:1.9718, R:0.0014, T:0.0450(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0462 (C:1.9705, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0497 (C:1.9690, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0483 (C:1.9675, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0438 (C:1.9658, R:0.0014, T:0.0437(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0481 (C:1.9741, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0431 (C:1.9717, R:0.0014, T:0.0429(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0462 (C:1.9687, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0436 (C:1.9707, R:0.0014, T:0.0434(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0472 (C:1.9707, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0474 (C:1.9656, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0482 (C:1.9659, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0450 (C:1.9736, R:0.0014, T:0.0449(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 193 TRAINING SUMMARY:
  Total Loss: 0.0465
  Contrastive: 1.9711
  Reconstruction: 0.0014
  Topological: 0.0464 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4335
  Contrastive: 1.9330
  Reconstruction: 0.0014
  Topological: 0.4333 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 193/300 COMPLETE (41.6s)
Train Loss: 0.0465 (C:1.9711, R:0.0014, T:0.0464)
Val Loss:   0.4335 (C:1.9330, R:0.0014, T:0.4333)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 194 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0453 (C:1.9706, R:0.0014, T:0.0451(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0456 (C:1.9717, R:0.0014, T:0.0454(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0470 (C:1.9768, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0445 (C:1.9676, R:0.0014, T:0.0444(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0464 (C:1.9777, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0457 (C:1.9690, R:0.0014, T:0.0455(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0444 (C:1.9705, R:0.0014, T:0.0442(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0465 (C:1.9724, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0491 (C:1.9724, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0446 (C:1.9712, R:0.0014, T:0.0445(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0468 (C:1.9693, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0462 (C:1.9700, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0446 (C:1.9687, R:0.0014, T:0.0445(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0464 (C:1.9674, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0434 (C:1.9694, R:0.0014, T:0.0433(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0465 (C:1.9743, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0453 (C:1.9725, R:0.0014, T:0.0452(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0446 (C:1.9744, R:0.0014, T:0.0445(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0484 (C:1.9715, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0466 (C:1.9711, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0481 (C:1.9658, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0492 (C:1.9709, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0463

ğŸ“Š EPOCH 194 TRAINING SUMMARY:
  Total Loss: 0.0464
  Contrastive: 1.9709
  Reconstruction: 0.0014
  Topological: 0.0463 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4265
  Contrastive: 1.9378
  Reconstruction: 0.0014
  Topological: 0.4263 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 194/300 COMPLETE (41.8s)
Train Loss: 0.0464 (C:1.9709, R:0.0014, T:0.0463)
Val Loss:   0.4265 (C:1.9378, R:0.0014, T:0.4263)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 195 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0475 (C:1.9750, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0458 (C:1.9654, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0502 (C:1.9717, R:0.0014, T:0.0501(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0474 (C:1.9706, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0505 (C:1.9708, R:0.0014, T:0.0503(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0427 (C:1.9732, R:0.0014, T:0.0425(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0479 (C:1.9657, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0482 (C:1.9694, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0502 (C:1.9659, R:0.0014, T:0.0501(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0480 (C:1.9699, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0460 (C:1.9654, R:0.0014, T:0.0459(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0457 (C:1.9779, R:0.0014, T:0.0455(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0489 (C:1.9703, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0443 (C:1.9679, R:0.0014, T:0.0442(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0449 (C:1.9729, R:0.0014, T:0.0447(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0457 (C:1.9708, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0462 (C:1.9714, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0478 (C:1.9726, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0426 (C:1.9757, R:0.0014, T:0.0425(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0457 (C:1.9686, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0491 (C:1.9772, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0490 (C:1.9679, R:0.0014, T:0.0489(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 195 TRAINING SUMMARY:
  Total Loss: 0.0465
  Contrastive: 1.9711
  Reconstruction: 0.0014
  Topological: 0.0463 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4275
  Contrastive: 1.9301
  Reconstruction: 0.0014
  Topological: 0.4274 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 195/300 COMPLETE (42.4s)
Train Loss: 0.0465 (C:1.9711, R:0.0014, T:0.0463)
Val Loss:   0.4275 (C:1.9301, R:0.0014, T:0.4274)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 196 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0464 (C:1.9691, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0426 (C:1.9678, R:0.0014, T:0.0425(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0460 (C:1.9745, R:0.0014, T:0.0458(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0427 (C:1.9668, R:0.0014, T:0.0426(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0472 (C:1.9734, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0465 (C:1.9650, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0483 (C:1.9698, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0459 (C:1.9712, R:0.0014, T:0.0458(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0451 (C:1.9684, R:0.0014, T:0.0450(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0468 (C:1.9698, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0481 (C:1.9728, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0432 (C:1.9696, R:0.0014, T:0.0431(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0464 (C:1.9664, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0487 (C:1.9653, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0481 (C:1.9695, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0438 (C:1.9679, R:0.0014, T:0.0437(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0439 (C:1.9736, R:0.0014, T:0.0437(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0491 (C:1.9647, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0467 (C:1.9623, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0446 (C:1.9692, R:0.0014, T:0.0445(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0499 (C:1.9712, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0472 (C:1.9701, R:0.0014, T:0.0471(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 196 TRAINING SUMMARY:
  Total Loss: 0.0465
  Contrastive: 1.9706
  Reconstruction: 0.0014
  Topological: 0.0463 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4312
  Contrastive: 1.9300
  Reconstruction: 0.0014
  Topological: 0.4310 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 196/300 COMPLETE (42.3s)
Train Loss: 0.0465 (C:1.9706, R:0.0014, T:0.0463)
Val Loss:   0.4312 (C:1.9300, R:0.0014, T:0.4310)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 197 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0475 (C:1.9719, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0449 (C:1.9721, R:0.0014, T:0.0447(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0447 (C:1.9699, R:0.0014, T:0.0446(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0477 (C:1.9709, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0464 (C:1.9680, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0449 (C:1.9734, R:0.0014, T:0.0447(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0490 (C:1.9733, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0443 (C:1.9642, R:0.0014, T:0.0442(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0456 (C:1.9668, R:0.0014, T:0.0455(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0468 (C:1.9698, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0440 (C:1.9703, R:0.0014, T:0.0439(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0478 (C:1.9687, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0455 (C:1.9701, R:0.0014, T:0.0453(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0462 (C:1.9734, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0477 (C:1.9688, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0443 (C:1.9682, R:0.0014, T:0.0442(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0446 (C:1.9754, R:0.0014, T:0.0444(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0468 (C:1.9737, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0494 (C:1.9699, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0456 (C:1.9698, R:0.0014, T:0.0454(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0472 (C:1.9736, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0465 (C:1.9746, R:0.0014, T:0.0464(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 197 TRAINING SUMMARY:
  Total Loss: 0.0465
  Contrastive: 1.9709
  Reconstruction: 0.0014
  Topological: 0.0463 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.3766
  Contrastive: 1.9269
  Reconstruction: 0.0014
  Topological: 0.3764 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 197/300 COMPLETE (42.6s)
Train Loss: 0.0465 (C:1.9709, R:0.0014, T:0.0463)
Val Loss:   0.3766 (C:1.9269, R:0.0014, T:0.3764)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 198 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0498 (C:1.9718, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0479 (C:1.9708, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0453 (C:1.9697, R:0.0014, T:0.0452(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0444 (C:1.9697, R:0.0014, T:0.0443(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0434 (C:1.9738, R:0.0014, T:0.0433(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0464 (C:1.9651, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0475 (C:1.9721, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0475 (C:1.9774, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0464 (C:1.9695, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0458 (C:1.9668, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0457 (C:1.9733, R:0.0014, T:0.0455(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0469 (C:1.9753, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0470 (C:1.9665, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0461 (C:1.9687, R:0.0014, T:0.0459(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0449 (C:1.9684, R:0.0014, T:0.0447(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0476 (C:1.9690, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0501 (C:1.9749, R:0.0014, T:0.0500(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0460 (C:1.9676, R:0.0014, T:0.0458(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0455 (C:1.9678, R:0.0014, T:0.0453(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0447 (C:1.9686, R:0.0014, T:0.0445(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0491 (C:1.9705, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0463 (C:1.9694, R:0.0014, T:0.0462(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 198 TRAINING SUMMARY:
  Total Loss: 0.0467
  Contrastive: 1.9707
  Reconstruction: 0.0014
  Topological: 0.0466 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4479
  Contrastive: 1.9312
  Reconstruction: 0.0014
  Topological: 0.4477 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 198/300 COMPLETE (42.9s)
Train Loss: 0.0467 (C:1.9707, R:0.0014, T:0.0466)
Val Loss:   0.4479 (C:1.9312, R:0.0014, T:0.4477)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 199 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0469 (C:1.9717, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0465 (C:1.9726, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0462 (C:1.9710, R:0.0014, T:0.0460(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0442 (C:1.9648, R:0.0014, T:0.0441(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0445 (C:1.9734, R:0.0014, T:0.0443(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0476 (C:1.9700, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0472 (C:1.9700, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0461 (C:1.9718, R:0.0014, T:0.0460(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0490 (C:1.9725, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0453 (C:1.9679, R:0.0014, T:0.0452(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0456 (C:1.9707, R:0.0014, T:0.0455(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0471 (C:1.9661, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0462 (C:1.9730, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0461 (C:1.9672, R:0.0014, T:0.0459(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0458 (C:1.9767, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0458 (C:1.9715, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0493 (C:1.9717, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0489 (C:1.9673, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0450 (C:1.9739, R:0.0014, T:0.0449(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0460 (C:1.9702, R:0.0014, T:0.0459(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0453 (C:1.9709, R:0.0014, T:0.0451(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0453 (C:1.9666, R:0.0014, T:0.0452(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0463

ğŸ“Š EPOCH 199 TRAINING SUMMARY:
  Total Loss: 0.0464
  Contrastive: 1.9709
  Reconstruction: 0.0014
  Topological: 0.0463 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4072
  Contrastive: 1.9343
  Reconstruction: 0.0014
  Topological: 0.4070 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 199/300 COMPLETE (44.1s)
Train Loss: 0.0464 (C:1.9709, R:0.0014, T:0.0463)
Val Loss:   0.4072 (C:1.9343, R:0.0014, T:0.4070)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 200 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0454 (C:1.9695, R:0.0014, T:0.0452(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0454 (C:1.9705, R:0.0014, T:0.0452(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0462 (C:1.9700, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0509 (C:1.9667, R:0.0014, T:0.0508(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0461 (C:1.9738, R:0.0014, T:0.0460(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0450 (C:1.9728, R:0.0014, T:0.0449(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0469 (C:1.9726, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0467 (C:1.9662, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0488 (C:1.9759, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0448 (C:1.9722, R:0.0014, T:0.0446(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0479 (C:1.9759, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0468 (C:1.9719, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0460 (C:1.9704, R:0.0014, T:0.0458(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0468 (C:1.9666, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0446 (C:1.9771, R:0.0014, T:0.0445(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0451 (C:1.9741, R:0.0014, T:0.0450(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0455 (C:1.9669, R:0.0014, T:0.0453(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0502 (C:1.9717, R:0.0014, T:0.0501(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0479 (C:1.9647, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0459 (C:1.9641, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0487 (C:1.9749, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0454 (C:1.9712, R:0.0014, T:0.0452(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 200 TRAINING SUMMARY:
  Total Loss: 0.0464
  Contrastive: 1.9707
  Reconstruction: 0.0014
  Topological: 0.0463 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4425
  Contrastive: 1.9284
  Reconstruction: 0.0014
  Topological: 0.4423 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 200/300 COMPLETE (43.4s)
Train Loss: 0.0464 (C:1.9707, R:0.0014, T:0.0463)
Val Loss:   0.4425 (C:1.9284, R:0.0014, T:0.4423)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 201 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0452 (C:1.9687, R:0.0014, T:0.0451(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0495 (C:1.9725, R:0.0014, T:0.0494(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0456 (C:1.9774, R:0.0014, T:0.0455(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0468 (C:1.9736, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0475 (C:1.9697, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0457 (C:1.9714, R:0.0014, T:0.0455(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0484 (C:1.9698, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0466 (C:1.9760, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0448 (C:1.9745, R:0.0014, T:0.0447(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0473 (C:1.9716, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0464 (C:1.9704, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0430 (C:1.9728, R:0.0014, T:0.0429(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0465 (C:1.9733, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0470 (C:1.9628, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0435 (C:1.9714, R:0.0014, T:0.0434(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0468 (C:1.9657, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0453 (C:1.9723, R:0.0014, T:0.0452(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0464 (C:1.9689, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0464 (C:1.9661, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0478 (C:1.9704, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0463 (C:1.9754, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0432 (C:1.9640, R:0.0014, T:0.0430(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 201 TRAINING SUMMARY:
  Total Loss: 0.0465
  Contrastive: 1.9708
  Reconstruction: 0.0014
  Topological: 0.0464 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4114
  Contrastive: 1.9310
  Reconstruction: 0.0014
  Topological: 0.4112 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 201/300 COMPLETE (43.2s)
Train Loss: 0.0465 (C:1.9708, R:0.0014, T:0.0464)
Val Loss:   0.4114 (C:1.9310, R:0.0014, T:0.4112)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 202 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0467 (C:1.9663, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0435 (C:1.9777, R:0.0014, T:0.0433(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0435 (C:1.9758, R:0.0014, T:0.0434(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0465 (C:1.9721, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0479 (C:1.9621, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0521 (C:1.9719, R:0.0014, T:0.0520(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0449 (C:1.9705, R:0.0014, T:0.0448(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0459 (C:1.9734, R:0.0014, T:0.0458(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0442 (C:1.9756, R:0.0014, T:0.0440(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0479 (C:1.9714, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0462 (C:1.9734, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0475 (C:1.9741, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0414 (C:1.9708, R:0.0014, T:0.0413(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0462 (C:1.9718, R:0.0014, T:0.0460(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0473 (C:1.9744, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0446 (C:1.9658, R:0.0014, T:0.0444(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0485 (C:1.9683, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0450 (C:1.9722, R:0.0014, T:0.0449(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0478 (C:1.9666, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0447 (C:1.9702, R:0.0014, T:0.0446(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0428 (C:1.9631, R:0.0014, T:0.0426(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0473 (C:1.9729, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0462

ğŸ“Š EPOCH 202 TRAINING SUMMARY:
  Total Loss: 0.0463
  Contrastive: 1.9707
  Reconstruction: 0.0014
  Topological: 0.0462 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4403
  Contrastive: 1.9259
  Reconstruction: 0.0014
  Topological: 0.4401 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 202/300 COMPLETE (43.6s)
Train Loss: 0.0463 (C:1.9707, R:0.0014, T:0.0462)
Val Loss:   0.4403 (C:1.9259, R:0.0014, T:0.4401)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 203 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0448 (C:1.9704, R:0.0014, T:0.0447(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0457 (C:1.9730, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0461 (C:1.9690, R:0.0014, T:0.0460(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0478 (C:1.9711, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0480 (C:1.9689, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0473 (C:1.9698, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0489 (C:1.9700, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0456 (C:1.9678, R:0.0014, T:0.0455(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0452 (C:1.9653, R:0.0014, T:0.0451(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0428 (C:1.9687, R:0.0014, T:0.0426(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0470 (C:1.9747, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0457 (C:1.9714, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0465 (C:1.9680, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0464 (C:1.9626, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0459 (C:1.9740, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0439 (C:1.9711, R:0.0014, T:0.0438(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0477 (C:1.9730, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0474 (C:1.9714, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0478 (C:1.9724, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0458 (C:1.9706, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0449 (C:1.9696, R:0.0014, T:0.0447(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0462 (C:1.9685, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0460

ğŸ“Š EPOCH 203 TRAINING SUMMARY:
  Total Loss: 0.0462
  Contrastive: 1.9709
  Reconstruction: 0.0014
  Topological: 0.0460 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4370
  Contrastive: 1.9386
  Reconstruction: 0.0014
  Topological: 0.4368 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 203/300 COMPLETE (44.1s)
Train Loss: 0.0462 (C:1.9709, R:0.0014, T:0.0460)
Val Loss:   0.4370 (C:1.9386, R:0.0014, T:0.4368)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 204 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0466 (C:1.9741, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0453 (C:1.9712, R:0.0014, T:0.0451(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0471 (C:1.9763, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0456 (C:1.9741, R:0.0014, T:0.0454(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0469 (C:1.9738, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0492 (C:1.9689, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0444 (C:1.9667, R:0.0014, T:0.0443(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0469 (C:1.9692, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0481 (C:1.9736, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0448 (C:1.9733, R:0.0014, T:0.0446(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0481 (C:1.9704, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0443 (C:1.9715, R:0.0014, T:0.0442(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0455 (C:1.9725, R:0.0014, T:0.0454(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0456 (C:1.9700, R:0.0014, T:0.0455(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0449 (C:1.9664, R:0.0014, T:0.0448(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0448 (C:1.9711, R:0.0014, T:0.0446(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0471 (C:1.9750, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0435 (C:1.9656, R:0.0014, T:0.0433(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0476 (C:1.9730, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0449 (C:1.9674, R:0.0014, T:0.0447(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0478 (C:1.9714, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0440 (C:1.9687, R:0.0014, T:0.0439(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 204 TRAINING SUMMARY:
  Total Loss: 0.0464
  Contrastive: 1.9709
  Reconstruction: 0.0014
  Topological: 0.0463 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4206
  Contrastive: 1.9242
  Reconstruction: 0.0014
  Topological: 0.4205 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 204/300 COMPLETE (43.4s)
Train Loss: 0.0464 (C:1.9709, R:0.0014, T:0.0463)
Val Loss:   0.4206 (C:1.9242, R:0.0014, T:0.4205)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 205 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0444 (C:1.9699, R:0.0014, T:0.0442(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0469 (C:1.9739, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0470 (C:1.9687, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0427 (C:1.9697, R:0.0014, T:0.0426(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0442 (C:1.9704, R:0.0014, T:0.0440(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0464 (C:1.9656, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0429 (C:1.9740, R:0.0014, T:0.0428(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0466 (C:1.9680, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0490 (C:1.9721, R:0.0014, T:0.0489(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0447 (C:1.9703, R:0.0014, T:0.0446(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0452 (C:1.9689, R:0.0014, T:0.0450(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0459 (C:1.9713, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0464 (C:1.9708, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0483 (C:1.9735, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0452 (C:1.9732, R:0.0014, T:0.0451(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0405 (C:1.9759, R:0.0014, T:0.0404(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0460 (C:1.9681, R:0.0014, T:0.0459(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0462 (C:1.9701, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0477 (C:1.9666, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0441 (C:1.9732, R:0.0014, T:0.0440(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0463 (C:1.9744, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0486 (C:1.9722, R:0.0014, T:0.0484(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 205 TRAINING SUMMARY:
  Total Loss: 0.0462
  Contrastive: 1.9705
  Reconstruction: 0.0014
  Topological: 0.0461 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4018
  Contrastive: 1.9290
  Reconstruction: 0.0014
  Topological: 0.4016 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 205/300 COMPLETE (43.2s)
Train Loss: 0.0462 (C:1.9705, R:0.0014, T:0.0461)
Val Loss:   0.4018 (C:1.9290, R:0.0014, T:0.4016)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 206 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0484 (C:1.9721, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0489 (C:1.9673, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0453 (C:1.9710, R:0.0014, T:0.0452(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0457 (C:1.9696, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0463 (C:1.9739, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0444 (C:1.9707, R:0.0014, T:0.0442(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0467 (C:1.9671, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0477 (C:1.9719, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0492 (C:1.9705, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0456 (C:1.9749, R:0.0014, T:0.0455(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0426 (C:1.9711, R:0.0014, T:0.0424(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0467 (C:1.9708, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0461 (C:1.9745, R:0.0014, T:0.0459(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0475 (C:1.9700, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0462 (C:1.9679, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0447 (C:1.9675, R:0.0014, T:0.0445(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0441 (C:1.9742, R:0.0014, T:0.0440(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0488 (C:1.9733, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0467 (C:1.9686, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0452 (C:1.9725, R:0.0014, T:0.0451(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0463 (C:1.9707, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0471 (C:1.9690, R:0.0014, T:0.0470(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 206 TRAINING SUMMARY:
  Total Loss: 0.0465
  Contrastive: 1.9710
  Reconstruction: 0.0014
  Topological: 0.0463 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4191
  Contrastive: 1.9321
  Reconstruction: 0.0014
  Topological: 0.4189 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 206/300 COMPLETE (42.5s)
Train Loss: 0.0465 (C:1.9710, R:0.0014, T:0.0463)
Val Loss:   0.4191 (C:1.9321, R:0.0014, T:0.4189)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 207 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0470 (C:1.9705, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0486 (C:1.9673, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0466 (C:1.9707, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0457 (C:1.9750, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0447 (C:1.9703, R:0.0014, T:0.0446(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0451 (C:1.9697, R:0.0014, T:0.0450(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0467 (C:1.9725, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0486 (C:1.9672, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0447 (C:1.9707, R:0.0014, T:0.0445(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0484 (C:1.9726, R:0.0014, T:0.0483(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0465 (C:1.9669, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0474 (C:1.9726, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0481 (C:1.9669, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0469 (C:1.9726, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0467 (C:1.9703, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0437 (C:1.9631, R:0.0014, T:0.0436(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0489 (C:1.9660, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0462 (C:1.9746, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0485 (C:1.9735, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0437 (C:1.9710, R:0.0014, T:0.0436(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0475 (C:1.9666, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0464 (C:1.9668, R:0.0014, T:0.0462(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 207 TRAINING SUMMARY:
  Total Loss: 0.0463
  Contrastive: 1.9710
  Reconstruction: 0.0014
  Topological: 0.0461 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4189
  Contrastive: 1.9283
  Reconstruction: 0.0014
  Topological: 0.4188 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 207/300 COMPLETE (42.6s)
Train Loss: 0.0463 (C:1.9710, R:0.0014, T:0.0461)
Val Loss:   0.4189 (C:1.9283, R:0.0014, T:0.4188)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 208 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0464 (C:1.9654, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0457 (C:1.9726, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0472 (C:1.9717, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0464 (C:1.9697, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0473 (C:1.9724, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0460 (C:1.9672, R:0.0014, T:0.0458(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0467 (C:1.9698, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0470 (C:1.9708, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0465 (C:1.9754, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0466 (C:1.9750, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0459 (C:1.9744, R:0.0014, T:0.0458(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0458 (C:1.9738, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0451 (C:1.9679, R:0.0014, T:0.0450(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0484 (C:1.9694, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0456 (C:1.9765, R:0.0014, T:0.0454(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0457 (C:1.9679, R:0.0014, T:0.0455(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0455 (C:1.9700, R:0.0014, T:0.0454(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0464 (C:1.9729, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0452 (C:1.9676, R:0.0014, T:0.0451(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0452 (C:1.9703, R:0.0014, T:0.0450(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0445 (C:1.9729, R:0.0014, T:0.0444(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0466 (C:1.9754, R:0.0014, T:0.0464(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 208 TRAINING SUMMARY:
  Total Loss: 0.0465
  Contrastive: 1.9711
  Reconstruction: 0.0014
  Topological: 0.0464 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4508
  Contrastive: 1.9299
  Reconstruction: 0.0014
  Topological: 0.4507 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 208/300 COMPLETE (43.2s)
Train Loss: 0.0465 (C:1.9711, R:0.0014, T:0.0464)
Val Loss:   0.4508 (C:1.9299, R:0.0014, T:0.4507)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 209 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0481 (C:1.9606, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0453 (C:1.9727, R:0.0014, T:0.0452(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0435 (C:1.9706, R:0.0014, T:0.0434(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0478 (C:1.9728, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0447 (C:1.9710, R:0.0014, T:0.0445(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0464 (C:1.9715, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0476 (C:1.9677, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0476 (C:1.9685, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0481 (C:1.9647, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0452 (C:1.9702, R:0.0014, T:0.0451(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0462 (C:1.9710, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0495 (C:1.9697, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0478 (C:1.9749, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0495 (C:1.9774, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0495 (C:1.9659, R:0.0014, T:0.0493(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0478 (C:1.9760, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0461 (C:1.9722, R:0.0014, T:0.0460(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0467 (C:1.9736, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0450 (C:1.9682, R:0.0014, T:0.0448(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0475 (C:1.9770, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0510 (C:1.9687, R:0.0014, T:0.0508(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0490 (C:1.9757, R:0.0014, T:0.0489(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 209 TRAINING SUMMARY:
  Total Loss: 0.0464
  Contrastive: 1.9711
  Reconstruction: 0.0014
  Topological: 0.0462 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4181
  Contrastive: 1.9336
  Reconstruction: 0.0014
  Topological: 0.4180 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 209/300 COMPLETE (42.9s)
Train Loss: 0.0464 (C:1.9711, R:0.0014, T:0.0462)
Val Loss:   0.4181 (C:1.9336, R:0.0014, T:0.4180)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 210 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0473 (C:1.9726, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0451 (C:1.9729, R:0.0014, T:0.0449(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0478 (C:1.9718, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0484 (C:1.9671, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0451 (C:1.9676, R:0.0014, T:0.0449(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0492 (C:1.9734, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0456 (C:1.9692, R:0.0014, T:0.0454(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0476 (C:1.9731, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0453 (C:1.9688, R:0.0014, T:0.0452(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0482 (C:1.9781, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0450 (C:1.9717, R:0.0014, T:0.0449(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0474 (C:1.9714, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0480 (C:1.9715, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0438 (C:1.9702, R:0.0014, T:0.0437(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0414 (C:1.9708, R:0.0014, T:0.0413(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0427 (C:1.9691, R:0.0014, T:0.0426(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0459 (C:1.9744, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0483 (C:1.9695, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0498 (C:1.9708, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0469 (C:1.9725, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0453 (C:1.9665, R:0.0014, T:0.0452(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0477 (C:1.9699, R:0.0014, T:0.0476(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 210 TRAINING SUMMARY:
  Total Loss: 0.0462
  Contrastive: 1.9709
  Reconstruction: 0.0014
  Topological: 0.0461 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4034
  Contrastive: 1.9286
  Reconstruction: 0.0014
  Topological: 0.4033 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 210/300 COMPLETE (42.7s)
Train Loss: 0.0462 (C:1.9709, R:0.0014, T:0.0461)
Val Loss:   0.4034 (C:1.9286, R:0.0014, T:0.4033)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 211 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0486 (C:1.9706, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0469 (C:1.9667, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0479 (C:1.9709, R:0.0014, T:0.0477(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0444 (C:1.9696, R:0.0014, T:0.0442(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0497 (C:1.9716, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0458 (C:1.9726, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0475 (C:1.9722, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0469 (C:1.9700, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0504 (C:1.9719, R:0.0014, T:0.0502(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0477 (C:1.9646, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0440 (C:1.9745, R:0.0014, T:0.0438(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0499 (C:1.9697, R:0.0014, T:0.0498(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0471 (C:1.9682, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0441 (C:1.9750, R:0.0014, T:0.0440(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0444 (C:1.9706, R:0.0014, T:0.0442(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0463 (C:1.9741, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0493 (C:1.9693, R:0.0014, T:0.0492(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0439 (C:1.9725, R:0.0014, T:0.0438(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0483 (C:1.9731, R:0.0014, T:0.0482(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0439 (C:1.9663, R:0.0014, T:0.0437(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0479 (C:1.9676, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0496 (C:1.9682, R:0.0014, T:0.0495(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 211 TRAINING SUMMARY:
  Total Loss: 0.0463
  Contrastive: 1.9710
  Reconstruction: 0.0014
  Topological: 0.0462 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4440
  Contrastive: 1.9292
  Reconstruction: 0.0014
  Topological: 0.4439 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 211/300 COMPLETE (42.5s)
Train Loss: 0.0463 (C:1.9710, R:0.0014, T:0.0462)
Val Loss:   0.4440 (C:1.9292, R:0.0014, T:0.4439)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 212 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0464 (C:1.9657, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0499 (C:1.9680, R:0.0014, T:0.0497(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0477 (C:1.9725, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0486 (C:1.9736, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0445 (C:1.9749, R:0.0014, T:0.0443(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0433 (C:1.9746, R:0.0014, T:0.0431(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0448 (C:1.9667, R:0.0014, T:0.0447(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0477 (C:1.9689, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0445 (C:1.9711, R:0.0014, T:0.0444(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0446 (C:1.9762, R:0.0014, T:0.0444(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0479 (C:1.9715, R:0.0014, T:0.0478(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0433 (C:1.9740, R:0.0014, T:0.0431(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0440 (C:1.9753, R:0.0014, T:0.0438(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0468 (C:1.9750, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0525 (C:1.9726, R:0.0014, T:0.0523(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0475 (C:1.9685, R:0.0014, T:0.0473(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0434 (C:1.9701, R:0.0014, T:0.0433(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0459 (C:1.9698, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0481 (C:1.9723, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0464 (C:1.9663, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0459 (C:1.9718, R:0.0014, T:0.0458(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0467 (C:1.9726, R:0.0014, T:0.0466(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 212 TRAINING SUMMARY:
  Total Loss: 0.0465
  Contrastive: 1.9713
  Reconstruction: 0.0014
  Topological: 0.0463 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4077
  Contrastive: 1.9295
  Reconstruction: 0.0014
  Topological: 0.4076 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 212/300 COMPLETE (43.1s)
Train Loss: 0.0465 (C:1.9713, R:0.0014, T:0.0463)
Val Loss:   0.4077 (C:1.9295, R:0.0014, T:0.4076)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 213 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0466 (C:1.9726, R:0.0014, T:0.0465(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0491 (C:1.9762, R:0.0014, T:0.0490(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0437 (C:1.9684, R:0.0014, T:0.0436(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0460 (C:1.9757, R:0.0014, T:0.0459(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0440 (C:1.9682, R:0.0014, T:0.0438(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0460 (C:1.9705, R:0.0014, T:0.0458(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0482 (C:1.9689, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0460 (C:1.9723, R:0.0014, T:0.0458(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0442 (C:1.9769, R:0.0014, T:0.0440(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0452 (C:1.9716, R:0.0014, T:0.0451(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0482 (C:1.9687, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0474 (C:1.9714, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0459 (C:1.9717, R:0.0014, T:0.0458(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0431 (C:1.9725, R:0.0014, T:0.0430(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0457 (C:1.9690, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0458 (C:1.9771, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0459 (C:1.9750, R:0.0014, T:0.0458(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0425 (C:1.9689, R:0.0014, T:0.0424(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0470 (C:1.9738, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0490 (C:1.9754, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0473 (C:1.9733, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0418 (C:1.9767, R:0.0014, T:0.0416(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 213 TRAINING SUMMARY:
  Total Loss: 0.0463
  Contrastive: 1.9712
  Reconstruction: 0.0014
  Topological: 0.0461 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4077
  Contrastive: 1.9327
  Reconstruction: 0.0014
  Topological: 0.4076 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 213/300 COMPLETE (42.0s)
Train Loss: 0.0463 (C:1.9712, R:0.0014, T:0.0461)
Val Loss:   0.4077 (C:1.9327, R:0.0014, T:0.4076)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 214 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0465 (C:1.9687, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0456 (C:1.9710, R:0.0014, T:0.0454(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0489 (C:1.9652, R:0.0014, T:0.0488(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0487 (C:1.9707, R:0.0014, T:0.0486(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0481 (C:1.9629, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0486 (C:1.9704, R:0.0014, T:0.0484(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0476 (C:1.9721, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0460 (C:1.9687, R:0.0014, T:0.0459(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0464 (C:1.9698, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0438 (C:1.9687, R:0.0014, T:0.0437(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0487 (C:1.9787, R:0.0014, T:0.0485(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0488 (C:1.9718, R:0.0014, T:0.0487(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0475 (C:1.9708, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0461 (C:1.9715, R:0.0014, T:0.0459(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0463 (C:1.9716, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0478 (C:1.9728, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0458 (C:1.9714, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0452 (C:1.9722, R:0.0014, T:0.0450(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0497 (C:1.9679, R:0.0014, T:0.0496(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0434 (C:1.9676, R:0.0014, T:0.0433(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0478 (C:1.9762, R:0.0014, T:0.0476(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0469 (C:1.9699, R:0.0014, T:0.0467(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 214 TRAINING SUMMARY:
  Total Loss: 0.0465
  Contrastive: 1.9708
  Reconstruction: 0.0014
  Topological: 0.0463 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.3917
  Contrastive: 1.9338
  Reconstruction: 0.0014
  Topological: 0.3916 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 214/300 COMPLETE (42.3s)
Train Loss: 0.0465 (C:1.9708, R:0.0014, T:0.0463)
Val Loss:   0.3917 (C:1.9338, R:0.0014, T:0.3916)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 215 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0446 (C:1.9716, R:0.0014, T:0.0444(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0440 (C:1.9706, R:0.0014, T:0.0439(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0465 (C:1.9694, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0445 (C:1.9725, R:0.0014, T:0.0443(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0439 (C:1.9702, R:0.0014, T:0.0438(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0434 (C:1.9716, R:0.0014, T:0.0432(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0463 (C:1.9733, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0465 (C:1.9704, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0469 (C:1.9680, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0468 (C:1.9718, R:0.0014, T:0.0466(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0449 (C:1.9703, R:0.0014, T:0.0448(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0476 (C:1.9684, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0439 (C:1.9696, R:0.0014, T:0.0438(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0415 (C:1.9704, R:0.0014, T:0.0414(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0451 (C:1.9722, R:0.0014, T:0.0450(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0464 (C:1.9720, R:0.0014, T:0.0463(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0458 (C:1.9652, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0482 (C:1.9684, R:0.0014, T:0.0480(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0455 (C:1.9681, R:0.0014, T:0.0453(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0476 (C:1.9662, R:0.0014, T:0.0475(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0439 (C:1.9748, R:0.0014, T:0.0438(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0439 (C:1.9684, R:0.0014, T:0.0438(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.0460

ğŸ“Š EPOCH 215 TRAINING SUMMARY:
  Total Loss: 0.0461
  Contrastive: 1.9712
  Reconstruction: 0.0014
  Topological: 0.0460 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4112
  Contrastive: 1.9292
  Reconstruction: 0.0014
  Topological: 0.4111 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 215/300 COMPLETE (43.8s)
Train Loss: 0.0461 (C:1.9712, R:0.0014, T:0.0460)
Val Loss:   0.4112 (C:1.9292, R:0.0014, T:0.4111)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 216 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0465 (C:1.9696, R:0.0014, T:0.0464(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0421 (C:1.9665, R:0.0014, T:0.0420(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0492 (C:1.9714, R:0.0014, T:0.0491(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0461 (C:1.9697, R:0.0014, T:0.0459(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0473 (C:1.9684, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0443 (C:1.9754, R:0.0014, T:0.0441(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0468 (C:1.9694, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0437 (C:1.9737, R:0.0014, T:0.0436(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0459 (C:1.9717, R:0.0014, T:0.0457(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0439 (C:1.9718, R:0.0014, T:0.0437(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0455 (C:1.9691, R:0.0014, T:0.0454(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0449 (C:1.9689, R:0.0014, T:0.0448(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0470 (C:1.9740, R:0.0014, T:0.0469(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0426 (C:1.9688, R:0.0014, T:0.0424(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0454 (C:1.9710, R:0.0014, T:0.0453(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0441 (C:1.9746, R:0.0014, T:0.0440(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0461 (C:1.9702, R:0.0014, T:0.0460(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0463 (C:1.9724, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0474 (C:1.9691, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0432 (C:1.9706, R:0.0014, T:0.0431(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0480 (C:1.9694, R:0.0014, T:0.0479(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0467 (C:1.9723, R:0.0014, T:0.0465(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 216 TRAINING SUMMARY:
  Total Loss: 0.0463
  Contrastive: 1.9710
  Reconstruction: 0.0014
  Topological: 0.0462 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.4332
  Contrastive: 1.9333
  Reconstruction: 0.0014
  Topological: 0.4331 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 216/300 COMPLETE (43.6s)
Train Loss: 0.0463 (C:1.9710, R:0.0014, T:0.0462)
Val Loss:   0.4332 (C:1.9333, R:0.0014, T:0.4331)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 217 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.0482 (C:1.9708, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.0446 (C:1.9709, R:0.0014, T:0.0445(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.0463 (C:1.9680, R:0.0014, T:0.0461(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.0430 (C:1.9761, R:0.0014, T:0.0429(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.0473 (C:1.9677, R:0.0014, T:0.0472(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.0464 (C:1.9712, R:0.0014, T:0.0462(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.0460 (C:1.9732, R:0.0014, T:0.0458(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.0468 (C:1.9727, R:0.0014, T:0.0467(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.0442 (C:1.9623, R:0.0014, T:0.0440(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.0507 (C:1.9701, R:0.0014, T:0.0505(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.0469 (C:1.9673, R:0.0014, T:0.0468(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.0450 (C:1.9768, R:0.0014, T:0.0448(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.0475 (C:1.9717, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.0461 (C:1.9717, R:0.0014, T:0.0459(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.0457 (C:1.9703, R:0.0014, T:0.0456(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.0472 (C:1.9700, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.0472 (C:1.9730, R:0.0014, T:0.0471(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.0476 (C:1.9701, R:0.0014, T:0.0474(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.0483 (C:1.9684, R:0.0014, T:0.0481(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.0449 (C:1.9705, R:0.0014, T:0.0448(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.0471 (C:1.9715, R:0.0014, T:0.0470(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.0448 (C:1.9678, R:0.0014, T:0.0447(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 217 TRAINING SUMMARY:
  Total Loss: 0.0463
  Contrastive: 1.9708
  Reconstruction: 0.0014
  Topological: 0.0462 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 0.3884
  Contrastive: 1.9310
  Reconstruction: 0.0014
  Topological: 0.3883 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 217/300 COMPLETE (43.8s)
Train Loss: 0.0463 (C:1.9708, R:0.0014, T:0.0462)
Val Loss:   0.3884 (C:1.9310, R:0.0014, T:0.3883)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

ğŸ›‘ Early stopping triggered after 217 epochs
Best model was at epoch 197 with Val Loss: 0.3766

======================================================================
ğŸ“ˆ FINAL TOPOLOGICAL LEARNING ANALYSIS
======================================================================
First topological learning: Epoch 1
Epochs with topology: 217/217
Max consecutive topology epochs: 217
Best topological loss: 0.0460
Final topological loss: 0.0462
âœ… SUCCESS: Topological learning achieved!
ğŸš€ EXCELLENT: Very consistent topological learning (>80%)
ğŸ“ˆ Topological learning appears stable

======================================================================
ğŸ¯ TOPOLOGICAL AUTOENCODER TRAINING COMPLETED
======================================================================
âœ… Topological training completed successfully!
Saving results...
Loading best model from entailment_surfaces/supervised_contrastive_autoencoder/experiments/topological_autoencoder_torchph_phase1_20250722_141618/checkpoints/best_model.pt
Starting model evaluation...
========================================
GlobalContrastiveEvaluator initialized on cuda
Starting comprehensive evaluation...
============================================================
Extracting latent representations...
  Processed 1/10 batches
Extracted representations: torch.Size([9824, 75])
Evaluating clustering performance...
Clustering Results:
  Silhouette Score: 0.0097
  Adjusted Rand Score: 0.1503
  Clustering Accuracy: 0.5627
Evaluating classification performance...
  Extracting training representations...
Extracting latent representations...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
Extracted representations: torch.Size([547740, 75])
  Extracting validation representations...
Extracting latent representations...
  Processed 1/9 batches
Extracted representations: torch.Size([9180, 75])
Subsampled training to 50000 samples
  Training on 50000 samples, evaluating on 9180 samples
Classification Results:
  Accuracy: 0.5853
  Per-class F1: [0.6357340720221607, 0.42931188561215367, 0.6770063119927863]
Evaluating reconstruction quality...
Reconstruction Results:
  Average MSE: 0.001382
Evaluating separation quality...
Separation Results:
  Positive distances: 1.483 Â± 0.213
  Negative distances: 1.557 Â± 0.230
  Separation ratio: 1.05x
  Gap: -2.492
  Perfect separation: No

Comprehensive evaluation completed!

============================================================
EVALUATION SUMMARY
============================================================
Clustering Performance:
  Silhouette Score: 0.0097
  Clustering Accuracy: 0.5627
  Adjusted Rand Score: 0.1503

Classification Performance:
  Accuracy: 0.5853

Separation Quality:
  Separation Ratio: 1.05x
  Gap: -2.492
  Perfect Separation: False

Reconstruction Quality:
  Average MSE: 0.001382
============================================================
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/topological_autoencoder_torchph_phase1_20250722_141618/results/evaluation_results_20250722_165551.json
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/topological_autoencoder_torchph_phase1_20250722_141618/results/evaluation_results_20250722_165551.json

Key Results:
  Separation ratio: 1.05x
  Perfect separation: False
  Classification accuracy: 0.5853

============================================================
TOPOLOGICAL TRAINING ANALYSIS
============================================================

ğŸ“ˆ TOPOLOGICAL LEARNING DIAGNOSIS:
  Total epochs: 217
  Epochs with topological learning: 217
  Current topological loss: 0.0462
  Current topological weight: 1.0000
  âš ï¸  Topological loss is increasing (may need tuning)
ğŸš€ EXCELLENT: Consistent topological learning achieved!
Final topological loss: 0.0462
Epochs with topology: 217/217
âš ï¸  Poor clustering accuracy: 0.563

Final analysis saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/topological_autoencoder_torchph_phase1_20250722_141618/results/final_analysis.json
Experiment saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/topological_autoencoder_torchph_phase1_20250722_141618

Analysis completed with exit code: 0
Time: Tue 22 Jul 16:55:52 BST 2025

=== ANALYSIS SUCCESSFUL ===
Regularization successful!


Job finished.
