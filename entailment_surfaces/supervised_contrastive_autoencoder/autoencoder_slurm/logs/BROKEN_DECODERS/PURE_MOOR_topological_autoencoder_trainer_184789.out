Starting Surface Distance Metric Analysis job...
Job ID: 184789
Node: gpuvm16
Time: Tue 22 Jul 11:54:10 BST 2025
Loading CUDA...
Activating conda environment...
Activated conda environment: /vol/bitbucket/ahb24/tda_entailment_new
Python location: /vol/bitbucket/ahb24/tda_entailment_new/bin/python
Checking GPU availability...
Tue Jul 22 11:54:16 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.133.07             Driver Version: 570.133.07     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla T4                       Off |   00000000:00:06.0 Off |                    0 |
| N/A   35C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+

Testing PyTorch and CUDA...
PyTorch version: 2.4.1
CUDA available: True
CUDA device: Tesla T4
GPU memory: 15.6 GB
PyTorch setup verified!

Starting Topological Training...

============================================================
TOPOLOGICAL AUTOENCODER TRAINING WITH TORCHPH
============================================================
Experiment setup completed:
  Experiment directory: entailment_surfaces/supervised_contrastive_autoencoder/experiments/topological_autoencoder_torchph_phase1_20250722_115506
  Config saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/topological_autoencoder_torchph_phase1_20250722_115506/config.json
Loading data...
========================================
FlexibleEmbedder initialized with type: 'concat'
Output dimension will be: 1536
GlobalDataLoader initialized:
  Embedding type: concat
  Output dimension: 1536
  Sample size: All
Starting data loading pipeline...
============================================================
Loading training data from data/processed/snli_full_standard_SBERT.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 549367 training samples
Loading validation data from data/processed/snli_full_standard_SBERT_validation.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9842 validation samples
Loading test data from data/processed/snli_full_standard_SBERT_test.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9824 test samples
Generating embeddings for training...
Generating concat embeddings on cuda
Processing 549367 samples in batches of 1000
  Processing batch 1/550
  Processing batch 6/550
  Processing batch 11/550
  Processing batch 16/550
  Processing batch 21/550
  Processing batch 26/550
  Processing batch 31/550
  Processing batch 36/550
  Processing batch 41/550
  Processing batch 46/550
  Processing batch 51/550
  Processing batch 56/550
  Processing batch 61/550
  Processing batch 66/550
  Processing batch 71/550
  Processing batch 76/550
  Processing batch 81/550
  Processing batch 86/550
  Processing batch 91/550
  Processing batch 96/550
  Processing batch 101/550
  Processing batch 106/550
  Processing batch 111/550
  Processing batch 116/550
  Processing batch 121/550
  Processing batch 126/550
  Processing batch 131/550
  Processing batch 136/550
  Processing batch 141/550
  Processing batch 146/550
  Processing batch 151/550
  Processing batch 156/550
  Processing batch 161/550
  Processing batch 166/550
  Processing batch 171/550
  Processing batch 176/550
  Processing batch 181/550
  Processing batch 186/550
  Processing batch 191/550
  Processing batch 196/550
  Processing batch 201/550
  Processing batch 206/550
  Processing batch 211/550
  Processing batch 216/550
  Processing batch 221/550
  Processing batch 226/550
  Processing batch 231/550
  Processing batch 236/550
  Processing batch 241/550
  Processing batch 246/550
  Processing batch 251/550
  Processing batch 256/550
  Processing batch 261/550
  Processing batch 266/550
  Processing batch 271/550
  Processing batch 276/550
  Processing batch 281/550
  Processing batch 286/550
  Processing batch 291/550
  Processing batch 296/550
  Processing batch 301/550
  Processing batch 306/550
  Processing batch 311/550
  Processing batch 316/550
  Processing batch 321/550
  Processing batch 326/550
  Processing batch 331/550
  Processing batch 336/550
  Processing batch 341/550
  Processing batch 346/550
  Processing batch 351/550
  Processing batch 356/550
  Processing batch 361/550
  Processing batch 366/550
  Processing batch 371/550
  Processing batch 376/550
  Processing batch 381/550
  Processing batch 386/550
  Processing batch 391/550
  Processing batch 396/550
  Processing batch 401/550
  Processing batch 406/550
  Processing batch 411/550
  Processing batch 416/550
  Processing batch 421/550
  Processing batch 426/550
  Processing batch 431/550
  Processing batch 436/550
  Processing batch 441/550
  Processing batch 446/550
  Processing batch 451/550
  Processing batch 456/550
  Processing batch 461/550
  Processing batch 466/550
  Processing batch 471/550
  Processing batch 476/550
  Processing batch 481/550
  Processing batch 486/550
  Processing batch 491/550
  Processing batch 496/550
  Processing batch 501/550
  Processing batch 506/550
  Processing batch 511/550
  Processing batch 516/550
  Processing batch 521/550
  Processing batch 526/550
  Processing batch 531/550
  Processing batch 536/550
  Processing batch 541/550
  Processing batch 546/550
Generated concat embeddings: torch.Size([549367, 1536])
Generating embeddings for validation...
Generating concat embeddings on cuda
Processing 9842 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9842, 1536])
Generating embeddings for test...
Generating concat embeddings on cuda
Processing 9824 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9824, 1536])
EntailmentDataset created: 549367 samples
  Embedding shape: torch.Size([549367, 1536])
  Class distribution: {'entailment': 183416, 'neutral': 182764, 'contradiction': 183187}
EntailmentDataset created: 9842 samples
  Embedding shape: torch.Size([9842, 1536])
  Class distribution: {'entailment': 3329, 'neutral': 3235, 'contradiction': 3278}
EntailmentDataset created: 9824 samples
  Embedding shape: torch.Size([9824, 1536])
  Class distribution: {'entailment': 3368, 'neutral': 3219, 'contradiction': 3237}

Data loading pipeline completed!
Output embedding dimension: 1536
Updated model input_dim to: 1536
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 537
  Class 2: 183187 samples
  Class 0: 183416 samples
  Class 1: 182764 samples
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 9
  Class 2: 3278 samples
  Class 0: 3329 samples
  Class 1: 3235 samples
DataLoaders created:
  Batch size: 1020
  Balanced sampling: True
  Train batches: 537
  Val batches: 9
  Test batches: 10
Data loading completed!
  Train: 549367 samples, 537 batches
  Val: 9842 samples, 9 batches
  Test: 9824 samples, 10 batches
ContrastiveAutoencoder initialized:
  Input dim: 1536
  Latent dim: 100
  Hidden dims: [1024, 768, 512, 256, 128]
  Dropout rate: 0.2
  Total parameters: 5,865,316
FullDatasetContrastiveLoss initialized:
  Margin: 2.0
  Update frequency: 3 epochs
  Max global samples: 5000
FullDatasetCombinedLoss initialized:
  Contrastive weight: 0.0
  Base reconstruction weight: 0.1
  Scheduled reconstruction: warmup=10 epochs, max_weight=0.3
MoorTopologicalLoss Initialized: Using 0-dimensional persistence pairings (MST edges).
No prototypes being used for topological loss - whole dataset instead.
TopologicalTrainer initialized on device: cuda
Model parameters: 5,865,316
Enhanced with topological loss monitoring
Starting Phase 1: Pure Topological Training
  Contrastive weight: 0.0
  Topological weight: 1.0
  Reconstruction weight: 0.1

======================================================================
ğŸ§  TOPOLOGICAL AUTOENCODER TRAINING STARTED
======================================================================

============================================================
EPOCH 1 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=46.6861 (C:2.0000, R:0.0110, T:46.6850(w:1.000)âš ï¸)
Batch  25/537: Loss=5.2711 (C:6.1482, R:0.0099, T:5.2702(w:1.000)ğŸš€)
Batch  50/537: Loss=3.6449 (C:5.4392, R:0.0100, T:3.6439(w:1.000)ğŸš€)
Batch  75/537: Loss=3.3285 (C:5.3884, R:0.0099, T:3.3275(w:1.000)ğŸš€)
Batch 100/537: Loss=2.9506 (C:5.3617, R:0.0099, T:2.9496(w:1.000)ğŸš€)
Batch 125/537: Loss=2.8561 (C:5.3628, R:0.0100, T:2.8551(w:1.000)ğŸš€)
Batch 150/537: Loss=2.7286 (C:5.3374, R:0.0100, T:2.7276(w:1.000)ğŸš€)
Batch 175/537: Loss=2.7168 (C:5.3858, R:0.0100, T:2.7158(w:1.000)ğŸš€)
Batch 200/537: Loss=2.5893 (C:5.3348, R:0.0100, T:2.5883(w:1.000)ğŸš€)
Batch 225/537: Loss=2.6110 (C:5.2520, R:0.0100, T:2.6100(w:1.000)ğŸš€)
Batch 250/537: Loss=2.5150 (C:5.1348, R:0.0100, T:2.5140(w:1.000)ğŸš€)
Batch 275/537: Loss=2.5138 (C:5.1768, R:0.0100, T:2.5128(w:1.000)ğŸš€)
Batch 300/537: Loss=2.4175 (C:5.1978, R:0.0099, T:2.4165(w:1.000)ğŸš€)
Batch 325/537: Loss=2.4716 (C:5.2836, R:0.0099, T:2.4706(w:1.000)ğŸš€)
Batch 350/537: Loss=2.3947 (C:5.2823, R:0.0099, T:2.3937(w:1.000)ğŸš€)
Batch 375/537: Loss=2.3605 (C:5.2947, R:0.0099, T:2.3595(w:1.000)ğŸš€)
Batch 400/537: Loss=2.4329 (C:5.3563, R:0.0099, T:2.4319(w:1.000)ğŸš€)
Batch 425/537: Loss=2.5207 (C:5.3515, R:0.0100, T:2.5197(w:1.000)ğŸš€)
Batch 450/537: Loss=2.2592 (C:5.3682, R:0.0099, T:2.2582(w:1.000)ğŸš€)
Batch 475/537: Loss=2.3704 (C:5.3800, R:0.0100, T:2.3694(w:1.000)ğŸš€)
Batch 500/537: Loss=2.2993 (C:5.3263, R:0.0100, T:2.2983(w:1.000)ğŸš€)
Batch 525/537: Loss=2.4439 (C:5.2691, R:0.0100, T:2.4429(w:1.000)ğŸš€)
ğŸ‰ MILESTONE: First topological learning detected at epoch 1!
   Initial topological loss: 3.2002
ğŸ“ˆ New best topological loss: 3.2002

ğŸ“Š EPOCH 1 TRAINING SUMMARY:
  Total Loss: 3.2012
  Contrastive: 5.2852
  Reconstruction: 0.0100
  Topological: 3.2002 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 41.8696
  Contrastive: 1.9830
  Reconstruction: 0.0099
  Topological: 41.8686 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 1/300 COMPLETE (56.8s)
Train Loss: 3.2012 (C:5.2852, R:0.0100, T:3.2002)
Val Loss:   41.8696 (C:1.9830, R:0.0099, T:41.8686)
ğŸš€ Good topological learning progress
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 2 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=2.3618 (C:5.2810, R:0.0100, T:2.3608(w:1.000)ğŸš€)
Batch  25/537: Loss=2.3800 (C:5.3225, R:0.0099, T:2.3790(w:1.000)ğŸš€)
Batch  50/537: Loss=2.3457 (C:5.2341, R:0.0099, T:2.3447(w:1.000)ğŸš€)
Batch  75/537: Loss=2.3181 (C:5.2496, R:0.0099, T:2.3171(w:1.000)ğŸš€)
Batch 100/537: Loss=2.3129 (C:5.2322, R:0.0099, T:2.3119(w:1.000)ğŸš€)
Batch 125/537: Loss=2.3264 (C:5.2780, R:0.0099, T:2.3254(w:1.000)ğŸš€)
Batch 150/537: Loss=2.3751 (C:5.4439, R:0.0100, T:2.3741(w:1.000)ğŸš€)
Batch 175/537: Loss=2.4130 (C:5.2630, R:0.0100, T:2.4120(w:1.000)ğŸš€)
Batch 200/537: Loss=2.3976 (C:5.2260, R:0.0100, T:2.3966(w:1.000)ğŸš€)
Batch 225/537: Loss=2.3684 (C:5.3439, R:0.0100, T:2.3674(w:1.000)ğŸš€)
Batch 250/537: Loss=2.0928 (C:5.4411, R:0.0100, T:2.0918(w:1.000)ğŸš€)
Batch 275/537: Loss=2.1366 (C:5.1256, R:0.0099, T:2.1356(w:1.000)ğŸš€)
Batch 300/537: Loss=2.0326 (C:5.2669, R:0.0099, T:2.0316(w:1.000)ğŸš€)
Batch 325/537: Loss=2.0766 (C:5.3681, R:0.0100, T:2.0756(w:1.000)ğŸš€)
Batch 350/537: Loss=2.0416 (C:5.2261, R:0.0100, T:2.0406(w:1.000)ğŸš€)
Batch 375/537: Loss=1.9279 (C:5.3076, R:0.0100, T:1.9269(w:1.000)ğŸš€)
Batch 400/537: Loss=1.9226 (C:5.1782, R:0.0100, T:1.9216(w:1.000)ğŸš€)
Batch 425/537: Loss=1.8092 (C:5.3445, R:0.0100, T:1.8083(w:1.000)ğŸš€)
Batch 450/537: Loss=1.8075 (C:5.3856, R:0.0100, T:1.8065(w:1.000)ğŸš€)
Batch 475/537: Loss=1.7987 (C:5.3943, R:0.0099, T:1.7977(w:1.000)ğŸš€)
Batch 500/537: Loss=1.7599 (C:5.4602, R:0.0100, T:1.7589(w:1.000)ğŸš€)
Batch 525/537: Loss=1.7871 (C:5.3662, R:0.0100, T:1.7861(w:1.000)ğŸš€)
ğŸ“ˆ New best topological loss: 2.1130

ğŸ“Š EPOCH 2 TRAINING SUMMARY:
  Total Loss: 2.1140
  Contrastive: 5.3324
  Reconstruction: 0.0100
  Topological: 2.1130 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 36.0776
  Contrastive: 2.1983
  Reconstruction: 0.0099
  Topological: 36.0766 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 2/300 COMPLETE (45.6s)
Train Loss: 2.1140 (C:5.3324, R:0.0100, T:2.1130)
Val Loss:   36.0776 (C:2.1983, R:0.0099, T:36.0766)
ğŸš€ Good topological learning progress
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 3 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.7513 (C:5.3252, R:0.0100, T:1.7503(w:1.000)ğŸš€)
Batch  25/537: Loss=1.7291 (C:5.4293, R:0.0099, T:1.7281(w:1.000)ğŸš€)
Batch  50/537: Loss=1.7877 (C:5.2161, R:0.0099, T:1.7867(w:1.000)ğŸš€)
Batch  75/537: Loss=1.7487 (C:5.4744, R:0.0100, T:1.7477(w:1.000)ğŸš€)
Batch 100/537: Loss=1.7070 (C:5.4264, R:0.0099, T:1.7060(w:1.000)ğŸš€)
Batch 125/537: Loss=1.6809 (C:5.3992, R:0.0100, T:1.6799(w:1.000)ğŸš€)
Batch 150/537: Loss=1.6809 (C:5.3879, R:0.0099, T:1.6799(w:1.000)ğŸš€)
Batch 175/537: Loss=1.6899 (C:5.4981, R:0.0099, T:1.6889(w:1.000)ğŸš€)
Batch 200/537: Loss=1.5814 (C:5.4382, R:0.0100, T:1.5804(w:1.000)ğŸš€)
Batch 225/537: Loss=1.5108 (C:5.3566, R:0.0099, T:1.5098(w:1.000)ğŸš€)
Batch 250/537: Loss=1.6454 (C:5.6474, R:0.0099, T:1.6444(w:1.000)ğŸš€)
Batch 275/537: Loss=1.5148 (C:5.3705, R:0.0100, T:1.5138(w:1.000)ğŸš€)
Batch 300/537: Loss=1.5074 (C:5.4686, R:0.0099, T:1.5064(w:1.000)ğŸš€)
Batch 325/537: Loss=1.4895 (C:5.5025, R:0.0100, T:1.4885(w:1.000)ğŸš€)
Batch 350/537: Loss=1.4273 (C:5.4247, R:0.0100, T:1.4263(w:1.000)ğŸš€)
Batch 375/537: Loss=1.5164 (C:5.3618, R:0.0099, T:1.5154(w:1.000)ğŸš€)
Batch 400/537: Loss=1.4568 (C:5.4201, R:0.0100, T:1.4558(w:1.000)ğŸš€)
Batch 425/537: Loss=1.4323 (C:5.4802, R:0.0100, T:1.4313(w:1.000)ğŸš€)
Batch 450/537: Loss=1.4468 (C:5.4453, R:0.0099, T:1.4458(w:1.000)ğŸš€)
Batch 475/537: Loss=1.4740 (C:5.6079, R:0.0100, T:1.4730(w:1.000)ğŸš€)
Batch 500/537: Loss=1.4321 (C:5.3685, R:0.0099, T:1.4311(w:1.000)ğŸš€)
Batch 525/537: Loss=1.3303 (C:5.5041, R:0.0100, T:1.3293(w:1.000)ğŸš€)
ğŸ“ˆ New best topological loss: 1.5737

ğŸ“Š EPOCH 3 TRAINING SUMMARY:
  Total Loss: 1.5747
  Contrastive: 5.4378
  Reconstruction: 0.0100
  Topological: 1.5737 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 29.8160
  Contrastive: 2.5547
  Reconstruction: 0.0099
  Topological: 29.8151 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 3/300 COMPLETE (44.7s)
Train Loss: 1.5747 (C:5.4378, R:0.0100, T:1.5737)
Val Loss:   29.8160 (C:2.5547, R:0.0099, T:29.8151)
ğŸš€ Good topological learning progress
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 4 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.3969 (C:5.4457, R:0.0099, T:1.3959(w:1.000)ğŸš€)
Batch  25/537: Loss=1.2790 (C:5.3986, R:0.0099, T:1.2780(w:1.000)ğŸš€)
Batch  50/537: Loss=1.3889 (C:5.4170, R:0.0099, T:1.3879(w:1.000)ğŸš€)
Batch  75/537: Loss=1.3265 (C:5.5734, R:0.0099, T:1.3255(w:1.000)ğŸš€)
Batch 100/537: Loss=1.3283 (C:5.4590, R:0.0099, T:1.3273(w:1.000)ğŸš€)
Batch 125/537: Loss=1.3846 (C:5.6657, R:0.0099, T:1.3836(w:1.000)ğŸš€)
Batch 150/537: Loss=1.2572 (C:5.4663, R:0.0099, T:1.2562(w:1.000)ğŸš€)
Batch 175/537: Loss=1.3194 (C:5.4228, R:0.0100, T:1.3184(w:1.000)ğŸš€)
Batch 200/537: Loss=1.2246 (C:5.5476, R:0.0099, T:1.2236(w:1.000)ğŸš€)
Batch 225/537: Loss=1.2638 (C:5.5608, R:0.0100, T:1.2628(w:1.000)ğŸš€)
Batch 250/537: Loss=1.2899 (C:5.3881, R:0.0100, T:1.2889(w:1.000)ğŸš€)
Batch 275/537: Loss=1.2460 (C:5.4928, R:0.0100, T:1.2450(w:1.000)ğŸš€)
Batch 300/537: Loss=1.3574 (C:5.5344, R:0.0100, T:1.3564(w:1.000)ğŸš€)
Batch 325/537: Loss=1.2665 (C:5.4038, R:0.0100, T:1.2655(w:1.000)ğŸš€)
Batch 350/537: Loss=1.1947 (C:5.5176, R:0.0099, T:1.1937(w:1.000)ğŸš€)
Batch 375/537: Loss=1.2054 (C:5.5225, R:0.0100, T:1.2044(w:1.000)ğŸš€)
Batch 400/537: Loss=1.1349 (C:5.5474, R:0.0099, T:1.1339(w:1.000)ğŸš€)
Batch 425/537: Loss=1.1984 (C:5.4530, R:0.0100, T:1.1974(w:1.000)ğŸš€)
Batch 450/537: Loss=1.2576 (C:5.6512, R:0.0100, T:1.2566(w:1.000)ğŸš€)
Batch 475/537: Loss=1.2220 (C:5.6736, R:0.0100, T:1.2210(w:1.000)ğŸš€)
Batch 500/537: Loss=1.1107 (C:5.5451, R:0.0100, T:1.1097(w:1.000)ğŸš€)
Batch 525/537: Loss=1.1711 (C:5.4843, R:0.0099, T:1.1701(w:1.000)ğŸš€)
ğŸ“ˆ New best topological loss: 1.2677

ğŸ“Š EPOCH 4 TRAINING SUMMARY:
  Total Loss: 1.2687
  Contrastive: 5.5083
  Reconstruction: 0.0100
  Topological: 1.2677 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 23.6812
  Contrastive: 2.9519
  Reconstruction: 0.0099
  Topological: 23.6802 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 4/300 COMPLETE (44.5s)
Train Loss: 1.2687 (C:5.5083, R:0.0100, T:1.2677)
Val Loss:   23.6812 (C:2.9519, R:0.0099, T:23.6802)
ğŸš€ Good topological learning progress
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 5 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1968 (C:5.6084, R:0.0100, T:1.1958(w:1.000)ğŸš€)
Batch  25/537: Loss=1.1112 (C:5.4869, R:0.0100, T:1.1102(w:1.000)ğŸš€)
Batch  50/537: Loss=1.1352 (C:5.5952, R:0.0099, T:1.1342(w:1.000)ğŸš€)
Batch  75/537: Loss=1.1395 (C:5.4830, R:0.0099, T:1.1386(w:1.000)ğŸš€)
Batch 100/537: Loss=1.1660 (C:5.6846, R:0.0100, T:1.1650(w:1.000)ğŸš€)
Batch 125/537: Loss=1.1053 (C:5.4493, R:0.0100, T:1.1043(w:1.000)ğŸš€)
Batch 150/537: Loss=1.0690 (C:5.6570, R:0.0100, T:1.0680(w:1.000)ğŸš€)
Batch 175/537: Loss=1.0603 (C:5.6684, R:0.0099, T:1.0593(w:1.000)ğŸš€)
Batch 200/537: Loss=1.0615 (C:5.4898, R:0.0100, T:1.0605(w:1.000)ğŸš€)
Batch 225/537: Loss=1.0577 (C:5.5879, R:0.0100, T:1.0567(w:1.000)ğŸš€)
Batch 250/537: Loss=1.0537 (C:5.5351, R:0.0100, T:1.0527(w:1.000)ğŸš€)
Batch 275/537: Loss=1.0796 (C:5.5338, R:0.0100, T:1.0786(w:1.000)ğŸš€)
Batch 300/537: Loss=1.0840 (C:5.5761, R:0.0100, T:1.0830(w:1.000)ğŸš€)
Batch 325/537: Loss=1.0142 (C:5.5769, R:0.0100, T:1.0132(w:1.000)ğŸš€)
Batch 350/537: Loss=1.0401 (C:5.5493, R:0.0100, T:1.0391(w:1.000)ğŸš€)
Batch 375/537: Loss=1.0155 (C:5.6696, R:0.0099, T:1.0145(w:1.000)ğŸš€)
Batch 400/537: Loss=1.0328 (C:5.5744, R:0.0099, T:1.0318(w:1.000)ğŸš€)
Batch 425/537: Loss=1.0262 (C:5.5660, R:0.0099, T:1.0252(w:1.000)ğŸš€)
Batch 450/537: Loss=1.0329 (C:5.6190, R:0.0099, T:1.0319(w:1.000)ğŸš€)
Batch 475/537: Loss=0.9752 (C:5.6044, R:0.0099, T:0.9742(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.9442 (C:5.5574, R:0.0100, T:0.9432(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.9759 (C:5.6029, R:0.0100, T:0.9749(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 1.0642

ğŸ“Š EPOCH 5 TRAINING SUMMARY:
  Total Loss: 1.0651
  Contrastive: 5.5613
  Reconstruction: 0.0100
  Topological: 1.0642 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 20.6463
  Contrastive: 3.1391
  Reconstruction: 0.0099
  Topological: 20.6453 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 5/300 COMPLETE (45.4s)
Train Loss: 1.0651 (C:5.5613, R:0.0100, T:1.0642)
Val Loss:   20.6463 (C:3.1391, R:0.0099, T:20.6453)
ğŸš€ Good topological learning progress
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 6 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.9925 (C:5.6047, R:0.0100, T:0.9915(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.9820 (C:5.6651, R:0.0099, T:0.9810(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.9954 (C:5.6471, R:0.0100, T:0.9944(w:1.000)ğŸ‰)
Batch  75/537: Loss=1.0043 (C:5.5654, R:0.0100, T:1.0033(w:1.000)ğŸš€)
Batch 100/537: Loss=0.9269 (C:5.6687, R:0.0100, T:0.9259(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.9414 (C:5.4907, R:0.0099, T:0.9404(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.9525 (C:5.5644, R:0.0099, T:0.9515(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.9216 (C:5.5844, R:0.0099, T:0.9206(w:1.000)ğŸ‰)
Batch 200/537: Loss=1.0106 (C:5.6787, R:0.0099, T:1.0096(w:1.000)ğŸš€)
Batch 225/537: Loss=0.9913 (C:5.6760, R:0.0099, T:0.9903(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.9476 (C:5.6212, R:0.0099, T:0.9466(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.9350 (C:5.6252, R:0.0099, T:0.9340(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.9509 (C:5.6103, R:0.0099, T:0.9499(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.9241 (C:5.5914, R:0.0099, T:0.9231(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.9752 (C:5.6569, R:0.0099, T:0.9742(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.9495 (C:5.6573, R:0.0100, T:0.9485(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.9597 (C:5.5986, R:0.0100, T:0.9587(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.9283 (C:5.6632, R:0.0099, T:0.9274(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.9307 (C:5.7178, R:0.0100, T:0.9297(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.9084 (C:5.6214, R:0.0099, T:0.9074(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.9143 (C:5.5211, R:0.0100, T:0.9133(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.8665 (C:5.6279, R:0.0100, T:0.8655(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.9549

ğŸ“Š EPOCH 6 TRAINING SUMMARY:
  Total Loss: 0.9559
  Contrastive: 5.5901
  Reconstruction: 0.0100
  Topological: 0.9549 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 18.6392
  Contrastive: 3.2894
  Reconstruction: 0.0099
  Topological: 18.6382 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 6/300 COMPLETE (45.3s)
Train Loss: 0.9559 (C:5.5901, R:0.0100, T:0.9549)
Val Loss:   18.6392 (C:3.2894, R:0.0099, T:18.6382)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 7 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.8805 (C:5.5992, R:0.0099, T:0.8795(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.9156 (C:5.7899, R:0.0100, T:0.9146(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.9144 (C:5.5839, R:0.0099, T:0.9134(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.9145 (C:5.6102, R:0.0100, T:0.9135(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.8928 (C:5.5861, R:0.0100, T:0.8918(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.8752 (C:5.6250, R:0.0100, T:0.8742(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.8688 (C:5.6126, R:0.0099, T:0.8678(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.9039 (C:5.6336, R:0.0100, T:0.9029(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.8610 (C:5.6384, R:0.0099, T:0.8600(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.8736 (C:5.5914, R:0.0099, T:0.8726(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.8659 (C:5.5715, R:0.0100, T:0.8649(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.9025 (C:5.6043, R:0.0100, T:0.9015(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.8845 (C:5.5754, R:0.0100, T:0.8835(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.8852 (C:5.5759, R:0.0099, T:0.8842(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.8397 (C:5.5760, R:0.0099, T:0.8387(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.8663 (C:5.6362, R:0.0100, T:0.8653(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.8166 (C:5.5797, R:0.0099, T:0.8156(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.8272 (C:5.6172, R:0.0100, T:0.8262(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.8032 (C:5.5483, R:0.0100, T:0.8022(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.8415 (C:5.5624, R:0.0099, T:0.8405(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.8428 (C:5.6213, R:0.0100, T:0.8418(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.8783 (C:5.6357, R:0.0099, T:0.8773(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.8708

ğŸ“Š EPOCH 7 TRAINING SUMMARY:
  Total Loss: 0.8718
  Contrastive: 5.6017
  Reconstruction: 0.0100
  Topological: 0.8708 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 16.1483
  Contrastive: 3.4824
  Reconstruction: 0.0099
  Topological: 16.1473 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 7/300 COMPLETE (45.1s)
Train Loss: 0.8718 (C:5.6017, R:0.0100, T:0.8708)
Val Loss:   16.1483 (C:3.4824, R:0.0099, T:16.1473)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 8 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.8305 (C:5.5635, R:0.0100, T:0.8295(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.8283 (C:5.6719, R:0.0099, T:0.8273(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.8669 (C:5.6900, R:0.0100, T:0.8659(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.8174 (C:5.6801, R:0.0100, T:0.8164(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.8524 (C:5.5932, R:0.0100, T:0.8514(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.8223 (C:5.6657, R:0.0100, T:0.8213(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.7737 (C:5.6756, R:0.0100, T:0.7727(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.7614 (C:5.6903, R:0.0100, T:0.7604(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.8325 (C:5.6537, R:0.0100, T:0.8316(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.8400 (C:5.6461, R:0.0100, T:0.8390(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.7878 (C:5.6109, R:0.0100, T:0.7868(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.7548 (C:5.6060, R:0.0099, T:0.7538(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.7853 (C:5.6281, R:0.0100, T:0.7843(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.7678 (C:5.5788, R:0.0099, T:0.7668(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.8240 (C:5.5813, R:0.0100, T:0.8230(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.7691 (C:5.5653, R:0.0099, T:0.7681(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.8117 (C:5.6293, R:0.0100, T:0.8107(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.7629 (C:5.6151, R:0.0099, T:0.7619(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.7687 (C:5.6342, R:0.0100, T:0.7677(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.7942 (C:5.5981, R:0.0100, T:0.7932(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.7520 (C:5.6319, R:0.0100, T:0.7510(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.7359 (C:5.6685, R:0.0100, T:0.7349(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.8002

ğŸ“Š EPOCH 8 TRAINING SUMMARY:
  Total Loss: 0.8012
  Contrastive: 5.6118
  Reconstruction: 0.0100
  Topological: 0.8002 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 14.3886
  Contrastive: 3.5889
  Reconstruction: 0.0099
  Topological: 14.3876 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 8/300 COMPLETE (44.9s)
Train Loss: 0.8012 (C:5.6118, R:0.0100, T:0.8002)
Val Loss:   14.3886 (C:3.5889, R:0.0099, T:14.3876)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 9 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.7513 (C:5.6199, R:0.0099, T:0.7503(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.7643 (C:5.6306, R:0.0100, T:0.7633(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.7668 (C:5.6061, R:0.0100, T:0.7658(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.7466 (C:5.6222, R:0.0100, T:0.7456(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.7850 (C:5.6615, R:0.0099, T:0.7840(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.7557 (C:5.5721, R:0.0099, T:0.7547(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.7563 (C:5.6655, R:0.0100, T:0.7553(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.7605 (C:5.5848, R:0.0099, T:0.7595(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.7723 (C:5.5985, R:0.0100, T:0.7713(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.7599 (C:5.6247, R:0.0100, T:0.7589(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.7485 (C:5.6270, R:0.0099, T:0.7475(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.7407 (C:5.6046, R:0.0100, T:0.7397(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.7562 (C:5.5711, R:0.0100, T:0.7552(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.7479 (C:5.6014, R:0.0100, T:0.7469(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.7680 (C:5.6287, R:0.0099, T:0.7671(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.7466 (C:5.6094, R:0.0100, T:0.7456(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.7867 (C:5.6139, R:0.0100, T:0.7857(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.7569 (C:5.6838, R:0.0099, T:0.7559(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.7348 (C:5.5866, R:0.0100, T:0.7338(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.7276 (C:5.6219, R:0.0099, T:0.7266(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.7154 (C:5.6788, R:0.0099, T:0.7144(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.7513 (C:5.6005, R:0.0099, T:0.7503(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.7479

ğŸ“Š EPOCH 9 TRAINING SUMMARY:
  Total Loss: 0.7489
  Contrastive: 5.6188
  Reconstruction: 0.0100
  Topological: 0.7479 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 12.9064
  Contrastive: 3.7047
  Reconstruction: 0.0099
  Topological: 12.9054 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 9/300 COMPLETE (45.3s)
Train Loss: 0.7489 (C:5.6188, R:0.0100, T:0.7479)
Val Loss:   12.9064 (C:3.7047, R:0.0099, T:12.9054)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 10 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.7076 (C:5.6016, R:0.0099, T:0.7066(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.7310 (C:5.6093, R:0.0099, T:0.7300(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.7675 (C:5.6489, R:0.0099, T:0.7665(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6976 (C:5.6204, R:0.0099, T:0.6966(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6743 (C:5.6073, R:0.0099, T:0.6733(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.7050 (C:5.6518, R:0.0100, T:0.7040(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.7257 (C:5.6374, R:0.0100, T:0.7247(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.7437 (C:5.6007, R:0.0100, T:0.7427(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.7127 (C:5.6728, R:0.0100, T:0.7117(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.7181 (C:5.6604, R:0.0099, T:0.7172(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.7071 (C:5.5976, R:0.0100, T:0.7061(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.7066 (C:5.5738, R:0.0100, T:0.7056(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.7056 (C:5.6640, R:0.0099, T:0.7046(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.7051 (C:5.6880, R:0.0100, T:0.7041(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.7108 (C:5.6592, R:0.0100, T:0.7098(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.7348 (C:5.6194, R:0.0100, T:0.7338(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6963 (C:5.6146, R:0.0099, T:0.6953(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.7308 (C:5.6754, R:0.0100, T:0.7298(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6625 (C:5.6184, R:0.0099, T:0.6615(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6715 (C:5.6029, R:0.0099, T:0.6705(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.7267 (C:5.6160, R:0.0100, T:0.7257(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6943 (C:5.5751, R:0.0099, T:0.6933(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.7114

ğŸ“Š EPOCH 10 TRAINING SUMMARY:
  Total Loss: 0.7124
  Contrastive: 5.6224
  Reconstruction: 0.0100
  Topological: 0.7114 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 11.7583
  Contrastive: 3.7676
  Reconstruction: 0.0099
  Topological: 11.7573 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 10/300 COMPLETE (45.6s)
Train Loss: 0.7124 (C:5.6224, R:0.0100, T:0.7114)
Val Loss:   11.7583 (C:3.7676, R:0.0099, T:11.7573)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 11 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.7137 (C:5.5798, R:0.0100, T:0.7127(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.7055 (C:5.5861, R:0.0100, T:0.7045(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6866 (C:5.6019, R:0.0100, T:0.6856(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6612 (C:5.6334, R:0.0100, T:0.6602(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6826 (C:5.6533, R:0.0100, T:0.6816(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6478 (C:5.6419, R:0.0099, T:0.6468(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6867 (C:5.6210, R:0.0100, T:0.6857(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6947 (C:5.6554, R:0.0099, T:0.6937(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6831 (C:5.6498, R:0.0100, T:0.6821(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.7269 (C:5.6657, R:0.0100, T:0.7259(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6994 (C:5.6402, R:0.0099, T:0.6984(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6883 (C:5.6654, R:0.0100, T:0.6873(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6797 (C:5.6271, R:0.0099, T:0.6787(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6526 (C:5.6099, R:0.0100, T:0.6516(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6961 (C:5.6701, R:0.0100, T:0.6951(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6814 (C:5.6384, R:0.0100, T:0.6804(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6873 (C:5.6297, R:0.0099, T:0.6863(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6595 (C:5.6259, R:0.0099, T:0.6585(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6652 (C:5.6586, R:0.0099, T:0.6642(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.7138 (C:5.6130, R:0.0100, T:0.7128(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6673 (C:5.5959, R:0.0100, T:0.6663(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6757 (C:5.6456, R:0.0100, T:0.6747(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6869

ğŸ“Š EPOCH 11 TRAINING SUMMARY:
  Total Loss: 0.6879
  Contrastive: 5.6265
  Reconstruction: 0.0100
  Topological: 0.6869 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 11.0703
  Contrastive: 3.8418
  Reconstruction: 0.0099
  Topological: 11.0693 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 11/300 COMPLETE (45.4s)
Train Loss: 0.6879 (C:5.6265, R:0.0100, T:0.6869)
Val Loss:   11.0703 (C:3.8418, R:0.0099, T:11.0693)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 12 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6625 (C:5.6230, R:0.0100, T:0.6615(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6714 (C:5.5528, R:0.0100, T:0.6704(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6974 (C:5.6032, R:0.0100, T:0.6964(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6641 (C:5.6437, R:0.0100, T:0.6631(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6951 (C:5.6339, R:0.0099, T:0.6941(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6737 (C:5.6582, R:0.0099, T:0.6727(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6916 (C:5.5820, R:0.0099, T:0.6906(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6724 (C:5.6367, R:0.0100, T:0.6714(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6755 (C:5.6253, R:0.0099, T:0.6745(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.7154 (C:5.6748, R:0.0100, T:0.7144(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6739 (C:5.5868, R:0.0099, T:0.6729(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6344 (C:5.6115, R:0.0099, T:0.6334(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6361 (C:5.6267, R:0.0100, T:0.6351(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6764 (C:5.6129, R:0.0099, T:0.6754(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6422 (C:5.6392, R:0.0100, T:0.6412(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6538 (C:5.6168, R:0.0100, T:0.6528(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6570 (C:5.6952, R:0.0099, T:0.6560(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6785 (C:5.6298, R:0.0100, T:0.6775(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6432 (C:5.6692, R:0.0100, T:0.6422(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6534 (C:5.6274, R:0.0100, T:0.6524(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6701 (C:5.6447, R:0.0100, T:0.6691(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6527 (C:5.5860, R:0.0100, T:0.6517(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6696

ğŸ“Š EPOCH 12 TRAINING SUMMARY:
  Total Loss: 0.6706
  Contrastive: 5.6249
  Reconstruction: 0.0100
  Topological: 0.6696 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 10.2094
  Contrastive: 3.9321
  Reconstruction: 0.0099
  Topological: 10.2084 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 12/300 COMPLETE (45.5s)
Train Loss: 0.6706 (C:5.6249, R:0.0100, T:0.6696)
Val Loss:   10.2094 (C:3.9321, R:0.0099, T:10.2084)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 13 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6770 (C:5.6918, R:0.0100, T:0.6760(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6728 (C:5.6108, R:0.0099, T:0.6718(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6943 (C:5.6709, R:0.0100, T:0.6933(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6744 (C:5.5888, R:0.0100, T:0.6734(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6534 (C:5.6102, R:0.0099, T:0.6524(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.7079 (C:5.6510, R:0.0100, T:0.7069(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6367 (C:5.6348, R:0.0099, T:0.6357(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6722 (C:5.6183, R:0.0100, T:0.6712(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6797 (C:5.6385, R:0.0099, T:0.6787(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6690 (C:5.5971, R:0.0100, T:0.6680(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6337 (C:5.6311, R:0.0100, T:0.6327(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6541 (C:5.5890, R:0.0100, T:0.6531(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6372 (C:5.6250, R:0.0100, T:0.6362(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.7021 (C:5.6426, R:0.0099, T:0.7011(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6710 (C:5.6373, R:0.0100, T:0.6700(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6886 (C:5.6012, R:0.0099, T:0.6876(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6330 (C:5.6115, R:0.0099, T:0.6320(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6558 (C:5.6013, R:0.0099, T:0.6548(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6635 (C:5.6097, R:0.0099, T:0.6625(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6354 (C:5.6443, R:0.0099, T:0.6344(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6443 (C:5.6704, R:0.0099, T:0.6433(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6662 (C:5.6395, R:0.0100, T:0.6652(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6595

ğŸ“Š EPOCH 13 TRAINING SUMMARY:
  Total Loss: 0.6605
  Contrastive: 5.6244
  Reconstruction: 0.0100
  Topological: 0.6595 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 10.2323
  Contrastive: 3.8880
  Reconstruction: 0.0099
  Topological: 10.2313 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 13/300 COMPLETE (45.0s)
Train Loss: 0.6605 (C:5.6244, R:0.0100, T:0.6595)
Val Loss:   10.2323 (C:3.8880, R:0.0099, T:10.2313)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 14 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6614 (C:5.6168, R:0.0099, T:0.6604(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6411 (C:5.6261, R:0.0100, T:0.6401(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6197 (C:5.6601, R:0.0100, T:0.6187(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6348 (C:5.6741, R:0.0100, T:0.6338(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6631 (C:5.6527, R:0.0100, T:0.6621(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6411 (C:5.5978, R:0.0099, T:0.6401(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6602 (C:5.6253, R:0.0099, T:0.6592(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6434 (C:5.6599, R:0.0099, T:0.6424(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6781 (C:5.6141, R:0.0100, T:0.6771(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6434 (C:5.6044, R:0.0099, T:0.6424(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6601 (C:5.6699, R:0.0100, T:0.6591(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6319 (C:5.6108, R:0.0100, T:0.6309(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6393 (C:5.6213, R:0.0099, T:0.6383(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6298 (C:5.6117, R:0.0099, T:0.6288(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6459 (C:5.5578, R:0.0099, T:0.6449(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6763 (C:5.6238, R:0.0100, T:0.6753(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6602 (C:5.6680, R:0.0100, T:0.6592(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6606 (C:5.6311, R:0.0100, T:0.6596(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6765 (C:5.6089, R:0.0100, T:0.6755(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6762 (C:5.6534, R:0.0099, T:0.6752(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6472 (C:5.6508, R:0.0099, T:0.6462(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6296 (C:5.6097, R:0.0100, T:0.6286(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6509

ğŸ“Š EPOCH 14 TRAINING SUMMARY:
  Total Loss: 0.6519
  Contrastive: 5.6233
  Reconstruction: 0.0100
  Topological: 0.6509 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 9.6587
  Contrastive: 3.9518
  Reconstruction: 0.0099
  Topological: 9.6577 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 14/300 COMPLETE (45.1s)
Train Loss: 0.6519 (C:5.6233, R:0.0100, T:0.6509)
Val Loss:   9.6587 (C:3.9518, R:0.0099, T:9.6577)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 15 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6806 (C:5.6237, R:0.0099, T:0.6796(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6452 (C:5.6129, R:0.0100, T:0.6442(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6642 (C:5.6686, R:0.0099, T:0.6632(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6310 (C:5.6081, R:0.0099, T:0.6300(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6389 (C:5.6399, R:0.0099, T:0.6379(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6053 (C:5.5874, R:0.0099, T:0.6043(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6547 (C:5.6119, R:0.0099, T:0.6537(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6542 (C:5.6558, R:0.0100, T:0.6532(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6256 (C:5.6171, R:0.0100, T:0.6247(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6578 (C:5.6168, R:0.0100, T:0.6568(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6344 (C:5.5583, R:0.0099, T:0.6334(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6291 (C:5.6671, R:0.0100, T:0.6281(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6967 (C:5.6212, R:0.0100, T:0.6957(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6487 (C:5.6030, R:0.0100, T:0.6477(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6616 (C:5.6322, R:0.0100, T:0.6606(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6336 (C:5.6018, R:0.0099, T:0.6326(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6559 (C:5.6301, R:0.0099, T:0.6549(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6549 (C:5.6115, R:0.0100, T:0.6539(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6375 (C:5.6118, R:0.0100, T:0.6365(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6386 (C:5.6167, R:0.0100, T:0.6376(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6536 (C:5.6017, R:0.0099, T:0.6526(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6584 (C:5.6255, R:0.0100, T:0.6574(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6475

ğŸ“Š EPOCH 15 TRAINING SUMMARY:
  Total Loss: 0.6484
  Contrastive: 5.6191
  Reconstruction: 0.0100
  Topological: 0.6475 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 9.4625
  Contrastive: 3.9521
  Reconstruction: 0.0099
  Topological: 9.4615 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 15/300 COMPLETE (45.2s)
Train Loss: 0.6484 (C:5.6191, R:0.0100, T:0.6475)
Val Loss:   9.4625 (C:3.9521, R:0.0099, T:9.4615)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 16 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6378 (C:5.5813, R:0.0099, T:0.6368(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6364 (C:5.6396, R:0.0100, T:0.6354(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6295 (C:5.6063, R:0.0099, T:0.6285(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6033 (C:5.6903, R:0.0100, T:0.6023(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6475 (C:5.6373, R:0.0100, T:0.6465(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6416 (C:5.6301, R:0.0100, T:0.6406(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6383 (C:5.5481, R:0.0099, T:0.6373(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6605 (C:5.6173, R:0.0100, T:0.6595(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6431 (C:5.6116, R:0.0100, T:0.6421(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6489 (C:5.6006, R:0.0100, T:0.6479(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6768 (C:5.6217, R:0.0100, T:0.6758(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6562 (C:5.6302, R:0.0100, T:0.6552(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6445 (C:5.6236, R:0.0099, T:0.6435(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6249 (C:5.6385, R:0.0099, T:0.6239(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6593 (C:5.6283, R:0.0100, T:0.6583(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6443 (C:5.6128, R:0.0100, T:0.6433(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6395 (C:5.6083, R:0.0100, T:0.6385(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6243 (C:5.5686, R:0.0099, T:0.6233(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6617 (C:5.6551, R:0.0100, T:0.6607(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6140 (C:5.6507, R:0.0100, T:0.6130(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6405 (C:5.6084, R:0.0100, T:0.6395(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6770 (C:5.6458, R:0.0099, T:0.6760(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6390

ğŸ“Š EPOCH 16 TRAINING SUMMARY:
  Total Loss: 0.6400
  Contrastive: 5.6195
  Reconstruction: 0.0100
  Topological: 0.6390 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 9.2499
  Contrastive: 3.9911
  Reconstruction: 0.0099
  Topological: 9.2489 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 16/300 COMPLETE (45.3s)
Train Loss: 0.6400 (C:5.6195, R:0.0100, T:0.6390)
Val Loss:   9.2499 (C:3.9911, R:0.0099, T:9.2489)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 17 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6278 (C:5.6137, R:0.0099, T:0.6268(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6349 (C:5.6443, R:0.0099, T:0.6339(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6374 (C:5.6544, R:0.0100, T:0.6364(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6531 (C:5.6276, R:0.0100, T:0.6521(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6319 (C:5.6045, R:0.0100, T:0.6309(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6130 (C:5.6420, R:0.0100, T:0.6120(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6383 (C:5.6159, R:0.0099, T:0.6373(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6099 (C:5.6271, R:0.0100, T:0.6089(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6546 (C:5.6076, R:0.0099, T:0.6537(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6470 (C:5.6112, R:0.0100, T:0.6460(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6229 (C:5.6345, R:0.0100, T:0.6219(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6410 (C:5.6610, R:0.0099, T:0.6400(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6285 (C:5.6009, R:0.0099, T:0.6275(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6285 (C:5.6160, R:0.0100, T:0.6275(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6546 (C:5.6029, R:0.0099, T:0.6537(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6400 (C:5.6419, R:0.0100, T:0.6390(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6196 (C:5.6342, R:0.0100, T:0.6186(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6383 (C:5.6481, R:0.0100, T:0.6373(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6158 (C:5.6256, R:0.0100, T:0.6148(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6584 (C:5.6669, R:0.0100, T:0.6574(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6311 (C:5.5951, R:0.0100, T:0.6301(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6241 (C:5.6333, R:0.0100, T:0.6231(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6364

ğŸ“Š EPOCH 17 TRAINING SUMMARY:
  Total Loss: 0.6374
  Contrastive: 5.6162
  Reconstruction: 0.0100
  Topological: 0.6364 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 9.0364
  Contrastive: 3.9847
  Reconstruction: 0.0099
  Topological: 9.0354 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 17/300 COMPLETE (44.8s)
Train Loss: 0.6374 (C:5.6162, R:0.0100, T:0.6364)
Val Loss:   9.0364 (C:3.9847, R:0.0099, T:9.0354)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 18 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6368 (C:5.5814, R:0.0100, T:0.6359(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6530 (C:5.6063, R:0.0099, T:0.6520(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6318 (C:5.6205, R:0.0100, T:0.6308(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6430 (C:5.5957, R:0.0100, T:0.6420(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6502 (C:5.6288, R:0.0100, T:0.6492(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6394 (C:5.6365, R:0.0100, T:0.6384(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5979 (C:5.6189, R:0.0099, T:0.5969(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6605 (C:5.6039, R:0.0100, T:0.6595(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6409 (C:5.6477, R:0.0100, T:0.6399(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6333 (C:5.5886, R:0.0099, T:0.6323(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6165 (C:5.6328, R:0.0099, T:0.6155(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6850 (C:5.6142, R:0.0100, T:0.6840(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6131 (C:5.6572, R:0.0100, T:0.6121(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6326 (C:5.6185, R:0.0100, T:0.6317(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6476 (C:5.6372, R:0.0100, T:0.6466(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6083 (C:5.6194, R:0.0099, T:0.6073(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6538 (C:5.6102, R:0.0100, T:0.6528(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6073 (C:5.5998, R:0.0100, T:0.6063(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6196 (C:5.5856, R:0.0099, T:0.6186(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6336 (C:5.6228, R:0.0100, T:0.6326(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6293 (C:5.6632, R:0.0100, T:0.6283(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5984 (C:5.5773, R:0.0099, T:0.5974(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6312

ğŸ“Š EPOCH 18 TRAINING SUMMARY:
  Total Loss: 0.6322
  Contrastive: 5.6170
  Reconstruction: 0.0100
  Topological: 0.6312 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 8.9281
  Contrastive: 4.0134
  Reconstruction: 0.0099
  Topological: 8.9271 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 18/300 COMPLETE (48.3s)
Train Loss: 0.6322 (C:5.6170, R:0.0100, T:0.6312)
Val Loss:   8.9281 (C:4.0134, R:0.0099, T:8.9271)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 19 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6155 (C:5.5887, R:0.0099, T:0.6145(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6209 (C:5.6499, R:0.0100, T:0.6199(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5896 (C:5.6430, R:0.0100, T:0.5886(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6613 (C:5.6161, R:0.0100, T:0.6603(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6411 (C:5.5790, R:0.0099, T:0.6401(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5993 (C:5.5635, R:0.0100, T:0.5983(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6279 (C:5.5892, R:0.0099, T:0.6269(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6538 (C:5.5966, R:0.0099, T:0.6528(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6341 (C:5.6563, R:0.0099, T:0.6331(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6406 (C:5.6374, R:0.0100, T:0.6396(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6307 (C:5.5871, R:0.0100, T:0.6297(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6555 (C:5.6428, R:0.0100, T:0.6545(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6389 (C:5.6426, R:0.0100, T:0.6379(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6212 (C:5.6080, R:0.0100, T:0.6202(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6218 (C:5.5864, R:0.0099, T:0.6209(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6189 (C:5.6059, R:0.0100, T:0.6179(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6227 (C:5.6030, R:0.0100, T:0.6217(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5989 (C:5.6105, R:0.0100, T:0.5979(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6146 (C:5.5989, R:0.0099, T:0.6136(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6526 (C:5.6004, R:0.0100, T:0.6516(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6249 (C:5.6732, R:0.0100, T:0.6239(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6686 (C:5.6249, R:0.0100, T:0.6676(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6284

ğŸ“Š EPOCH 19 TRAINING SUMMARY:
  Total Loss: 0.6294
  Contrastive: 5.6158
  Reconstruction: 0.0100
  Topological: 0.6284 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 8.4370
  Contrastive: 4.0731
  Reconstruction: 0.0099
  Topological: 8.4360 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 19/300 COMPLETE (45.2s)
Train Loss: 0.6294 (C:5.6158, R:0.0100, T:0.6284)
Val Loss:   8.4370 (C:4.0731, R:0.0099, T:8.4360)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 20 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6487 (C:5.6196, R:0.0099, T:0.6477(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5975 (C:5.5940, R:0.0100, T:0.5965(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6406 (C:5.6498, R:0.0100, T:0.6396(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6423 (C:5.6374, R:0.0100, T:0.6413(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6237 (C:5.6655, R:0.0100, T:0.6227(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6186 (C:5.6221, R:0.0100, T:0.6177(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6265 (C:5.6276, R:0.0100, T:0.6255(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6337 (C:5.6340, R:0.0099, T:0.6327(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6388 (C:5.6208, R:0.0100, T:0.6378(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6335 (C:5.6167, R:0.0100, T:0.6325(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5875 (C:5.6102, R:0.0100, T:0.5865(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6764 (C:5.6024, R:0.0100, T:0.6754(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6299 (C:5.6066, R:0.0100, T:0.6289(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6247 (C:5.6243, R:0.0099, T:0.6237(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5799 (C:5.6174, R:0.0099, T:0.5790(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6441 (C:5.6557, R:0.0100, T:0.6431(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6140 (C:5.5861, R:0.0100, T:0.6130(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6322 (C:5.6341, R:0.0099, T:0.6312(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6424 (C:5.6665, R:0.0099, T:0.6414(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6423 (C:5.6264, R:0.0099, T:0.6413(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6095 (C:5.6114, R:0.0100, T:0.6085(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6031 (C:5.5993, R:0.0099, T:0.6021(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6249

ğŸ“Š EPOCH 20 TRAINING SUMMARY:
  Total Loss: 0.6259
  Contrastive: 5.6149
  Reconstruction: 0.0100
  Topological: 0.6249 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 8.4729
  Contrastive: 4.0637
  Reconstruction: 0.0099
  Topological: 8.4719 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 20/300 COMPLETE (46.8s)
Train Loss: 0.6259 (C:5.6149, R:0.0100, T:0.6249)
Val Loss:   8.4729 (C:4.0637, R:0.0099, T:8.4719)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 21 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6249 (C:5.6228, R:0.0100, T:0.6239(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6150 (C:5.5850, R:0.0100, T:0.6140(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6761 (C:5.5864, R:0.0100, T:0.6751(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6094 (C:5.6106, R:0.0099, T:0.6084(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6341 (C:5.5770, R:0.0099, T:0.6331(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6216 (C:5.6083, R:0.0099, T:0.6206(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6268 (C:5.5851, R:0.0099, T:0.6258(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6112 (C:5.6344, R:0.0100, T:0.6102(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6066 (C:5.6153, R:0.0099, T:0.6056(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6253 (C:5.7007, R:0.0100, T:0.6243(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5864 (C:5.6626, R:0.0100, T:0.5854(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6117 (C:5.5919, R:0.0099, T:0.6107(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5874 (C:5.6209, R:0.0099, T:0.5864(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6165 (C:5.5757, R:0.0099, T:0.6155(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6261 (C:5.6470, R:0.0100, T:0.6251(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6053 (C:5.6119, R:0.0099, T:0.6043(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6185 (C:5.6406, R:0.0100, T:0.6175(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6262 (C:5.6310, R:0.0100, T:0.6252(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6216 (C:5.6025, R:0.0099, T:0.6206(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6281 (C:5.6512, R:0.0100, T:0.6271(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5911 (C:5.6207, R:0.0100, T:0.5901(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6468 (C:5.5899, R:0.0099, T:0.6458(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6200

ğŸ“Š EPOCH 21 TRAINING SUMMARY:
  Total Loss: 0.6210
  Contrastive: 5.6152
  Reconstruction: 0.0100
  Topological: 0.6200 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 8.2246
  Contrastive: 4.0833
  Reconstruction: 0.0099
  Topological: 8.2236 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 21/300 COMPLETE (49.3s)
Train Loss: 0.6210 (C:5.6152, R:0.0100, T:0.6200)
Val Loss:   8.2246 (C:4.0833, R:0.0099, T:8.2236)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 22 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5967 (C:5.6372, R:0.0100, T:0.5958(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6347 (C:5.6346, R:0.0099, T:0.6337(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6079 (C:5.6195, R:0.0100, T:0.6069(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6211 (C:5.6339, R:0.0100, T:0.6201(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6294 (C:5.6103, R:0.0099, T:0.6284(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6319 (C:5.6292, R:0.0099, T:0.6309(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6072 (C:5.5906, R:0.0099, T:0.6062(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6378 (C:5.6261, R:0.0100, T:0.6368(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6506 (C:5.5863, R:0.0100, T:0.6496(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6218 (C:5.5893, R:0.0100, T:0.6208(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6509 (C:5.5822, R:0.0100, T:0.6499(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6455 (C:5.6440, R:0.0100, T:0.6445(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6321 (C:5.6275, R:0.0099, T:0.6311(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6299 (C:5.6631, R:0.0100, T:0.6289(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5784 (C:5.6494, R:0.0099, T:0.5774(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6136 (C:5.6539, R:0.0099, T:0.6126(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6421 (C:5.6235, R:0.0100, T:0.6411(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5915 (C:5.6241, R:0.0100, T:0.5905(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5911 (C:5.6280, R:0.0100, T:0.5901(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6041 (C:5.6097, R:0.0100, T:0.6031(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5988 (C:5.6398, R:0.0099, T:0.5978(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6097 (C:5.5968, R:0.0100, T:0.6087(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6177

ğŸ“Š EPOCH 22 TRAINING SUMMARY:
  Total Loss: 0.6187
  Contrastive: 5.6162
  Reconstruction: 0.0100
  Topological: 0.6177 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 7.9785
  Contrastive: 4.1178
  Reconstruction: 0.0099
  Topological: 7.9775 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 22/300 COMPLETE (47.8s)
Train Loss: 0.6187 (C:5.6162, R:0.0100, T:0.6177)
Val Loss:   7.9785 (C:4.1178, R:0.0099, T:7.9775)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 23 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6267 (C:5.6437, R:0.0100, T:0.6257(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6257 (C:5.5754, R:0.0099, T:0.6247(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6145 (C:5.6479, R:0.0100, T:0.6135(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5970 (C:5.6194, R:0.0099, T:0.5960(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6209 (C:5.6126, R:0.0100, T:0.6199(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5839 (C:5.6596, R:0.0099, T:0.5829(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6177 (C:5.6097, R:0.0099, T:0.6167(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6344 (C:5.6346, R:0.0100, T:0.6334(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6127 (C:5.6258, R:0.0100, T:0.6117(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6074 (C:5.6027, R:0.0100, T:0.6064(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5877 (C:5.6105, R:0.0100, T:0.5867(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6065 (C:5.6155, R:0.0100, T:0.6055(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6322 (C:5.6217, R:0.0099, T:0.6312(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5998 (C:5.5895, R:0.0099, T:0.5988(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5901 (C:5.6581, R:0.0100, T:0.5891(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5779 (C:5.6151, R:0.0099, T:0.5769(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6007 (C:5.6385, R:0.0100, T:0.5997(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6159 (C:5.6143, R:0.0100, T:0.6149(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6067 (C:5.6326, R:0.0100, T:0.6057(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6019 (C:5.5767, R:0.0099, T:0.6009(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6116 (C:5.5729, R:0.0100, T:0.6107(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5861 (C:5.6298, R:0.0100, T:0.5851(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6134

ğŸ“Š EPOCH 23 TRAINING SUMMARY:
  Total Loss: 0.6144
  Contrastive: 5.6166
  Reconstruction: 0.0100
  Topological: 0.6134 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 7.7469
  Contrastive: 4.1506
  Reconstruction: 0.0099
  Topological: 7.7459 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 23/300 COMPLETE (49.0s)
Train Loss: 0.6144 (C:5.6166, R:0.0100, T:0.6134)
Val Loss:   7.7469 (C:4.1506, R:0.0099, T:7.7459)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 24 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5834 (C:5.6538, R:0.0099, T:0.5824(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6215 (C:5.6553, R:0.0100, T:0.6205(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6173 (C:5.5794, R:0.0100, T:0.6163(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6094 (C:5.6122, R:0.0100, T:0.6084(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6026 (C:5.5999, R:0.0100, T:0.6016(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6094 (C:5.6013, R:0.0100, T:0.6084(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6212 (C:5.6480, R:0.0100, T:0.6202(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6082 (C:5.6261, R:0.0100, T:0.6072(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6034 (C:5.6027, R:0.0099, T:0.6024(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6077 (C:5.5995, R:0.0100, T:0.6067(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5797 (C:5.6028, R:0.0100, T:0.5787(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6078 (C:5.6092, R:0.0099, T:0.6068(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5965 (C:5.6599, R:0.0100, T:0.5955(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6246 (C:5.5439, R:0.0099, T:0.6237(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5859 (C:5.6186, R:0.0100, T:0.5849(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5940 (C:5.6373, R:0.0099, T:0.5930(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5907 (C:5.5779, R:0.0100, T:0.5897(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5757 (C:5.6049, R:0.0099, T:0.5747(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6010 (C:5.6327, R:0.0099, T:0.6000(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6323 (C:5.5863, R:0.0100, T:0.6313(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6327 (C:5.6125, R:0.0100, T:0.6317(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6096 (C:5.5559, R:0.0099, T:0.6086(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6095

ğŸ“Š EPOCH 24 TRAINING SUMMARY:
  Total Loss: 0.6105
  Contrastive: 5.6171
  Reconstruction: 0.0100
  Topological: 0.6095 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 7.6836
  Contrastive: 4.1272
  Reconstruction: 0.0099
  Topological: 7.6826 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 24/300 COMPLETE (50.3s)
Train Loss: 0.6105 (C:5.6171, R:0.0100, T:0.6095)
Val Loss:   7.6836 (C:4.1272, R:0.0099, T:7.6826)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 25 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6238 (C:5.5937, R:0.0100, T:0.6228(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6091 (C:5.6366, R:0.0100, T:0.6081(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6035 (C:5.6246, R:0.0099, T:0.6025(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6009 (C:5.6196, R:0.0100, T:0.5999(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5955 (C:5.6350, R:0.0099, T:0.5945(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6164 (C:5.6026, R:0.0100, T:0.6154(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5807 (C:5.6412, R:0.0100, T:0.5797(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6066 (C:5.6473, R:0.0099, T:0.6056(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5880 (C:5.6353, R:0.0099, T:0.5870(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5710 (C:5.6338, R:0.0099, T:0.5700(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5827 (C:5.5661, R:0.0099, T:0.5817(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6057 (C:5.5705, R:0.0100, T:0.6047(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6232 (C:5.6190, R:0.0100, T:0.6222(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6036 (C:5.6319, R:0.0100, T:0.6026(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5812 (C:5.6632, R:0.0100, T:0.5802(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6036 (C:5.6579, R:0.0100, T:0.6026(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5807 (C:5.5793, R:0.0100, T:0.5797(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5832 (C:5.6295, R:0.0099, T:0.5822(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6253 (C:5.6184, R:0.0100, T:0.6243(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5930 (C:5.6335, R:0.0100, T:0.5920(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6007 (C:5.5987, R:0.0099, T:0.5997(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6199 (C:5.6299, R:0.0099, T:0.6189(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6060

ğŸ“Š EPOCH 25 TRAINING SUMMARY:
  Total Loss: 0.6070
  Contrastive: 5.6149
  Reconstruction: 0.0100
  Topological: 0.6060 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 7.5335
  Contrastive: 4.1491
  Reconstruction: 0.0099
  Topological: 7.5326 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 25/300 COMPLETE (48.7s)
Train Loss: 0.6070 (C:5.6149, R:0.0100, T:0.6060)
Val Loss:   7.5335 (C:4.1491, R:0.0099, T:7.5326)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 26 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5830 (C:5.5863, R:0.0100, T:0.5820(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5955 (C:5.5870, R:0.0099, T:0.5945(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6057 (C:5.6040, R:0.0100, T:0.6047(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5936 (C:5.5692, R:0.0100, T:0.5926(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6134 (C:5.5789, R:0.0099, T:0.6124(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6063 (C:5.6286, R:0.0100, T:0.6053(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6034 (C:5.6232, R:0.0099, T:0.6024(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5956 (C:5.5964, R:0.0099, T:0.5946(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5814 (C:5.5638, R:0.0100, T:0.5804(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5971 (C:5.6335, R:0.0099, T:0.5961(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5818 (C:5.6041, R:0.0100, T:0.5808(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6153 (C:5.6210, R:0.0100, T:0.6143(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5906 (C:5.6077, R:0.0099, T:0.5897(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5749 (C:5.6343, R:0.0100, T:0.5739(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6068 (C:5.5991, R:0.0100, T:0.6058(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6045 (C:5.5991, R:0.0100, T:0.6035(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6036 (C:5.6206, R:0.0100, T:0.6026(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5868 (C:5.5978, R:0.0099, T:0.5859(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6475 (C:5.6361, R:0.0100, T:0.6465(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6081 (C:5.6066, R:0.0100, T:0.6071(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6011 (C:5.5783, R:0.0099, T:0.6001(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5574 (C:5.6261, R:0.0099, T:0.5564(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6044

ğŸ“Š EPOCH 26 TRAINING SUMMARY:
  Total Loss: 0.6054
  Contrastive: 5.6123
  Reconstruction: 0.0100
  Topological: 0.6044 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 7.3380
  Contrastive: 4.1840
  Reconstruction: 0.0099
  Topological: 7.3370 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 26/300 COMPLETE (45.3s)
Train Loss: 0.6054 (C:5.6123, R:0.0100, T:0.6044)
Val Loss:   7.3380 (C:4.1840, R:0.0099, T:7.3370)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 27 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5979 (C:5.6411, R:0.0100, T:0.5969(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6000 (C:5.6023, R:0.0100, T:0.5990(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6060 (C:5.6335, R:0.0100, T:0.6050(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6259 (C:5.6425, R:0.0100, T:0.6249(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5813 (C:5.5905, R:0.0100, T:0.5803(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5717 (C:5.5396, R:0.0099, T:0.5708(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6101 (C:5.6079, R:0.0099, T:0.6091(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5993 (C:5.5978, R:0.0099, T:0.5983(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6072 (C:5.6385, R:0.0100, T:0.6062(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5979 (C:5.5926, R:0.0100, T:0.5969(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5971 (C:5.6399, R:0.0100, T:0.5961(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6292 (C:5.6063, R:0.0100, T:0.6282(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6062 (C:5.6251, R:0.0100, T:0.6053(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6145 (C:5.5892, R:0.0100, T:0.6135(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6053 (C:5.6002, R:0.0100, T:0.6043(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5926 (C:5.5972, R:0.0099, T:0.5916(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5925 (C:5.6518, R:0.0100, T:0.5915(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6048 (C:5.6468, R:0.0100, T:0.6038(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6333 (C:5.5795, R:0.0099, T:0.6323(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5915 (C:5.6348, R:0.0099, T:0.5905(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5798 (C:5.5966, R:0.0100, T:0.5789(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5984 (C:5.6320, R:0.0100, T:0.5974(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6022

ğŸ“Š EPOCH 27 TRAINING SUMMARY:
  Total Loss: 0.6032
  Contrastive: 5.6143
  Reconstruction: 0.0100
  Topological: 0.6022 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 7.1615
  Contrastive: 4.2105
  Reconstruction: 0.0099
  Topological: 7.1605 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 27/300 COMPLETE (45.7s)
Train Loss: 0.6032 (C:5.6143, R:0.0100, T:0.6022)
Val Loss:   7.1615 (C:4.2105, R:0.0099, T:7.1605)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 28 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6283 (C:5.6549, R:0.0099, T:0.6273(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6355 (C:5.6082, R:0.0100, T:0.6345(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6084 (C:5.6325, R:0.0099, T:0.6074(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5658 (C:5.5960, R:0.0100, T:0.5648(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6249 (C:5.6365, R:0.0100, T:0.6239(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5983 (C:5.6374, R:0.0100, T:0.5973(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5807 (C:5.6202, R:0.0100, T:0.5797(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5817 (C:5.5571, R:0.0099, T:0.5807(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6376 (C:5.6005, R:0.0100, T:0.6366(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6138 (C:5.5787, R:0.0100, T:0.6128(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5760 (C:5.6319, R:0.0100, T:0.5750(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5843 (C:5.6285, R:0.0100, T:0.5833(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5886 (C:5.5815, R:0.0099, T:0.5876(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6083 (C:5.6086, R:0.0100, T:0.6073(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6240 (C:5.6283, R:0.0099, T:0.6230(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5933 (C:5.6503, R:0.0099, T:0.5923(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5932 (C:5.5528, R:0.0100, T:0.5922(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5822 (C:5.5916, R:0.0100, T:0.5812(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5875 (C:5.5771, R:0.0100, T:0.5865(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5801 (C:5.6056, R:0.0099, T:0.5791(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6085 (C:5.5992, R:0.0099, T:0.6075(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6319 (C:5.5941, R:0.0100, T:0.6309(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6017

ğŸ“Š EPOCH 28 TRAINING SUMMARY:
  Total Loss: 0.6027
  Contrastive: 5.6130
  Reconstruction: 0.0100
  Topological: 0.6017 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 7.1459
  Contrastive: 4.2089
  Reconstruction: 0.0099
  Topological: 7.1449 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 28/300 COMPLETE (45.5s)
Train Loss: 0.6027 (C:5.6130, R:0.0100, T:0.6017)
Val Loss:   7.1459 (C:4.2089, R:0.0099, T:7.1449)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 29 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6051 (C:5.6378, R:0.0100, T:0.6041(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6008 (C:5.6504, R:0.0100, T:0.5998(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6111 (C:5.6540, R:0.0100, T:0.6101(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5880 (C:5.6232, R:0.0100, T:0.5870(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5840 (C:5.5667, R:0.0099, T:0.5830(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6051 (C:5.6480, R:0.0099, T:0.6041(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5709 (C:5.6125, R:0.0100, T:0.5699(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5867 (C:5.6235, R:0.0100, T:0.5857(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5895 (C:5.6236, R:0.0100, T:0.5885(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6358 (C:5.6216, R:0.0100, T:0.6348(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6341 (C:5.5434, R:0.0100, T:0.6331(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5851 (C:5.5832, R:0.0100, T:0.5841(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6419 (C:5.6080, R:0.0100, T:0.6409(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6139 (C:5.6195, R:0.0100, T:0.6129(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5948 (C:5.5640, R:0.0099, T:0.5938(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5984 (C:5.5961, R:0.0100, T:0.5974(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5809 (C:5.5914, R:0.0099, T:0.5799(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6249 (C:5.6298, R:0.0099, T:0.6239(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6271 (C:5.6233, R:0.0099, T:0.6261(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6335 (C:5.6191, R:0.0100, T:0.6325(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6087 (C:5.5812, R:0.0100, T:0.6077(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6327 (C:5.6747, R:0.0100, T:0.6317(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6005

ğŸ“Š EPOCH 29 TRAINING SUMMARY:
  Total Loss: 0.6015
  Contrastive: 5.6134
  Reconstruction: 0.0100
  Topological: 0.6005 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 7.0148
  Contrastive: 4.2044
  Reconstruction: 0.0099
  Topological: 7.0138 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 29/300 COMPLETE (44.9s)
Train Loss: 0.6015 (C:5.6134, R:0.0100, T:0.6005)
Val Loss:   7.0148 (C:4.2044, R:0.0099, T:7.0138)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 30 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6068 (C:5.5938, R:0.0100, T:0.6058(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5851 (C:5.5749, R:0.0100, T:0.5841(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6167 (C:5.6581, R:0.0100, T:0.6157(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6150 (C:5.6095, R:0.0099, T:0.6140(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5690 (C:5.6040, R:0.0100, T:0.5680(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6241 (C:5.6285, R:0.0100, T:0.6231(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5786 (C:5.6337, R:0.0099, T:0.5776(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6105 (C:5.6095, R:0.0100, T:0.6096(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6158 (C:5.5861, R:0.0099, T:0.6149(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6051 (C:5.5904, R:0.0100, T:0.6041(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6079 (C:5.6263, R:0.0100, T:0.6069(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6057 (C:5.6105, R:0.0100, T:0.6047(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5713 (C:5.6083, R:0.0100, T:0.5703(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6140 (C:5.6264, R:0.0100, T:0.6130(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6096 (C:5.5998, R:0.0100, T:0.6086(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5790 (C:5.6029, R:0.0099, T:0.5780(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6125 (C:5.5958, R:0.0100, T:0.6115(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5698 (C:5.6435, R:0.0100, T:0.5688(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5837 (C:5.5811, R:0.0099, T:0.5827(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5862 (C:5.6078, R:0.0100, T:0.5852(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5895 (C:5.5848, R:0.0099, T:0.5885(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5899 (C:5.6154, R:0.0099, T:0.5889(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5972

ğŸ“Š EPOCH 30 TRAINING SUMMARY:
  Total Loss: 0.5982
  Contrastive: 5.6103
  Reconstruction: 0.0100
  Topological: 0.5972 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.9307
  Contrastive: 4.2385
  Reconstruction: 0.0099
  Topological: 6.9297 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 30/300 COMPLETE (45.5s)
Train Loss: 0.5982 (C:5.6103, R:0.0100, T:0.5972)
Val Loss:   6.9307 (C:4.2385, R:0.0099, T:6.9297)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 31 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5670 (C:5.6127, R:0.0100, T:0.5660(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5677 (C:5.5847, R:0.0099, T:0.5667(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6327 (C:5.5857, R:0.0100, T:0.6317(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6137 (C:5.6188, R:0.0099, T:0.6127(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5663 (C:5.6298, R:0.0100, T:0.5653(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6100 (C:5.6316, R:0.0100, T:0.6090(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6078 (C:5.5977, R:0.0099, T:0.6068(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5874 (C:5.6466, R:0.0100, T:0.5864(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6167 (C:5.5977, R:0.0100, T:0.6157(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6035 (C:5.5784, R:0.0100, T:0.6025(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6137 (C:5.6034, R:0.0099, T:0.6127(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5854 (C:5.6249, R:0.0099, T:0.5844(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6104 (C:5.6576, R:0.0099, T:0.6094(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5995 (C:5.6162, R:0.0100, T:0.5985(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5793 (C:5.5947, R:0.0100, T:0.5783(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6161 (C:5.6374, R:0.0099, T:0.6151(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5793 (C:5.6225, R:0.0099, T:0.5783(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6233 (C:5.5873, R:0.0100, T:0.6223(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6181 (C:5.5937, R:0.0100, T:0.6171(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6141 (C:5.5913, R:0.0099, T:0.6131(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5827 (C:5.6412, R:0.0100, T:0.5817(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5639 (C:5.6403, R:0.0100, T:0.5629(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 31 TRAINING SUMMARY:
  Total Loss: 0.5984
  Contrastive: 5.6084
  Reconstruction: 0.0100
  Topological: 0.5974 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.8747
  Contrastive: 4.1987
  Reconstruction: 0.0099
  Topological: 6.8737 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 31/300 COMPLETE (44.7s)
Train Loss: 0.5984 (C:5.6084, R:0.0100, T:0.5974)
Val Loss:   6.8747 (C:4.1987, R:0.0099, T:6.8737)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 32 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6206 (C:5.5546, R:0.0100, T:0.6196(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5955 (C:5.6383, R:0.0099, T:0.5945(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5941 (C:5.5869, R:0.0100, T:0.5931(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5800 (C:5.5659, R:0.0100, T:0.5790(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5924 (C:5.6445, R:0.0100, T:0.5914(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5648 (C:5.6133, R:0.0100, T:0.5638(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6050 (C:5.6035, R:0.0099, T:0.6040(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6075 (C:5.6467, R:0.0100, T:0.6065(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5823 (C:5.5822, R:0.0099, T:0.5813(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6033 (C:5.5751, R:0.0099, T:0.6023(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6079 (C:5.6082, R:0.0100, T:0.6069(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6379 (C:5.5872, R:0.0099, T:0.6369(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5857 (C:5.6605, R:0.0099, T:0.5847(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6237 (C:5.6073, R:0.0100, T:0.6227(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6120 (C:5.6278, R:0.0099, T:0.6110(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5927 (C:5.5860, R:0.0099, T:0.5917(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5816 (C:5.6151, R:0.0099, T:0.5806(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6124 (C:5.5772, R:0.0099, T:0.6114(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6078 (C:5.6259, R:0.0099, T:0.6068(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5838 (C:5.6194, R:0.0100, T:0.5828(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6074 (C:5.5884, R:0.0099, T:0.6064(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6018 (C:5.6201, R:0.0099, T:0.6008(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 32 TRAINING SUMMARY:
  Total Loss: 0.5984
  Contrastive: 5.6084
  Reconstruction: 0.0100
  Topological: 0.5974 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.7006
  Contrastive: 4.2327
  Reconstruction: 0.0099
  Topological: 6.6996 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 32/300 COMPLETE (45.5s)
Train Loss: 0.5984 (C:5.6084, R:0.0100, T:0.5974)
Val Loss:   6.7006 (C:4.2327, R:0.0099, T:6.6996)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 33 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6254 (C:5.5974, R:0.0100, T:0.6244(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6032 (C:5.5846, R:0.0099, T:0.6022(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5594 (C:5.5943, R:0.0099, T:0.5584(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5975 (C:5.6228, R:0.0100, T:0.5965(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6145 (C:5.5988, R:0.0100, T:0.6135(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5822 (C:5.5825, R:0.0100, T:0.5812(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5829 (C:5.6183, R:0.0100, T:0.5819(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5865 (C:5.5979, R:0.0099, T:0.5855(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6091 (C:5.5854, R:0.0100, T:0.6081(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5953 (C:5.5911, R:0.0099, T:0.5943(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5941 (C:5.5762, R:0.0100, T:0.5931(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5720 (C:5.5813, R:0.0099, T:0.5710(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5825 (C:5.5823, R:0.0099, T:0.5815(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5646 (C:5.6131, R:0.0099, T:0.5636(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5852 (C:5.5852, R:0.0100, T:0.5842(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5723 (C:5.5733, R:0.0100, T:0.5713(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6048 (C:5.5933, R:0.0099, T:0.6038(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5945 (C:5.5789, R:0.0099, T:0.5935(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6068 (C:5.6205, R:0.0100, T:0.6058(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5960 (C:5.6239, R:0.0100, T:0.5950(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6068 (C:5.6246, R:0.0100, T:0.6058(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5762 (C:5.6130, R:0.0100, T:0.5752(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5967

ğŸ“Š EPOCH 33 TRAINING SUMMARY:
  Total Loss: 0.5977
  Contrastive: 5.6058
  Reconstruction: 0.0100
  Topological: 0.5967 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.4307
  Contrastive: 4.2833
  Reconstruction: 0.0099
  Topological: 6.4297 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 33/300 COMPLETE (45.2s)
Train Loss: 0.5977 (C:5.6058, R:0.0100, T:0.5967)
Val Loss:   6.4307 (C:4.2833, R:0.0099, T:6.4297)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 34 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5792 (C:5.6295, R:0.0100, T:0.5782(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5740 (C:5.5727, R:0.0099, T:0.5730(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5777 (C:5.5947, R:0.0099, T:0.5767(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6011 (C:5.5938, R:0.0099, T:0.6001(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5786 (C:5.5933, R:0.0100, T:0.5776(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6157 (C:5.5737, R:0.0100, T:0.6147(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5699 (C:5.6186, R:0.0100, T:0.5689(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6074 (C:5.6128, R:0.0099, T:0.6064(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6108 (C:5.5657, R:0.0100, T:0.6098(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5768 (C:5.6164, R:0.0100, T:0.5758(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5801 (C:5.6360, R:0.0099, T:0.5791(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6080 (C:5.5650, R:0.0099, T:0.6070(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6287 (C:5.5954, R:0.0099, T:0.6278(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6091 (C:5.5983, R:0.0100, T:0.6081(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6270 (C:5.5845, R:0.0099, T:0.6260(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6030 (C:5.5695, R:0.0099, T:0.6020(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5890 (C:5.6298, R:0.0100, T:0.5881(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5953 (C:5.6191, R:0.0099, T:0.5943(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5811 (C:5.6323, R:0.0100, T:0.5801(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5771 (C:5.6275, R:0.0100, T:0.5761(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6131 (C:5.6093, R:0.0099, T:0.6121(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6036 (C:5.5920, R:0.0100, T:0.6026(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5955

ğŸ“Š EPOCH 34 TRAINING SUMMARY:
  Total Loss: 0.5965
  Contrastive: 5.6029
  Reconstruction: 0.0100
  Topological: 0.5955 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.7169
  Contrastive: 4.2314
  Reconstruction: 0.0099
  Topological: 6.7159 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 34/300 COMPLETE (45.5s)
Train Loss: 0.5965 (C:5.6029, R:0.0100, T:0.5955)
Val Loss:   6.7169 (C:4.2314, R:0.0099, T:6.7159)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 35 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6016 (C:5.5552, R:0.0099, T:0.6006(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6124 (C:5.6036, R:0.0099, T:0.6114(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5357 (C:5.5980, R:0.0099, T:0.5347(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6177 (C:5.5810, R:0.0100, T:0.6167(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5937 (C:5.5851, R:0.0099, T:0.5927(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5964 (C:5.6543, R:0.0100, T:0.5955(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5758 (C:5.6111, R:0.0099, T:0.5748(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6228 (C:5.5633, R:0.0099, T:0.6218(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6021 (C:5.6254, R:0.0100, T:0.6011(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6121 (C:5.5936, R:0.0100, T:0.6111(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5977 (C:5.6010, R:0.0100, T:0.5967(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6197 (C:5.5788, R:0.0100, T:0.6187(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6164 (C:5.5698, R:0.0099, T:0.6154(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5834 (C:5.5996, R:0.0099, T:0.5824(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5859 (C:5.6204, R:0.0100, T:0.5850(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6124 (C:5.5934, R:0.0099, T:0.6114(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6191 (C:5.6291, R:0.0100, T:0.6181(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6067 (C:5.5994, R:0.0100, T:0.6057(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6008 (C:5.5960, R:0.0100, T:0.5998(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5958 (C:5.6156, R:0.0100, T:0.5948(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6267 (C:5.5869, R:0.0099, T:0.6257(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5563 (C:5.5934, R:0.0099, T:0.5553(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5920

ğŸ“Š EPOCH 35 TRAINING SUMMARY:
  Total Loss: 0.5930
  Contrastive: 5.6055
  Reconstruction: 0.0100
  Topological: 0.5920 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.4346
  Contrastive: 4.2664
  Reconstruction: 0.0099
  Topological: 6.4337 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 35/300 COMPLETE (45.8s)
Train Loss: 0.5930 (C:5.6055, R:0.0100, T:0.5920)
Val Loss:   6.4346 (C:4.2664, R:0.0099, T:6.4337)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 36 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6485 (C:5.6031, R:0.0100, T:0.6475(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5901 (C:5.6249, R:0.0100, T:0.5891(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6040 (C:5.6238, R:0.0099, T:0.6031(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6004 (C:5.6048, R:0.0100, T:0.5994(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5908 (C:5.6195, R:0.0100, T:0.5898(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5739 (C:5.5818, R:0.0100, T:0.5729(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6022 (C:5.5557, R:0.0099, T:0.6012(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5928 (C:5.5711, R:0.0099, T:0.5918(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5869 (C:5.5669, R:0.0099, T:0.5859(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5704 (C:5.6106, R:0.0099, T:0.5694(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5895 (C:5.6434, R:0.0100, T:0.5885(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5800 (C:5.5686, R:0.0099, T:0.5790(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5747 (C:5.6284, R:0.0100, T:0.5737(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5850 (C:5.6064, R:0.0099, T:0.5840(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5834 (C:5.6154, R:0.0100, T:0.5824(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5623 (C:5.6308, R:0.0100, T:0.5613(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5404 (C:5.5385, R:0.0099, T:0.5394(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5714 (C:5.5741, R:0.0099, T:0.5704(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5875 (C:5.6147, R:0.0099, T:0.5865(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5854 (C:5.6015, R:0.0100, T:0.5844(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6131 (C:5.6272, R:0.0099, T:0.6121(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6192 (C:5.5988, R:0.0099, T:0.6182(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 36 TRAINING SUMMARY:
  Total Loss: 0.5952
  Contrastive: 5.6011
  Reconstruction: 0.0100
  Topological: 0.5942 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.3035
  Contrastive: 4.2926
  Reconstruction: 0.0099
  Topological: 6.3025 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 36/300 COMPLETE (45.4s)
Train Loss: 0.5952 (C:5.6011, R:0.0100, T:0.5942)
Val Loss:   6.3035 (C:4.2926, R:0.0099, T:6.3025)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 37 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5537 (C:5.6118, R:0.0099, T:0.5527(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5785 (C:5.6008, R:0.0099, T:0.5775(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5850 (C:5.6303, R:0.0100, T:0.5840(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6020 (C:5.5956, R:0.0100, T:0.6010(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6166 (C:5.5924, R:0.0099, T:0.6156(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5900 (C:5.5721, R:0.0100, T:0.5890(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5882 (C:5.6240, R:0.0099, T:0.5872(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5991 (C:5.6006, R:0.0100, T:0.5981(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6111 (C:5.6069, R:0.0099, T:0.6101(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5752 (C:5.6014, R:0.0099, T:0.5742(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5726 (C:5.5707, R:0.0100, T:0.5716(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5845 (C:5.5852, R:0.0100, T:0.5835(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5894 (C:5.5895, R:0.0100, T:0.5884(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5804 (C:5.5604, R:0.0100, T:0.5794(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5994 (C:5.5733, R:0.0100, T:0.5984(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5882 (C:5.6133, R:0.0099, T:0.5872(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5844 (C:5.5616, R:0.0099, T:0.5834(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5617 (C:5.5819, R:0.0100, T:0.5607(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6144 (C:5.6366, R:0.0100, T:0.6134(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6004 (C:5.5968, R:0.0099, T:0.5994(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5819 (C:5.6157, R:0.0099, T:0.5809(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6149 (C:5.5917, R:0.0100, T:0.6139(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5915

ğŸ“Š EPOCH 37 TRAINING SUMMARY:
  Total Loss: 0.5925
  Contrastive: 5.6023
  Reconstruction: 0.0100
  Topological: 0.5915 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.3954
  Contrastive: 4.2629
  Reconstruction: 0.0099
  Topological: 6.3944 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 37/300 COMPLETE (44.9s)
Train Loss: 0.5925 (C:5.6023, R:0.0100, T:0.5915)
Val Loss:   6.3954 (C:4.2629, R:0.0099, T:6.3944)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 38 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5604 (C:5.5875, R:0.0099, T:0.5594(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6255 (C:5.5682, R:0.0100, T:0.6245(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5775 (C:5.5979, R:0.0099, T:0.5765(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5997 (C:5.6144, R:0.0100, T:0.5987(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5707 (C:5.5686, R:0.0099, T:0.5697(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5960 (C:5.6114, R:0.0100, T:0.5950(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6043 (C:5.5521, R:0.0099, T:0.6033(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5773 (C:5.6072, R:0.0100, T:0.5763(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6031 (C:5.5923, R:0.0100, T:0.6021(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6061 (C:5.5925, R:0.0100, T:0.6051(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5755 (C:5.5906, R:0.0100, T:0.5745(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5953 (C:5.6462, R:0.0100, T:0.5943(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6186 (C:5.5596, R:0.0099, T:0.6177(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6092 (C:5.5728, R:0.0100, T:0.6082(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6096 (C:5.6343, R:0.0099, T:0.6086(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5841 (C:5.5716, R:0.0099, T:0.5831(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6125 (C:5.6538, R:0.0100, T:0.6115(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6273 (C:5.5715, R:0.0100, T:0.6263(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6099 (C:5.5999, R:0.0100, T:0.6089(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5890 (C:5.5713, R:0.0099, T:0.5880(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5882 (C:5.6245, R:0.0099, T:0.5872(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5884 (C:5.5871, R:0.0100, T:0.5874(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5904

ğŸ“Š EPOCH 38 TRAINING SUMMARY:
  Total Loss: 0.5914
  Contrastive: 5.6008
  Reconstruction: 0.0100
  Topological: 0.5904 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.1551
  Contrastive: 4.3080
  Reconstruction: 0.0099
  Topological: 6.1541 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 38/300 COMPLETE (45.1s)
Train Loss: 0.5914 (C:5.6008, R:0.0100, T:0.5904)
Val Loss:   6.1551 (C:4.3080, R:0.0099, T:6.1541)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 39 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5833 (C:5.6298, R:0.0099, T:0.5823(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6060 (C:5.5849, R:0.0100, T:0.6050(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5787 (C:5.6011, R:0.0099, T:0.5777(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5741 (C:5.5776, R:0.0099, T:0.5731(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5666 (C:5.6424, R:0.0099, T:0.5656(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5982 (C:5.6063, R:0.0100, T:0.5972(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5813 (C:5.5979, R:0.0099, T:0.5803(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6052 (C:5.5391, R:0.0099, T:0.6043(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5979 (C:5.5761, R:0.0099, T:0.5969(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5755 (C:5.6260, R:0.0099, T:0.5745(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6159 (C:5.5959, R:0.0100, T:0.6149(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6368 (C:5.5884, R:0.0099, T:0.6358(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6030 (C:5.6022, R:0.0100, T:0.6020(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6133 (C:5.5778, R:0.0100, T:0.6123(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5886 (C:5.6019, R:0.0100, T:0.5876(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5734 (C:5.5899, R:0.0100, T:0.5724(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6166 (C:5.6094, R:0.0100, T:0.6156(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5582 (C:5.5965, R:0.0100, T:0.5572(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5984 (C:5.6152, R:0.0099, T:0.5974(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5911 (C:5.5605, R:0.0100, T:0.5901(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5926 (C:5.5922, R:0.0099, T:0.5916(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6075 (C:5.5690, R:0.0099, T:0.6065(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5895

ğŸ“Š EPOCH 39 TRAINING SUMMARY:
  Total Loss: 0.5905
  Contrastive: 5.5995
  Reconstruction: 0.0100
  Topological: 0.5895 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.1988
  Contrastive: 4.2900
  Reconstruction: 0.0099
  Topological: 6.1978 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 39/300 COMPLETE (45.2s)
Train Loss: 0.5905 (C:5.5995, R:0.0100, T:0.5895)
Val Loss:   6.1988 (C:4.2900, R:0.0099, T:6.1978)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 40 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6179 (C:5.5765, R:0.0100, T:0.6169(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6028 (C:5.5564, R:0.0100, T:0.6018(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6080 (C:5.5798, R:0.0099, T:0.6071(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5714 (C:5.5910, R:0.0099, T:0.5704(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5758 (C:5.6491, R:0.0100, T:0.5748(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5754 (C:5.6015, R:0.0099, T:0.5744(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5652 (C:5.5828, R:0.0099, T:0.5642(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6096 (C:5.5849, R:0.0099, T:0.6086(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5860 (C:5.6112, R:0.0100, T:0.5851(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6110 (C:5.5468, R:0.0099, T:0.6100(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5903 (C:5.5878, R:0.0099, T:0.5893(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6006 (C:5.6010, R:0.0100, T:0.5996(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6038 (C:5.6288, R:0.0100, T:0.6028(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5762 (C:5.6016, R:0.0099, T:0.5752(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5702 (C:5.5759, R:0.0100, T:0.5692(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5994 (C:5.5815, R:0.0099, T:0.5984(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5773 (C:5.6040, R:0.0100, T:0.5763(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6051 (C:5.6430, R:0.0100, T:0.6041(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6176 (C:5.6136, R:0.0100, T:0.6166(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6148 (C:5.6036, R:0.0100, T:0.6138(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6070 (C:5.6156, R:0.0100, T:0.6060(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5807 (C:5.5543, R:0.0100, T:0.5797(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 40 TRAINING SUMMARY:
  Total Loss: 0.5918
  Contrastive: 5.5996
  Reconstruction: 0.0100
  Topological: 0.5908 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.9777
  Contrastive: 4.3296
  Reconstruction: 0.0099
  Topological: 5.9767 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 40/300 COMPLETE (45.2s)
Train Loss: 0.5918 (C:5.5996, R:0.0100, T:0.5908)
Val Loss:   5.9777 (C:4.3296, R:0.0099, T:5.9767)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 41 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6056 (C:5.6151, R:0.0099, T:0.6046(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5864 (C:5.5682, R:0.0099, T:0.5854(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6065 (C:5.5840, R:0.0099, T:0.6055(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6054 (C:5.6098, R:0.0100, T:0.6044(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5455 (C:5.5911, R:0.0099, T:0.5445(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5978 (C:5.5566, R:0.0099, T:0.5968(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5966 (C:5.6307, R:0.0100, T:0.5956(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5695 (C:5.6038, R:0.0100, T:0.5685(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5617 (C:5.5966, R:0.0099, T:0.5607(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5740 (C:5.6170, R:0.0099, T:0.5730(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5976 (C:5.6004, R:0.0100, T:0.5966(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5896 (C:5.6016, R:0.0099, T:0.5886(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5944 (C:5.6014, R:0.0100, T:0.5934(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5896 (C:5.5439, R:0.0100, T:0.5886(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5903 (C:5.5919, R:0.0100, T:0.5893(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6100 (C:5.6135, R:0.0100, T:0.6091(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6148 (C:5.6068, R:0.0100, T:0.6138(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5586 (C:5.5984, R:0.0100, T:0.5576(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5874 (C:5.6171, R:0.0100, T:0.5864(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5817 (C:5.5929, R:0.0100, T:0.5807(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6405 (C:5.6063, R:0.0100, T:0.6395(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5790 (C:5.6016, R:0.0099, T:0.5780(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5887

ğŸ“Š EPOCH 41 TRAINING SUMMARY:
  Total Loss: 0.5897
  Contrastive: 5.5972
  Reconstruction: 0.0100
  Topological: 0.5887 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.0926
  Contrastive: 4.2954
  Reconstruction: 0.0099
  Topological: 6.0916 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 41/300 COMPLETE (44.8s)
Train Loss: 0.5897 (C:5.5972, R:0.0100, T:0.5887)
Val Loss:   6.0926 (C:4.2954, R:0.0099, T:6.0916)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 42 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5808 (C:5.5603, R:0.0099, T:0.5798(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6042 (C:5.6015, R:0.0100, T:0.6032(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5931 (C:5.5831, R:0.0099, T:0.5921(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6173 (C:5.6158, R:0.0099, T:0.6163(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6161 (C:5.6254, R:0.0099, T:0.6151(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6396 (C:5.6279, R:0.0100, T:0.6386(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6188 (C:5.5998, R:0.0099, T:0.6178(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6007 (C:5.5896, R:0.0099, T:0.5998(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5690 (C:5.5998, R:0.0100, T:0.5680(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6014 (C:5.6024, R:0.0100, T:0.6004(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6133 (C:5.5820, R:0.0100, T:0.6123(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6065 (C:5.5798, R:0.0099, T:0.6055(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6246 (C:5.5958, R:0.0099, T:0.6236(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5688 (C:5.5689, R:0.0099, T:0.5678(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5935 (C:5.5905, R:0.0100, T:0.5925(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5841 (C:5.6111, R:0.0100, T:0.5831(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5997 (C:5.6195, R:0.0100, T:0.5987(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5802 (C:5.5979, R:0.0100, T:0.5792(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6216 (C:5.6019, R:0.0100, T:0.6206(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5559 (C:5.5662, R:0.0100, T:0.5549(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6038 (C:5.5930, R:0.0100, T:0.6028(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5771 (C:5.6112, R:0.0099, T:0.5761(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 42 TRAINING SUMMARY:
  Total Loss: 0.5901
  Contrastive: 5.5971
  Reconstruction: 0.0100
  Topological: 0.5891 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.1259
  Contrastive: 4.3225
  Reconstruction: 0.0099
  Topological: 6.1249 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 42/300 COMPLETE (44.7s)
Train Loss: 0.5901 (C:5.5971, R:0.0100, T:0.5891)
Val Loss:   6.1259 (C:4.3225, R:0.0099, T:6.1249)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 43 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5949 (C:5.5830, R:0.0099, T:0.5939(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5934 (C:5.5997, R:0.0100, T:0.5924(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5969 (C:5.5833, R:0.0099, T:0.5959(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5620 (C:5.6384, R:0.0099, T:0.5610(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5718 (C:5.5796, R:0.0099, T:0.5708(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5936 (C:5.6079, R:0.0100, T:0.5926(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5641 (C:5.5870, R:0.0100, T:0.5631(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5847 (C:5.5841, R:0.0099, T:0.5837(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5812 (C:5.6025, R:0.0100, T:0.5802(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6214 (C:5.5972, R:0.0099, T:0.6204(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5568 (C:5.6075, R:0.0100, T:0.5558(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6161 (C:5.6112, R:0.0100, T:0.6151(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5910 (C:5.5833, R:0.0099, T:0.5900(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5949 (C:5.6362, R:0.0100, T:0.5939(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5759 (C:5.5836, R:0.0099, T:0.5749(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5964 (C:5.5983, R:0.0100, T:0.5954(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6128 (C:5.5598, R:0.0099, T:0.6118(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5909 (C:5.5442, R:0.0100, T:0.5899(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5777 (C:5.6176, R:0.0100, T:0.5767(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5879 (C:5.5955, R:0.0099, T:0.5869(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6054 (C:5.6040, R:0.0099, T:0.6044(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5652 (C:5.6143, R:0.0099, T:0.5642(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5884

ğŸ“Š EPOCH 43 TRAINING SUMMARY:
  Total Loss: 0.5894
  Contrastive: 5.5970
  Reconstruction: 0.0100
  Topological: 0.5884 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.0062
  Contrastive: 4.2973
  Reconstruction: 0.0099
  Topological: 6.0052 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 43/300 COMPLETE (43.6s)
Train Loss: 0.5894 (C:5.5970, R:0.0100, T:0.5884)
Val Loss:   6.0062 (C:4.2973, R:0.0099, T:6.0052)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 44 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5788 (C:5.5528, R:0.0100, T:0.5778(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5821 (C:5.5879, R:0.0100, T:0.5811(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5851 (C:5.6137, R:0.0100, T:0.5841(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5963 (C:5.6249, R:0.0100, T:0.5953(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5681 (C:5.5710, R:0.0099, T:0.5671(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5886 (C:5.6084, R:0.0100, T:0.5876(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5850 (C:5.5896, R:0.0099, T:0.5840(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5833 (C:5.5833, R:0.0099, T:0.5823(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5693 (C:5.5836, R:0.0099, T:0.5684(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5789 (C:5.6204, R:0.0099, T:0.5779(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5858 (C:5.5899, R:0.0099, T:0.5848(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5823 (C:5.5839, R:0.0100, T:0.5813(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5891 (C:5.5827, R:0.0099, T:0.5881(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5942 (C:5.5870, R:0.0099, T:0.5932(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5848 (C:5.5627, R:0.0099, T:0.5838(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5758 (C:5.6409, R:0.0100, T:0.5748(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5886 (C:5.6431, R:0.0100, T:0.5876(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5803 (C:5.5896, R:0.0099, T:0.5793(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5872 (C:5.6018, R:0.0100, T:0.5862(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5878 (C:5.5884, R:0.0099, T:0.5868(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5710 (C:5.6258, R:0.0100, T:0.5700(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5866 (C:5.5587, R:0.0099, T:0.5856(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5876

ğŸ“Š EPOCH 44 TRAINING SUMMARY:
  Total Loss: 0.5886
  Contrastive: 5.5948
  Reconstruction: 0.0100
  Topological: 0.5876 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.9162
  Contrastive: 4.3112
  Reconstruction: 0.0099
  Topological: 5.9153 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 44/300 COMPLETE (44.2s)
Train Loss: 0.5886 (C:5.5948, R:0.0100, T:0.5876)
Val Loss:   5.9162 (C:4.3112, R:0.0099, T:5.9153)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 45 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6239 (C:5.6263, R:0.0100, T:0.6229(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5844 (C:5.5693, R:0.0100, T:0.5834(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5601 (C:5.5643, R:0.0100, T:0.5592(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6035 (C:5.5716, R:0.0099, T:0.6025(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6002 (C:5.5747, R:0.0099, T:0.5992(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5834 (C:5.6192, R:0.0099, T:0.5824(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5938 (C:5.6043, R:0.0099, T:0.5928(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5758 (C:5.6059, R:0.0100, T:0.5748(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5598 (C:5.6023, R:0.0100, T:0.5588(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5741 (C:5.6386, R:0.0100, T:0.5731(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5924 (C:5.5438, R:0.0099, T:0.5914(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5666 (C:5.6104, R:0.0100, T:0.5656(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5926 (C:5.6080, R:0.0099, T:0.5916(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6137 (C:5.6395, R:0.0099, T:0.6127(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5810 (C:5.5902, R:0.0099, T:0.5800(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5521 (C:5.6390, R:0.0100, T:0.5511(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5860 (C:5.5536, R:0.0100, T:0.5850(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5857 (C:5.5985, R:0.0099, T:0.5847(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5553 (C:5.6258, R:0.0099, T:0.5543(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5983 (C:5.5848, R:0.0100, T:0.5973(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5716 (C:5.5797, R:0.0099, T:0.5706(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5805 (C:5.6045, R:0.0099, T:0.5795(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 45 TRAINING SUMMARY:
  Total Loss: 0.5894
  Contrastive: 5.5955
  Reconstruction: 0.0100
  Topological: 0.5884 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.8135
  Contrastive: 4.3330
  Reconstruction: 0.0099
  Topological: 5.8125 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 45/300 COMPLETE (44.9s)
Train Loss: 0.5894 (C:5.5955, R:0.0100, T:0.5884)
Val Loss:   5.8135 (C:4.3330, R:0.0099, T:5.8125)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 46 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5846 (C:5.6042, R:0.0100, T:0.5836(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5665 (C:5.6009, R:0.0099, T:0.5655(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5733 (C:5.6157, R:0.0099, T:0.5723(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6014 (C:5.6082, R:0.0099, T:0.6004(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5878 (C:5.5868, R:0.0100, T:0.5868(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5532 (C:5.5798, R:0.0100, T:0.5522(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5815 (C:5.6000, R:0.0099, T:0.5805(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6166 (C:5.6218, R:0.0099, T:0.6157(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5801 (C:5.5931, R:0.0099, T:0.5791(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5635 (C:5.5881, R:0.0099, T:0.5626(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5946 (C:5.5813, R:0.0099, T:0.5937(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6162 (C:5.5674, R:0.0099, T:0.6152(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6068 (C:5.6265, R:0.0099, T:0.6058(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5829 (C:5.5605, R:0.0099, T:0.5819(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5607 (C:5.6260, R:0.0100, T:0.5597(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5761 (C:5.5830, R:0.0099, T:0.5751(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5997 (C:5.5901, R:0.0100, T:0.5987(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6037 (C:5.5422, R:0.0100, T:0.6027(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5643 (C:5.5472, R:0.0099, T:0.5633(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5862 (C:5.5825, R:0.0099, T:0.5853(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5863 (C:5.6000, R:0.0099, T:0.5853(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5940 (C:5.5941, R:0.0100, T:0.5931(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5867

ğŸ“Š EPOCH 46 TRAINING SUMMARY:
  Total Loss: 0.5877
  Contrastive: 5.5952
  Reconstruction: 0.0100
  Topological: 0.5867 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.7467
  Contrastive: 4.3417
  Reconstruction: 0.0099
  Topological: 5.7457 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 46/300 COMPLETE (45.9s)
Train Loss: 0.5877 (C:5.5952, R:0.0100, T:0.5867)
Val Loss:   5.7467 (C:4.3417, R:0.0099, T:5.7457)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 47 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5634 (C:5.6008, R:0.0099, T:0.5624(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5659 (C:5.5943, R:0.0100, T:0.5649(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5537 (C:5.6034, R:0.0099, T:0.5527(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5624 (C:5.5686, R:0.0099, T:0.5614(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5889 (C:5.5777, R:0.0099, T:0.5879(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5700 (C:5.5530, R:0.0100, T:0.5690(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5579 (C:5.6493, R:0.0100, T:0.5569(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6024 (C:5.5621, R:0.0100, T:0.6014(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5757 (C:5.5706, R:0.0100, T:0.5748(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5838 (C:5.6323, R:0.0099, T:0.5828(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5800 (C:5.5967, R:0.0100, T:0.5790(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6010 (C:5.6128, R:0.0100, T:0.6000(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5992 (C:5.6117, R:0.0100, T:0.5982(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6193 (C:5.5815, R:0.0099, T:0.6183(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6068 (C:5.5868, R:0.0099, T:0.6058(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5981 (C:5.6016, R:0.0099, T:0.5971(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5568 (C:5.5862, R:0.0100, T:0.5558(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5895 (C:5.5873, R:0.0100, T:0.5885(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5978 (C:5.6134, R:0.0099, T:0.5968(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6005 (C:5.5858, R:0.0099, T:0.5995(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5836 (C:5.6034, R:0.0100, T:0.5826(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6084 (C:5.5718, R:0.0099, T:0.6074(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 47 TRAINING SUMMARY:
  Total Loss: 0.5879
  Contrastive: 5.5920
  Reconstruction: 0.0100
  Topological: 0.5869 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.5746
  Contrastive: 4.3610
  Reconstruction: 0.0099
  Topological: 5.5736 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 47/300 COMPLETE (46.7s)
Train Loss: 0.5879 (C:5.5920, R:0.0100, T:0.5869)
Val Loss:   5.5746 (C:4.3610, R:0.0099, T:5.5736)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 48 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5802 (C:5.6298, R:0.0100, T:0.5792(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6089 (C:5.5818, R:0.0100, T:0.6079(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5950 (C:5.5590, R:0.0100, T:0.5940(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6143 (C:5.6433, R:0.0100, T:0.6133(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5601 (C:5.5699, R:0.0100, T:0.5591(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5876 (C:5.5720, R:0.0099, T:0.5866(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5792 (C:5.5693, R:0.0099, T:0.5782(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5962 (C:5.6315, R:0.0100, T:0.5952(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6178 (C:5.5875, R:0.0100, T:0.6168(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5800 (C:5.6232, R:0.0100, T:0.5790(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5789 (C:5.6018, R:0.0100, T:0.5779(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5942 (C:5.5531, R:0.0099, T:0.5932(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6024 (C:5.6194, R:0.0100, T:0.6015(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5657 (C:5.6218, R:0.0100, T:0.5647(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5765 (C:5.5724, R:0.0100, T:0.5755(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5642 (C:5.5700, R:0.0099, T:0.5632(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5840 (C:5.6321, R:0.0099, T:0.5830(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6145 (C:5.5745, R:0.0100, T:0.6135(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5872 (C:5.5661, R:0.0099, T:0.5862(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6055 (C:5.5821, R:0.0099, T:0.6045(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6190 (C:5.5849, R:0.0100, T:0.6180(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5895 (C:5.6065, R:0.0099, T:0.5885(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 48 TRAINING SUMMARY:
  Total Loss: 0.5880
  Contrastive: 5.5908
  Reconstruction: 0.0100
  Topological: 0.5870 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.7087
  Contrastive: 4.3559
  Reconstruction: 0.0099
  Topological: 5.7077 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 48/300 COMPLETE (46.1s)
Train Loss: 0.5880 (C:5.5908, R:0.0100, T:0.5870)
Val Loss:   5.7087 (C:4.3559, R:0.0099, T:5.7077)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 49 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5650 (C:5.6129, R:0.0100, T:0.5640(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5755 (C:5.5940, R:0.0100, T:0.5746(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6195 (C:5.6221, R:0.0099, T:0.6185(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5889 (C:5.6141, R:0.0099, T:0.5879(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5852 (C:5.5902, R:0.0099, T:0.5842(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6106 (C:5.6324, R:0.0099, T:0.6096(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6050 (C:5.5739, R:0.0099, T:0.6040(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6132 (C:5.5985, R:0.0099, T:0.6122(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5757 (C:5.5751, R:0.0100, T:0.5747(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5846 (C:5.6257, R:0.0100, T:0.5836(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5811 (C:5.5326, R:0.0099, T:0.5801(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5840 (C:5.6555, R:0.0100, T:0.5830(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5895 (C:5.5610, R:0.0099, T:0.5885(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5666 (C:5.6095, R:0.0099, T:0.5656(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5873 (C:5.6124, R:0.0099, T:0.5863(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5852 (C:5.5549, R:0.0100, T:0.5842(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5884 (C:5.5802, R:0.0099, T:0.5874(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5701 (C:5.6185, R:0.0100, T:0.5691(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5671 (C:5.5811, R:0.0100, T:0.5661(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6065 (C:5.5859, R:0.0099, T:0.6055(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5928 (C:5.5674, R:0.0099, T:0.5918(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5495 (C:5.5890, R:0.0100, T:0.5485(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 49 TRAINING SUMMARY:
  Total Loss: 0.5896
  Contrastive: 5.5893
  Reconstruction: 0.0100
  Topological: 0.5886 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.6490
  Contrastive: 4.3421
  Reconstruction: 0.0099
  Topological: 5.6480 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 49/300 COMPLETE (45.7s)
Train Loss: 0.5896 (C:5.5893, R:0.0100, T:0.5886)
Val Loss:   5.6490 (C:4.3421, R:0.0099, T:5.6480)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 50 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5677 (C:5.5675, R:0.0099, T:0.5667(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5959 (C:5.5787, R:0.0099, T:0.5949(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5946 (C:5.6166, R:0.0100, T:0.5936(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5929 (C:5.5509, R:0.0099, T:0.5919(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6029 (C:5.5708, R:0.0099, T:0.6019(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5933 (C:5.5934, R:0.0100, T:0.5923(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5870 (C:5.6043, R:0.0099, T:0.5860(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5822 (C:5.6284, R:0.0100, T:0.5812(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5925 (C:5.6191, R:0.0100, T:0.5915(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6036 (C:5.6115, R:0.0099, T:0.6026(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5944 (C:5.6127, R:0.0099, T:0.5934(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5893 (C:5.6058, R:0.0100, T:0.5883(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5762 (C:5.5902, R:0.0100, T:0.5752(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6104 (C:5.6116, R:0.0100, T:0.6094(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6225 (C:5.6317, R:0.0100, T:0.6215(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6184 (C:5.6245, R:0.0100, T:0.6174(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5896 (C:5.6013, R:0.0100, T:0.5886(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6303 (C:5.5682, R:0.0100, T:0.6293(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5970 (C:5.5568, R:0.0099, T:0.5960(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6124 (C:5.5383, R:0.0100, T:0.6114(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6098 (C:5.6313, R:0.0100, T:0.6088(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5872 (C:5.6002, R:0.0100, T:0.5862(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 50 TRAINING SUMMARY:
  Total Loss: 0.5885
  Contrastive: 5.5891
  Reconstruction: 0.0100
  Topological: 0.5875 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.4952
  Contrastive: 4.3768
  Reconstruction: 0.0099
  Topological: 5.4942 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 50/300 COMPLETE (45.6s)
Train Loss: 0.5885 (C:5.5891, R:0.0100, T:0.5875)
Val Loss:   5.4952 (C:4.3768, R:0.0099, T:5.4942)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 51 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5912 (C:5.6283, R:0.0100, T:0.5903(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6027 (C:5.5680, R:0.0099, T:0.6017(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5857 (C:5.6008, R:0.0100, T:0.5847(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5933 (C:5.6156, R:0.0100, T:0.5923(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6068 (C:5.5554, R:0.0099, T:0.6058(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6188 (C:5.6532, R:0.0099, T:0.6178(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5893 (C:5.6084, R:0.0100, T:0.5883(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5758 (C:5.5551, R:0.0099, T:0.5748(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5641 (C:5.6472, R:0.0100, T:0.5631(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5645 (C:5.5534, R:0.0099, T:0.5635(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5750 (C:5.5847, R:0.0099, T:0.5740(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5806 (C:5.5490, R:0.0099, T:0.5796(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5832 (C:5.5849, R:0.0099, T:0.5822(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5810 (C:5.6143, R:0.0100, T:0.5800(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5826 (C:5.5962, R:0.0100, T:0.5816(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6202 (C:5.6016, R:0.0099, T:0.6192(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5875 (C:5.5709, R:0.0099, T:0.5865(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6256 (C:5.6059, R:0.0100, T:0.6246(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5792 (C:5.5485, R:0.0099, T:0.5782(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5879 (C:5.6083, R:0.0099, T:0.5870(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5907 (C:5.5820, R:0.0099, T:0.5897(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5844 (C:5.6150, R:0.0099, T:0.5834(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 51 TRAINING SUMMARY:
  Total Loss: 0.5887
  Contrastive: 5.5891
  Reconstruction: 0.0100
  Topological: 0.5877 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.7611
  Contrastive: 4.3303
  Reconstruction: 0.0099
  Topological: 5.7601 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 51/300 COMPLETE (44.8s)
Train Loss: 0.5887 (C:5.5891, R:0.0100, T:0.5877)
Val Loss:   5.7611 (C:4.3303, R:0.0099, T:5.7601)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 52 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5764 (C:5.5506, R:0.0100, T:0.5755(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5895 (C:5.6004, R:0.0099, T:0.5885(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5858 (C:5.5714, R:0.0099, T:0.5848(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5698 (C:5.6349, R:0.0099, T:0.5688(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5717 (C:5.5743, R:0.0099, T:0.5707(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5882 (C:5.6211, R:0.0099, T:0.5873(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5769 (C:5.6041, R:0.0100, T:0.5759(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5995 (C:5.5661, R:0.0099, T:0.5985(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6006 (C:5.6337, R:0.0099, T:0.5997(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5820 (C:5.6225, R:0.0099, T:0.5810(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6062 (C:5.6230, R:0.0100, T:0.6052(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5779 (C:5.6032, R:0.0099, T:0.5769(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5823 (C:5.5785, R:0.0099, T:0.5813(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6153 (C:5.6024, R:0.0099, T:0.6143(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5917 (C:5.6298, R:0.0100, T:0.5907(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5843 (C:5.5794, R:0.0099, T:0.5833(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5769 (C:5.5825, R:0.0100, T:0.5759(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5801 (C:5.6070, R:0.0100, T:0.5791(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5516 (C:5.6083, R:0.0100, T:0.5506(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5933 (C:5.6242, R:0.0100, T:0.5923(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5854 (C:5.6116, R:0.0100, T:0.5844(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5928 (C:5.6072, R:0.0099, T:0.5918(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 52 TRAINING SUMMARY:
  Total Loss: 0.5883
  Contrastive: 5.5904
  Reconstruction: 0.0100
  Topological: 0.5873 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.5783
  Contrastive: 4.3695
  Reconstruction: 0.0099
  Topological: 5.5773 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 52/300 COMPLETE (44.8s)
Train Loss: 0.5883 (C:5.5904, R:0.0100, T:0.5873)
Val Loss:   5.5783 (C:4.3695, R:0.0099, T:5.5773)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 53 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5917 (C:5.5969, R:0.0100, T:0.5907(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6083 (C:5.5507, R:0.0099, T:0.6073(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5942 (C:5.6110, R:0.0099, T:0.5933(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5724 (C:5.6007, R:0.0099, T:0.5714(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5822 (C:5.5785, R:0.0099, T:0.5812(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5569 (C:5.5476, R:0.0099, T:0.5559(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5729 (C:5.5811, R:0.0100, T:0.5719(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5614 (C:5.5834, R:0.0100, T:0.5604(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5662 (C:5.5811, R:0.0099, T:0.5652(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5658 (C:5.6115, R:0.0100, T:0.5648(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5301 (C:5.5824, R:0.0100, T:0.5291(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6092 (C:5.5894, R:0.0100, T:0.6082(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5925 (C:5.5963, R:0.0100, T:0.5915(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5799 (C:5.5713, R:0.0099, T:0.5789(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5614 (C:5.6252, R:0.0100, T:0.5604(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5888 (C:5.5728, R:0.0100, T:0.5878(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6028 (C:5.5930, R:0.0099, T:0.6018(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6317 (C:5.5814, R:0.0099, T:0.6308(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6086 (C:5.5438, R:0.0100, T:0.6076(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5956 (C:5.5967, R:0.0099, T:0.5946(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6047 (C:5.6251, R:0.0100, T:0.6037(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5722 (C:5.5762, R:0.0100, T:0.5712(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5864

ğŸ“Š EPOCH 53 TRAINING SUMMARY:
  Total Loss: 0.5874
  Contrastive: 5.5913
  Reconstruction: 0.0100
  Topological: 0.5864 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.5612
  Contrastive: 4.3405
  Reconstruction: 0.0099
  Topological: 5.5602 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 53/300 COMPLETE (44.9s)
Train Loss: 0.5874 (C:5.5913, R:0.0100, T:0.5864)
Val Loss:   5.5612 (C:4.3405, R:0.0099, T:5.5602)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 54 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5891 (C:5.5517, R:0.0099, T:0.5881(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6049 (C:5.6263, R:0.0100, T:0.6039(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5814 (C:5.5661, R:0.0099, T:0.5804(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5960 (C:5.5930, R:0.0099, T:0.5950(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6141 (C:5.5951, R:0.0100, T:0.6131(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5210 (C:5.5782, R:0.0100, T:0.5200(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5775 (C:5.6035, R:0.0100, T:0.5765(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5856 (C:5.5735, R:0.0100, T:0.5846(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6022 (C:5.6156, R:0.0100, T:0.6012(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5891 (C:5.6109, R:0.0099, T:0.5881(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5773 (C:5.5568, R:0.0100, T:0.5763(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5681 (C:5.5937, R:0.0100, T:0.5671(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5703 (C:5.5881, R:0.0100, T:0.5693(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5845 (C:5.5768, R:0.0100, T:0.5835(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5971 (C:5.5955, R:0.0100, T:0.5961(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6081 (C:5.6017, R:0.0099, T:0.6071(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6011 (C:5.5821, R:0.0099, T:0.6002(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6049 (C:5.5952, R:0.0100, T:0.6039(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5975 (C:5.5869, R:0.0099, T:0.5966(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5617 (C:5.5938, R:0.0100, T:0.5607(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5826 (C:5.5862, R:0.0099, T:0.5816(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5842 (C:5.5846, R:0.0100, T:0.5832(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5860

ğŸ“Š EPOCH 54 TRAINING SUMMARY:
  Total Loss: 0.5870
  Contrastive: 5.5883
  Reconstruction: 0.0100
  Topological: 0.5860 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.5836
  Contrastive: 4.3437
  Reconstruction: 0.0099
  Topological: 5.5827 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 54/300 COMPLETE (44.7s)
Train Loss: 0.5870 (C:5.5883, R:0.0100, T:0.5860)
Val Loss:   5.5836 (C:4.3437, R:0.0099, T:5.5827)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 55 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5590 (C:5.5801, R:0.0100, T:0.5580(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5847 (C:5.5890, R:0.0099, T:0.5837(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5815 (C:5.5914, R:0.0099, T:0.5805(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5827 (C:5.5659, R:0.0099, T:0.5817(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6100 (C:5.6468, R:0.0100, T:0.6090(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5972 (C:5.6252, R:0.0100, T:0.5962(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5895 (C:5.6080, R:0.0100, T:0.5885(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6117 (C:5.5668, R:0.0099, T:0.6107(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6007 (C:5.6079, R:0.0100, T:0.5997(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5705 (C:5.5551, R:0.0100, T:0.5695(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5752 (C:5.6524, R:0.0099, T:0.5742(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6140 (C:5.5891, R:0.0100, T:0.6130(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5699 (C:5.6194, R:0.0099, T:0.5689(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5648 (C:5.5741, R:0.0100, T:0.5638(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5658 (C:5.6009, R:0.0099, T:0.5648(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5562 (C:5.5962, R:0.0099, T:0.5552(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5926 (C:5.5680, R:0.0099, T:0.5916(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5814 (C:5.5896, R:0.0099, T:0.5804(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5962 (C:5.6041, R:0.0100, T:0.5952(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6104 (C:5.5643, R:0.0099, T:0.6094(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5521 (C:5.5878, R:0.0099, T:0.5511(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5967 (C:5.6222, R:0.0099, T:0.5957(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 55 TRAINING SUMMARY:
  Total Loss: 0.5873
  Contrastive: 5.5880
  Reconstruction: 0.0100
  Topological: 0.5864 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.3686
  Contrastive: 4.3947
  Reconstruction: 0.0099
  Topological: 5.3676 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 55/300 COMPLETE (45.4s)
Train Loss: 0.5873 (C:5.5880, R:0.0100, T:0.5864)
Val Loss:   5.3686 (C:4.3947, R:0.0099, T:5.3676)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 56 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5789 (C:5.5847, R:0.0099, T:0.5779(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5878 (C:5.5290, R:0.0099, T:0.5868(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6253 (C:5.6296, R:0.0100, T:0.6243(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5809 (C:5.5458, R:0.0100, T:0.5799(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5650 (C:5.5516, R:0.0100, T:0.5641(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5832 (C:5.5719, R:0.0099, T:0.5822(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5714 (C:5.5801, R:0.0100, T:0.5704(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6105 (C:5.5663, R:0.0099, T:0.6095(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5744 (C:5.5889, R:0.0099, T:0.5735(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5906 (C:5.5684, R:0.0100, T:0.5896(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5623 (C:5.6141, R:0.0100, T:0.5613(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5932 (C:5.5694, R:0.0099, T:0.5922(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6085 (C:5.6060, R:0.0100, T:0.6075(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5892 (C:5.6035, R:0.0100, T:0.5882(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6038 (C:5.5740, R:0.0099, T:0.6028(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5977 (C:5.5790, R:0.0100, T:0.5967(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5862 (C:5.5630, R:0.0099, T:0.5853(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5959 (C:5.6232, R:0.0100, T:0.5949(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5744 (C:5.5880, R:0.0100, T:0.5734(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5971 (C:5.5888, R:0.0099, T:0.5962(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5671 (C:5.5877, R:0.0099, T:0.5661(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5793 (C:5.6203, R:0.0100, T:0.5783(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 56 TRAINING SUMMARY:
  Total Loss: 0.5903
  Contrastive: 5.5885
  Reconstruction: 0.0100
  Topological: 0.5893 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.5469
  Contrastive: 4.3576
  Reconstruction: 0.0099
  Topological: 5.5459 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 56/300 COMPLETE (44.9s)
Train Loss: 0.5903 (C:5.5885, R:0.0100, T:0.5893)
Val Loss:   5.5469 (C:4.3576, R:0.0099, T:5.5459)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 57 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5839 (C:5.5888, R:0.0099, T:0.5830(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5623 (C:5.5566, R:0.0099, T:0.5613(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5995 (C:5.6380, R:0.0100, T:0.5985(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5510 (C:5.6550, R:0.0100, T:0.5500(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5739 (C:5.5906, R:0.0100, T:0.5729(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5451 (C:5.6295, R:0.0099, T:0.5441(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5861 (C:5.5956, R:0.0100, T:0.5851(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5638 (C:5.5562, R:0.0100, T:0.5628(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6020 (C:5.6039, R:0.0099, T:0.6010(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5573 (C:5.6241, R:0.0099, T:0.5563(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5712 (C:5.5270, R:0.0099, T:0.5702(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6078 (C:5.6437, R:0.0100, T:0.6068(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5675 (C:5.5579, R:0.0099, T:0.5665(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5727 (C:5.6226, R:0.0100, T:0.5717(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5984 (C:5.5862, R:0.0099, T:0.5974(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5633 (C:5.5754, R:0.0099, T:0.5623(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5987 (C:5.5809, R:0.0099, T:0.5977(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5635 (C:5.5715, R:0.0100, T:0.5625(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6114 (C:5.5449, R:0.0100, T:0.6104(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5540 (C:5.5761, R:0.0100, T:0.5530(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5926 (C:5.5952, R:0.0099, T:0.5916(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5900 (C:5.5822, R:0.0100, T:0.5890(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5854

ğŸ“Š EPOCH 57 TRAINING SUMMARY:
  Total Loss: 0.5864
  Contrastive: 5.5882
  Reconstruction: 0.0100
  Topological: 0.5854 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.4580
  Contrastive: 4.3591
  Reconstruction: 0.0099
  Topological: 5.4570 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 57/300 COMPLETE (45.1s)
Train Loss: 0.5864 (C:5.5882, R:0.0100, T:0.5854)
Val Loss:   5.4580 (C:4.3591, R:0.0099, T:5.4570)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 58 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5798 (C:5.5743, R:0.0099, T:0.5788(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6044 (C:5.5455, R:0.0100, T:0.6034(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5651 (C:5.5571, R:0.0100, T:0.5641(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6102 (C:5.5310, R:0.0100, T:0.6092(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6038 (C:5.6031, R:0.0099, T:0.6028(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5656 (C:5.6016, R:0.0100, T:0.5646(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5932 (C:5.6005, R:0.0100, T:0.5922(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5778 (C:5.5544, R:0.0100, T:0.5768(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5802 (C:5.5689, R:0.0100, T:0.5792(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5949 (C:5.5997, R:0.0099, T:0.5939(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6170 (C:5.5784, R:0.0100, T:0.6160(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6143 (C:5.6071, R:0.0100, T:0.6133(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5625 (C:5.5881, R:0.0099, T:0.5615(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6031 (C:5.5355, R:0.0099, T:0.6021(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6124 (C:5.6048, R:0.0100, T:0.6114(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6035 (C:5.5622, R:0.0100, T:0.6025(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5764 (C:5.5855, R:0.0099, T:0.5754(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5808 (C:5.5635, R:0.0099, T:0.5798(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5708 (C:5.6036, R:0.0100, T:0.5698(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5500 (C:5.5944, R:0.0100, T:0.5490(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5535 (C:5.5743, R:0.0100, T:0.5525(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5849 (C:5.6144, R:0.0099, T:0.5839(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 58 TRAINING SUMMARY:
  Total Loss: 0.5872
  Contrastive: 5.5888
  Reconstruction: 0.0100
  Topological: 0.5862 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.4067
  Contrastive: 4.3821
  Reconstruction: 0.0099
  Topological: 5.4057 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 58/300 COMPLETE (44.9s)
Train Loss: 0.5872 (C:5.5888, R:0.0100, T:0.5862)
Val Loss:   5.4067 (C:4.3821, R:0.0099, T:5.4057)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 59 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5882 (C:5.5949, R:0.0099, T:0.5872(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6130 (C:5.6305, R:0.0100, T:0.6120(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5938 (C:5.5212, R:0.0100, T:0.5928(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5600 (C:5.5718, R:0.0100, T:0.5590(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5905 (C:5.6014, R:0.0099, T:0.5895(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6220 (C:5.5918, R:0.0099, T:0.6210(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5872 (C:5.6136, R:0.0100, T:0.5862(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5741 (C:5.5848, R:0.0099, T:0.5731(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6091 (C:5.6020, R:0.0100, T:0.6081(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5860 (C:5.5545, R:0.0099, T:0.5850(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5959 (C:5.5958, R:0.0100, T:0.5949(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5915 (C:5.5770, R:0.0099, T:0.5905(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5971 (C:5.6388, R:0.0099, T:0.5961(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6072 (C:5.5420, R:0.0099, T:0.6062(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6366 (C:5.5488, R:0.0100, T:0.6356(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6063 (C:5.5818, R:0.0100, T:0.6053(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5827 (C:5.5707, R:0.0099, T:0.5817(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6003 (C:5.6113, R:0.0100, T:0.5993(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5716 (C:5.5625, R:0.0100, T:0.5706(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5667 (C:5.5939, R:0.0099, T:0.5657(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5764 (C:5.5671, R:0.0099, T:0.5754(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5727 (C:5.6016, R:0.0100, T:0.5717(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5851

ğŸ“Š EPOCH 59 TRAINING SUMMARY:
  Total Loss: 0.5861
  Contrastive: 5.5861
  Reconstruction: 0.0100
  Topological: 0.5851 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.3396
  Contrastive: 4.3965
  Reconstruction: 0.0099
  Topological: 5.3387 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 59/300 COMPLETE (45.6s)
Train Loss: 0.5861 (C:5.5861, R:0.0100, T:0.5851)
Val Loss:   5.3396 (C:4.3965, R:0.0099, T:5.3387)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 60 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6096 (C:5.6112, R:0.0100, T:0.6086(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5775 (C:5.5687, R:0.0099, T:0.5765(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5780 (C:5.5516, R:0.0100, T:0.5770(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6145 (C:5.6027, R:0.0100, T:0.6135(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5848 (C:5.5698, R:0.0100, T:0.5838(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5939 (C:5.6200, R:0.0100, T:0.5929(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6081 (C:5.6252, R:0.0100, T:0.6071(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6021 (C:5.5824, R:0.0100, T:0.6011(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5815 (C:5.5646, R:0.0100, T:0.5805(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5917 (C:5.5891, R:0.0100, T:0.5907(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5705 (C:5.5734, R:0.0100, T:0.5695(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5910 (C:5.5862, R:0.0100, T:0.5900(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5857 (C:5.5523, R:0.0100, T:0.5847(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6202 (C:5.5952, R:0.0099, T:0.6192(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5669 (C:5.5581, R:0.0100, T:0.5659(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5906 (C:5.6000, R:0.0100, T:0.5896(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5440 (C:5.5596, R:0.0099, T:0.5430(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5864 (C:5.6007, R:0.0099, T:0.5854(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5864 (C:5.5620, R:0.0099, T:0.5854(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5809 (C:5.6219, R:0.0100, T:0.5799(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5908 (C:5.6175, R:0.0100, T:0.5898(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6043 (C:5.5644, R:0.0100, T:0.6033(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 60 TRAINING SUMMARY:
  Total Loss: 0.5870
  Contrastive: 5.5856
  Reconstruction: 0.0100
  Topological: 0.5860 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.3720
  Contrastive: 4.3944
  Reconstruction: 0.0099
  Topological: 5.3710 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 60/300 COMPLETE (45.6s)
Train Loss: 0.5870 (C:5.5856, R:0.0100, T:0.5860)
Val Loss:   5.3720 (C:4.3944, R:0.0099, T:5.3710)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 61 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5684 (C:5.6124, R:0.0099, T:0.5674(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5885 (C:5.5667, R:0.0100, T:0.5875(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5976 (C:5.5621, R:0.0099, T:0.5966(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5839 (C:5.5695, R:0.0100, T:0.5829(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6105 (C:5.6474, R:0.0100, T:0.6095(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5685 (C:5.5576, R:0.0099, T:0.5675(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6192 (C:5.6217, R:0.0100, T:0.6182(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5869 (C:5.5571, R:0.0100, T:0.5859(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5578 (C:5.5873, R:0.0099, T:0.5568(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6025 (C:5.6375, R:0.0099, T:0.6015(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5726 (C:5.6150, R:0.0099, T:0.5716(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5745 (C:5.5737, R:0.0099, T:0.5735(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6008 (C:5.6061, R:0.0099, T:0.5998(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5451 (C:5.5839, R:0.0099, T:0.5441(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5502 (C:5.6197, R:0.0100, T:0.5492(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6077 (C:5.5896, R:0.0100, T:0.6067(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5827 (C:5.5791, R:0.0099, T:0.5817(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5992 (C:5.6082, R:0.0099, T:0.5982(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5747 (C:5.6093, R:0.0100, T:0.5737(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5811 (C:5.5521, R:0.0099, T:0.5801(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5658 (C:5.5638, R:0.0100, T:0.5648(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5718 (C:5.5790, R:0.0100, T:0.5708(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5839

ğŸ“Š EPOCH 61 TRAINING SUMMARY:
  Total Loss: 0.5849
  Contrastive: 5.5881
  Reconstruction: 0.0100
  Topological: 0.5839 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.2381
  Contrastive: 4.4050
  Reconstruction: 0.0099
  Topological: 5.2371 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 61/300 COMPLETE (45.3s)
Train Loss: 0.5849 (C:5.5881, R:0.0100, T:0.5839)
Val Loss:   5.2381 (C:4.4050, R:0.0099, T:5.2371)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 62 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5739 (C:5.6210, R:0.0100, T:0.5729(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6121 (C:5.5311, R:0.0100, T:0.6111(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5797 (C:5.5774, R:0.0100, T:0.5787(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5707 (C:5.5658, R:0.0099, T:0.5697(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5919 (C:5.5841, R:0.0100, T:0.5909(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5752 (C:5.5769, R:0.0100, T:0.5742(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6018 (C:5.6032, R:0.0100, T:0.6008(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5903 (C:5.5863, R:0.0100, T:0.5893(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5811 (C:5.5360, R:0.0099, T:0.5801(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5806 (C:5.5763, R:0.0099, T:0.5796(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6095 (C:5.5061, R:0.0099, T:0.6085(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5463 (C:5.6254, R:0.0099, T:0.5453(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6108 (C:5.5407, R:0.0099, T:0.6098(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5826 (C:5.5768, R:0.0100, T:0.5816(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5749 (C:5.6131, R:0.0100, T:0.5739(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6057 (C:5.5840, R:0.0100, T:0.6047(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5975 (C:5.6043, R:0.0100, T:0.5965(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5574 (C:5.5546, R:0.0100, T:0.5564(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5867 (C:5.5798, R:0.0099, T:0.5857(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5708 (C:5.6439, R:0.0099, T:0.5698(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6355 (C:5.5820, R:0.0099, T:0.6346(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5649 (C:5.5545, R:0.0100, T:0.5639(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 62 TRAINING SUMMARY:
  Total Loss: 0.5863
  Contrastive: 5.5864
  Reconstruction: 0.0100
  Topological: 0.5853 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.3522
  Contrastive: 4.3666
  Reconstruction: 0.0099
  Topological: 5.3512 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 62/300 COMPLETE (45.3s)
Train Loss: 0.5863 (C:5.5864, R:0.0100, T:0.5853)
Val Loss:   5.3522 (C:4.3666, R:0.0099, T:5.3512)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 63 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5886 (C:5.5961, R:0.0099, T:0.5876(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5818 (C:5.5985, R:0.0099, T:0.5808(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5783 (C:5.5665, R:0.0099, T:0.5774(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5782 (C:5.6246, R:0.0100, T:0.5772(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5616 (C:5.6023, R:0.0100, T:0.5606(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6089 (C:5.5802, R:0.0100, T:0.6079(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5764 (C:5.5933, R:0.0100, T:0.5754(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5848 (C:5.5924, R:0.0099, T:0.5838(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5778 (C:5.5815, R:0.0100, T:0.5768(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5715 (C:5.6151, R:0.0099, T:0.5705(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5846 (C:5.4941, R:0.0100, T:0.5836(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5761 (C:5.5988, R:0.0100, T:0.5751(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5774 (C:5.5731, R:0.0099, T:0.5764(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5852 (C:5.6048, R:0.0099, T:0.5843(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6153 (C:5.5904, R:0.0100, T:0.6143(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5834 (C:5.5853, R:0.0100, T:0.5824(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5895 (C:5.5342, R:0.0100, T:0.5885(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5876 (C:5.6168, R:0.0099, T:0.5866(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5924 (C:5.6013, R:0.0100, T:0.5914(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5698 (C:5.5817, R:0.0100, T:0.5688(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5714 (C:5.6042, R:0.0100, T:0.5704(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5713 (C:5.5814, R:0.0100, T:0.5703(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 63 TRAINING SUMMARY:
  Total Loss: 0.5863
  Contrastive: 5.5872
  Reconstruction: 0.0100
  Topological: 0.5853 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.4324
  Contrastive: 4.3940
  Reconstruction: 0.0099
  Topological: 5.4314 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 63/300 COMPLETE (45.3s)
Train Loss: 0.5863 (C:5.5872, R:0.0100, T:0.5853)
Val Loss:   5.4324 (C:4.3940, R:0.0099, T:5.4314)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 64 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5854 (C:5.6062, R:0.0099, T:0.5844(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5930 (C:5.6164, R:0.0099, T:0.5920(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5598 (C:5.5438, R:0.0099, T:0.5588(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6168 (C:5.5764, R:0.0099, T:0.6158(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5742 (C:5.5921, R:0.0100, T:0.5733(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5697 (C:5.6182, R:0.0100, T:0.5687(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5911 (C:5.5293, R:0.0099, T:0.5901(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6147 (C:5.6172, R:0.0100, T:0.6137(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5479 (C:5.5915, R:0.0100, T:0.5469(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5956 (C:5.5781, R:0.0100, T:0.5946(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5966 (C:5.5843, R:0.0100, T:0.5956(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5326 (C:5.5916, R:0.0100, T:0.5316(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5618 (C:5.5664, R:0.0099, T:0.5609(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5883 (C:5.6413, R:0.0099, T:0.5873(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5772 (C:5.6096, R:0.0100, T:0.5762(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6111 (C:5.5669, R:0.0099, T:0.6101(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5923 (C:5.6172, R:0.0100, T:0.5914(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6010 (C:5.6011, R:0.0100, T:0.6000(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5706 (C:5.5493, R:0.0100, T:0.5696(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5819 (C:5.6203, R:0.0099, T:0.5809(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6155 (C:5.5705, R:0.0099, T:0.6146(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6419 (C:5.6051, R:0.0099, T:0.6409(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5818

ğŸ“Š EPOCH 64 TRAINING SUMMARY:
  Total Loss: 0.5828
  Contrastive: 5.5895
  Reconstruction: 0.0100
  Topological: 0.5818 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.3108
  Contrastive: 4.3905
  Reconstruction: 0.0099
  Topological: 5.3098 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 64/300 COMPLETE (45.5s)
Train Loss: 0.5828 (C:5.5895, R:0.0100, T:0.5818)
Val Loss:   5.3108 (C:4.3905, R:0.0099, T:5.3098)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 65 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5886 (C:5.6236, R:0.0100, T:0.5876(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6071 (C:5.6335, R:0.0100, T:0.6061(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6066 (C:5.6109, R:0.0100, T:0.6056(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6063 (C:5.5600, R:0.0099, T:0.6053(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5855 (C:5.5870, R:0.0100, T:0.5845(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5973 (C:5.6206, R:0.0100, T:0.5963(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5821 (C:5.5826, R:0.0099, T:0.5811(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5821 (C:5.6560, R:0.0100, T:0.5811(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5692 (C:5.5772, R:0.0099, T:0.5683(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5826 (C:5.6535, R:0.0100, T:0.5816(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5877 (C:5.5739, R:0.0100, T:0.5867(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5811 (C:5.5862, R:0.0100, T:0.5801(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6021 (C:5.5965, R:0.0100, T:0.6011(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5697 (C:5.6029, R:0.0100, T:0.5687(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5720 (C:5.5577, R:0.0099, T:0.5710(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5701 (C:5.6270, R:0.0100, T:0.5691(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5645 (C:5.5942, R:0.0099, T:0.5635(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6104 (C:5.5988, R:0.0099, T:0.6094(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5581 (C:5.5904, R:0.0100, T:0.5571(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6076 (C:5.6192, R:0.0100, T:0.6066(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5786 (C:5.5816, R:0.0100, T:0.5776(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6108 (C:5.5861, R:0.0100, T:0.6098(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 65 TRAINING SUMMARY:
  Total Loss: 0.5841
  Contrastive: 5.5877
  Reconstruction: 0.0100
  Topological: 0.5831 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.2751
  Contrastive: 4.3881
  Reconstruction: 0.0099
  Topological: 5.2741 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 65/300 COMPLETE (45.1s)
Train Loss: 0.5841 (C:5.5877, R:0.0100, T:0.5831)
Val Loss:   5.2751 (C:4.3881, R:0.0099, T:5.2741)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 66 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5754 (C:5.5886, R:0.0100, T:0.5744(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5864 (C:5.6158, R:0.0100, T:0.5854(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6115 (C:5.5782, R:0.0100, T:0.6105(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5703 (C:5.6096, R:0.0099, T:0.5693(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5894 (C:5.5779, R:0.0099, T:0.5884(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5637 (C:5.6156, R:0.0099, T:0.5627(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5802 (C:5.6219, R:0.0099, T:0.5792(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5706 (C:5.5773, R:0.0100, T:0.5696(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5808 (C:5.5882, R:0.0100, T:0.5798(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5932 (C:5.6219, R:0.0100, T:0.5922(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6263 (C:5.5955, R:0.0100, T:0.6253(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5457 (C:5.5709, R:0.0100, T:0.5447(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5780 (C:5.5990, R:0.0100, T:0.5770(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5821 (C:5.5994, R:0.0100, T:0.5811(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5875 (C:5.5559, R:0.0100, T:0.5865(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5869 (C:5.5962, R:0.0099, T:0.5859(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5657 (C:5.6106, R:0.0100, T:0.5647(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5872 (C:5.6250, R:0.0100, T:0.5862(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5895 (C:5.5458, R:0.0099, T:0.5885(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5763 (C:5.5908, R:0.0100, T:0.5753(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5599 (C:5.5997, R:0.0100, T:0.5589(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5977 (C:5.5545, R:0.0100, T:0.5967(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 66 TRAINING SUMMARY:
  Total Loss: 0.5836
  Contrastive: 5.5859
  Reconstruction: 0.0100
  Topological: 0.5826 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.4466
  Contrastive: 4.3700
  Reconstruction: 0.0099
  Topological: 5.4456 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 66/300 COMPLETE (45.3s)
Train Loss: 0.5836 (C:5.5859, R:0.0100, T:0.5826)
Val Loss:   5.4466 (C:4.3700, R:0.0099, T:5.4456)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 67 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5841 (C:5.5619, R:0.0100, T:0.5831(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5804 (C:5.5893, R:0.0099, T:0.5794(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5769 (C:5.6109, R:0.0100, T:0.5759(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5785 (C:5.6281, R:0.0100, T:0.5775(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5892 (C:5.5527, R:0.0099, T:0.5882(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5864 (C:5.5775, R:0.0099, T:0.5854(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5804 (C:5.5969, R:0.0099, T:0.5794(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5967 (C:5.6174, R:0.0100, T:0.5957(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5865 (C:5.6373, R:0.0100, T:0.5855(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5628 (C:5.5434, R:0.0099, T:0.5618(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5588 (C:5.6007, R:0.0100, T:0.5578(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5881 (C:5.6020, R:0.0099, T:0.5871(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5819 (C:5.5935, R:0.0100, T:0.5809(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5417 (C:5.5520, R:0.0099, T:0.5407(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5967 (C:5.6135, R:0.0100, T:0.5957(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5707 (C:5.5638, R:0.0099, T:0.5697(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6104 (C:5.6085, R:0.0100, T:0.6094(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6001 (C:5.6016, R:0.0100, T:0.5991(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5703 (C:5.6139, R:0.0100, T:0.5693(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5648 (C:5.5768, R:0.0100, T:0.5638(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5779 (C:5.5761, R:0.0100, T:0.5769(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5973 (C:5.5826, R:0.0100, T:0.5963(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5811

ğŸ“Š EPOCH 67 TRAINING SUMMARY:
  Total Loss: 0.5821
  Contrastive: 5.5862
  Reconstruction: 0.0100
  Topological: 0.5811 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.2834
  Contrastive: 4.3917
  Reconstruction: 0.0099
  Topological: 5.2824 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 67/300 COMPLETE (45.6s)
Train Loss: 0.5821 (C:5.5862, R:0.0100, T:0.5811)
Val Loss:   5.2834 (C:4.3917, R:0.0099, T:5.2824)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 68 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5635 (C:5.6073, R:0.0100, T:0.5625(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5731 (C:5.6087, R:0.0100, T:0.5721(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6057 (C:5.6060, R:0.0099, T:0.6047(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6047 (C:5.5590, R:0.0099, T:0.6037(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5653 (C:5.5882, R:0.0099, T:0.5643(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6089 (C:5.5461, R:0.0100, T:0.6079(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6057 (C:5.5910, R:0.0100, T:0.6047(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5968 (C:5.5578, R:0.0099, T:0.5958(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5956 (C:5.5730, R:0.0100, T:0.5946(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5874 (C:5.5771, R:0.0100, T:0.5864(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5752 (C:5.5593, R:0.0099, T:0.5742(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5772 (C:5.5270, R:0.0099, T:0.5762(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5592 (C:5.6039, R:0.0099, T:0.5582(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5889 (C:5.5844, R:0.0099, T:0.5879(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5900 (C:5.5771, R:0.0100, T:0.5890(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6129 (C:5.6218, R:0.0100, T:0.6119(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5992 (C:5.5488, R:0.0100, T:0.5982(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5470 (C:5.5637, R:0.0100, T:0.5460(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5818 (C:5.5824, R:0.0100, T:0.5808(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6004 (C:5.5804, R:0.0100, T:0.5994(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5883 (C:5.5819, R:0.0099, T:0.5873(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5894 (C:5.5819, R:0.0099, T:0.5884(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 68 TRAINING SUMMARY:
  Total Loss: 0.5835
  Contrastive: 5.5860
  Reconstruction: 0.0100
  Topological: 0.5826 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.3721
  Contrastive: 4.3591
  Reconstruction: 0.0099
  Topological: 5.3711 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 68/300 COMPLETE (45.4s)
Train Loss: 0.5835 (C:5.5860, R:0.0100, T:0.5826)
Val Loss:   5.3721 (C:4.3591, R:0.0099, T:5.3711)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 69 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5771 (C:5.5507, R:0.0100, T:0.5761(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5808 (C:5.6403, R:0.0100, T:0.5798(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5823 (C:5.5468, R:0.0099, T:0.5813(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6005 (C:5.5695, R:0.0099, T:0.5995(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5977 (C:5.5943, R:0.0100, T:0.5967(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5908 (C:5.5620, R:0.0100, T:0.5898(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6033 (C:5.6238, R:0.0099, T:0.6023(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5688 (C:5.5683, R:0.0099, T:0.5678(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6078 (C:5.5624, R:0.0099, T:0.6068(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5695 (C:5.5569, R:0.0099, T:0.5685(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6008 (C:5.6301, R:0.0100, T:0.5998(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5494 (C:5.6033, R:0.0100, T:0.5484(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5786 (C:5.5516, R:0.0100, T:0.5776(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5856 (C:5.6210, R:0.0100, T:0.5846(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5861 (C:5.5832, R:0.0099, T:0.5851(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5868 (C:5.6363, R:0.0099, T:0.5858(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5874 (C:5.6114, R:0.0100, T:0.5864(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6063 (C:5.5881, R:0.0099, T:0.6053(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6026 (C:5.5641, R:0.0100, T:0.6016(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5838 (C:5.5692, R:0.0099, T:0.5828(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5752 (C:5.5800, R:0.0100, T:0.5742(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6120 (C:5.5828, R:0.0100, T:0.6110(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 69 TRAINING SUMMARY:
  Total Loss: 0.5847
  Contrastive: 5.5852
  Reconstruction: 0.0100
  Topological: 0.5837 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.2567
  Contrastive: 4.3998
  Reconstruction: 0.0099
  Topological: 5.2557 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 69/300 COMPLETE (45.6s)
Train Loss: 0.5847 (C:5.5852, R:0.0100, T:0.5837)
Val Loss:   5.2567 (C:4.3998, R:0.0099, T:5.2557)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 70 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5620 (C:5.5856, R:0.0100, T:0.5611(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5573 (C:5.5817, R:0.0100, T:0.5563(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5995 (C:5.6041, R:0.0100, T:0.5985(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5481 (C:5.5913, R:0.0100, T:0.5471(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5859 (C:5.6167, R:0.0099, T:0.5849(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6212 (C:5.6054, R:0.0100, T:0.6202(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6047 (C:5.5811, R:0.0100, T:0.6037(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5958 (C:5.5715, R:0.0099, T:0.5948(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6119 (C:5.5789, R:0.0100, T:0.6109(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5646 (C:5.5527, R:0.0099, T:0.5636(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5516 (C:5.6139, R:0.0100, T:0.5506(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5813 (C:5.5603, R:0.0100, T:0.5803(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5869 (C:5.5962, R:0.0100, T:0.5859(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5642 (C:5.5602, R:0.0100, T:0.5632(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5826 (C:5.5665, R:0.0100, T:0.5816(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5747 (C:5.5765, R:0.0099, T:0.5737(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5846 (C:5.6383, R:0.0100, T:0.5836(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5739 (C:5.5923, R:0.0100, T:0.5729(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5905 (C:5.5795, R:0.0099, T:0.5895(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5828 (C:5.5835, R:0.0099, T:0.5818(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6026 (C:5.5997, R:0.0100, T:0.6016(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5666 (C:5.5903, R:0.0099, T:0.5656(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 70 TRAINING SUMMARY:
  Total Loss: 0.5834
  Contrastive: 5.5862
  Reconstruction: 0.0100
  Topological: 0.5824 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.2186
  Contrastive: 4.3993
  Reconstruction: 0.0099
  Topological: 5.2176 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 70/300 COMPLETE (45.7s)
Train Loss: 0.5834 (C:5.5862, R:0.0100, T:0.5824)
Val Loss:   5.2186 (C:4.3993, R:0.0099, T:5.2176)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 71 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5781 (C:5.5715, R:0.0100, T:0.5771(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5856 (C:5.6327, R:0.0100, T:0.5846(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5971 (C:5.5847, R:0.0100, T:0.5961(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5990 (C:5.5598, R:0.0099, T:0.5980(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6004 (C:5.5402, R:0.0100, T:0.5994(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5737 (C:5.6122, R:0.0100, T:0.5727(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5684 (C:5.6068, R:0.0099, T:0.5674(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5830 (C:5.6031, R:0.0100, T:0.5820(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5903 (C:5.6077, R:0.0099, T:0.5893(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5885 (C:5.5642, R:0.0099, T:0.5875(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5923 (C:5.6051, R:0.0100, T:0.5913(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5806 (C:5.5744, R:0.0100, T:0.5796(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6221 (C:5.5945, R:0.0099, T:0.6211(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5926 (C:5.5599, R:0.0100, T:0.5916(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5806 (C:5.5772, R:0.0099, T:0.5796(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5964 (C:5.5913, R:0.0099, T:0.5954(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5950 (C:5.6050, R:0.0100, T:0.5940(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5732 (C:5.6162, R:0.0100, T:0.5722(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5881 (C:5.5402, R:0.0099, T:0.5871(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5975 (C:5.5451, R:0.0099, T:0.5966(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5993 (C:5.5965, R:0.0100, T:0.5983(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5930 (C:5.6002, R:0.0100, T:0.5920(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 71 TRAINING SUMMARY:
  Total Loss: 0.5826
  Contrastive: 5.5854
  Reconstruction: 0.0100
  Topological: 0.5816 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.1276
  Contrastive: 4.3928
  Reconstruction: 0.0099
  Topological: 5.1266 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 71/300 COMPLETE (45.2s)
Train Loss: 0.5826 (C:5.5854, R:0.0100, T:0.5816)
Val Loss:   5.1276 (C:4.3928, R:0.0099, T:5.1266)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 72 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6099 (C:5.5980, R:0.0100, T:0.6089(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5891 (C:5.5781, R:0.0100, T:0.5881(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5954 (C:5.5801, R:0.0100, T:0.5944(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5906 (C:5.6136, R:0.0100, T:0.5896(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5778 (C:5.5659, R:0.0100, T:0.5768(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5950 (C:5.5838, R:0.0099, T:0.5940(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5886 (C:5.6160, R:0.0100, T:0.5876(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5805 (C:5.6207, R:0.0099, T:0.5795(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5905 (C:5.5287, R:0.0099, T:0.5895(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5754 (C:5.6140, R:0.0100, T:0.5744(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6142 (C:5.6029, R:0.0100, T:0.6132(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5891 (C:5.5743, R:0.0099, T:0.5881(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5625 (C:5.6040, R:0.0099, T:0.5615(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5947 (C:5.5975, R:0.0099, T:0.5937(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5768 (C:5.6437, R:0.0099, T:0.5758(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5873 (C:5.5903, R:0.0100, T:0.5863(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5729 (C:5.6015, R:0.0099, T:0.5719(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6286 (C:5.5828, R:0.0099, T:0.6276(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5606 (C:5.5764, R:0.0100, T:0.5596(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5987 (C:5.6015, R:0.0100, T:0.5977(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5709 (C:5.5465, R:0.0100, T:0.5699(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5276 (C:5.5905, R:0.0099, T:0.5266(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 72 TRAINING SUMMARY:
  Total Loss: 0.5822
  Contrastive: 5.5852
  Reconstruction: 0.0100
  Topological: 0.5812 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.2352
  Contrastive: 4.3793
  Reconstruction: 0.0099
  Topological: 5.2342 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 72/300 COMPLETE (45.5s)
Train Loss: 0.5822 (C:5.5852, R:0.0100, T:0.5812)
Val Loss:   5.2352 (C:4.3793, R:0.0099, T:5.2342)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 73 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5781 (C:5.5658, R:0.0100, T:0.5771(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5848 (C:5.6113, R:0.0100, T:0.5838(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5576 (C:5.5904, R:0.0100, T:0.5566(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5438 (C:5.5681, R:0.0099, T:0.5428(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5971 (C:5.5991, R:0.0100, T:0.5961(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5897 (C:5.5729, R:0.0099, T:0.5887(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5730 (C:5.5739, R:0.0099, T:0.5720(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5795 (C:5.5415, R:0.0099, T:0.5785(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5899 (C:5.5802, R:0.0099, T:0.5889(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5970 (C:5.5959, R:0.0099, T:0.5960(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5632 (C:5.6209, R:0.0100, T:0.5622(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5988 (C:5.5854, R:0.0100, T:0.5978(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5598 (C:5.5935, R:0.0100, T:0.5588(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5744 (C:5.5892, R:0.0099, T:0.5734(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5986 (C:5.5494, R:0.0099, T:0.5976(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5820 (C:5.6154, R:0.0100, T:0.5810(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6046 (C:5.5796, R:0.0100, T:0.6036(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5690 (C:5.6178, R:0.0100, T:0.5680(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5828 (C:5.5871, R:0.0100, T:0.5818(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6249 (C:5.6063, R:0.0100, T:0.6239(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5605 (C:5.5641, R:0.0099, T:0.5595(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5832 (C:5.5941, R:0.0100, T:0.5822(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5803

ğŸ“Š EPOCH 73 TRAINING SUMMARY:
  Total Loss: 0.5813
  Contrastive: 5.5851
  Reconstruction: 0.0100
  Topological: 0.5803 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.2465
  Contrastive: 4.3799
  Reconstruction: 0.0099
  Topological: 5.2455 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 73/300 COMPLETE (46.2s)
Train Loss: 0.5813 (C:5.5851, R:0.0100, T:0.5803)
Val Loss:   5.2465 (C:4.3799, R:0.0099, T:5.2455)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 74 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5812 (C:5.5627, R:0.0100, T:0.5802(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5953 (C:5.5918, R:0.0100, T:0.5943(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5885 (C:5.6195, R:0.0099, T:0.5875(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6012 (C:5.5355, R:0.0100, T:0.6003(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6147 (C:5.6217, R:0.0100, T:0.6137(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5935 (C:5.5372, R:0.0100, T:0.5925(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5583 (C:5.5504, R:0.0099, T:0.5573(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5805 (C:5.5767, R:0.0099, T:0.5795(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5969 (C:5.5436, R:0.0099, T:0.5959(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5867 (C:5.5856, R:0.0099, T:0.5857(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5758 (C:5.6382, R:0.0100, T:0.5748(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5687 (C:5.5467, R:0.0099, T:0.5677(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5683 (C:5.5913, R:0.0099, T:0.5673(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5720 (C:5.5845, R:0.0099, T:0.5710(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5545 (C:5.5850, R:0.0100, T:0.5535(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5646 (C:5.5821, R:0.0099, T:0.5637(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6043 (C:5.5783, R:0.0100, T:0.6033(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5662 (C:5.5481, R:0.0099, T:0.5652(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5302 (C:5.6185, R:0.0100, T:0.5292(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5920 (C:5.6106, R:0.0100, T:0.5910(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5880 (C:5.5331, R:0.0099, T:0.5870(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5949 (C:5.6706, R:0.0099, T:0.5939(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 74 TRAINING SUMMARY:
  Total Loss: 0.5831
  Contrastive: 5.5847
  Reconstruction: 0.0100
  Topological: 0.5821 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.4220
  Contrastive: 4.3509
  Reconstruction: 0.0099
  Topological: 5.4210 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 74/300 COMPLETE (46.1s)
Train Loss: 0.5831 (C:5.5847, R:0.0100, T:0.5821)
Val Loss:   5.4220 (C:4.3509, R:0.0099, T:5.4210)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 75 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5979 (C:5.5163, R:0.0099, T:0.5969(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5723 (C:5.6097, R:0.0100, T:0.5714(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5607 (C:5.5607, R:0.0099, T:0.5597(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5926 (C:5.6148, R:0.0099, T:0.5916(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5833 (C:5.5238, R:0.0100, T:0.5823(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5725 (C:5.5694, R:0.0100, T:0.5715(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5749 (C:5.5588, R:0.0100, T:0.5739(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5599 (C:5.5883, R:0.0099, T:0.5589(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5983 (C:5.5412, R:0.0099, T:0.5973(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5740 (C:5.5935, R:0.0100, T:0.5730(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5932 (C:5.5510, R:0.0099, T:0.5922(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5830 (C:5.5989, R:0.0099, T:0.5820(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5719 (C:5.6067, R:0.0100, T:0.5709(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5847 (C:5.5689, R:0.0099, T:0.5838(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5988 (C:5.6474, R:0.0100, T:0.5978(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6017 (C:5.5529, R:0.0100, T:0.6007(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5652 (C:5.5403, R:0.0100, T:0.5642(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5735 (C:5.5503, R:0.0099, T:0.5725(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5973 (C:5.5771, R:0.0099, T:0.5963(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5571 (C:5.5834, R:0.0100, T:0.5561(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5937 (C:5.5673, R:0.0100, T:0.5927(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5660 (C:5.6274, R:0.0100, T:0.5650(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 75 TRAINING SUMMARY:
  Total Loss: 0.5821
  Contrastive: 5.5858
  Reconstruction: 0.0100
  Topological: 0.5811 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.2655
  Contrastive: 4.3833
  Reconstruction: 0.0099
  Topological: 5.2645 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 75/300 COMPLETE (45.8s)
Train Loss: 0.5821 (C:5.5858, R:0.0100, T:0.5811)
Val Loss:   5.2655 (C:4.3833, R:0.0099, T:5.2645)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 76 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5854 (C:5.5639, R:0.0099, T:0.5844(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5681 (C:5.5931, R:0.0100, T:0.5671(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5901 (C:5.5895, R:0.0099, T:0.5891(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5799 (C:5.6383, R:0.0100, T:0.5790(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5868 (C:5.5695, R:0.0100, T:0.5858(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5643 (C:5.6129, R:0.0100, T:0.5633(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5897 (C:5.6154, R:0.0100, T:0.5887(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5667 (C:5.5317, R:0.0099, T:0.5657(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5771 (C:5.6122, R:0.0100, T:0.5761(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5531 (C:5.6121, R:0.0099, T:0.5521(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5992 (C:5.5594, R:0.0100, T:0.5982(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5664 (C:5.5877, R:0.0099, T:0.5654(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5993 (C:5.5764, R:0.0099, T:0.5983(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5762 (C:5.6037, R:0.0100, T:0.5752(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5636 (C:5.5814, R:0.0099, T:0.5626(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5916 (C:5.5844, R:0.0099, T:0.5906(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5950 (C:5.5544, R:0.0100, T:0.5940(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5421 (C:5.5874, R:0.0100, T:0.5411(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5958 (C:5.6205, R:0.0099, T:0.5948(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5727 (C:5.5737, R:0.0100, T:0.5717(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5906 (C:5.6104, R:0.0100, T:0.5896(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5650 (C:5.5788, R:0.0099, T:0.5640(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5793

ğŸ“Š EPOCH 76 TRAINING SUMMARY:
  Total Loss: 0.5802
  Contrastive: 5.5866
  Reconstruction: 0.0100
  Topological: 0.5793 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.1285
  Contrastive: 4.3928
  Reconstruction: 0.0099
  Topological: 5.1275 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 76/300 COMPLETE (45.0s)
Train Loss: 0.5802 (C:5.5866, R:0.0100, T:0.5793)
Val Loss:   5.1285 (C:4.3928, R:0.0099, T:5.1275)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 77 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6043 (C:5.5946, R:0.0099, T:0.6033(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5801 (C:5.5653, R:0.0100, T:0.5791(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6014 (C:5.5654, R:0.0100, T:0.6004(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5975 (C:5.5769, R:0.0099, T:0.5965(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5702 (C:5.5617, R:0.0099, T:0.5692(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5910 (C:5.5948, R:0.0099, T:0.5900(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6168 (C:5.6582, R:0.0100, T:0.6158(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5699 (C:5.5849, R:0.0100, T:0.5689(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5970 (C:5.5960, R:0.0099, T:0.5960(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5340 (C:5.5860, R:0.0099, T:0.5330(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5874 (C:5.6192, R:0.0099, T:0.5864(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5768 (C:5.5913, R:0.0100, T:0.5758(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5762 (C:5.5769, R:0.0099, T:0.5752(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5757 (C:5.5801, R:0.0099, T:0.5747(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6176 (C:5.5669, R:0.0099, T:0.6166(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5945 (C:5.5824, R:0.0100, T:0.5935(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5680 (C:5.5708, R:0.0100, T:0.5671(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5885 (C:5.6089, R:0.0100, T:0.5875(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5585 (C:5.6254, R:0.0100, T:0.5575(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5991 (C:5.5777, R:0.0100, T:0.5981(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5357 (C:5.5873, R:0.0099, T:0.5347(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5830 (C:5.5620, R:0.0099, T:0.5820(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5782

ğŸ“Š EPOCH 77 TRAINING SUMMARY:
  Total Loss: 0.5792
  Contrastive: 5.5867
  Reconstruction: 0.0100
  Topological: 0.5782 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0672
  Contrastive: 4.4462
  Reconstruction: 0.0099
  Topological: 5.0663 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 77/300 COMPLETE (45.7s)
Train Loss: 0.5792 (C:5.5867, R:0.0100, T:0.5782)
Val Loss:   5.0672 (C:4.4462, R:0.0099, T:5.0663)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 78 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5862 (C:5.6055, R:0.0100, T:0.5852(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5522 (C:5.5602, R:0.0099, T:0.5512(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5872 (C:5.6202, R:0.0100, T:0.5862(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5845 (C:5.5606, R:0.0100, T:0.5835(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5808 (C:5.5775, R:0.0099, T:0.5798(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5802 (C:5.5789, R:0.0100, T:0.5792(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5564 (C:5.5818, R:0.0100, T:0.5554(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5654 (C:5.5747, R:0.0099, T:0.5644(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5426 (C:5.5799, R:0.0100, T:0.5416(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5637 (C:5.5892, R:0.0100, T:0.5627(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5787 (C:5.5843, R:0.0099, T:0.5777(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5540 (C:5.5615, R:0.0100, T:0.5530(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6084 (C:5.5828, R:0.0100, T:0.6074(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5717 (C:5.6112, R:0.0100, T:0.5707(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5751 (C:5.5903, R:0.0099, T:0.5741(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6018 (C:5.5972, R:0.0100, T:0.6008(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5881 (C:5.6073, R:0.0099, T:0.5871(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5902 (C:5.5874, R:0.0099, T:0.5892(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5941 (C:5.5600, R:0.0100, T:0.5931(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6186 (C:5.6173, R:0.0100, T:0.6176(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5807 (C:5.6123, R:0.0099, T:0.5797(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5863 (C:5.5840, R:0.0100, T:0.5853(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 78 TRAINING SUMMARY:
  Total Loss: 0.5806
  Contrastive: 5.5862
  Reconstruction: 0.0100
  Topological: 0.5796 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.2329
  Contrastive: 4.3640
  Reconstruction: 0.0099
  Topological: 5.2319 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 78/300 COMPLETE (45.6s)
Train Loss: 0.5806 (C:5.5862, R:0.0100, T:0.5796)
Val Loss:   5.2329 (C:4.3640, R:0.0099, T:5.2319)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 79 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5850 (C:5.5484, R:0.0100, T:0.5840(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5740 (C:5.5905, R:0.0100, T:0.5731(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5865 (C:5.5370, R:0.0100, T:0.5855(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5909 (C:5.6105, R:0.0099, T:0.5899(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5677 (C:5.5555, R:0.0100, T:0.5667(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5504 (C:5.6214, R:0.0099, T:0.5494(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5795 (C:5.5796, R:0.0099, T:0.5785(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5896 (C:5.5946, R:0.0100, T:0.5886(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5817 (C:5.6338, R:0.0100, T:0.5807(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5807 (C:5.5866, R:0.0099, T:0.5798(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5725 (C:5.5843, R:0.0100, T:0.5715(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5997 (C:5.6016, R:0.0100, T:0.5987(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5659 (C:5.5933, R:0.0100, T:0.5649(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5742 (C:5.6093, R:0.0100, T:0.5732(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6102 (C:5.6055, R:0.0100, T:0.6092(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5884 (C:5.6164, R:0.0099, T:0.5874(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5673 (C:5.5735, R:0.0099, T:0.5663(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5837 (C:5.6160, R:0.0100, T:0.5827(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5864 (C:5.6440, R:0.0100, T:0.5854(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5761 (C:5.5570, R:0.0099, T:0.5751(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6123 (C:5.6022, R:0.0099, T:0.6113(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6093 (C:5.5984, R:0.0100, T:0.6083(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5773

ğŸ“Š EPOCH 79 TRAINING SUMMARY:
  Total Loss: 0.5783
  Contrastive: 5.5874
  Reconstruction: 0.0100
  Topological: 0.5773 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.2038
  Contrastive: 4.3800
  Reconstruction: 0.0099
  Topological: 5.2028 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 79/300 COMPLETE (44.7s)
Train Loss: 0.5783 (C:5.5874, R:0.0100, T:0.5773)
Val Loss:   5.2038 (C:4.3800, R:0.0099, T:5.2028)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 80 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5809 (C:5.5789, R:0.0100, T:0.5799(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5938 (C:5.5441, R:0.0100, T:0.5928(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5994 (C:5.6498, R:0.0100, T:0.5983(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5723 (C:5.5414, R:0.0099, T:0.5713(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5794 (C:5.5688, R:0.0100, T:0.5784(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5997 (C:5.6097, R:0.0100, T:0.5987(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5703 (C:5.5967, R:0.0100, T:0.5693(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5599 (C:5.6241, R:0.0099, T:0.5589(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5383 (C:5.5590, R:0.0099, T:0.5373(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5738 (C:5.6110, R:0.0100, T:0.5728(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5834 (C:5.5546, R:0.0099, T:0.5824(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5706 (C:5.5674, R:0.0099, T:0.5696(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5577 (C:5.5547, R:0.0099, T:0.5567(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5839 (C:5.6495, R:0.0099, T:0.5829(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5592 (C:5.6166, R:0.0100, T:0.5582(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5804 (C:5.5378, R:0.0099, T:0.5794(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5841 (C:5.6261, R:0.0099, T:0.5831(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5711 (C:5.5969, R:0.0100, T:0.5701(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5713 (C:5.5893, R:0.0100, T:0.5703(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5629 (C:5.6185, R:0.0100, T:0.5619(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5669 (C:5.5637, R:0.0100, T:0.5659(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5583 (C:5.5987, R:0.0100, T:0.5573(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 80 TRAINING SUMMARY:
  Total Loss: 0.5784
  Contrastive: 5.5867
  Reconstruction: 0.0100
  Topological: 0.5775 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.1914
  Contrastive: 4.3728
  Reconstruction: 0.0099
  Topological: 5.1904 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 80/300 COMPLETE (45.6s)
Train Loss: 0.5784 (C:5.5867, R:0.0100, T:0.5775)
Val Loss:   5.1914 (C:4.3728, R:0.0099, T:5.1904)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 81 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5871 (C:5.5734, R:0.0100, T:0.5861(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5575 (C:5.6183, R:0.0100, T:0.5565(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5695 (C:5.5782, R:0.0100, T:0.5685(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5801 (C:5.6233, R:0.0100, T:0.5791(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5801 (C:5.6050, R:0.0100, T:0.5791(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5739 (C:5.5833, R:0.0100, T:0.5729(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5645 (C:5.5299, R:0.0099, T:0.5635(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5789 (C:5.5874, R:0.0100, T:0.5779(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5868 (C:5.5658, R:0.0100, T:0.5858(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5872 (C:5.5790, R:0.0100, T:0.5862(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5791 (C:5.6476, R:0.0100, T:0.5781(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5874 (C:5.5950, R:0.0099, T:0.5864(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5957 (C:5.5517, R:0.0100, T:0.5947(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5763 (C:5.5869, R:0.0099, T:0.5754(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6122 (C:5.5567, R:0.0099, T:0.6112(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5918 (C:5.5788, R:0.0099, T:0.5908(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5869 (C:5.5961, R:0.0099, T:0.5860(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5617 (C:5.6031, R:0.0100, T:0.5607(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5731 (C:5.6114, R:0.0100, T:0.5721(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5863 (C:5.6394, R:0.0100, T:0.5853(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5754 (C:5.5680, R:0.0100, T:0.5744(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5782 (C:5.5955, R:0.0100, T:0.5772(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 81 TRAINING SUMMARY:
  Total Loss: 0.5784
  Contrastive: 5.5851
  Reconstruction: 0.0100
  Topological: 0.5774 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.2041
  Contrastive: 4.3766
  Reconstruction: 0.0099
  Topological: 5.2031 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 81/300 COMPLETE (45.2s)
Train Loss: 0.5784 (C:5.5851, R:0.0100, T:0.5774)
Val Loss:   5.2041 (C:4.3766, R:0.0099, T:5.2031)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 82 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5918 (C:5.5380, R:0.0099, T:0.5908(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5361 (C:5.5791, R:0.0100, T:0.5351(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5685 (C:5.5634, R:0.0099, T:0.5675(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5664 (C:5.5387, R:0.0100, T:0.5654(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5838 (C:5.5758, R:0.0099, T:0.5828(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5598 (C:5.6107, R:0.0100, T:0.5588(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5463 (C:5.5631, R:0.0099, T:0.5453(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5694 (C:5.6140, R:0.0100, T:0.5684(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5704 (C:5.5671, R:0.0099, T:0.5694(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5952 (C:5.5989, R:0.0099, T:0.5942(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5638 (C:5.6220, R:0.0100, T:0.5628(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6093 (C:5.5811, R:0.0100, T:0.6083(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5820 (C:5.5864, R:0.0099, T:0.5810(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5269 (C:5.6116, R:0.0100, T:0.5259(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5585 (C:5.5639, R:0.0100, T:0.5575(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6001 (C:5.5560, R:0.0100, T:0.5991(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5727 (C:5.5746, R:0.0100, T:0.5717(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5897 (C:5.5790, R:0.0099, T:0.5887(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5986 (C:5.6078, R:0.0100, T:0.5976(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5907 (C:5.5871, R:0.0100, T:0.5897(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5698 (C:5.5454, R:0.0099, T:0.5688(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5763 (C:5.5969, R:0.0100, T:0.5753(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5766

ğŸ“Š EPOCH 82 TRAINING SUMMARY:
  Total Loss: 0.5776
  Contrastive: 5.5853
  Reconstruction: 0.0100
  Topological: 0.5766 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.1194
  Contrastive: 4.4095
  Reconstruction: 0.0099
  Topological: 5.1184 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 82/300 COMPLETE (48.7s)
Train Loss: 0.5776 (C:5.5853, R:0.0100, T:0.5766)
Val Loss:   5.1194 (C:4.4095, R:0.0099, T:5.1184)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 83 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5651 (C:5.5952, R:0.0099, T:0.5641(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5944 (C:5.5807, R:0.0100, T:0.5934(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5574 (C:5.5998, R:0.0099, T:0.5565(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6037 (C:5.6463, R:0.0100, T:0.6027(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6062 (C:5.5695, R:0.0099, T:0.6053(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5859 (C:5.5894, R:0.0100, T:0.5849(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5750 (C:5.6169, R:0.0099, T:0.5740(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5776 (C:5.5929, R:0.0100, T:0.5766(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6093 (C:5.6159, R:0.0100, T:0.6083(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6024 (C:5.5707, R:0.0099, T:0.6014(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5903 (C:5.5657, R:0.0100, T:0.5893(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5772 (C:5.6032, R:0.0099, T:0.5762(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5762 (C:5.6320, R:0.0099, T:0.5752(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5737 (C:5.5687, R:0.0099, T:0.5727(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6045 (C:5.6107, R:0.0100, T:0.6035(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6067 (C:5.5743, R:0.0099, T:0.6057(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5769 (C:5.5424, R:0.0099, T:0.5759(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5814 (C:5.5949, R:0.0100, T:0.5804(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5761 (C:5.5614, R:0.0100, T:0.5751(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6063 (C:5.5928, R:0.0100, T:0.6053(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5466 (C:5.6005, R:0.0099, T:0.5456(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5863 (C:5.6445, R:0.0100, T:0.5853(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5764

ğŸ“Š EPOCH 83 TRAINING SUMMARY:
  Total Loss: 0.5774
  Contrastive: 5.5869
  Reconstruction: 0.0100
  Topological: 0.5764 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.2026
  Contrastive: 4.3839
  Reconstruction: 0.0099
  Topological: 5.2016 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 83/300 COMPLETE (45.9s)
Train Loss: 0.5774 (C:5.5869, R:0.0100, T:0.5764)
Val Loss:   5.2026 (C:4.3839, R:0.0099, T:5.2016)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 84 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5689 (C:5.5438, R:0.0100, T:0.5679(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5806 (C:5.5945, R:0.0099, T:0.5796(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5762 (C:5.6245, R:0.0099, T:0.5752(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5945 (C:5.5915, R:0.0099, T:0.5935(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5743 (C:5.6048, R:0.0100, T:0.5733(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5470 (C:5.5812, R:0.0099, T:0.5460(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6168 (C:5.5765, R:0.0099, T:0.6158(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5803 (C:5.6106, R:0.0099, T:0.5793(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5670 (C:5.6184, R:0.0099, T:0.5660(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5870 (C:5.5688, R:0.0099, T:0.5860(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5974 (C:5.5571, R:0.0099, T:0.5964(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5748 (C:5.5738, R:0.0099, T:0.5738(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5891 (C:5.5972, R:0.0099, T:0.5881(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5909 (C:5.5652, R:0.0100, T:0.5899(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5449 (C:5.5873, R:0.0099, T:0.5440(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5782 (C:5.6009, R:0.0100, T:0.5772(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5563 (C:5.5605, R:0.0100, T:0.5553(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5528 (C:5.5918, R:0.0099, T:0.5518(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6133 (C:5.5894, R:0.0100, T:0.6123(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5656 (C:5.6030, R:0.0100, T:0.5646(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5706 (C:5.5717, R:0.0099, T:0.5696(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5915 (C:5.5826, R:0.0100, T:0.5905(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5758

ğŸ“Š EPOCH 84 TRAINING SUMMARY:
  Total Loss: 0.5768
  Contrastive: 5.5859
  Reconstruction: 0.0100
  Topological: 0.5758 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.1479
  Contrastive: 4.4124
  Reconstruction: 0.0099
  Topological: 5.1469 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 84/300 COMPLETE (49.5s)
Train Loss: 0.5768 (C:5.5859, R:0.0100, T:0.5758)
Val Loss:   5.1479 (C:4.4124, R:0.0099, T:5.1469)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 85 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5492 (C:5.5875, R:0.0099, T:0.5482(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6152 (C:5.5893, R:0.0099, T:0.6142(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5686 (C:5.5815, R:0.0099, T:0.5677(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6103 (C:5.5912, R:0.0100, T:0.6093(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5473 (C:5.6121, R:0.0099, T:0.5463(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5758 (C:5.5862, R:0.0099, T:0.5749(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5761 (C:5.5567, R:0.0100, T:0.5751(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5698 (C:5.5954, R:0.0100, T:0.5688(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5889 (C:5.5672, R:0.0100, T:0.5879(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5810 (C:5.6113, R:0.0100, T:0.5800(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5760 (C:5.5792, R:0.0100, T:0.5750(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5626 (C:5.5621, R:0.0100, T:0.5616(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5648 (C:5.5912, R:0.0099, T:0.5638(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5455 (C:5.6286, R:0.0100, T:0.5445(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5835 (C:5.5871, R:0.0099, T:0.5825(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5929 (C:5.5548, R:0.0100, T:0.5920(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5524 (C:5.6109, R:0.0100, T:0.5514(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5858 (C:5.5793, R:0.0100, T:0.5848(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5594 (C:5.6155, R:0.0100, T:0.5584(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5545 (C:5.6068, R:0.0099, T:0.5535(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5864 (C:5.5952, R:0.0099, T:0.5854(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5392 (C:5.5739, R:0.0099, T:0.5382(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 85 TRAINING SUMMARY:
  Total Loss: 0.5777
  Contrastive: 5.5854
  Reconstruction: 0.0100
  Topological: 0.5767 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.1962
  Contrastive: 4.3956
  Reconstruction: 0.0099
  Topological: 5.1952 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 85/300 COMPLETE (48.5s)
Train Loss: 0.5777 (C:5.5854, R:0.0100, T:0.5767)
Val Loss:   5.1962 (C:4.3956, R:0.0099, T:5.1952)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 86 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5686 (C:5.5850, R:0.0100, T:0.5676(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5661 (C:5.6184, R:0.0099, T:0.5651(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5660 (C:5.5717, R:0.0099, T:0.5650(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5766 (C:5.5535, R:0.0100, T:0.5756(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5908 (C:5.5987, R:0.0100, T:0.5898(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5660 (C:5.6057, R:0.0100, T:0.5650(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5563 (C:5.5652, R:0.0099, T:0.5553(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5860 (C:5.5959, R:0.0100, T:0.5850(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5419 (C:5.5757, R:0.0099, T:0.5409(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5615 (C:5.5763, R:0.0099, T:0.5605(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5699 (C:5.5500, R:0.0100, T:0.5689(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5776 (C:5.5901, R:0.0100, T:0.5766(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5671 (C:5.6201, R:0.0100, T:0.5661(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5956 (C:5.5746, R:0.0099, T:0.5947(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5819 (C:5.6101, R:0.0100, T:0.5809(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5663 (C:5.5777, R:0.0099, T:0.5653(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5682 (C:5.6082, R:0.0100, T:0.5672(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5634 (C:5.5851, R:0.0099, T:0.5624(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5443 (C:5.5699, R:0.0100, T:0.5433(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5753 (C:5.6151, R:0.0100, T:0.5743(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5743 (C:5.5710, R:0.0100, T:0.5733(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5726 (C:5.6030, R:0.0099, T:0.5717(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5747

ğŸ“Š EPOCH 86 TRAINING SUMMARY:
  Total Loss: 0.5757
  Contrastive: 5.5898
  Reconstruction: 0.0100
  Topological: 0.5747 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0534
  Contrastive: 4.4334
  Reconstruction: 0.0099
  Topological: 5.0524 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 86/300 COMPLETE (47.5s)
Train Loss: 0.5757 (C:5.5898, R:0.0100, T:0.5747)
Val Loss:   5.0534 (C:4.4334, R:0.0099, T:5.0524)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 87 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5719 (C:5.6080, R:0.0099, T:0.5710(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5743 (C:5.6553, R:0.0100, T:0.5733(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5394 (C:5.5982, R:0.0100, T:0.5384(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5718 (C:5.5828, R:0.0100, T:0.5708(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5958 (C:5.6086, R:0.0100, T:0.5948(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5879 (C:5.5509, R:0.0100, T:0.5870(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5920 (C:5.5852, R:0.0100, T:0.5910(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5774 (C:5.5619, R:0.0099, T:0.5764(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5983 (C:5.5504, R:0.0100, T:0.5974(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5512 (C:5.6211, R:0.0099, T:0.5502(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5888 (C:5.5850, R:0.0100, T:0.5878(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6165 (C:5.5981, R:0.0100, T:0.6155(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5790 (C:5.5991, R:0.0099, T:0.5780(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5641 (C:5.5514, R:0.0099, T:0.5631(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5885 (C:5.5790, R:0.0100, T:0.5875(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5390 (C:5.5963, R:0.0099, T:0.5380(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5581 (C:5.6128, R:0.0100, T:0.5571(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6202 (C:5.5970, R:0.0100, T:0.6192(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6116 (C:5.5922, R:0.0099, T:0.6106(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5903 (C:5.5952, R:0.0100, T:0.5893(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5954 (C:5.5886, R:0.0100, T:0.5944(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5431 (C:5.5606, R:0.0099, T:0.5421(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 87 TRAINING SUMMARY:
  Total Loss: 0.5771
  Contrastive: 5.5860
  Reconstruction: 0.0100
  Topological: 0.5761 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0679
  Contrastive: 4.4046
  Reconstruction: 0.0099
  Topological: 5.0669 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 87/300 COMPLETE (50.3s)
Train Loss: 0.5771 (C:5.5860, R:0.0100, T:0.5761)
Val Loss:   5.0679 (C:4.4046, R:0.0099, T:5.0669)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 88 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5508 (C:5.6044, R:0.0100, T:0.5498(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5747 (C:5.5534, R:0.0099, T:0.5737(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5812 (C:5.5980, R:0.0100, T:0.5802(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5714 (C:5.5920, R:0.0099, T:0.5704(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5455 (C:5.5998, R:0.0100, T:0.5445(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5752 (C:5.6018, R:0.0100, T:0.5742(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5752 (C:5.6098, R:0.0099, T:0.5742(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5860 (C:5.6196, R:0.0099, T:0.5850(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5936 (C:5.5910, R:0.0100, T:0.5926(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6012 (C:5.5620, R:0.0099, T:0.6002(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5663 (C:5.6414, R:0.0099, T:0.5653(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5813 (C:5.5868, R:0.0100, T:0.5803(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5890 (C:5.5191, R:0.0099, T:0.5880(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5886 (C:5.5865, R:0.0100, T:0.5876(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5932 (C:5.6380, R:0.0100, T:0.5922(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5521 (C:5.5839, R:0.0100, T:0.5511(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5357 (C:5.5454, R:0.0100, T:0.5347(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5719 (C:5.6324, R:0.0100, T:0.5709(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5954 (C:5.5928, R:0.0100, T:0.5944(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6140 (C:5.6148, R:0.0100, T:0.6130(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5830 (C:5.5516, R:0.0099, T:0.5820(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5765 (C:5.6110, R:0.0100, T:0.5755(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 88 TRAINING SUMMARY:
  Total Loss: 0.5760
  Contrastive: 5.5850
  Reconstruction: 0.0100
  Topological: 0.5750 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.2852
  Contrastive: 4.3733
  Reconstruction: 0.0099
  Topological: 5.2842 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 88/300 COMPLETE (50.5s)
Train Loss: 0.5760 (C:5.5850, R:0.0100, T:0.5750)
Val Loss:   5.2852 (C:4.3733, R:0.0099, T:5.2842)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 89 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5426 (C:5.5533, R:0.0100, T:0.5416(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5908 (C:5.5983, R:0.0100, T:0.5898(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5674 (C:5.5772, R:0.0100, T:0.5664(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5808 (C:5.5786, R:0.0099, T:0.5798(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5712 (C:5.5979, R:0.0099, T:0.5702(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5704 (C:5.5812, R:0.0100, T:0.5694(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6122 (C:5.5445, R:0.0099, T:0.6112(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5705 (C:5.6024, R:0.0100, T:0.5695(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5645 (C:5.6084, R:0.0099, T:0.5635(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5557 (C:5.6073, R:0.0099, T:0.5547(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5674 (C:5.6168, R:0.0100, T:0.5664(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5914 (C:5.5703, R:0.0099, T:0.5904(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5985 (C:5.5607, R:0.0099, T:0.5975(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5971 (C:5.6258, R:0.0100, T:0.5961(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5804 (C:5.5631, R:0.0100, T:0.5794(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5616 (C:5.5578, R:0.0099, T:0.5606(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5741 (C:5.6158, R:0.0099, T:0.5731(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5777 (C:5.5574, R:0.0099, T:0.5767(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5866 (C:5.6427, R:0.0100, T:0.5856(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5497 (C:5.5739, R:0.0100, T:0.5487(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5921 (C:5.5614, R:0.0100, T:0.5911(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5995 (C:5.6188, R:0.0099, T:0.5985(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5742

ğŸ“Š EPOCH 89 TRAINING SUMMARY:
  Total Loss: 0.5751
  Contrastive: 5.5870
  Reconstruction: 0.0100
  Topological: 0.5742 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.1608
  Contrastive: 4.4024
  Reconstruction: 0.0099
  Topological: 5.1598 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 89/300 COMPLETE (50.7s)
Train Loss: 0.5751 (C:5.5870, R:0.0100, T:0.5742)
Val Loss:   5.1608 (C:4.4024, R:0.0099, T:5.1598)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 90 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5699 (C:5.5878, R:0.0099, T:0.5690(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5485 (C:5.6315, R:0.0099, T:0.5475(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5918 (C:5.5898, R:0.0100, T:0.5908(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5998 (C:5.5911, R:0.0099, T:0.5988(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5992 (C:5.5498, R:0.0100, T:0.5982(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5954 (C:5.6440, R:0.0100, T:0.5944(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5692 (C:5.6029, R:0.0100, T:0.5682(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5830 (C:5.5903, R:0.0100, T:0.5820(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5675 (C:5.6055, R:0.0099, T:0.5665(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5806 (C:5.5599, R:0.0100, T:0.5796(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6070 (C:5.6086, R:0.0100, T:0.6060(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5938 (C:5.6168, R:0.0099, T:0.5928(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5816 (C:5.5368, R:0.0099, T:0.5806(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5821 (C:5.5782, R:0.0099, T:0.5811(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5879 (C:5.5647, R:0.0100, T:0.5869(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5833 (C:5.5520, R:0.0099, T:0.5823(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5452 (C:5.5743, R:0.0099, T:0.5442(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5372 (C:5.6228, R:0.0099, T:0.5362(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5416 (C:5.6114, R:0.0100, T:0.5406(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5627 (C:5.6002, R:0.0100, T:0.5617(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5330 (C:5.6202, R:0.0099, T:0.5320(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5740 (C:5.6018, R:0.0100, T:0.5730(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 90 TRAINING SUMMARY:
  Total Loss: 0.5767
  Contrastive: 5.5886
  Reconstruction: 0.0100
  Topological: 0.5757 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0176
  Contrastive: 4.4238
  Reconstruction: 0.0099
  Topological: 5.0166 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 90/300 COMPLETE (48.7s)
Train Loss: 0.5767 (C:5.5886, R:0.0100, T:0.5757)
Val Loss:   5.0176 (C:4.4238, R:0.0099, T:5.0166)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 91 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5621 (C:5.6010, R:0.0100, T:0.5611(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5666 (C:5.5537, R:0.0100, T:0.5656(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5727 (C:5.5892, R:0.0100, T:0.5717(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5782 (C:5.5578, R:0.0100, T:0.5772(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5686 (C:5.6703, R:0.0099, T:0.5676(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5513 (C:5.5844, R:0.0100, T:0.5503(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5805 (C:5.6133, R:0.0100, T:0.5795(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5887 (C:5.5937, R:0.0099, T:0.5877(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5729 (C:5.5767, R:0.0100, T:0.5719(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5981 (C:5.6114, R:0.0100, T:0.5971(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5823 (C:5.6279, R:0.0099, T:0.5813(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5982 (C:5.5047, R:0.0099, T:0.5972(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5662 (C:5.5732, R:0.0100, T:0.5652(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5674 (C:5.6307, R:0.0099, T:0.5664(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5727 (C:5.5995, R:0.0100, T:0.5717(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5626 (C:5.6205, R:0.0100, T:0.5616(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5519 (C:5.5938, R:0.0099, T:0.5509(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5583 (C:5.5928, R:0.0099, T:0.5573(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5759 (C:5.6036, R:0.0100, T:0.5749(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5734 (C:5.5691, R:0.0100, T:0.5724(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5855 (C:5.6010, R:0.0100, T:0.5845(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5905 (C:5.5795, R:0.0100, T:0.5896(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5733

ğŸ“Š EPOCH 91 TRAINING SUMMARY:
  Total Loss: 0.5743
  Contrastive: 5.5899
  Reconstruction: 0.0100
  Topological: 0.5733 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.1191
  Contrastive: 4.3968
  Reconstruction: 0.0099
  Topological: 5.1181 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 91/300 COMPLETE (45.4s)
Train Loss: 0.5743 (C:5.5899, R:0.0100, T:0.5733)
Val Loss:   5.1191 (C:4.3968, R:0.0099, T:5.1181)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 92 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5696 (C:5.5644, R:0.0100, T:0.5686(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5547 (C:5.5637, R:0.0099, T:0.5537(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5637 (C:5.6251, R:0.0099, T:0.5627(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5304 (C:5.5953, R:0.0100, T:0.5294(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5868 (C:5.5965, R:0.0099, T:0.5858(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5568 (C:5.5505, R:0.0099, T:0.5558(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5807 (C:5.5561, R:0.0100, T:0.5797(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5834 (C:5.5945, R:0.0100, T:0.5824(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5650 (C:5.5969, R:0.0099, T:0.5640(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5741 (C:5.6270, R:0.0100, T:0.5731(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5412 (C:5.5565, R:0.0099, T:0.5402(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5752 (C:5.5641, R:0.0100, T:0.5742(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5890 (C:5.5826, R:0.0100, T:0.5880(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5862 (C:5.6160, R:0.0100, T:0.5852(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5382 (C:5.5509, R:0.0099, T:0.5372(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5689 (C:5.6007, R:0.0099, T:0.5679(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5618 (C:5.5943, R:0.0100, T:0.5608(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5844 (C:5.5899, R:0.0099, T:0.5834(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5625 (C:5.5703, R:0.0100, T:0.5615(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5751 (C:5.5834, R:0.0099, T:0.5741(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5478 (C:5.6270, R:0.0099, T:0.5468(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5929 (C:5.6417, R:0.0099, T:0.5919(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5725

ğŸ“Š EPOCH 92 TRAINING SUMMARY:
  Total Loss: 0.5735
  Contrastive: 5.5861
  Reconstruction: 0.0100
  Topological: 0.5725 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0067
  Contrastive: 4.4220
  Reconstruction: 0.0099
  Topological: 5.0057 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 92/300 COMPLETE (45.6s)
Train Loss: 0.5735 (C:5.5861, R:0.0100, T:0.5725)
Val Loss:   5.0067 (C:4.4220, R:0.0099, T:5.0057)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 93 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5662 (C:5.6158, R:0.0100, T:0.5652(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5563 (C:5.5640, R:0.0100, T:0.5553(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6009 (C:5.5722, R:0.0099, T:0.5999(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5964 (C:5.5564, R:0.0100, T:0.5954(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6060 (C:5.6639, R:0.0100, T:0.6050(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5518 (C:5.5241, R:0.0099, T:0.5508(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5963 (C:5.6079, R:0.0099, T:0.5953(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5689 (C:5.5432, R:0.0100, T:0.5679(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5892 (C:5.5298, R:0.0099, T:0.5882(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5518 (C:5.5968, R:0.0100, T:0.5508(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5934 (C:5.5622, R:0.0100, T:0.5924(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5610 (C:5.5637, R:0.0099, T:0.5601(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5663 (C:5.5549, R:0.0100, T:0.5653(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5430 (C:5.5962, R:0.0100, T:0.5420(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6031 (C:5.6002, R:0.0100, T:0.6021(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5625 (C:5.5649, R:0.0100, T:0.5615(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5758 (C:5.6040, R:0.0100, T:0.5748(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5871 (C:5.6087, R:0.0099, T:0.5861(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5402 (C:5.5899, R:0.0099, T:0.5392(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5874 (C:5.6249, R:0.0100, T:0.5864(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5459 (C:5.5658, R:0.0099, T:0.5450(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5924 (C:5.5494, R:0.0100, T:0.5914(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5714

ğŸ“Š EPOCH 93 TRAINING SUMMARY:
  Total Loss: 0.5724
  Contrastive: 5.5876
  Reconstruction: 0.0100
  Topological: 0.5714 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0988
  Contrastive: 4.4207
  Reconstruction: 0.0099
  Topological: 5.0978 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 93/300 COMPLETE (45.2s)
Train Loss: 0.5724 (C:5.5876, R:0.0100, T:0.5714)
Val Loss:   5.0988 (C:4.4207, R:0.0099, T:5.0978)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 94 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5787 (C:5.5939, R:0.0099, T:0.5777(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5852 (C:5.6495, R:0.0100, T:0.5842(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5653 (C:5.5631, R:0.0100, T:0.5643(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5670 (C:5.5942, R:0.0100, T:0.5660(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5668 (C:5.5395, R:0.0100, T:0.5658(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5771 (C:5.5941, R:0.0099, T:0.5761(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5719 (C:5.5711, R:0.0099, T:0.5709(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5877 (C:5.6029, R:0.0099, T:0.5867(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5522 (C:5.5670, R:0.0100, T:0.5512(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5926 (C:5.5963, R:0.0100, T:0.5916(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6059 (C:5.5955, R:0.0100, T:0.6049(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5988 (C:5.5763, R:0.0099, T:0.5978(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5572 (C:5.6041, R:0.0100, T:0.5562(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5971 (C:5.6031, R:0.0100, T:0.5961(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5764 (C:5.5605, R:0.0100, T:0.5754(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5661 (C:5.6147, R:0.0100, T:0.5652(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5593 (C:5.5869, R:0.0100, T:0.5583(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5584 (C:5.6047, R:0.0100, T:0.5574(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5555 (C:5.6081, R:0.0100, T:0.5545(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5718 (C:5.5771, R:0.0099, T:0.5708(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5925 (C:5.5629, R:0.0100, T:0.5915(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5750 (C:5.5731, R:0.0100, T:0.5740(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 94 TRAINING SUMMARY:
  Total Loss: 0.5748
  Contrastive: 5.5884
  Reconstruction: 0.0100
  Topological: 0.5738 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.1064
  Contrastive: 4.3957
  Reconstruction: 0.0099
  Topological: 5.1054 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 94/300 COMPLETE (45.1s)
Train Loss: 0.5748 (C:5.5884, R:0.0100, T:0.5738)
Val Loss:   5.1064 (C:4.3957, R:0.0099, T:5.1054)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 95 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5529 (C:5.5820, R:0.0100, T:0.5519(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5879 (C:5.6066, R:0.0099, T:0.5869(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6043 (C:5.5856, R:0.0100, T:0.6033(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5894 (C:5.6090, R:0.0100, T:0.5884(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5809 (C:5.5471, R:0.0100, T:0.5800(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5634 (C:5.5753, R:0.0099, T:0.5624(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5911 (C:5.5971, R:0.0100, T:0.5901(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5557 (C:5.5992, R:0.0100, T:0.5547(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5991 (C:5.6163, R:0.0100, T:0.5981(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5567 (C:5.6067, R:0.0100, T:0.5557(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5846 (C:5.5765, R:0.0100, T:0.5836(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5770 (C:5.6346, R:0.0099, T:0.5760(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5914 (C:5.5766, R:0.0100, T:0.5904(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5741 (C:5.5789, R:0.0099, T:0.5731(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5941 (C:5.5560, R:0.0100, T:0.5931(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5849 (C:5.5993, R:0.0100, T:0.5839(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5564 (C:5.5533, R:0.0099, T:0.5554(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5737 (C:5.5926, R:0.0099, T:0.5727(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5705 (C:5.5865, R:0.0100, T:0.5695(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5720 (C:5.5566, R:0.0099, T:0.5710(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5662 (C:5.5922, R:0.0100, T:0.5653(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5878 (C:5.6012, R:0.0100, T:0.5868(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 95 TRAINING SUMMARY:
  Total Loss: 0.5744
  Contrastive: 5.5882
  Reconstruction: 0.0100
  Topological: 0.5734 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.1101
  Contrastive: 4.4083
  Reconstruction: 0.0099
  Topological: 5.1091 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 95/300 COMPLETE (45.1s)
Train Loss: 0.5744 (C:5.5882, R:0.0100, T:0.5734)
Val Loss:   5.1101 (C:4.4083, R:0.0099, T:5.1091)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 96 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5568 (C:5.5674, R:0.0100, T:0.5558(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5733 (C:5.6154, R:0.0100, T:0.5723(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5802 (C:5.5948, R:0.0099, T:0.5792(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6115 (C:5.5868, R:0.0100, T:0.6105(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5685 (C:5.6492, R:0.0100, T:0.5675(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5955 (C:5.5727, R:0.0100, T:0.5945(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5472 (C:5.5955, R:0.0100, T:0.5462(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5665 (C:5.5761, R:0.0100, T:0.5655(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5531 (C:5.5740, R:0.0099, T:0.5521(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5637 (C:5.5888, R:0.0099, T:0.5627(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5811 (C:5.5270, R:0.0099, T:0.5801(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5837 (C:5.6056, R:0.0100, T:0.5827(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5686 (C:5.5908, R:0.0099, T:0.5676(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5689 (C:5.5837, R:0.0100, T:0.5679(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6045 (C:5.6160, R:0.0099, T:0.6035(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5342 (C:5.5786, R:0.0100, T:0.5332(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5498 (C:5.6055, R:0.0099, T:0.5488(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5689 (C:5.6039, R:0.0100, T:0.5679(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5647 (C:5.5949, R:0.0099, T:0.5637(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5623 (C:5.6281, R:0.0099, T:0.5613(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6026 (C:5.5954, R:0.0099, T:0.6017(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5536 (C:5.5886, R:0.0099, T:0.5526(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 96 TRAINING SUMMARY:
  Total Loss: 0.5740
  Contrastive: 5.5883
  Reconstruction: 0.0100
  Topological: 0.5730 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0097
  Contrastive: 4.4337
  Reconstruction: 0.0099
  Topological: 5.0087 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 96/300 COMPLETE (45.3s)
Train Loss: 0.5740 (C:5.5883, R:0.0100, T:0.5730)
Val Loss:   5.0097 (C:4.4337, R:0.0099, T:5.0087)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 97 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5832 (C:5.5765, R:0.0099, T:0.5823(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5669 (C:5.5735, R:0.0100, T:0.5659(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5927 (C:5.5533, R:0.0100, T:0.5917(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5725 (C:5.6029, R:0.0100, T:0.5715(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6072 (C:5.5712, R:0.0100, T:0.6062(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5490 (C:5.5899, R:0.0100, T:0.5480(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5374 (C:5.5978, R:0.0100, T:0.5364(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5804 (C:5.5813, R:0.0100, T:0.5794(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5250 (C:5.5406, R:0.0099, T:0.5240(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5893 (C:5.6197, R:0.0099, T:0.5883(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5990 (C:5.5704, R:0.0100, T:0.5980(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5387 (C:5.5747, R:0.0099, T:0.5377(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5725 (C:5.6255, R:0.0099, T:0.5715(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5642 (C:5.6370, R:0.0100, T:0.5632(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5875 (C:5.6089, R:0.0100, T:0.5865(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5781 (C:5.5815, R:0.0100, T:0.5772(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5534 (C:5.6083, R:0.0100, T:0.5524(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5671 (C:5.5866, R:0.0099, T:0.5661(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5412 (C:5.6263, R:0.0099, T:0.5402(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5819 (C:5.5209, R:0.0100, T:0.5809(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5789 (C:5.6088, R:0.0099, T:0.5779(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5503 (C:5.5873, R:0.0099, T:0.5493(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 97 TRAINING SUMMARY:
  Total Loss: 0.5727
  Contrastive: 5.5902
  Reconstruction: 0.0100
  Topological: 0.5717 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0315
  Contrastive: 4.4257
  Reconstruction: 0.0099
  Topological: 5.0305 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 97/300 COMPLETE (45.8s)
Train Loss: 0.5727 (C:5.5902, R:0.0100, T:0.5717)
Val Loss:   5.0315 (C:4.4257, R:0.0099, T:5.0305)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 98 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5652 (C:5.6170, R:0.0100, T:0.5642(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5881 (C:5.5946, R:0.0099, T:0.5871(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5386 (C:5.6138, R:0.0100, T:0.5377(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5903 (C:5.5620, R:0.0099, T:0.5893(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5507 (C:5.6047, R:0.0100, T:0.5497(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5309 (C:5.5758, R:0.0099, T:0.5299(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5724 (C:5.6048, R:0.0100, T:0.5714(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5791 (C:5.5428, R:0.0100, T:0.5781(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5430 (C:5.6027, R:0.0099, T:0.5420(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5625 (C:5.5681, R:0.0099, T:0.5615(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5827 (C:5.5673, R:0.0099, T:0.5817(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5835 (C:5.5757, R:0.0099, T:0.5825(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5628 (C:5.5899, R:0.0100, T:0.5618(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5908 (C:5.6067, R:0.0099, T:0.5898(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5783 (C:5.5869, R:0.0099, T:0.5773(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5939 (C:5.5789, R:0.0099, T:0.5929(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5461 (C:5.6000, R:0.0100, T:0.5451(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5677 (C:5.5652, R:0.0099, T:0.5667(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5681 (C:5.6115, R:0.0100, T:0.5671(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5333 (C:5.5838, R:0.0100, T:0.5323(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5679 (C:5.5927, R:0.0100, T:0.5669(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5574 (C:5.5987, R:0.0100, T:0.5564(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5712

ğŸ“Š EPOCH 98 TRAINING SUMMARY:
  Total Loss: 0.5722
  Contrastive: 5.5889
  Reconstruction: 0.0100
  Topological: 0.5712 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0508
  Contrastive: 4.4272
  Reconstruction: 0.0099
  Topological: 5.0498 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 98/300 COMPLETE (45.9s)
Train Loss: 0.5722 (C:5.5889, R:0.0100, T:0.5712)
Val Loss:   5.0508 (C:4.4272, R:0.0099, T:5.0498)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 99 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5265 (C:5.5924, R:0.0100, T:0.5255(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5816 (C:5.5981, R:0.0100, T:0.5806(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5746 (C:5.5815, R:0.0099, T:0.5736(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5817 (C:5.5170, R:0.0099, T:0.5807(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5444 (C:5.6255, R:0.0100, T:0.5434(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5785 (C:5.6093, R:0.0100, T:0.5775(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5701 (C:5.5967, R:0.0100, T:0.5691(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5448 (C:5.5519, R:0.0100, T:0.5438(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5536 (C:5.5715, R:0.0099, T:0.5526(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5581 (C:5.5541, R:0.0100, T:0.5571(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5859 (C:5.5790, R:0.0099, T:0.5849(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5627 (C:5.5802, R:0.0099, T:0.5617(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5663 (C:5.6008, R:0.0100, T:0.5653(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5847 (C:5.5367, R:0.0100, T:0.5837(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5569 (C:5.6128, R:0.0099, T:0.5559(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6044 (C:5.6043, R:0.0100, T:0.6034(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6001 (C:5.5762, R:0.0099, T:0.5991(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5909 (C:5.6392, R:0.0099, T:0.5899(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5900 (C:5.5617, R:0.0100, T:0.5890(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5815 (C:5.6281, R:0.0100, T:0.5805(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6044 (C:5.5901, R:0.0099, T:0.6034(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6050 (C:5.6099, R:0.0100, T:0.6040(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5711

ğŸ“Š EPOCH 99 TRAINING SUMMARY:
  Total Loss: 0.5721
  Contrastive: 5.5887
  Reconstruction: 0.0100
  Topological: 0.5711 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0408
  Contrastive: 4.4263
  Reconstruction: 0.0099
  Topological: 5.0399 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 99/300 COMPLETE (46.1s)
Train Loss: 0.5721 (C:5.5887, R:0.0100, T:0.5711)
Val Loss:   5.0408 (C:4.4263, R:0.0099, T:5.0399)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 100 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5414 (C:5.5709, R:0.0099, T:0.5404(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5590 (C:5.5961, R:0.0099, T:0.5580(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5574 (C:5.6430, R:0.0100, T:0.5564(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5573 (C:5.5877, R:0.0099, T:0.5563(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5696 (C:5.5752, R:0.0099, T:0.5686(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5521 (C:5.6153, R:0.0100, T:0.5511(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6215 (C:5.6135, R:0.0099, T:0.6205(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5814 (C:5.6140, R:0.0100, T:0.5804(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5644 (C:5.5989, R:0.0100, T:0.5634(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5518 (C:5.6222, R:0.0100, T:0.5508(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5726 (C:5.5613, R:0.0099, T:0.5716(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5896 (C:5.6059, R:0.0100, T:0.5886(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5701 (C:5.6079, R:0.0100, T:0.5691(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5754 (C:5.5545, R:0.0100, T:0.5744(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5925 (C:5.6206, R:0.0100, T:0.5915(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5818 (C:5.5685, R:0.0100, T:0.5808(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5658 (C:5.5793, R:0.0099, T:0.5648(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5665 (C:5.6324, R:0.0100, T:0.5655(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5868 (C:5.6147, R:0.0099, T:0.5858(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5871 (C:5.5888, R:0.0100, T:0.5861(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5989 (C:5.6278, R:0.0099, T:0.5979(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5433 (C:5.5834, R:0.0099, T:0.5423(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5704

ğŸ“Š EPOCH 100 TRAINING SUMMARY:
  Total Loss: 0.5714
  Contrastive: 5.5911
  Reconstruction: 0.0100
  Topological: 0.5704 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0912
  Contrastive: 4.4222
  Reconstruction: 0.0099
  Topological: 5.0902 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 100/300 COMPLETE (45.9s)
Train Loss: 0.5714 (C:5.5911, R:0.0100, T:0.5704)
Val Loss:   5.0912 (C:4.4222, R:0.0099, T:5.0902)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 101 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5522 (C:5.5708, R:0.0099, T:0.5512(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5579 (C:5.6075, R:0.0100, T:0.5569(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5339 (C:5.5991, R:0.0099, T:0.5329(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6064 (C:5.5953, R:0.0100, T:0.6054(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5750 (C:5.5761, R:0.0100, T:0.5740(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5830 (C:5.6131, R:0.0100, T:0.5820(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5687 (C:5.6064, R:0.0099, T:0.5677(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5641 (C:5.6161, R:0.0099, T:0.5631(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5760 (C:5.5855, R:0.0099, T:0.5750(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5924 (C:5.5108, R:0.0100, T:0.5914(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5636 (C:5.6104, R:0.0100, T:0.5626(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5518 (C:5.5858, R:0.0100, T:0.5508(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5669 (C:5.6017, R:0.0100, T:0.5659(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5944 (C:5.5776, R:0.0100, T:0.5934(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6125 (C:5.5829, R:0.0099, T:0.6115(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5737 (C:5.5936, R:0.0099, T:0.5727(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6102 (C:5.5464, R:0.0100, T:0.6092(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5765 (C:5.6002, R:0.0099, T:0.5755(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5770 (C:5.5516, R:0.0100, T:0.5760(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5937 (C:5.6151, R:0.0099, T:0.5928(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5553 (C:5.5724, R:0.0099, T:0.5543(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5609 (C:5.6103, R:0.0100, T:0.5599(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5701

ğŸ“Š EPOCH 101 TRAINING SUMMARY:
  Total Loss: 0.5711
  Contrastive: 5.5877
  Reconstruction: 0.0100
  Topological: 0.5701 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0620
  Contrastive: 4.4083
  Reconstruction: 0.0099
  Topological: 5.0610 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 101/300 COMPLETE (44.9s)
Train Loss: 0.5711 (C:5.5877, R:0.0100, T:0.5701)
Val Loss:   5.0620 (C:4.4083, R:0.0099, T:5.0610)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 102 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5834 (C:5.5646, R:0.0100, T:0.5824(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6002 (C:5.6566, R:0.0100, T:0.5992(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5564 (C:5.6341, R:0.0100, T:0.5554(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5830 (C:5.6080, R:0.0100, T:0.5820(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5433 (C:5.5885, R:0.0099, T:0.5423(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5764 (C:5.5954, R:0.0099, T:0.5754(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5588 (C:5.5379, R:0.0100, T:0.5578(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5626 (C:5.6041, R:0.0100, T:0.5616(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5698 (C:5.5765, R:0.0100, T:0.5688(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5874 (C:5.5770, R:0.0100, T:0.5864(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5901 (C:5.6019, R:0.0099, T:0.5891(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5878 (C:5.5648, R:0.0099, T:0.5868(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5737 (C:5.6152, R:0.0100, T:0.5727(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5732 (C:5.6206, R:0.0099, T:0.5722(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5802 (C:5.5870, R:0.0100, T:0.5792(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5712 (C:5.5859, R:0.0100, T:0.5702(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5466 (C:5.5975, R:0.0099, T:0.5456(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5720 (C:5.5752, R:0.0099, T:0.5710(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5502 (C:5.5924, R:0.0099, T:0.5492(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5959 (C:5.6041, R:0.0100, T:0.5949(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5815 (C:5.6160, R:0.0100, T:0.5806(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5816 (C:5.5687, R:0.0099, T:0.5806(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5682

ğŸ“Š EPOCH 102 TRAINING SUMMARY:
  Total Loss: 0.5692
  Contrastive: 5.5903
  Reconstruction: 0.0100
  Topological: 0.5682 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0989
  Contrastive: 4.4003
  Reconstruction: 0.0099
  Topological: 5.0979 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 102/300 COMPLETE (45.2s)
Train Loss: 0.5692 (C:5.5903, R:0.0100, T:0.5682)
Val Loss:   5.0989 (C:4.4003, R:0.0099, T:5.0979)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 103 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5975 (C:5.5714, R:0.0099, T:0.5965(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5498 (C:5.5846, R:0.0099, T:0.5488(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5784 (C:5.5990, R:0.0099, T:0.5774(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5564 (C:5.5817, R:0.0099, T:0.5554(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5734 (C:5.6251, R:0.0100, T:0.5724(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5772 (C:5.6096, R:0.0099, T:0.5762(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5485 (C:5.5623, R:0.0099, T:0.5475(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5877 (C:5.6135, R:0.0099, T:0.5868(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5972 (C:5.5480, R:0.0099, T:0.5962(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5539 (C:5.6293, R:0.0100, T:0.5529(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5714 (C:5.5938, R:0.0099, T:0.5704(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5876 (C:5.5822, R:0.0100, T:0.5866(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5550 (C:5.5895, R:0.0100, T:0.5540(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5946 (C:5.5795, R:0.0100, T:0.5936(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5977 (C:5.5952, R:0.0100, T:0.5967(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5445 (C:5.6113, R:0.0099, T:0.5435(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6014 (C:5.6022, R:0.0100, T:0.6004(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5663 (C:5.5839, R:0.0100, T:0.5653(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5405 (C:5.5597, R:0.0100, T:0.5395(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5798 (C:5.6010, R:0.0099, T:0.5788(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5628 (C:5.6148, R:0.0100, T:0.5618(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6027 (C:5.5908, R:0.0100, T:0.6017(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 103 TRAINING SUMMARY:
  Total Loss: 0.5700
  Contrastive: 5.5909
  Reconstruction: 0.0100
  Topological: 0.5690 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0226
  Contrastive: 4.4221
  Reconstruction: 0.0099
  Topological: 5.0216 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 103/300 COMPLETE (44.7s)
Train Loss: 0.5700 (C:5.5909, R:0.0100, T:0.5690)
Val Loss:   5.0226 (C:4.4221, R:0.0099, T:5.0216)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 104 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5987 (C:5.5787, R:0.0099, T:0.5977(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5797 (C:5.6113, R:0.0100, T:0.5787(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5589 (C:5.5865, R:0.0099, T:0.5579(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5584 (C:5.5889, R:0.0099, T:0.5574(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5678 (C:5.6164, R:0.0100, T:0.5668(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6190 (C:5.5750, R:0.0100, T:0.6180(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5944 (C:5.6232, R:0.0099, T:0.5934(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5576 (C:5.6023, R:0.0100, T:0.5566(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5393 (C:5.6193, R:0.0099, T:0.5383(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5873 (C:5.5951, R:0.0100, T:0.5863(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5533 (C:5.5820, R:0.0099, T:0.5523(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5536 (C:5.6027, R:0.0100, T:0.5526(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5428 (C:5.5739, R:0.0100, T:0.5418(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5490 (C:5.6084, R:0.0099, T:0.5480(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5779 (C:5.5716, R:0.0100, T:0.5769(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5697 (C:5.5422, R:0.0099, T:0.5687(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5792 (C:5.6023, R:0.0099, T:0.5782(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5543 (C:5.5712, R:0.0099, T:0.5533(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5557 (C:5.5953, R:0.0100, T:0.5547(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5845 (C:5.6094, R:0.0099, T:0.5835(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5784 (C:5.6035, R:0.0100, T:0.5774(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5638 (C:5.5924, R:0.0099, T:0.5628(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 104 TRAINING SUMMARY:
  Total Loss: 0.5707
  Contrastive: 5.5895
  Reconstruction: 0.0100
  Topological: 0.5698 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0580
  Contrastive: 4.4073
  Reconstruction: 0.0099
  Topological: 5.0570 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 104/300 COMPLETE (45.3s)
Train Loss: 0.5707 (C:5.5895, R:0.0100, T:0.5698)
Val Loss:   5.0580 (C:4.4073, R:0.0099, T:5.0570)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 105 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5613 (C:5.5602, R:0.0099, T:0.5603(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5889 (C:5.5511, R:0.0099, T:0.5879(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5780 (C:5.5963, R:0.0100, T:0.5770(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5638 (C:5.6004, R:0.0100, T:0.5628(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5919 (C:5.5624, R:0.0100, T:0.5909(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5663 (C:5.5654, R:0.0099, T:0.5653(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6085 (C:5.6000, R:0.0100, T:0.6075(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5913 (C:5.6002, R:0.0099, T:0.5903(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5686 (C:5.5652, R:0.0100, T:0.5676(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5776 (C:5.5562, R:0.0100, T:0.5767(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5494 (C:5.6357, R:0.0100, T:0.5484(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5848 (C:5.6198, R:0.0099, T:0.5838(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5954 (C:5.6026, R:0.0099, T:0.5944(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5875 (C:5.5837, R:0.0100, T:0.5865(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5745 (C:5.5777, R:0.0100, T:0.5736(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5823 (C:5.5285, R:0.0099, T:0.5813(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5548 (C:5.6509, R:0.0100, T:0.5538(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5754 (C:5.5883, R:0.0099, T:0.5745(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5581 (C:5.5616, R:0.0100, T:0.5571(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5670 (C:5.6371, R:0.0100, T:0.5660(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5684 (C:5.5667, R:0.0099, T:0.5674(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5711 (C:5.6074, R:0.0100, T:0.5701(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 105 TRAINING SUMMARY:
  Total Loss: 0.5708
  Contrastive: 5.5914
  Reconstruction: 0.0100
  Topological: 0.5698 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.1386
  Contrastive: 4.3819
  Reconstruction: 0.0099
  Topological: 5.1376 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 105/300 COMPLETE (45.4s)
Train Loss: 0.5708 (C:5.5914, R:0.0100, T:0.5698)
Val Loss:   5.1386 (C:4.3819, R:0.0099, T:5.1376)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 106 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5840 (C:5.5326, R:0.0099, T:0.5830(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5654 (C:5.5721, R:0.0100, T:0.5644(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5759 (C:5.5728, R:0.0099, T:0.5749(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5652 (C:5.5821, R:0.0100, T:0.5642(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5542 (C:5.6488, R:0.0100, T:0.5532(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5779 (C:5.5765, R:0.0099, T:0.5769(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5733 (C:5.5530, R:0.0099, T:0.5724(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5927 (C:5.6011, R:0.0099, T:0.5917(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5864 (C:5.6084, R:0.0100, T:0.5854(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5442 (C:5.5816, R:0.0100, T:0.5433(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5644 (C:5.5736, R:0.0100, T:0.5634(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5702 (C:5.5835, R:0.0100, T:0.5692(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5286 (C:5.6005, R:0.0100, T:0.5276(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5662 (C:5.5524, R:0.0099, T:0.5652(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5824 (C:5.5839, R:0.0100, T:0.5814(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5728 (C:5.5510, R:0.0099, T:0.5718(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5289 (C:5.5475, R:0.0100, T:0.5279(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5832 (C:5.6323, R:0.0099, T:0.5822(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5831 (C:5.5404, R:0.0100, T:0.5821(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5666 (C:5.6018, R:0.0100, T:0.5656(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5462 (C:5.5773, R:0.0099, T:0.5452(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5849 (C:5.5558, R:0.0099, T:0.5840(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5680

ğŸ“Š EPOCH 106 TRAINING SUMMARY:
  Total Loss: 0.5690
  Contrastive: 5.5894
  Reconstruction: 0.0100
  Topological: 0.5680 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9208
  Contrastive: 4.4397
  Reconstruction: 0.0099
  Topological: 4.9198 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 106/300 COMPLETE (45.8s)
Train Loss: 0.5690 (C:5.5894, R:0.0100, T:0.5680)
Val Loss:   4.9208 (C:4.4397, R:0.0099, T:4.9198)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 107 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5881 (C:5.6079, R:0.0099, T:0.5871(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5325 (C:5.5705, R:0.0099, T:0.5315(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6098 (C:5.6062, R:0.0099, T:0.6089(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5719 (C:5.5987, R:0.0100, T:0.5709(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5604 (C:5.6075, R:0.0099, T:0.5594(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5579 (C:5.6212, R:0.0100, T:0.5569(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5733 (C:5.5952, R:0.0099, T:0.5723(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5880 (C:5.6121, R:0.0099, T:0.5870(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5961 (C:5.5961, R:0.0099, T:0.5951(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5663 (C:5.5839, R:0.0099, T:0.5653(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5714 (C:5.6433, R:0.0100, T:0.5704(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5820 (C:5.5880, R:0.0099, T:0.5810(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5728 (C:5.6126, R:0.0100, T:0.5718(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5675 (C:5.5619, R:0.0100, T:0.5665(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5384 (C:5.6294, R:0.0100, T:0.5374(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5524 (C:5.5864, R:0.0099, T:0.5514(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5572 (C:5.6027, R:0.0100, T:0.5562(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5599 (C:5.5984, R:0.0100, T:0.5589(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5731 (C:5.6059, R:0.0099, T:0.5721(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5655 (C:5.5590, R:0.0100, T:0.5645(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5902 (C:5.6394, R:0.0100, T:0.5892(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5780 (C:5.5909, R:0.0100, T:0.5770(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5659

ğŸ“Š EPOCH 107 TRAINING SUMMARY:
  Total Loss: 0.5669
  Contrastive: 5.5884
  Reconstruction: 0.0100
  Topological: 0.5659 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8715
  Contrastive: 4.4506
  Reconstruction: 0.0099
  Topological: 4.8705 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 107/300 COMPLETE (45.8s)
Train Loss: 0.5669 (C:5.5884, R:0.0100, T:0.5659)
Val Loss:   4.8715 (C:4.4506, R:0.0099, T:4.8705)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 108 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5634 (C:5.6416, R:0.0100, T:0.5624(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5655 (C:5.5507, R:0.0099, T:0.5645(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5798 (C:5.5876, R:0.0099, T:0.5788(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5762 (C:5.5856, R:0.0099, T:0.5752(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5546 (C:5.5992, R:0.0100, T:0.5536(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5362 (C:5.5277, R:0.0099, T:0.5352(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5799 (C:5.6082, R:0.0100, T:0.5789(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5571 (C:5.5674, R:0.0099, T:0.5561(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6050 (C:5.6123, R:0.0100, T:0.6040(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5463 (C:5.5428, R:0.0100, T:0.5453(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5364 (C:5.6368, R:0.0100, T:0.5354(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5434 (C:5.6044, R:0.0099, T:0.5424(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5421 (C:5.6262, R:0.0100, T:0.5411(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5610 (C:5.6004, R:0.0099, T:0.5600(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5577 (C:5.5506, R:0.0099, T:0.5567(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5785 (C:5.6214, R:0.0100, T:0.5775(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5675 (C:5.6057, R:0.0099, T:0.5665(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5753 (C:5.6006, R:0.0100, T:0.5743(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5772 (C:5.5925, R:0.0100, T:0.5762(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5491 (C:5.5756, R:0.0100, T:0.5481(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5499 (C:5.5981, R:0.0099, T:0.5489(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5708 (C:5.5923, R:0.0100, T:0.5698(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 108 TRAINING SUMMARY:
  Total Loss: 0.5677
  Contrastive: 5.5906
  Reconstruction: 0.0100
  Topological: 0.5667 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9972
  Contrastive: 4.4181
  Reconstruction: 0.0099
  Topological: 4.9962 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 108/300 COMPLETE (45.1s)
Train Loss: 0.5677 (C:5.5906, R:0.0100, T:0.5667)
Val Loss:   4.9972 (C:4.4181, R:0.0099, T:4.9962)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 109 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5348 (C:5.5809, R:0.0100, T:0.5338(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5503 (C:5.6504, R:0.0099, T:0.5493(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5598 (C:5.5581, R:0.0100, T:0.5588(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5792 (C:5.5941, R:0.0099, T:0.5782(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5766 (C:5.5838, R:0.0099, T:0.5756(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5559 (C:5.6038, R:0.0100, T:0.5549(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5713 (C:5.5611, R:0.0099, T:0.5703(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5296 (C:5.5734, R:0.0100, T:0.5286(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5511 (C:5.6319, R:0.0099, T:0.5501(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5634 (C:5.5527, R:0.0099, T:0.5625(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5634 (C:5.5683, R:0.0100, T:0.5624(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5814 (C:5.5506, R:0.0100, T:0.5804(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6058 (C:5.5704, R:0.0100, T:0.6048(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5843 (C:5.6110, R:0.0099, T:0.5833(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5824 (C:5.6584, R:0.0100, T:0.5814(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5636 (C:5.5450, R:0.0099, T:0.5626(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5304 (C:5.6142, R:0.0099, T:0.5294(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5915 (C:5.5969, R:0.0099, T:0.5905(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5637 (C:5.5939, R:0.0099, T:0.5627(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5746 (C:5.6072, R:0.0100, T:0.5736(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5553 (C:5.5444, R:0.0100, T:0.5543(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5602 (C:5.5907, R:0.0100, T:0.5592(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 109 TRAINING SUMMARY:
  Total Loss: 0.5684
  Contrastive: 5.5899
  Reconstruction: 0.0100
  Topological: 0.5674 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9269
  Contrastive: 4.4212
  Reconstruction: 0.0099
  Topological: 4.9259 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 109/300 COMPLETE (45.1s)
Train Loss: 0.5684 (C:5.5899, R:0.0100, T:0.5674)
Val Loss:   4.9269 (C:4.4212, R:0.0099, T:4.9259)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 110 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5606 (C:5.5816, R:0.0099, T:0.5596(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5509 (C:5.5691, R:0.0099, T:0.5499(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5674 (C:5.6093, R:0.0100, T:0.5665(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5461 (C:5.5817, R:0.0100, T:0.5451(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5807 (C:5.5917, R:0.0100, T:0.5797(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5917 (C:5.6552, R:0.0100, T:0.5907(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5772 (C:5.5710, R:0.0100, T:0.5762(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5653 (C:5.5814, R:0.0100, T:0.5643(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5545 (C:5.6370, R:0.0100, T:0.5535(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5641 (C:5.5746, R:0.0099, T:0.5631(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5698 (C:5.6063, R:0.0100, T:0.5688(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5618 (C:5.6063, R:0.0100, T:0.5608(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5795 (C:5.6306, R:0.0100, T:0.5785(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5405 (C:5.5719, R:0.0099, T:0.5395(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5861 (C:5.6285, R:0.0099, T:0.5851(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5535 (C:5.6068, R:0.0100, T:0.5525(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5927 (C:5.6096, R:0.0100, T:0.5917(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5470 (C:5.6126, R:0.0100, T:0.5460(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6060 (C:5.6149, R:0.0100, T:0.6050(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5900 (C:5.6172, R:0.0100, T:0.5890(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5702 (C:5.5472, R:0.0099, T:0.5692(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5643 (C:5.5524, R:0.0100, T:0.5633(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 110 TRAINING SUMMARY:
  Total Loss: 0.5678
  Contrastive: 5.5906
  Reconstruction: 0.0100
  Topological: 0.5668 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0632
  Contrastive: 4.4313
  Reconstruction: 0.0099
  Topological: 5.0622 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 110/300 COMPLETE (45.2s)
Train Loss: 0.5678 (C:5.5906, R:0.0100, T:0.5668)
Val Loss:   5.0632 (C:4.4313, R:0.0099, T:5.0622)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 111 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5532 (C:5.5749, R:0.0099, T:0.5522(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5807 (C:5.5689, R:0.0099, T:0.5797(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5669 (C:5.6372, R:0.0099, T:0.5659(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5625 (C:5.5840, R:0.0100, T:0.5616(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5572 (C:5.5988, R:0.0099, T:0.5562(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5537 (C:5.5594, R:0.0099, T:0.5527(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5730 (C:5.6120, R:0.0100, T:0.5720(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5564 (C:5.5473, R:0.0100, T:0.5554(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5566 (C:5.5736, R:0.0099, T:0.5556(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5568 (C:5.5427, R:0.0100, T:0.5558(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5830 (C:5.6181, R:0.0099, T:0.5820(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5717 (C:5.6036, R:0.0100, T:0.5707(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5640 (C:5.5821, R:0.0100, T:0.5630(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5994 (C:5.5827, R:0.0099, T:0.5984(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5892 (C:5.5937, R:0.0100, T:0.5882(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5866 (C:5.6242, R:0.0100, T:0.5856(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5511 (C:5.6185, R:0.0100, T:0.5501(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5714 (C:5.6242, R:0.0100, T:0.5704(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5564 (C:5.6329, R:0.0100, T:0.5554(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5729 (C:5.5851, R:0.0100, T:0.5719(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5362 (C:5.6116, R:0.0099, T:0.5352(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5661 (C:5.5878, R:0.0099, T:0.5651(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5637

ğŸ“Š EPOCH 111 TRAINING SUMMARY:
  Total Loss: 0.5647
  Contrastive: 5.5929
  Reconstruction: 0.0100
  Topological: 0.5637 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9874
  Contrastive: 4.4329
  Reconstruction: 0.0099
  Topological: 4.9864 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 111/300 COMPLETE (45.2s)
Train Loss: 0.5647 (C:5.5929, R:0.0100, T:0.5637)
Val Loss:   4.9874 (C:4.4329, R:0.0099, T:4.9864)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 112 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5809 (C:5.6164, R:0.0100, T:0.5799(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5786 (C:5.6024, R:0.0100, T:0.5776(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5332 (C:5.5584, R:0.0099, T:0.5322(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5551 (C:5.6244, R:0.0099, T:0.5541(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5872 (C:5.6427, R:0.0099, T:0.5862(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5576 (C:5.6031, R:0.0100, T:0.5566(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5867 (C:5.5750, R:0.0100, T:0.5857(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5725 (C:5.5770, R:0.0099, T:0.5715(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5537 (C:5.5944, R:0.0099, T:0.5527(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6042 (C:5.5877, R:0.0100, T:0.6032(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5611 (C:5.6162, R:0.0099, T:0.5601(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5801 (C:5.6364, R:0.0100, T:0.5791(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5847 (C:5.6116, R:0.0099, T:0.5837(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5395 (C:5.5613, R:0.0099, T:0.5385(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5622 (C:5.5609, R:0.0099, T:0.5612(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5569 (C:5.6000, R:0.0099, T:0.5559(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5307 (C:5.5765, R:0.0100, T:0.5297(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5718 (C:5.5861, R:0.0099, T:0.5708(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5603 (C:5.5629, R:0.0100, T:0.5593(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5577 (C:5.5953, R:0.0100, T:0.5567(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5484 (C:5.5716, R:0.0100, T:0.5474(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5732 (C:5.6065, R:0.0100, T:0.5722(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5632

ğŸ“Š EPOCH 112 TRAINING SUMMARY:
  Total Loss: 0.5642
  Contrastive: 5.5904
  Reconstruction: 0.0100
  Topological: 0.5632 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9947
  Contrastive: 4.4049
  Reconstruction: 0.0099
  Topological: 4.9938 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 112/300 COMPLETE (44.6s)
Train Loss: 0.5642 (C:5.5904, R:0.0100, T:0.5632)
Val Loss:   4.9947 (C:4.4049, R:0.0099, T:4.9938)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 113 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5686 (C:5.5553, R:0.0099, T:0.5676(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5446 (C:5.6117, R:0.0099, T:0.5437(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5635 (C:5.5845, R:0.0100, T:0.5625(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5771 (C:5.6054, R:0.0100, T:0.5761(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5797 (C:5.5523, R:0.0099, T:0.5787(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6067 (C:5.6069, R:0.0099, T:0.6057(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6036 (C:5.5654, R:0.0099, T:0.6026(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5427 (C:5.5653, R:0.0100, T:0.5417(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5988 (C:5.6103, R:0.0099, T:0.5978(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5418 (C:5.5999, R:0.0100, T:0.5408(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5622 (C:5.5710, R:0.0100, T:0.5612(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5476 (C:5.5757, R:0.0100, T:0.5466(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5788 (C:5.6064, R:0.0100, T:0.5778(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5673 (C:5.5597, R:0.0100, T:0.5663(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5387 (C:5.5939, R:0.0099, T:0.5377(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5413 (C:5.6032, R:0.0099, T:0.5403(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5667 (C:5.5927, R:0.0099, T:0.5658(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5509 (C:5.6012, R:0.0100, T:0.5499(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5770 (C:5.6143, R:0.0099, T:0.5760(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5566 (C:5.5829, R:0.0099, T:0.5556(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5542 (C:5.6103, R:0.0099, T:0.5532(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5465 (C:5.5960, R:0.0099, T:0.5455(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 113 TRAINING SUMMARY:
  Total Loss: 0.5647
  Contrastive: 5.5916
  Reconstruction: 0.0100
  Topological: 0.5637 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.1674
  Contrastive: 4.3970
  Reconstruction: 0.0099
  Topological: 5.1665 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 113/300 COMPLETE (43.3s)
Train Loss: 0.5647 (C:5.5916, R:0.0100, T:0.5637)
Val Loss:   5.1674 (C:4.3970, R:0.0099, T:5.1665)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 114 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5749 (C:5.5492, R:0.0099, T:0.5739(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5745 (C:5.6150, R:0.0100, T:0.5735(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5541 (C:5.5671, R:0.0099, T:0.5531(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5642 (C:5.5941, R:0.0100, T:0.5632(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5960 (C:5.5534, R:0.0100, T:0.5950(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5611 (C:5.5916, R:0.0099, T:0.5601(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5499 (C:5.6035, R:0.0100, T:0.5489(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5780 (C:5.6286, R:0.0099, T:0.5770(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5657 (C:5.5761, R:0.0099, T:0.5648(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5863 (C:5.6263, R:0.0100, T:0.5853(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5468 (C:5.6220, R:0.0100, T:0.5458(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5537 (C:5.5662, R:0.0100, T:0.5527(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5959 (C:5.5568, R:0.0100, T:0.5949(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5810 (C:5.6050, R:0.0099, T:0.5800(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5645 (C:5.6254, R:0.0100, T:0.5635(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5531 (C:5.6589, R:0.0099, T:0.5521(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5439 (C:5.5746, R:0.0099, T:0.5429(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5515 (C:5.5950, R:0.0099, T:0.5505(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5715 (C:5.5151, R:0.0099, T:0.5705(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5372 (C:5.5978, R:0.0100, T:0.5362(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5429 (C:5.5616, R:0.0099, T:0.5419(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5541 (C:5.5666, R:0.0099, T:0.5531(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 114 TRAINING SUMMARY:
  Total Loss: 0.5664
  Contrastive: 5.5918
  Reconstruction: 0.0100
  Topological: 0.5654 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9549
  Contrastive: 4.4543
  Reconstruction: 0.0099
  Topological: 4.9539 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 114/300 COMPLETE (43.4s)
Train Loss: 0.5664 (C:5.5918, R:0.0100, T:0.5654)
Val Loss:   4.9549 (C:4.4543, R:0.0099, T:4.9539)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 115 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5694 (C:5.6060, R:0.0100, T:0.5684(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5598 (C:5.5612, R:0.0100, T:0.5588(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5802 (C:5.6089, R:0.0100, T:0.5792(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5535 (C:5.5848, R:0.0100, T:0.5525(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5676 (C:5.5830, R:0.0099, T:0.5666(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5569 (C:5.5976, R:0.0100, T:0.5559(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5581 (C:5.5848, R:0.0099, T:0.5572(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5722 (C:5.5896, R:0.0099, T:0.5712(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5682 (C:5.5906, R:0.0099, T:0.5672(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5659 (C:5.5859, R:0.0099, T:0.5649(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5837 (C:5.6010, R:0.0099, T:0.5827(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5585 (C:5.5977, R:0.0100, T:0.5575(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5462 (C:5.6293, R:0.0100, T:0.5452(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5787 (C:5.5435, R:0.0099, T:0.5777(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5565 (C:5.5839, R:0.0099, T:0.5555(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5324 (C:5.5597, R:0.0099, T:0.5314(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5546 (C:5.5517, R:0.0099, T:0.5536(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5619 (C:5.5956, R:0.0099, T:0.5609(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5981 (C:5.5782, R:0.0100, T:0.5971(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5703 (C:5.6278, R:0.0100, T:0.5693(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5719 (C:5.5858, R:0.0100, T:0.5709(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5667 (C:5.6373, R:0.0099, T:0.5657(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 115 TRAINING SUMMARY:
  Total Loss: 0.5669
  Contrastive: 5.5899
  Reconstruction: 0.0100
  Topological: 0.5659 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0067
  Contrastive: 4.4209
  Reconstruction: 0.0099
  Topological: 5.0057 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 115/300 COMPLETE (43.2s)
Train Loss: 0.5669 (C:5.5899, R:0.0100, T:0.5659)
Val Loss:   5.0067 (C:4.4209, R:0.0099, T:5.0057)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 116 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5729 (C:5.5822, R:0.0099, T:0.5719(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5406 (C:5.5736, R:0.0099, T:0.5396(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5327 (C:5.6438, R:0.0100, T:0.5317(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5844 (C:5.6555, R:0.0100, T:0.5834(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5779 (C:5.5731, R:0.0100, T:0.5769(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5383 (C:5.6376, R:0.0100, T:0.5373(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5850 (C:5.5400, R:0.0099, T:0.5840(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5260 (C:5.5558, R:0.0099, T:0.5250(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5699 (C:5.6390, R:0.0100, T:0.5689(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5755 (C:5.5903, R:0.0100, T:0.5745(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5337 (C:5.5810, R:0.0099, T:0.5327(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5431 (C:5.5733, R:0.0100, T:0.5421(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5466 (C:5.5577, R:0.0100, T:0.5456(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5555 (C:5.5708, R:0.0099, T:0.5546(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5478 (C:5.5975, R:0.0100, T:0.5468(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5584 (C:5.5804, R:0.0099, T:0.5574(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5646 (C:5.5831, R:0.0099, T:0.5636(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5665 (C:5.6047, R:0.0100, T:0.5655(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5708 (C:5.5684, R:0.0099, T:0.5698(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5777 (C:5.6162, R:0.0099, T:0.5767(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5752 (C:5.5824, R:0.0100, T:0.5742(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5570 (C:5.5821, R:0.0099, T:0.5560(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 116 TRAINING SUMMARY:
  Total Loss: 0.5660
  Contrastive: 5.5919
  Reconstruction: 0.0100
  Topological: 0.5650 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9517
  Contrastive: 4.4265
  Reconstruction: 0.0099
  Topological: 4.9507 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 116/300 COMPLETE (43.5s)
Train Loss: 0.5660 (C:5.5919, R:0.0100, T:0.5650)
Val Loss:   4.9517 (C:4.4265, R:0.0099, T:4.9507)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 117 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5699 (C:5.5886, R:0.0100, T:0.5689(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5540 (C:5.5824, R:0.0100, T:0.5530(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5915 (C:5.5854, R:0.0100, T:0.5905(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5631 (C:5.5888, R:0.0099, T:0.5621(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5489 (C:5.6360, R:0.0100, T:0.5479(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5663 (C:5.6127, R:0.0100, T:0.5653(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5615 (C:5.5963, R:0.0100, T:0.5605(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5625 (C:5.5881, R:0.0100, T:0.5615(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5669 (C:5.5497, R:0.0100, T:0.5659(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5535 (C:5.5971, R:0.0100, T:0.5525(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5607 (C:5.5366, R:0.0100, T:0.5597(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5945 (C:5.5961, R:0.0099, T:0.5936(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5747 (C:5.5743, R:0.0100, T:0.5737(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5627 (C:5.6083, R:0.0100, T:0.5617(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5394 (C:5.5840, R:0.0099, T:0.5384(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5738 (C:5.5738, R:0.0099, T:0.5728(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5590 (C:5.5884, R:0.0099, T:0.5580(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5792 (C:5.5495, R:0.0099, T:0.5782(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5340 (C:5.6209, R:0.0100, T:0.5330(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5628 (C:5.6134, R:0.0099, T:0.5618(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5956 (C:5.6022, R:0.0100, T:0.5946(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5876 (C:5.5587, R:0.0100, T:0.5866(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 117 TRAINING SUMMARY:
  Total Loss: 0.5644
  Contrastive: 5.5932
  Reconstruction: 0.0100
  Topological: 0.5634 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8379
  Contrastive: 4.4560
  Reconstruction: 0.0099
  Topological: 4.8369 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 117/300 COMPLETE (45.2s)
Train Loss: 0.5644 (C:5.5932, R:0.0100, T:0.5634)
Val Loss:   4.8379 (C:4.4560, R:0.0099, T:4.8369)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 118 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5380 (C:5.6085, R:0.0099, T:0.5370(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5660 (C:5.6154, R:0.0099, T:0.5650(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5392 (C:5.5962, R:0.0100, T:0.5382(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5585 (C:5.6398, R:0.0100, T:0.5575(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5643 (C:5.6112, R:0.0100, T:0.5633(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5723 (C:5.6139, R:0.0100, T:0.5713(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5469 (C:5.6372, R:0.0100, T:0.5459(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5668 (C:5.5534, R:0.0100, T:0.5658(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5696 (C:5.6508, R:0.0100, T:0.5686(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5740 (C:5.5821, R:0.0100, T:0.5730(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5486 (C:5.6040, R:0.0100, T:0.5476(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5593 (C:5.6101, R:0.0099, T:0.5583(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5778 (C:5.5930, R:0.0100, T:0.5768(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5366 (C:5.5994, R:0.0099, T:0.5356(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5809 (C:5.6123, R:0.0099, T:0.5799(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5704 (C:5.5632, R:0.0099, T:0.5694(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5784 (C:5.5931, R:0.0100, T:0.5774(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6045 (C:5.5936, R:0.0100, T:0.6035(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5848 (C:5.5834, R:0.0100, T:0.5838(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5854 (C:5.6349, R:0.0099, T:0.5844(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5741 (C:5.5907, R:0.0100, T:0.5731(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5837 (C:5.6228, R:0.0100, T:0.5827(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5632

ğŸ“Š EPOCH 118 TRAINING SUMMARY:
  Total Loss: 0.5642
  Contrastive: 5.5900
  Reconstruction: 0.0100
  Topological: 0.5632 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9583
  Contrastive: 4.4241
  Reconstruction: 0.0099
  Topological: 4.9573 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 118/300 COMPLETE (45.0s)
Train Loss: 0.5642 (C:5.5900, R:0.0100, T:0.5632)
Val Loss:   4.9583 (C:4.4241, R:0.0099, T:4.9573)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 119 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5519 (C:5.5846, R:0.0100, T:0.5509(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5580 (C:5.6124, R:0.0099, T:0.5570(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5510 (C:5.5369, R:0.0100, T:0.5500(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5862 (C:5.5910, R:0.0099, T:0.5853(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5721 (C:5.5837, R:0.0100, T:0.5711(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5599 (C:5.5817, R:0.0100, T:0.5589(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5745 (C:5.5858, R:0.0100, T:0.5735(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5639 (C:5.5831, R:0.0099, T:0.5629(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5775 (C:5.5937, R:0.0100, T:0.5765(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5980 (C:5.5930, R:0.0099, T:0.5970(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5765 (C:5.5618, R:0.0099, T:0.5755(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5445 (C:5.6229, R:0.0100, T:0.5435(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5515 (C:5.5828, R:0.0100, T:0.5505(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5659 (C:5.5907, R:0.0100, T:0.5649(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5760 (C:5.6178, R:0.0099, T:0.5750(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5879 (C:5.5456, R:0.0099, T:0.5869(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5060 (C:5.5870, R:0.0099, T:0.5050(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5776 (C:5.5907, R:0.0100, T:0.5766(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5639 (C:5.6124, R:0.0099, T:0.5629(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5721 (C:5.6373, R:0.0100, T:0.5711(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5877 (C:5.5743, R:0.0099, T:0.5867(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5828 (C:5.6005, R:0.0099, T:0.5818(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5625

ğŸ“Š EPOCH 119 TRAINING SUMMARY:
  Total Loss: 0.5635
  Contrastive: 5.5908
  Reconstruction: 0.0100
  Topological: 0.5625 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9834
  Contrastive: 4.4268
  Reconstruction: 0.0099
  Topological: 4.9824 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 119/300 COMPLETE (44.6s)
Train Loss: 0.5635 (C:5.5908, R:0.0100, T:0.5625)
Val Loss:   4.9834 (C:4.4268, R:0.0099, T:4.9824)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 120 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5804 (C:5.5904, R:0.0100, T:0.5794(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5532 (C:5.5773, R:0.0099, T:0.5522(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5544 (C:5.5632, R:0.0099, T:0.5534(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5761 (C:5.5929, R:0.0100, T:0.5751(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5641 (C:5.5618, R:0.0100, T:0.5631(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5877 (C:5.5682, R:0.0099, T:0.5867(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5679 (C:5.5562, R:0.0099, T:0.5669(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5708 (C:5.6252, R:0.0100, T:0.5698(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5505 (C:5.5562, R:0.0099, T:0.5495(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5402 (C:5.5962, R:0.0099, T:0.5392(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5274 (C:5.5819, R:0.0100, T:0.5264(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5695 (C:5.5504, R:0.0100, T:0.5685(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5418 (C:5.5913, R:0.0100, T:0.5408(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5610 (C:5.5955, R:0.0100, T:0.5600(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5766 (C:5.6041, R:0.0100, T:0.5756(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5644 (C:5.5903, R:0.0099, T:0.5634(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5487 (C:5.5948, R:0.0099, T:0.5477(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5694 (C:5.5876, R:0.0099, T:0.5684(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5640 (C:5.6087, R:0.0099, T:0.5630(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5335 (C:5.6049, R:0.0100, T:0.5325(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5528 (C:5.5838, R:0.0100, T:0.5518(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5506 (C:5.5727, R:0.0100, T:0.5496(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 120 TRAINING SUMMARY:
  Total Loss: 0.5652
  Contrastive: 5.5922
  Reconstruction: 0.0100
  Topological: 0.5642 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8844
  Contrastive: 4.4642
  Reconstruction: 0.0099
  Topological: 4.8834 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 120/300 COMPLETE (45.4s)
Train Loss: 0.5652 (C:5.5922, R:0.0100, T:0.5642)
Val Loss:   4.8844 (C:4.4642, R:0.0099, T:4.8834)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 121 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5789 (C:5.6425, R:0.0100, T:0.5779(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5528 (C:5.5778, R:0.0100, T:0.5518(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5578 (C:5.5907, R:0.0099, T:0.5568(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5590 (C:5.6037, R:0.0100, T:0.5580(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5792 (C:5.5653, R:0.0099, T:0.5782(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5644 (C:5.6003, R:0.0099, T:0.5634(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5548 (C:5.5823, R:0.0100, T:0.5538(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5628 (C:5.6036, R:0.0100, T:0.5619(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5557 (C:5.6153, R:0.0099, T:0.5547(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5555 (C:5.6051, R:0.0099, T:0.5545(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6043 (C:5.5495, R:0.0100, T:0.6033(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5692 (C:5.6152, R:0.0100, T:0.5682(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5639 (C:5.4958, R:0.0100, T:0.5629(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5556 (C:5.6466, R:0.0099, T:0.5546(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5893 (C:5.5845, R:0.0100, T:0.5883(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5527 (C:5.5927, R:0.0099, T:0.5517(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5462 (C:5.5757, R:0.0099, T:0.5452(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5590 (C:5.5805, R:0.0100, T:0.5580(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5591 (C:5.6309, R:0.0099, T:0.5581(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5383 (C:5.5302, R:0.0099, T:0.5373(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5516 (C:5.5762, R:0.0100, T:0.5506(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5484 (C:5.6412, R:0.0099, T:0.5474(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5620

ğŸ“Š EPOCH 121 TRAINING SUMMARY:
  Total Loss: 0.5630
  Contrastive: 5.5926
  Reconstruction: 0.0100
  Topological: 0.5620 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8740
  Contrastive: 4.4270
  Reconstruction: 0.0099
  Topological: 4.8730 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 121/300 COMPLETE (44.6s)
Train Loss: 0.5630 (C:5.5926, R:0.0100, T:0.5620)
Val Loss:   4.8740 (C:4.4270, R:0.0099, T:4.8730)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 122 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5655 (C:5.5738, R:0.0099, T:0.5645(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5439 (C:5.6196, R:0.0100, T:0.5429(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5550 (C:5.5884, R:0.0100, T:0.5541(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5517 (C:5.5949, R:0.0100, T:0.5507(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5547 (C:5.5985, R:0.0100, T:0.5537(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5439 (C:5.6010, R:0.0100, T:0.5429(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5666 (C:5.6285, R:0.0099, T:0.5656(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5531 (C:5.5748, R:0.0099, T:0.5521(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5858 (C:5.5920, R:0.0099, T:0.5849(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5853 (C:5.5840, R:0.0100, T:0.5843(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5539 (C:5.5779, R:0.0100, T:0.5529(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5343 (C:5.5641, R:0.0100, T:0.5333(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5793 (C:5.6138, R:0.0100, T:0.5783(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5669 (C:5.5504, R:0.0099, T:0.5659(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5801 (C:5.5969, R:0.0100, T:0.5791(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5639 (C:5.5618, R:0.0100, T:0.5629(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5605 (C:5.5824, R:0.0100, T:0.5595(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5970 (C:5.5739, R:0.0099, T:0.5960(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5727 (C:5.5763, R:0.0099, T:0.5717(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5693 (C:5.5963, R:0.0100, T:0.5683(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5787 (C:5.5439, R:0.0100, T:0.5777(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5731 (C:5.5746, R:0.0100, T:0.5721(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5614

ğŸ“Š EPOCH 122 TRAINING SUMMARY:
  Total Loss: 0.5624
  Contrastive: 5.5916
  Reconstruction: 0.0100
  Topological: 0.5614 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9394
  Contrastive: 4.4362
  Reconstruction: 0.0099
  Topological: 4.9384 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 122/300 COMPLETE (45.0s)
Train Loss: 0.5624 (C:5.5916, R:0.0100, T:0.5614)
Val Loss:   4.9394 (C:4.4362, R:0.0099, T:4.9384)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 123 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5456 (C:5.5951, R:0.0100, T:0.5446(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5461 (C:5.6004, R:0.0099, T:0.5452(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5684 (C:5.5413, R:0.0099, T:0.5674(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5805 (C:5.6231, R:0.0100, T:0.5795(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5509 (C:5.5918, R:0.0100, T:0.5499(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5641 (C:5.6177, R:0.0100, T:0.5631(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5688 (C:5.5933, R:0.0099, T:0.5678(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5615 (C:5.6029, R:0.0100, T:0.5605(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5581 (C:5.6423, R:0.0099, T:0.5572(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5790 (C:5.5968, R:0.0099, T:0.5780(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5814 (C:5.6003, R:0.0100, T:0.5804(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5768 (C:5.5658, R:0.0099, T:0.5758(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5541 (C:5.5759, R:0.0099, T:0.5531(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5754 (C:5.5827, R:0.0100, T:0.5744(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5597 (C:5.6494, R:0.0100, T:0.5587(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5521 (C:5.6050, R:0.0100, T:0.5511(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5644 (C:5.5913, R:0.0100, T:0.5634(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5838 (C:5.6150, R:0.0099, T:0.5828(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5727 (C:5.6128, R:0.0099, T:0.5718(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5741 (C:5.6049, R:0.0099, T:0.5731(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5744 (C:5.6018, R:0.0099, T:0.5734(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5420 (C:5.5587, R:0.0100, T:0.5410(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5609

ğŸ“Š EPOCH 123 TRAINING SUMMARY:
  Total Loss: 0.5619
  Contrastive: 5.5933
  Reconstruction: 0.0100
  Topological: 0.5609 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8856
  Contrastive: 4.4480
  Reconstruction: 0.0099
  Topological: 4.8846 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 123/300 COMPLETE (45.4s)
Train Loss: 0.5619 (C:5.5933, R:0.0100, T:0.5609)
Val Loss:   4.8856 (C:4.4480, R:0.0099, T:4.8846)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 124 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5275 (C:5.6122, R:0.0099, T:0.5265(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5591 (C:5.6034, R:0.0100, T:0.5581(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5908 (C:5.5844, R:0.0100, T:0.5898(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5918 (C:5.6295, R:0.0100, T:0.5908(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5855 (C:5.5943, R:0.0100, T:0.5845(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5813 (C:5.5750, R:0.0099, T:0.5803(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5773 (C:5.6370, R:0.0100, T:0.5763(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5490 (C:5.5676, R:0.0099, T:0.5480(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6006 (C:5.5626, R:0.0099, T:0.5996(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5713 (C:5.5779, R:0.0099, T:0.5703(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5849 (C:5.5967, R:0.0100, T:0.5839(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5554 (C:5.5793, R:0.0100, T:0.5544(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5742 (C:5.6108, R:0.0099, T:0.5732(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5472 (C:5.5672, R:0.0100, T:0.5462(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5595 (C:5.5693, R:0.0100, T:0.5585(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5885 (C:5.5940, R:0.0100, T:0.5875(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5465 (C:5.5966, R:0.0100, T:0.5455(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5576 (C:5.5824, R:0.0100, T:0.5566(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5783 (C:5.6245, R:0.0100, T:0.5773(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5988 (C:5.6088, R:0.0099, T:0.5978(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5484 (C:5.5876, R:0.0100, T:0.5474(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5702 (C:5.5615, R:0.0100, T:0.5692(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 124 TRAINING SUMMARY:
  Total Loss: 0.5635
  Contrastive: 5.5925
  Reconstruction: 0.0100
  Topological: 0.5625 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9068
  Contrastive: 4.4420
  Reconstruction: 0.0099
  Topological: 4.9058 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 124/300 COMPLETE (45.6s)
Train Loss: 0.5635 (C:5.5925, R:0.0100, T:0.5625)
Val Loss:   4.9068 (C:4.4420, R:0.0099, T:4.9058)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 125 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5609 (C:5.5931, R:0.0100, T:0.5599(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5505 (C:5.5947, R:0.0100, T:0.5495(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5862 (C:5.5732, R:0.0099, T:0.5852(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5723 (C:5.6296, R:0.0100, T:0.5713(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5828 (C:5.5677, R:0.0100, T:0.5818(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5384 (C:5.5954, R:0.0099, T:0.5374(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5226 (C:5.6124, R:0.0099, T:0.5216(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5621 (C:5.5708, R:0.0099, T:0.5611(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5677 (C:5.5638, R:0.0100, T:0.5667(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5673 (C:5.5966, R:0.0099, T:0.5663(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5644 (C:5.5902, R:0.0100, T:0.5634(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5499 (C:5.6025, R:0.0100, T:0.5489(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5598 (C:5.5478, R:0.0099, T:0.5588(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5393 (C:5.5707, R:0.0099, T:0.5383(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6023 (C:5.6375, R:0.0100, T:0.6013(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5558 (C:5.5913, R:0.0100, T:0.5548(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5531 (C:5.5421, R:0.0099, T:0.5522(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5754 (C:5.6015, R:0.0100, T:0.5744(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5199 (C:5.5649, R:0.0099, T:0.5189(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5551 (C:5.5814, R:0.0099, T:0.5541(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5711 (C:5.5875, R:0.0100, T:0.5701(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5387 (C:5.5774, R:0.0100, T:0.5377(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5599

ğŸ“Š EPOCH 125 TRAINING SUMMARY:
  Total Loss: 0.5609
  Contrastive: 5.5919
  Reconstruction: 0.0100
  Topological: 0.5599 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9773
  Contrastive: 4.4219
  Reconstruction: 0.0099
  Topological: 4.9763 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 125/300 COMPLETE (44.1s)
Train Loss: 0.5609 (C:5.5919, R:0.0100, T:0.5599)
Val Loss:   4.9773 (C:4.4219, R:0.0099, T:4.9763)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 126 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5484 (C:5.5842, R:0.0100, T:0.5474(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5788 (C:5.6047, R:0.0100, T:0.5778(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5873 (C:5.5873, R:0.0099, T:0.5863(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5888 (C:5.5984, R:0.0100, T:0.5878(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5918 (C:5.6576, R:0.0099, T:0.5908(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5785 (C:5.6106, R:0.0100, T:0.5775(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5508 (C:5.6134, R:0.0100, T:0.5498(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5578 (C:5.5818, R:0.0100, T:0.5568(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5776 (C:5.5906, R:0.0100, T:0.5767(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5559 (C:5.6211, R:0.0100, T:0.5549(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5585 (C:5.6298, R:0.0099, T:0.5575(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5657 (C:5.5768, R:0.0100, T:0.5647(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5785 (C:5.5837, R:0.0100, T:0.5775(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5634 (C:5.6189, R:0.0100, T:0.5624(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5633 (C:5.5812, R:0.0100, T:0.5623(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5297 (C:5.6089, R:0.0099, T:0.5287(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5538 (C:5.5497, R:0.0100, T:0.5528(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5847 (C:5.5878, R:0.0099, T:0.5837(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5457 (C:5.6145, R:0.0099, T:0.5447(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5925 (C:5.5491, R:0.0100, T:0.5915(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5560 (C:5.5736, R:0.0100, T:0.5550(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5848 (C:5.5961, R:0.0099, T:0.5838(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 126 TRAINING SUMMARY:
  Total Loss: 0.5611
  Contrastive: 5.5926
  Reconstruction: 0.0100
  Topological: 0.5601 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9700
  Contrastive: 4.4220
  Reconstruction: 0.0099
  Topological: 4.9690 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 126/300 COMPLETE (44.6s)
Train Loss: 0.5611 (C:5.5926, R:0.0100, T:0.5601)
Val Loss:   4.9700 (C:4.4220, R:0.0099, T:4.9690)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 127 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5760 (C:5.5667, R:0.0100, T:0.5751(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5367 (C:5.6152, R:0.0100, T:0.5357(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5721 (C:5.5329, R:0.0099, T:0.5711(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5403 (C:5.5978, R:0.0099, T:0.5393(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5482 (C:5.5533, R:0.0099, T:0.5472(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5362 (C:5.5893, R:0.0099, T:0.5352(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5511 (C:5.6418, R:0.0100, T:0.5501(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5501 (C:5.5957, R:0.0100, T:0.5491(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5677 (C:5.5910, R:0.0099, T:0.5668(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5678 (C:5.5934, R:0.0100, T:0.5668(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5795 (C:5.5788, R:0.0099, T:0.5785(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5462 (C:5.6189, R:0.0099, T:0.5452(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5394 (C:5.5739, R:0.0099, T:0.5384(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5419 (C:5.5968, R:0.0099, T:0.5409(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5351 (C:5.5742, R:0.0099, T:0.5341(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5764 (C:5.6120, R:0.0100, T:0.5754(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5604 (C:5.5962, R:0.0099, T:0.5594(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5797 (C:5.6114, R:0.0099, T:0.5787(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5437 (C:5.6157, R:0.0100, T:0.5427(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5517 (C:5.6168, R:0.0100, T:0.5507(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5636 (C:5.5596, R:0.0100, T:0.5626(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5517 (C:5.5476, R:0.0099, T:0.5508(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5588

ğŸ“Š EPOCH 127 TRAINING SUMMARY:
  Total Loss: 0.5598
  Contrastive: 5.5949
  Reconstruction: 0.0100
  Topological: 0.5588 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8244
  Contrastive: 4.4400
  Reconstruction: 0.0099
  Topological: 4.8234 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 127/300 COMPLETE (46.3s)
Train Loss: 0.5598 (C:5.5949, R:0.0100, T:0.5588)
Val Loss:   4.8244 (C:4.4400, R:0.0099, T:4.8234)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 128 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5592 (C:5.6088, R:0.0100, T:0.5582(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5622 (C:5.5919, R:0.0099, T:0.5612(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5447 (C:5.5448, R:0.0099, T:0.5437(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5734 (C:5.6138, R:0.0100, T:0.5724(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5352 (C:5.5641, R:0.0099, T:0.5342(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5952 (C:5.6384, R:0.0100, T:0.5942(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5622 (C:5.5921, R:0.0099, T:0.5612(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5492 (C:5.6145, R:0.0100, T:0.5482(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5292 (C:5.6046, R:0.0099, T:0.5282(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5502 (C:5.6214, R:0.0099, T:0.5492(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5622 (C:5.5809, R:0.0099, T:0.5612(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5585 (C:5.5808, R:0.0100, T:0.5575(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5372 (C:5.6248, R:0.0099, T:0.5362(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5440 (C:5.6154, R:0.0100, T:0.5430(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5837 (C:5.5895, R:0.0100, T:0.5827(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5553 (C:5.5822, R:0.0099, T:0.5543(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5217 (C:5.5607, R:0.0100, T:0.5207(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5780 (C:5.5524, R:0.0099, T:0.5770(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5358 (C:5.5357, R:0.0100, T:0.5348(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5717 (C:5.6248, R:0.0099, T:0.5707(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5692 (C:5.5501, R:0.0099, T:0.5682(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5544 (C:5.6084, R:0.0100, T:0.5534(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5583

ğŸ“Š EPOCH 128 TRAINING SUMMARY:
  Total Loss: 0.5593
  Contrastive: 5.5936
  Reconstruction: 0.0100
  Topological: 0.5583 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8904
  Contrastive: 4.4370
  Reconstruction: 0.0099
  Topological: 4.8894 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 128/300 COMPLETE (46.4s)
Train Loss: 0.5593 (C:5.5936, R:0.0100, T:0.5583)
Val Loss:   4.8904 (C:4.4370, R:0.0099, T:4.8894)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 129 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5704 (C:5.6061, R:0.0100, T:0.5694(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5608 (C:5.5620, R:0.0099, T:0.5598(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5810 (C:5.6111, R:0.0099, T:0.5800(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5646 (C:5.6035, R:0.0099, T:0.5636(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5644 (C:5.6282, R:0.0100, T:0.5634(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5859 (C:5.5831, R:0.0100, T:0.5849(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5566 (C:5.6231, R:0.0100, T:0.5556(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5618 (C:5.6334, R:0.0100, T:0.5608(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5840 (C:5.5747, R:0.0099, T:0.5830(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5931 (C:5.5524, R:0.0100, T:0.5921(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5455 (C:5.5723, R:0.0100, T:0.5445(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5603 (C:5.6293, R:0.0100, T:0.5593(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5355 (C:5.6094, R:0.0099, T:0.5345(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5596 (C:5.5814, R:0.0100, T:0.5586(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5472 (C:5.5846, R:0.0100, T:0.5462(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5372 (C:5.5909, R:0.0100, T:0.5362(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5630 (C:5.6195, R:0.0100, T:0.5620(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5470 (C:5.5736, R:0.0099, T:0.5460(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5732 (C:5.6176, R:0.0100, T:0.5722(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5782 (C:5.5935, R:0.0099, T:0.5772(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5857 (C:5.5416, R:0.0099, T:0.5848(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5715 (C:5.5314, R:0.0099, T:0.5705(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 129 TRAINING SUMMARY:
  Total Loss: 0.5595
  Contrastive: 5.5931
  Reconstruction: 0.0100
  Topological: 0.5585 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8461
  Contrastive: 4.4295
  Reconstruction: 0.0099
  Topological: 4.8452 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 129/300 COMPLETE (45.8s)
Train Loss: 0.5595 (C:5.5931, R:0.0100, T:0.5585)
Val Loss:   4.8461 (C:4.4295, R:0.0099, T:4.8452)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 130 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5506 (C:5.6160, R:0.0099, T:0.5496(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5434 (C:5.5967, R:0.0100, T:0.5424(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5706 (C:5.5919, R:0.0100, T:0.5696(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5669 (C:5.6314, R:0.0100, T:0.5659(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5442 (C:5.6279, R:0.0099, T:0.5432(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5442 (C:5.5787, R:0.0100, T:0.5432(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5558 (C:5.6086, R:0.0099, T:0.5548(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5574 (C:5.5842, R:0.0100, T:0.5564(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6003 (C:5.6041, R:0.0099, T:0.5993(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5291 (C:5.5485, R:0.0099, T:0.5281(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5385 (C:5.5950, R:0.0100, T:0.5376(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5597 (C:5.5608, R:0.0100, T:0.5587(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5626 (C:5.5808, R:0.0100, T:0.5616(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5671 (C:5.5966, R:0.0099, T:0.5661(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5769 (C:5.6289, R:0.0099, T:0.5759(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5625 (C:5.5661, R:0.0100, T:0.5615(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5697 (C:5.6027, R:0.0100, T:0.5687(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5741 (C:5.5969, R:0.0100, T:0.5731(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5663 (C:5.5977, R:0.0099, T:0.5653(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5419 (C:5.5682, R:0.0099, T:0.5409(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5757 (C:5.5674, R:0.0100, T:0.5747(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5516 (C:5.6015, R:0.0099, T:0.5506(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 130 TRAINING SUMMARY:
  Total Loss: 0.5595
  Contrastive: 5.5913
  Reconstruction: 0.0100
  Topological: 0.5585 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9688
  Contrastive: 4.4137
  Reconstruction: 0.0099
  Topological: 4.9678 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 130/300 COMPLETE (44.9s)
Train Loss: 0.5595 (C:5.5913, R:0.0100, T:0.5585)
Val Loss:   4.9688 (C:4.4137, R:0.0099, T:4.9678)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 131 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5434 (C:5.5769, R:0.0100, T:0.5424(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5620 (C:5.5481, R:0.0099, T:0.5611(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5820 (C:5.6121, R:0.0100, T:0.5810(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5580 (C:5.5975, R:0.0100, T:0.5570(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5850 (C:5.6375, R:0.0100, T:0.5840(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5986 (C:5.5922, R:0.0100, T:0.5976(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5416 (C:5.5604, R:0.0100, T:0.5406(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5720 (C:5.5763, R:0.0100, T:0.5710(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5556 (C:5.5896, R:0.0099, T:0.5546(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5425 (C:5.5583, R:0.0100, T:0.5415(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5755 (C:5.6128, R:0.0099, T:0.5745(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5265 (C:5.6079, R:0.0099, T:0.5255(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5482 (C:5.5838, R:0.0099, T:0.5472(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5852 (C:5.6128, R:0.0100, T:0.5842(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5467 (C:5.5877, R:0.0100, T:0.5457(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5500 (C:5.6048, R:0.0100, T:0.5490(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5793 (C:5.5637, R:0.0099, T:0.5783(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5750 (C:5.6049, R:0.0100, T:0.5740(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5516 (C:5.5795, R:0.0099, T:0.5506(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5400 (C:5.5696, R:0.0100, T:0.5390(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5325 (C:5.6313, R:0.0100, T:0.5315(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5760 (C:5.5933, R:0.0100, T:0.5750(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 131 TRAINING SUMMARY:
  Total Loss: 0.5602
  Contrastive: 5.5921
  Reconstruction: 0.0100
  Topological: 0.5592 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8833
  Contrastive: 4.4396
  Reconstruction: 0.0099
  Topological: 4.8823 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 131/300 COMPLETE (44.6s)
Train Loss: 0.5602 (C:5.5921, R:0.0100, T:0.5592)
Val Loss:   4.8833 (C:4.4396, R:0.0099, T:4.8823)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 132 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5691 (C:5.5841, R:0.0100, T:0.5681(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5713 (C:5.6397, R:0.0100, T:0.5703(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5782 (C:5.5939, R:0.0100, T:0.5772(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5838 (C:5.5564, R:0.0099, T:0.5828(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5517 (C:5.5704, R:0.0100, T:0.5507(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5692 (C:5.6070, R:0.0100, T:0.5682(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5596 (C:5.5854, R:0.0099, T:0.5586(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5675 (C:5.5362, R:0.0100, T:0.5665(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5691 (C:5.6194, R:0.0100, T:0.5681(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5611 (C:5.6126, R:0.0100, T:0.5601(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5830 (C:5.6109, R:0.0100, T:0.5820(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5692 (C:5.5345, R:0.0099, T:0.5682(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5354 (C:5.6338, R:0.0099, T:0.5344(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5430 (C:5.5744, R:0.0100, T:0.5420(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5602 (C:5.6011, R:0.0100, T:0.5592(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5395 (C:5.5670, R:0.0100, T:0.5386(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5465 (C:5.6347, R:0.0099, T:0.5455(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5553 (C:5.5705, R:0.0099, T:0.5543(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5376 (C:5.5928, R:0.0100, T:0.5366(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5425 (C:5.6458, R:0.0099, T:0.5415(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5851 (C:5.6158, R:0.0100, T:0.5841(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5527 (C:5.5775, R:0.0099, T:0.5517(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 132 TRAINING SUMMARY:
  Total Loss: 0.5601
  Contrastive: 5.5926
  Reconstruction: 0.0100
  Topological: 0.5591 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9686
  Contrastive: 4.4058
  Reconstruction: 0.0099
  Topological: 4.9676 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 132/300 COMPLETE (45.3s)
Train Loss: 0.5601 (C:5.5926, R:0.0100, T:0.5591)
Val Loss:   4.9686 (C:4.4058, R:0.0099, T:4.9676)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 133 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5564 (C:5.5594, R:0.0100, T:0.5554(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5345 (C:5.5931, R:0.0099, T:0.5335(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5897 (C:5.5760, R:0.0099, T:0.5887(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5490 (C:5.6065, R:0.0100, T:0.5480(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5831 (C:5.5652, R:0.0099, T:0.5821(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5535 (C:5.5946, R:0.0100, T:0.5525(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5284 (C:5.6011, R:0.0099, T:0.5274(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5770 (C:5.6079, R:0.0100, T:0.5760(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5677 (C:5.6050, R:0.0099, T:0.5667(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5670 (C:5.6400, R:0.0100, T:0.5660(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5592 (C:5.6019, R:0.0100, T:0.5582(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5737 (C:5.5901, R:0.0099, T:0.5727(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5387 (C:5.5698, R:0.0099, T:0.5377(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5366 (C:5.5986, R:0.0099, T:0.5356(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5745 (C:5.5870, R:0.0099, T:0.5735(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5572 (C:5.5761, R:0.0100, T:0.5562(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5589 (C:5.6087, R:0.0100, T:0.5579(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5828 (C:5.5824, R:0.0100, T:0.5818(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5601 (C:5.6252, R:0.0100, T:0.5591(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5544 (C:5.5565, R:0.0099, T:0.5534(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5456 (C:5.5943, R:0.0099, T:0.5446(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5574 (C:5.5407, R:0.0099, T:0.5564(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 133 TRAINING SUMMARY:
  Total Loss: 0.5594
  Contrastive: 5.5947
  Reconstruction: 0.0100
  Topological: 0.5584 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8615
  Contrastive: 4.4287
  Reconstruction: 0.0099
  Topological: 4.8605 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 133/300 COMPLETE (45.0s)
Train Loss: 0.5594 (C:5.5947, R:0.0100, T:0.5584)
Val Loss:   4.8615 (C:4.4287, R:0.0099, T:4.8605)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 134 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5537 (C:5.5729, R:0.0100, T:0.5528(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6062 (C:5.5748, R:0.0099, T:0.6052(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5510 (C:5.6435, R:0.0099, T:0.5500(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5864 (C:5.5996, R:0.0100, T:0.5854(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5554 (C:5.5769, R:0.0100, T:0.5544(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5685 (C:5.5827, R:0.0099, T:0.5675(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5624 (C:5.5873, R:0.0100, T:0.5614(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5435 (C:5.5919, R:0.0100, T:0.5425(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5825 (C:5.5550, R:0.0099, T:0.5815(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5435 (C:5.5998, R:0.0100, T:0.5425(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5462 (C:5.6172, R:0.0100, T:0.5452(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5583 (C:5.5516, R:0.0099, T:0.5573(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5671 (C:5.5845, R:0.0099, T:0.5661(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5526 (C:5.5953, R:0.0099, T:0.5516(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5398 (C:5.6252, R:0.0100, T:0.5388(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5696 (C:5.5363, R:0.0099, T:0.5686(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5719 (C:5.6055, R:0.0100, T:0.5709(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5716 (C:5.5621, R:0.0099, T:0.5706(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5491 (C:5.6065, R:0.0100, T:0.5481(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5661 (C:5.5727, R:0.0099, T:0.5652(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5506 (C:5.5536, R:0.0099, T:0.5496(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5342 (C:5.5844, R:0.0100, T:0.5332(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 134 TRAINING SUMMARY:
  Total Loss: 0.5600
  Contrastive: 5.5914
  Reconstruction: 0.0100
  Topological: 0.5590 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9481
  Contrastive: 4.4179
  Reconstruction: 0.0099
  Topological: 4.9471 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 134/300 COMPLETE (44.5s)
Train Loss: 0.5600 (C:5.5914, R:0.0100, T:0.5590)
Val Loss:   4.9481 (C:4.4179, R:0.0099, T:4.9471)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 135 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5728 (C:5.5829, R:0.0100, T:0.5718(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5869 (C:5.5706, R:0.0100, T:0.5859(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5529 (C:5.6090, R:0.0100, T:0.5519(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5560 (C:5.5959, R:0.0100, T:0.5550(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5442 (C:5.5528, R:0.0100, T:0.5432(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5752 (C:5.6853, R:0.0100, T:0.5742(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5250 (C:5.6064, R:0.0100, T:0.5240(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5469 (C:5.5605, R:0.0099, T:0.5459(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5537 (C:5.6460, R:0.0099, T:0.5527(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5712 (C:5.5527, R:0.0100, T:0.5702(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5562 (C:5.5979, R:0.0099, T:0.5552(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5713 (C:5.6363, R:0.0099, T:0.5704(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5841 (C:5.5966, R:0.0100, T:0.5831(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5486 (C:5.5707, R:0.0099, T:0.5476(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6154 (C:5.6518, R:0.0100, T:0.6144(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5703 (C:5.5491, R:0.0100, T:0.5693(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5769 (C:5.6225, R:0.0100, T:0.5759(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5336 (C:5.5825, R:0.0099, T:0.5326(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5335 (C:5.6006, R:0.0099, T:0.5325(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5539 (C:5.5324, R:0.0099, T:0.5529(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5882 (C:5.5627, R:0.0099, T:0.5873(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5500 (C:5.6332, R:0.0100, T:0.5490(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 135 TRAINING SUMMARY:
  Total Loss: 0.5601
  Contrastive: 5.5931
  Reconstruction: 0.0100
  Topological: 0.5591 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8851
  Contrastive: 4.4262
  Reconstruction: 0.0099
  Topological: 4.8841 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 135/300 COMPLETE (44.1s)
Train Loss: 0.5601 (C:5.5931, R:0.0100, T:0.5591)
Val Loss:   4.8851 (C:4.4262, R:0.0099, T:4.8841)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 136 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5755 (C:5.5942, R:0.0100, T:0.5745(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5721 (C:5.5974, R:0.0100, T:0.5711(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5563 (C:5.6120, R:0.0100, T:0.5553(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5538 (C:5.5614, R:0.0099, T:0.5528(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5459 (C:5.5882, R:0.0100, T:0.5449(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5561 (C:5.6242, R:0.0100, T:0.5551(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5488 (C:5.5694, R:0.0100, T:0.5478(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5727 (C:5.6332, R:0.0100, T:0.5717(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5665 (C:5.5782, R:0.0100, T:0.5655(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5324 (C:5.6071, R:0.0100, T:0.5314(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5294 (C:5.5813, R:0.0100, T:0.5284(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5599 (C:5.6198, R:0.0100, T:0.5589(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5352 (C:5.5956, R:0.0099, T:0.5342(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5424 (C:5.6182, R:0.0099, T:0.5414(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5697 (C:5.5531, R:0.0099, T:0.5687(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5568 (C:5.6074, R:0.0099, T:0.5558(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5409 (C:5.6005, R:0.0100, T:0.5399(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5604 (C:5.6260, R:0.0100, T:0.5594(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5784 (C:5.5932, R:0.0100, T:0.5774(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5558 (C:5.5444, R:0.0099, T:0.5548(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5759 (C:5.6110, R:0.0100, T:0.5749(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5510 (C:5.5690, R:0.0099, T:0.5500(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5576

ğŸ“Š EPOCH 136 TRAINING SUMMARY:
  Total Loss: 0.5586
  Contrastive: 5.5936
  Reconstruction: 0.0100
  Topological: 0.5576 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8256
  Contrastive: 4.4311
  Reconstruction: 0.0099
  Topological: 4.8246 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 136/300 COMPLETE (45.3s)
Train Loss: 0.5586 (C:5.5936, R:0.0100, T:0.5576)
Val Loss:   4.8256 (C:4.4311, R:0.0099, T:4.8246)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 137 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5670 (C:5.5866, R:0.0099, T:0.5660(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5436 (C:5.5867, R:0.0099, T:0.5426(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5515 (C:5.6054, R:0.0100, T:0.5505(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5249 (C:5.5768, R:0.0099, T:0.5239(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5598 (C:5.6253, R:0.0100, T:0.5588(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5484 (C:5.5964, R:0.0100, T:0.5474(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5342 (C:5.5729, R:0.0100, T:0.5332(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5552 (C:5.6336, R:0.0100, T:0.5542(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5554 (C:5.6179, R:0.0099, T:0.5544(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5700 (C:5.5466, R:0.0099, T:0.5690(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5566 (C:5.5770, R:0.0099, T:0.5556(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5804 (C:5.6035, R:0.0100, T:0.5794(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5669 (C:5.6251, R:0.0100, T:0.5659(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5630 (C:5.6033, R:0.0100, T:0.5620(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5523 (C:5.5588, R:0.0099, T:0.5513(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5677 (C:5.6304, R:0.0100, T:0.5667(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5610 (C:5.5520, R:0.0099, T:0.5600(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5662 (C:5.6221, R:0.0100, T:0.5652(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5445 (C:5.5664, R:0.0100, T:0.5435(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5349 (C:5.6464, R:0.0100, T:0.5339(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5628 (C:5.5891, R:0.0100, T:0.5618(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5624 (C:5.6056, R:0.0100, T:0.5614(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 137 TRAINING SUMMARY:
  Total Loss: 0.5596
  Contrastive: 5.5931
  Reconstruction: 0.0100
  Topological: 0.5586 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9038
  Contrastive: 4.4254
  Reconstruction: 0.0099
  Topological: 4.9028 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 137/300 COMPLETE (45.0s)
Train Loss: 0.5596 (C:5.5931, R:0.0100, T:0.5586)
Val Loss:   4.9038 (C:4.4254, R:0.0099, T:4.9028)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 138 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5584 (C:5.5488, R:0.0099, T:0.5574(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5498 (C:5.6271, R:0.0100, T:0.5488(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5758 (C:5.6257, R:0.0099, T:0.5748(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5495 (C:5.6032, R:0.0100, T:0.5485(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5473 (C:5.5797, R:0.0100, T:0.5463(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5533 (C:5.6241, R:0.0100, T:0.5523(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5279 (C:5.5818, R:0.0099, T:0.5269(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5625 (C:5.6236, R:0.0099, T:0.5615(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5636 (C:5.6048, R:0.0100, T:0.5627(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5734 (C:5.5871, R:0.0100, T:0.5724(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5364 (C:5.6255, R:0.0100, T:0.5354(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5471 (C:5.5870, R:0.0100, T:0.5461(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5765 (C:5.5786, R:0.0099, T:0.5755(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5746 (C:5.5758, R:0.0099, T:0.5736(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5480 (C:5.5720, R:0.0099, T:0.5470(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5738 (C:5.5928, R:0.0099, T:0.5729(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5714 (C:5.5962, R:0.0099, T:0.5704(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5510 (C:5.5751, R:0.0100, T:0.5500(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5640 (C:5.6528, R:0.0099, T:0.5630(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5401 (C:5.5861, R:0.0099, T:0.5391(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5579 (C:5.5734, R:0.0099, T:0.5569(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5711 (C:5.6270, R:0.0100, T:0.5701(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5568

ğŸ“Š EPOCH 138 TRAINING SUMMARY:
  Total Loss: 0.5578
  Contrastive: 5.5933
  Reconstruction: 0.0100
  Topological: 0.5568 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.7948
  Contrastive: 4.4584
  Reconstruction: 0.0099
  Topological: 4.7938 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 138/300 COMPLETE (45.8s)
Train Loss: 0.5578 (C:5.5933, R:0.0100, T:0.5568)
Val Loss:   4.7948 (C:4.4584, R:0.0099, T:4.7938)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 139 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5781 (C:5.6251, R:0.0100, T:0.5771(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5360 (C:5.5316, R:0.0099, T:0.5350(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5519 (C:5.5869, R:0.0099, T:0.5509(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5441 (C:5.6252, R:0.0099, T:0.5431(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5725 (C:5.6080, R:0.0100, T:0.5715(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5407 (C:5.5604, R:0.0099, T:0.5397(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5537 (C:5.5515, R:0.0099, T:0.5527(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5644 (C:5.6420, R:0.0100, T:0.5634(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5619 (C:5.5595, R:0.0099, T:0.5609(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5408 (C:5.5982, R:0.0100, T:0.5398(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5685 (C:5.5677, R:0.0099, T:0.5675(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6006 (C:5.5904, R:0.0099, T:0.5996(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5497 (C:5.5747, R:0.0100, T:0.5487(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5658 (C:5.5908, R:0.0099, T:0.5648(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5820 (C:5.6434, R:0.0100, T:0.5810(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5492 (C:5.5805, R:0.0099, T:0.5482(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5361 (C:5.6193, R:0.0100, T:0.5351(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5684 (C:5.5787, R:0.0099, T:0.5674(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5545 (C:5.5938, R:0.0100, T:0.5535(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5520 (C:5.6123, R:0.0100, T:0.5510(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5810 (C:5.6201, R:0.0099, T:0.5800(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5662 (C:5.5681, R:0.0099, T:0.5653(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 139 TRAINING SUMMARY:
  Total Loss: 0.5587
  Contrastive: 5.5902
  Reconstruction: 0.0100
  Topological: 0.5577 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8176
  Contrastive: 4.4612
  Reconstruction: 0.0099
  Topological: 4.8167 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 139/300 COMPLETE (45.3s)
Train Loss: 0.5587 (C:5.5902, R:0.0100, T:0.5577)
Val Loss:   4.8176 (C:4.4612, R:0.0099, T:4.8167)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 140 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5582 (C:5.6147, R:0.0100, T:0.5572(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5871 (C:5.5544, R:0.0100, T:0.5861(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5493 (C:5.5528, R:0.0099, T:0.5484(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5410 (C:5.6027, R:0.0100, T:0.5400(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5481 (C:5.5999, R:0.0100, T:0.5471(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5634 (C:5.5548, R:0.0100, T:0.5624(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5628 (C:5.5995, R:0.0099, T:0.5618(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5610 (C:5.5334, R:0.0099, T:0.5600(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5263 (C:5.6402, R:0.0099, T:0.5253(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5630 (C:5.6185, R:0.0100, T:0.5620(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5639 (C:5.5568, R:0.0099, T:0.5629(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5672 (C:5.6323, R:0.0100, T:0.5662(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5387 (C:5.6260, R:0.0100, T:0.5377(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5652 (C:5.5892, R:0.0100, T:0.5642(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5559 (C:5.5988, R:0.0099, T:0.5549(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5295 (C:5.5711, R:0.0099, T:0.5285(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5784 (C:5.5715, R:0.0100, T:0.5774(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5591 (C:5.6103, R:0.0099, T:0.5581(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5368 (C:5.5527, R:0.0099, T:0.5358(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5598 (C:5.6098, R:0.0099, T:0.5588(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5587 (C:5.6346, R:0.0100, T:0.5577(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5903 (C:5.5484, R:0.0099, T:0.5893(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 140 TRAINING SUMMARY:
  Total Loss: 0.5588
  Contrastive: 5.5928
  Reconstruction: 0.0100
  Topological: 0.5578 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8178
  Contrastive: 4.4759
  Reconstruction: 0.0099
  Topological: 4.8168 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 140/300 COMPLETE (45.7s)
Train Loss: 0.5588 (C:5.5928, R:0.0100, T:0.5578)
Val Loss:   4.8178 (C:4.4759, R:0.0099, T:4.8168)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 141 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5616 (C:5.6588, R:0.0100, T:0.5606(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5491 (C:5.5722, R:0.0099, T:0.5481(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5652 (C:5.5874, R:0.0100, T:0.5642(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5456 (C:5.5866, R:0.0099, T:0.5446(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5381 (C:5.5725, R:0.0099, T:0.5371(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5510 (C:5.5386, R:0.0100, T:0.5500(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5272 (C:5.5282, R:0.0099, T:0.5262(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5913 (C:5.6182, R:0.0100, T:0.5903(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5605 (C:5.5380, R:0.0100, T:0.5595(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5655 (C:5.5802, R:0.0099, T:0.5645(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5674 (C:5.5876, R:0.0100, T:0.5664(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5514 (C:5.5820, R:0.0099, T:0.5504(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5648 (C:5.6043, R:0.0099, T:0.5638(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5735 (C:5.5764, R:0.0100, T:0.5725(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5727 (C:5.5904, R:0.0100, T:0.5717(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5542 (C:5.5838, R:0.0099, T:0.5532(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5840 (C:5.5895, R:0.0100, T:0.5830(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5525 (C:5.5956, R:0.0100, T:0.5515(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5725 (C:5.5794, R:0.0099, T:0.5715(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5262 (C:5.5816, R:0.0100, T:0.5252(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5616 (C:5.6704, R:0.0100, T:0.5606(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6100 (C:5.5732, R:0.0100, T:0.6090(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5564

ğŸ“Š EPOCH 141 TRAINING SUMMARY:
  Total Loss: 0.5574
  Contrastive: 5.5939
  Reconstruction: 0.0100
  Topological: 0.5564 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8228
  Contrastive: 4.4437
  Reconstruction: 0.0099
  Topological: 4.8218 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 141/300 COMPLETE (45.5s)
Train Loss: 0.5574 (C:5.5939, R:0.0100, T:0.5564)
Val Loss:   4.8228 (C:4.4437, R:0.0099, T:4.8218)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 142 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5419 (C:5.5976, R:0.0100, T:0.5409(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5633 (C:5.5889, R:0.0100, T:0.5623(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5615 (C:5.5809, R:0.0099, T:0.5605(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5525 (C:5.5864, R:0.0099, T:0.5515(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5642 (C:5.5728, R:0.0100, T:0.5632(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5714 (C:5.6233, R:0.0100, T:0.5704(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5919 (C:5.6013, R:0.0100, T:0.5909(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5658 (C:5.6182, R:0.0099, T:0.5649(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5611 (C:5.5627, R:0.0099, T:0.5601(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5902 (C:5.5883, R:0.0100, T:0.5892(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5553 (C:5.6419, R:0.0099, T:0.5543(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5564 (C:5.5736, R:0.0100, T:0.5554(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5594 (C:5.5933, R:0.0099, T:0.5584(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5744 (C:5.6261, R:0.0100, T:0.5735(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5730 (C:5.6121, R:0.0100, T:0.5720(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5778 (C:5.6107, R:0.0100, T:0.5768(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5867 (C:5.5809, R:0.0100, T:0.5857(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5634 (C:5.5992, R:0.0099, T:0.5624(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5607 (C:5.6081, R:0.0100, T:0.5597(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5710 (C:5.6098, R:0.0099, T:0.5700(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5547 (C:5.5895, R:0.0100, T:0.5537(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5361 (C:5.6908, R:0.0100, T:0.5351(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 142 TRAINING SUMMARY:
  Total Loss: 0.5588
  Contrastive: 5.5943
  Reconstruction: 0.0100
  Topological: 0.5578 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9432
  Contrastive: 4.4149
  Reconstruction: 0.0099
  Topological: 4.9422 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 142/300 COMPLETE (45.0s)
Train Loss: 0.5588 (C:5.5943, R:0.0100, T:0.5578)
Val Loss:   4.9432 (C:4.4149, R:0.0099, T:4.9422)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 143 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5822 (C:5.5786, R:0.0100, T:0.5812(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5587 (C:5.5600, R:0.0099, T:0.5577(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5799 (C:5.6043, R:0.0099, T:0.5789(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5957 (C:5.6095, R:0.0100, T:0.5947(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5747 (C:5.6048, R:0.0100, T:0.5737(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5595 (C:5.5839, R:0.0099, T:0.5585(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5567 (C:5.5946, R:0.0099, T:0.5557(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5496 (C:5.5316, R:0.0099, T:0.5486(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5676 (C:5.5927, R:0.0100, T:0.5666(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5151 (C:5.5671, R:0.0100, T:0.5141(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5668 (C:5.6288, R:0.0099, T:0.5658(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5678 (C:5.5730, R:0.0100, T:0.5668(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5485 (C:5.5744, R:0.0100, T:0.5475(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5490 (C:5.6082, R:0.0100, T:0.5481(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5560 (C:5.5610, R:0.0100, T:0.5550(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5415 (C:5.5771, R:0.0100, T:0.5405(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5890 (C:5.5754, R:0.0099, T:0.5880(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5421 (C:5.5607, R:0.0100, T:0.5411(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5531 (C:5.5863, R:0.0100, T:0.5521(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5609 (C:5.5883, R:0.0100, T:0.5599(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5416 (C:5.5640, R:0.0100, T:0.5406(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5709 (C:5.5857, R:0.0099, T:0.5699(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5557

ğŸ“Š EPOCH 143 TRAINING SUMMARY:
  Total Loss: 0.5567
  Contrastive: 5.5936
  Reconstruction: 0.0100
  Topological: 0.5557 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8982
  Contrastive: 4.4254
  Reconstruction: 0.0099
  Topological: 4.8972 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 143/300 COMPLETE (45.3s)
Train Loss: 0.5567 (C:5.5936, R:0.0100, T:0.5557)
Val Loss:   4.8982 (C:4.4254, R:0.0099, T:4.8972)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 144 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5752 (C:5.5638, R:0.0099, T:0.5742(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5583 (C:5.6228, R:0.0100, T:0.5573(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5699 (C:5.5767, R:0.0099, T:0.5689(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5455 (C:5.5958, R:0.0100, T:0.5445(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5695 (C:5.5536, R:0.0100, T:0.5685(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5460 (C:5.6123, R:0.0100, T:0.5450(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5654 (C:5.6023, R:0.0100, T:0.5644(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5866 (C:5.5797, R:0.0100, T:0.5856(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5359 (C:5.6134, R:0.0100, T:0.5349(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5657 (C:5.6056, R:0.0100, T:0.5647(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5568 (C:5.5694, R:0.0100, T:0.5558(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5592 (C:5.5905, R:0.0100, T:0.5582(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5695 (C:5.5819, R:0.0100, T:0.5685(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5788 (C:5.6426, R:0.0100, T:0.5778(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5675 (C:5.5757, R:0.0100, T:0.5665(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5581 (C:5.6169, R:0.0099, T:0.5571(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5574 (C:5.5811, R:0.0100, T:0.5564(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5600 (C:5.5755, R:0.0099, T:0.5590(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5799 (C:5.5879, R:0.0099, T:0.5789(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5898 (C:5.6141, R:0.0100, T:0.5888(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5626 (C:5.5780, R:0.0099, T:0.5616(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5500 (C:5.5935, R:0.0100, T:0.5490(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 144 TRAINING SUMMARY:
  Total Loss: 0.5584
  Contrastive: 5.5925
  Reconstruction: 0.0100
  Topological: 0.5574 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8825
  Contrastive: 4.4336
  Reconstruction: 0.0099
  Topological: 4.8815 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 144/300 COMPLETE (45.9s)
Train Loss: 0.5584 (C:5.5925, R:0.0100, T:0.5574)
Val Loss:   4.8825 (C:4.4336, R:0.0099, T:4.8815)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 145 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5373 (C:5.5780, R:0.0099, T:0.5363(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5704 (C:5.6028, R:0.0099, T:0.5694(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5482 (C:5.5867, R:0.0099, T:0.5473(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5549 (C:5.6288, R:0.0100, T:0.5539(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5325 (C:5.5584, R:0.0099, T:0.5315(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5600 (C:5.5872, R:0.0100, T:0.5590(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5365 (C:5.5303, R:0.0100, T:0.5355(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5335 (C:5.6137, R:0.0099, T:0.5325(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5341 (C:5.6120, R:0.0100, T:0.5331(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5457 (C:5.5857, R:0.0100, T:0.5447(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5605 (C:5.5992, R:0.0100, T:0.5595(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5502 (C:5.5571, R:0.0100, T:0.5492(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5180 (C:5.5696, R:0.0099, T:0.5170(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5368 (C:5.6107, R:0.0100, T:0.5358(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5717 (C:5.5815, R:0.0099, T:0.5707(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5706 (C:5.5920, R:0.0100, T:0.5696(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5671 (C:5.5947, R:0.0099, T:0.5661(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5721 (C:5.6094, R:0.0100, T:0.5711(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5697 (C:5.6066, R:0.0099, T:0.5687(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5618 (C:5.5800, R:0.0100, T:0.5608(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5558 (C:5.6083, R:0.0100, T:0.5548(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5743 (C:5.5334, R:0.0099, T:0.5733(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 145 TRAINING SUMMARY:
  Total Loss: 0.5572
  Contrastive: 5.5947
  Reconstruction: 0.0100
  Topological: 0.5562 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9645
  Contrastive: 4.4245
  Reconstruction: 0.0099
  Topological: 4.9636 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 145/300 COMPLETE (46.6s)
Train Loss: 0.5572 (C:5.5947, R:0.0100, T:0.5562)
Val Loss:   4.9645 (C:4.4245, R:0.0099, T:4.9636)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 146 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5376 (C:5.5737, R:0.0100, T:0.5366(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5796 (C:5.6180, R:0.0099, T:0.5786(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5505 (C:5.6091, R:0.0100, T:0.5495(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5701 (C:5.5779, R:0.0099, T:0.5691(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5547 (C:5.5875, R:0.0100, T:0.5537(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5444 (C:5.6170, R:0.0100, T:0.5434(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5767 (C:5.5781, R:0.0099, T:0.5757(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5912 (C:5.5886, R:0.0099, T:0.5902(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5619 (C:5.5924, R:0.0100, T:0.5609(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5484 (C:5.5862, R:0.0100, T:0.5474(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5701 (C:5.5557, R:0.0099, T:0.5692(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5597 (C:5.6090, R:0.0100, T:0.5587(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5455 (C:5.6088, R:0.0100, T:0.5445(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5700 (C:5.5966, R:0.0100, T:0.5690(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5643 (C:5.6228, R:0.0099, T:0.5633(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5734 (C:5.5682, R:0.0100, T:0.5724(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5541 (C:5.5986, R:0.0100, T:0.5531(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5381 (C:5.6049, R:0.0100, T:0.5371(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5445 (C:5.5887, R:0.0100, T:0.5435(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5569 (C:5.5424, R:0.0099, T:0.5559(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5257 (C:5.6044, R:0.0100, T:0.5247(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5422 (C:5.5999, R:0.0100, T:0.5412(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5547

ğŸ“Š EPOCH 146 TRAINING SUMMARY:
  Total Loss: 0.5557
  Contrastive: 5.5941
  Reconstruction: 0.0100
  Topological: 0.5547 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.6612
  Contrastive: 4.4727
  Reconstruction: 0.0099
  Topological: 4.6602 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 146/300 COMPLETE (46.4s)
Train Loss: 0.5557 (C:5.5941, R:0.0100, T:0.5547)
Val Loss:   4.6612 (C:4.4727, R:0.0099, T:4.6602)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 147 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5668 (C:5.6436, R:0.0100, T:0.5658(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5605 (C:5.5801, R:0.0100, T:0.5595(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5605 (C:5.5874, R:0.0100, T:0.5595(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5976 (C:5.5388, R:0.0100, T:0.5966(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5406 (C:5.5970, R:0.0099, T:0.5396(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5644 (C:5.6004, R:0.0100, T:0.5634(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5522 (C:5.5597, R:0.0099, T:0.5512(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5382 (C:5.5866, R:0.0099, T:0.5372(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5448 (C:5.6287, R:0.0100, T:0.5438(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5463 (C:5.5443, R:0.0100, T:0.5453(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5729 (C:5.6543, R:0.0099, T:0.5720(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5237 (C:5.5621, R:0.0099, T:0.5227(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5612 (C:5.5757, R:0.0100, T:0.5602(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5553 (C:5.5543, R:0.0099, T:0.5543(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5997 (C:5.6216, R:0.0099, T:0.5987(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5266 (C:5.5528, R:0.0100, T:0.5256(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5258 (C:5.6424, R:0.0100, T:0.5248(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5636 (C:5.6152, R:0.0100, T:0.5626(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5490 (C:5.5799, R:0.0100, T:0.5480(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5547 (C:5.5567, R:0.0099, T:0.5537(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5638 (C:5.5856, R:0.0100, T:0.5628(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5541 (C:5.5660, R:0.0100, T:0.5531(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 147 TRAINING SUMMARY:
  Total Loss: 0.5569
  Contrastive: 5.5928
  Reconstruction: 0.0100
  Topological: 0.5559 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.7999
  Contrastive: 4.4569
  Reconstruction: 0.0099
  Topological: 4.7989 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 147/300 COMPLETE (45.7s)
Train Loss: 0.5569 (C:5.5928, R:0.0100, T:0.5559)
Val Loss:   4.7999 (C:4.4569, R:0.0099, T:4.7989)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 148 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5235 (C:5.6218, R:0.0100, T:0.5225(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5811 (C:5.6282, R:0.0100, T:0.5801(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5833 (C:5.5982, R:0.0099, T:0.5823(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5517 (C:5.5674, R:0.0100, T:0.5507(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5784 (C:5.5890, R:0.0099, T:0.5774(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5781 (C:5.5880, R:0.0100, T:0.5771(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5480 (C:5.6191, R:0.0100, T:0.5470(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5461 (C:5.5605, R:0.0100, T:0.5451(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5488 (C:5.5696, R:0.0099, T:0.5478(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5844 (C:5.6172, R:0.0100, T:0.5834(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5536 (C:5.5798, R:0.0100, T:0.5526(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5323 (C:5.6138, R:0.0099, T:0.5313(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5425 (C:5.5220, R:0.0099, T:0.5416(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6068 (C:5.6274, R:0.0100, T:0.6058(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5375 (C:5.5918, R:0.0100, T:0.5365(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5768 (C:5.6236, R:0.0099, T:0.5758(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5672 (C:5.5638, R:0.0099, T:0.5662(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5581 (C:5.5775, R:0.0099, T:0.5571(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5547 (C:5.6217, R:0.0100, T:0.5537(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5030 (C:5.5221, R:0.0100, T:0.5020(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5630 (C:5.6187, R:0.0099, T:0.5620(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5333 (C:5.5955, R:0.0099, T:0.5323(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 148 TRAINING SUMMARY:
  Total Loss: 0.5560
  Contrastive: 5.5929
  Reconstruction: 0.0100
  Topological: 0.5551 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8370
  Contrastive: 4.4543
  Reconstruction: 0.0099
  Topological: 4.8360 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 148/300 COMPLETE (46.1s)
Train Loss: 0.5560 (C:5.5929, R:0.0100, T:0.5551)
Val Loss:   4.8370 (C:4.4543, R:0.0099, T:4.8360)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 149 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5573 (C:5.6214, R:0.0100, T:0.5563(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5400 (C:5.5583, R:0.0099, T:0.5390(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5919 (C:5.6285, R:0.0100, T:0.5909(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5457 (C:5.6149, R:0.0100, T:0.5447(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5553 (C:5.5821, R:0.0099, T:0.5543(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5688 (C:5.6060, R:0.0099, T:0.5678(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5321 (C:5.5811, R:0.0099, T:0.5312(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5778 (C:5.5656, R:0.0099, T:0.5769(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5563 (C:5.5946, R:0.0099, T:0.5553(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5563 (C:5.5537, R:0.0100, T:0.5553(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5850 (C:5.6008, R:0.0099, T:0.5840(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5580 (C:5.5602, R:0.0100, T:0.5570(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5614 (C:5.6248, R:0.0100, T:0.5604(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5614 (C:5.5664, R:0.0100, T:0.5604(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5808 (C:5.6279, R:0.0100, T:0.5798(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5665 (C:5.5927, R:0.0100, T:0.5655(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5389 (C:5.5954, R:0.0100, T:0.5379(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5574 (C:5.5999, R:0.0100, T:0.5564(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5541 (C:5.5656, R:0.0099, T:0.5531(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5453 (C:5.5856, R:0.0100, T:0.5443(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5593 (C:5.6142, R:0.0099, T:0.5583(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5816 (C:5.5678, R:0.0100, T:0.5806(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5535

ğŸ“Š EPOCH 149 TRAINING SUMMARY:
  Total Loss: 0.5545
  Contrastive: 5.5962
  Reconstruction: 0.0100
  Topological: 0.5535 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.7171
  Contrastive: 4.4737
  Reconstruction: 0.0099
  Topological: 4.7161 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 149/300 COMPLETE (49.5s)
Train Loss: 0.5545 (C:5.5962, R:0.0100, T:0.5535)
Val Loss:   4.7171 (C:4.4737, R:0.0099, T:4.7161)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 150 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5563 (C:5.6384, R:0.0100, T:0.5553(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5606 (C:5.5929, R:0.0099, T:0.5596(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5447 (C:5.6120, R:0.0100, T:0.5437(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5445 (C:5.6080, R:0.0099, T:0.5435(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5460 (C:5.5855, R:0.0100, T:0.5450(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5459 (C:5.6089, R:0.0100, T:0.5449(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5607 (C:5.5806, R:0.0099, T:0.5597(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5606 (C:5.5627, R:0.0099, T:0.5596(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5578 (C:5.6151, R:0.0100, T:0.5568(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5599 (C:5.5920, R:0.0099, T:0.5589(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5443 (C:5.5995, R:0.0099, T:0.5433(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5603 (C:5.5952, R:0.0099, T:0.5593(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5446 (C:5.6148, R:0.0099, T:0.5436(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5281 (C:5.5952, R:0.0100, T:0.5271(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5777 (C:5.6478, R:0.0100, T:0.5767(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5593 (C:5.5576, R:0.0100, T:0.5584(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5685 (C:5.6215, R:0.0099, T:0.5675(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5574 (C:5.5984, R:0.0100, T:0.5564(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5575 (C:5.5884, R:0.0100, T:0.5565(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5746 (C:5.5874, R:0.0099, T:0.5736(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5354 (C:5.5913, R:0.0100, T:0.5344(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5707 (C:5.6446, R:0.0100, T:0.5697(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5522

ğŸ“Š EPOCH 150 TRAINING SUMMARY:
  Total Loss: 0.5532
  Contrastive: 5.5955
  Reconstruction: 0.0100
  Topological: 0.5522 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8423
  Contrastive: 4.4311
  Reconstruction: 0.0099
  Topological: 4.8413 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 150/300 COMPLETE (46.3s)
Train Loss: 0.5532 (C:5.5955, R:0.0100, T:0.5522)
Val Loss:   4.8423 (C:4.4311, R:0.0099, T:4.8413)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 151 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5517 (C:5.5705, R:0.0099, T:0.5507(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5623 (C:5.6331, R:0.0100, T:0.5613(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5420 (C:5.5781, R:0.0100, T:0.5410(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5598 (C:5.5581, R:0.0100, T:0.5588(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5588 (C:5.5856, R:0.0099, T:0.5578(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5300 (C:5.6228, R:0.0099, T:0.5290(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5508 (C:5.5972, R:0.0099, T:0.5498(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5732 (C:5.6126, R:0.0099, T:0.5722(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5732 (C:5.5533, R:0.0100, T:0.5722(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5477 (C:5.5782, R:0.0100, T:0.5467(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5787 (C:5.6002, R:0.0099, T:0.5777(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5685 (C:5.6222, R:0.0099, T:0.5675(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5292 (C:5.5751, R:0.0100, T:0.5282(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5628 (C:5.6442, R:0.0100, T:0.5618(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5325 (C:5.6255, R:0.0100, T:0.5315(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5295 (C:5.5497, R:0.0099, T:0.5285(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5651 (C:5.5929, R:0.0099, T:0.5642(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5474 (C:5.5830, R:0.0099, T:0.5464(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5377 (C:5.5863, R:0.0099, T:0.5367(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5588 (C:5.6448, R:0.0100, T:0.5578(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5342 (C:5.5799, R:0.0099, T:0.5333(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5308 (C:5.5665, R:0.0100, T:0.5298(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 151 TRAINING SUMMARY:
  Total Loss: 0.5534
  Contrastive: 5.5963
  Reconstruction: 0.0100
  Topological: 0.5524 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8381
  Contrastive: 4.4438
  Reconstruction: 0.0099
  Topological: 4.8371 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 151/300 COMPLETE (49.6s)
Train Loss: 0.5534 (C:5.5963, R:0.0100, T:0.5524)
Val Loss:   4.8381 (C:4.4438, R:0.0099, T:4.8371)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 152 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5631 (C:5.6072, R:0.0099, T:0.5621(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5586 (C:5.6145, R:0.0100, T:0.5576(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5639 (C:5.5584, R:0.0099, T:0.5629(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5558 (C:5.5848, R:0.0099, T:0.5548(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5489 (C:5.6080, R:0.0100, T:0.5479(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5466 (C:5.6048, R:0.0099, T:0.5456(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5458 (C:5.6061, R:0.0100, T:0.5448(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5655 (C:5.5878, R:0.0099, T:0.5645(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5253 (C:5.6233, R:0.0099, T:0.5243(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5642 (C:5.5565, R:0.0100, T:0.5632(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5790 (C:5.5982, R:0.0100, T:0.5780(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5358 (C:5.5724, R:0.0099, T:0.5348(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5694 (C:5.6135, R:0.0100, T:0.5684(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5622 (C:5.5899, R:0.0100, T:0.5612(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5549 (C:5.5831, R:0.0099, T:0.5539(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5508 (C:5.5650, R:0.0099, T:0.5499(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5650 (C:5.6014, R:0.0099, T:0.5640(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5403 (C:5.5581, R:0.0099, T:0.5393(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5437 (C:5.5724, R:0.0099, T:0.5427(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5626 (C:5.6030, R:0.0100, T:0.5616(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5712 (C:5.6039, R:0.0099, T:0.5702(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5428 (C:5.6017, R:0.0099, T:0.5418(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 152 TRAINING SUMMARY:
  Total Loss: 0.5543
  Contrastive: 5.5940
  Reconstruction: 0.0100
  Topological: 0.5533 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.6974
  Contrastive: 4.4793
  Reconstruction: 0.0099
  Topological: 4.6964 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 152/300 COMPLETE (48.2s)
Train Loss: 0.5543 (C:5.5940, R:0.0100, T:0.5533)
Val Loss:   4.6974 (C:4.4793, R:0.0099, T:4.6964)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 153 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5516 (C:5.6624, R:0.0100, T:0.5506(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5446 (C:5.6093, R:0.0100, T:0.5436(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5494 (C:5.5682, R:0.0100, T:0.5484(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5488 (C:5.6157, R:0.0099, T:0.5478(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5546 (C:5.5917, R:0.0100, T:0.5536(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5634 (C:5.5872, R:0.0100, T:0.5624(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5610 (C:5.5940, R:0.0100, T:0.5600(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5862 (C:5.6375, R:0.0100, T:0.5852(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5750 (C:5.5647, R:0.0099, T:0.5740(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5416 (C:5.5700, R:0.0099, T:0.5406(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5563 (C:5.5983, R:0.0100, T:0.5553(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5280 (C:5.5963, R:0.0100, T:0.5270(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5406 (C:5.6180, R:0.0100, T:0.5397(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5082 (C:5.6082, R:0.0099, T:0.5072(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5814 (C:5.5995, R:0.0099, T:0.5804(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5577 (C:5.6239, R:0.0100, T:0.5567(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5371 (C:5.6121, R:0.0099, T:0.5361(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5640 (C:5.5388, R:0.0099, T:0.5631(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5604 (C:5.6265, R:0.0099, T:0.5594(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5603 (C:5.5644, R:0.0100, T:0.5594(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5442 (C:5.6025, R:0.0099, T:0.5432(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5558 (C:5.5679, R:0.0099, T:0.5548(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5521

ğŸ“Š EPOCH 153 TRAINING SUMMARY:
  Total Loss: 0.5531
  Contrastive: 5.5965
  Reconstruction: 0.0100
  Topological: 0.5521 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.7342
  Contrastive: 4.4836
  Reconstruction: 0.0099
  Topological: 4.7332 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 153/300 COMPLETE (46.9s)
Train Loss: 0.5531 (C:5.5965, R:0.0100, T:0.5521)
Val Loss:   4.7342 (C:4.4836, R:0.0099, T:4.7332)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 154 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5681 (C:5.6264, R:0.0099, T:0.5671(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5528 (C:5.6094, R:0.0099, T:0.5518(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5323 (C:5.5844, R:0.0100, T:0.5313(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5710 (C:5.5457, R:0.0100, T:0.5700(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5377 (C:5.5845, R:0.0099, T:0.5367(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5339 (C:5.5939, R:0.0100, T:0.5329(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5352 (C:5.6205, R:0.0099, T:0.5342(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5303 (C:5.6014, R:0.0100, T:0.5293(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5584 (C:5.5800, R:0.0099, T:0.5574(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5615 (C:5.5888, R:0.0100, T:0.5605(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5509 (C:5.6193, R:0.0100, T:0.5499(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5624 (C:5.5652, R:0.0100, T:0.5614(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5480 (C:5.6708, R:0.0100, T:0.5470(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5673 (C:5.5695, R:0.0099, T:0.5663(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5662 (C:5.5732, R:0.0100, T:0.5652(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5537 (C:5.5962, R:0.0100, T:0.5527(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5696 (C:5.6329, R:0.0100, T:0.5686(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5285 (C:5.6213, R:0.0099, T:0.5275(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6077 (C:5.6014, R:0.0099, T:0.6067(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5677 (C:5.5875, R:0.0100, T:0.5667(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5510 (C:5.5931, R:0.0100, T:0.5500(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5571 (C:5.5827, R:0.0100, T:0.5561(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5511

ğŸ“Š EPOCH 154 TRAINING SUMMARY:
  Total Loss: 0.5521
  Contrastive: 5.5954
  Reconstruction: 0.0100
  Topological: 0.5511 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8494
  Contrastive: 4.4406
  Reconstruction: 0.0099
  Topological: 4.8484 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 154/300 COMPLETE (49.2s)
Train Loss: 0.5521 (C:5.5954, R:0.0100, T:0.5511)
Val Loss:   4.8494 (C:4.4406, R:0.0099, T:4.8484)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 155 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5360 (C:5.5899, R:0.0099, T:0.5350(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5717 (C:5.6439, R:0.0100, T:0.5707(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5632 (C:5.5418, R:0.0099, T:0.5622(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5409 (C:5.6092, R:0.0099, T:0.5399(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5515 (C:5.6267, R:0.0099, T:0.5505(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5381 (C:5.6401, R:0.0099, T:0.5371(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5598 (C:5.5688, R:0.0100, T:0.5588(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5530 (C:5.5778, R:0.0099, T:0.5520(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5281 (C:5.5744, R:0.0099, T:0.5271(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5373 (C:5.5737, R:0.0100, T:0.5363(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5676 (C:5.5996, R:0.0099, T:0.5666(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5411 (C:5.6007, R:0.0099, T:0.5401(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5168 (C:5.6099, R:0.0099, T:0.5158(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6014 (C:5.6326, R:0.0100, T:0.6004(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5659 (C:5.6099, R:0.0099, T:0.5649(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5708 (C:5.6037, R:0.0100, T:0.5698(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5506 (C:5.5850, R:0.0100, T:0.5496(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5432 (C:5.5555, R:0.0100, T:0.5422(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5360 (C:5.6212, R:0.0099, T:0.5350(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5478 (C:5.5714, R:0.0100, T:0.5468(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5441 (C:5.6313, R:0.0100, T:0.5431(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5696 (C:5.5850, R:0.0100, T:0.5686(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 155 TRAINING SUMMARY:
  Total Loss: 0.5537
  Contrastive: 5.5959
  Reconstruction: 0.0100
  Topological: 0.5527 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.6964
  Contrastive: 4.4815
  Reconstruction: 0.0099
  Topological: 4.6955 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 155/300 COMPLETE (50.0s)
Train Loss: 0.5537 (C:5.5959, R:0.0100, T:0.5527)
Val Loss:   4.6964 (C:4.4815, R:0.0099, T:4.6955)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 156 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5831 (C:5.6561, R:0.0100, T:0.5821(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5483 (C:5.5740, R:0.0099, T:0.5474(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5668 (C:5.6453, R:0.0100, T:0.5658(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5610 (C:5.5891, R:0.0099, T:0.5600(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5458 (C:5.6248, R:0.0100, T:0.5448(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5566 (C:5.6065, R:0.0099, T:0.5557(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6012 (C:5.5607, R:0.0100, T:0.6002(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5625 (C:5.6077, R:0.0100, T:0.5615(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5503 (C:5.5802, R:0.0099, T:0.5493(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5620 (C:5.5730, R:0.0099, T:0.5610(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5371 (C:5.6206, R:0.0100, T:0.5361(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5718 (C:5.6061, R:0.0100, T:0.5708(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5358 (C:5.6222, R:0.0099, T:0.5348(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5409 (C:5.5607, R:0.0099, T:0.5399(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5770 (C:5.6010, R:0.0100, T:0.5760(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5388 (C:5.5685, R:0.0100, T:0.5378(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5613 (C:5.5235, R:0.0099, T:0.5603(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5752 (C:5.6547, R:0.0100, T:0.5742(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5622 (C:5.5111, R:0.0100, T:0.5612(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5987 (C:5.6429, R:0.0100, T:0.5977(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5555 (C:5.5865, R:0.0099, T:0.5545(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5751 (C:5.5940, R:0.0100, T:0.5741(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 156 TRAINING SUMMARY:
  Total Loss: 0.5539
  Contrastive: 5.5953
  Reconstruction: 0.0100
  Topological: 0.5529 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8373
  Contrastive: 4.4597
  Reconstruction: 0.0099
  Topological: 4.8363 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 156/300 COMPLETE (49.6s)
Train Loss: 0.5539 (C:5.5953, R:0.0100, T:0.5529)
Val Loss:   4.8373 (C:4.4597, R:0.0099, T:4.8363)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 157 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5743 (C:5.6465, R:0.0100, T:0.5733(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5482 (C:5.6147, R:0.0099, T:0.5472(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5511 (C:5.6165, R:0.0100, T:0.5501(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5576 (C:5.5914, R:0.0100, T:0.5566(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5505 (C:5.5893, R:0.0099, T:0.5495(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5383 (C:5.5937, R:0.0100, T:0.5373(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5789 (C:5.5799, R:0.0100, T:0.5779(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5408 (C:5.6404, R:0.0099, T:0.5398(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5554 (C:5.5485, R:0.0100, T:0.5544(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5451 (C:5.5959, R:0.0099, T:0.5442(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5300 (C:5.5832, R:0.0100, T:0.5290(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5296 (C:5.5965, R:0.0099, T:0.5286(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5611 (C:5.5718, R:0.0100, T:0.5601(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5571 (C:5.5366, R:0.0100, T:0.5561(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5426 (C:5.6176, R:0.0099, T:0.5416(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5451 (C:5.5677, R:0.0099, T:0.5441(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5565 (C:5.6170, R:0.0100, T:0.5555(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5391 (C:5.5519, R:0.0099, T:0.5381(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5983 (C:5.5985, R:0.0099, T:0.5973(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5534 (C:5.5841, R:0.0099, T:0.5525(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5346 (C:5.5719, R:0.0100, T:0.5336(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5877 (C:5.5923, R:0.0100, T:0.5867(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 157 TRAINING SUMMARY:
  Total Loss: 0.5525
  Contrastive: 5.5968
  Reconstruction: 0.0100
  Topological: 0.5515 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8870
  Contrastive: 4.4181
  Reconstruction: 0.0099
  Topological: 4.8860 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 157/300 COMPLETE (47.7s)
Train Loss: 0.5525 (C:5.5968, R:0.0100, T:0.5515)
Val Loss:   4.8870 (C:4.4181, R:0.0099, T:4.8860)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 158 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5081 (C:5.5789, R:0.0100, T:0.5071(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5481 (C:5.5883, R:0.0100, T:0.5471(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5478 (C:5.6030, R:0.0100, T:0.5468(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5577 (C:5.5959, R:0.0099, T:0.5567(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5562 (C:5.5550, R:0.0099, T:0.5552(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5418 (C:5.5952, R:0.0099, T:0.5408(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5791 (C:5.5615, R:0.0099, T:0.5781(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5902 (C:5.6364, R:0.0100, T:0.5892(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5452 (C:5.5669, R:0.0100, T:0.5442(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5476 (C:5.5736, R:0.0100, T:0.5466(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5278 (C:5.6355, R:0.0100, T:0.5268(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5286 (C:5.6053, R:0.0100, T:0.5276(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5529 (C:5.5752, R:0.0100, T:0.5519(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5762 (C:5.6114, R:0.0100, T:0.5752(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5197 (C:5.6088, R:0.0100, T:0.5187(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5671 (C:5.5925, R:0.0099, T:0.5661(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5519 (C:5.5598, R:0.0100, T:0.5509(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5579 (C:5.5777, R:0.0099, T:0.5569(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5191 (C:5.5349, R:0.0099, T:0.5181(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5782 (C:5.6666, R:0.0100, T:0.5772(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5833 (C:5.6220, R:0.0100, T:0.5823(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5629 (C:5.5546, R:0.0100, T:0.5619(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 158 TRAINING SUMMARY:
  Total Loss: 0.5527
  Contrastive: 5.5949
  Reconstruction: 0.0100
  Topological: 0.5517 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0069
  Contrastive: 4.3940
  Reconstruction: 0.0099
  Topological: 5.0060 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 158/300 COMPLETE (45.5s)
Train Loss: 0.5527 (C:5.5949, R:0.0100, T:0.5517)
Val Loss:   5.0069 (C:4.3940, R:0.0099, T:5.0060)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 159 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5321 (C:5.5663, R:0.0099, T:0.5311(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5235 (C:5.5867, R:0.0099, T:0.5225(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5916 (C:5.5802, R:0.0099, T:0.5906(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5766 (C:5.6099, R:0.0099, T:0.5756(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5047 (C:5.5713, R:0.0100, T:0.5037(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5412 (C:5.6193, R:0.0100, T:0.5402(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5474 (C:5.5590, R:0.0100, T:0.5464(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5261 (C:5.5982, R:0.0100, T:0.5251(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5594 (C:5.5896, R:0.0099, T:0.5584(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5517 (C:5.5649, R:0.0100, T:0.5507(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5664 (C:5.6064, R:0.0099, T:0.5654(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5348 (C:5.5944, R:0.0099, T:0.5338(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5410 (C:5.5837, R:0.0100, T:0.5400(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5495 (C:5.6055, R:0.0099, T:0.5485(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5717 (C:5.5769, R:0.0100, T:0.5707(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5491 (C:5.6598, R:0.0099, T:0.5482(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5192 (C:5.6092, R:0.0100, T:0.5182(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5311 (C:5.6223, R:0.0100, T:0.5301(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5635 (C:5.5650, R:0.0099, T:0.5625(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5604 (C:5.5820, R:0.0099, T:0.5595(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5428 (C:5.6160, R:0.0099, T:0.5418(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5160 (C:5.6143, R:0.0099, T:0.5150(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 159 TRAINING SUMMARY:
  Total Loss: 0.5521
  Contrastive: 5.5949
  Reconstruction: 0.0100
  Topological: 0.5511 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9001
  Contrastive: 4.4102
  Reconstruction: 0.0099
  Topological: 4.8991 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 159/300 COMPLETE (44.6s)
Train Loss: 0.5521 (C:5.5949, R:0.0100, T:0.5511)
Val Loss:   4.9001 (C:4.4102, R:0.0099, T:4.8991)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 160 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5590 (C:5.5520, R:0.0099, T:0.5580(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5692 (C:5.6228, R:0.0100, T:0.5682(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5679 (C:5.5696, R:0.0099, T:0.5669(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5744 (C:5.6439, R:0.0100, T:0.5734(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5656 (C:5.5622, R:0.0100, T:0.5646(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5466 (C:5.6540, R:0.0100, T:0.5456(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5820 (C:5.5741, R:0.0100, T:0.5810(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5770 (C:5.6018, R:0.0099, T:0.5760(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5313 (C:5.5843, R:0.0099, T:0.5303(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5366 (C:5.5848, R:0.0099, T:0.5356(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5393 (C:5.5831, R:0.0099, T:0.5383(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5517 (C:5.5887, R:0.0100, T:0.5507(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5669 (C:5.5909, R:0.0100, T:0.5659(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5219 (C:5.6203, R:0.0099, T:0.5209(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5197 (C:5.5833, R:0.0100, T:0.5187(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5658 (C:5.5995, R:0.0099, T:0.5648(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5203 (C:5.5880, R:0.0099, T:0.5193(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5703 (C:5.5713, R:0.0100, T:0.5693(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5499 (C:5.5881, R:0.0099, T:0.5489(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5624 (C:5.5744, R:0.0099, T:0.5614(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5391 (C:5.5675, R:0.0099, T:0.5381(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5508 (C:5.5896, R:0.0099, T:0.5498(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 160 TRAINING SUMMARY:
  Total Loss: 0.5525
  Contrastive: 5.5933
  Reconstruction: 0.0100
  Topological: 0.5515 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0414
  Contrastive: 4.4084
  Reconstruction: 0.0099
  Topological: 5.0404 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 160/300 COMPLETE (44.6s)
Train Loss: 0.5525 (C:5.5933, R:0.0100, T:0.5515)
Val Loss:   5.0414 (C:4.4084, R:0.0099, T:5.0404)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 161 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5511 (C:5.5643, R:0.0100, T:0.5501(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5315 (C:5.6150, R:0.0100, T:0.5305(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5796 (C:5.6127, R:0.0100, T:0.5786(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5490 (C:5.5803, R:0.0100, T:0.5480(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5838 (C:5.6047, R:0.0100, T:0.5828(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5692 (C:5.5745, R:0.0100, T:0.5682(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5379 (C:5.6074, R:0.0099, T:0.5369(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5400 (C:5.6009, R:0.0100, T:0.5390(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5531 (C:5.6135, R:0.0100, T:0.5521(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5237 (C:5.5763, R:0.0099, T:0.5227(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5505 (C:5.5531, R:0.0099, T:0.5495(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5703 (C:5.6441, R:0.0100, T:0.5693(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5257 (C:5.5921, R:0.0100, T:0.5247(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5367 (C:5.6024, R:0.0100, T:0.5357(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5281 (C:5.6048, R:0.0099, T:0.5271(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5408 (C:5.6201, R:0.0099, T:0.5398(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5696 (C:5.5259, R:0.0100, T:0.5686(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5845 (C:5.5884, R:0.0099, T:0.5835(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5962 (C:5.6293, R:0.0099, T:0.5952(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5323 (C:5.5762, R:0.0099, T:0.5313(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5643 (C:5.5782, R:0.0100, T:0.5633(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5764 (C:5.6026, R:0.0100, T:0.5754(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 161 TRAINING SUMMARY:
  Total Loss: 0.5528
  Contrastive: 5.5950
  Reconstruction: 0.0100
  Topological: 0.5518 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8571
  Contrastive: 4.4442
  Reconstruction: 0.0099
  Topological: 4.8562 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 161/300 COMPLETE (45.2s)
Train Loss: 0.5528 (C:5.5950, R:0.0100, T:0.5518)
Val Loss:   4.8571 (C:4.4442, R:0.0099, T:4.8562)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 162 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5498 (C:5.5784, R:0.0099, T:0.5489(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5717 (C:5.5958, R:0.0100, T:0.5707(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5920 (C:5.6321, R:0.0100, T:0.5910(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5429 (C:5.5545, R:0.0099, T:0.5419(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5613 (C:5.5680, R:0.0099, T:0.5603(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5701 (C:5.6390, R:0.0100, T:0.5691(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5546 (C:5.5838, R:0.0100, T:0.5536(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5476 (C:5.6371, R:0.0100, T:0.5466(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5303 (C:5.5968, R:0.0099, T:0.5294(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5400 (C:5.5722, R:0.0100, T:0.5390(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5526 (C:5.6098, R:0.0100, T:0.5516(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5915 (C:5.6031, R:0.0100, T:0.5905(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5350 (C:5.6169, R:0.0099, T:0.5340(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5298 (C:5.6121, R:0.0099, T:0.5288(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5708 (C:5.5607, R:0.0099, T:0.5698(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5412 (C:5.6150, R:0.0099, T:0.5402(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5363 (C:5.5897, R:0.0099, T:0.5353(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5091 (C:5.5881, R:0.0099, T:0.5081(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5312 (C:5.5754, R:0.0099, T:0.5302(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5162 (C:5.5908, R:0.0100, T:0.5152(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5831 (C:5.6372, R:0.0100, T:0.5821(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5347 (C:5.5817, R:0.0099, T:0.5337(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 162 TRAINING SUMMARY:
  Total Loss: 0.5529
  Contrastive: 5.5957
  Reconstruction: 0.0100
  Topological: 0.5519 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.7279
  Contrastive: 4.4599
  Reconstruction: 0.0099
  Topological: 4.7269 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 162/300 COMPLETE (44.8s)
Train Loss: 0.5529 (C:5.5957, R:0.0100, T:0.5519)
Val Loss:   4.7279 (C:4.4599, R:0.0099, T:4.7269)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 163 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5449 (C:5.6169, R:0.0100, T:0.5439(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5626 (C:5.5509, R:0.0099, T:0.5617(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5355 (C:5.6139, R:0.0100, T:0.5345(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5580 (C:5.5902, R:0.0100, T:0.5570(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5795 (C:5.5967, R:0.0100, T:0.5785(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5455 (C:5.6280, R:0.0100, T:0.5445(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5784 (C:5.5300, R:0.0100, T:0.5774(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5654 (C:5.6445, R:0.0099, T:0.5644(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5729 (C:5.5799, R:0.0099, T:0.5719(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5709 (C:5.5924, R:0.0099, T:0.5699(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5418 (C:5.6000, R:0.0100, T:0.5408(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5696 (C:5.6374, R:0.0100, T:0.5686(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5620 (C:5.5472, R:0.0100, T:0.5610(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5400 (C:5.5978, R:0.0099, T:0.5390(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5401 (C:5.6207, R:0.0100, T:0.5391(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5673 (C:5.5699, R:0.0100, T:0.5663(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5590 (C:5.5969, R:0.0099, T:0.5580(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5426 (C:5.6037, R:0.0099, T:0.5416(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5629 (C:5.5869, R:0.0099, T:0.5619(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5496 (C:5.6117, R:0.0099, T:0.5486(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5664 (C:5.5612, R:0.0099, T:0.5654(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5627 (C:5.5758, R:0.0100, T:0.5617(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 163 TRAINING SUMMARY:
  Total Loss: 0.5535
  Contrastive: 5.5941
  Reconstruction: 0.0100
  Topological: 0.5525 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8198
  Contrastive: 4.4519
  Reconstruction: 0.0099
  Topological: 4.8188 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 163/300 COMPLETE (44.7s)
Train Loss: 0.5535 (C:5.5941, R:0.0100, T:0.5525)
Val Loss:   4.8198 (C:4.4519, R:0.0099, T:4.8188)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 164 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5564 (C:5.6014, R:0.0099, T:0.5554(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5414 (C:5.5552, R:0.0099, T:0.5404(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5739 (C:5.6061, R:0.0100, T:0.5729(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5395 (C:5.5604, R:0.0100, T:0.5385(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5863 (C:5.5800, R:0.0099, T:0.5853(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5271 (C:5.5942, R:0.0100, T:0.5262(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5600 (C:5.5783, R:0.0100, T:0.5590(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5744 (C:5.6428, R:0.0100, T:0.5734(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5578 (C:5.5603, R:0.0100, T:0.5568(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5589 (C:5.5733, R:0.0100, T:0.5579(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5521 (C:5.5829, R:0.0099, T:0.5511(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5518 (C:5.5841, R:0.0099, T:0.5509(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5225 (C:5.5833, R:0.0099, T:0.5215(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5465 (C:5.5744, R:0.0100, T:0.5455(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5532 (C:5.5295, R:0.0099, T:0.5522(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5489 (C:5.6041, R:0.0099, T:0.5479(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5466 (C:5.6213, R:0.0100, T:0.5456(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5447 (C:5.5869, R:0.0100, T:0.5437(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5418 (C:5.5761, R:0.0100, T:0.5408(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5681 (C:5.5860, R:0.0100, T:0.5671(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5459 (C:5.5716, R:0.0100, T:0.5449(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5808 (C:5.6063, R:0.0100, T:0.5798(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5506

ğŸ“Š EPOCH 164 TRAINING SUMMARY:
  Total Loss: 0.5516
  Contrastive: 5.5956
  Reconstruction: 0.0100
  Topological: 0.5506 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8618
  Contrastive: 4.4209
  Reconstruction: 0.0099
  Topological: 4.8608 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 164/300 COMPLETE (44.4s)
Train Loss: 0.5516 (C:5.5956, R:0.0100, T:0.5506)
Val Loss:   4.8618 (C:4.4209, R:0.0099, T:4.8608)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 165 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5512 (C:5.5908, R:0.0099, T:0.5502(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5778 (C:5.5789, R:0.0099, T:0.5768(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5301 (C:5.6386, R:0.0099, T:0.5291(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5601 (C:5.5381, R:0.0099, T:0.5591(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5493 (C:5.6361, R:0.0099, T:0.5483(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5595 (C:5.5445, R:0.0099, T:0.5586(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5694 (C:5.6332, R:0.0100, T:0.5684(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5386 (C:5.5636, R:0.0100, T:0.5376(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5488 (C:5.5968, R:0.0099, T:0.5478(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5831 (C:5.5761, R:0.0099, T:0.5821(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5320 (C:5.5875, R:0.0099, T:0.5310(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5532 (C:5.6346, R:0.0099, T:0.5522(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5412 (C:5.5662, R:0.0100, T:0.5402(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5467 (C:5.6123, R:0.0100, T:0.5457(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5606 (C:5.5715, R:0.0099, T:0.5596(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5480 (C:5.6372, R:0.0100, T:0.5470(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5638 (C:5.6144, R:0.0099, T:0.5628(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5753 (C:5.6427, R:0.0100, T:0.5743(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5517 (C:5.5756, R:0.0100, T:0.5507(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5299 (C:5.5943, R:0.0100, T:0.5289(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5284 (C:5.5778, R:0.0100, T:0.5274(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5474 (C:5.6065, R:0.0100, T:0.5464(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5498

ğŸ“Š EPOCH 165 TRAINING SUMMARY:
  Total Loss: 0.5507
  Contrastive: 5.5958
  Reconstruction: 0.0100
  Topological: 0.5498 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8579
  Contrastive: 4.4416
  Reconstruction: 0.0099
  Topological: 4.8569 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 165/300 COMPLETE (43.4s)
Train Loss: 0.5507 (C:5.5958, R:0.0100, T:0.5498)
Val Loss:   4.8579 (C:4.4416, R:0.0099, T:4.8569)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 166 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5470 (C:5.6024, R:0.0099, T:0.5460(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5672 (C:5.5849, R:0.0100, T:0.5662(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5332 (C:5.6125, R:0.0100, T:0.5322(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5635 (C:5.5989, R:0.0099, T:0.5625(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5284 (C:5.5750, R:0.0099, T:0.5275(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5716 (C:5.5603, R:0.0100, T:0.5706(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5451 (C:5.5940, R:0.0099, T:0.5441(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5891 (C:5.5793, R:0.0099, T:0.5881(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5589 (C:5.5657, R:0.0100, T:0.5579(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5466 (C:5.6098, R:0.0100, T:0.5456(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5650 (C:5.5895, R:0.0100, T:0.5640(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5398 (C:5.5753, R:0.0100, T:0.5388(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5574 (C:5.5659, R:0.0099, T:0.5564(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5573 (C:5.5768, R:0.0100, T:0.5563(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5870 (C:5.5984, R:0.0100, T:0.5860(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5316 (C:5.5922, R:0.0100, T:0.5306(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5651 (C:5.5857, R:0.0099, T:0.5641(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5244 (C:5.6323, R:0.0100, T:0.5234(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5988 (C:5.5597, R:0.0100, T:0.5978(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5466 (C:5.5748, R:0.0100, T:0.5456(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5458 (C:5.5910, R:0.0099, T:0.5448(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5686 (C:5.6101, R:0.0100, T:0.5676(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 166 TRAINING SUMMARY:
  Total Loss: 0.5516
  Contrastive: 5.5949
  Reconstruction: 0.0100
  Topological: 0.5506 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.7918
  Contrastive: 4.4711
  Reconstruction: 0.0099
  Topological: 4.7908 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 166/300 COMPLETE (43.6s)
Train Loss: 0.5516 (C:5.5949, R:0.0100, T:0.5506)
Val Loss:   4.7918 (C:4.4711, R:0.0099, T:4.7908)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

ğŸ›‘ Early stopping triggered after 166 epochs
Best model was at epoch 146 with Val Loss: 4.6612

======================================================================
ğŸ“ˆ FINAL TOPOLOGICAL LEARNING ANALYSIS
======================================================================
First topological learning: Epoch 1
Epochs with topology: 166/166
Max consecutive topology epochs: 166
Best topological loss: 0.5498
Final topological loss: 0.5506
âœ… SUCCESS: Topological learning achieved!
ğŸš€ EXCELLENT: Very consistent topological learning (>80%)
ğŸ“ˆ Topological learning appears stable

======================================================================
ğŸ¯ TOPOLOGICAL AUTOENCODER TRAINING COMPLETED
======================================================================
âœ… Topological training completed successfully!
Saving results...
Loading best model from entailment_surfaces/supervised_contrastive_autoencoder/experiments/topological_autoencoder_torchph_phase1_20250722_115506/checkpoints/best_model.pt
Starting model evaluation...
========================================
GlobalContrastiveEvaluator initialized on cuda
Starting comprehensive evaluation...
============================================================
Extracting latent representations...
  Processed 1/10 batches
Extracted representations: torch.Size([9824, 100])
Evaluating clustering performance...
Clustering Results:
  Silhouette Score: 0.0006
  Adjusted Rand Score: 0.0003
  Clustering Accuracy: 0.3439
Evaluating classification performance...
  Extracting training representations...
Extracting latent representations...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
Extracted representations: torch.Size([547740, 100])
  Extracting validation representations...
Extracting latent representations...
  Processed 1/9 batches
Extracted representations: torch.Size([9180, 100])
Subsampled training to 50000 samples
  Training on 50000 samples, evaluating on 9180 samples
Classification Results:
  Accuracy: 0.5300
  Per-class F1: [0.5724761031818776, 0.4473324213406293, 0.5624615384615385]
Evaluating reconstruction quality...
Reconstruction Results:
  Average MSE: 0.009863
Evaluating separation quality...
Separation Results:
  Positive distances: 4.470 Â± 0.429
  Negative distances: 4.488 Â± 0.418
  Separation ratio: 1.00x
  Gap: -5.823
  Perfect separation: No

Comprehensive evaluation completed!

============================================================
EVALUATION SUMMARY
============================================================
Clustering Performance:
  Silhouette Score: 0.0006
  Clustering Accuracy: 0.3439
  Adjusted Rand Score: 0.0003

Classification Performance:
  Accuracy: 0.5300

Separation Quality:
  Separation Ratio: 1.00x
  Gap: -5.823
  Perfect Separation: False

Reconstruction Quality:
  Average MSE: 0.009863
============================================================
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/topological_autoencoder_torchph_phase1_20250722_115506/results/evaluation_results_20250722_140224.json
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/topological_autoencoder_torchph_phase1_20250722_115506/results/evaluation_results_20250722_140224.json

Key Results:
  Separation ratio: 1.00x
  Perfect separation: False
  Classification accuracy: 0.5300

============================================================
TOPOLOGICAL TRAINING ANALYSIS
============================================================

ğŸ“ˆ TOPOLOGICAL LEARNING DIAGNOSIS:
  Total epochs: 166
  Epochs with topological learning: 166
  Current topological loss: 0.5506
  Current topological weight: 1.0000
  âœ… Topological loss is decreasing (good progress)
ğŸš€ EXCELLENT: Consistent topological learning achieved!
Final topological loss: 0.5506
Epochs with topology: 166/166
âš ï¸  Poor clustering accuracy: 0.344

Final analysis saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/topological_autoencoder_torchph_phase1_20250722_115506/results/final_analysis.json
Experiment saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/topological_autoencoder_torchph_phase1_20250722_115506

Analysis completed with exit code: 0
Time: Tue 22 Jul 14:02:25 BST 2025

=== ANALYSIS SUCCESSFUL ===
Regularization successful!


Job finished.
