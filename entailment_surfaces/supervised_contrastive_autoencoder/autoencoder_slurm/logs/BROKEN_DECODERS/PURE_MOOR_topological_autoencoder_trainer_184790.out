Starting Surface Distance Metric Analysis job...
Job ID: 184790
Node: gpuvm17
Time: Tue 22 Jul 11:54:27 BST 2025
Loading CUDA...
Activating conda environment...
Activated conda environment: /vol/bitbucket/ahb24/tda_entailment_new
Python location: /vol/bitbucket/ahb24/tda_entailment_new/bin/python
Checking GPU availability...
Tue Jul 22 11:54:29 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.133.07             Driver Version: 570.133.07     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla T4                       Off |   00000000:00:06.0 Off |                    0 |
| N/A   30C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+

Testing PyTorch and CUDA...
PyTorch version: 2.4.1
CUDA available: True
CUDA device: Tesla T4
GPU memory: 15.6 GB
PyTorch setup verified!

Starting Topological Training...

============================================================
TOPOLOGICAL AUTOENCODER TRAINING WITH TORCHPH
============================================================
Experiment setup completed:
  Experiment directory: entailment_surfaces/supervised_contrastive_autoencoder/experiments/topological_autoencoder_torchph_phase1_20250722_115437
  Config saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/topological_autoencoder_torchph_phase1_20250722_115437/config.json
Loading data...
========================================
FlexibleEmbedder initialized with type: 'concat'
Output dimension will be: 1536
GlobalDataLoader initialized:
  Embedding type: concat
  Output dimension: 1536
  Sample size: All
Starting data loading pipeline...
============================================================
Loading training data from data/processed/snli_full_standard_SBERT.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 549367 training samples
Loading validation data from data/processed/snli_full_standard_SBERT_validation.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9842 validation samples
Loading test data from data/processed/snli_full_standard_SBERT_test.pt
  Loaded keys: ['premise_embeddings', 'hypothesis_embeddings', 'labels', 'texts', 'metadata']
  Final dataset: 9824 test samples
Generating embeddings for training...
Generating concat embeddings on cuda
Processing 549367 samples in batches of 1000
  Processing batch 1/550
  Processing batch 6/550
  Processing batch 11/550
  Processing batch 16/550
  Processing batch 21/550
  Processing batch 26/550
  Processing batch 31/550
  Processing batch 36/550
  Processing batch 41/550
  Processing batch 46/550
  Processing batch 51/550
  Processing batch 56/550
  Processing batch 61/550
  Processing batch 66/550
  Processing batch 71/550
  Processing batch 76/550
  Processing batch 81/550
  Processing batch 86/550
  Processing batch 91/550
  Processing batch 96/550
  Processing batch 101/550
  Processing batch 106/550
  Processing batch 111/550
  Processing batch 116/550
  Processing batch 121/550
  Processing batch 126/550
  Processing batch 131/550
  Processing batch 136/550
  Processing batch 141/550
  Processing batch 146/550
  Processing batch 151/550
  Processing batch 156/550
  Processing batch 161/550
  Processing batch 166/550
  Processing batch 171/550
  Processing batch 176/550
  Processing batch 181/550
  Processing batch 186/550
  Processing batch 191/550
  Processing batch 196/550
  Processing batch 201/550
  Processing batch 206/550
  Processing batch 211/550
  Processing batch 216/550
  Processing batch 221/550
  Processing batch 226/550
  Processing batch 231/550
  Processing batch 236/550
  Processing batch 241/550
  Processing batch 246/550
  Processing batch 251/550
  Processing batch 256/550
  Processing batch 261/550
  Processing batch 266/550
  Processing batch 271/550
  Processing batch 276/550
  Processing batch 281/550
  Processing batch 286/550
  Processing batch 291/550
  Processing batch 296/550
  Processing batch 301/550
  Processing batch 306/550
  Processing batch 311/550
  Processing batch 316/550
  Processing batch 321/550
  Processing batch 326/550
  Processing batch 331/550
  Processing batch 336/550
  Processing batch 341/550
  Processing batch 346/550
  Processing batch 351/550
  Processing batch 356/550
  Processing batch 361/550
  Processing batch 366/550
  Processing batch 371/550
  Processing batch 376/550
  Processing batch 381/550
  Processing batch 386/550
  Processing batch 391/550
  Processing batch 396/550
  Processing batch 401/550
  Processing batch 406/550
  Processing batch 411/550
  Processing batch 416/550
  Processing batch 421/550
  Processing batch 426/550
  Processing batch 431/550
  Processing batch 436/550
  Processing batch 441/550
  Processing batch 446/550
  Processing batch 451/550
  Processing batch 456/550
  Processing batch 461/550
  Processing batch 466/550
  Processing batch 471/550
  Processing batch 476/550
  Processing batch 481/550
  Processing batch 486/550
  Processing batch 491/550
  Processing batch 496/550
  Processing batch 501/550
  Processing batch 506/550
  Processing batch 511/550
  Processing batch 516/550
  Processing batch 521/550
  Processing batch 526/550
  Processing batch 531/550
  Processing batch 536/550
  Processing batch 541/550
  Processing batch 546/550
Generated concat embeddings: torch.Size([549367, 1536])
Generating embeddings for validation...
Generating concat embeddings on cuda
Processing 9842 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9842, 1536])
Generating embeddings for test...
Generating concat embeddings on cuda
Processing 9824 samples in batches of 1000
  Processing batch 1/10
  Processing batch 6/10
Generated concat embeddings: torch.Size([9824, 1536])
EntailmentDataset created: 549367 samples
  Embedding shape: torch.Size([549367, 1536])
  Class distribution: {'entailment': 183416, 'neutral': 182764, 'contradiction': 183187}
EntailmentDataset created: 9842 samples
  Embedding shape: torch.Size([9842, 1536])
  Class distribution: {'entailment': 3329, 'neutral': 3235, 'contradiction': 3278}
EntailmentDataset created: 9824 samples
  Embedding shape: torch.Size([9824, 1536])
  Class distribution: {'entailment': 3368, 'neutral': 3219, 'contradiction': 3237}

Data loading pipeline completed!
Output embedding dimension: 1536
Updated model input_dim to: 1536
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 537
  Class 2: 183187 samples
  Class 0: 183416 samples
  Class 1: 182764 samples
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class per batch: 340
  Effective batch size: 1020
  Number of batches: 9
  Class 2: 3278 samples
  Class 0: 3329 samples
  Class 1: 3235 samples
DataLoaders created:
  Batch size: 1020
  Balanced sampling: True
  Train batches: 537
  Val batches: 9
  Test batches: 10
Data loading completed!
  Train: 549367 samples, 537 batches
  Val: 9842 samples, 9 batches
  Test: 9824 samples, 10 batches
ContrastiveAutoencoder initialized:
  Input dim: 1536
  Latent dim: 100
  Hidden dims: [1024, 768, 512, 256, 128]
  Dropout rate: 0.2
  Total parameters: 5,865,316
FullDatasetContrastiveLoss initialized:
  Margin: 2.0
  Update frequency: 3 epochs
  Max global samples: 5000
FullDatasetCombinedLoss initialized:
  Contrastive weight: 0.0
  Base reconstruction weight: 0.1
  Scheduled reconstruction: warmup=10 epochs, max_weight=0.3
MoorTopologicalLoss Initialized: Using 0-dimensional persistence pairings (MST edges).
No prototypes being used for topological loss - whole dataset instead.
TopologicalTrainer initialized on device: cuda
Model parameters: 5,865,316
Enhanced with topological loss monitoring
Starting Phase 1: Pure Topological Training
  Contrastive weight: 0.0
  Topological weight: 1.0
  Reconstruction weight: 0.1

======================================================================
ğŸ§  TOPOLOGICAL AUTOENCODER TRAINING STARTED
======================================================================

============================================================
EPOCH 1 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=47.8746 (C:2.0000, R:0.0110, T:47.8735(w:1.000)âš ï¸)
Batch  25/537: Loss=7.4674 (C:4.1054, R:0.0099, T:7.4664(w:1.000)ğŸš€)
Batch  50/537: Loss=4.4838 (C:4.9613, R:0.0100, T:4.4828(w:1.000)ğŸš€)
Batch  75/537: Loss=3.4926 (C:5.3843, R:0.0100, T:3.4916(w:1.000)ğŸš€)
Batch 100/537: Loss=3.1948 (C:5.3456, R:0.0100, T:3.1938(w:1.000)ğŸš€)
Batch 125/537: Loss=3.0382 (C:5.3148, R:0.0100, T:3.0372(w:1.000)ğŸš€)
Batch 150/537: Loss=2.8588 (C:5.3587, R:0.0099, T:2.8578(w:1.000)ğŸš€)
Batch 175/537: Loss=2.8434 (C:5.3928, R:0.0100, T:2.8424(w:1.000)ğŸš€)
Batch 200/537: Loss=2.7659 (C:5.3636, R:0.0100, T:2.7649(w:1.000)ğŸš€)
Batch 225/537: Loss=2.5460 (C:5.3252, R:0.0099, T:2.5450(w:1.000)ğŸš€)
Batch 250/537: Loss=2.6051 (C:5.3497, R:0.0100, T:2.6041(w:1.000)ğŸš€)
Batch 275/537: Loss=2.5091 (C:5.3068, R:0.0099, T:2.5081(w:1.000)ğŸš€)
Batch 300/537: Loss=2.5092 (C:5.3559, R:0.0099, T:2.5082(w:1.000)ğŸš€)
Batch 325/537: Loss=2.5599 (C:5.3780, R:0.0099, T:2.5589(w:1.000)ğŸš€)
Batch 350/537: Loss=2.4567 (C:5.3401, R:0.0100, T:2.4557(w:1.000)ğŸš€)
Batch 375/537: Loss=2.3990 (C:5.2551, R:0.0099, T:2.3980(w:1.000)ğŸš€)
Batch 400/537: Loss=2.3726 (C:5.2215, R:0.0099, T:2.3716(w:1.000)ğŸš€)
Batch 425/537: Loss=2.4137 (C:5.3226, R:0.0099, T:2.4127(w:1.000)ğŸš€)
Batch 450/537: Loss=2.3840 (C:5.3084, R:0.0099, T:2.3830(w:1.000)ğŸš€)
Batch 475/537: Loss=2.5013 (C:5.2065, R:0.0099, T:2.5003(w:1.000)ğŸš€)
Batch 500/537: Loss=2.4498 (C:5.2148, R:0.0100, T:2.4488(w:1.000)ğŸš€)
Batch 525/537: Loss=2.3069 (C:5.2832, R:0.0099, T:2.3059(w:1.000)ğŸš€)
ğŸ‰ MILESTONE: First topological learning detected at epoch 1!
   Initial topological loss: 3.5893
ğŸ“ˆ New best topological loss: 3.5893

ğŸ“Š EPOCH 1 TRAINING SUMMARY:
  Total Loss: 3.5903
  Contrastive: 5.2658
  Reconstruction: 0.0100
  Topological: 3.5893 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 42.4317
  Contrastive: 1.9831
  Reconstruction: 0.0099
  Topological: 42.4307 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 1/300 COMPLETE (44.8s)
Train Loss: 3.5903 (C:5.2658, R:0.0100, T:3.5893)
Val Loss:   42.4317 (C:1.9831, R:0.0099, T:42.4307)
ğŸš€ Good topological learning progress
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 2 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=2.3148 (C:5.3224, R:0.0100, T:2.3138(w:1.000)ğŸš€)
Batch  25/537: Loss=2.3354 (C:5.2903, R:0.0100, T:2.3344(w:1.000)ğŸš€)
Batch  50/537: Loss=2.3989 (C:5.3176, R:0.0099, T:2.3979(w:1.000)ğŸš€)
Batch  75/537: Loss=2.2409 (C:5.2689, R:0.0100, T:2.2399(w:1.000)ğŸš€)
Batch 100/537: Loss=2.3083 (C:5.2985, R:0.0099, T:2.3073(w:1.000)ğŸš€)
Batch 125/537: Loss=2.4061 (C:5.4171, R:0.0100, T:2.4051(w:1.000)ğŸš€)
Batch 150/537: Loss=2.4518 (C:5.3399, R:0.0100, T:2.4508(w:1.000)ğŸš€)
Batch 175/537: Loss=2.3908 (C:5.3809, R:0.0099, T:2.3898(w:1.000)ğŸš€)
Batch 200/537: Loss=2.3807 (C:5.2199, R:0.0099, T:2.3797(w:1.000)ğŸš€)
Batch 225/537: Loss=2.3254 (C:5.3852, R:0.0100, T:2.3244(w:1.000)ğŸš€)
Batch 250/537: Loss=2.3549 (C:5.2948, R:0.0100, T:2.3539(w:1.000)ğŸš€)
Batch 275/537: Loss=2.2587 (C:5.3116, R:0.0100, T:2.2577(w:1.000)ğŸš€)
Batch 300/537: Loss=2.2980 (C:5.2254, R:0.0100, T:2.2970(w:1.000)ğŸš€)
Batch 325/537: Loss=2.4138 (C:5.3388, R:0.0100, T:2.4128(w:1.000)ğŸš€)
Batch 350/537: Loss=2.3270 (C:5.3572, R:0.0099, T:2.3261(w:1.000)ğŸš€)
Batch 375/537: Loss=2.2966 (C:5.2588, R:0.0099, T:2.2956(w:1.000)ğŸš€)
Batch 400/537: Loss=2.2709 (C:5.2229, R:0.0100, T:2.2699(w:1.000)ğŸš€)
Batch 425/537: Loss=2.2557 (C:5.1647, R:0.0100, T:2.2547(w:1.000)ğŸš€)
Batch 450/537: Loss=2.3106 (C:5.2065, R:0.0099, T:2.3096(w:1.000)ğŸš€)
Batch 475/537: Loss=2.3142 (C:5.3827, R:0.0099, T:2.3132(w:1.000)ğŸš€)
Batch 500/537: Loss=2.2467 (C:5.4857, R:0.0099, T:2.2457(w:1.000)ğŸš€)
Batch 525/537: Loss=2.3098 (C:5.3707, R:0.0100, T:2.3088(w:1.000)ğŸš€)
ğŸ“ˆ New best topological loss: 2.3479

ğŸ“Š EPOCH 2 TRAINING SUMMARY:
  Total Loss: 2.3489
  Contrastive: 5.3039
  Reconstruction: 0.0100
  Topological: 2.3479 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 42.1087
  Contrastive: 1.9810
  Reconstruction: 0.0099
  Topological: 42.1077 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 2/300 COMPLETE (45.2s)
Train Loss: 2.3489 (C:5.3039, R:0.0100, T:2.3479)
Val Loss:   42.1087 (C:1.9810, R:0.0099, T:42.1077)
ğŸš€ Good topological learning progress
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 3 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=2.2352 (C:5.3022, R:0.0099, T:2.2342(w:1.000)ğŸš€)
Batch  25/537: Loss=2.2843 (C:5.3264, R:0.0099, T:2.2833(w:1.000)ğŸš€)
Batch  50/537: Loss=2.2232 (C:5.3801, R:0.0099, T:2.2222(w:1.000)ğŸš€)
Batch  75/537: Loss=2.2467 (C:5.3520, R:0.0100, T:2.2457(w:1.000)ğŸš€)
Batch 100/537: Loss=2.2114 (C:5.1907, R:0.0100, T:2.2104(w:1.000)ğŸš€)
Batch 125/537: Loss=1.9879 (C:5.4308, R:0.0099, T:1.9869(w:1.000)ğŸš€)
Batch 150/537: Loss=2.0812 (C:5.2877, R:0.0100, T:2.0802(w:1.000)ğŸš€)
Batch 175/537: Loss=2.0028 (C:5.2254, R:0.0099, T:2.0018(w:1.000)ğŸš€)
Batch 200/537: Loss=2.0184 (C:5.2014, R:0.0099, T:2.0174(w:1.000)ğŸš€)
Batch 225/537: Loss=1.9227 (C:5.4409, R:0.0100, T:1.9217(w:1.000)ğŸš€)
Batch 250/537: Loss=2.0711 (C:5.3334, R:0.0100, T:2.0701(w:1.000)ğŸš€)
Batch 275/537: Loss=1.9893 (C:5.3167, R:0.0099, T:1.9883(w:1.000)ğŸš€)
Batch 300/537: Loss=1.9985 (C:5.3670, R:0.0100, T:1.9975(w:1.000)ğŸš€)
Batch 325/537: Loss=1.8858 (C:5.3485, R:0.0099, T:1.8848(w:1.000)ğŸš€)
Batch 350/537: Loss=1.8468 (C:5.3555, R:0.0099, T:1.8458(w:1.000)ğŸš€)
Batch 375/537: Loss=1.8558 (C:5.2287, R:0.0100, T:1.8548(w:1.000)ğŸš€)
Batch 400/537: Loss=1.7575 (C:5.4482, R:0.0099, T:1.7565(w:1.000)ğŸš€)
Batch 425/537: Loss=1.7943 (C:5.4325, R:0.0099, T:1.7933(w:1.000)ğŸš€)
Batch 450/537: Loss=1.7797 (C:5.3325, R:0.0100, T:1.7787(w:1.000)ğŸš€)
Batch 475/537: Loss=1.7571 (C:5.3278, R:0.0100, T:1.7561(w:1.000)ğŸš€)
Batch 500/537: Loss=1.6916 (C:5.3613, R:0.0099, T:1.6906(w:1.000)ğŸš€)
Batch 525/537: Loss=1.7700 (C:5.3514, R:0.0100, T:1.7690(w:1.000)ğŸš€)
ğŸ“ˆ New best topological loss: 1.9888

ğŸ“Š EPOCH 3 TRAINING SUMMARY:
  Total Loss: 1.9898
  Contrastive: 5.3361
  Reconstruction: 0.0100
  Topological: 1.9888 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 36.4293
  Contrastive: 2.1822
  Reconstruction: 0.0099
  Topological: 36.4283 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 3/300 COMPLETE (44.7s)
Train Loss: 1.9898 (C:5.3361, R:0.0100, T:1.9888)
Val Loss:   36.4293 (C:2.1822, R:0.0099, T:36.4283)
ğŸš€ Good topological learning progress
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 4 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.8176 (C:5.4057, R:0.0100, T:1.8166(w:1.000)ğŸš€)
Batch  25/537: Loss=1.7905 (C:5.2345, R:0.0100, T:1.7895(w:1.000)ğŸš€)
Batch  50/537: Loss=1.8023 (C:5.5700, R:0.0100, T:1.8013(w:1.000)ğŸš€)
Batch  75/537: Loss=1.6821 (C:5.3855, R:0.0099, T:1.6811(w:1.000)ğŸš€)
Batch 100/537: Loss=1.7458 (C:5.2985, R:0.0100, T:1.7448(w:1.000)ğŸš€)
Batch 125/537: Loss=1.7778 (C:5.5340, R:0.0099, T:1.7768(w:1.000)ğŸš€)
Batch 150/537: Loss=1.7147 (C:5.5008, R:0.0099, T:1.7137(w:1.000)ğŸš€)
Batch 175/537: Loss=1.7355 (C:5.3189, R:0.0099, T:1.7345(w:1.000)ğŸš€)
Batch 200/537: Loss=1.6796 (C:5.3841, R:0.0100, T:1.6787(w:1.000)ğŸš€)
Batch 225/537: Loss=1.6550 (C:5.3944, R:0.0099, T:1.6540(w:1.000)ğŸš€)
Batch 250/537: Loss=1.6890 (C:5.3946, R:0.0100, T:1.6880(w:1.000)ğŸš€)
Batch 275/537: Loss=1.6197 (C:5.4198, R:0.0099, T:1.6187(w:1.000)ğŸš€)
Batch 300/537: Loss=1.5812 (C:5.4080, R:0.0099, T:1.5802(w:1.000)ğŸš€)
Batch 325/537: Loss=1.6794 (C:5.4088, R:0.0099, T:1.6784(w:1.000)ğŸš€)
Batch 350/537: Loss=1.5806 (C:5.3570, R:0.0099, T:1.5796(w:1.000)ğŸš€)
Batch 375/537: Loss=1.5642 (C:5.5943, R:0.0100, T:1.5632(w:1.000)ğŸš€)
Batch 400/537: Loss=1.5791 (C:5.4615, R:0.0099, T:1.5781(w:1.000)ğŸš€)
Batch 425/537: Loss=1.4833 (C:5.3906, R:0.0099, T:1.4823(w:1.000)ğŸš€)
Batch 450/537: Loss=1.5119 (C:5.4329, R:0.0099, T:1.5109(w:1.000)ğŸš€)
Batch 475/537: Loss=1.4637 (C:5.3337, R:0.0099, T:1.4627(w:1.000)ğŸš€)
Batch 500/537: Loss=1.3947 (C:5.4876, R:0.0100, T:1.3937(w:1.000)ğŸš€)
Batch 525/537: Loss=1.4671 (C:5.4288, R:0.0099, T:1.4661(w:1.000)ğŸš€)
ğŸ“ˆ New best topological loss: 1.6360

ğŸ“Š EPOCH 4 TRAINING SUMMARY:
  Total Loss: 1.6370
  Contrastive: 5.4134
  Reconstruction: 0.0100
  Topological: 1.6360 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 31.5701
  Contrastive: 2.4501
  Reconstruction: 0.0099
  Topological: 31.5691 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 4/300 COMPLETE (45.1s)
Train Loss: 1.6370 (C:5.4134, R:0.0100, T:1.6360)
Val Loss:   31.5701 (C:2.4501, R:0.0099, T:31.5691)
ğŸš€ Good topological learning progress
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 5 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.4539 (C:5.6261, R:0.0099, T:1.4529(w:1.000)ğŸš€)
Batch  25/537: Loss=1.4915 (C:5.3240, R:0.0100, T:1.4905(w:1.000)ğŸš€)
Batch  50/537: Loss=1.3930 (C:5.4133, R:0.0100, T:1.3920(w:1.000)ğŸš€)
Batch  75/537: Loss=1.3401 (C:5.4592, R:0.0100, T:1.3391(w:1.000)ğŸš€)
Batch 100/537: Loss=1.3529 (C:5.4666, R:0.0100, T:1.3519(w:1.000)ğŸš€)
Batch 125/537: Loss=1.3522 (C:5.4951, R:0.0100, T:1.3512(w:1.000)ğŸš€)
Batch 150/537: Loss=1.4089 (C:5.5471, R:0.0100, T:1.4079(w:1.000)ğŸš€)
Batch 175/537: Loss=1.3206 (C:5.5710, R:0.0100, T:1.3196(w:1.000)ğŸš€)
Batch 200/537: Loss=1.3040 (C:5.3702, R:0.0100, T:1.3030(w:1.000)ğŸš€)
Batch 225/537: Loss=1.2903 (C:5.5781, R:0.0100, T:1.2893(w:1.000)ğŸš€)
Batch 250/537: Loss=1.2537 (C:5.5699, R:0.0100, T:1.2527(w:1.000)ğŸš€)
Batch 275/537: Loss=1.2681 (C:5.5474, R:0.0100, T:1.2671(w:1.000)ğŸš€)
Batch 300/537: Loss=1.2556 (C:5.4190, R:0.0100, T:1.2546(w:1.000)ğŸš€)
Batch 325/537: Loss=1.2902 (C:5.5299, R:0.0099, T:1.2892(w:1.000)ğŸš€)
Batch 350/537: Loss=1.3242 (C:5.4968, R:0.0100, T:1.3232(w:1.000)ğŸš€)
Batch 375/537: Loss=1.2752 (C:5.4485, R:0.0100, T:1.2742(w:1.000)ğŸš€)
Batch 400/537: Loss=1.2940 (C:5.4256, R:0.0100, T:1.2930(w:1.000)ğŸš€)
Batch 425/537: Loss=1.2296 (C:5.5976, R:0.0099, T:1.2286(w:1.000)ğŸš€)
Batch 450/537: Loss=1.2687 (C:5.5293, R:0.0100, T:1.2677(w:1.000)ğŸš€)
Batch 475/537: Loss=1.2437 (C:5.4812, R:0.0100, T:1.2427(w:1.000)ğŸš€)
Batch 500/537: Loss=1.2563 (C:5.4462, R:0.0099, T:1.2553(w:1.000)ğŸš€)
Batch 525/537: Loss=1.2103 (C:5.4825, R:0.0100, T:1.2093(w:1.000)ğŸš€)
ğŸ“ˆ New best topological loss: 1.3143

ğŸ“Š EPOCH 5 TRAINING SUMMARY:
  Total Loss: 1.3153
  Contrastive: 5.4802
  Reconstruction: 0.0100
  Topological: 1.3143 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 26.5228
  Contrastive: 2.7454
  Reconstruction: 0.0099
  Topological: 26.5219 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 5/300 COMPLETE (44.8s)
Train Loss: 1.3153 (C:5.4802, R:0.0100, T:1.3143)
Val Loss:   26.5228 (C:2.7454, R:0.0099, T:26.5219)
ğŸš€ Good topological learning progress
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 6 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.1376 (C:5.4683, R:0.0100, T:1.1366(w:1.000)ğŸš€)
Batch  25/537: Loss=1.1890 (C:5.5374, R:0.0100, T:1.1880(w:1.000)ğŸš€)
Batch  50/537: Loss=1.1848 (C:5.5175, R:0.0099, T:1.1838(w:1.000)ğŸš€)
Batch  75/537: Loss=1.2217 (C:5.5327, R:0.0100, T:1.2207(w:1.000)ğŸš€)
Batch 100/537: Loss=1.1855 (C:5.5388, R:0.0099, T:1.1845(w:1.000)ğŸš€)
Batch 125/537: Loss=1.1792 (C:5.4498, R:0.0099, T:1.1782(w:1.000)ğŸš€)
Batch 150/537: Loss=1.1486 (C:5.4961, R:0.0099, T:1.1476(w:1.000)ğŸš€)
Batch 175/537: Loss=1.1985 (C:5.5339, R:0.0100, T:1.1975(w:1.000)ğŸš€)
Batch 200/537: Loss=1.1894 (C:5.6846, R:0.0100, T:1.1884(w:1.000)ğŸš€)
Batch 225/537: Loss=1.1582 (C:5.5131, R:0.0100, T:1.1572(w:1.000)ğŸš€)
Batch 250/537: Loss=1.1526 (C:5.4194, R:0.0099, T:1.1516(w:1.000)ğŸš€)
Batch 275/537: Loss=1.0998 (C:5.5835, R:0.0099, T:1.0988(w:1.000)ğŸš€)
Batch 300/537: Loss=1.1410 (C:5.4468, R:0.0100, T:1.1400(w:1.000)ğŸš€)
Batch 325/537: Loss=1.0984 (C:5.5909, R:0.0099, T:1.0974(w:1.000)ğŸš€)
Batch 350/537: Loss=1.0545 (C:5.5619, R:0.0099, T:1.0536(w:1.000)ğŸš€)
Batch 375/537: Loss=1.1477 (C:5.5885, R:0.0100, T:1.1467(w:1.000)ğŸš€)
Batch 400/537: Loss=1.0826 (C:5.5749, R:0.0100, T:1.0816(w:1.000)ğŸš€)
Batch 425/537: Loss=1.0765 (C:5.4535, R:0.0100, T:1.0755(w:1.000)ğŸš€)
Batch 450/537: Loss=1.0482 (C:5.5677, R:0.0100, T:1.0472(w:1.000)ğŸš€)
Batch 475/537: Loss=1.0810 (C:5.5321, R:0.0099, T:1.0800(w:1.000)ğŸš€)
Batch 500/537: Loss=1.0792 (C:5.3926, R:0.0099, T:1.0782(w:1.000)ğŸš€)
Batch 525/537: Loss=1.0534 (C:5.4366, R:0.0099, T:1.0524(w:1.000)ğŸš€)
ğŸ“ˆ New best topological loss: 1.1363

ğŸ“Š EPOCH 6 TRAINING SUMMARY:
  Total Loss: 1.1373
  Contrastive: 5.5277
  Reconstruction: 0.0100
  Topological: 1.1363 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 21.7866
  Contrastive: 3.0811
  Reconstruction: 0.0099
  Topological: 21.7856 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 6/300 COMPLETE (45.0s)
Train Loss: 1.1373 (C:5.5277, R:0.0100, T:1.1363)
Val Loss:   21.7866 (C:3.0811, R:0.0099, T:21.7856)
ğŸš€ Good topological learning progress
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 7 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=1.0718 (C:5.5430, R:0.0100, T:1.0708(w:1.000)ğŸš€)
Batch  25/537: Loss=1.0239 (C:5.5902, R:0.0100, T:1.0229(w:1.000)ğŸš€)
Batch  50/537: Loss=1.0071 (C:5.5770, R:0.0099, T:1.0061(w:1.000)ğŸš€)
Batch  75/537: Loss=1.0475 (C:5.5056, R:0.0099, T:1.0466(w:1.000)ğŸš€)
Batch 100/537: Loss=0.9638 (C:5.5572, R:0.0100, T:0.9628(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.9709 (C:5.5188, R:0.0100, T:0.9699(w:1.000)ğŸ‰)
Batch 150/537: Loss=1.0051 (C:5.5724, R:0.0100, T:1.0041(w:1.000)ğŸš€)
Batch 175/537: Loss=0.9963 (C:5.5559, R:0.0099, T:0.9953(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.9969 (C:5.4402, R:0.0100, T:0.9959(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.9636 (C:5.5261, R:0.0099, T:0.9626(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.9974 (C:5.6096, R:0.0099, T:0.9964(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.9697 (C:5.5695, R:0.0100, T:0.9687(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.9500 (C:5.5485, R:0.0099, T:0.9490(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.9415 (C:5.6223, R:0.0100, T:0.9405(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.9490 (C:5.6311, R:0.0100, T:0.9480(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.9110 (C:5.5516, R:0.0100, T:0.9100(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.9498 (C:5.5717, R:0.0100, T:0.9488(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.9885 (C:5.6167, R:0.0100, T:0.9875(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.9128 (C:5.6115, R:0.0100, T:0.9118(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.8996 (C:5.5627, R:0.0100, T:0.8986(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.9326 (C:5.5780, R:0.0099, T:0.9317(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.9197 (C:5.5191, R:0.0099, T:0.9187(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.9731

ğŸ“Š EPOCH 7 TRAINING SUMMARY:
  Total Loss: 0.9741
  Contrastive: 5.5660
  Reconstruction: 0.0100
  Topological: 0.9731 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 18.3779
  Contrastive: 3.3009
  Reconstruction: 0.0099
  Topological: 18.3769 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 7/300 COMPLETE (44.2s)
Train Loss: 0.9741 (C:5.5660, R:0.0100, T:0.9731)
Val Loss:   18.3779 (C:3.3009, R:0.0099, T:18.3769)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 8 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.9343 (C:5.5816, R:0.0100, T:0.9333(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.8963 (C:5.5715, R:0.0099, T:0.8953(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.8866 (C:5.5707, R:0.0100, T:0.8856(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.9095 (C:5.6097, R:0.0100, T:0.9085(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.8863 (C:5.5765, R:0.0100, T:0.8853(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.8763 (C:5.5998, R:0.0099, T:0.8753(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.9431 (C:5.5917, R:0.0100, T:0.9421(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.8852 (C:5.5764, R:0.0100, T:0.8843(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.8508 (C:5.6430, R:0.0100, T:0.8498(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.8764 (C:5.5577, R:0.0100, T:0.8754(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.8619 (C:5.6152, R:0.0099, T:0.8609(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.8448 (C:5.6155, R:0.0099, T:0.8438(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.9021 (C:5.6316, R:0.0100, T:0.9011(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.8328 (C:5.5339, R:0.0100, T:0.8318(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.8492 (C:5.6132, R:0.0100, T:0.8482(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.8367 (C:5.5865, R:0.0100, T:0.8357(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.8716 (C:5.5062, R:0.0099, T:0.8706(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.8320 (C:5.5126, R:0.0100, T:0.8310(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.8475 (C:5.6207, R:0.0100, T:0.8465(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.8060 (C:5.6373, R:0.0100, T:0.8050(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.8296 (C:5.6527, R:0.0099, T:0.8286(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.7952 (C:5.6622, R:0.0100, T:0.7942(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.8643

ğŸ“Š EPOCH 8 TRAINING SUMMARY:
  Total Loss: 0.8653
  Contrastive: 5.5919
  Reconstruction: 0.0100
  Topological: 0.8643 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 15.4791
  Contrastive: 3.5219
  Reconstruction: 0.0099
  Topological: 15.4781 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 8/300 COMPLETE (45.4s)
Train Loss: 0.8653 (C:5.5919, R:0.0100, T:0.8643)
Val Loss:   15.4791 (C:3.5219, R:0.0099, T:15.4781)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 9 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.8153 (C:5.6264, R:0.0099, T:0.8143(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.8196 (C:5.5817, R:0.0100, T:0.8186(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.8030 (C:5.5997, R:0.0100, T:0.8020(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.8041 (C:5.5869, R:0.0100, T:0.8031(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.8259 (C:5.6496, R:0.0099, T:0.8249(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.7933 (C:5.5444, R:0.0099, T:0.7923(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.7926 (C:5.5994, R:0.0100, T:0.7916(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.7587 (C:5.6593, R:0.0099, T:0.7577(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.7918 (C:5.6379, R:0.0100, T:0.7908(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.7945 (C:5.6422, R:0.0100, T:0.7935(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.8055 (C:5.6128, R:0.0100, T:0.8045(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.8465 (C:5.7304, R:0.0100, T:0.8455(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.7999 (C:5.5913, R:0.0100, T:0.7989(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.7684 (C:5.5878, R:0.0099, T:0.7674(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.7778 (C:5.6166, R:0.0099, T:0.7768(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.7451 (C:5.5985, R:0.0099, T:0.7441(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.7781 (C:5.5889, R:0.0099, T:0.7771(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.7618 (C:5.6553, R:0.0100, T:0.7608(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.7743 (C:5.6607, R:0.0100, T:0.7733(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.7372 (C:5.5966, R:0.0099, T:0.7363(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.7527 (C:5.6390, R:0.0099, T:0.7517(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.7496 (C:5.5897, R:0.0100, T:0.7486(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.7921

ğŸ“Š EPOCH 9 TRAINING SUMMARY:
  Total Loss: 0.7931
  Contrastive: 5.6093
  Reconstruction: 0.0100
  Topological: 0.7921 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 13.8728
  Contrastive: 3.6062
  Reconstruction: 0.0099
  Topological: 13.8718 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 9/300 COMPLETE (45.6s)
Train Loss: 0.7931 (C:5.6093, R:0.0100, T:0.7921)
Val Loss:   13.8728 (C:3.6062, R:0.0099, T:13.8718)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 10 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.7607 (C:5.6220, R:0.0100, T:0.7597(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.7314 (C:5.5473, R:0.0099, T:0.7304(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.7557 (C:5.6413, R:0.0100, T:0.7547(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.7399 (C:5.5785, R:0.0099, T:0.7389(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.7340 (C:5.6182, R:0.0099, T:0.7330(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.7737 (C:5.5799, R:0.0099, T:0.7727(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.7504 (C:5.5774, R:0.0100, T:0.7494(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.7809 (C:5.5696, R:0.0100, T:0.7799(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.7423 (C:5.6752, R:0.0100, T:0.7413(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.7582 (C:5.5883, R:0.0100, T:0.7572(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.7599 (C:5.6012, R:0.0099, T:0.7589(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.7739 (C:5.6151, R:0.0099, T:0.7729(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.7265 (C:5.5695, R:0.0100, T:0.7255(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.7372 (C:5.6099, R:0.0100, T:0.7362(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.7470 (C:5.6353, R:0.0100, T:0.7460(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.7286 (C:5.6183, R:0.0099, T:0.7276(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.7040 (C:5.5931, R:0.0099, T:0.7030(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.7134 (C:5.6029, R:0.0099, T:0.7124(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.7063 (C:5.6195, R:0.0100, T:0.7053(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.7136 (C:5.6922, R:0.0100, T:0.7126(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.7359 (C:5.5646, R:0.0100, T:0.7350(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6614 (C:5.6212, R:0.0100, T:0.6604(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.7436

ğŸ“Š EPOCH 10 TRAINING SUMMARY:
  Total Loss: 0.7446
  Contrastive: 5.6187
  Reconstruction: 0.0100
  Topological: 0.7436 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 12.7554
  Contrastive: 3.6970
  Reconstruction: 0.0099
  Topological: 12.7544 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 10/300 COMPLETE (44.8s)
Train Loss: 0.7446 (C:5.6187, R:0.0100, T:0.7436)
Val Loss:   12.7554 (C:3.6970, R:0.0099, T:12.7544)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 11 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.7604 (C:5.5817, R:0.0099, T:0.7595(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6949 (C:5.6980, R:0.0099, T:0.6939(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.7324 (C:5.6114, R:0.0100, T:0.7314(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.7125 (C:5.5877, R:0.0099, T:0.7116(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6895 (C:5.6201, R:0.0100, T:0.6885(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.7412 (C:5.6603, R:0.0100, T:0.7402(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.7547 (C:5.5841, R:0.0099, T:0.7537(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6709 (C:5.5595, R:0.0099, T:0.6699(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.7168 (C:5.6224, R:0.0099, T:0.7158(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.7373 (C:5.6546, R:0.0099, T:0.7363(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6724 (C:5.6436, R:0.0099, T:0.6714(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.7125 (C:5.6236, R:0.0099, T:0.7115(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6870 (C:5.6118, R:0.0099, T:0.6860(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.7049 (C:5.6311, R:0.0100, T:0.7040(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.7175 (C:5.5679, R:0.0100, T:0.7165(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6941 (C:5.6097, R:0.0099, T:0.6931(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6782 (C:5.6681, R:0.0100, T:0.6772(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.7079 (C:5.6762, R:0.0100, T:0.7069(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.7576 (C:5.6540, R:0.0100, T:0.7566(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.7063 (C:5.6057, R:0.0100, T:0.7053(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6997 (C:5.6708, R:0.0100, T:0.6987(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.7387 (C:5.6329, R:0.0099, T:0.7377(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.7096

ğŸ“Š EPOCH 11 TRAINING SUMMARY:
  Total Loss: 0.7106
  Contrastive: 5.6298
  Reconstruction: 0.0100
  Topological: 0.7096 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 11.9508
  Contrastive: 3.7788
  Reconstruction: 0.0099
  Topological: 11.9498 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 11/300 COMPLETE (45.1s)
Train Loss: 0.7106 (C:5.6298, R:0.0100, T:0.7096)
Val Loss:   11.9508 (C:3.7788, R:0.0099, T:11.9498)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 12 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.7261 (C:5.6355, R:0.0100, T:0.7251(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.7197 (C:5.6543, R:0.0100, T:0.7187(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.7253 (C:5.6852, R:0.0100, T:0.7243(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6910 (C:5.6737, R:0.0100, T:0.6900(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6910 (C:5.6121, R:0.0099, T:0.6900(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6927 (C:5.6183, R:0.0099, T:0.6917(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6907 (C:5.6421, R:0.0100, T:0.6897(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6758 (C:5.6412, R:0.0100, T:0.6748(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6860 (C:5.6865, R:0.0099, T:0.6850(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6699 (C:5.6588, R:0.0099, T:0.6689(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6787 (C:5.6222, R:0.0099, T:0.6777(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6805 (C:5.6474, R:0.0100, T:0.6795(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6923 (C:5.6272, R:0.0100, T:0.6913(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6682 (C:5.5798, R:0.0100, T:0.6672(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.7134 (C:5.5788, R:0.0099, T:0.7125(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6764 (C:5.5758, R:0.0100, T:0.6754(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.7016 (C:5.5774, R:0.0100, T:0.7006(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6621 (C:5.6492, R:0.0100, T:0.6611(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6826 (C:5.6503, R:0.0100, T:0.6816(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6922 (C:5.6647, R:0.0099, T:0.6913(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6708 (C:5.6328, R:0.0099, T:0.6698(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.7025 (C:5.6223, R:0.0099, T:0.7015(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6880

ğŸ“Š EPOCH 12 TRAINING SUMMARY:
  Total Loss: 0.6890
  Contrastive: 5.6292
  Reconstruction: 0.0100
  Topological: 0.6880 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 11.2060
  Contrastive: 3.8347
  Reconstruction: 0.0099
  Topological: 11.2050 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 12/300 COMPLETE (45.1s)
Train Loss: 0.6890 (C:5.6292, R:0.0100, T:0.6880)
Val Loss:   11.2060 (C:3.8347, R:0.0099, T:11.2050)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 13 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6643 (C:5.6211, R:0.0099, T:0.6633(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6693 (C:5.6316, R:0.0100, T:0.6683(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6957 (C:5.6080, R:0.0100, T:0.6947(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6618 (C:5.6165, R:0.0099, T:0.6608(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6722 (C:5.6222, R:0.0099, T:0.6712(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6752 (C:5.6438, R:0.0100, T:0.6742(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6796 (C:5.5919, R:0.0099, T:0.6786(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6890 (C:5.6626, R:0.0100, T:0.6880(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6975 (C:5.6496, R:0.0100, T:0.6965(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6985 (C:5.6595, R:0.0100, T:0.6975(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.7040 (C:5.6125, R:0.0100, T:0.7030(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6456 (C:5.6397, R:0.0100, T:0.6446(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6615 (C:5.6065, R:0.0100, T:0.6605(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6414 (C:5.6353, R:0.0100, T:0.6404(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6726 (C:5.6489, R:0.0100, T:0.6716(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6822 (C:5.6215, R:0.0099, T:0.6812(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6404 (C:5.6057, R:0.0099, T:0.6394(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6326 (C:5.6072, R:0.0099, T:0.6316(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6755 (C:5.6131, R:0.0100, T:0.6745(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6734 (C:5.5680, R:0.0099, T:0.6724(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6472 (C:5.6493, R:0.0100, T:0.6462(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6807 (C:5.6261, R:0.0100, T:0.6797(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6696

ğŸ“Š EPOCH 13 TRAINING SUMMARY:
  Total Loss: 0.6706
  Contrastive: 5.6271
  Reconstruction: 0.0100
  Topological: 0.6696 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 10.5546
  Contrastive: 3.8862
  Reconstruction: 0.0099
  Topological: 10.5536 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 13/300 COMPLETE (45.0s)
Train Loss: 0.6706 (C:5.6271, R:0.0100, T:0.6696)
Val Loss:   10.5546 (C:3.8862, R:0.0099, T:10.5536)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 14 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6656 (C:5.6196, R:0.0100, T:0.6646(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6340 (C:5.6135, R:0.0100, T:0.6330(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6644 (C:5.6371, R:0.0099, T:0.6634(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6317 (C:5.6499, R:0.0100, T:0.6307(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.7031 (C:5.5909, R:0.0099, T:0.7021(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6833 (C:5.6392, R:0.0100, T:0.6823(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6655 (C:5.6762, R:0.0100, T:0.6645(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6751 (C:5.6543, R:0.0100, T:0.6741(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6703 (C:5.6377, R:0.0099, T:0.6693(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6266 (C:5.6333, R:0.0099, T:0.6256(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6597 (C:5.5862, R:0.0099, T:0.6587(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.7040 (C:5.5989, R:0.0100, T:0.7030(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6506 (C:5.6089, R:0.0099, T:0.6496(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6440 (C:5.6287, R:0.0099, T:0.6430(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.7082 (C:5.6614, R:0.0100, T:0.7072(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6668 (C:5.6403, R:0.0100, T:0.6658(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6326 (C:5.6281, R:0.0099, T:0.6316(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6475 (C:5.6473, R:0.0100, T:0.6465(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6367 (C:5.6244, R:0.0100, T:0.6357(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6676 (C:5.6105, R:0.0099, T:0.6666(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6311 (C:5.6204, R:0.0100, T:0.6301(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6458 (C:5.6346, R:0.0100, T:0.6448(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6583

ğŸ“Š EPOCH 14 TRAINING SUMMARY:
  Total Loss: 0.6593
  Contrastive: 5.6242
  Reconstruction: 0.0100
  Topological: 0.6583 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 10.0544
  Contrastive: 3.9034
  Reconstruction: 0.0099
  Topological: 10.0534 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 14/300 COMPLETE (45.3s)
Train Loss: 0.6593 (C:5.6242, R:0.0100, T:0.6583)
Val Loss:   10.0544 (C:3.9034, R:0.0099, T:10.0534)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 15 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6772 (C:5.6169, R:0.0100, T:0.6762(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6459 (C:5.6612, R:0.0099, T:0.6450(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6718 (C:5.6084, R:0.0099, T:0.6708(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6656 (C:5.6019, R:0.0099, T:0.6646(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6420 (C:5.6434, R:0.0099, T:0.6410(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6901 (C:5.6411, R:0.0100, T:0.6891(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6443 (C:5.6303, R:0.0099, T:0.6433(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6217 (C:5.6480, R:0.0100, T:0.6207(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6614 (C:5.6245, R:0.0099, T:0.6604(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6487 (C:5.6121, R:0.0100, T:0.6477(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6639 (C:5.6204, R:0.0100, T:0.6629(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6189 (C:5.6200, R:0.0099, T:0.6179(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6584 (C:5.6181, R:0.0100, T:0.6574(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6112 (C:5.6296, R:0.0099, T:0.6102(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6357 (C:5.6080, R:0.0099, T:0.6347(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6231 (C:5.5871, R:0.0099, T:0.6221(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6416 (C:5.6278, R:0.0099, T:0.6406(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6527 (C:5.6302, R:0.0099, T:0.6517(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6875 (C:5.6273, R:0.0100, T:0.6865(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6624 (C:5.6383, R:0.0100, T:0.6614(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6498 (C:5.6180, R:0.0099, T:0.6488(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6655 (C:5.6395, R:0.0099, T:0.6645(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6500

ğŸ“Š EPOCH 15 TRAINING SUMMARY:
  Total Loss: 0.6510
  Contrastive: 5.6225
  Reconstruction: 0.0100
  Topological: 0.6500 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 9.5619
  Contrastive: 3.9607
  Reconstruction: 0.0099
  Topological: 9.5609 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 15/300 COMPLETE (45.4s)
Train Loss: 0.6510 (C:5.6225, R:0.0100, T:0.6500)
Val Loss:   9.5619 (C:3.9607, R:0.0099, T:9.5609)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 16 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6503 (C:5.5980, R:0.0100, T:0.6493(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6593 (C:5.6060, R:0.0100, T:0.6583(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6634 (C:5.6135, R:0.0099, T:0.6624(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6488 (C:5.6440, R:0.0100, T:0.6478(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6707 (C:5.6376, R:0.0100, T:0.6697(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6545 (C:5.5914, R:0.0099, T:0.6535(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6750 (C:5.5640, R:0.0099, T:0.6740(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6778 (C:5.5979, R:0.0100, T:0.6768(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6577 (C:5.5920, R:0.0099, T:0.6567(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6420 (C:5.6459, R:0.0099, T:0.6410(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6216 (C:5.6239, R:0.0100, T:0.6206(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6383 (C:5.6415, R:0.0100, T:0.6373(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6669 (C:5.6357, R:0.0100, T:0.6659(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6442 (C:5.6275, R:0.0100, T:0.6432(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6450 (C:5.6238, R:0.0100, T:0.6440(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6390 (C:5.6578, R:0.0099, T:0.6380(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6268 (C:5.6060, R:0.0099, T:0.6258(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6416 (C:5.6206, R:0.0100, T:0.6406(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6519 (C:5.6282, R:0.0099, T:0.6510(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6440 (C:5.5875, R:0.0100, T:0.6430(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6324 (C:5.6249, R:0.0100, T:0.6314(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6261 (C:5.6180, R:0.0100, T:0.6251(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6427

ğŸ“Š EPOCH 16 TRAINING SUMMARY:
  Total Loss: 0.6437
  Contrastive: 5.6227
  Reconstruction: 0.0100
  Topological: 0.6427 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 9.4120
  Contrastive: 3.9822
  Reconstruction: 0.0099
  Topological: 9.4110 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 16/300 COMPLETE (44.6s)
Train Loss: 0.6437 (C:5.6227, R:0.0100, T:0.6427)
Val Loss:   9.4120 (C:3.9822, R:0.0099, T:9.4110)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 17 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6441 (C:5.5930, R:0.0099, T:0.6431(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6051 (C:5.6305, R:0.0100, T:0.6041(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6628 (C:5.6473, R:0.0099, T:0.6618(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6819 (C:5.6405, R:0.0099, T:0.6809(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6488 (C:5.6304, R:0.0100, T:0.6478(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6473 (C:5.6448, R:0.0100, T:0.6463(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6553 (C:5.5895, R:0.0099, T:0.6543(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6446 (C:5.6509, R:0.0100, T:0.6436(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6134 (C:5.6494, R:0.0100, T:0.6124(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6463 (C:5.6411, R:0.0099, T:0.6453(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6520 (C:5.6578, R:0.0100, T:0.6510(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6342 (C:5.6394, R:0.0100, T:0.6332(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6939 (C:5.6745, R:0.0100, T:0.6929(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6285 (C:5.6180, R:0.0099, T:0.6275(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6230 (C:5.6203, R:0.0099, T:0.6220(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6485 (C:5.6021, R:0.0099, T:0.6475(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6523 (C:5.6469, R:0.0099, T:0.6513(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5827 (C:5.6558, R:0.0099, T:0.5817(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5927 (C:5.6482, R:0.0099, T:0.5917(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6612 (C:5.6468, R:0.0100, T:0.6602(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6477 (C:5.6411, R:0.0100, T:0.6467(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6682 (C:5.6350, R:0.0099, T:0.6672(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6369

ğŸ“Š EPOCH 17 TRAINING SUMMARY:
  Total Loss: 0.6379
  Contrastive: 5.6216
  Reconstruction: 0.0100
  Topological: 0.6369 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 8.9569
  Contrastive: 4.0421
  Reconstruction: 0.0099
  Topological: 8.9559 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 17/300 COMPLETE (45.0s)
Train Loss: 0.6379 (C:5.6216, R:0.0100, T:0.6369)
Val Loss:   8.9569 (C:4.0421, R:0.0099, T:8.9559)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 18 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6269 (C:5.6710, R:0.0100, T:0.6259(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6514 (C:5.6534, R:0.0099, T:0.6504(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6256 (C:5.5989, R:0.0100, T:0.6246(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6126 (C:5.6355, R:0.0099, T:0.6116(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6512 (C:5.6453, R:0.0100, T:0.6502(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6517 (C:5.6146, R:0.0099, T:0.6508(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6312 (C:5.6016, R:0.0100, T:0.6302(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6353 (C:5.5882, R:0.0100, T:0.6343(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6016 (C:5.6132, R:0.0100, T:0.6006(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6352 (C:5.5759, R:0.0099, T:0.6342(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6489 (C:5.6833, R:0.0099, T:0.6479(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6510 (C:5.6429, R:0.0100, T:0.6500(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6410 (C:5.5776, R:0.0099, T:0.6400(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6654 (C:5.6581, R:0.0100, T:0.6644(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6228 (C:5.5910, R:0.0100, T:0.6218(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6304 (C:5.6244, R:0.0099, T:0.6295(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6616 (C:5.5560, R:0.0100, T:0.6606(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6528 (C:5.6495, R:0.0100, T:0.6518(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6518 (C:5.6421, R:0.0100, T:0.6508(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5968 (C:5.6124, R:0.0099, T:0.5958(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6436 (C:5.5681, R:0.0100, T:0.6426(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6053 (C:5.6340, R:0.0100, T:0.6043(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6336

ğŸ“Š EPOCH 18 TRAINING SUMMARY:
  Total Loss: 0.6346
  Contrastive: 5.6188
  Reconstruction: 0.0100
  Topological: 0.6336 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 8.9253
  Contrastive: 4.0410
  Reconstruction: 0.0099
  Topological: 8.9243 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 18/300 COMPLETE (45.1s)
Train Loss: 0.6346 (C:5.6188, R:0.0100, T:0.6336)
Val Loss:   8.9253 (C:4.0410, R:0.0099, T:8.9243)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 19 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6247 (C:5.6008, R:0.0099, T:0.6237(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6249 (C:5.6033, R:0.0100, T:0.6239(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6220 (C:5.6285, R:0.0100, T:0.6210(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6204 (C:5.5941, R:0.0100, T:0.6194(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6118 (C:5.6354, R:0.0100, T:0.6108(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6458 (C:5.6255, R:0.0099, T:0.6448(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6647 (C:5.6817, R:0.0100, T:0.6638(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6411 (C:5.6162, R:0.0100, T:0.6401(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5763 (C:5.6255, R:0.0099, T:0.5754(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6310 (C:5.6062, R:0.0099, T:0.6301(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6438 (C:5.6059, R:0.0100, T:0.6428(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6292 (C:5.6179, R:0.0099, T:0.6282(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6332 (C:5.6207, R:0.0099, T:0.6322(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5957 (C:5.5943, R:0.0100, T:0.5947(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6486 (C:5.6698, R:0.0100, T:0.6476(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6518 (C:5.6436, R:0.0100, T:0.6508(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6188 (C:5.5730, R:0.0100, T:0.6178(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6240 (C:5.6268, R:0.0100, T:0.6230(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6205 (C:5.5889, R:0.0099, T:0.6195(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6424 (C:5.5974, R:0.0099, T:0.6414(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5890 (C:5.6211, R:0.0100, T:0.5880(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6269 (C:5.6432, R:0.0100, T:0.6259(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6265

ğŸ“Š EPOCH 19 TRAINING SUMMARY:
  Total Loss: 0.6275
  Contrastive: 5.6175
  Reconstruction: 0.0100
  Topological: 0.6265 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 8.6303
  Contrastive: 4.0375
  Reconstruction: 0.0099
  Topological: 8.6293 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 19/300 COMPLETE (45.1s)
Train Loss: 0.6275 (C:5.6175, R:0.0100, T:0.6265)
Val Loss:   8.6303 (C:4.0375, R:0.0099, T:8.6293)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 20 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6271 (C:5.5685, R:0.0099, T:0.6261(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6451 (C:5.6399, R:0.0100, T:0.6441(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6330 (C:5.6167, R:0.0100, T:0.6320(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6074 (C:5.6062, R:0.0099, T:0.6064(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6222 (C:5.6262, R:0.0099, T:0.6212(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5978 (C:5.6414, R:0.0099, T:0.5968(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6674 (C:5.6007, R:0.0100, T:0.6664(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6116 (C:5.6056, R:0.0100, T:0.6107(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6313 (C:5.6574, R:0.0100, T:0.6303(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6335 (C:5.6083, R:0.0100, T:0.6325(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5776 (C:5.6158, R:0.0099, T:0.5766(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6161 (C:5.6319, R:0.0100, T:0.6151(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6018 (C:5.6146, R:0.0099, T:0.6008(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6230 (C:5.6018, R:0.0099, T:0.6220(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6415 (C:5.5930, R:0.0099, T:0.6405(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6162 (C:5.6430, R:0.0100, T:0.6152(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6013 (C:5.6819, R:0.0100, T:0.6003(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6061 (C:5.6506, R:0.0099, T:0.6051(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6277 (C:5.6304, R:0.0099, T:0.6267(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6036 (C:5.5743, R:0.0099, T:0.6026(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5988 (C:5.6098, R:0.0099, T:0.5978(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6082 (C:5.5765, R:0.0099, T:0.6072(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6241

ğŸ“Š EPOCH 20 TRAINING SUMMARY:
  Total Loss: 0.6251
  Contrastive: 5.6178
  Reconstruction: 0.0100
  Topological: 0.6241 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 8.5502
  Contrastive: 4.0543
  Reconstruction: 0.0099
  Topological: 8.5492 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 20/300 COMPLETE (45.7s)
Train Loss: 0.6251 (C:5.6178, R:0.0100, T:0.6241)
Val Loss:   8.5502 (C:4.0543, R:0.0099, T:8.5492)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 21 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5959 (C:5.6027, R:0.0099, T:0.5949(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6117 (C:5.6237, R:0.0099, T:0.6107(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6268 (C:5.5717, R:0.0099, T:0.6258(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6346 (C:5.5958, R:0.0099, T:0.6337(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6185 (C:5.6792, R:0.0100, T:0.6175(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5993 (C:5.5829, R:0.0100, T:0.5983(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6064 (C:5.5660, R:0.0100, T:0.6054(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6138 (C:5.6484, R:0.0099, T:0.6128(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6149 (C:5.5872, R:0.0099, T:0.6139(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5984 (C:5.5755, R:0.0099, T:0.5974(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6231 (C:5.6552, R:0.0099, T:0.6221(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6215 (C:5.5928, R:0.0099, T:0.6205(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6226 (C:5.6095, R:0.0100, T:0.6216(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6135 (C:5.6025, R:0.0099, T:0.6125(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6172 (C:5.6211, R:0.0099, T:0.6162(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6516 (C:5.6947, R:0.0100, T:0.6506(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6191 (C:5.6047, R:0.0100, T:0.6181(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6138 (C:5.5405, R:0.0100, T:0.6128(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6327 (C:5.6728, R:0.0100, T:0.6317(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6210 (C:5.5885, R:0.0099, T:0.6201(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5874 (C:5.6346, R:0.0100, T:0.5864(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6339 (C:5.6177, R:0.0099, T:0.6330(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6185

ğŸ“Š EPOCH 21 TRAINING SUMMARY:
  Total Loss: 0.6195
  Contrastive: 5.6158
  Reconstruction: 0.0100
  Topological: 0.6185 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 8.1725
  Contrastive: 4.1230
  Reconstruction: 0.0099
  Topological: 8.1715 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 21/300 COMPLETE (45.2s)
Train Loss: 0.6195 (C:5.6158, R:0.0100, T:0.6185)
Val Loss:   8.1725 (C:4.1230, R:0.0099, T:8.1715)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 22 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6134 (C:5.6438, R:0.0100, T:0.6124(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6221 (C:5.6004, R:0.0100, T:0.6211(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6084 (C:5.6283, R:0.0099, T:0.6074(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6012 (C:5.6022, R:0.0099, T:0.6002(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6129 (C:5.6139, R:0.0099, T:0.6119(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6039 (C:5.6016, R:0.0099, T:0.6029(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6008 (C:5.6166, R:0.0100, T:0.5998(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6547 (C:5.6544, R:0.0100, T:0.6537(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6334 (C:5.6071, R:0.0099, T:0.6324(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6065 (C:5.6464, R:0.0100, T:0.6055(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6023 (C:5.5967, R:0.0100, T:0.6013(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5981 (C:5.5986, R:0.0099, T:0.5971(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6621 (C:5.6279, R:0.0100, T:0.6611(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6189 (C:5.6504, R:0.0100, T:0.6179(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5978 (C:5.6363, R:0.0099, T:0.5968(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6369 (C:5.5996, R:0.0099, T:0.6359(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6212 (C:5.5651, R:0.0099, T:0.6202(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5987 (C:5.5858, R:0.0099, T:0.5977(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6237 (C:5.5885, R:0.0099, T:0.6227(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6156 (C:5.6123, R:0.0099, T:0.6146(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6262 (C:5.5982, R:0.0099, T:0.6252(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5973 (C:5.5979, R:0.0100, T:0.5963(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6171

ğŸ“Š EPOCH 22 TRAINING SUMMARY:
  Total Loss: 0.6181
  Contrastive: 5.6137
  Reconstruction: 0.0100
  Topological: 0.6171 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 8.0840
  Contrastive: 4.0944
  Reconstruction: 0.0099
  Topological: 8.0831 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 22/300 COMPLETE (46.0s)
Train Loss: 0.6181 (C:5.6137, R:0.0100, T:0.6171)
Val Loss:   8.0840 (C:4.0944, R:0.0099, T:8.0831)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 23 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6574 (C:5.6280, R:0.0099, T:0.6564(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6149 (C:5.6237, R:0.0099, T:0.6139(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6151 (C:5.6147, R:0.0100, T:0.6142(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6226 (C:5.6280, R:0.0099, T:0.6216(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6340 (C:5.6103, R:0.0100, T:0.6330(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5936 (C:5.6384, R:0.0099, T:0.5926(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6221 (C:5.6104, R:0.0099, T:0.6211(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5979 (C:5.6002, R:0.0099, T:0.5969(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6261 (C:5.5711, R:0.0099, T:0.6251(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5992 (C:5.6022, R:0.0100, T:0.5982(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6059 (C:5.5988, R:0.0099, T:0.6049(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6397 (C:5.6183, R:0.0099, T:0.6387(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5823 (C:5.6297, R:0.0100, T:0.5813(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5935 (C:5.5694, R:0.0099, T:0.5925(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6136 (C:5.6228, R:0.0100, T:0.6126(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6306 (C:5.6182, R:0.0100, T:0.6296(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6078 (C:5.5897, R:0.0099, T:0.6068(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6005 (C:5.6024, R:0.0100, T:0.5995(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6095 (C:5.6288, R:0.0099, T:0.6085(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6166 (C:5.6025, R:0.0099, T:0.6156(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6069 (C:5.6347, R:0.0100, T:0.6059(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5928 (C:5.5748, R:0.0100, T:0.5918(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6134

ğŸ“Š EPOCH 23 TRAINING SUMMARY:
  Total Loss: 0.6144
  Contrastive: 5.6132
  Reconstruction: 0.0100
  Topological: 0.6134 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 7.9204
  Contrastive: 4.1133
  Reconstruction: 0.0099
  Topological: 7.9194 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 23/300 COMPLETE (45.9s)
Train Loss: 0.6144 (C:5.6132, R:0.0100, T:0.6134)
Val Loss:   7.9204 (C:4.1133, R:0.0099, T:7.9194)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 24 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6161 (C:5.6229, R:0.0100, T:0.6151(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5914 (C:5.5620, R:0.0099, T:0.5904(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5856 (C:5.6012, R:0.0100, T:0.5846(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5857 (C:5.6332, R:0.0100, T:0.5847(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5899 (C:5.6778, R:0.0100, T:0.5889(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6032 (C:5.5760, R:0.0099, T:0.6022(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5910 (C:5.5861, R:0.0099, T:0.5900(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6027 (C:5.5950, R:0.0099, T:0.6017(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5781 (C:5.6316, R:0.0100, T:0.5771(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6243 (C:5.6651, R:0.0100, T:0.6233(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6204 (C:5.6161, R:0.0100, T:0.6194(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6222 (C:5.6060, R:0.0100, T:0.6212(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6054 (C:5.6070, R:0.0100, T:0.6044(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5964 (C:5.5854, R:0.0099, T:0.5954(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6256 (C:5.6027, R:0.0099, T:0.6246(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5939 (C:5.6147, R:0.0099, T:0.5929(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6245 (C:5.6192, R:0.0099, T:0.6235(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6090 (C:5.6350, R:0.0100, T:0.6080(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5910 (C:5.6410, R:0.0100, T:0.5900(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6289 (C:5.6157, R:0.0100, T:0.6279(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6328 (C:5.6240, R:0.0099, T:0.6318(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6007 (C:5.6227, R:0.0099, T:0.5997(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6101

ğŸ“Š EPOCH 24 TRAINING SUMMARY:
  Total Loss: 0.6111
  Contrastive: 5.6132
  Reconstruction: 0.0100
  Topological: 0.6101 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 7.6695
  Contrastive: 4.1405
  Reconstruction: 0.0099
  Topological: 7.6685 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 24/300 COMPLETE (45.7s)
Train Loss: 0.6111 (C:5.6132, R:0.0100, T:0.6101)
Val Loss:   7.6695 (C:4.1405, R:0.0099, T:7.6685)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 25 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5848 (C:5.5929, R:0.0099, T:0.5838(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6342 (C:5.6330, R:0.0100, T:0.6332(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6314 (C:5.5846, R:0.0100, T:0.6304(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6316 (C:5.6448, R:0.0100, T:0.6306(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6227 (C:5.5679, R:0.0100, T:0.6217(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6094 (C:5.6168, R:0.0100, T:0.6084(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6036 (C:5.5521, R:0.0100, T:0.6026(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5909 (C:5.5837, R:0.0099, T:0.5899(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5954 (C:5.5978, R:0.0099, T:0.5944(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6203 (C:5.6211, R:0.0100, T:0.6193(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5954 (C:5.6258, R:0.0099, T:0.5944(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5541 (C:5.5787, R:0.0099, T:0.5531(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6051 (C:5.6409, R:0.0099, T:0.6041(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6095 (C:5.6564, R:0.0100, T:0.6086(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6089 (C:5.6105, R:0.0099, T:0.6079(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6257 (C:5.6127, R:0.0099, T:0.6247(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6007 (C:5.6196, R:0.0100, T:0.5997(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5956 (C:5.6389, R:0.0099, T:0.5946(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6199 (C:5.5854, R:0.0099, T:0.6190(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5893 (C:5.6091, R:0.0100, T:0.5883(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5761 (C:5.5900, R:0.0099, T:0.5751(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6149 (C:5.5958, R:0.0100, T:0.6139(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6064

ğŸ“Š EPOCH 25 TRAINING SUMMARY:
  Total Loss: 0.6074
  Contrastive: 5.6125
  Reconstruction: 0.0100
  Topological: 0.6064 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 7.5778
  Contrastive: 4.1664
  Reconstruction: 0.0099
  Topological: 7.5768 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 25/300 COMPLETE (46.5s)
Train Loss: 0.6074 (C:5.6125, R:0.0100, T:0.6064)
Val Loss:   7.5778 (C:4.1664, R:0.0099, T:7.5768)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 26 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5984 (C:5.6386, R:0.0099, T:0.5974(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6036 (C:5.6498, R:0.0100, T:0.6026(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5936 (C:5.6255, R:0.0099, T:0.5926(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6068 (C:5.6229, R:0.0099, T:0.6058(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5918 (C:5.6148, R:0.0100, T:0.5909(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6045 (C:5.5866, R:0.0100, T:0.6035(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5763 (C:5.5989, R:0.0100, T:0.5753(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6374 (C:5.6083, R:0.0100, T:0.6364(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6022 (C:5.6516, R:0.0099, T:0.6012(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5779 (C:5.5984, R:0.0100, T:0.5769(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5864 (C:5.6050, R:0.0100, T:0.5854(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5950 (C:5.6333, R:0.0099, T:0.5940(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6185 (C:5.6870, R:0.0099, T:0.6175(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5899 (C:5.6298, R:0.0100, T:0.5889(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6032 (C:5.5985, R:0.0100, T:0.6022(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6111 (C:5.5869, R:0.0099, T:0.6101(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5957 (C:5.6139, R:0.0099, T:0.5947(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6292 (C:5.6119, R:0.0099, T:0.6282(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5776 (C:5.5920, R:0.0100, T:0.5766(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5666 (C:5.5613, R:0.0100, T:0.5656(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6088 (C:5.5880, R:0.0099, T:0.6078(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5678 (C:5.6413, R:0.0100, T:0.5668(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6039

ğŸ“Š EPOCH 26 TRAINING SUMMARY:
  Total Loss: 0.6049
  Contrastive: 5.6131
  Reconstruction: 0.0100
  Topological: 0.6039 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 7.5520
  Contrastive: 4.1450
  Reconstruction: 0.0099
  Topological: 7.5510 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 26/300 COMPLETE (45.4s)
Train Loss: 0.6049 (C:5.6131, R:0.0100, T:0.6039)
Val Loss:   7.5520 (C:4.1450, R:0.0099, T:7.5510)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 27 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6270 (C:5.6087, R:0.0100, T:0.6260(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5806 (C:5.6233, R:0.0099, T:0.5796(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5605 (C:5.6055, R:0.0100, T:0.5595(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5922 (C:5.5895, R:0.0100, T:0.5912(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6214 (C:5.6276, R:0.0099, T:0.6204(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6176 (C:5.6195, R:0.0100, T:0.6166(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6277 (C:5.6396, R:0.0099, T:0.6267(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5822 (C:5.5862, R:0.0099, T:0.5812(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6075 (C:5.6213, R:0.0100, T:0.6065(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6019 (C:5.5837, R:0.0100, T:0.6009(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6127 (C:5.5907, R:0.0099, T:0.6117(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6273 (C:5.5842, R:0.0100, T:0.6263(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5739 (C:5.5553, R:0.0099, T:0.5729(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6055 (C:5.5419, R:0.0100, T:0.6045(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5826 (C:5.6379, R:0.0100, T:0.5816(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6042 (C:5.6433, R:0.0100, T:0.6032(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5859 (C:5.5702, R:0.0100, T:0.5849(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6308 (C:5.6060, R:0.0100, T:0.6298(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5847 (C:5.6045, R:0.0100, T:0.5837(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6376 (C:5.5921, R:0.0099, T:0.6366(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6268 (C:5.5960, R:0.0100, T:0.6258(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5816 (C:5.6392, R:0.0100, T:0.5806(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 27 TRAINING SUMMARY:
  Total Loss: 0.6056
  Contrastive: 5.6089
  Reconstruction: 0.0100
  Topological: 0.6046 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 7.4663
  Contrastive: 4.1698
  Reconstruction: 0.0099
  Topological: 7.4654 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 27/300 COMPLETE (45.0s)
Train Loss: 0.6056 (C:5.6089, R:0.0100, T:0.6046)
Val Loss:   7.4663 (C:4.1698, R:0.0099, T:7.4654)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 28 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6112 (C:5.5895, R:0.0100, T:0.6102(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6207 (C:5.5755, R:0.0100, T:0.6197(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5822 (C:5.6009, R:0.0099, T:0.5812(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6055 (C:5.6476, R:0.0099, T:0.6045(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5755 (C:5.5796, R:0.0099, T:0.5745(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6035 (C:5.6636, R:0.0100, T:0.6025(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6119 (C:5.6214, R:0.0099, T:0.6109(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5958 (C:5.6380, R:0.0100, T:0.5948(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5980 (C:5.6043, R:0.0100, T:0.5970(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5831 (C:5.6267, R:0.0100, T:0.5821(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5767 (C:5.6228, R:0.0099, T:0.5757(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5870 (C:5.6052, R:0.0100, T:0.5860(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5968 (C:5.5890, R:0.0100, T:0.5958(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5981 (C:5.5733, R:0.0100, T:0.5971(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5712 (C:5.6065, R:0.0099, T:0.5702(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6022 (C:5.6110, R:0.0099, T:0.6012(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5879 (C:5.6108, R:0.0100, T:0.5869(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6004 (C:5.6051, R:0.0099, T:0.5994(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5682 (C:5.6222, R:0.0099, T:0.5672(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6293 (C:5.5877, R:0.0100, T:0.6283(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5778 (C:5.6144, R:0.0100, T:0.5768(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6184 (C:5.6440, R:0.0099, T:0.6174(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.6007

ğŸ“Š EPOCH 28 TRAINING SUMMARY:
  Total Loss: 0.6017
  Contrastive: 5.6094
  Reconstruction: 0.0100
  Topological: 0.6007 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 7.4018
  Contrastive: 4.1347
  Reconstruction: 0.0099
  Topological: 7.4008 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 28/300 COMPLETE (45.8s)
Train Loss: 0.6017 (C:5.6094, R:0.0100, T:0.6007)
Val Loss:   7.4018 (C:4.1347, R:0.0099, T:7.4008)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 29 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5641 (C:5.5635, R:0.0099, T:0.5631(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6103 (C:5.6510, R:0.0100, T:0.6093(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5694 (C:5.6236, R:0.0100, T:0.5684(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5818 (C:5.5759, R:0.0099, T:0.5808(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5909 (C:5.6161, R:0.0100, T:0.5899(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6075 (C:5.6011, R:0.0099, T:0.6065(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5759 (C:5.6515, R:0.0100, T:0.5749(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6041 (C:5.6254, R:0.0100, T:0.6031(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6194 (C:5.6096, R:0.0100, T:0.6184(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6188 (C:5.6259, R:0.0100, T:0.6178(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6170 (C:5.6149, R:0.0100, T:0.6160(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6044 (C:5.6357, R:0.0099, T:0.6035(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6002 (C:5.6323, R:0.0099, T:0.5992(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6086 (C:5.5957, R:0.0099, T:0.6076(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5731 (C:5.5921, R:0.0100, T:0.5721(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6279 (C:5.6313, R:0.0099, T:0.6269(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6213 (C:5.5723, R:0.0100, T:0.6203(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6019 (C:5.5966, R:0.0100, T:0.6009(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5898 (C:5.6196, R:0.0099, T:0.5888(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6054 (C:5.5990, R:0.0100, T:0.6044(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6074 (C:5.6188, R:0.0099, T:0.6064(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5911 (C:5.5757, R:0.0099, T:0.5901(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5988

ğŸ“Š EPOCH 29 TRAINING SUMMARY:
  Total Loss: 0.5998
  Contrastive: 5.6106
  Reconstruction: 0.0100
  Topological: 0.5988 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 7.2104
  Contrastive: 4.1796
  Reconstruction: 0.0099
  Topological: 7.2095 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 29/300 COMPLETE (46.3s)
Train Loss: 0.5998 (C:5.6106, R:0.0100, T:0.5988)
Val Loss:   7.2104 (C:4.1796, R:0.0099, T:7.2095)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 30 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5857 (C:5.5795, R:0.0099, T:0.5847(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5967 (C:5.5675, R:0.0100, T:0.5957(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5665 (C:5.6418, R:0.0100, T:0.5655(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5901 (C:5.6014, R:0.0099, T:0.5891(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5998 (C:5.6274, R:0.0100, T:0.5988(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6136 (C:5.5744, R:0.0099, T:0.6126(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5695 (C:5.6122, R:0.0100, T:0.5686(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5971 (C:5.6312, R:0.0099, T:0.5961(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6016 (C:5.6158, R:0.0099, T:0.6006(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6171 (C:5.6860, R:0.0100, T:0.6161(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5936 (C:5.5862, R:0.0100, T:0.5926(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5946 (C:5.5981, R:0.0099, T:0.5936(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6023 (C:5.6454, R:0.0100, T:0.6013(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6045 (C:5.5682, R:0.0100, T:0.6035(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6225 (C:5.6306, R:0.0100, T:0.6215(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5833 (C:5.5436, R:0.0099, T:0.5823(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5936 (C:5.5688, R:0.0099, T:0.5926(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5750 (C:5.5753, R:0.0099, T:0.5740(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6072 (C:5.6183, R:0.0100, T:0.6062(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6167 (C:5.5596, R:0.0099, T:0.6158(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5907 (C:5.6352, R:0.0099, T:0.5897(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6196 (C:5.6196, R:0.0099, T:0.6186(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5979

ğŸ“Š EPOCH 30 TRAINING SUMMARY:
  Total Loss: 0.5989
  Contrastive: 5.6089
  Reconstruction: 0.0100
  Topological: 0.5979 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 7.0199
  Contrastive: 4.2155
  Reconstruction: 0.0099
  Topological: 7.0189 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 30/300 COMPLETE (45.1s)
Train Loss: 0.5989 (C:5.6089, R:0.0100, T:0.5979)
Val Loss:   7.0199 (C:4.2155, R:0.0099, T:7.0189)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 31 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6130 (C:5.5829, R:0.0100, T:0.6120(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5933 (C:5.6503, R:0.0099, T:0.5923(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6080 (C:5.5828, R:0.0099, T:0.6070(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6242 (C:5.6321, R:0.0099, T:0.6232(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6048 (C:5.5659, R:0.0100, T:0.6038(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6052 (C:5.5838, R:0.0100, T:0.6042(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5677 (C:5.5822, R:0.0100, T:0.5667(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5672 (C:5.6112, R:0.0099, T:0.5662(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6134 (C:5.5919, R:0.0100, T:0.6124(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6009 (C:5.6272, R:0.0099, T:0.5999(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5863 (C:5.5932, R:0.0099, T:0.5853(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6041 (C:5.6253, R:0.0099, T:0.6031(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5924 (C:5.6016, R:0.0100, T:0.5914(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5950 (C:5.5970, R:0.0099, T:0.5940(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6032 (C:5.5967, R:0.0100, T:0.6022(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5606 (C:5.5980, R:0.0099, T:0.5596(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6115 (C:5.5935, R:0.0099, T:0.6105(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6172 (C:5.6793, R:0.0100, T:0.6162(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5706 (C:5.6190, R:0.0099, T:0.5696(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6037 (C:5.5740, R:0.0100, T:0.6027(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6032 (C:5.6298, R:0.0099, T:0.6022(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6267 (C:5.6273, R:0.0100, T:0.6257(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5960

ğŸ“Š EPOCH 31 TRAINING SUMMARY:
  Total Loss: 0.5970
  Contrastive: 5.6084
  Reconstruction: 0.0100
  Topological: 0.5960 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.8379
  Contrastive: 4.2079
  Reconstruction: 0.0099
  Topological: 6.8369 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 31/300 COMPLETE (45.4s)
Train Loss: 0.5970 (C:5.6084, R:0.0100, T:0.5960)
Val Loss:   6.8379 (C:4.2079, R:0.0099, T:6.8369)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 32 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6002 (C:5.6045, R:0.0099, T:0.5992(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6222 (C:5.5566, R:0.0099, T:0.6212(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5881 (C:5.6111, R:0.0100, T:0.5872(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5984 (C:5.5799, R:0.0099, T:0.5974(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6134 (C:5.6172, R:0.0100, T:0.6124(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5728 (C:5.6351, R:0.0100, T:0.5718(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5828 (C:5.6001, R:0.0099, T:0.5818(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6079 (C:5.6345, R:0.0099, T:0.6069(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6113 (C:5.5786, R:0.0100, T:0.6103(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5978 (C:5.6097, R:0.0100, T:0.5968(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5517 (C:5.5693, R:0.0100, T:0.5507(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5771 (C:5.5890, R:0.0100, T:0.5761(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5914 (C:5.6159, R:0.0100, T:0.5904(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6254 (C:5.6455, R:0.0100, T:0.6244(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5948 (C:5.6171, R:0.0100, T:0.5938(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6115 (C:5.6667, R:0.0099, T:0.6105(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5879 (C:5.6138, R:0.0100, T:0.5869(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5999 (C:5.6377, R:0.0100, T:0.5989(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5980 (C:5.6055, R:0.0100, T:0.5970(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5768 (C:5.6680, R:0.0100, T:0.5759(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6200 (C:5.6477, R:0.0100, T:0.6190(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5979 (C:5.5603, R:0.0099, T:0.5969(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 32 TRAINING SUMMARY:
  Total Loss: 0.5971
  Contrastive: 5.6071
  Reconstruction: 0.0100
  Topological: 0.5961 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.6834
  Contrastive: 4.2403
  Reconstruction: 0.0099
  Topological: 6.6824 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 32/300 COMPLETE (45.3s)
Train Loss: 0.5971 (C:5.6071, R:0.0100, T:0.5961)
Val Loss:   6.6834 (C:4.2403, R:0.0099, T:6.6824)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 33 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6412 (C:5.6275, R:0.0100, T:0.6402(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6160 (C:5.6038, R:0.0099, T:0.6150(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6134 (C:5.5824, R:0.0100, T:0.6124(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5497 (C:5.6379, R:0.0099, T:0.5488(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5958 (C:5.5731, R:0.0099, T:0.5948(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6211 (C:5.6633, R:0.0100, T:0.6201(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5853 (C:5.5963, R:0.0099, T:0.5843(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5799 (C:5.6363, R:0.0099, T:0.5789(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5957 (C:5.6016, R:0.0099, T:0.5947(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5951 (C:5.5792, R:0.0100, T:0.5941(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5718 (C:5.5698, R:0.0100, T:0.5708(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5700 (C:5.5890, R:0.0100, T:0.5690(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5991 (C:5.6268, R:0.0099, T:0.5981(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5563 (C:5.5921, R:0.0100, T:0.5553(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5878 (C:5.6214, R:0.0099, T:0.5868(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6077 (C:5.5745, R:0.0099, T:0.6067(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5885 (C:5.6053, R:0.0099, T:0.5875(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5804 (C:5.6006, R:0.0100, T:0.5794(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6181 (C:5.6184, R:0.0100, T:0.6171(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5868 (C:5.5975, R:0.0100, T:0.5858(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6089 (C:5.6371, R:0.0100, T:0.6079(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6190 (C:5.5796, R:0.0099, T:0.6180(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5932

ğŸ“Š EPOCH 33 TRAINING SUMMARY:
  Total Loss: 0.5941
  Contrastive: 5.6050
  Reconstruction: 0.0100
  Topological: 0.5932 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.6019
  Contrastive: 4.2522
  Reconstruction: 0.0099
  Topological: 6.6009 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 33/300 COMPLETE (44.6s)
Train Loss: 0.5941 (C:5.6050, R:0.0100, T:0.5932)
Val Loss:   6.6019 (C:4.2522, R:0.0099, T:6.6009)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 34 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5892 (C:5.5982, R:0.0099, T:0.5882(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6070 (C:5.6250, R:0.0100, T:0.6060(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6028 (C:5.5966, R:0.0099, T:0.6018(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5942 (C:5.6377, R:0.0100, T:0.5932(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6031 (C:5.6398, R:0.0100, T:0.6021(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6403 (C:5.6509, R:0.0100, T:0.6393(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5718 (C:5.6137, R:0.0100, T:0.5708(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6013 (C:5.5749, R:0.0099, T:0.6003(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6145 (C:5.6197, R:0.0100, T:0.6135(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5906 (C:5.5929, R:0.0100, T:0.5896(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5711 (C:5.5888, R:0.0099, T:0.5701(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5402 (C:5.5904, R:0.0099, T:0.5393(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6100 (C:5.5807, R:0.0100, T:0.6090(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5908 (C:5.6331, R:0.0100, T:0.5898(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6057 (C:5.6420, R:0.0100, T:0.6047(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6311 (C:5.6681, R:0.0099, T:0.6301(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5980 (C:5.6357, R:0.0100, T:0.5970(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6041 (C:5.5607, R:0.0100, T:0.6031(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5776 (C:5.6297, R:0.0099, T:0.5766(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6043 (C:5.5332, R:0.0099, T:0.6033(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5930 (C:5.5710, R:0.0100, T:0.5920(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5642 (C:5.6269, R:0.0100, T:0.5632(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 34 TRAINING SUMMARY:
  Total Loss: 0.5947
  Contrastive: 5.6059
  Reconstruction: 0.0100
  Topological: 0.5937 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.6119
  Contrastive: 4.2505
  Reconstruction: 0.0099
  Topological: 6.6109 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 34/300 COMPLETE (45.0s)
Train Loss: 0.5947 (C:5.6059, R:0.0100, T:0.5937)
Val Loss:   6.6119 (C:4.2505, R:0.0099, T:6.6109)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 35 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5802 (C:5.5888, R:0.0099, T:0.5793(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5915 (C:5.6175, R:0.0100, T:0.5905(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5684 (C:5.5653, R:0.0099, T:0.5674(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6003 (C:5.6258, R:0.0099, T:0.5993(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5976 (C:5.5933, R:0.0100, T:0.5966(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6019 (C:5.6319, R:0.0100, T:0.6009(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5708 (C:5.6246, R:0.0099, T:0.5698(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6281 (C:5.5947, R:0.0099, T:0.6271(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5908 (C:5.5900, R:0.0099, T:0.5898(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5863 (C:5.6135, R:0.0100, T:0.5853(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5954 (C:5.6403, R:0.0100, T:0.5944(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5833 (C:5.5632, R:0.0099, T:0.5823(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5924 (C:5.6140, R:0.0100, T:0.5914(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5543 (C:5.6276, R:0.0099, T:0.5533(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5865 (C:5.5988, R:0.0099, T:0.5855(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5896 (C:5.6183, R:0.0100, T:0.5886(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6117 (C:5.5827, R:0.0099, T:0.6107(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6302 (C:5.6124, R:0.0099, T:0.6292(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5837 (C:5.5828, R:0.0099, T:0.5827(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5826 (C:5.6115, R:0.0099, T:0.5816(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5898 (C:5.6082, R:0.0099, T:0.5888(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5608 (C:5.5945, R:0.0099, T:0.5599(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5910

ğŸ“Š EPOCH 35 TRAINING SUMMARY:
  Total Loss: 0.5920
  Contrastive: 5.6021
  Reconstruction: 0.0100
  Topological: 0.5910 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.4590
  Contrastive: 4.2764
  Reconstruction: 0.0099
  Topological: 6.4580 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 35/300 COMPLETE (46.7s)
Train Loss: 0.5920 (C:5.6021, R:0.0100, T:0.5910)
Val Loss:   6.4590 (C:4.2764, R:0.0099, T:6.4580)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 36 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5806 (C:5.6303, R:0.0100, T:0.5796(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5858 (C:5.5613, R:0.0099, T:0.5848(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5963 (C:5.5880, R:0.0100, T:0.5953(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5919 (C:5.6337, R:0.0100, T:0.5909(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6310 (C:5.5931, R:0.0099, T:0.6300(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5846 (C:5.6365, R:0.0100, T:0.5836(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6013 (C:5.6056, R:0.0099, T:0.6003(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5906 (C:5.5689, R:0.0100, T:0.5896(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6231 (C:5.5745, R:0.0100, T:0.6221(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5766 (C:5.6388, R:0.0100, T:0.5756(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5802 (C:5.5543, R:0.0100, T:0.5792(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5969 (C:5.5980, R:0.0100, T:0.5959(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5933 (C:5.5810, R:0.0100, T:0.5923(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6046 (C:5.6286, R:0.0100, T:0.6036(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6128 (C:5.6299, R:0.0100, T:0.6118(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5741 (C:5.6167, R:0.0100, T:0.5731(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6013 (C:5.5921, R:0.0100, T:0.6003(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5985 (C:5.6129, R:0.0099, T:0.5975(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5741 (C:5.5586, R:0.0100, T:0.5731(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5988 (C:5.6323, R:0.0100, T:0.5978(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5941 (C:5.6005, R:0.0100, T:0.5931(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5814 (C:5.5783, R:0.0100, T:0.5804(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 36 TRAINING SUMMARY:
  Total Loss: 0.5938
  Contrastive: 5.6006
  Reconstruction: 0.0100
  Topological: 0.5928 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.3294
  Contrastive: 4.2886
  Reconstruction: 0.0099
  Topological: 6.3284 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 36/300 COMPLETE (46.6s)
Train Loss: 0.5938 (C:5.6006, R:0.0100, T:0.5928)
Val Loss:   6.3294 (C:4.2886, R:0.0099, T:6.3284)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 37 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6071 (C:5.6404, R:0.0100, T:0.6061(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6080 (C:5.6109, R:0.0100, T:0.6070(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5976 (C:5.6007, R:0.0100, T:0.5966(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6086 (C:5.6593, R:0.0100, T:0.6076(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5940 (C:5.5650, R:0.0100, T:0.5930(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5686 (C:5.5982, R:0.0100, T:0.5676(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5677 (C:5.6331, R:0.0100, T:0.5667(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5828 (C:5.5947, R:0.0100, T:0.5818(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5645 (C:5.6042, R:0.0100, T:0.5635(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5961 (C:5.5658, R:0.0099, T:0.5951(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5992 (C:5.6129, R:0.0099, T:0.5982(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6027 (C:5.6112, R:0.0100, T:0.6017(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6131 (C:5.5843, R:0.0100, T:0.6121(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5975 (C:5.5973, R:0.0100, T:0.5965(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5883 (C:5.6066, R:0.0100, T:0.5873(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6349 (C:5.5944, R:0.0100, T:0.6339(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6176 (C:5.5976, R:0.0100, T:0.6166(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6247 (C:5.5858, R:0.0100, T:0.6237(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5850 (C:5.6620, R:0.0100, T:0.5840(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5928 (C:5.5825, R:0.0100, T:0.5918(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6306 (C:5.6625, R:0.0100, T:0.6296(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5766 (C:5.5855, R:0.0099, T:0.5756(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5907

ğŸ“Š EPOCH 37 TRAINING SUMMARY:
  Total Loss: 0.5917
  Contrastive: 5.6024
  Reconstruction: 0.0100
  Topological: 0.5907 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.3379
  Contrastive: 4.2824
  Reconstruction: 0.0099
  Topological: 6.3369 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 37/300 COMPLETE (46.0s)
Train Loss: 0.5917 (C:5.6024, R:0.0100, T:0.5907)
Val Loss:   6.3379 (C:4.2824, R:0.0099, T:6.3369)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 38 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6083 (C:5.6183, R:0.0100, T:0.6073(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5565 (C:5.6058, R:0.0100, T:0.5555(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6191 (C:5.6008, R:0.0100, T:0.6181(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5798 (C:5.6484, R:0.0100, T:0.5788(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5871 (C:5.5612, R:0.0099, T:0.5861(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5997 (C:5.5831, R:0.0099, T:0.5987(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5787 (C:5.5791, R:0.0099, T:0.5777(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5851 (C:5.6087, R:0.0100, T:0.5841(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5825 (C:5.5972, R:0.0099, T:0.5815(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5806 (C:5.6653, R:0.0100, T:0.5796(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6012 (C:5.5890, R:0.0099, T:0.6002(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5941 (C:5.6100, R:0.0100, T:0.5931(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5826 (C:5.5921, R:0.0100, T:0.5816(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6491 (C:5.5811, R:0.0100, T:0.6481(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6151 (C:5.5891, R:0.0100, T:0.6141(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5914 (C:5.5639, R:0.0099, T:0.5904(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6114 (C:5.5950, R:0.0099, T:0.6104(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5669 (C:5.5858, R:0.0099, T:0.5659(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5746 (C:5.6602, R:0.0100, T:0.5737(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6202 (C:5.5456, R:0.0100, T:0.6192(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5796 (C:5.6266, R:0.0099, T:0.5786(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5827 (C:5.6021, R:0.0099, T:0.5817(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 38 TRAINING SUMMARY:
  Total Loss: 0.5921
  Contrastive: 5.6006
  Reconstruction: 0.0100
  Topological: 0.5911 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.0649
  Contrastive: 4.3347
  Reconstruction: 0.0099
  Topological: 6.0639 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 38/300 COMPLETE (46.0s)
Train Loss: 0.5921 (C:5.6006, R:0.0100, T:0.5911)
Val Loss:   6.0649 (C:4.3347, R:0.0099, T:6.0639)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 39 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5759 (C:5.6303, R:0.0100, T:0.5749(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5713 (C:5.6056, R:0.0099, T:0.5703(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5756 (C:5.6240, R:0.0099, T:0.5746(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5950 (C:5.6110, R:0.0099, T:0.5940(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5996 (C:5.5589, R:0.0099, T:0.5986(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5766 (C:5.6128, R:0.0099, T:0.5756(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5874 (C:5.5988, R:0.0100, T:0.5864(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5894 (C:5.5873, R:0.0100, T:0.5884(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6105 (C:5.6173, R:0.0100, T:0.6095(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5703 (C:5.6290, R:0.0100, T:0.5694(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5763 (C:5.5723, R:0.0099, T:0.5753(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5871 (C:5.6216, R:0.0100, T:0.5861(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5763 (C:5.6285, R:0.0100, T:0.5753(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5842 (C:5.5864, R:0.0100, T:0.5832(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5652 (C:5.5684, R:0.0099, T:0.5642(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5719 (C:5.5783, R:0.0100, T:0.5709(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5720 (C:5.6058, R:0.0099, T:0.5711(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6248 (C:5.6397, R:0.0099, T:0.6238(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6044 (C:5.5823, R:0.0100, T:0.6034(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5497 (C:5.6105, R:0.0099, T:0.5487(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5934 (C:5.5583, R:0.0099, T:0.5924(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5719 (C:5.5759, R:0.0099, T:0.5709(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5887

ğŸ“Š EPOCH 39 TRAINING SUMMARY:
  Total Loss: 0.5897
  Contrastive: 5.6006
  Reconstruction: 0.0100
  Topological: 0.5887 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.1840
  Contrastive: 4.2812
  Reconstruction: 0.0099
  Topological: 6.1830 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 39/300 COMPLETE (49.6s)
Train Loss: 0.5897 (C:5.6006, R:0.0100, T:0.5887)
Val Loss:   6.1840 (C:4.2812, R:0.0099, T:6.1830)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 40 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5807 (C:5.5898, R:0.0099, T:0.5797(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6129 (C:5.6080, R:0.0100, T:0.6119(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5904 (C:5.5745, R:0.0099, T:0.5894(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5834 (C:5.5868, R:0.0100, T:0.5824(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5891 (C:5.6449, R:0.0100, T:0.5881(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5738 (C:5.6196, R:0.0100, T:0.5728(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6073 (C:5.5675, R:0.0100, T:0.6063(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5923 (C:5.6472, R:0.0099, T:0.5914(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5917 (C:5.5754, R:0.0099, T:0.5907(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6249 (C:5.5885, R:0.0100, T:0.6239(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5758 (C:5.5627, R:0.0100, T:0.5748(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5603 (C:5.5927, R:0.0100, T:0.5593(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6187 (C:5.5732, R:0.0100, T:0.6177(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5803 (C:5.6042, R:0.0099, T:0.5793(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6163 (C:5.5729, R:0.0099, T:0.6153(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5904 (C:5.6085, R:0.0099, T:0.5894(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5947 (C:5.5670, R:0.0099, T:0.5937(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5894 (C:5.6174, R:0.0099, T:0.5884(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5980 (C:5.6227, R:0.0099, T:0.5970(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6073 (C:5.6250, R:0.0100, T:0.6063(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5582 (C:5.5779, R:0.0100, T:0.5572(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5920 (C:5.6057, R:0.0100, T:0.5910(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5880

ğŸ“Š EPOCH 40 TRAINING SUMMARY:
  Total Loss: 0.5890
  Contrastive: 5.5986
  Reconstruction: 0.0100
  Topological: 0.5880 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.1810
  Contrastive: 4.3081
  Reconstruction: 0.0099
  Topological: 6.1800 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 40/300 COMPLETE (47.7s)
Train Loss: 0.5890 (C:5.5986, R:0.0100, T:0.5880)
Val Loss:   6.1810 (C:4.3081, R:0.0099, T:6.1800)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 41 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5822 (C:5.6139, R:0.0100, T:0.5812(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5728 (C:5.6337, R:0.0099, T:0.5718(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5682 (C:5.6473, R:0.0100, T:0.5672(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6113 (C:5.5475, R:0.0100, T:0.6103(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6050 (C:5.6597, R:0.0100, T:0.6040(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5809 (C:5.6071, R:0.0100, T:0.5799(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5463 (C:5.5741, R:0.0100, T:0.5453(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6398 (C:5.6584, R:0.0100, T:0.6388(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6239 (C:5.5710, R:0.0099, T:0.6229(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5780 (C:5.5801, R:0.0100, T:0.5770(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5891 (C:5.5944, R:0.0099, T:0.5881(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6050 (C:5.5795, R:0.0099, T:0.6041(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5323 (C:5.5857, R:0.0099, T:0.5313(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5877 (C:5.6191, R:0.0100, T:0.5867(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5920 (C:5.5931, R:0.0100, T:0.5910(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6265 (C:5.6675, R:0.0099, T:0.6255(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6447 (C:5.6460, R:0.0099, T:0.6437(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5843 (C:5.6393, R:0.0100, T:0.5833(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6276 (C:5.5960, R:0.0100, T:0.6266(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5949 (C:5.5912, R:0.0099, T:0.5939(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5689 (C:5.5739, R:0.0099, T:0.5679(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5737 (C:5.5756, R:0.0100, T:0.5727(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 41 TRAINING SUMMARY:
  Total Loss: 0.5910
  Contrastive: 5.5991
  Reconstruction: 0.0100
  Topological: 0.5900 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.1242
  Contrastive: 4.2989
  Reconstruction: 0.0099
  Topological: 6.1232 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 41/300 COMPLETE (45.9s)
Train Loss: 0.5910 (C:5.5991, R:0.0100, T:0.5900)
Val Loss:   6.1242 (C:4.2989, R:0.0099, T:6.1232)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 42 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5770 (C:5.5710, R:0.0099, T:0.5760(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5904 (C:5.6445, R:0.0100, T:0.5894(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6015 (C:5.6119, R:0.0099, T:0.6005(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5990 (C:5.5783, R:0.0100, T:0.5980(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6040 (C:5.6100, R:0.0100, T:0.6030(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5833 (C:5.5960, R:0.0099, T:0.5823(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5933 (C:5.5918, R:0.0099, T:0.5923(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5697 (C:5.6038, R:0.0100, T:0.5687(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5789 (C:5.5969, R:0.0099, T:0.5779(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5587 (C:5.5918, R:0.0100, T:0.5577(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5767 (C:5.5958, R:0.0100, T:0.5757(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5674 (C:5.6506, R:0.0100, T:0.5664(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5769 (C:5.6002, R:0.0100, T:0.5759(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6013 (C:5.6070, R:0.0100, T:0.6003(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5839 (C:5.5782, R:0.0100, T:0.5829(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5822 (C:5.6237, R:0.0100, T:0.5812(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5883 (C:5.5685, R:0.0100, T:0.5873(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6056 (C:5.5595, R:0.0099, T:0.6047(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5824 (C:5.6386, R:0.0100, T:0.5814(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5991 (C:5.5913, R:0.0100, T:0.5981(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5789 (C:5.5838, R:0.0100, T:0.5779(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5621 (C:5.6368, R:0.0100, T:0.5611(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5879

ğŸ“Š EPOCH 42 TRAINING SUMMARY:
  Total Loss: 0.5889
  Contrastive: 5.5987
  Reconstruction: 0.0100
  Topological: 0.5879 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 6.0093
  Contrastive: 4.2976
  Reconstruction: 0.0099
  Topological: 6.0083 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 42/300 COMPLETE (45.7s)
Train Loss: 0.5889 (C:5.5987, R:0.0100, T:0.5879)
Val Loss:   6.0093 (C:4.2976, R:0.0099, T:6.0083)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 43 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5878 (C:5.6015, R:0.0099, T:0.5868(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5962 (C:5.5881, R:0.0099, T:0.5952(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5769 (C:5.5984, R:0.0099, T:0.5759(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6340 (C:5.5864, R:0.0100, T:0.6330(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5835 (C:5.5779, R:0.0100, T:0.5825(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5712 (C:5.6180, R:0.0100, T:0.5702(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6163 (C:5.6293, R:0.0100, T:0.6153(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5989 (C:5.6206, R:0.0100, T:0.5979(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5706 (C:5.6143, R:0.0100, T:0.5696(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5503 (C:5.6148, R:0.0100, T:0.5493(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5997 (C:5.6039, R:0.0100, T:0.5987(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5983 (C:5.5555, R:0.0100, T:0.5973(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5866 (C:5.5932, R:0.0100, T:0.5856(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5755 (C:5.5896, R:0.0100, T:0.5745(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5526 (C:5.6051, R:0.0100, T:0.5516(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5626 (C:5.5917, R:0.0099, T:0.5617(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5940 (C:5.6133, R:0.0100, T:0.5930(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5993 (C:5.5552, R:0.0100, T:0.5983(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6339 (C:5.5761, R:0.0099, T:0.6329(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6127 (C:5.6104, R:0.0100, T:0.6117(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6045 (C:5.6207, R:0.0099, T:0.6035(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5809 (C:5.6189, R:0.0100, T:0.5799(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5871

ğŸ“Š EPOCH 43 TRAINING SUMMARY:
  Total Loss: 0.5881
  Contrastive: 5.5985
  Reconstruction: 0.0100
  Topological: 0.5871 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.8629
  Contrastive: 4.3256
  Reconstruction: 0.0099
  Topological: 5.8619 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 43/300 COMPLETE (45.6s)
Train Loss: 0.5881 (C:5.5985, R:0.0100, T:0.5871)
Val Loss:   5.8629 (C:4.3256, R:0.0099, T:5.8619)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 44 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6041 (C:5.5883, R:0.0099, T:0.6032(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5700 (C:5.6180, R:0.0100, T:0.5690(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5662 (C:5.6231, R:0.0100, T:0.5652(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5833 (C:5.5879, R:0.0100, T:0.5823(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5786 (C:5.5627, R:0.0099, T:0.5776(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5841 (C:5.6460, R:0.0100, T:0.5831(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5846 (C:5.6427, R:0.0100, T:0.5836(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5884 (C:5.5875, R:0.0099, T:0.5874(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5937 (C:5.5468, R:0.0099, T:0.5927(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6003 (C:5.6004, R:0.0099, T:0.5993(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5823 (C:5.5900, R:0.0100, T:0.5813(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5863 (C:5.6074, R:0.0100, T:0.5853(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6116 (C:5.6022, R:0.0100, T:0.6106(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6089 (C:5.5631, R:0.0099, T:0.6079(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6084 (C:5.5578, R:0.0099, T:0.6074(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5574 (C:5.5786, R:0.0099, T:0.5564(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5634 (C:5.6320, R:0.0099, T:0.5624(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5708 (C:5.6019, R:0.0100, T:0.5698(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5840 (C:5.5715, R:0.0100, T:0.5830(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5926 (C:5.6183, R:0.0100, T:0.5916(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6007 (C:5.6178, R:0.0099, T:0.5997(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6207 (C:5.5997, R:0.0100, T:0.6197(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 44 TRAINING SUMMARY:
  Total Loss: 0.5886
  Contrastive: 5.5968
  Reconstruction: 0.0100
  Topological: 0.5876 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.9057
  Contrastive: 4.3380
  Reconstruction: 0.0099
  Topological: 5.9047 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 44/300 COMPLETE (43.6s)
Train Loss: 0.5886 (C:5.5968, R:0.0100, T:0.5876)
Val Loss:   5.9057 (C:4.3380, R:0.0099, T:5.9047)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 45 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6000 (C:5.5953, R:0.0100, T:0.5990(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6092 (C:5.6427, R:0.0099, T:0.6082(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5945 (C:5.6140, R:0.0100, T:0.5935(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5455 (C:5.6001, R:0.0100, T:0.5445(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5996 (C:5.5840, R:0.0100, T:0.5986(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5896 (C:5.5693, R:0.0099, T:0.5886(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5643 (C:5.6246, R:0.0100, T:0.5633(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5726 (C:5.6135, R:0.0100, T:0.5716(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5781 (C:5.5928, R:0.0100, T:0.5771(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5952 (C:5.6028, R:0.0100, T:0.5942(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5886 (C:5.6145, R:0.0100, T:0.5876(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6017 (C:5.6661, R:0.0100, T:0.6007(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6446 (C:5.5562, R:0.0100, T:0.6436(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6125 (C:5.5881, R:0.0099, T:0.6115(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5881 (C:5.5489, R:0.0100, T:0.5871(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6086 (C:5.5747, R:0.0100, T:0.6076(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5889 (C:5.6012, R:0.0100, T:0.5879(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5959 (C:5.6078, R:0.0100, T:0.5949(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5733 (C:5.5594, R:0.0099, T:0.5723(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6252 (C:5.5792, R:0.0100, T:0.6242(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6147 (C:5.5766, R:0.0100, T:0.6137(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5825 (C:5.5957, R:0.0100, T:0.5815(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 45 TRAINING SUMMARY:
  Total Loss: 0.5891
  Contrastive: 5.5966
  Reconstruction: 0.0100
  Topological: 0.5881 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.9532
  Contrastive: 4.3250
  Reconstruction: 0.0099
  Topological: 5.9522 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 45/300 COMPLETE (44.6s)
Train Loss: 0.5891 (C:5.5966, R:0.0100, T:0.5881)
Val Loss:   5.9532 (C:4.3250, R:0.0099, T:5.9522)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 46 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5901 (C:5.5839, R:0.0099, T:0.5891(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5689 (C:5.5905, R:0.0100, T:0.5679(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5714 (C:5.6212, R:0.0100, T:0.5704(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6098 (C:5.5426, R:0.0099, T:0.6088(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5679 (C:5.6282, R:0.0099, T:0.5669(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6198 (C:5.6023, R:0.0099, T:0.6188(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6103 (C:5.6157, R:0.0099, T:0.6093(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5923 (C:5.5508, R:0.0099, T:0.5913(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5971 (C:5.6360, R:0.0100, T:0.5961(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5922 (C:5.5330, R:0.0099, T:0.5912(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5741 (C:5.5513, R:0.0100, T:0.5731(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5729 (C:5.6349, R:0.0100, T:0.5719(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5968 (C:5.5973, R:0.0100, T:0.5959(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5903 (C:5.5655, R:0.0099, T:0.5893(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5820 (C:5.5707, R:0.0099, T:0.5810(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5884 (C:5.5853, R:0.0099, T:0.5874(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5821 (C:5.5601, R:0.0100, T:0.5811(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5729 (C:5.6119, R:0.0100, T:0.5719(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5796 (C:5.6315, R:0.0100, T:0.5786(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5853 (C:5.5844, R:0.0100, T:0.5843(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5877 (C:5.6134, R:0.0099, T:0.5867(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5756 (C:5.6354, R:0.0100, T:0.5746(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5868

ğŸ“Š EPOCH 46 TRAINING SUMMARY:
  Total Loss: 0.5878
  Contrastive: 5.5963
  Reconstruction: 0.0100
  Topological: 0.5868 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.7790
  Contrastive: 4.3385
  Reconstruction: 0.0099
  Topological: 5.7780 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 46/300 COMPLETE (44.7s)
Train Loss: 0.5878 (C:5.5963, R:0.0100, T:0.5868)
Val Loss:   5.7790 (C:4.3385, R:0.0099, T:5.7780)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 47 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5909 (C:5.6043, R:0.0100, T:0.5899(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5952 (C:5.6059, R:0.0100, T:0.5942(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5753 (C:5.6266, R:0.0100, T:0.5743(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5870 (C:5.5958, R:0.0100, T:0.5860(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5903 (C:5.5754, R:0.0099, T:0.5893(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5713 (C:5.6235, R:0.0100, T:0.5703(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5461 (C:5.5813, R:0.0100, T:0.5451(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6045 (C:5.6368, R:0.0100, T:0.6035(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5678 (C:5.5692, R:0.0099, T:0.5668(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5924 (C:5.6160, R:0.0100, T:0.5914(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6050 (C:5.6274, R:0.0100, T:0.6040(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5871 (C:5.6089, R:0.0100, T:0.5861(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6057 (C:5.5911, R:0.0099, T:0.6047(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5706 (C:5.5892, R:0.0100, T:0.5696(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5846 (C:5.6228, R:0.0099, T:0.5836(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5781 (C:5.5478, R:0.0100, T:0.5771(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6158 (C:5.6301, R:0.0099, T:0.6148(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5967 (C:5.5439, R:0.0099, T:0.5957(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5979 (C:5.6415, R:0.0100, T:0.5969(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5814 (C:5.6108, R:0.0100, T:0.5804(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5697 (C:5.6179, R:0.0099, T:0.5687(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6160 (C:5.6322, R:0.0100, T:0.6150(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 47 TRAINING SUMMARY:
  Total Loss: 0.5879
  Contrastive: 5.5945
  Reconstruction: 0.0100
  Topological: 0.5869 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.8060
  Contrastive: 4.3300
  Reconstruction: 0.0099
  Topological: 5.8050 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 47/300 COMPLETE (45.6s)
Train Loss: 0.5879 (C:5.5945, R:0.0100, T:0.5869)
Val Loss:   5.8060 (C:4.3300, R:0.0099, T:5.8050)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 48 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6139 (C:5.5926, R:0.0100, T:0.6129(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6057 (C:5.6284, R:0.0099, T:0.6047(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6069 (C:5.6088, R:0.0100, T:0.6059(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5434 (C:5.5914, R:0.0100, T:0.5424(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5765 (C:5.5648, R:0.0100, T:0.5755(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5852 (C:5.5333, R:0.0099, T:0.5842(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5706 (C:5.5854, R:0.0099, T:0.5696(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5564 (C:5.5904, R:0.0099, T:0.5554(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5836 (C:5.5856, R:0.0100, T:0.5826(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5859 (C:5.5438, R:0.0099, T:0.5849(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5680 (C:5.5899, R:0.0099, T:0.5670(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5863 (C:5.5770, R:0.0100, T:0.5853(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5789 (C:5.6525, R:0.0100, T:0.5779(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5584 (C:5.5722, R:0.0100, T:0.5574(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5816 (C:5.5766, R:0.0100, T:0.5806(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5908 (C:5.5635, R:0.0100, T:0.5898(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5879 (C:5.6041, R:0.0099, T:0.5869(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6269 (C:5.6022, R:0.0100, T:0.6259(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5872 (C:5.5914, R:0.0100, T:0.5862(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5808 (C:5.6144, R:0.0099, T:0.5798(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5644 (C:5.6050, R:0.0100, T:0.5634(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5801 (C:5.5867, R:0.0100, T:0.5791(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5860

ğŸ“Š EPOCH 48 TRAINING SUMMARY:
  Total Loss: 0.5870
  Contrastive: 5.5946
  Reconstruction: 0.0100
  Topological: 0.5860 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.6811
  Contrastive: 4.3588
  Reconstruction: 0.0099
  Topological: 5.6801 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 48/300 COMPLETE (46.0s)
Train Loss: 0.5870 (C:5.5946, R:0.0100, T:0.5860)
Val Loss:   5.6811 (C:4.3588, R:0.0099, T:5.6801)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 49 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5901 (C:5.6171, R:0.0100, T:0.5891(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6245 (C:5.6154, R:0.0100, T:0.6235(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5811 (C:5.5995, R:0.0100, T:0.5801(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6123 (C:5.5827, R:0.0100, T:0.6113(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5703 (C:5.5914, R:0.0099, T:0.5693(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5890 (C:5.6010, R:0.0100, T:0.5880(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5998 (C:5.5865, R:0.0100, T:0.5988(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5645 (C:5.5446, R:0.0099, T:0.5635(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5887 (C:5.5743, R:0.0099, T:0.5877(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5812 (C:5.6248, R:0.0100, T:0.5802(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6068 (C:5.5907, R:0.0099, T:0.6058(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5733 (C:5.5853, R:0.0100, T:0.5723(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6293 (C:5.6383, R:0.0100, T:0.6283(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5823 (C:5.5344, R:0.0099, T:0.5813(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5863 (C:5.6272, R:0.0099, T:0.5853(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5864 (C:5.5737, R:0.0099, T:0.5854(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5806 (C:5.5906, R:0.0099, T:0.5797(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5876 (C:5.5566, R:0.0099, T:0.5866(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5820 (C:5.5752, R:0.0100, T:0.5810(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5885 (C:5.5697, R:0.0100, T:0.5875(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5812 (C:5.6164, R:0.0100, T:0.5802(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5874 (C:5.5776, R:0.0099, T:0.5864(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 49 TRAINING SUMMARY:
  Total Loss: 0.5888
  Contrastive: 5.5931
  Reconstruction: 0.0100
  Topological: 0.5878 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.6933
  Contrastive: 4.3358
  Reconstruction: 0.0099
  Topological: 5.6923 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 49/300 COMPLETE (44.6s)
Train Loss: 0.5888 (C:5.5931, R:0.0100, T:0.5878)
Val Loss:   5.6933 (C:4.3358, R:0.0099, T:5.6923)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 50 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5752 (C:5.5861, R:0.0100, T:0.5742(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5865 (C:5.6015, R:0.0100, T:0.5855(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5822 (C:5.5554, R:0.0100, T:0.5812(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6129 (C:5.5750, R:0.0099, T:0.6119(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5826 (C:5.5959, R:0.0100, T:0.5816(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6055 (C:5.6065, R:0.0100, T:0.6045(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5753 (C:5.5932, R:0.0099, T:0.5743(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5998 (C:5.5720, R:0.0100, T:0.5988(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6070 (C:5.5747, R:0.0100, T:0.6060(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5933 (C:5.5837, R:0.0100, T:0.5923(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6064 (C:5.5626, R:0.0100, T:0.6054(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5696 (C:5.5628, R:0.0100, T:0.5686(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6002 (C:5.6062, R:0.0100, T:0.5992(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5955 (C:5.6060, R:0.0099, T:0.5945(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5748 (C:5.6141, R:0.0100, T:0.5738(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6059 (C:5.5737, R:0.0100, T:0.6049(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5670 (C:5.6457, R:0.0099, T:0.5660(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5821 (C:5.5822, R:0.0100, T:0.5811(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5826 (C:5.5497, R:0.0100, T:0.5816(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5982 (C:5.6249, R:0.0100, T:0.5972(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5777 (C:5.5618, R:0.0100, T:0.5767(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5966 (C:5.5705, R:0.0099, T:0.5956(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5857

ğŸ“Š EPOCH 50 TRAINING SUMMARY:
  Total Loss: 0.5867
  Contrastive: 5.5924
  Reconstruction: 0.0100
  Topological: 0.5857 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.5631
  Contrastive: 4.3614
  Reconstruction: 0.0099
  Topological: 5.5621 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 50/300 COMPLETE (45.4s)
Train Loss: 0.5867 (C:5.5924, R:0.0100, T:0.5857)
Val Loss:   5.5631 (C:4.3614, R:0.0099, T:5.5621)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 51 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5852 (C:5.6056, R:0.0100, T:0.5842(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5909 (C:5.5822, R:0.0099, T:0.5899(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5858 (C:5.6322, R:0.0100, T:0.5848(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5853 (C:5.5779, R:0.0099, T:0.5843(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5551 (C:5.5442, R:0.0099, T:0.5541(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6040 (C:5.6114, R:0.0099, T:0.6030(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6035 (C:5.6325, R:0.0100, T:0.6025(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5932 (C:5.5601, R:0.0099, T:0.5923(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6073 (C:5.6139, R:0.0099, T:0.6063(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5428 (C:5.5938, R:0.0099, T:0.5418(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5756 (C:5.5962, R:0.0099, T:0.5746(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6354 (C:5.5601, R:0.0099, T:0.6345(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5811 (C:5.5799, R:0.0100, T:0.5801(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5902 (C:5.5872, R:0.0100, T:0.5892(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5917 (C:5.6031, R:0.0100, T:0.5907(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5934 (C:5.5754, R:0.0100, T:0.5924(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5949 (C:5.6336, R:0.0100, T:0.5939(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5675 (C:5.5759, R:0.0099, T:0.5666(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6109 (C:5.5700, R:0.0100, T:0.6099(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5986 (C:5.5596, R:0.0099, T:0.5976(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5493 (C:5.5499, R:0.0099, T:0.5483(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6054 (C:5.5931, R:0.0100, T:0.6044(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5854

ğŸ“Š EPOCH 51 TRAINING SUMMARY:
  Total Loss: 0.5864
  Contrastive: 5.5924
  Reconstruction: 0.0100
  Topological: 0.5854 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.6853
  Contrastive: 4.3365
  Reconstruction: 0.0099
  Topological: 5.6843 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 51/300 COMPLETE (43.9s)
Train Loss: 0.5864 (C:5.5924, R:0.0100, T:0.5854)
Val Loss:   5.6853 (C:4.3365, R:0.0099, T:5.6843)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 52 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5785 (C:5.5658, R:0.0099, T:0.5775(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5809 (C:5.6297, R:0.0100, T:0.5799(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5587 (C:5.5937, R:0.0100, T:0.5577(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5686 (C:5.5978, R:0.0099, T:0.5676(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5878 (C:5.5643, R:0.0100, T:0.5868(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5967 (C:5.6227, R:0.0100, T:0.5957(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5829 (C:5.5812, R:0.0099, T:0.5819(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6196 (C:5.5882, R:0.0100, T:0.6186(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5939 (C:5.5981, R:0.0100, T:0.5929(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6199 (C:5.6089, R:0.0100, T:0.6189(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5735 (C:5.6070, R:0.0100, T:0.5725(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5827 (C:5.5943, R:0.0099, T:0.5818(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6030 (C:5.6380, R:0.0100, T:0.6020(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5842 (C:5.6078, R:0.0100, T:0.5832(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5725 (C:5.6155, R:0.0099, T:0.5715(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5674 (C:5.5660, R:0.0100, T:0.5664(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5788 (C:5.5490, R:0.0100, T:0.5778(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5870 (C:5.6618, R:0.0099, T:0.5861(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5739 (C:5.5699, R:0.0100, T:0.5729(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6084 (C:5.6044, R:0.0099, T:0.6074(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6022 (C:5.6188, R:0.0100, T:0.6012(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6124 (C:5.5959, R:0.0100, T:0.6114(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 52 TRAINING SUMMARY:
  Total Loss: 0.5866
  Contrastive: 5.5921
  Reconstruction: 0.0100
  Topological: 0.5856 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.6395
  Contrastive: 4.3482
  Reconstruction: 0.0099
  Topological: 5.6385 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 52/300 COMPLETE (43.9s)
Train Loss: 0.5866 (C:5.5921, R:0.0100, T:0.5856)
Val Loss:   5.6395 (C:4.3482, R:0.0099, T:5.6385)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 53 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5815 (C:5.5976, R:0.0100, T:0.5805(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5972 (C:5.5833, R:0.0099, T:0.5962(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5776 (C:5.5798, R:0.0100, T:0.5766(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5636 (C:5.5815, R:0.0100, T:0.5626(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5583 (C:5.6509, R:0.0100, T:0.5573(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5792 (C:5.5608, R:0.0099, T:0.5782(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5787 (C:5.6183, R:0.0099, T:0.5777(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5689 (C:5.6045, R:0.0100, T:0.5679(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5946 (C:5.6047, R:0.0100, T:0.5936(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5822 (C:5.5820, R:0.0100, T:0.5812(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5845 (C:5.5862, R:0.0099, T:0.5835(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5597 (C:5.5934, R:0.0100, T:0.5587(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5758 (C:5.5304, R:0.0100, T:0.5748(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5706 (C:5.5953, R:0.0100, T:0.5696(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6030 (C:5.6044, R:0.0099, T:0.6020(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6336 (C:5.6059, R:0.0100, T:0.6326(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6233 (C:5.5942, R:0.0100, T:0.6223(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6001 (C:5.5647, R:0.0099, T:0.5991(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6257 (C:5.6241, R:0.0100, T:0.6247(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5842 (C:5.5865, R:0.0099, T:0.5832(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5265 (C:5.5985, R:0.0100, T:0.5255(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5918 (C:5.5896, R:0.0100, T:0.5908(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5843

ğŸ“Š EPOCH 53 TRAINING SUMMARY:
  Total Loss: 0.5853
  Contrastive: 5.5927
  Reconstruction: 0.0100
  Topological: 0.5843 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.5105
  Contrastive: 4.3736
  Reconstruction: 0.0099
  Topological: 5.5095 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 53/300 COMPLETE (43.6s)
Train Loss: 0.5853 (C:5.5927, R:0.0100, T:0.5843)
Val Loss:   5.5105 (C:4.3736, R:0.0099, T:5.5095)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 54 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5793 (C:5.6133, R:0.0100, T:0.5783(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5703 (C:5.6037, R:0.0099, T:0.5694(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5834 (C:5.6204, R:0.0100, T:0.5824(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5825 (C:5.5979, R:0.0100, T:0.5815(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5550 (C:5.5835, R:0.0100, T:0.5540(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5872 (C:5.6163, R:0.0100, T:0.5862(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5920 (C:5.5480, R:0.0100, T:0.5910(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5551 (C:5.5769, R:0.0099, T:0.5541(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5787 (C:5.5924, R:0.0099, T:0.5777(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5750 (C:5.5913, R:0.0099, T:0.5740(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5627 (C:5.6135, R:0.0100, T:0.5617(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6016 (C:5.6341, R:0.0099, T:0.6006(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6086 (C:5.6184, R:0.0100, T:0.6076(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5819 (C:5.5690, R:0.0099, T:0.5810(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5612 (C:5.6245, R:0.0099, T:0.5603(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5812 (C:5.6008, R:0.0099, T:0.5802(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5647 (C:5.6137, R:0.0100, T:0.5637(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6097 (C:5.6067, R:0.0100, T:0.6087(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5863 (C:5.5722, R:0.0099, T:0.5853(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6012 (C:5.6092, R:0.0100, T:0.6002(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5979 (C:5.6255, R:0.0100, T:0.5969(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5652 (C:5.6236, R:0.0099, T:0.5642(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5840

ğŸ“Š EPOCH 54 TRAINING SUMMARY:
  Total Loss: 0.5850
  Contrastive: 5.5917
  Reconstruction: 0.0100
  Topological: 0.5840 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.5861
  Contrastive: 4.3521
  Reconstruction: 0.0099
  Topological: 5.5851 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 54/300 COMPLETE (44.2s)
Train Loss: 0.5850 (C:5.5917, R:0.0100, T:0.5840)
Val Loss:   5.5861 (C:4.3521, R:0.0099, T:5.5851)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 55 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5770 (C:5.5978, R:0.0100, T:0.5760(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5416 (C:5.6119, R:0.0099, T:0.5406(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5567 (C:5.5957, R:0.0099, T:0.5557(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5754 (C:5.5828, R:0.0099, T:0.5745(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5852 (C:5.5817, R:0.0099, T:0.5842(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5925 (C:5.6119, R:0.0099, T:0.5915(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5952 (C:5.6211, R:0.0100, T:0.5942(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5802 (C:5.6524, R:0.0099, T:0.5793(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5633 (C:5.5528, R:0.0099, T:0.5623(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5861 (C:5.6247, R:0.0099, T:0.5851(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5863 (C:5.5816, R:0.0099, T:0.5853(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5800 (C:5.6459, R:0.0100, T:0.5790(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6000 (C:5.5927, R:0.0100, T:0.5990(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5910 (C:5.5551, R:0.0099, T:0.5900(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6004 (C:5.5861, R:0.0099, T:0.5994(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5916 (C:5.5592, R:0.0099, T:0.5906(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5756 (C:5.6010, R:0.0099, T:0.5746(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6037 (C:5.6176, R:0.0100, T:0.6027(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6018 (C:5.5896, R:0.0100, T:0.6008(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5633 (C:5.5807, R:0.0099, T:0.5623(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5782 (C:5.6333, R:0.0099, T:0.5772(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5345 (C:5.5848, R:0.0099, T:0.5335(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5835

ğŸ“Š EPOCH 55 TRAINING SUMMARY:
  Total Loss: 0.5845
  Contrastive: 5.5902
  Reconstruction: 0.0100
  Topological: 0.5835 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.4959
  Contrastive: 4.3566
  Reconstruction: 0.0099
  Topological: 5.4949 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 55/300 COMPLETE (44.4s)
Train Loss: 0.5845 (C:5.5902, R:0.0100, T:0.5835)
Val Loss:   5.4959 (C:4.3566, R:0.0099, T:5.4949)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 56 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5625 (C:5.5983, R:0.0100, T:0.5615(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6089 (C:5.6084, R:0.0100, T:0.6079(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5809 (C:5.6108, R:0.0099, T:0.5799(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5880 (C:5.5741, R:0.0099, T:0.5870(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6064 (C:5.5621, R:0.0099, T:0.6054(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6313 (C:5.5842, R:0.0099, T:0.6303(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5733 (C:5.6092, R:0.0100, T:0.5723(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5955 (C:5.5461, R:0.0099, T:0.5945(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5639 (C:5.5846, R:0.0100, T:0.5629(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5878 (C:5.5767, R:0.0099, T:0.5868(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5725 (C:5.5887, R:0.0100, T:0.5715(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5796 (C:5.5925, R:0.0099, T:0.5786(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5804 (C:5.6101, R:0.0100, T:0.5794(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5749 (C:5.6004, R:0.0100, T:0.5739(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5764 (C:5.5646, R:0.0099, T:0.5754(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5965 (C:5.6084, R:0.0100, T:0.5955(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5627 (C:5.6144, R:0.0099, T:0.5617(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6025 (C:5.5716, R:0.0099, T:0.6015(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5791 (C:5.5785, R:0.0099, T:0.5781(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5682 (C:5.5910, R:0.0099, T:0.5672(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5866 (C:5.5769, R:0.0100, T:0.5856(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6030 (C:5.6286, R:0.0100, T:0.6020(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5824

ğŸ“Š EPOCH 56 TRAINING SUMMARY:
  Total Loss: 0.5834
  Contrastive: 5.5894
  Reconstruction: 0.0100
  Topological: 0.5824 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.5157
  Contrastive: 4.3476
  Reconstruction: 0.0099
  Topological: 5.5148 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 56/300 COMPLETE (43.4s)
Train Loss: 0.5834 (C:5.5894, R:0.0100, T:0.5824)
Val Loss:   5.5157 (C:4.3476, R:0.0099, T:5.5148)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 57 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5820 (C:5.5785, R:0.0100, T:0.5810(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5789 (C:5.5938, R:0.0100, T:0.5779(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5753 (C:5.5896, R:0.0100, T:0.5743(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5658 (C:5.6195, R:0.0100, T:0.5648(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5598 (C:5.5738, R:0.0100, T:0.5588(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5672 (C:5.5483, R:0.0100, T:0.5662(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5956 (C:5.5906, R:0.0099, T:0.5946(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5635 (C:5.5743, R:0.0099, T:0.5625(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5680 (C:5.6186, R:0.0099, T:0.5670(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6022 (C:5.5683, R:0.0099, T:0.6013(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5881 (C:5.5841, R:0.0099, T:0.5871(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5828 (C:5.5896, R:0.0100, T:0.5818(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5753 (C:5.5961, R:0.0099, T:0.5743(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5982 (C:5.5829, R:0.0100, T:0.5972(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5823 (C:5.5732, R:0.0099, T:0.5813(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5737 (C:5.6034, R:0.0099, T:0.5727(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5936 (C:5.5654, R:0.0099, T:0.5926(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5837 (C:5.5926, R:0.0100, T:0.5828(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5625 (C:5.5480, R:0.0099, T:0.5615(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6099 (C:5.6343, R:0.0100, T:0.6089(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5959 (C:5.5964, R:0.0100, T:0.5949(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5659 (C:5.5653, R:0.0099, T:0.5649(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 57 TRAINING SUMMARY:
  Total Loss: 0.5843
  Contrastive: 5.5888
  Reconstruction: 0.0100
  Topological: 0.5833 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.4217
  Contrastive: 4.3944
  Reconstruction: 0.0099
  Topological: 5.4207 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 57/300 COMPLETE (43.6s)
Train Loss: 0.5843 (C:5.5888, R:0.0100, T:0.5833)
Val Loss:   5.4217 (C:4.3944, R:0.0099, T:5.4207)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 58 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5706 (C:5.6273, R:0.0100, T:0.5696(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5997 (C:5.5830, R:0.0100, T:0.5987(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5612 (C:5.5780, R:0.0100, T:0.5602(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5539 (C:5.6193, R:0.0099, T:0.5529(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5886 (C:5.5965, R:0.0100, T:0.5876(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5814 (C:5.5688, R:0.0100, T:0.5804(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5675 (C:5.5968, R:0.0100, T:0.5665(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5801 (C:5.6009, R:0.0099, T:0.5791(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5889 (C:5.6039, R:0.0099, T:0.5879(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5860 (C:5.5508, R:0.0100, T:0.5850(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5876 (C:5.5953, R:0.0100, T:0.5866(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5589 (C:5.6066, R:0.0100, T:0.5579(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5754 (C:5.6010, R:0.0100, T:0.5744(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5801 (C:5.5900, R:0.0099, T:0.5792(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5684 (C:5.6064, R:0.0099, T:0.5674(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5751 (C:5.5523, R:0.0100, T:0.5741(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5636 (C:5.6406, R:0.0099, T:0.5626(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5869 (C:5.6336, R:0.0100, T:0.5859(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5835 (C:5.6210, R:0.0100, T:0.5825(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5828 (C:5.6091, R:0.0099, T:0.5818(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6080 (C:5.5718, R:0.0099, T:0.6070(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6109 (C:5.6723, R:0.0100, T:0.6099(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 58 TRAINING SUMMARY:
  Total Loss: 0.5837
  Contrastive: 5.5912
  Reconstruction: 0.0100
  Topological: 0.5827 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.4185
  Contrastive: 4.3739
  Reconstruction: 0.0099
  Topological: 5.4175 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 58/300 COMPLETE (43.7s)
Train Loss: 0.5837 (C:5.5912, R:0.0100, T:0.5827)
Val Loss:   5.4185 (C:4.3739, R:0.0099, T:5.4175)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 59 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5973 (C:5.5837, R:0.0099, T:0.5963(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6057 (C:5.5918, R:0.0099, T:0.6047(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5771 (C:5.5998, R:0.0100, T:0.5761(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5743 (C:5.5793, R:0.0100, T:0.5733(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5612 (C:5.6067, R:0.0100, T:0.5602(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5923 (C:5.6042, R:0.0100, T:0.5913(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5954 (C:5.5489, R:0.0100, T:0.5944(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5909 (C:5.6261, R:0.0099, T:0.5899(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6044 (C:5.6195, R:0.0100, T:0.6034(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5786 (C:5.6170, R:0.0099, T:0.5776(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6073 (C:5.5575, R:0.0100, T:0.6063(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5559 (C:5.5581, R:0.0100, T:0.5549(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5969 (C:5.6102, R:0.0099, T:0.5959(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5895 (C:5.6555, R:0.0100, T:0.5885(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6011 (C:5.6096, R:0.0100, T:0.6001(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5970 (C:5.5479, R:0.0099, T:0.5960(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5934 (C:5.6070, R:0.0100, T:0.5924(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6100 (C:5.6184, R:0.0100, T:0.6090(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5930 (C:5.5902, R:0.0099, T:0.5920(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5957 (C:5.5708, R:0.0099, T:0.5947(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5941 (C:5.5622, R:0.0100, T:0.5931(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6102 (C:5.5846, R:0.0099, T:0.6092(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5810

ğŸ“Š EPOCH 59 TRAINING SUMMARY:
  Total Loss: 0.5820
  Contrastive: 5.5898
  Reconstruction: 0.0100
  Topological: 0.5810 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.6189
  Contrastive: 4.3377
  Reconstruction: 0.0099
  Topological: 5.6179 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 59/300 COMPLETE (43.5s)
Train Loss: 0.5820 (C:5.5898, R:0.0100, T:0.5810)
Val Loss:   5.6189 (C:4.3377, R:0.0099, T:5.6179)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 60 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5675 (C:5.5481, R:0.0099, T:0.5665(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5985 (C:5.5692, R:0.0100, T:0.5975(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5768 (C:5.6098, R:0.0100, T:0.5758(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5739 (C:5.5710, R:0.0099, T:0.5729(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6014 (C:5.5493, R:0.0099, T:0.6004(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5950 (C:5.5834, R:0.0100, T:0.5940(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5812 (C:5.6386, R:0.0100, T:0.5802(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5587 (C:5.6017, R:0.0100, T:0.5577(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6065 (C:5.5417, R:0.0100, T:0.6055(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5792 (C:5.6111, R:0.0099, T:0.5782(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5968 (C:5.5692, R:0.0100, T:0.5958(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5917 (C:5.5978, R:0.0100, T:0.5907(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5856 (C:5.5710, R:0.0099, T:0.5846(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6036 (C:5.5977, R:0.0100, T:0.6026(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5892 (C:5.5407, R:0.0099, T:0.5882(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6009 (C:5.6039, R:0.0100, T:0.5999(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5994 (C:5.5862, R:0.0099, T:0.5984(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5691 (C:5.5835, R:0.0100, T:0.5681(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5736 (C:5.5663, R:0.0099, T:0.5726(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5696 (C:5.6074, R:0.0100, T:0.5686(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5757 (C:5.5945, R:0.0100, T:0.5747(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5962 (C:5.5879, R:0.0100, T:0.5952(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 60 TRAINING SUMMARY:
  Total Loss: 0.5851
  Contrastive: 5.5892
  Reconstruction: 0.0100
  Topological: 0.5841 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.3127
  Contrastive: 4.3794
  Reconstruction: 0.0099
  Topological: 5.3117 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 60/300 COMPLETE (44.0s)
Train Loss: 0.5851 (C:5.5892, R:0.0100, T:0.5841)
Val Loss:   5.3127 (C:4.3794, R:0.0099, T:5.3117)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 61 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6037 (C:5.5959, R:0.0100, T:0.6027(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5747 (C:5.5389, R:0.0100, T:0.5737(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5856 (C:5.6065, R:0.0099, T:0.5846(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5813 (C:5.6021, R:0.0100, T:0.5803(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6198 (C:5.5798, R:0.0099, T:0.6188(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5800 (C:5.5655, R:0.0099, T:0.5790(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5762 (C:5.5642, R:0.0100, T:0.5752(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5629 (C:5.5990, R:0.0100, T:0.5619(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5601 (C:5.6104, R:0.0100, T:0.5591(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6052 (C:5.5806, R:0.0100, T:0.6042(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6320 (C:5.6025, R:0.0099, T:0.6310(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5688 (C:5.5990, R:0.0100, T:0.5678(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5688 (C:5.6160, R:0.0100, T:0.5678(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5666 (C:5.5911, R:0.0100, T:0.5656(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5679 (C:5.5731, R:0.0099, T:0.5669(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6024 (C:5.6168, R:0.0100, T:0.6014(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6003 (C:5.5740, R:0.0100, T:0.5993(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5495 (C:5.5805, R:0.0100, T:0.5485(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5721 (C:5.6161, R:0.0100, T:0.5711(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5593 (C:5.5722, R:0.0099, T:0.5583(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5958 (C:5.5698, R:0.0099, T:0.5948(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5959 (C:5.5732, R:0.0099, T:0.5949(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5801

ğŸ“Š EPOCH 61 TRAINING SUMMARY:
  Total Loss: 0.5811
  Contrastive: 5.5895
  Reconstruction: 0.0100
  Topological: 0.5801 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.2906
  Contrastive: 4.4034
  Reconstruction: 0.0099
  Topological: 5.2897 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 61/300 COMPLETE (43.7s)
Train Loss: 0.5811 (C:5.5895, R:0.0100, T:0.5801)
Val Loss:   5.2906 (C:4.4034, R:0.0099, T:5.2897)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 62 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5864 (C:5.6376, R:0.0100, T:0.5854(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6134 (C:5.6078, R:0.0100, T:0.6124(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5896 (C:5.5653, R:0.0099, T:0.5886(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5821 (C:5.6213, R:0.0100, T:0.5811(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5697 (C:5.5863, R:0.0100, T:0.5687(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5825 (C:5.5474, R:0.0099, T:0.5815(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5899 (C:5.6073, R:0.0100, T:0.5889(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5701 (C:5.5803, R:0.0100, T:0.5691(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5835 (C:5.6538, R:0.0099, T:0.5825(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5814 (C:5.5698, R:0.0099, T:0.5804(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5801 (C:5.6337, R:0.0099, T:0.5791(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6005 (C:5.5266, R:0.0100, T:0.5995(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5951 (C:5.6633, R:0.0100, T:0.5941(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5630 (C:5.5565, R:0.0099, T:0.5620(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5687 (C:5.6252, R:0.0099, T:0.5677(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5888 (C:5.6010, R:0.0100, T:0.5878(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5627 (C:5.6186, R:0.0099, T:0.5617(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6093 (C:5.5999, R:0.0099, T:0.6083(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5850 (C:5.5277, R:0.0099, T:0.5840(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6120 (C:5.6196, R:0.0099, T:0.6110(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5967 (C:5.5749, R:0.0100, T:0.5957(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5894 (C:5.6474, R:0.0100, T:0.5884(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 62 TRAINING SUMMARY:
  Total Loss: 0.5823
  Contrastive: 5.5906
  Reconstruction: 0.0100
  Topological: 0.5813 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.5013
  Contrastive: 4.3405
  Reconstruction: 0.0099
  Topological: 5.5004 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 62/300 COMPLETE (43.3s)
Train Loss: 0.5823 (C:5.5906, R:0.0100, T:0.5813)
Val Loss:   5.5013 (C:4.3405, R:0.0099, T:5.5004)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 63 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5550 (C:5.5529, R:0.0099, T:0.5540(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5705 (C:5.6541, R:0.0100, T:0.5695(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5755 (C:5.5684, R:0.0100, T:0.5745(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5615 (C:5.5738, R:0.0099, T:0.5606(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5814 (C:5.5769, R:0.0100, T:0.5804(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5572 (C:5.5859, R:0.0099, T:0.5562(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5973 (C:5.6224, R:0.0100, T:0.5963(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5644 (C:5.5947, R:0.0100, T:0.5635(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6109 (C:5.6089, R:0.0100, T:0.6100(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5962 (C:5.5871, R:0.0100, T:0.5952(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5694 (C:5.5845, R:0.0099, T:0.5685(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5769 (C:5.6330, R:0.0099, T:0.5759(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6046 (C:5.5767, R:0.0100, T:0.6036(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5836 (C:5.5561, R:0.0099, T:0.5826(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5774 (C:5.5784, R:0.0099, T:0.5764(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6101 (C:5.5507, R:0.0100, T:0.6091(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5888 (C:5.6789, R:0.0100, T:0.5878(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5836 (C:5.5658, R:0.0099, T:0.5826(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5961 (C:5.6375, R:0.0100, T:0.5951(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5775 (C:5.6108, R:0.0100, T:0.5765(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5616 (C:5.6321, R:0.0099, T:0.5606(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5682 (C:5.5997, R:0.0099, T:0.5672(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 63 TRAINING SUMMARY:
  Total Loss: 0.5835
  Contrastive: 5.5885
  Reconstruction: 0.0100
  Topological: 0.5825 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.2478
  Contrastive: 4.4070
  Reconstruction: 0.0099
  Topological: 5.2468 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 63/300 COMPLETE (45.2s)
Train Loss: 0.5835 (C:5.5885, R:0.0100, T:0.5825)
Val Loss:   5.2478 (C:4.4070, R:0.0099, T:5.2468)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 64 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6164 (C:5.6029, R:0.0100, T:0.6154(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5872 (C:5.5793, R:0.0100, T:0.5862(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5957 (C:5.5893, R:0.0100, T:0.5947(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5903 (C:5.6055, R:0.0099, T:0.5893(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5538 (C:5.6013, R:0.0100, T:0.5528(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5537 (C:5.5713, R:0.0100, T:0.5527(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5630 (C:5.5439, R:0.0099, T:0.5621(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5895 (C:5.6174, R:0.0099, T:0.5885(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5850 (C:5.5655, R:0.0099, T:0.5840(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5851 (C:5.5590, R:0.0099, T:0.5841(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6012 (C:5.5870, R:0.0100, T:0.6002(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5942 (C:5.5907, R:0.0100, T:0.5932(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5890 (C:5.5981, R:0.0099, T:0.5880(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6325 (C:5.5920, R:0.0100, T:0.6315(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6125 (C:5.5894, R:0.0100, T:0.6115(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5589 (C:5.5439, R:0.0099, T:0.5579(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6026 (C:5.5995, R:0.0100, T:0.6016(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5547 (C:5.6116, R:0.0100, T:0.5537(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5676 (C:5.6089, R:0.0099, T:0.5666(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6060 (C:5.5625, R:0.0099, T:0.6050(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6120 (C:5.6134, R:0.0100, T:0.6110(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6010 (C:5.6028, R:0.0099, T:0.6000(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 64 TRAINING SUMMARY:
  Total Loss: 0.5820
  Contrastive: 5.5894
  Reconstruction: 0.0100
  Topological: 0.5810 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.4358
  Contrastive: 4.3475
  Reconstruction: 0.0099
  Topological: 5.4348 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 64/300 COMPLETE (44.9s)
Train Loss: 0.5820 (C:5.5894, R:0.0100, T:0.5810)
Val Loss:   5.4358 (C:4.3475, R:0.0099, T:5.4348)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 65 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6050 (C:5.5553, R:0.0099, T:0.6040(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5734 (C:5.6159, R:0.0100, T:0.5724(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6002 (C:5.5377, R:0.0100, T:0.5992(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5579 (C:5.5927, R:0.0100, T:0.5569(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6117 (C:5.5606, R:0.0099, T:0.6107(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5737 (C:5.6172, R:0.0100, T:0.5727(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5850 (C:5.5487, R:0.0099, T:0.5841(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5875 (C:5.5793, R:0.0100, T:0.5866(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5939 (C:5.6004, R:0.0099, T:0.5929(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5766 (C:5.6010, R:0.0100, T:0.5757(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5708 (C:5.6090, R:0.0100, T:0.5698(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5989 (C:5.5780, R:0.0099, T:0.5980(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5770 (C:5.5567, R:0.0100, T:0.5760(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5616 (C:5.6066, R:0.0099, T:0.5606(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5783 (C:5.5475, R:0.0099, T:0.5773(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5718 (C:5.6106, R:0.0100, T:0.5708(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5438 (C:5.5907, R:0.0099, T:0.5429(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5706 (C:5.5795, R:0.0100, T:0.5696(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5800 (C:5.5784, R:0.0100, T:0.5790(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5763 (C:5.6868, R:0.0100, T:0.5753(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5955 (C:5.5775, R:0.0100, T:0.5945(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5719 (C:5.5697, R:0.0099, T:0.5709(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5795

ğŸ“Š EPOCH 65 TRAINING SUMMARY:
  Total Loss: 0.5805
  Contrastive: 5.5877
  Reconstruction: 0.0100
  Topological: 0.5795 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.1663
  Contrastive: 4.3937
  Reconstruction: 0.0099
  Topological: 5.1654 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 65/300 COMPLETE (45.6s)
Train Loss: 0.5805 (C:5.5877, R:0.0100, T:0.5795)
Val Loss:   5.1663 (C:4.3937, R:0.0099, T:5.1654)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 66 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6005 (C:5.5977, R:0.0099, T:0.5995(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5704 (C:5.5723, R:0.0100, T:0.5694(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5798 (C:5.5615, R:0.0100, T:0.5788(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5647 (C:5.5932, R:0.0099, T:0.5637(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6052 (C:5.5967, R:0.0100, T:0.6042(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5684 (C:5.5860, R:0.0100, T:0.5674(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5617 (C:5.6023, R:0.0100, T:0.5607(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5976 (C:5.5436, R:0.0099, T:0.5966(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5894 (C:5.6078, R:0.0099, T:0.5884(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5557 (C:5.6339, R:0.0100, T:0.5547(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5683 (C:5.5482, R:0.0100, T:0.5673(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5826 (C:5.5539, R:0.0099, T:0.5816(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5487 (C:5.6123, R:0.0100, T:0.5477(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5654 (C:5.5853, R:0.0100, T:0.5644(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5780 (C:5.6009, R:0.0099, T:0.5770(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5934 (C:5.5650, R:0.0100, T:0.5924(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6023 (C:5.5985, R:0.0099, T:0.6013(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5575 (C:5.5580, R:0.0100, T:0.5565(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5721 (C:5.5829, R:0.0099, T:0.5711(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6154 (C:5.5542, R:0.0099, T:0.6144(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5684 (C:5.5797, R:0.0099, T:0.5674(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5464 (C:5.5959, R:0.0100, T:0.5454(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5787

ğŸ“Š EPOCH 66 TRAINING SUMMARY:
  Total Loss: 0.5797
  Contrastive: 5.5874
  Reconstruction: 0.0100
  Topological: 0.5787 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.2626
  Contrastive: 4.3917
  Reconstruction: 0.0099
  Topological: 5.2616 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 66/300 COMPLETE (43.7s)
Train Loss: 0.5797 (C:5.5874, R:0.0100, T:0.5787)
Val Loss:   5.2626 (C:4.3917, R:0.0099, T:5.2616)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 67 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5816 (C:5.5719, R:0.0099, T:0.5806(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5231 (C:5.6200, R:0.0100, T:0.5221(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5984 (C:5.5775, R:0.0100, T:0.5974(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5376 (C:5.5367, R:0.0099, T:0.5366(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5749 (C:5.5758, R:0.0099, T:0.5739(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5671 (C:5.6188, R:0.0100, T:0.5661(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5907 (C:5.5872, R:0.0100, T:0.5897(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6229 (C:5.6099, R:0.0099, T:0.6219(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5771 (C:5.6010, R:0.0100, T:0.5761(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5552 (C:5.6120, R:0.0099, T:0.5542(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5766 (C:5.6034, R:0.0100, T:0.5756(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5902 (C:5.5792, R:0.0099, T:0.5892(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6083 (C:5.6007, R:0.0099, T:0.6073(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5782 (C:5.5257, R:0.0099, T:0.5773(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5999 (C:5.6287, R:0.0099, T:0.5989(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6010 (C:5.5617, R:0.0099, T:0.6000(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5757 (C:5.6359, R:0.0100, T:0.5747(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5816 (C:5.5671, R:0.0099, T:0.5807(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5899 (C:5.5369, R:0.0100, T:0.5889(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5951 (C:5.5981, R:0.0099, T:0.5941(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5712 (C:5.6332, R:0.0099, T:0.5702(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5609 (C:5.5590, R:0.0099, T:0.5599(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 67 TRAINING SUMMARY:
  Total Loss: 0.5799
  Contrastive: 5.5885
  Reconstruction: 0.0100
  Topological: 0.5789 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0547
  Contrastive: 4.4442
  Reconstruction: 0.0099
  Topological: 5.0538 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 67/300 COMPLETE (46.3s)
Train Loss: 0.5799 (C:5.5885, R:0.0100, T:0.5789)
Val Loss:   5.0547 (C:4.4442, R:0.0099, T:5.0538)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 68 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5849 (C:5.6686, R:0.0099, T:0.5839(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5849 (C:5.5991, R:0.0100, T:0.5839(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6311 (C:5.5986, R:0.0100, T:0.6301(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5517 (C:5.6452, R:0.0100, T:0.5507(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5954 (C:5.5120, R:0.0100, T:0.5944(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5763 (C:5.5519, R:0.0100, T:0.5753(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5674 (C:5.5245, R:0.0100, T:0.5664(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5716 (C:5.5986, R:0.0099, T:0.5706(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6043 (C:5.6259, R:0.0100, T:0.6033(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5885 (C:5.5801, R:0.0100, T:0.5875(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5955 (C:5.5699, R:0.0099, T:0.5945(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5694 (C:5.5974, R:0.0100, T:0.5684(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5468 (C:5.5764, R:0.0100, T:0.5458(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5748 (C:5.5962, R:0.0100, T:0.5738(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5724 (C:5.5897, R:0.0100, T:0.5714(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5883 (C:5.6013, R:0.0100, T:0.5873(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5891 (C:5.5702, R:0.0099, T:0.5881(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5863 (C:5.5992, R:0.0100, T:0.5853(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5794 (C:5.5433, R:0.0099, T:0.5784(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5758 (C:5.5849, R:0.0100, T:0.5748(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5751 (C:5.6001, R:0.0100, T:0.5741(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5443 (C:5.5549, R:0.0099, T:0.5433(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5786

ğŸ“Š EPOCH 68 TRAINING SUMMARY:
  Total Loss: 0.5796
  Contrastive: 5.5867
  Reconstruction: 0.0100
  Topological: 0.5786 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.3020
  Contrastive: 4.3753
  Reconstruction: 0.0099
  Topological: 5.3010 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 68/300 COMPLETE (46.0s)
Train Loss: 0.5796 (C:5.5867, R:0.0100, T:0.5786)
Val Loss:   5.3020 (C:4.3753, R:0.0099, T:5.3010)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 69 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5587 (C:5.5667, R:0.0100, T:0.5577(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5710 (C:5.6063, R:0.0099, T:0.5700(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5633 (C:5.5757, R:0.0100, T:0.5623(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5938 (C:5.5865, R:0.0100, T:0.5928(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5717 (C:5.5621, R:0.0099, T:0.5707(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5812 (C:5.5826, R:0.0100, T:0.5802(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5824 (C:5.5757, R:0.0099, T:0.5814(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5739 (C:5.5914, R:0.0099, T:0.5729(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5616 (C:5.6380, R:0.0100, T:0.5606(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5710 (C:5.5638, R:0.0100, T:0.5700(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5525 (C:5.6016, R:0.0099, T:0.5515(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5629 (C:5.5511, R:0.0099, T:0.5619(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5527 (C:5.6206, R:0.0099, T:0.5517(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5743 (C:5.5843, R:0.0099, T:0.5733(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5507 (C:5.5874, R:0.0099, T:0.5497(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6015 (C:5.5474, R:0.0100, T:0.6005(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5348 (C:5.6378, R:0.0100, T:0.5338(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5912 (C:5.6378, R:0.0100, T:0.5902(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5645 (C:5.5700, R:0.0099, T:0.5636(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6197 (C:5.5563, R:0.0100, T:0.6187(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5809 (C:5.6096, R:0.0099, T:0.5799(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5700 (C:5.6230, R:0.0100, T:0.5690(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5786

ğŸ“Š EPOCH 69 TRAINING SUMMARY:
  Total Loss: 0.5796
  Contrastive: 5.5883
  Reconstruction: 0.0100
  Topological: 0.5786 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.2335
  Contrastive: 4.3872
  Reconstruction: 0.0099
  Topological: 5.2325 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 69/300 COMPLETE (44.7s)
Train Loss: 0.5796 (C:5.5883, R:0.0100, T:0.5786)
Val Loss:   5.2335 (C:4.3872, R:0.0099, T:5.2325)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 70 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6151 (C:5.5925, R:0.0099, T:0.6141(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5669 (C:5.5738, R:0.0100, T:0.5660(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5819 (C:5.5606, R:0.0099, T:0.5809(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5585 (C:5.6014, R:0.0099, T:0.5575(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5608 (C:5.5949, R:0.0100, T:0.5599(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6004 (C:5.6197, R:0.0100, T:0.5994(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5628 (C:5.6089, R:0.0099, T:0.5618(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5680 (C:5.5569, R:0.0099, T:0.5670(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5983 (C:5.6708, R:0.0100, T:0.5973(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5801 (C:5.5590, R:0.0099, T:0.5791(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5910 (C:5.5696, R:0.0099, T:0.5900(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6009 (C:5.5719, R:0.0100, T:0.5999(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5842 (C:5.6168, R:0.0099, T:0.5832(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5651 (C:5.6312, R:0.0100, T:0.5641(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5576 (C:5.5894, R:0.0099, T:0.5566(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6112 (C:5.5646, R:0.0099, T:0.6103(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5972 (C:5.6150, R:0.0100, T:0.5962(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6037 (C:5.6019, R:0.0100, T:0.6027(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5974 (C:5.5570, R:0.0100, T:0.5964(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5811 (C:5.6263, R:0.0099, T:0.5801(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6126 (C:5.5698, R:0.0099, T:0.6116(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5732 (C:5.6102, R:0.0099, T:0.5722(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 70 TRAINING SUMMARY:
  Total Loss: 0.5806
  Contrastive: 5.5880
  Reconstruction: 0.0100
  Topological: 0.5796 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.1878
  Contrastive: 4.3991
  Reconstruction: 0.0099
  Topological: 5.1868 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 70/300 COMPLETE (46.1s)
Train Loss: 0.5806 (C:5.5880, R:0.0100, T:0.5796)
Val Loss:   5.1878 (C:4.3991, R:0.0099, T:5.1868)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 71 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5810 (C:5.5606, R:0.0099, T:0.5800(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5868 (C:5.6225, R:0.0099, T:0.5858(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5713 (C:5.5990, R:0.0100, T:0.5703(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5643 (C:5.5792, R:0.0099, T:0.5633(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5760 (C:5.5962, R:0.0100, T:0.5750(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5568 (C:5.5750, R:0.0099, T:0.5558(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5884 (C:5.5891, R:0.0100, T:0.5874(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5827 (C:5.5355, R:0.0099, T:0.5817(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5667 (C:5.5960, R:0.0099, T:0.5657(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6084 (C:5.5518, R:0.0100, T:0.6074(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5900 (C:5.5812, R:0.0099, T:0.5890(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5598 (C:5.5333, R:0.0099, T:0.5588(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5662 (C:5.5794, R:0.0100, T:0.5652(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5794 (C:5.5512, R:0.0099, T:0.5784(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5623 (C:5.5704, R:0.0100, T:0.5613(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5606 (C:5.6031, R:0.0099, T:0.5596(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5658 (C:5.5677, R:0.0099, T:0.5648(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5723 (C:5.5686, R:0.0100, T:0.5713(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5715 (C:5.5875, R:0.0099, T:0.5705(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6069 (C:5.5255, R:0.0099, T:0.6059(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5735 (C:5.5672, R:0.0100, T:0.5725(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5842 (C:5.6128, R:0.0099, T:0.5832(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5781

ğŸ“Š EPOCH 71 TRAINING SUMMARY:
  Total Loss: 0.5791
  Contrastive: 5.5860
  Reconstruction: 0.0100
  Topological: 0.5781 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.1852
  Contrastive: 4.3776
  Reconstruction: 0.0099
  Topological: 5.1842 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 71/300 COMPLETE (45.7s)
Train Loss: 0.5791 (C:5.5860, R:0.0100, T:0.5781)
Val Loss:   5.1852 (C:4.3776, R:0.0099, T:5.1842)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 72 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5901 (C:5.5691, R:0.0100, T:0.5891(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5511 (C:5.6025, R:0.0099, T:0.5501(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5789 (C:5.5841, R:0.0099, T:0.5779(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5827 (C:5.5691, R:0.0099, T:0.5817(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5600 (C:5.5645, R:0.0099, T:0.5590(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5937 (C:5.5436, R:0.0099, T:0.5927(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5837 (C:5.5649, R:0.0099, T:0.5827(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5756 (C:5.5958, R:0.0100, T:0.5746(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5366 (C:5.5790, R:0.0099, T:0.5356(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5975 (C:5.5779, R:0.0099, T:0.5965(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6043 (C:5.6102, R:0.0100, T:0.6033(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5959 (C:5.5348, R:0.0100, T:0.5949(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5479 (C:5.6004, R:0.0099, T:0.5469(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5817 (C:5.5616, R:0.0099, T:0.5807(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5725 (C:5.5883, R:0.0099, T:0.5715(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5674 (C:5.6017, R:0.0099, T:0.5664(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5558 (C:5.5930, R:0.0099, T:0.5548(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5928 (C:5.6010, R:0.0100, T:0.5918(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5791 (C:5.5998, R:0.0099, T:0.5781(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5671 (C:5.5911, R:0.0100, T:0.5661(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5877 (C:5.5942, R:0.0099, T:0.5867(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5864 (C:5.5611, R:0.0099, T:0.5854(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5777

ğŸ“Š EPOCH 72 TRAINING SUMMARY:
  Total Loss: 0.5787
  Contrastive: 5.5867
  Reconstruction: 0.0100
  Topological: 0.5777 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.1843
  Contrastive: 4.4132
  Reconstruction: 0.0099
  Topological: 5.1833 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 72/300 COMPLETE (44.4s)
Train Loss: 0.5787 (C:5.5867, R:0.0100, T:0.5777)
Val Loss:   5.1843 (C:4.4132, R:0.0099, T:5.1833)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 73 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5537 (C:5.5796, R:0.0099, T:0.5527(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5816 (C:5.5973, R:0.0100, T:0.5806(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5720 (C:5.5906, R:0.0100, T:0.5710(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5701 (C:5.5765, R:0.0099, T:0.5691(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5732 (C:5.5550, R:0.0099, T:0.5722(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5964 (C:5.5964, R:0.0099, T:0.5954(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5665 (C:5.5907, R:0.0100, T:0.5655(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6091 (C:5.5533, R:0.0099, T:0.6081(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5823 (C:5.5804, R:0.0100, T:0.5813(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5801 (C:5.5838, R:0.0099, T:0.5791(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5698 (C:5.6187, R:0.0100, T:0.5688(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5963 (C:5.5945, R:0.0100, T:0.5953(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5606 (C:5.5948, R:0.0100, T:0.5596(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5609 (C:5.6075, R:0.0100, T:0.5599(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5969 (C:5.5459, R:0.0099, T:0.5959(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5900 (C:5.5762, R:0.0099, T:0.5890(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5734 (C:5.5691, R:0.0099, T:0.5724(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5783 (C:5.5693, R:0.0100, T:0.5773(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5823 (C:5.5668, R:0.0100, T:0.5813(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5841 (C:5.6212, R:0.0100, T:0.5831(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5943 (C:5.6242, R:0.0099, T:0.5933(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6173 (C:5.5896, R:0.0100, T:0.6163(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5763

ğŸ“Š EPOCH 73 TRAINING SUMMARY:
  Total Loss: 0.5773
  Contrastive: 5.5877
  Reconstruction: 0.0100
  Topological: 0.5763 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.3295
  Contrastive: 4.3683
  Reconstruction: 0.0099
  Topological: 5.3285 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 73/300 COMPLETE (45.8s)
Train Loss: 0.5773 (C:5.5877, R:0.0100, T:0.5763)
Val Loss:   5.3295 (C:4.3683, R:0.0099, T:5.3285)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 74 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5758 (C:5.5390, R:0.0099, T:0.5748(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5778 (C:5.5799, R:0.0099, T:0.5768(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5656 (C:5.5768, R:0.0100, T:0.5646(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5652 (C:5.6082, R:0.0100, T:0.5642(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6103 (C:5.5610, R:0.0099, T:0.6093(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5673 (C:5.5952, R:0.0100, T:0.5663(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5984 (C:5.6117, R:0.0100, T:0.5974(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5591 (C:5.5463, R:0.0100, T:0.5581(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6087 (C:5.5874, R:0.0099, T:0.6077(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5643 (C:5.5903, R:0.0099, T:0.5633(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5802 (C:5.5741, R:0.0100, T:0.5792(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5968 (C:5.5848, R:0.0100, T:0.5958(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5902 (C:5.5557, R:0.0099, T:0.5892(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5826 (C:5.6366, R:0.0100, T:0.5816(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5912 (C:5.5631, R:0.0099, T:0.5902(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5970 (C:5.5431, R:0.0099, T:0.5960(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5724 (C:5.6143, R:0.0099, T:0.5714(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5785 (C:5.6040, R:0.0100, T:0.5775(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5658 (C:5.5733, R:0.0099, T:0.5648(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5815 (C:5.5722, R:0.0099, T:0.5806(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5698 (C:5.5749, R:0.0099, T:0.5688(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5779 (C:5.6119, R:0.0100, T:0.5769(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 74 TRAINING SUMMARY:
  Total Loss: 0.5781
  Contrastive: 5.5878
  Reconstruction: 0.0100
  Topological: 0.5771 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.1918
  Contrastive: 4.3951
  Reconstruction: 0.0099
  Topological: 5.1908 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 74/300 COMPLETE (45.6s)
Train Loss: 0.5781 (C:5.5878, R:0.0100, T:0.5771)
Val Loss:   5.1918 (C:4.3951, R:0.0099, T:5.1908)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 75 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5635 (C:5.5582, R:0.0099, T:0.5625(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5468 (C:5.5946, R:0.0099, T:0.5458(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6158 (C:5.5786, R:0.0100, T:0.6148(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5598 (C:5.6114, R:0.0100, T:0.5588(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5556 (C:5.5946, R:0.0100, T:0.5546(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5840 (C:5.6092, R:0.0100, T:0.5830(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5829 (C:5.5928, R:0.0100, T:0.5819(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5602 (C:5.5583, R:0.0099, T:0.5592(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6025 (C:5.6068, R:0.0100, T:0.6015(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5943 (C:5.6174, R:0.0100, T:0.5933(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5340 (C:5.6123, R:0.0099, T:0.5330(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5783 (C:5.6747, R:0.0100, T:0.5773(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6061 (C:5.6271, R:0.0099, T:0.6052(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5688 (C:5.5586, R:0.0100, T:0.5678(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5688 (C:5.5895, R:0.0099, T:0.5678(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5906 (C:5.5723, R:0.0100, T:0.5896(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5355 (C:5.6111, R:0.0100, T:0.5345(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6022 (C:5.5781, R:0.0099, T:0.6012(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5637 (C:5.5654, R:0.0100, T:0.5627(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6288 (C:5.5590, R:0.0100, T:0.6278(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5537 (C:5.6240, R:0.0099, T:0.5527(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5691 (C:5.5816, R:0.0100, T:0.5681(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 75 TRAINING SUMMARY:
  Total Loss: 0.5795
  Contrastive: 5.5875
  Reconstruction: 0.0100
  Topological: 0.5785 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.2160
  Contrastive: 4.3979
  Reconstruction: 0.0099
  Topological: 5.2150 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 75/300 COMPLETE (45.4s)
Train Loss: 0.5795 (C:5.5875, R:0.0100, T:0.5785)
Val Loss:   5.2160 (C:4.3979, R:0.0099, T:5.2150)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 76 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5925 (C:5.5988, R:0.0100, T:0.5916(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5961 (C:5.6312, R:0.0099, T:0.5951(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5934 (C:5.6418, R:0.0100, T:0.5924(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5634 (C:5.5727, R:0.0100, T:0.5624(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5671 (C:5.5692, R:0.0099, T:0.5661(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5782 (C:5.5966, R:0.0099, T:0.5772(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5151 (C:5.6005, R:0.0100, T:0.5141(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5756 (C:5.6485, R:0.0100, T:0.5746(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6022 (C:5.5686, R:0.0100, T:0.6012(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5648 (C:5.5998, R:0.0099, T:0.5638(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5636 (C:5.5603, R:0.0100, T:0.5626(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5778 (C:5.5781, R:0.0100, T:0.5768(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5867 (C:5.6396, R:0.0100, T:0.5857(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5879 (C:5.6115, R:0.0099, T:0.5869(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6212 (C:5.5948, R:0.0100, T:0.6202(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6128 (C:5.5678, R:0.0100, T:0.6118(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5766 (C:5.6095, R:0.0100, T:0.5756(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5388 (C:5.5370, R:0.0100, T:0.5378(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5421 (C:5.6735, R:0.0100, T:0.5411(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5588 (C:5.5616, R:0.0100, T:0.5578(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5729 (C:5.5785, R:0.0100, T:0.5719(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5723 (C:5.5614, R:0.0099, T:0.5713(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5758

ğŸ“Š EPOCH 76 TRAINING SUMMARY:
  Total Loss: 0.5768
  Contrastive: 5.5873
  Reconstruction: 0.0100
  Topological: 0.5758 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0827
  Contrastive: 4.4332
  Reconstruction: 0.0099
  Topological: 5.0817 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 76/300 COMPLETE (45.5s)
Train Loss: 0.5768 (C:5.5873, R:0.0100, T:0.5758)
Val Loss:   5.0827 (C:4.4332, R:0.0099, T:5.0817)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 77 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5893 (C:5.6388, R:0.0100, T:0.5883(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6012 (C:5.6276, R:0.0100, T:0.6002(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5661 (C:5.5983, R:0.0100, T:0.5651(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5983 (C:5.5628, R:0.0099, T:0.5973(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5979 (C:5.5712, R:0.0099, T:0.5969(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5747 (C:5.5766, R:0.0099, T:0.5737(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6055 (C:5.6051, R:0.0100, T:0.6045(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5870 (C:5.6006, R:0.0100, T:0.5860(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5506 (C:5.6190, R:0.0100, T:0.5496(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5879 (C:5.5832, R:0.0099, T:0.5869(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5691 (C:5.5846, R:0.0099, T:0.5681(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5772 (C:5.5891, R:0.0099, T:0.5762(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5842 (C:5.5683, R:0.0100, T:0.5832(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5820 (C:5.6195, R:0.0100, T:0.5810(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5373 (C:5.6267, R:0.0100, T:0.5363(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5381 (C:5.5602, R:0.0099, T:0.5371(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5801 (C:5.5887, R:0.0099, T:0.5791(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5951 (C:5.5906, R:0.0100, T:0.5941(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5526 (C:5.5835, R:0.0100, T:0.5516(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5858 (C:5.5941, R:0.0100, T:0.5848(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5772 (C:5.6287, R:0.0100, T:0.5762(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5453 (C:5.5685, R:0.0100, T:0.5443(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5750

ğŸ“Š EPOCH 77 TRAINING SUMMARY:
  Total Loss: 0.5760
  Contrastive: 5.5884
  Reconstruction: 0.0100
  Topological: 0.5750 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.1314
  Contrastive: 4.4086
  Reconstruction: 0.0099
  Topological: 5.1304 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 77/300 COMPLETE (45.9s)
Train Loss: 0.5760 (C:5.5884, R:0.0100, T:0.5750)
Val Loss:   5.1314 (C:4.4086, R:0.0099, T:5.1304)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 78 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5724 (C:5.6079, R:0.0099, T:0.5714(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6216 (C:5.5493, R:0.0100, T:0.6206(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5855 (C:5.5887, R:0.0100, T:0.5845(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5760 (C:5.5524, R:0.0100, T:0.5750(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5661 (C:5.5477, R:0.0100, T:0.5651(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5678 (C:5.5747, R:0.0099, T:0.5668(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6088 (C:5.5531, R:0.0099, T:0.6078(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5764 (C:5.6088, R:0.0100, T:0.5755(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5815 (C:5.5840, R:0.0099, T:0.5805(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5588 (C:5.5670, R:0.0100, T:0.5578(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5938 (C:5.5976, R:0.0100, T:0.5928(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5675 (C:5.5696, R:0.0099, T:0.5666(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5703 (C:5.6140, R:0.0100, T:0.5693(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5509 (C:5.5880, R:0.0100, T:0.5499(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5833 (C:5.5648, R:0.0100, T:0.5823(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5938 (C:5.5894, R:0.0099, T:0.5928(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5866 (C:5.5987, R:0.0100, T:0.5856(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6014 (C:5.5569, R:0.0100, T:0.6004(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5776 (C:5.6018, R:0.0100, T:0.5766(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5967 (C:5.5653, R:0.0100, T:0.5957(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5675 (C:5.6282, R:0.0099, T:0.5665(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5586 (C:5.5406, R:0.0099, T:0.5576(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 78 TRAINING SUMMARY:
  Total Loss: 0.5768
  Contrastive: 5.5881
  Reconstruction: 0.0100
  Topological: 0.5758 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.1955
  Contrastive: 4.3968
  Reconstruction: 0.0099
  Topological: 5.1945 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 78/300 COMPLETE (44.1s)
Train Loss: 0.5768 (C:5.5881, R:0.0100, T:0.5758)
Val Loss:   5.1955 (C:4.3968, R:0.0099, T:5.1945)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 79 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5792 (C:5.5783, R:0.0099, T:0.5782(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5948 (C:5.5524, R:0.0100, T:0.5938(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5747 (C:5.5699, R:0.0100, T:0.5737(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5505 (C:5.5822, R:0.0100, T:0.5495(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5798 (C:5.5846, R:0.0100, T:0.5788(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5525 (C:5.5807, R:0.0100, T:0.5516(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5319 (C:5.5641, R:0.0099, T:0.5309(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5801 (C:5.6113, R:0.0100, T:0.5791(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5760 (C:5.6198, R:0.0100, T:0.5750(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5772 (C:5.6464, R:0.0099, T:0.5762(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5949 (C:5.6027, R:0.0099, T:0.5940(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5799 (C:5.6109, R:0.0100, T:0.5789(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5396 (C:5.5539, R:0.0099, T:0.5386(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5779 (C:5.5812, R:0.0099, T:0.5770(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5751 (C:5.6029, R:0.0100, T:0.5741(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5799 (C:5.5590, R:0.0099, T:0.5789(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5571 (C:5.6210, R:0.0099, T:0.5561(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5505 (C:5.5320, R:0.0100, T:0.5495(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5768 (C:5.5634, R:0.0099, T:0.5758(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5767 (C:5.6062, R:0.0099, T:0.5757(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6013 (C:5.5669, R:0.0099, T:0.6003(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5725 (C:5.6110, R:0.0100, T:0.5715(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 79 TRAINING SUMMARY:
  Total Loss: 0.5766
  Contrastive: 5.5883
  Reconstruction: 0.0100
  Topological: 0.5756 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9904
  Contrastive: 4.4466
  Reconstruction: 0.0099
  Topological: 4.9894 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 79/300 COMPLETE (46.9s)
Train Loss: 0.5766 (C:5.5883, R:0.0100, T:0.5756)
Val Loss:   4.9904 (C:4.4466, R:0.0099, T:4.9894)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 80 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.6289 (C:5.6523, R:0.0099, T:0.6279(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5666 (C:5.5912, R:0.0100, T:0.5656(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5595 (C:5.5919, R:0.0100, T:0.5585(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5706 (C:5.6078, R:0.0100, T:0.5696(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5990 (C:5.5663, R:0.0099, T:0.5980(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6171 (C:5.6047, R:0.0099, T:0.6161(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5798 (C:5.6220, R:0.0100, T:0.5788(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5586 (C:5.5883, R:0.0100, T:0.5576(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5731 (C:5.6064, R:0.0099, T:0.5722(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5839 (C:5.5614, R:0.0099, T:0.5830(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5715 (C:5.5723, R:0.0100, T:0.5705(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5773 (C:5.5818, R:0.0099, T:0.5763(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5944 (C:5.6415, R:0.0100, T:0.5934(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5625 (C:5.5273, R:0.0099, T:0.5615(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5694 (C:5.6034, R:0.0099, T:0.5684(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.6018 (C:5.6197, R:0.0100, T:0.6008(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5953 (C:5.6068, R:0.0100, T:0.5943(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5767 (C:5.6464, R:0.0100, T:0.5757(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5928 (C:5.5635, R:0.0099, T:0.5918(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5851 (C:5.6235, R:0.0100, T:0.5841(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5577 (C:5.6027, R:0.0099, T:0.5567(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5815 (C:5.5585, R:0.0100, T:0.5805(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 80 TRAINING SUMMARY:
  Total Loss: 0.5764
  Contrastive: 5.5889
  Reconstruction: 0.0100
  Topological: 0.5755 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.1681
  Contrastive: 4.4150
  Reconstruction: 0.0099
  Topological: 5.1671 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 80/300 COMPLETE (45.8s)
Train Loss: 0.5764 (C:5.5889, R:0.0100, T:0.5755)
Val Loss:   5.1681 (C:4.4150, R:0.0099, T:5.1671)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 81 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5986 (C:5.5923, R:0.0100, T:0.5976(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5965 (C:5.5573, R:0.0100, T:0.5955(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5832 (C:5.6300, R:0.0100, T:0.5822(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5535 (C:5.5598, R:0.0099, T:0.5525(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5827 (C:5.6529, R:0.0099, T:0.5817(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5573 (C:5.5382, R:0.0100, T:0.5563(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5879 (C:5.5804, R:0.0100, T:0.5869(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5849 (C:5.6141, R:0.0100, T:0.5839(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5602 (C:5.5781, R:0.0100, T:0.5592(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5882 (C:5.6044, R:0.0100, T:0.5873(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5656 (C:5.5717, R:0.0100, T:0.5646(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5837 (C:5.6034, R:0.0099, T:0.5827(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5688 (C:5.5569, R:0.0099, T:0.5678(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5605 (C:5.6142, R:0.0100, T:0.5595(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5773 (C:5.6080, R:0.0099, T:0.5763(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5385 (C:5.5576, R:0.0099, T:0.5375(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5698 (C:5.5831, R:0.0100, T:0.5688(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5843 (C:5.6360, R:0.0099, T:0.5833(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6046 (C:5.6095, R:0.0100, T:0.6036(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5608 (C:5.6080, R:0.0099, T:0.5598(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5859 (C:5.5823, R:0.0099, T:0.5850(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5782 (C:5.6136, R:0.0100, T:0.5772(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5749

ğŸ“Š EPOCH 81 TRAINING SUMMARY:
  Total Loss: 0.5759
  Contrastive: 5.5880
  Reconstruction: 0.0100
  Topological: 0.5749 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0989
  Contrastive: 4.4163
  Reconstruction: 0.0099
  Topological: 5.0979 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 81/300 COMPLETE (44.3s)
Train Loss: 0.5759 (C:5.5880, R:0.0100, T:0.5749)
Val Loss:   5.0989 (C:4.4163, R:0.0099, T:5.0979)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 82 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5764 (C:5.5910, R:0.0100, T:0.5754(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5538 (C:5.5501, R:0.0100, T:0.5528(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5687 (C:5.6077, R:0.0100, T:0.5677(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5712 (C:5.5757, R:0.0099, T:0.5702(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5649 (C:5.6318, R:0.0100, T:0.5639(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5793 (C:5.6160, R:0.0100, T:0.5783(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5799 (C:5.5790, R:0.0100, T:0.5789(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6090 (C:5.6429, R:0.0100, T:0.6080(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6063 (C:5.5655, R:0.0099, T:0.6053(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5774 (C:5.6001, R:0.0100, T:0.5764(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5549 (C:5.5408, R:0.0099, T:0.5539(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5628 (C:5.5818, R:0.0100, T:0.5618(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5860 (C:5.6248, R:0.0100, T:0.5850(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5870 (C:5.5784, R:0.0099, T:0.5860(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5965 (C:5.5900, R:0.0100, T:0.5955(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5892 (C:5.5981, R:0.0099, T:0.5882(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5876 (C:5.5201, R:0.0100, T:0.5866(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5594 (C:5.5883, R:0.0099, T:0.5584(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5723 (C:5.5739, R:0.0100, T:0.5713(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5797 (C:5.5669, R:0.0100, T:0.5787(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5591 (C:5.6408, R:0.0099, T:0.5581(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5748 (C:5.5217, R:0.0100, T:0.5738(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 82 TRAINING SUMMARY:
  Total Loss: 0.5760
  Contrastive: 5.5893
  Reconstruction: 0.0100
  Topological: 0.5750 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0808
  Contrastive: 4.4389
  Reconstruction: 0.0099
  Topological: 5.0798 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 82/300 COMPLETE (45.2s)
Train Loss: 0.5760 (C:5.5893, R:0.0100, T:0.5750)
Val Loss:   5.0808 (C:4.4389, R:0.0099, T:5.0798)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 83 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5860 (C:5.6184, R:0.0099, T:0.5850(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5868 (C:5.6000, R:0.0099, T:0.5858(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5933 (C:5.5723, R:0.0100, T:0.5923(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5833 (C:5.5464, R:0.0099, T:0.5823(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5428 (C:5.6102, R:0.0100, T:0.5418(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5607 (C:5.6095, R:0.0099, T:0.5597(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5424 (C:5.5467, R:0.0099, T:0.5414(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5917 (C:5.6105, R:0.0100, T:0.5907(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5542 (C:5.5724, R:0.0100, T:0.5532(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5980 (C:5.6399, R:0.0100, T:0.5970(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5941 (C:5.5567, R:0.0099, T:0.5931(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5706 (C:5.5386, R:0.0099, T:0.5696(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6002 (C:5.5942, R:0.0100, T:0.5992(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5652 (C:5.5889, R:0.0099, T:0.5642(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5911 (C:5.5993, R:0.0100, T:0.5902(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5851 (C:5.5949, R:0.0099, T:0.5842(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5715 (C:5.5754, R:0.0100, T:0.5705(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5796 (C:5.5937, R:0.0100, T:0.5786(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5920 (C:5.5844, R:0.0100, T:0.5910(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5642 (C:5.5457, R:0.0100, T:0.5632(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6300 (C:5.5960, R:0.0099, T:0.6290(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5806 (C:5.5415, R:0.0100, T:0.5796(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 83 TRAINING SUMMARY:
  Total Loss: 0.5760
  Contrastive: 5.5872
  Reconstruction: 0.0100
  Topological: 0.5750 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.1708
  Contrastive: 4.3989
  Reconstruction: 0.0099
  Topological: 5.1698 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 83/300 COMPLETE (45.2s)
Train Loss: 0.5760 (C:5.5872, R:0.0100, T:0.5750)
Val Loss:   5.1708 (C:4.3989, R:0.0099, T:5.1698)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 84 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5569 (C:5.5774, R:0.0099, T:0.5559(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5534 (C:5.5921, R:0.0099, T:0.5524(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5703 (C:5.5616, R:0.0100, T:0.5693(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5647 (C:5.5941, R:0.0099, T:0.5637(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5765 (C:5.5674, R:0.0100, T:0.5755(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5872 (C:5.6114, R:0.0099, T:0.5862(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5666 (C:5.6081, R:0.0100, T:0.5656(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5542 (C:5.5923, R:0.0100, T:0.5532(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5783 (C:5.6064, R:0.0100, T:0.5773(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5811 (C:5.5848, R:0.0099, T:0.5801(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5936 (C:5.5525, R:0.0100, T:0.5926(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5833 (C:5.5792, R:0.0099, T:0.5824(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5625 (C:5.5950, R:0.0099, T:0.5615(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6001 (C:5.5728, R:0.0100, T:0.5991(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5518 (C:5.5629, R:0.0099, T:0.5508(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5731 (C:5.5576, R:0.0099, T:0.5721(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5588 (C:5.5689, R:0.0100, T:0.5578(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5770 (C:5.5722, R:0.0100, T:0.5760(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5531 (C:5.6024, R:0.0100, T:0.5521(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5878 (C:5.5932, R:0.0099, T:0.5868(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5728 (C:5.5773, R:0.0099, T:0.5718(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5807 (C:5.5576, R:0.0100, T:0.5797(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 84 TRAINING SUMMARY:
  Total Loss: 0.5765
  Contrastive: 5.5867
  Reconstruction: 0.0100
  Topological: 0.5755 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.2079
  Contrastive: 4.3817
  Reconstruction: 0.0099
  Topological: 5.2069 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 84/300 COMPLETE (44.8s)
Train Loss: 0.5765 (C:5.5867, R:0.0100, T:0.5755)
Val Loss:   5.2079 (C:4.3817, R:0.0099, T:5.2069)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 85 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5666 (C:5.5729, R:0.0100, T:0.5656(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5617 (C:5.5985, R:0.0099, T:0.5607(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5648 (C:5.6045, R:0.0099, T:0.5638(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5704 (C:5.5589, R:0.0100, T:0.5694(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6504 (C:5.6052, R:0.0099, T:0.6494(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6031 (C:5.5505, R:0.0099, T:0.6021(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5768 (C:5.5640, R:0.0099, T:0.5758(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5903 (C:5.5790, R:0.0100, T:0.5893(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5593 (C:5.6055, R:0.0100, T:0.5583(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5759 (C:5.6157, R:0.0100, T:0.5749(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5627 (C:5.5979, R:0.0100, T:0.5617(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5770 (C:5.5983, R:0.0099, T:0.5760(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5992 (C:5.5925, R:0.0100, T:0.5982(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5501 (C:5.5327, R:0.0099, T:0.5491(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5468 (C:5.5940, R:0.0099, T:0.5458(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5799 (C:5.5753, R:0.0100, T:0.5789(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5960 (C:5.5788, R:0.0099, T:0.5950(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5842 (C:5.5791, R:0.0099, T:0.5832(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5714 (C:5.6002, R:0.0099, T:0.5704(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5716 (C:5.5451, R:0.0099, T:0.5706(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5479 (C:5.5924, R:0.0100, T:0.5469(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5930 (C:5.5460, R:0.0100, T:0.5920(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5740

ğŸ“Š EPOCH 85 TRAINING SUMMARY:
  Total Loss: 0.5750
  Contrastive: 5.5900
  Reconstruction: 0.0100
  Topological: 0.5740 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.1841
  Contrastive: 4.4065
  Reconstruction: 0.0099
  Topological: 5.1831 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 85/300 COMPLETE (45.7s)
Train Loss: 0.5750 (C:5.5900, R:0.0100, T:0.5740)
Val Loss:   5.1841 (C:4.4065, R:0.0099, T:5.1831)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 86 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5814 (C:5.5988, R:0.0100, T:0.5804(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5928 (C:5.5900, R:0.0100, T:0.5918(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5759 (C:5.5812, R:0.0100, T:0.5749(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5566 (C:5.5949, R:0.0099, T:0.5556(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5702 (C:5.5564, R:0.0099, T:0.5692(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5854 (C:5.6334, R:0.0100, T:0.5844(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5615 (C:5.5870, R:0.0100, T:0.5605(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5848 (C:5.6049, R:0.0099, T:0.5838(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5758 (C:5.5845, R:0.0099, T:0.5748(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5677 (C:5.5841, R:0.0100, T:0.5667(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.6118 (C:5.5922, R:0.0100, T:0.6108(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5590 (C:5.6042, R:0.0100, T:0.5580(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5303 (C:5.5991, R:0.0099, T:0.5293(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5714 (C:5.5664, R:0.0099, T:0.5704(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5845 (C:5.5964, R:0.0099, T:0.5835(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5421 (C:5.5768, R:0.0099, T:0.5411(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5869 (C:5.5681, R:0.0099, T:0.5859(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5799 (C:5.5754, R:0.0100, T:0.5789(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5614 (C:5.5658, R:0.0100, T:0.5604(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5763 (C:5.5769, R:0.0099, T:0.5753(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5578 (C:5.5678, R:0.0099, T:0.5568(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5821 (C:5.5510, R:0.0099, T:0.5811(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5724

ğŸ“Š EPOCH 86 TRAINING SUMMARY:
  Total Loss: 0.5734
  Contrastive: 5.5910
  Reconstruction: 0.0100
  Topological: 0.5724 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0338
  Contrastive: 4.4492
  Reconstruction: 0.0099
  Topological: 5.0329 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 86/300 COMPLETE (45.2s)
Train Loss: 0.5734 (C:5.5910, R:0.0100, T:0.5724)
Val Loss:   5.0338 (C:4.4492, R:0.0099, T:5.0329)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 87 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5946 (C:5.6450, R:0.0100, T:0.5936(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5955 (C:5.6221, R:0.0100, T:0.5945(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5580 (C:5.5998, R:0.0099, T:0.5571(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5762 (C:5.6208, R:0.0100, T:0.5752(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5800 (C:5.5529, R:0.0099, T:0.5790(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5746 (C:5.5884, R:0.0099, T:0.5736(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5644 (C:5.5993, R:0.0100, T:0.5634(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5817 (C:5.6155, R:0.0099, T:0.5807(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5678 (C:5.6285, R:0.0100, T:0.5668(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5732 (C:5.5987, R:0.0100, T:0.5723(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5424 (C:5.6084, R:0.0100, T:0.5414(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5623 (C:5.5957, R:0.0099, T:0.5613(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5818 (C:5.5920, R:0.0099, T:0.5808(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5367 (C:5.6017, R:0.0099, T:0.5357(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5776 (C:5.6107, R:0.0100, T:0.5766(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5667 (C:5.6188, R:0.0100, T:0.5658(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5733 (C:5.5942, R:0.0100, T:0.5723(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5828 (C:5.5844, R:0.0100, T:0.5818(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5746 (C:5.5586, R:0.0100, T:0.5736(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6173 (C:5.6111, R:0.0100, T:0.6163(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5640 (C:5.5714, R:0.0099, T:0.5630(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5922 (C:5.5940, R:0.0100, T:0.5912(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 87 TRAINING SUMMARY:
  Total Loss: 0.5741
  Contrastive: 5.5892
  Reconstruction: 0.0100
  Topological: 0.5731 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0884
  Contrastive: 4.4153
  Reconstruction: 0.0099
  Topological: 5.0874 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 87/300 COMPLETE (45.3s)
Train Loss: 0.5741 (C:5.5892, R:0.0100, T:0.5731)
Val Loss:   5.0884 (C:4.4153, R:0.0099, T:5.0874)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 88 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5854 (C:5.6142, R:0.0099, T:0.5844(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5632 (C:5.5869, R:0.0100, T:0.5622(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5849 (C:5.6060, R:0.0100, T:0.5839(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5691 (C:5.5747, R:0.0100, T:0.5681(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5788 (C:5.6209, R:0.0100, T:0.5778(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5797 (C:5.5513, R:0.0100, T:0.5787(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5969 (C:5.6234, R:0.0099, T:0.5959(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.6026 (C:5.5610, R:0.0099, T:0.6017(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5796 (C:5.5354, R:0.0100, T:0.5786(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5867 (C:5.6259, R:0.0100, T:0.5857(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5652 (C:5.5975, R:0.0099, T:0.5642(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5877 (C:5.6455, R:0.0100, T:0.5867(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6018 (C:5.5479, R:0.0099, T:0.6008(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5723 (C:5.5598, R:0.0100, T:0.5713(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5596 (C:5.5947, R:0.0100, T:0.5586(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5533 (C:5.6084, R:0.0100, T:0.5523(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5647 (C:5.6092, R:0.0100, T:0.5637(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5934 (C:5.5777, R:0.0099, T:0.5924(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5613 (C:5.5590, R:0.0099, T:0.5604(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5515 (C:5.6068, R:0.0099, T:0.5505(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5510 (C:5.5413, R:0.0099, T:0.5500(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5985 (C:5.6108, R:0.0099, T:0.5975(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 88 TRAINING SUMMARY:
  Total Loss: 0.5745
  Contrastive: 5.5888
  Reconstruction: 0.0100
  Topological: 0.5735 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.1161
  Contrastive: 4.4157
  Reconstruction: 0.0099
  Topological: 5.1151 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 88/300 COMPLETE (45.5s)
Train Loss: 0.5745 (C:5.5888, R:0.0100, T:0.5735)
Val Loss:   5.1161 (C:4.4157, R:0.0099, T:5.1151)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 89 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5647 (C:5.5893, R:0.0100, T:0.5637(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5537 (C:5.5469, R:0.0099, T:0.5527(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5509 (C:5.6038, R:0.0099, T:0.5499(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5508 (C:5.6199, R:0.0100, T:0.5498(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5703 (C:5.5803, R:0.0099, T:0.5693(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5634 (C:5.5845, R:0.0100, T:0.5624(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5763 (C:5.6138, R:0.0100, T:0.5753(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5649 (C:5.5994, R:0.0100, T:0.5639(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5634 (C:5.5948, R:0.0100, T:0.5624(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5752 (C:5.6144, R:0.0100, T:0.5743(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5456 (C:5.5593, R:0.0099, T:0.5446(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5914 (C:5.5480, R:0.0099, T:0.5905(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.6054 (C:5.6234, R:0.0100, T:0.6044(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5830 (C:5.6032, R:0.0099, T:0.5820(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5564 (C:5.5975, R:0.0099, T:0.5554(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5553 (C:5.6045, R:0.0100, T:0.5543(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5521 (C:5.5613, R:0.0099, T:0.5511(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5820 (C:5.5671, R:0.0100, T:0.5810(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5766 (C:5.6093, R:0.0099, T:0.5756(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5611 (C:5.5782, R:0.0100, T:0.5601(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5570 (C:5.5985, R:0.0099, T:0.5560(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5656 (C:5.5633, R:0.0099, T:0.5646(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5711

ğŸ“Š EPOCH 89 TRAINING SUMMARY:
  Total Loss: 0.5721
  Contrastive: 5.5882
  Reconstruction: 0.0100
  Topological: 0.5711 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.1278
  Contrastive: 4.3977
  Reconstruction: 0.0099
  Topological: 5.1268 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 89/300 COMPLETE (45.1s)
Train Loss: 0.5721 (C:5.5882, R:0.0100, T:0.5711)
Val Loss:   5.1278 (C:4.3977, R:0.0099, T:5.1268)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 90 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5694 (C:5.5640, R:0.0100, T:0.5684(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5716 (C:5.6167, R:0.0099, T:0.5706(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5356 (C:5.5951, R:0.0099, T:0.5346(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5691 (C:5.5810, R:0.0099, T:0.5681(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.6038 (C:5.5978, R:0.0099, T:0.6028(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5471 (C:5.5580, R:0.0099, T:0.5461(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5772 (C:5.5068, R:0.0100, T:0.5762(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5723 (C:5.6290, R:0.0099, T:0.5713(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5543 (C:5.5649, R:0.0100, T:0.5533(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5604 (C:5.6003, R:0.0100, T:0.5594(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5659 (C:5.6054, R:0.0100, T:0.5649(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5513 (C:5.5870, R:0.0100, T:0.5503(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5815 (C:5.6122, R:0.0100, T:0.5805(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5687 (C:5.6036, R:0.0099, T:0.5677(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5681 (C:5.5510, R:0.0099, T:0.5671(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5843 (C:5.6368, R:0.0099, T:0.5833(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5751 (C:5.5795, R:0.0100, T:0.5741(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5776 (C:5.5774, R:0.0100, T:0.5766(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5636 (C:5.6065, R:0.0100, T:0.5626(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5413 (C:5.5320, R:0.0100, T:0.5403(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5631 (C:5.5408, R:0.0099, T:0.5621(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5682 (C:5.6015, R:0.0099, T:0.5672(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 90 TRAINING SUMMARY:
  Total Loss: 0.5727
  Contrastive: 5.5876
  Reconstruction: 0.0100
  Topological: 0.5717 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9984
  Contrastive: 4.4234
  Reconstruction: 0.0099
  Topological: 4.9974 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 90/300 COMPLETE (46.0s)
Train Loss: 0.5727 (C:5.5876, R:0.0100, T:0.5717)
Val Loss:   4.9984 (C:4.4234, R:0.0099, T:4.9974)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 91 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5919 (C:5.5968, R:0.0100, T:0.5909(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5817 (C:5.6117, R:0.0099, T:0.5807(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5807 (C:5.6030, R:0.0100, T:0.5797(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5610 (C:5.5945, R:0.0100, T:0.5600(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5741 (C:5.5825, R:0.0099, T:0.5731(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5763 (C:5.5747, R:0.0100, T:0.5753(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5833 (C:5.5841, R:0.0099, T:0.5823(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5778 (C:5.6280, R:0.0100, T:0.5768(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5638 (C:5.5907, R:0.0100, T:0.5628(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5711 (C:5.5846, R:0.0100, T:0.5701(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5615 (C:5.6118, R:0.0099, T:0.5605(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5360 (C:5.5441, R:0.0099, T:0.5351(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5554 (C:5.5771, R:0.0100, T:0.5544(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6140 (C:5.6441, R:0.0099, T:0.6130(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.6044 (C:5.5439, R:0.0100, T:0.6035(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5589 (C:5.6196, R:0.0099, T:0.5579(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5797 (C:5.6074, R:0.0100, T:0.5787(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5846 (C:5.5695, R:0.0100, T:0.5836(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5823 (C:5.5582, R:0.0100, T:0.5813(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5837 (C:5.6162, R:0.0100, T:0.5827(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5909 (C:5.6395, R:0.0100, T:0.5899(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5389 (C:5.6318, R:0.0099, T:0.5379(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 91 TRAINING SUMMARY:
  Total Loss: 0.5724
  Contrastive: 5.5899
  Reconstruction: 0.0100
  Topological: 0.5714 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9750
  Contrastive: 4.4233
  Reconstruction: 0.0099
  Topological: 4.9741 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 91/300 COMPLETE (45.6s)
Train Loss: 0.5724 (C:5.5899, R:0.0100, T:0.5714)
Val Loss:   4.9750 (C:4.4233, R:0.0099, T:4.9741)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 92 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5535 (C:5.5814, R:0.0100, T:0.5525(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5586 (C:5.6068, R:0.0100, T:0.5576(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5893 (C:5.5907, R:0.0100, T:0.5883(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6073 (C:5.5932, R:0.0099, T:0.6063(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5345 (C:5.6222, R:0.0100, T:0.5335(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5469 (C:5.5668, R:0.0100, T:0.5459(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5594 (C:5.6064, R:0.0099, T:0.5584(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5883 (C:5.6004, R:0.0100, T:0.5873(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5637 (C:5.6380, R:0.0100, T:0.5628(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5910 (C:5.5700, R:0.0100, T:0.5901(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5555 (C:5.5843, R:0.0099, T:0.5545(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5967 (C:5.5992, R:0.0099, T:0.5957(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5837 (C:5.5618, R:0.0099, T:0.5827(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5552 (C:5.6089, R:0.0100, T:0.5542(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5870 (C:5.5822, R:0.0100, T:0.5860(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5771 (C:5.5674, R:0.0100, T:0.5761(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5928 (C:5.5820, R:0.0100, T:0.5918(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5676 (C:5.5718, R:0.0099, T:0.5666(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5552 (C:5.6202, R:0.0100, T:0.5542(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5615 (C:5.6113, R:0.0100, T:0.5605(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5524 (C:5.6135, R:0.0099, T:0.5514(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5761 (C:5.5688, R:0.0099, T:0.5751(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5701

ğŸ“Š EPOCH 92 TRAINING SUMMARY:
  Total Loss: 0.5710
  Contrastive: 5.5883
  Reconstruction: 0.0100
  Topological: 0.5701 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0693
  Contrastive: 4.4074
  Reconstruction: 0.0099
  Topological: 5.0683 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 92/300 COMPLETE (44.5s)
Train Loss: 0.5710 (C:5.5883, R:0.0100, T:0.5701)
Val Loss:   5.0693 (C:4.4074, R:0.0099, T:5.0683)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 93 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5400 (C:5.6003, R:0.0100, T:0.5390(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5859 (C:5.6116, R:0.0100, T:0.5849(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5459 (C:5.6129, R:0.0099, T:0.5450(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5656 (C:5.5910, R:0.0099, T:0.5646(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5875 (C:5.5954, R:0.0100, T:0.5865(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5989 (C:5.5920, R:0.0100, T:0.5979(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5604 (C:5.5310, R:0.0100, T:0.5594(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5477 (C:5.6027, R:0.0099, T:0.5467(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5847 (C:5.5809, R:0.0100, T:0.5837(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5665 (C:5.6320, R:0.0099, T:0.5655(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5619 (C:5.5825, R:0.0100, T:0.5609(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5753 (C:5.5951, R:0.0099, T:0.5743(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5455 (C:5.5825, R:0.0100, T:0.5445(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5706 (C:5.5638, R:0.0100, T:0.5696(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5809 (C:5.6122, R:0.0099, T:0.5799(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5681 (C:5.5451, R:0.0099, T:0.5671(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5519 (C:5.5666, R:0.0099, T:0.5509(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5746 (C:5.5524, R:0.0100, T:0.5736(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5706 (C:5.5901, R:0.0100, T:0.5696(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5678 (C:5.6008, R:0.0099, T:0.5668(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5582 (C:5.6334, R:0.0100, T:0.5572(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5697 (C:5.5363, R:0.0100, T:0.5687(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 93 TRAINING SUMMARY:
  Total Loss: 0.5725
  Contrastive: 5.5878
  Reconstruction: 0.0100
  Topological: 0.5715 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0656
  Contrastive: 4.4159
  Reconstruction: 0.0099
  Topological: 5.0646 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 93/300 COMPLETE (46.0s)
Train Loss: 0.5725 (C:5.5878, R:0.0100, T:0.5715)
Val Loss:   5.0656 (C:4.4159, R:0.0099, T:5.0646)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 94 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5598 (C:5.5878, R:0.0100, T:0.5588(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5927 (C:5.5564, R:0.0099, T:0.5917(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5528 (C:5.5668, R:0.0099, T:0.5518(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5985 (C:5.5932, R:0.0100, T:0.5975(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5861 (C:5.6118, R:0.0099, T:0.5851(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5738 (C:5.5989, R:0.0100, T:0.5728(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5704 (C:5.5996, R:0.0099, T:0.5694(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5845 (C:5.5600, R:0.0100, T:0.5835(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5879 (C:5.5793, R:0.0100, T:0.5869(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5541 (C:5.5989, R:0.0100, T:0.5531(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5963 (C:5.5735, R:0.0100, T:0.5953(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5784 (C:5.5815, R:0.0099, T:0.5774(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5451 (C:5.6488, R:0.0099, T:0.5441(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5582 (C:5.5666, R:0.0099, T:0.5572(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5682 (C:5.6029, R:0.0099, T:0.5672(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5662 (C:5.5948, R:0.0099, T:0.5652(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5644 (C:5.5575, R:0.0100, T:0.5634(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5775 (C:5.5925, R:0.0100, T:0.5765(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5817 (C:5.6085, R:0.0100, T:0.5807(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5520 (C:5.5897, R:0.0100, T:0.5510(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5784 (C:5.6272, R:0.0100, T:0.5774(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5571 (C:5.5674, R:0.0099, T:0.5561(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 94 TRAINING SUMMARY:
  Total Loss: 0.5724
  Contrastive: 5.5874
  Reconstruction: 0.0100
  Topological: 0.5714 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0154
  Contrastive: 4.4332
  Reconstruction: 0.0099
  Topological: 5.0144 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 94/300 COMPLETE (45.7s)
Train Loss: 0.5724 (C:5.5874, R:0.0100, T:0.5714)
Val Loss:   5.0154 (C:4.4332, R:0.0099, T:5.0144)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 95 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5625 (C:5.6089, R:0.0100, T:0.5615(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5787 (C:5.5359, R:0.0100, T:0.5777(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5958 (C:5.5787, R:0.0100, T:0.5948(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5751 (C:5.5769, R:0.0100, T:0.5741(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5406 (C:5.5653, R:0.0100, T:0.5396(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5726 (C:5.5479, R:0.0100, T:0.5716(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5877 (C:5.5828, R:0.0099, T:0.5867(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5582 (C:5.5534, R:0.0099, T:0.5572(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5725 (C:5.6083, R:0.0099, T:0.5715(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5534 (C:5.6124, R:0.0099, T:0.5524(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5648 (C:5.5513, R:0.0099, T:0.5638(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5754 (C:5.5873, R:0.0099, T:0.5744(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5486 (C:5.5882, R:0.0099, T:0.5476(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5420 (C:5.5956, R:0.0099, T:0.5410(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5772 (C:5.5833, R:0.0100, T:0.5762(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5985 (C:5.5857, R:0.0100, T:0.5975(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5645 (C:5.6095, R:0.0100, T:0.5635(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5911 (C:5.6052, R:0.0100, T:0.5901(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5483 (C:5.5257, R:0.0099, T:0.5473(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5503 (C:5.5690, R:0.0099, T:0.5493(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5725 (C:5.5946, R:0.0100, T:0.5715(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5677 (C:5.5826, R:0.0100, T:0.5667(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 95 TRAINING SUMMARY:
  Total Loss: 0.5713
  Contrastive: 5.5881
  Reconstruction: 0.0100
  Topological: 0.5703 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9184
  Contrastive: 4.4509
  Reconstruction: 0.0099
  Topological: 4.9174 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 95/300 COMPLETE (44.5s)
Train Loss: 0.5713 (C:5.5881, R:0.0100, T:0.5703)
Val Loss:   4.9184 (C:4.4509, R:0.0099, T:4.9174)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 96 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5769 (C:5.6350, R:0.0100, T:0.5759(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5808 (C:5.5454, R:0.0100, T:0.5798(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5682 (C:5.6140, R:0.0100, T:0.5672(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5618 (C:5.6170, R:0.0099, T:0.5608(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5543 (C:5.6177, R:0.0099, T:0.5533(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5577 (C:5.5563, R:0.0099, T:0.5567(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5922 (C:5.6306, R:0.0100, T:0.5912(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5655 (C:5.5805, R:0.0100, T:0.5645(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6012 (C:5.6028, R:0.0100, T:0.6002(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5784 (C:5.5711, R:0.0099, T:0.5774(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5575 (C:5.6026, R:0.0100, T:0.5565(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5794 (C:5.5997, R:0.0100, T:0.5784(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5676 (C:5.6024, R:0.0099, T:0.5666(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5660 (C:5.5485, R:0.0099, T:0.5650(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5941 (C:5.6021, R:0.0100, T:0.5931(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5485 (C:5.5483, R:0.0100, T:0.5475(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5347 (C:5.5659, R:0.0100, T:0.5337(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5651 (C:5.5539, R:0.0100, T:0.5641(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5378 (C:5.6080, R:0.0099, T:0.5368(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5549 (C:5.5554, R:0.0099, T:0.5539(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5781 (C:5.6193, R:0.0100, T:0.5771(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5587 (C:5.5785, R:0.0100, T:0.5577(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 96 TRAINING SUMMARY:
  Total Loss: 0.5716
  Contrastive: 5.5889
  Reconstruction: 0.0100
  Topological: 0.5706 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0273
  Contrastive: 4.4063
  Reconstruction: 0.0099
  Topological: 5.0264 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 96/300 COMPLETE (43.7s)
Train Loss: 0.5716 (C:5.5889, R:0.0100, T:0.5706)
Val Loss:   5.0273 (C:4.4063, R:0.0099, T:5.0264)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 97 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5680 (C:5.5636, R:0.0099, T:0.5670(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5577 (C:5.5953, R:0.0099, T:0.5568(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5587 (C:5.5516, R:0.0099, T:0.5577(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5838 (C:5.5913, R:0.0100, T:0.5828(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5753 (C:5.5486, R:0.0100, T:0.5743(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5677 (C:5.5565, R:0.0100, T:0.5667(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5643 (C:5.6121, R:0.0100, T:0.5633(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5721 (C:5.5524, R:0.0100, T:0.5711(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5758 (C:5.5435, R:0.0100, T:0.5748(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5938 (C:5.6032, R:0.0100, T:0.5928(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5980 (C:5.5547, R:0.0099, T:0.5970(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5935 (C:5.6379, R:0.0100, T:0.5925(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5690 (C:5.5604, R:0.0099, T:0.5681(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5539 (C:5.5684, R:0.0100, T:0.5529(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5458 (C:5.6041, R:0.0100, T:0.5448(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5638 (C:5.6024, R:0.0100, T:0.5628(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.6027 (C:5.5450, R:0.0099, T:0.6017(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5747 (C:5.5715, R:0.0099, T:0.5737(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5600 (C:5.5897, R:0.0099, T:0.5590(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6103 (C:5.5403, R:0.0100, T:0.6093(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5386 (C:5.5850, R:0.0100, T:0.5376(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5657 (C:5.5665, R:0.0100, T:0.5647(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 97 TRAINING SUMMARY:
  Total Loss: 0.5724
  Contrastive: 5.5879
  Reconstruction: 0.0100
  Topological: 0.5715 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9758
  Contrastive: 4.4278
  Reconstruction: 0.0099
  Topological: 4.9748 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 97/300 COMPLETE (43.4s)
Train Loss: 0.5724 (C:5.5879, R:0.0100, T:0.5715)
Val Loss:   4.9758 (C:4.4278, R:0.0099, T:4.9748)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 98 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5747 (C:5.5721, R:0.0099, T:0.5737(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5561 (C:5.5743, R:0.0100, T:0.5551(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5653 (C:5.5818, R:0.0100, T:0.5643(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5638 (C:5.5905, R:0.0099, T:0.5628(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5257 (C:5.6253, R:0.0099, T:0.5247(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5527 (C:5.5634, R:0.0099, T:0.5517(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5624 (C:5.5959, R:0.0100, T:0.5614(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5736 (C:5.6186, R:0.0099, T:0.5726(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.6079 (C:5.5879, R:0.0099, T:0.6070(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5817 (C:5.5415, R:0.0100, T:0.5807(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5498 (C:5.5723, R:0.0100, T:0.5488(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5545 (C:5.5843, R:0.0099, T:0.5535(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5731 (C:5.4925, R:0.0099, T:0.5721(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5657 (C:5.6121, R:0.0099, T:0.5647(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5508 (C:5.6001, R:0.0099, T:0.5498(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5922 (C:5.6429, R:0.0100, T:0.5912(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5939 (C:5.5407, R:0.0100, T:0.5929(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5722 (C:5.6241, R:0.0099, T:0.5712(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5707 (C:5.5681, R:0.0100, T:0.5697(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5657 (C:5.6018, R:0.0099, T:0.5647(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5822 (C:5.6040, R:0.0100, T:0.5812(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5775 (C:5.5642, R:0.0099, T:0.5765(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5693

ğŸ“Š EPOCH 98 TRAINING SUMMARY:
  Total Loss: 0.5703
  Contrastive: 5.5885
  Reconstruction: 0.0100
  Topological: 0.5693 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0076
  Contrastive: 4.4150
  Reconstruction: 0.0099
  Topological: 5.0066 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 98/300 COMPLETE (43.6s)
Train Loss: 0.5703 (C:5.5885, R:0.0100, T:0.5693)
Val Loss:   5.0076 (C:4.4150, R:0.0099, T:5.0066)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 99 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5455 (C:5.5730, R:0.0100, T:0.5445(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6196 (C:5.5472, R:0.0100, T:0.6186(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5717 (C:5.5672, R:0.0099, T:0.5707(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5925 (C:5.5903, R:0.0099, T:0.5915(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5646 (C:5.6068, R:0.0100, T:0.5636(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5724 (C:5.5756, R:0.0100, T:0.5714(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.6062 (C:5.5837, R:0.0100, T:0.6052(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5460 (C:5.6343, R:0.0099, T:0.5450(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5607 (C:5.5499, R:0.0100, T:0.5597(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5508 (C:5.6219, R:0.0100, T:0.5498(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5500 (C:5.5783, R:0.0100, T:0.5490(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5603 (C:5.5905, R:0.0100, T:0.5593(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5519 (C:5.5503, R:0.0100, T:0.5509(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5831 (C:5.6220, R:0.0100, T:0.5821(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5941 (C:5.5656, R:0.0100, T:0.5931(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5747 (C:5.5622, R:0.0100, T:0.5737(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5889 (C:5.5917, R:0.0100, T:0.5879(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5392 (C:5.5718, R:0.0099, T:0.5382(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5750 (C:5.6351, R:0.0100, T:0.5740(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5637 (C:5.5866, R:0.0100, T:0.5627(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5929 (C:5.5677, R:0.0100, T:0.5919(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5980 (C:5.5435, R:0.0099, T:0.5970(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5683

ğŸ“Š EPOCH 99 TRAINING SUMMARY:
  Total Loss: 0.5693
  Contrastive: 5.5877
  Reconstruction: 0.0100
  Topological: 0.5683 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9762
  Contrastive: 4.4195
  Reconstruction: 0.0099
  Topological: 4.9753 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 99/300 COMPLETE (44.4s)
Train Loss: 0.5693 (C:5.5877, R:0.0100, T:0.5683)
Val Loss:   4.9762 (C:4.4195, R:0.0099, T:4.9753)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 100 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5391 (C:5.5727, R:0.0099, T:0.5381(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5888 (C:5.5950, R:0.0099, T:0.5878(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5648 (C:5.5840, R:0.0099, T:0.5638(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5372 (C:5.5889, R:0.0100, T:0.5362(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5341 (C:5.5975, R:0.0100, T:0.5331(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5826 (C:5.6340, R:0.0100, T:0.5816(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5458 (C:5.6184, R:0.0100, T:0.5448(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5693 (C:5.5959, R:0.0100, T:0.5683(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5795 (C:5.5710, R:0.0099, T:0.5785(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5532 (C:5.5500, R:0.0099, T:0.5522(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5698 (C:5.6052, R:0.0099, T:0.5689(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5853 (C:5.5870, R:0.0100, T:0.5843(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5268 (C:5.6011, R:0.0100, T:0.5258(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5597 (C:5.5694, R:0.0100, T:0.5587(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5793 (C:5.5864, R:0.0099, T:0.5783(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5507 (C:5.6270, R:0.0100, T:0.5497(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5789 (C:5.5686, R:0.0099, T:0.5779(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5585 (C:5.5827, R:0.0099, T:0.5575(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5801 (C:5.5679, R:0.0100, T:0.5791(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5454 (C:5.5976, R:0.0100, T:0.5444(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5424 (C:5.5895, R:0.0099, T:0.5414(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5900 (C:5.6253, R:0.0100, T:0.5890(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5679

ğŸ“Š EPOCH 100 TRAINING SUMMARY:
  Total Loss: 0.5689
  Contrastive: 5.5877
  Reconstruction: 0.0100
  Topological: 0.5679 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9750
  Contrastive: 4.4140
  Reconstruction: 0.0099
  Topological: 4.9740 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 100/300 COMPLETE (44.5s)
Train Loss: 0.5689 (C:5.5877, R:0.0100, T:0.5679)
Val Loss:   4.9750 (C:4.4140, R:0.0099, T:4.9740)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 101 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5597 (C:5.5862, R:0.0100, T:0.5587(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5974 (C:5.5596, R:0.0099, T:0.5964(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5480 (C:5.6093, R:0.0099, T:0.5470(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5727 (C:5.5973, R:0.0100, T:0.5717(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5417 (C:5.6090, R:0.0100, T:0.5407(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5672 (C:5.6178, R:0.0100, T:0.5662(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5665 (C:5.6475, R:0.0100, T:0.5655(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5640 (C:5.5611, R:0.0099, T:0.5630(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5817 (C:5.5871, R:0.0100, T:0.5807(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5605 (C:5.5592, R:0.0099, T:0.5595(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5863 (C:5.6082, R:0.0099, T:0.5853(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5717 (C:5.6298, R:0.0100, T:0.5707(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5790 (C:5.5388, R:0.0100, T:0.5780(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5884 (C:5.6298, R:0.0100, T:0.5874(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5598 (C:5.5777, R:0.0100, T:0.5588(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5402 (C:5.6013, R:0.0100, T:0.5392(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5561 (C:5.5320, R:0.0099, T:0.5552(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5622 (C:5.6172, R:0.0100, T:0.5612(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5759 (C:5.5944, R:0.0100, T:0.5749(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6181 (C:5.5598, R:0.0100, T:0.6171(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6461 (C:5.5823, R:0.0100, T:0.6451(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5664 (C:5.5722, R:0.0099, T:0.5654(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5677

ğŸ“Š EPOCH 101 TRAINING SUMMARY:
  Total Loss: 0.5687
  Contrastive: 5.5878
  Reconstruction: 0.0100
  Topological: 0.5677 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8352
  Contrastive: 4.4711
  Reconstruction: 0.0099
  Topological: 4.8342 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 101/300 COMPLETE (45.5s)
Train Loss: 0.5687 (C:5.5878, R:0.0100, T:0.5677)
Val Loss:   4.8352 (C:4.4711, R:0.0099, T:4.8342)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 102 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5814 (C:5.6353, R:0.0099, T:0.5804(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5656 (C:5.6046, R:0.0099, T:0.5646(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5478 (C:5.6025, R:0.0099, T:0.5468(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5608 (C:5.5465, R:0.0099, T:0.5598(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5906 (C:5.6211, R:0.0099, T:0.5897(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6030 (C:5.6133, R:0.0099, T:0.6020(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5824 (C:5.5684, R:0.0100, T:0.5814(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5800 (C:5.6231, R:0.0100, T:0.5790(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5710 (C:5.5506, R:0.0099, T:0.5700(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5692 (C:5.5355, R:0.0099, T:0.5682(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5506 (C:5.6034, R:0.0099, T:0.5496(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5923 (C:5.5715, R:0.0100, T:0.5913(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5458 (C:5.6067, R:0.0099, T:0.5448(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5751 (C:5.5989, R:0.0100, T:0.5741(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5836 (C:5.5779, R:0.0100, T:0.5826(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5610 (C:5.5797, R:0.0099, T:0.5600(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5858 (C:5.5811, R:0.0099, T:0.5848(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.6035 (C:5.5551, R:0.0099, T:0.6025(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5585 (C:5.5751, R:0.0100, T:0.5575(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5919 (C:5.5958, R:0.0100, T:0.5909(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5777 (C:5.6051, R:0.0100, T:0.5767(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5595 (C:5.5916, R:0.0099, T:0.5585(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 102 TRAINING SUMMARY:
  Total Loss: 0.5697
  Contrastive: 5.5891
  Reconstruction: 0.0100
  Topological: 0.5687 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0694
  Contrastive: 4.4124
  Reconstruction: 0.0099
  Topological: 5.0684 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 102/300 COMPLETE (46.6s)
Train Loss: 0.5697 (C:5.5891, R:0.0100, T:0.5687)
Val Loss:   5.0694 (C:4.4124, R:0.0099, T:5.0684)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 103 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5588 (C:5.5779, R:0.0100, T:0.5578(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5613 (C:5.5368, R:0.0100, T:0.5603(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5842 (C:5.5890, R:0.0099, T:0.5833(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5890 (C:5.5947, R:0.0100, T:0.5880(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5511 (C:5.5784, R:0.0100, T:0.5501(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5769 (C:5.5576, R:0.0100, T:0.5759(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5748 (C:5.6021, R:0.0099, T:0.5738(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5665 (C:5.6013, R:0.0099, T:0.5655(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5709 (C:5.6115, R:0.0099, T:0.5699(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5640 (C:5.6023, R:0.0100, T:0.5630(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5688 (C:5.5568, R:0.0099, T:0.5678(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5629 (C:5.5984, R:0.0100, T:0.5619(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5852 (C:5.5988, R:0.0100, T:0.5842(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5694 (C:5.6324, R:0.0100, T:0.5684(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5865 (C:5.5676, R:0.0100, T:0.5855(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5760 (C:5.6211, R:0.0100, T:0.5750(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5683 (C:5.5826, R:0.0100, T:0.5673(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5706 (C:5.5900, R:0.0100, T:0.5696(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5627 (C:5.6107, R:0.0099, T:0.5617(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5626 (C:5.5574, R:0.0099, T:0.5616(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5722 (C:5.5422, R:0.0100, T:0.5712(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5630 (C:5.5564, R:0.0099, T:0.5620(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5673

ğŸ“Š EPOCH 103 TRAINING SUMMARY:
  Total Loss: 0.5683
  Contrastive: 5.5885
  Reconstruction: 0.0100
  Topological: 0.5673 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9619
  Contrastive: 4.4252
  Reconstruction: 0.0099
  Topological: 4.9609 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 103/300 COMPLETE (45.9s)
Train Loss: 0.5683 (C:5.5885, R:0.0100, T:0.5673)
Val Loss:   4.9619 (C:4.4252, R:0.0099, T:4.9609)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 104 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5681 (C:5.5839, R:0.0099, T:0.5671(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5520 (C:5.5853, R:0.0100, T:0.5510(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5708 (C:5.5749, R:0.0099, T:0.5698(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5699 (C:5.5939, R:0.0100, T:0.5689(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5577 (C:5.5835, R:0.0099, T:0.5567(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5630 (C:5.5596, R:0.0099, T:0.5620(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5389 (C:5.6016, R:0.0099, T:0.5379(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5457 (C:5.5873, R:0.0100, T:0.5447(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5935 (C:5.5556, R:0.0100, T:0.5925(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5894 (C:5.5497, R:0.0099, T:0.5884(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5765 (C:5.5667, R:0.0100, T:0.5755(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5609 (C:5.5530, R:0.0100, T:0.5599(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5719 (C:5.5595, R:0.0100, T:0.5709(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5659 (C:5.5681, R:0.0099, T:0.5649(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5473 (C:5.5710, R:0.0100, T:0.5463(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5685 (C:5.6266, R:0.0100, T:0.5675(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5884 (C:5.5955, R:0.0100, T:0.5874(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5549 (C:5.5971, R:0.0100, T:0.5539(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5515 (C:5.6083, R:0.0099, T:0.5506(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5975 (C:5.5646, R:0.0099, T:0.5965(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6042 (C:5.5970, R:0.0099, T:0.6032(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5546 (C:5.5967, R:0.0100, T:0.5536(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5666

ğŸ“Š EPOCH 104 TRAINING SUMMARY:
  Total Loss: 0.5676
  Contrastive: 5.5888
  Reconstruction: 0.0100
  Topological: 0.5666 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0677
  Contrastive: 4.3980
  Reconstruction: 0.0099
  Topological: 5.0667 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 104/300 COMPLETE (46.5s)
Train Loss: 0.5676 (C:5.5888, R:0.0100, T:0.5666)
Val Loss:   5.0677 (C:4.3980, R:0.0099, T:5.0667)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 105 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5721 (C:5.5700, R:0.0100, T:0.5711(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.6380 (C:5.5988, R:0.0099, T:0.6370(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5772 (C:5.6083, R:0.0099, T:0.5762(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5755 (C:5.5962, R:0.0100, T:0.5745(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5711 (C:5.5524, R:0.0100, T:0.5701(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5795 (C:5.5619, R:0.0100, T:0.5785(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5810 (C:5.6120, R:0.0100, T:0.5800(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5866 (C:5.6303, R:0.0099, T:0.5856(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5789 (C:5.5857, R:0.0099, T:0.5779(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5601 (C:5.6320, R:0.0099, T:0.5591(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5761 (C:5.6117, R:0.0100, T:0.5751(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5517 (C:5.5914, R:0.0099, T:0.5507(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5636 (C:5.5838, R:0.0100, T:0.5626(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5760 (C:5.5570, R:0.0100, T:0.5750(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5693 (C:5.5664, R:0.0099, T:0.5683(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5700 (C:5.5865, R:0.0099, T:0.5690(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5406 (C:5.5639, R:0.0099, T:0.5396(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5583 (C:5.6597, R:0.0100, T:0.5573(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5801 (C:5.5364, R:0.0100, T:0.5791(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5666 (C:5.6064, R:0.0100, T:0.5656(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.6024 (C:5.5684, R:0.0100, T:0.6014(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5617 (C:5.6300, R:0.0099, T:0.5607(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5664

ğŸ“Š EPOCH 105 TRAINING SUMMARY:
  Total Loss: 0.5673
  Contrastive: 5.5890
  Reconstruction: 0.0100
  Topological: 0.5664 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9034
  Contrastive: 4.4261
  Reconstruction: 0.0099
  Topological: 4.9024 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 105/300 COMPLETE (48.7s)
Train Loss: 0.5673 (C:5.5890, R:0.0100, T:0.5664)
Val Loss:   4.9034 (C:4.4261, R:0.0099, T:4.9024)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 106 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5632 (C:5.5752, R:0.0099, T:0.5622(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5586 (C:5.5690, R:0.0099, T:0.5576(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5531 (C:5.5237, R:0.0100, T:0.5521(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5306 (C:5.6034, R:0.0099, T:0.5296(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5651 (C:5.5657, R:0.0099, T:0.5641(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5693 (C:5.6166, R:0.0099, T:0.5683(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5667 (C:5.5353, R:0.0099, T:0.5657(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5765 (C:5.5844, R:0.0100, T:0.5755(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5645 (C:5.6365, R:0.0099, T:0.5635(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6080 (C:5.5769, R:0.0100, T:0.6070(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5703 (C:5.5640, R:0.0099, T:0.5693(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5395 (C:5.6085, R:0.0100, T:0.5385(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5830 (C:5.6086, R:0.0099, T:0.5820(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5798 (C:5.5689, R:0.0099, T:0.5788(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5715 (C:5.5915, R:0.0099, T:0.5706(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5695 (C:5.5864, R:0.0100, T:0.5685(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5466 (C:5.6112, R:0.0100, T:0.5456(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5605 (C:5.6184, R:0.0100, T:0.5595(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5890 (C:5.5573, R:0.0099, T:0.5880(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5433 (C:5.6216, R:0.0099, T:0.5423(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5690 (C:5.5544, R:0.0099, T:0.5680(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5635 (C:5.5431, R:0.0100, T:0.5625(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5656

ğŸ“Š EPOCH 106 TRAINING SUMMARY:
  Total Loss: 0.5666
  Contrastive: 5.5900
  Reconstruction: 0.0100
  Topological: 0.5656 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0414
  Contrastive: 4.4167
  Reconstruction: 0.0099
  Topological: 5.0404 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 106/300 COMPLETE (51.1s)
Train Loss: 0.5666 (C:5.5900, R:0.0100, T:0.5656)
Val Loss:   5.0414 (C:4.4167, R:0.0099, T:5.0404)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 107 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5397 (C:5.5743, R:0.0099, T:0.5387(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5592 (C:5.5867, R:0.0100, T:0.5582(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5761 (C:5.5737, R:0.0100, T:0.5751(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5883 (C:5.6231, R:0.0099, T:0.5873(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5574 (C:5.6021, R:0.0099, T:0.5564(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5683 (C:5.5668, R:0.0099, T:0.5673(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5412 (C:5.5744, R:0.0099, T:0.5402(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5720 (C:5.5804, R:0.0100, T:0.5710(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5714 (C:5.6197, R:0.0099, T:0.5704(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5645 (C:5.6019, R:0.0100, T:0.5635(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5841 (C:5.5777, R:0.0100, T:0.5831(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5658 (C:5.5677, R:0.0100, T:0.5648(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5582 (C:5.5795, R:0.0100, T:0.5572(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5516 (C:5.5507, R:0.0100, T:0.5506(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5821 (C:5.5998, R:0.0099, T:0.5811(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5603 (C:5.5645, R:0.0100, T:0.5593(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5736 (C:5.5617, R:0.0099, T:0.5726(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5542 (C:5.6432, R:0.0099, T:0.5532(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5823 (C:5.5603, R:0.0099, T:0.5813(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5402 (C:5.5993, R:0.0100, T:0.5392(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5971 (C:5.6048, R:0.0100, T:0.5962(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5393 (C:5.6384, R:0.0099, T:0.5383(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 107 TRAINING SUMMARY:
  Total Loss: 0.5679
  Contrastive: 5.5893
  Reconstruction: 0.0100
  Topological: 0.5669 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9577
  Contrastive: 4.4100
  Reconstruction: 0.0099
  Topological: 4.9567 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 107/300 COMPLETE (51.0s)
Train Loss: 0.5679 (C:5.5893, R:0.0100, T:0.5669)
Val Loss:   4.9577 (C:4.4100, R:0.0099, T:4.9567)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 108 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5408 (C:5.6019, R:0.0100, T:0.5398(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5571 (C:5.5729, R:0.0099, T:0.5561(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5744 (C:5.5955, R:0.0099, T:0.5734(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5640 (C:5.5613, R:0.0100, T:0.5631(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5782 (C:5.6093, R:0.0099, T:0.5772(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5522 (C:5.5865, R:0.0100, T:0.5512(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5771 (C:5.5968, R:0.0100, T:0.5761(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5712 (C:5.5588, R:0.0100, T:0.5702(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5690 (C:5.6359, R:0.0099, T:0.5680(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5527 (C:5.5829, R:0.0100, T:0.5517(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5609 (C:5.6190, R:0.0099, T:0.5599(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5638 (C:5.6132, R:0.0100, T:0.5628(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5485 (C:5.6050, R:0.0100, T:0.5475(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5562 (C:5.5516, R:0.0099, T:0.5552(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5655 (C:5.5807, R:0.0099, T:0.5645(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5666 (C:5.6349, R:0.0100, T:0.5656(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5970 (C:5.5858, R:0.0099, T:0.5961(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5941 (C:5.5515, R:0.0099, T:0.5931(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5816 (C:5.6490, R:0.0100, T:0.5806(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5727 (C:5.6165, R:0.0100, T:0.5717(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5609 (C:5.5740, R:0.0099, T:0.5599(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5842 (C:5.6109, R:0.0100, T:0.5832(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5651

ğŸ“Š EPOCH 108 TRAINING SUMMARY:
  Total Loss: 0.5661
  Contrastive: 5.5907
  Reconstruction: 0.0100
  Topological: 0.5651 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9826
  Contrastive: 4.4131
  Reconstruction: 0.0099
  Topological: 4.9816 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 108/300 COMPLETE (50.0s)
Train Loss: 0.5661 (C:5.5907, R:0.0100, T:0.5651)
Val Loss:   4.9826 (C:4.4131, R:0.0099, T:4.9816)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 109 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5864 (C:5.5597, R:0.0100, T:0.5854(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5824 (C:5.5878, R:0.0099, T:0.5815(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5740 (C:5.5781, R:0.0100, T:0.5730(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5562 (C:5.5925, R:0.0100, T:0.5552(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5911 (C:5.6018, R:0.0100, T:0.5901(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5854 (C:5.6285, R:0.0100, T:0.5844(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5656 (C:5.5919, R:0.0099, T:0.5646(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5575 (C:5.6047, R:0.0100, T:0.5565(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5605 (C:5.5731, R:0.0100, T:0.5595(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5762 (C:5.6485, R:0.0100, T:0.5752(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5428 (C:5.5885, R:0.0100, T:0.5418(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5681 (C:5.6102, R:0.0099, T:0.5671(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5706 (C:5.6133, R:0.0100, T:0.5697(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5792 (C:5.5650, R:0.0100, T:0.5782(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5713 (C:5.6073, R:0.0100, T:0.5703(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5346 (C:5.5938, R:0.0100, T:0.5336(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5749 (C:5.6112, R:0.0099, T:0.5739(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5513 (C:5.5752, R:0.0100, T:0.5503(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5571 (C:5.5825, R:0.0100, T:0.5561(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5576 (C:5.5646, R:0.0099, T:0.5566(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5790 (C:5.5807, R:0.0099, T:0.5780(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.6186 (C:5.6111, R:0.0099, T:0.6176(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 109 TRAINING SUMMARY:
  Total Loss: 0.5667
  Contrastive: 5.5895
  Reconstruction: 0.0100
  Topological: 0.5657 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0430
  Contrastive: 4.4249
  Reconstruction: 0.0099
  Topological: 5.0420 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 109/300 COMPLETE (46.1s)
Train Loss: 0.5667 (C:5.5895, R:0.0100, T:0.5657)
Val Loss:   5.0430 (C:4.4249, R:0.0099, T:5.0420)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 110 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5787 (C:5.5991, R:0.0099, T:0.5777(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5840 (C:5.5704, R:0.0099, T:0.5831(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5519 (C:5.5731, R:0.0099, T:0.5509(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5669 (C:5.5946, R:0.0100, T:0.5659(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5741 (C:5.6081, R:0.0100, T:0.5731(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5496 (C:5.5717, R:0.0099, T:0.5486(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5601 (C:5.5802, R:0.0099, T:0.5591(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5726 (C:5.6091, R:0.0099, T:0.5716(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5586 (C:5.5679, R:0.0099, T:0.5576(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5609 (C:5.5481, R:0.0099, T:0.5599(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5725 (C:5.5568, R:0.0099, T:0.5715(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5729 (C:5.5746, R:0.0100, T:0.5719(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5781 (C:5.5924, R:0.0099, T:0.5771(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5734 (C:5.5629, R:0.0099, T:0.5724(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5592 (C:5.5953, R:0.0100, T:0.5583(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5714 (C:5.6253, R:0.0099, T:0.5704(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5618 (C:5.6106, R:0.0100, T:0.5608(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5809 (C:5.6167, R:0.0099, T:0.5799(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5537 (C:5.6197, R:0.0100, T:0.5527(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5806 (C:5.6132, R:0.0100, T:0.5796(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5504 (C:5.5741, R:0.0099, T:0.5494(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5606 (C:5.5674, R:0.0100, T:0.5596(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 110 TRAINING SUMMARY:
  Total Loss: 0.5675
  Contrastive: 5.5902
  Reconstruction: 0.0100
  Topological: 0.5665 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.1435
  Contrastive: 4.3893
  Reconstruction: 0.0099
  Topological: 5.1425 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 110/300 COMPLETE (43.7s)
Train Loss: 0.5675 (C:5.5902, R:0.0100, T:0.5665)
Val Loss:   5.1435 (C:4.3893, R:0.0099, T:5.1425)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 111 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5397 (C:5.5348, R:0.0099, T:0.5387(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5585 (C:5.6217, R:0.0099, T:0.5575(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5788 (C:5.5636, R:0.0100, T:0.5778(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5565 (C:5.6031, R:0.0100, T:0.5555(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5801 (C:5.5768, R:0.0100, T:0.5791(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5661 (C:5.5837, R:0.0099, T:0.5651(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5621 (C:5.5920, R:0.0100, T:0.5611(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5503 (C:5.5901, R:0.0100, T:0.5493(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5540 (C:5.6136, R:0.0100, T:0.5530(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5623 (C:5.5770, R:0.0100, T:0.5613(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5610 (C:5.6152, R:0.0100, T:0.5600(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5520 (C:5.5807, R:0.0099, T:0.5510(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5508 (C:5.6039, R:0.0100, T:0.5498(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5779 (C:5.5632, R:0.0100, T:0.5769(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5965 (C:5.5665, R:0.0100, T:0.5955(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5361 (C:5.5393, R:0.0100, T:0.5351(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5677 (C:5.6473, R:0.0099, T:0.5667(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5623 (C:5.5725, R:0.0099, T:0.5613(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5828 (C:5.6480, R:0.0099, T:0.5818(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5470 (C:5.5070, R:0.0099, T:0.5461(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5583 (C:5.6146, R:0.0100, T:0.5573(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5845 (C:5.6077, R:0.0099, T:0.5835(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5636

ğŸ“Š EPOCH 111 TRAINING SUMMARY:
  Total Loss: 0.5646
  Contrastive: 5.5902
  Reconstruction: 0.0100
  Topological: 0.5636 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8723
  Contrastive: 4.4350
  Reconstruction: 0.0099
  Topological: 4.8713 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 111/300 COMPLETE (43.4s)
Train Loss: 0.5646 (C:5.5902, R:0.0100, T:0.5636)
Val Loss:   4.8723 (C:4.4350, R:0.0099, T:4.8713)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 112 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5609 (C:5.5904, R:0.0099, T:0.5599(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5678 (C:5.5253, R:0.0100, T:0.5668(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5828 (C:5.5338, R:0.0100, T:0.5818(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5808 (C:5.5630, R:0.0100, T:0.5798(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5854 (C:5.6276, R:0.0099, T:0.5844(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5333 (C:5.6117, R:0.0100, T:0.5323(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5605 (C:5.5736, R:0.0099, T:0.5595(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5839 (C:5.6092, R:0.0099, T:0.5829(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5785 (C:5.5916, R:0.0100, T:0.5775(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5310 (C:5.5682, R:0.0099, T:0.5300(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5584 (C:5.6370, R:0.0100, T:0.5574(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5820 (C:5.5935, R:0.0099, T:0.5810(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5445 (C:5.6296, R:0.0100, T:0.5435(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5747 (C:5.5784, R:0.0100, T:0.5737(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5721 (C:5.5790, R:0.0100, T:0.5711(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5189 (C:5.6023, R:0.0100, T:0.5179(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5844 (C:5.5716, R:0.0099, T:0.5835(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5488 (C:5.5677, R:0.0099, T:0.5478(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6168 (C:5.5998, R:0.0099, T:0.6158(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5511 (C:5.5738, R:0.0100, T:0.5501(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5984 (C:5.5819, R:0.0099, T:0.5974(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5715 (C:5.6059, R:0.0100, T:0.5705(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5620

ğŸ“Š EPOCH 112 TRAINING SUMMARY:
  Total Loss: 0.5630
  Contrastive: 5.5938
  Reconstruction: 0.0100
  Topological: 0.5620 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.1087
  Contrastive: 4.4129
  Reconstruction: 0.0099
  Topological: 5.1078 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 112/300 COMPLETE (43.9s)
Train Loss: 0.5630 (C:5.5938, R:0.0100, T:0.5620)
Val Loss:   5.1087 (C:4.4129, R:0.0099, T:5.1078)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 113 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5746 (C:5.5656, R:0.0100, T:0.5736(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5500 (C:5.6092, R:0.0099, T:0.5490(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5829 (C:5.6224, R:0.0100, T:0.5819(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5966 (C:5.5784, R:0.0100, T:0.5956(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5784 (C:5.5553, R:0.0099, T:0.5774(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5616 (C:5.5957, R:0.0100, T:0.5606(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5395 (C:5.5528, R:0.0099, T:0.5385(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5690 (C:5.5900, R:0.0099, T:0.5680(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5609 (C:5.5690, R:0.0099, T:0.5599(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6040 (C:5.6622, R:0.0099, T:0.6030(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5760 (C:5.5858, R:0.0099, T:0.5750(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5529 (C:5.5923, R:0.0100, T:0.5519(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5602 (C:5.5779, R:0.0100, T:0.5592(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5610 (C:5.6179, R:0.0100, T:0.5600(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5863 (C:5.5936, R:0.0100, T:0.5853(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5554 (C:5.5474, R:0.0099, T:0.5544(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5626 (C:5.5854, R:0.0099, T:0.5616(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5944 (C:5.5778, R:0.0100, T:0.5934(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5565 (C:5.6079, R:0.0100, T:0.5555(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5504 (C:5.5697, R:0.0099, T:0.5494(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5756 (C:5.5736, R:0.0100, T:0.5747(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5759 (C:5.5823, R:0.0099, T:0.5749(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 113 TRAINING SUMMARY:
  Total Loss: 0.5652
  Contrastive: 5.5900
  Reconstruction: 0.0100
  Topological: 0.5642 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9922
  Contrastive: 4.4187
  Reconstruction: 0.0099
  Topological: 4.9912 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 113/300 COMPLETE (43.5s)
Train Loss: 0.5652 (C:5.5900, R:0.0100, T:0.5642)
Val Loss:   4.9922 (C:4.4187, R:0.0099, T:4.9912)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 114 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5655 (C:5.5777, R:0.0099, T:0.5645(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5463 (C:5.6173, R:0.0100, T:0.5453(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5355 (C:5.6180, R:0.0100, T:0.5345(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5658 (C:5.5984, R:0.0099, T:0.5648(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5778 (C:5.5653, R:0.0100, T:0.5768(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5804 (C:5.6172, R:0.0100, T:0.5794(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5727 (C:5.6681, R:0.0100, T:0.5717(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5622 (C:5.5717, R:0.0099, T:0.5612(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5768 (C:5.6078, R:0.0100, T:0.5758(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5573 (C:5.5890, R:0.0100, T:0.5563(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5575 (C:5.6246, R:0.0100, T:0.5565(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5764 (C:5.5295, R:0.0099, T:0.5754(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5454 (C:5.6093, R:0.0099, T:0.5444(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5527 (C:5.5276, R:0.0099, T:0.5517(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5880 (C:5.5947, R:0.0100, T:0.5870(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5511 (C:5.5785, R:0.0100, T:0.5501(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5662 (C:5.5951, R:0.0100, T:0.5652(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5647 (C:5.6369, R:0.0100, T:0.5637(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5584 (C:5.6248, R:0.0100, T:0.5574(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5560 (C:5.6071, R:0.0100, T:0.5550(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5536 (C:5.6160, R:0.0100, T:0.5526(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5784 (C:5.6151, R:0.0100, T:0.5774(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 114 TRAINING SUMMARY:
  Total Loss: 0.5664
  Contrastive: 5.5912
  Reconstruction: 0.0100
  Topological: 0.5654 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0080
  Contrastive: 4.3929
  Reconstruction: 0.0099
  Topological: 5.0070 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 114/300 COMPLETE (43.3s)
Train Loss: 0.5664 (C:5.5912, R:0.0100, T:0.5654)
Val Loss:   5.0080 (C:4.3929, R:0.0099, T:5.0070)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 115 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5117 (C:5.5598, R:0.0099, T:0.5107(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5590 (C:5.6088, R:0.0099, T:0.5580(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5588 (C:5.6144, R:0.0099, T:0.5578(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5616 (C:5.5883, R:0.0099, T:0.5606(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5234 (C:5.6224, R:0.0100, T:0.5224(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5772 (C:5.6271, R:0.0100, T:0.5762(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5503 (C:5.5458, R:0.0099, T:0.5493(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5681 (C:5.6175, R:0.0099, T:0.5671(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5786 (C:5.5619, R:0.0100, T:0.5776(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5747 (C:5.5648, R:0.0099, T:0.5737(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5551 (C:5.5986, R:0.0100, T:0.5541(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5726 (C:5.5557, R:0.0099, T:0.5716(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5932 (C:5.6165, R:0.0099, T:0.5922(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5275 (C:5.5681, R:0.0100, T:0.5265(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5880 (C:5.5574, R:0.0100, T:0.5870(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5863 (C:5.5886, R:0.0100, T:0.5853(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5693 (C:5.5516, R:0.0099, T:0.5683(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5471 (C:5.5890, R:0.0099, T:0.5461(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5669 (C:5.5571, R:0.0099, T:0.5659(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5609 (C:5.5881, R:0.0100, T:0.5599(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5666 (C:5.5813, R:0.0100, T:0.5656(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5683 (C:5.6252, R:0.0100, T:0.5673(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 115 TRAINING SUMMARY:
  Total Loss: 0.5655
  Contrastive: 5.5906
  Reconstruction: 0.0100
  Topological: 0.5645 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9000
  Contrastive: 4.4341
  Reconstruction: 0.0099
  Topological: 4.8990 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 115/300 COMPLETE (43.9s)
Train Loss: 0.5655 (C:5.5906, R:0.0100, T:0.5645)
Val Loss:   4.9000 (C:4.4341, R:0.0099, T:4.8990)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 116 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5551 (C:5.5963, R:0.0099, T:0.5541(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5613 (C:5.5383, R:0.0099, T:0.5603(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5571 (C:5.6141, R:0.0100, T:0.5561(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5451 (C:5.5719, R:0.0100, T:0.5441(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5474 (C:5.5392, R:0.0099, T:0.5465(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5520 (C:5.5975, R:0.0099, T:0.5510(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5707 (C:5.5813, R:0.0099, T:0.5697(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5789 (C:5.5586, R:0.0099, T:0.5779(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5585 (C:5.5745, R:0.0099, T:0.5575(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5933 (C:5.6169, R:0.0100, T:0.5923(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5658 (C:5.5552, R:0.0099, T:0.5648(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5446 (C:5.6046, R:0.0099, T:0.5436(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5685 (C:5.5155, R:0.0100, T:0.5675(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5560 (C:5.5937, R:0.0100, T:0.5550(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5696 (C:5.5759, R:0.0099, T:0.5686(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5796 (C:5.6161, R:0.0099, T:0.5786(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5789 (C:5.5247, R:0.0099, T:0.5779(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5941 (C:5.6569, R:0.0099, T:0.5931(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5835 (C:5.5740, R:0.0100, T:0.5825(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5891 (C:5.5827, R:0.0100, T:0.5881(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5510 (C:5.5561, R:0.0100, T:0.5500(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5658 (C:5.6254, R:0.0100, T:0.5648(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 116 TRAINING SUMMARY:
  Total Loss: 0.5641
  Contrastive: 5.5899
  Reconstruction: 0.0100
  Topological: 0.5631 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8286
  Contrastive: 4.4599
  Reconstruction: 0.0099
  Topological: 4.8276 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 116/300 COMPLETE (43.6s)
Train Loss: 0.5641 (C:5.5899, R:0.0100, T:0.5631)
Val Loss:   4.8286 (C:4.4599, R:0.0099, T:4.8276)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 117 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5464 (C:5.6105, R:0.0099, T:0.5454(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5552 (C:5.6113, R:0.0100, T:0.5542(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6005 (C:5.6174, R:0.0099, T:0.5995(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5387 (C:5.6069, R:0.0099, T:0.5377(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5876 (C:5.5959, R:0.0099, T:0.5866(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6091 (C:5.6402, R:0.0099, T:0.6081(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5576 (C:5.5652, R:0.0100, T:0.5566(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5723 (C:5.6040, R:0.0100, T:0.5714(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5561 (C:5.5870, R:0.0099, T:0.5551(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5454 (C:5.6097, R:0.0099, T:0.5444(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5931 (C:5.6244, R:0.0099, T:0.5921(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5832 (C:5.5523, R:0.0100, T:0.5822(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5735 (C:5.5854, R:0.0099, T:0.5725(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5555 (C:5.6232, R:0.0099, T:0.5545(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5549 (C:5.5516, R:0.0099, T:0.5539(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5563 (C:5.5704, R:0.0099, T:0.5553(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5756 (C:5.6100, R:0.0100, T:0.5746(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5591 (C:5.5925, R:0.0099, T:0.5581(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5601 (C:5.5481, R:0.0100, T:0.5591(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5815 (C:5.6116, R:0.0100, T:0.5805(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5619 (C:5.6219, R:0.0099, T:0.5610(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5451 (C:5.5854, R:0.0099, T:0.5441(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5620

ğŸ“Š EPOCH 117 TRAINING SUMMARY:
  Total Loss: 0.5630
  Contrastive: 5.5909
  Reconstruction: 0.0100
  Topological: 0.5620 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8984
  Contrastive: 4.4400
  Reconstruction: 0.0099
  Topological: 4.8974 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 117/300 COMPLETE (43.5s)
Train Loss: 0.5630 (C:5.5909, R:0.0100, T:0.5620)
Val Loss:   4.8984 (C:4.4400, R:0.0099, T:4.8974)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 118 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5393 (C:5.6099, R:0.0100, T:0.5383(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5889 (C:5.5904, R:0.0099, T:0.5879(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5431 (C:5.5448, R:0.0099, T:0.5421(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5406 (C:5.6142, R:0.0099, T:0.5397(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5749 (C:5.6136, R:0.0100, T:0.5739(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5662 (C:5.6227, R:0.0100, T:0.5652(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5752 (C:5.5794, R:0.0100, T:0.5742(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5795 (C:5.5595, R:0.0099, T:0.5785(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5442 (C:5.5953, R:0.0099, T:0.5432(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.6136 (C:5.5697, R:0.0100, T:0.6126(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5587 (C:5.5517, R:0.0099, T:0.5578(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5995 (C:5.5756, R:0.0100, T:0.5985(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5716 (C:5.5932, R:0.0099, T:0.5706(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5467 (C:5.5584, R:0.0099, T:0.5457(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5677 (C:5.6320, R:0.0100, T:0.5667(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5699 (C:5.6242, R:0.0100, T:0.5689(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5874 (C:5.6206, R:0.0100, T:0.5864(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5659 (C:5.6102, R:0.0100, T:0.5649(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5936 (C:5.6382, R:0.0100, T:0.5926(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5894 (C:5.6309, R:0.0099, T:0.5884(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5721 (C:5.5977, R:0.0099, T:0.5711(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5521 (C:5.5529, R:0.0099, T:0.5511(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 118 TRAINING SUMMARY:
  Total Loss: 0.5637
  Contrastive: 5.5885
  Reconstruction: 0.0100
  Topological: 0.5627 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9957
  Contrastive: 4.4251
  Reconstruction: 0.0099
  Topological: 4.9947 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 118/300 COMPLETE (43.6s)
Train Loss: 0.5637 (C:5.5885, R:0.0100, T:0.5627)
Val Loss:   4.9957 (C:4.4251, R:0.0099, T:4.9947)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 119 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5568 (C:5.5583, R:0.0099, T:0.5559(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5757 (C:5.6175, R:0.0100, T:0.5747(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5890 (C:5.6211, R:0.0099, T:0.5880(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5820 (C:5.5969, R:0.0099, T:0.5810(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5536 (C:5.5863, R:0.0099, T:0.5526(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5656 (C:5.5629, R:0.0100, T:0.5646(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5420 (C:5.5922, R:0.0100, T:0.5410(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5813 (C:5.6239, R:0.0100, T:0.5803(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5864 (C:5.5828, R:0.0099, T:0.5854(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5681 (C:5.5137, R:0.0099, T:0.5671(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5539 (C:5.5883, R:0.0099, T:0.5529(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5756 (C:5.6233, R:0.0099, T:0.5746(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5718 (C:5.5546, R:0.0099, T:0.5708(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5580 (C:5.6276, R:0.0100, T:0.5570(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5553 (C:5.5896, R:0.0100, T:0.5543(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5820 (C:5.6033, R:0.0100, T:0.5810(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5516 (C:5.6138, R:0.0099, T:0.5507(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5564 (C:5.5794, R:0.0100, T:0.5554(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5601 (C:5.5731, R:0.0099, T:0.5591(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5674 (C:5.5417, R:0.0100, T:0.5664(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5680 (C:5.5370, R:0.0099, T:0.5670(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5288 (C:5.5897, R:0.0099, T:0.5278(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 119 TRAINING SUMMARY:
  Total Loss: 0.5644
  Contrastive: 5.5896
  Reconstruction: 0.0100
  Topological: 0.5634 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9149
  Contrastive: 4.4369
  Reconstruction: 0.0099
  Topological: 4.9139 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 119/300 COMPLETE (43.9s)
Train Loss: 0.5644 (C:5.5896, R:0.0100, T:0.5634)
Val Loss:   4.9149 (C:4.4369, R:0.0099, T:4.9139)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 120 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5747 (C:5.5930, R:0.0100, T:0.5737(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5697 (C:5.6479, R:0.0100, T:0.5687(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5527 (C:5.5644, R:0.0099, T:0.5517(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.6024 (C:5.5801, R:0.0099, T:0.6014(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5376 (C:5.5606, R:0.0100, T:0.5366(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5564 (C:5.6161, R:0.0100, T:0.5554(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5478 (C:5.5780, R:0.0099, T:0.5468(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5602 (C:5.5907, R:0.0099, T:0.5592(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5539 (C:5.6174, R:0.0100, T:0.5529(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5596 (C:5.5652, R:0.0100, T:0.5586(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5365 (C:5.6009, R:0.0099, T:0.5355(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5737 (C:5.5707, R:0.0100, T:0.5727(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5756 (C:5.5910, R:0.0100, T:0.5746(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5665 (C:5.5893, R:0.0100, T:0.5655(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5795 (C:5.6164, R:0.0100, T:0.5785(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5872 (C:5.6357, R:0.0099, T:0.5862(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5707 (C:5.6207, R:0.0100, T:0.5697(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5564 (C:5.6271, R:0.0100, T:0.5554(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5269 (C:5.5477, R:0.0099, T:0.5260(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5620 (C:5.6290, R:0.0099, T:0.5610(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5703 (C:5.5625, R:0.0099, T:0.5693(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5665 (C:5.5816, R:0.0100, T:0.5655(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5611

ğŸ“Š EPOCH 120 TRAINING SUMMARY:
  Total Loss: 0.5621
  Contrastive: 5.5902
  Reconstruction: 0.0100
  Topological: 0.5611 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8839
  Contrastive: 4.4425
  Reconstruction: 0.0099
  Topological: 4.8829 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 120/300 COMPLETE (43.9s)
Train Loss: 0.5621 (C:5.5902, R:0.0100, T:0.5611)
Val Loss:   4.8839 (C:4.4425, R:0.0099, T:4.8829)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 121 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5758 (C:5.5852, R:0.0099, T:0.5748(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5559 (C:5.5720, R:0.0100, T:0.5549(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5679 (C:5.6345, R:0.0100, T:0.5669(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5570 (C:5.6105, R:0.0100, T:0.5561(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5308 (C:5.5833, R:0.0099, T:0.5298(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5624 (C:5.5935, R:0.0100, T:0.5614(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5618 (C:5.6203, R:0.0100, T:0.5608(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5836 (C:5.5710, R:0.0100, T:0.5826(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5682 (C:5.5670, R:0.0100, T:0.5672(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5611 (C:5.5709, R:0.0099, T:0.5601(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5461 (C:5.5900, R:0.0100, T:0.5451(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5885 (C:5.5834, R:0.0100, T:0.5875(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5793 (C:5.5617, R:0.0099, T:0.5783(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5493 (C:5.6208, R:0.0100, T:0.5483(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5664 (C:5.6206, R:0.0100, T:0.5654(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5295 (C:5.5937, R:0.0099, T:0.5285(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5574 (C:5.6193, R:0.0099, T:0.5564(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5511 (C:5.6083, R:0.0100, T:0.5501(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5788 (C:5.5673, R:0.0099, T:0.5778(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5735 (C:5.6291, R:0.0100, T:0.5725(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5578 (C:5.5574, R:0.0100, T:0.5568(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5407 (C:5.5982, R:0.0099, T:0.5397(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5605

ğŸ“Š EPOCH 121 TRAINING SUMMARY:
  Total Loss: 0.5615
  Contrastive: 5.5900
  Reconstruction: 0.0100
  Topological: 0.5605 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9495
  Contrastive: 4.4066
  Reconstruction: 0.0099
  Topological: 4.9485 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 121/300 COMPLETE (43.6s)
Train Loss: 0.5615 (C:5.5900, R:0.0100, T:0.5605)
Val Loss:   4.9495 (C:4.4066, R:0.0099, T:4.9485)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 122 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5648 (C:5.5448, R:0.0100, T:0.5638(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5406 (C:5.6331, R:0.0100, T:0.5396(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.6022 (C:5.5898, R:0.0099, T:0.6012(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5766 (C:5.5385, R:0.0100, T:0.5756(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5643 (C:5.6290, R:0.0099, T:0.5633(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5549 (C:5.5780, R:0.0099, T:0.5539(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5983 (C:5.5961, R:0.0100, T:0.5973(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5507 (C:5.5710, R:0.0099, T:0.5497(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5871 (C:5.6108, R:0.0100, T:0.5861(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5755 (C:5.5524, R:0.0099, T:0.5745(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5603 (C:5.6093, R:0.0100, T:0.5593(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5923 (C:5.5684, R:0.0099, T:0.5914(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5263 (C:5.6517, R:0.0099, T:0.5254(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5463 (C:5.5674, R:0.0099, T:0.5453(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5570 (C:5.5946, R:0.0100, T:0.5560(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5578 (C:5.5999, R:0.0100, T:0.5568(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5776 (C:5.5884, R:0.0100, T:0.5766(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5666 (C:5.5945, R:0.0100, T:0.5656(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5747 (C:5.6029, R:0.0099, T:0.5737(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5759 (C:5.5622, R:0.0100, T:0.5749(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5878 (C:5.6160, R:0.0100, T:0.5868(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5700 (C:5.5946, R:0.0100, T:0.5690(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 122 TRAINING SUMMARY:
  Total Loss: 0.5625
  Contrastive: 5.5902
  Reconstruction: 0.0100
  Topological: 0.5616 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9255
  Contrastive: 4.4410
  Reconstruction: 0.0099
  Topological: 4.9245 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 122/300 COMPLETE (44.2s)
Train Loss: 0.5625 (C:5.5902, R:0.0100, T:0.5616)
Val Loss:   4.9255 (C:4.4410, R:0.0099, T:4.9245)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 123 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5979 (C:5.6199, R:0.0100, T:0.5969(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5918 (C:5.6400, R:0.0100, T:0.5908(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5574 (C:5.5431, R:0.0099, T:0.5564(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5355 (C:5.6316, R:0.0100, T:0.5345(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5478 (C:5.6186, R:0.0099, T:0.5469(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.6154 (C:5.5570, R:0.0100, T:0.6144(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5425 (C:5.5996, R:0.0100, T:0.5416(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5784 (C:5.5555, R:0.0100, T:0.5774(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5388 (C:5.5799, R:0.0099, T:0.5379(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5498 (C:5.5888, R:0.0100, T:0.5488(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5530 (C:5.5770, R:0.0100, T:0.5520(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5539 (C:5.6025, R:0.0100, T:0.5529(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5821 (C:5.6225, R:0.0100, T:0.5812(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5546 (C:5.5721, R:0.0100, T:0.5536(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5689 (C:5.6122, R:0.0100, T:0.5679(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5689 (C:5.5754, R:0.0099, T:0.5679(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5668 (C:5.6369, R:0.0100, T:0.5658(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5576 (C:5.5559, R:0.0100, T:0.5566(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5493 (C:5.5820, R:0.0100, T:0.5483(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5569 (C:5.5612, R:0.0099, T:0.5559(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5526 (C:5.5612, R:0.0099, T:0.5516(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5672 (C:5.5859, R:0.0100, T:0.5662(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 123 TRAINING SUMMARY:
  Total Loss: 0.5622
  Contrastive: 5.5900
  Reconstruction: 0.0100
  Topological: 0.5612 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8633
  Contrastive: 4.4454
  Reconstruction: 0.0099
  Topological: 4.8623 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 123/300 COMPLETE (43.9s)
Train Loss: 0.5622 (C:5.5900, R:0.0100, T:0.5612)
Val Loss:   4.8633 (C:4.4454, R:0.0099, T:4.8623)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 124 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5387 (C:5.6020, R:0.0100, T:0.5377(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5381 (C:5.5448, R:0.0099, T:0.5371(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5577 (C:5.5785, R:0.0099, T:0.5567(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5569 (C:5.5559, R:0.0099, T:0.5559(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5527 (C:5.5833, R:0.0099, T:0.5517(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5813 (C:5.6139, R:0.0100, T:0.5803(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5773 (C:5.5987, R:0.0100, T:0.5763(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5681 (C:5.5947, R:0.0099, T:0.5671(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5538 (C:5.5523, R:0.0100, T:0.5528(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5537 (C:5.6065, R:0.0099, T:0.5527(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5432 (C:5.5917, R:0.0099, T:0.5422(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5417 (C:5.5461, R:0.0100, T:0.5407(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5328 (C:5.5574, R:0.0100, T:0.5318(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5278 (C:5.5954, R:0.0099, T:0.5268(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5926 (C:5.5902, R:0.0099, T:0.5916(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5359 (C:5.5925, R:0.0099, T:0.5349(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5668 (C:5.5702, R:0.0099, T:0.5658(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5863 (C:5.5834, R:0.0100, T:0.5853(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5655 (C:5.5769, R:0.0100, T:0.5645(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5581 (C:5.5853, R:0.0100, T:0.5571(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5654 (C:5.5784, R:0.0099, T:0.5644(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5335 (C:5.6371, R:0.0100, T:0.5325(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 124 TRAINING SUMMARY:
  Total Loss: 0.5616
  Contrastive: 5.5907
  Reconstruction: 0.0100
  Topological: 0.5606 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.7726
  Contrastive: 4.4711
  Reconstruction: 0.0099
  Topological: 4.7716 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 124/300 COMPLETE (44.0s)
Train Loss: 0.5616 (C:5.5907, R:0.0100, T:0.5606)
Val Loss:   4.7726 (C:4.4711, R:0.0099, T:4.7716)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 125 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5685 (C:5.6315, R:0.0100, T:0.5675(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5472 (C:5.5923, R:0.0100, T:0.5462(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5418 (C:5.5826, R:0.0100, T:0.5408(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5540 (C:5.6071, R:0.0100, T:0.5530(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5495 (C:5.6173, R:0.0099, T:0.5485(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5682 (C:5.6274, R:0.0100, T:0.5672(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5790 (C:5.5400, R:0.0099, T:0.5780(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5298 (C:5.5980, R:0.0099, T:0.5288(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5417 (C:5.6211, R:0.0099, T:0.5407(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5901 (C:5.6281, R:0.0100, T:0.5891(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5815 (C:5.6083, R:0.0100, T:0.5805(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5830 (C:5.5825, R:0.0100, T:0.5820(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5847 (C:5.5885, R:0.0100, T:0.5838(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5898 (C:5.5276, R:0.0099, T:0.5888(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5391 (C:5.6036, R:0.0099, T:0.5381(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5744 (C:5.5662, R:0.0100, T:0.5734(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5392 (C:5.6060, R:0.0100, T:0.5382(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5726 (C:5.6030, R:0.0100, T:0.5716(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5308 (C:5.5814, R:0.0099, T:0.5298(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6010 (C:5.5742, R:0.0100, T:0.6000(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5584 (C:5.5964, R:0.0099, T:0.5574(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5388 (C:5.5836, R:0.0099, T:0.5378(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 125 TRAINING SUMMARY:
  Total Loss: 0.5617
  Contrastive: 5.5909
  Reconstruction: 0.0100
  Topological: 0.5607 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9464
  Contrastive: 4.4225
  Reconstruction: 0.0099
  Topological: 4.9454 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 125/300 COMPLETE (44.5s)
Train Loss: 0.5617 (C:5.5909, R:0.0100, T:0.5607)
Val Loss:   4.9464 (C:4.4225, R:0.0099, T:4.9454)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 126 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5552 (C:5.5798, R:0.0100, T:0.5542(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5733 (C:5.5894, R:0.0100, T:0.5724(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5477 (C:5.6110, R:0.0099, T:0.5467(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5318 (C:5.5609, R:0.0100, T:0.5308(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5945 (C:5.6422, R:0.0100, T:0.5935(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5455 (C:5.5749, R:0.0100, T:0.5445(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5682 (C:5.6044, R:0.0099, T:0.5672(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5493 (C:5.5325, R:0.0100, T:0.5483(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5599 (C:5.6030, R:0.0100, T:0.5589(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5634 (C:5.5720, R:0.0099, T:0.5624(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5857 (C:5.6574, R:0.0100, T:0.5847(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5817 (C:5.5620, R:0.0100, T:0.5807(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5593 (C:5.6164, R:0.0100, T:0.5584(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5654 (C:5.5844, R:0.0100, T:0.5644(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5913 (C:5.6108, R:0.0099, T:0.5903(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5541 (C:5.5712, R:0.0100, T:0.5531(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5623 (C:5.6200, R:0.0100, T:0.5613(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5589 (C:5.6205, R:0.0100, T:0.5579(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5558 (C:5.6257, R:0.0100, T:0.5548(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5546 (C:5.5458, R:0.0100, T:0.5536(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5849 (C:5.6084, R:0.0099, T:0.5839(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5807 (C:5.5407, R:0.0100, T:0.5797(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 126 TRAINING SUMMARY:
  Total Loss: 0.5624
  Contrastive: 5.5911
  Reconstruction: 0.0100
  Topological: 0.5614 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8302
  Contrastive: 4.4668
  Reconstruction: 0.0099
  Topological: 4.8292 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 126/300 COMPLETE (44.5s)
Train Loss: 0.5624 (C:5.5911, R:0.0100, T:0.5614)
Val Loss:   4.8302 (C:4.4668, R:0.0099, T:4.8292)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 127 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5504 (C:5.6095, R:0.0099, T:0.5494(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5765 (C:5.5917, R:0.0100, T:0.5755(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5498 (C:5.5887, R:0.0100, T:0.5488(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5531 (C:5.5958, R:0.0099, T:0.5521(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5684 (C:5.5634, R:0.0099, T:0.5674(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5622 (C:5.6002, R:0.0100, T:0.5612(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5400 (C:5.5791, R:0.0099, T:0.5390(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5675 (C:5.6116, R:0.0100, T:0.5665(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5628 (C:5.6237, R:0.0099, T:0.5618(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5748 (C:5.6056, R:0.0100, T:0.5738(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5580 (C:5.6076, R:0.0099, T:0.5570(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5466 (C:5.6405, R:0.0100, T:0.5456(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5533 (C:5.6004, R:0.0099, T:0.5523(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5738 (C:5.6027, R:0.0099, T:0.5728(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5930 (C:5.5797, R:0.0100, T:0.5920(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5581 (C:5.5387, R:0.0100, T:0.5571(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5437 (C:5.6216, R:0.0100, T:0.5427(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5478 (C:5.5904, R:0.0099, T:0.5468(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5537 (C:5.6049, R:0.0100, T:0.5527(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5548 (C:5.6242, R:0.0099, T:0.5538(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5301 (C:5.5716, R:0.0099, T:0.5291(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5362 (C:5.5563, R:0.0099, T:0.5352(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5604

ğŸ“Š EPOCH 127 TRAINING SUMMARY:
  Total Loss: 0.5614
  Contrastive: 5.5921
  Reconstruction: 0.0100
  Topological: 0.5604 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.7911
  Contrastive: 4.4604
  Reconstruction: 0.0099
  Topological: 4.7901 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 127/300 COMPLETE (44.5s)
Train Loss: 0.5614 (C:5.5921, R:0.0100, T:0.5604)
Val Loss:   4.7911 (C:4.4604, R:0.0099, T:4.7901)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 128 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5797 (C:5.5915, R:0.0099, T:0.5787(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5661 (C:5.5830, R:0.0100, T:0.5651(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5728 (C:5.6072, R:0.0100, T:0.5718(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5631 (C:5.5553, R:0.0099, T:0.5621(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5443 (C:5.6323, R:0.0099, T:0.5433(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5668 (C:5.5850, R:0.0099, T:0.5658(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5631 (C:5.6174, R:0.0099, T:0.5621(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5817 (C:5.5792, R:0.0100, T:0.5807(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5520 (C:5.5707, R:0.0100, T:0.5510(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5547 (C:5.5733, R:0.0099, T:0.5538(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5514 (C:5.5689, R:0.0100, T:0.5504(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5483 (C:5.6119, R:0.0100, T:0.5473(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5237 (C:5.5932, R:0.0099, T:0.5227(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5656 (C:5.5761, R:0.0099, T:0.5646(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5924 (C:5.5955, R:0.0100, T:0.5914(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5546 (C:5.5856, R:0.0099, T:0.5536(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5740 (C:5.5742, R:0.0100, T:0.5730(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5679 (C:5.5851, R:0.0099, T:0.5669(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5573 (C:5.5950, R:0.0100, T:0.5563(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5632 (C:5.6091, R:0.0099, T:0.5622(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5970 (C:5.5647, R:0.0100, T:0.5960(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5538 (C:5.6215, R:0.0099, T:0.5528(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5599

ğŸ“Š EPOCH 128 TRAINING SUMMARY:
  Total Loss: 0.5609
  Contrastive: 5.5918
  Reconstruction: 0.0100
  Topological: 0.5599 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8673
  Contrastive: 4.4428
  Reconstruction: 0.0099
  Topological: 4.8663 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 128/300 COMPLETE (45.1s)
Train Loss: 0.5609 (C:5.5918, R:0.0100, T:0.5599)
Val Loss:   4.8673 (C:4.4428, R:0.0099, T:4.8663)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 129 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5872 (C:5.5877, R:0.0099, T:0.5862(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5525 (C:5.5940, R:0.0099, T:0.5515(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5810 (C:5.6041, R:0.0100, T:0.5800(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5631 (C:5.6013, R:0.0099, T:0.5621(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5588 (C:5.5820, R:0.0099, T:0.5578(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5858 (C:5.6587, R:0.0100, T:0.5848(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5489 (C:5.5745, R:0.0099, T:0.5479(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5532 (C:5.5970, R:0.0100, T:0.5522(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5645 (C:5.5423, R:0.0099, T:0.5635(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5551 (C:5.6212, R:0.0100, T:0.5541(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5732 (C:5.6070, R:0.0099, T:0.5722(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5511 (C:5.5662, R:0.0100, T:0.5501(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5575 (C:5.6004, R:0.0099, T:0.5565(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5557 (C:5.5892, R:0.0100, T:0.5547(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5299 (C:5.6029, R:0.0100, T:0.5289(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5601 (C:5.6243, R:0.0100, T:0.5591(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5577 (C:5.5655, R:0.0100, T:0.5567(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5850 (C:5.5727, R:0.0099, T:0.5840(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5637 (C:5.6335, R:0.0100, T:0.5627(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.6004 (C:5.6170, R:0.0100, T:0.5994(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5498 (C:5.5835, R:0.0099, T:0.5488(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5530 (C:5.6258, R:0.0100, T:0.5520(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 129 TRAINING SUMMARY:
  Total Loss: 0.5619
  Contrastive: 5.5909
  Reconstruction: 0.0100
  Topological: 0.5609 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.7925
  Contrastive: 4.4436
  Reconstruction: 0.0099
  Topological: 4.7915 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 129/300 COMPLETE (45.0s)
Train Loss: 0.5619 (C:5.5909, R:0.0100, T:0.5609)
Val Loss:   4.7925 (C:4.4436, R:0.0099, T:4.7915)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 130 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5384 (C:5.6047, R:0.0100, T:0.5374(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5513 (C:5.5708, R:0.0100, T:0.5503(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5482 (C:5.5568, R:0.0099, T:0.5472(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5940 (C:5.6068, R:0.0100, T:0.5930(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5384 (C:5.6312, R:0.0100, T:0.5374(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5316 (C:5.5783, R:0.0100, T:0.5306(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5608 (C:5.5920, R:0.0100, T:0.5598(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5667 (C:5.6016, R:0.0100, T:0.5657(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5516 (C:5.5764, R:0.0100, T:0.5506(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5454 (C:5.6328, R:0.0100, T:0.5444(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5797 (C:5.5902, R:0.0100, T:0.5787(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6066 (C:5.6493, R:0.0099, T:0.6056(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5592 (C:5.6033, R:0.0099, T:0.5582(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5530 (C:5.5897, R:0.0099, T:0.5520(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5803 (C:5.5942, R:0.0100, T:0.5793(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5641 (C:5.6177, R:0.0100, T:0.5631(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5808 (C:5.5953, R:0.0100, T:0.5798(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5540 (C:5.6040, R:0.0100, T:0.5530(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5209 (C:5.6183, R:0.0099, T:0.5199(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5784 (C:5.5629, R:0.0100, T:0.5774(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5595 (C:5.5898, R:0.0099, T:0.5585(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5468 (C:5.5776, R:0.0099, T:0.5458(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5581

ğŸ“Š EPOCH 130 TRAINING SUMMARY:
  Total Loss: 0.5591
  Contrastive: 5.5942
  Reconstruction: 0.0100
  Topological: 0.5581 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9350
  Contrastive: 4.4405
  Reconstruction: 0.0099
  Topological: 4.9341 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 130/300 COMPLETE (45.0s)
Train Loss: 0.5591 (C:5.5942, R:0.0100, T:0.5581)
Val Loss:   4.9350 (C:4.4405, R:0.0099, T:4.9341)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 131 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5307 (C:5.5909, R:0.0100, T:0.5297(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5612 (C:5.5996, R:0.0099, T:0.5602(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5678 (C:5.5905, R:0.0100, T:0.5668(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5563 (C:5.5906, R:0.0100, T:0.5553(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5678 (C:5.5782, R:0.0099, T:0.5668(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5420 (C:5.6210, R:0.0099, T:0.5410(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5841 (C:5.5462, R:0.0099, T:0.5831(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5553 (C:5.5605, R:0.0099, T:0.5543(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5315 (C:5.5935, R:0.0099, T:0.5305(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5833 (C:5.6186, R:0.0099, T:0.5823(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5857 (C:5.5895, R:0.0099, T:0.5848(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5775 (C:5.6093, R:0.0100, T:0.5765(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5464 (C:5.6094, R:0.0099, T:0.5454(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5583 (C:5.5628, R:0.0099, T:0.5573(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5589 (C:5.6182, R:0.0100, T:0.5579(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5480 (C:5.5741, R:0.0100, T:0.5470(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5590 (C:5.5957, R:0.0099, T:0.5580(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5812 (C:5.5977, R:0.0100, T:0.5802(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5644 (C:5.6366, R:0.0100, T:0.5634(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5472 (C:5.5478, R:0.0099, T:0.5463(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5427 (C:5.5966, R:0.0099, T:0.5417(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5626 (C:5.5702, R:0.0100, T:0.5616(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 131 TRAINING SUMMARY:
  Total Loss: 0.5598
  Contrastive: 5.5915
  Reconstruction: 0.0100
  Topological: 0.5588 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8524
  Contrastive: 4.4504
  Reconstruction: 0.0099
  Topological: 4.8514 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 131/300 COMPLETE (44.3s)
Train Loss: 0.5598 (C:5.5915, R:0.0100, T:0.5588)
Val Loss:   4.8524 (C:4.4504, R:0.0099, T:4.8514)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 132 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5663 (C:5.5939, R:0.0099, T:0.5653(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5676 (C:5.5953, R:0.0100, T:0.5666(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5318 (C:5.6187, R:0.0100, T:0.5308(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5179 (C:5.5813, R:0.0100, T:0.5169(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5457 (C:5.6316, R:0.0100, T:0.5447(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5623 (C:5.5978, R:0.0100, T:0.5613(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5296 (C:5.5748, R:0.0099, T:0.5286(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5642 (C:5.6078, R:0.0100, T:0.5632(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5634 (C:5.6250, R:0.0099, T:0.5624(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5373 (C:5.5624, R:0.0099, T:0.5363(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5659 (C:5.6141, R:0.0100, T:0.5649(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5583 (C:5.5635, R:0.0100, T:0.5573(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5537 (C:5.6105, R:0.0100, T:0.5527(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5849 (C:5.6072, R:0.0100, T:0.5839(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5359 (C:5.5933, R:0.0100, T:0.5349(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5476 (C:5.5758, R:0.0100, T:0.5466(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5564 (C:5.6369, R:0.0100, T:0.5554(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5267 (C:5.5859, R:0.0100, T:0.5257(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5542 (C:5.6119, R:0.0099, T:0.5532(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5729 (C:5.5881, R:0.0099, T:0.5719(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5590 (C:5.6037, R:0.0099, T:0.5581(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5733 (C:5.5443, R:0.0100, T:0.5723(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 132 TRAINING SUMMARY:
  Total Loss: 0.5597
  Contrastive: 5.5923
  Reconstruction: 0.0100
  Topological: 0.5587 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.7808
  Contrastive: 4.4716
  Reconstruction: 0.0099
  Topological: 4.7798 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 132/300 COMPLETE (44.4s)
Train Loss: 0.5597 (C:5.5923, R:0.0100, T:0.5587)
Val Loss:   4.7808 (C:4.4716, R:0.0099, T:4.7798)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 133 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5456 (C:5.6162, R:0.0100, T:0.5446(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5662 (C:5.5323, R:0.0100, T:0.5653(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5238 (C:5.5751, R:0.0099, T:0.5228(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5673 (C:5.6053, R:0.0099, T:0.5663(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5923 (C:5.6318, R:0.0099, T:0.5913(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5861 (C:5.5874, R:0.0100, T:0.5851(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5829 (C:5.5791, R:0.0100, T:0.5819(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5356 (C:5.6174, R:0.0099, T:0.5346(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5525 (C:5.5581, R:0.0099, T:0.5515(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5461 (C:5.5696, R:0.0100, T:0.5451(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5429 (C:5.5528, R:0.0099, T:0.5419(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5519 (C:5.6280, R:0.0100, T:0.5509(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5821 (C:5.5996, R:0.0100, T:0.5811(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5677 (C:5.5343, R:0.0099, T:0.5667(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5762 (C:5.6219, R:0.0100, T:0.5752(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5819 (C:5.6124, R:0.0100, T:0.5809(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5687 (C:5.5725, R:0.0100, T:0.5677(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5451 (C:5.5927, R:0.0100, T:0.5441(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.6075 (C:5.5939, R:0.0100, T:0.6065(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5417 (C:5.5755, R:0.0100, T:0.5407(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5549 (C:5.6450, R:0.0100, T:0.5539(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5514 (C:5.5751, R:0.0100, T:0.5504(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5567

ğŸ“Š EPOCH 133 TRAINING SUMMARY:
  Total Loss: 0.5577
  Contrastive: 5.5915
  Reconstruction: 0.0100
  Topological: 0.5567 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9364
  Contrastive: 4.4273
  Reconstruction: 0.0099
  Topological: 4.9354 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 133/300 COMPLETE (45.5s)
Train Loss: 0.5577 (C:5.5915, R:0.0100, T:0.5567)
Val Loss:   4.9364 (C:4.4273, R:0.0099, T:4.9354)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 134 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5663 (C:5.5594, R:0.0099, T:0.5653(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5675 (C:5.6041, R:0.0100, T:0.5665(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5522 (C:5.5838, R:0.0100, T:0.5512(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5810 (C:5.6290, R:0.0100, T:0.5800(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5230 (C:5.5832, R:0.0099, T:0.5220(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5297 (C:5.5989, R:0.0100, T:0.5287(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5736 (C:5.5810, R:0.0099, T:0.5726(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5740 (C:5.6051, R:0.0100, T:0.5730(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5332 (C:5.6104, R:0.0100, T:0.5322(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5561 (C:5.5963, R:0.0099, T:0.5551(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5453 (C:5.5993, R:0.0100, T:0.5443(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5705 (C:5.5632, R:0.0099, T:0.5695(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5358 (C:5.5993, R:0.0100, T:0.5348(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5928 (C:5.5881, R:0.0100, T:0.5918(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5353 (C:5.6066, R:0.0100, T:0.5343(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5389 (C:5.6353, R:0.0100, T:0.5379(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5627 (C:5.5848, R:0.0100, T:0.5617(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5800 (C:5.6543, R:0.0099, T:0.5790(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5687 (C:5.5812, R:0.0099, T:0.5677(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5300 (C:5.5406, R:0.0099, T:0.5290(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5352 (C:5.6225, R:0.0100, T:0.5342(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5303 (C:5.5950, R:0.0099, T:0.5293(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 134 TRAINING SUMMARY:
  Total Loss: 0.5599
  Contrastive: 5.5916
  Reconstruction: 0.0100
  Topological: 0.5589 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9912
  Contrastive: 4.4110
  Reconstruction: 0.0099
  Topological: 4.9902 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 134/300 COMPLETE (45.2s)
Train Loss: 0.5599 (C:5.5916, R:0.0100, T:0.5589)
Val Loss:   4.9912 (C:4.4110, R:0.0099, T:4.9902)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 135 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5712 (C:5.5571, R:0.0099, T:0.5702(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5313 (C:5.5830, R:0.0099, T:0.5303(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5408 (C:5.5944, R:0.0100, T:0.5398(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5430 (C:5.6448, R:0.0100, T:0.5420(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5708 (C:5.5876, R:0.0099, T:0.5698(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5620 (C:5.6223, R:0.0100, T:0.5610(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5709 (C:5.5743, R:0.0099, T:0.5699(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5673 (C:5.5520, R:0.0100, T:0.5663(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5706 (C:5.6143, R:0.0100, T:0.5696(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5338 (C:5.5435, R:0.0099, T:0.5328(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5728 (C:5.6197, R:0.0099, T:0.5718(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5494 (C:5.6098, R:0.0100, T:0.5484(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5676 (C:5.5532, R:0.0099, T:0.5666(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5551 (C:5.6000, R:0.0100, T:0.5541(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5772 (C:5.5867, R:0.0100, T:0.5762(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5699 (C:5.6066, R:0.0100, T:0.5689(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5561 (C:5.5865, R:0.0099, T:0.5551(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5791 (C:5.5915, R:0.0100, T:0.5781(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5483 (C:5.6178, R:0.0100, T:0.5473(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5227 (C:5.5792, R:0.0099, T:0.5217(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5988 (C:5.5747, R:0.0100, T:0.5978(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5709 (C:5.5968, R:0.0100, T:0.5699(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 135 TRAINING SUMMARY:
  Total Loss: 0.5578
  Contrastive: 5.5922
  Reconstruction: 0.0100
  Topological: 0.5568 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8158
  Contrastive: 4.4392
  Reconstruction: 0.0099
  Topological: 4.8148 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 135/300 COMPLETE (44.9s)
Train Loss: 0.5578 (C:5.5922, R:0.0100, T:0.5568)
Val Loss:   4.8158 (C:4.4392, R:0.0099, T:4.8148)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 136 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5553 (C:5.5708, R:0.0099, T:0.5543(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5543 (C:5.6102, R:0.0100, T:0.5533(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5272 (C:5.6106, R:0.0099, T:0.5262(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5474 (C:5.5788, R:0.0100, T:0.5465(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5564 (C:5.5871, R:0.0100, T:0.5554(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5258 (C:5.6412, R:0.0100, T:0.5248(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5444 (C:5.6193, R:0.0099, T:0.5434(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5466 (C:5.6020, R:0.0100, T:0.5456(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5494 (C:5.5676, R:0.0099, T:0.5484(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5668 (C:5.6187, R:0.0100, T:0.5659(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5656 (C:5.5848, R:0.0099, T:0.5646(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5699 (C:5.5881, R:0.0100, T:0.5689(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5964 (C:5.6157, R:0.0099, T:0.5954(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5922 (C:5.6219, R:0.0100, T:0.5912(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5712 (C:5.6056, R:0.0099, T:0.5702(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5610 (C:5.5943, R:0.0099, T:0.5600(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5653 (C:5.5715, R:0.0099, T:0.5643(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5801 (C:5.6200, R:0.0100, T:0.5791(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5829 (C:5.5679, R:0.0100, T:0.5819(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5522 (C:5.5947, R:0.0100, T:0.5512(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5659 (C:5.6211, R:0.0100, T:0.5649(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5383 (C:5.5523, R:0.0100, T:0.5373(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5551

ğŸ“Š EPOCH 136 TRAINING SUMMARY:
  Total Loss: 0.5561
  Contrastive: 5.5933
  Reconstruction: 0.0100
  Topological: 0.5551 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.7820
  Contrastive: 4.4445
  Reconstruction: 0.0099
  Topological: 4.7810 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 136/300 COMPLETE (45.2s)
Train Loss: 0.5561 (C:5.5933, R:0.0100, T:0.5551)
Val Loss:   4.7820 (C:4.4445, R:0.0099, T:4.7810)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 137 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5890 (C:5.5938, R:0.0099, T:0.5880(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5569 (C:5.6305, R:0.0100, T:0.5559(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5735 (C:5.5879, R:0.0100, T:0.5725(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5528 (C:5.5616, R:0.0100, T:0.5518(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5491 (C:5.6127, R:0.0100, T:0.5481(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5485 (C:5.5814, R:0.0100, T:0.5475(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5401 (C:5.5445, R:0.0100, T:0.5391(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5600 (C:5.5940, R:0.0099, T:0.5590(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5209 (C:5.5617, R:0.0099, T:0.5199(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5413 (C:5.5700, R:0.0100, T:0.5403(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5350 (C:5.6175, R:0.0100, T:0.5340(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5563 (C:5.6135, R:0.0099, T:0.5553(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5617 (C:5.6103, R:0.0099, T:0.5607(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5491 (C:5.6172, R:0.0100, T:0.5481(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5726 (C:5.5937, R:0.0100, T:0.5716(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5448 (C:5.5686, R:0.0099, T:0.5438(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5927 (C:5.5975, R:0.0100, T:0.5917(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5583 (C:5.5704, R:0.0100, T:0.5573(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5767 (C:5.5603, R:0.0099, T:0.5757(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5759 (C:5.5706, R:0.0099, T:0.5749(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5479 (C:5.5655, R:0.0099, T:0.5469(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5532 (C:5.6091, R:0.0100, T:0.5522(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 137 TRAINING SUMMARY:
  Total Loss: 0.5572
  Contrastive: 5.5908
  Reconstruction: 0.0100
  Topological: 0.5562 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9313
  Contrastive: 4.4164
  Reconstruction: 0.0099
  Topological: 4.9303 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 137/300 COMPLETE (45.4s)
Train Loss: 0.5572 (C:5.5908, R:0.0100, T:0.5562)
Val Loss:   4.9313 (C:4.4164, R:0.0099, T:4.9303)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 138 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5610 (C:5.5586, R:0.0099, T:0.5600(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5426 (C:5.5939, R:0.0100, T:0.5416(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5716 (C:5.6101, R:0.0100, T:0.5706(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5674 (C:5.5709, R:0.0100, T:0.5664(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5836 (C:5.5752, R:0.0099, T:0.5826(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5521 (C:5.5876, R:0.0099, T:0.5511(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5307 (C:5.6632, R:0.0099, T:0.5297(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5604 (C:5.5837, R:0.0100, T:0.5594(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5463 (C:5.5516, R:0.0100, T:0.5453(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5474 (C:5.6211, R:0.0100, T:0.5464(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5622 (C:5.5701, R:0.0099, T:0.5612(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6120 (C:5.5973, R:0.0099, T:0.6110(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5399 (C:5.5717, R:0.0099, T:0.5389(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5591 (C:5.5462, R:0.0099, T:0.5581(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5757 (C:5.6343, R:0.0099, T:0.5747(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5827 (C:5.5929, R:0.0100, T:0.5817(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5648 (C:5.5709, R:0.0099, T:0.5638(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5448 (C:5.5546, R:0.0100, T:0.5438(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5357 (C:5.5649, R:0.0099, T:0.5347(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5571 (C:5.5664, R:0.0099, T:0.5561(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5251 (C:5.5714, R:0.0100, T:0.5241(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5597 (C:5.5660, R:0.0099, T:0.5587(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 138 TRAINING SUMMARY:
  Total Loss: 0.5584
  Contrastive: 5.5903
  Reconstruction: 0.0100
  Topological: 0.5574 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8349
  Contrastive: 4.4404
  Reconstruction: 0.0099
  Topological: 4.8339 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 138/300 COMPLETE (44.5s)
Train Loss: 0.5584 (C:5.5903, R:0.0100, T:0.5574)
Val Loss:   4.8349 (C:4.4404, R:0.0099, T:4.8339)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 139 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5653 (C:5.5880, R:0.0100, T:0.5643(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5399 (C:5.5854, R:0.0100, T:0.5389(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5530 (C:5.6242, R:0.0100, T:0.5521(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5547 (C:5.5447, R:0.0099, T:0.5537(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5449 (C:5.5583, R:0.0099, T:0.5439(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5403 (C:5.6147, R:0.0100, T:0.5393(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5703 (C:5.6236, R:0.0099, T:0.5693(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5309 (C:5.6054, R:0.0100, T:0.5299(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5603 (C:5.5621, R:0.0100, T:0.5594(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5925 (C:5.6305, R:0.0100, T:0.5915(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5437 (C:5.5464, R:0.0099, T:0.5427(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5541 (C:5.6171, R:0.0099, T:0.5531(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5242 (C:5.6136, R:0.0100, T:0.5232(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5669 (C:5.6351, R:0.0099, T:0.5659(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5461 (C:5.5870, R:0.0100, T:0.5451(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5315 (C:5.5854, R:0.0099, T:0.5305(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5836 (C:5.5942, R:0.0099, T:0.5826(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5834 (C:5.5864, R:0.0100, T:0.5824(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5344 (C:5.5872, R:0.0100, T:0.5335(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5453 (C:5.6176, R:0.0099, T:0.5443(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5861 (C:5.5399, R:0.0100, T:0.5851(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5195 (C:5.5434, R:0.0099, T:0.5185(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 139 TRAINING SUMMARY:
  Total Loss: 0.5568
  Contrastive: 5.5911
  Reconstruction: 0.0100
  Topological: 0.5558 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8693
  Contrastive: 4.4307
  Reconstruction: 0.0099
  Topological: 4.8683 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 139/300 COMPLETE (45.0s)
Train Loss: 0.5568 (C:5.5911, R:0.0100, T:0.5558)
Val Loss:   4.8693 (C:4.4307, R:0.0099, T:4.8683)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 140 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5709 (C:5.5587, R:0.0099, T:0.5699(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5179 (C:5.5930, R:0.0100, T:0.5169(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5634 (C:5.6114, R:0.0099, T:0.5624(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5426 (C:5.6413, R:0.0100, T:0.5416(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5555 (C:5.6038, R:0.0100, T:0.5545(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5856 (C:5.5823, R:0.0100, T:0.5846(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5597 (C:5.5596, R:0.0099, T:0.5587(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5693 (C:5.6246, R:0.0100, T:0.5683(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5552 (C:5.6344, R:0.0100, T:0.5542(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5435 (C:5.5736, R:0.0099, T:0.5425(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5655 (C:5.5949, R:0.0099, T:0.5645(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5549 (C:5.6381, R:0.0100, T:0.5539(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5375 (C:5.6131, R:0.0099, T:0.5365(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5957 (C:5.6307, R:0.0100, T:0.5947(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5481 (C:5.5500, R:0.0099, T:0.5471(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5513 (C:5.5993, R:0.0099, T:0.5503(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5683 (C:5.5544, R:0.0100, T:0.5673(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5459 (C:5.5487, R:0.0100, T:0.5449(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5569 (C:5.6136, R:0.0099, T:0.5559(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5799 (C:5.5770, R:0.0100, T:0.5789(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5820 (C:5.5851, R:0.0099, T:0.5810(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5654 (C:5.5941, R:0.0099, T:0.5644(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 140 TRAINING SUMMARY:
  Total Loss: 0.5578
  Contrastive: 5.5917
  Reconstruction: 0.0100
  Topological: 0.5568 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9213
  Contrastive: 4.4311
  Reconstruction: 0.0099
  Topological: 4.9203 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 140/300 COMPLETE (45.4s)
Train Loss: 0.5578 (C:5.5917, R:0.0100, T:0.5568)
Val Loss:   4.9213 (C:4.4311, R:0.0099, T:4.9203)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 141 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5415 (C:5.5738, R:0.0099, T:0.5405(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5739 (C:5.6358, R:0.0100, T:0.5729(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5507 (C:5.5912, R:0.0100, T:0.5497(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5481 (C:5.6140, R:0.0099, T:0.5471(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5574 (C:5.6004, R:0.0099, T:0.5564(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5534 (C:5.5562, R:0.0099, T:0.5525(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5484 (C:5.5954, R:0.0099, T:0.5474(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5654 (C:5.5882, R:0.0100, T:0.5644(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5492 (C:5.5881, R:0.0099, T:0.5482(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5993 (C:5.6224, R:0.0100, T:0.5983(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5203 (C:5.5918, R:0.0100, T:0.5193(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5760 (C:5.6586, R:0.0099, T:0.5750(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5521 (C:5.6081, R:0.0099, T:0.5511(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5386 (C:5.5823, R:0.0100, T:0.5376(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5618 (C:5.6290, R:0.0100, T:0.5608(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5605 (C:5.5956, R:0.0100, T:0.5595(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5562 (C:5.5859, R:0.0100, T:0.5552(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5500 (C:5.6218, R:0.0100, T:0.5490(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5592 (C:5.5314, R:0.0099, T:0.5582(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5836 (C:5.6369, R:0.0099, T:0.5826(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5501 (C:5.5666, R:0.0099, T:0.5491(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5513 (C:5.6415, R:0.0100, T:0.5503(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 141 TRAINING SUMMARY:
  Total Loss: 0.5568
  Contrastive: 5.5944
  Reconstruction: 0.0100
  Topological: 0.5558 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 5.0370
  Contrastive: 4.3981
  Reconstruction: 0.0099
  Topological: 5.0360 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 141/300 COMPLETE (43.9s)
Train Loss: 0.5568 (C:5.5944, R:0.0100, T:0.5558)
Val Loss:   5.0370 (C:4.3981, R:0.0099, T:5.0360)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 142 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5406 (C:5.5554, R:0.0100, T:0.5396(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5584 (C:5.5623, R:0.0100, T:0.5574(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5457 (C:5.6417, R:0.0099, T:0.5448(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5800 (C:5.5978, R:0.0099, T:0.5790(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5416 (C:5.5713, R:0.0100, T:0.5406(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5693 (C:5.5877, R:0.0099, T:0.5683(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5400 (C:5.5827, R:0.0099, T:0.5390(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5491 (C:5.5529, R:0.0100, T:0.5481(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5645 (C:5.5601, R:0.0099, T:0.5636(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5646 (C:5.6385, R:0.0099, T:0.5637(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5345 (C:5.5388, R:0.0100, T:0.5335(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.6009 (C:5.6654, R:0.0099, T:0.5999(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5509 (C:5.5783, R:0.0099, T:0.5499(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5264 (C:5.5599, R:0.0099, T:0.5254(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5531 (C:5.5972, R:0.0099, T:0.5521(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5542 (C:5.6018, R:0.0100, T:0.5532(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5225 (C:5.5988, R:0.0100, T:0.5215(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5589 (C:5.6051, R:0.0100, T:0.5579(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5409 (C:5.5312, R:0.0100, T:0.5399(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5584 (C:5.6182, R:0.0100, T:0.5574(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5460 (C:5.5994, R:0.0100, T:0.5450(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5501 (C:5.5880, R:0.0100, T:0.5491(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5547

ğŸ“Š EPOCH 142 TRAINING SUMMARY:
  Total Loss: 0.5557
  Contrastive: 5.5927
  Reconstruction: 0.0100
  Topological: 0.5547 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8261
  Contrastive: 4.4427
  Reconstruction: 0.0099
  Topological: 4.8251 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 142/300 COMPLETE (45.3s)
Train Loss: 0.5557 (C:5.5927, R:0.0100, T:0.5547)
Val Loss:   4.8261 (C:4.4427, R:0.0099, T:4.8251)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 143 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5406 (C:5.5959, R:0.0100, T:0.5396(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5526 (C:5.6061, R:0.0100, T:0.5516(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5543 (C:5.5833, R:0.0099, T:0.5534(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5584 (C:5.6031, R:0.0100, T:0.5574(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5579 (C:5.6445, R:0.0100, T:0.5569(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5483 (C:5.5908, R:0.0100, T:0.5473(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5863 (C:5.6382, R:0.0099, T:0.5853(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5485 (C:5.5624, R:0.0100, T:0.5475(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5170 (C:5.5939, R:0.0100, T:0.5161(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5677 (C:5.6132, R:0.0099, T:0.5667(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5541 (C:5.5699, R:0.0099, T:0.5531(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5531 (C:5.5979, R:0.0100, T:0.5521(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5435 (C:5.5592, R:0.0100, T:0.5425(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5525 (C:5.5937, R:0.0100, T:0.5515(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5966 (C:5.5785, R:0.0100, T:0.5956(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5723 (C:5.6141, R:0.0099, T:0.5713(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5668 (C:5.6128, R:0.0099, T:0.5658(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5410 (C:5.5968, R:0.0100, T:0.5400(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5562 (C:5.6552, R:0.0100, T:0.5552(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5624 (C:5.5814, R:0.0100, T:0.5614(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5529 (C:5.5642, R:0.0099, T:0.5519(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5737 (C:5.6030, R:0.0099, T:0.5727(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5546

ğŸ“Š EPOCH 143 TRAINING SUMMARY:
  Total Loss: 0.5556
  Contrastive: 5.5916
  Reconstruction: 0.0100
  Topological: 0.5546 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.7166
  Contrastive: 4.4666
  Reconstruction: 0.0099
  Topological: 4.7156 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 143/300 COMPLETE (45.4s)
Train Loss: 0.5556 (C:5.5916, R:0.0100, T:0.5546)
Val Loss:   4.7166 (C:4.4666, R:0.0099, T:4.7156)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 144 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5534 (C:5.6187, R:0.0100, T:0.5524(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5691 (C:5.5711, R:0.0100, T:0.5681(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5327 (C:5.5869, R:0.0100, T:0.5317(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5290 (C:5.5900, R:0.0099, T:0.5280(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5917 (C:5.5447, R:0.0100, T:0.5907(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5613 (C:5.6490, R:0.0099, T:0.5603(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5875 (C:5.5837, R:0.0099, T:0.5865(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5623 (C:5.5685, R:0.0099, T:0.5613(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5466 (C:5.6206, R:0.0099, T:0.5456(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5526 (C:5.5673, R:0.0100, T:0.5516(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5642 (C:5.6361, R:0.0099, T:0.5632(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5444 (C:5.5607, R:0.0100, T:0.5435(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5626 (C:5.5871, R:0.0099, T:0.5616(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5538 (C:5.5677, R:0.0099, T:0.5528(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5374 (C:5.6145, R:0.0100, T:0.5364(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5484 (C:5.5743, R:0.0100, T:0.5474(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5443 (C:5.5619, R:0.0100, T:0.5433(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5579 (C:5.5711, R:0.0099, T:0.5569(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5576 (C:5.6343, R:0.0100, T:0.5566(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5791 (C:5.5489, R:0.0099, T:0.5781(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5584 (C:5.5857, R:0.0099, T:0.5574(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5445 (C:5.5557, R:0.0099, T:0.5435(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 144 TRAINING SUMMARY:
  Total Loss: 0.5570
  Contrastive: 5.5906
  Reconstruction: 0.0100
  Topological: 0.5560 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8756
  Contrastive: 4.4216
  Reconstruction: 0.0099
  Topological: 4.8746 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 144/300 COMPLETE (44.4s)
Train Loss: 0.5570 (C:5.5906, R:0.0100, T:0.5560)
Val Loss:   4.8756 (C:4.4216, R:0.0099, T:4.8746)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 145 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5885 (C:5.5770, R:0.0100, T:0.5875(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5441 (C:5.5813, R:0.0099, T:0.5431(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5661 (C:5.5779, R:0.0099, T:0.5651(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5538 (C:5.5938, R:0.0100, T:0.5528(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5385 (C:5.5833, R:0.0100, T:0.5375(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5488 (C:5.6032, R:0.0099, T:0.5478(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5523 (C:5.6047, R:0.0100, T:0.5513(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5713 (C:5.6239, R:0.0099, T:0.5703(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5541 (C:5.6040, R:0.0099, T:0.5531(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5345 (C:5.5706, R:0.0100, T:0.5335(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5482 (C:5.5411, R:0.0099, T:0.5472(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5641 (C:5.5945, R:0.0099, T:0.5631(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5374 (C:5.5869, R:0.0100, T:0.5364(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5480 (C:5.6335, R:0.0100, T:0.5470(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5562 (C:5.5898, R:0.0100, T:0.5552(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5600 (C:5.5991, R:0.0100, T:0.5590(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5487 (C:5.5609, R:0.0100, T:0.5477(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5287 (C:5.6260, R:0.0100, T:0.5277(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5452 (C:5.5999, R:0.0100, T:0.5442(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5518 (C:5.5938, R:0.0099, T:0.5508(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5551 (C:5.5956, R:0.0100, T:0.5541(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5508 (C:5.5840, R:0.0100, T:0.5498(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5544

ğŸ“Š EPOCH 145 TRAINING SUMMARY:
  Total Loss: 0.5554
  Contrastive: 5.5911
  Reconstruction: 0.0100
  Topological: 0.5544 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8404
  Contrastive: 4.4419
  Reconstruction: 0.0099
  Topological: 4.8394 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 145/300 COMPLETE (45.6s)
Train Loss: 0.5554 (C:5.5911, R:0.0100, T:0.5544)
Val Loss:   4.8404 (C:4.4419, R:0.0099, T:4.8394)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 146 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5450 (C:5.5799, R:0.0100, T:0.5440(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5175 (C:5.5986, R:0.0100, T:0.5165(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5752 (C:5.5614, R:0.0099, T:0.5742(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5643 (C:5.6481, R:0.0099, T:0.5633(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5476 (C:5.5752, R:0.0100, T:0.5466(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5846 (C:5.5776, R:0.0099, T:0.5836(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5709 (C:5.6015, R:0.0099, T:0.5699(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5606 (C:5.6057, R:0.0100, T:0.5596(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5485 (C:5.6171, R:0.0100, T:0.5475(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5767 (C:5.5981, R:0.0099, T:0.5757(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5199 (C:5.5594, R:0.0099, T:0.5189(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5748 (C:5.6019, R:0.0100, T:0.5738(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5423 (C:5.5423, R:0.0100, T:0.5413(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5631 (C:5.6527, R:0.0100, T:0.5621(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5503 (C:5.5611, R:0.0099, T:0.5493(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5481 (C:5.5788, R:0.0099, T:0.5471(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5723 (C:5.5747, R:0.0100, T:0.5713(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5678 (C:5.5872, R:0.0100, T:0.5668(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5661 (C:5.6063, R:0.0100, T:0.5651(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5439 (C:5.5337, R:0.0099, T:0.5429(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5623 (C:5.5867, R:0.0100, T:0.5613(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5827 (C:5.6213, R:0.0099, T:0.5817(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 146 TRAINING SUMMARY:
  Total Loss: 0.5555
  Contrastive: 5.5914
  Reconstruction: 0.0100
  Topological: 0.5545 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.7807
  Contrastive: 4.4432
  Reconstruction: 0.0099
  Topological: 4.7798 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 146/300 COMPLETE (45.6s)
Train Loss: 0.5555 (C:5.5914, R:0.0100, T:0.5545)
Val Loss:   4.7807 (C:4.4432, R:0.0099, T:4.7798)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 147 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5486 (C:5.5923, R:0.0099, T:0.5476(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5705 (C:5.5536, R:0.0099, T:0.5695(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5422 (C:5.6202, R:0.0100, T:0.5412(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5615 (C:5.6118, R:0.0100, T:0.5605(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5870 (C:5.5699, R:0.0100, T:0.5860(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5772 (C:5.6053, R:0.0100, T:0.5762(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5425 (C:5.6025, R:0.0100, T:0.5415(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5543 (C:5.5891, R:0.0100, T:0.5533(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5339 (C:5.6123, R:0.0099, T:0.5329(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5313 (C:5.5679, R:0.0099, T:0.5303(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5323 (C:5.6113, R:0.0100, T:0.5313(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5339 (C:5.6112, R:0.0099, T:0.5330(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5765 (C:5.5783, R:0.0100, T:0.5755(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5522 (C:5.6241, R:0.0099, T:0.5512(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5768 (C:5.5941, R:0.0100, T:0.5758(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5535 (C:5.6030, R:0.0100, T:0.5525(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5731 (C:5.6178, R:0.0099, T:0.5721(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5509 (C:5.6092, R:0.0100, T:0.5499(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5721 (C:5.5257, R:0.0100, T:0.5711(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5544 (C:5.6210, R:0.0099, T:0.5535(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5509 (C:5.5706, R:0.0100, T:0.5499(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5660 (C:5.6089, R:0.0099, T:0.5650(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 147 TRAINING SUMMARY:
  Total Loss: 0.5564
  Contrastive: 5.5924
  Reconstruction: 0.0100
  Topological: 0.5555 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.7979
  Contrastive: 4.4396
  Reconstruction: 0.0099
  Topological: 4.7969 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 147/300 COMPLETE (44.4s)
Train Loss: 0.5564 (C:5.5924, R:0.0100, T:0.5555)
Val Loss:   4.7979 (C:4.4396, R:0.0099, T:4.7969)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 148 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5593 (C:5.6009, R:0.0100, T:0.5583(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5579 (C:5.5831, R:0.0099, T:0.5569(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5604 (C:5.6207, R:0.0099, T:0.5594(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5289 (C:5.5731, R:0.0099, T:0.5279(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5787 (C:5.5285, R:0.0100, T:0.5777(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5632 (C:5.6430, R:0.0099, T:0.5622(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5750 (C:5.5492, R:0.0100, T:0.5740(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5498 (C:5.6261, R:0.0099, T:0.5488(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5555 (C:5.5827, R:0.0099, T:0.5545(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5425 (C:5.5860, R:0.0099, T:0.5415(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5667 (C:5.5606, R:0.0100, T:0.5657(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5468 (C:5.5795, R:0.0100, T:0.5458(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5213 (C:5.6179, R:0.0099, T:0.5203(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5719 (C:5.5885, R:0.0099, T:0.5709(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5502 (C:5.5251, R:0.0100, T:0.5492(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5642 (C:5.5910, R:0.0100, T:0.5632(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5537 (C:5.6130, R:0.0100, T:0.5527(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5440 (C:5.5851, R:0.0099, T:0.5430(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5532 (C:5.5619, R:0.0099, T:0.5522(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5881 (C:5.5772, R:0.0100, T:0.5871(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5550 (C:5.5473, R:0.0099, T:0.5540(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5490 (C:5.5801, R:0.0100, T:0.5480(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5526

ğŸ“Š EPOCH 148 TRAINING SUMMARY:
  Total Loss: 0.5536
  Contrastive: 5.5939
  Reconstruction: 0.0100
  Topological: 0.5526 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.7021
  Contrastive: 4.4573
  Reconstruction: 0.0099
  Topological: 4.7011 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)
âœ… New best model saved!

ğŸ¯ EPOCH 148/300 COMPLETE (46.9s)
Train Loss: 0.5536 (C:5.5939, R:0.0100, T:0.5526)
Val Loss:   4.7021 (C:4.4573, R:0.0099, T:4.7011)
ğŸ‰ Topological complexity detected!
â­ Best model so far!
------------------------------------------------------------

============================================================
EPOCH 149 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5935 (C:5.5958, R:0.0100, T:0.5925(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5408 (C:5.5950, R:0.0100, T:0.5398(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5637 (C:5.5513, R:0.0100, T:0.5627(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5335 (C:5.5467, R:0.0100, T:0.5325(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5442 (C:5.5811, R:0.0099, T:0.5432(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5463 (C:5.6164, R:0.0099, T:0.5453(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5541 (C:5.6135, R:0.0100, T:0.5531(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5715 (C:5.5713, R:0.0100, T:0.5705(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5341 (C:5.5788, R:0.0100, T:0.5331(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5213 (C:5.5771, R:0.0099, T:0.5203(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5382 (C:5.5755, R:0.0100, T:0.5372(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5874 (C:5.5837, R:0.0099, T:0.5865(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5705 (C:5.5508, R:0.0099, T:0.5695(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5618 (C:5.6051, R:0.0100, T:0.5608(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5382 (C:5.5776, R:0.0100, T:0.5372(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5454 (C:5.6033, R:0.0099, T:0.5444(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5604 (C:5.5846, R:0.0099, T:0.5594(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5635 (C:5.6375, R:0.0100, T:0.5625(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5293 (C:5.5488, R:0.0099, T:0.5283(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5279 (C:5.6465, R:0.0100, T:0.5270(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5527 (C:5.5627, R:0.0100, T:0.5517(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5523 (C:5.5842, R:0.0099, T:0.5514(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 149 TRAINING SUMMARY:
  Total Loss: 0.5557
  Contrastive: 5.5911
  Reconstruction: 0.0100
  Topological: 0.5547 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.7837
  Contrastive: 4.4371
  Reconstruction: 0.0099
  Topological: 4.7827 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 149/300 COMPLETE (45.7s)
Train Loss: 0.5557 (C:5.5911, R:0.0100, T:0.5547)
Val Loss:   4.7837 (C:4.4371, R:0.0099, T:4.7827)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 150 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5536 (C:5.5775, R:0.0100, T:0.5526(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5702 (C:5.6189, R:0.0100, T:0.5692(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5637 (C:5.5808, R:0.0100, T:0.5627(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5579 (C:5.6352, R:0.0100, T:0.5569(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5593 (C:5.5954, R:0.0100, T:0.5583(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5398 (C:5.5586, R:0.0100, T:0.5388(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5795 (C:5.5524, R:0.0099, T:0.5785(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5544 (C:5.6342, R:0.0100, T:0.5534(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5500 (C:5.6093, R:0.0100, T:0.5490(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5389 (C:5.6041, R:0.0100, T:0.5379(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5315 (C:5.5974, R:0.0099, T:0.5305(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5679 (C:5.5524, R:0.0100, T:0.5669(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5486 (C:5.5981, R:0.0099, T:0.5476(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5667 (C:5.6054, R:0.0100, T:0.5657(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5284 (C:5.6087, R:0.0100, T:0.5274(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5434 (C:5.5851, R:0.0099, T:0.5424(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5630 (C:5.6032, R:0.0100, T:0.5620(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5785 (C:5.5674, R:0.0099, T:0.5775(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5716 (C:5.5731, R:0.0099, T:0.5706(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5584 (C:5.6108, R:0.0099, T:0.5574(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5179 (C:5.5945, R:0.0099, T:0.5169(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5660 (C:5.5243, R:0.0099, T:0.5650(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5525

ğŸ“Š EPOCH 150 TRAINING SUMMARY:
  Total Loss: 0.5535
  Contrastive: 5.5941
  Reconstruction: 0.0100
  Topological: 0.5525 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8069
  Contrastive: 4.4485
  Reconstruction: 0.0099
  Topological: 4.8059 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 150/300 COMPLETE (45.7s)
Train Loss: 0.5535 (C:5.5941, R:0.0100, T:0.5525)
Val Loss:   4.8069 (C:4.4485, R:0.0099, T:4.8059)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 151 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5466 (C:5.5904, R:0.0099, T:0.5456(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5616 (C:5.6133, R:0.0100, T:0.5606(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5309 (C:5.5595, R:0.0100, T:0.5299(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5269 (C:5.6087, R:0.0099, T:0.5259(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5707 (C:5.5634, R:0.0100, T:0.5697(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5471 (C:5.6205, R:0.0100, T:0.5461(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5578 (C:5.6295, R:0.0099, T:0.5568(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5648 (C:5.6201, R:0.0099, T:0.5638(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5231 (C:5.6139, R:0.0099, T:0.5221(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5636 (C:5.6079, R:0.0100, T:0.5626(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5386 (C:5.5961, R:0.0099, T:0.5376(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5514 (C:5.6215, R:0.0099, T:0.5504(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5714 (C:5.5905, R:0.0099, T:0.5704(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5604 (C:5.5937, R:0.0099, T:0.5594(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5519 (C:5.5973, R:0.0099, T:0.5509(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5549 (C:5.6074, R:0.0100, T:0.5539(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5735 (C:5.5517, R:0.0099, T:0.5725(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5497 (C:5.6063, R:0.0100, T:0.5487(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5530 (C:5.6402, R:0.0100, T:0.5520(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5372 (C:5.6136, R:0.0099, T:0.5362(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5529 (C:5.5951, R:0.0100, T:0.5519(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5502 (C:5.5547, R:0.0099, T:0.5492(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5523

ğŸ“Š EPOCH 151 TRAINING SUMMARY:
  Total Loss: 0.5533
  Contrastive: 5.5917
  Reconstruction: 0.0100
  Topological: 0.5523 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.7825
  Contrastive: 4.4654
  Reconstruction: 0.0099
  Topological: 4.7815 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 151/300 COMPLETE (46.9s)
Train Loss: 0.5533 (C:5.5917, R:0.0100, T:0.5523)
Val Loss:   4.7825 (C:4.4654, R:0.0099, T:4.7815)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 152 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5386 (C:5.6043, R:0.0099, T:0.5376(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5418 (C:5.6126, R:0.0099, T:0.5408(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5238 (C:5.6372, R:0.0099, T:0.5228(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5648 (C:5.5747, R:0.0100, T:0.5638(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5841 (C:5.5402, R:0.0100, T:0.5831(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5559 (C:5.5678, R:0.0100, T:0.5549(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5563 (C:5.6140, R:0.0100, T:0.5553(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5496 (C:5.5547, R:0.0099, T:0.5486(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5332 (C:5.6079, R:0.0100, T:0.5322(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5455 (C:5.5639, R:0.0100, T:0.5445(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5272 (C:5.6379, R:0.0100, T:0.5262(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5648 (C:5.6008, R:0.0100, T:0.5638(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5903 (C:5.5943, R:0.0099, T:0.5893(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5813 (C:5.6000, R:0.0100, T:0.5803(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5631 (C:5.5673, R:0.0100, T:0.5622(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5489 (C:5.5962, R:0.0100, T:0.5480(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5804 (C:5.6147, R:0.0100, T:0.5794(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5558 (C:5.5632, R:0.0099, T:0.5548(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5771 (C:5.5787, R:0.0099, T:0.5761(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5448 (C:5.5822, R:0.0099, T:0.5438(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5670 (C:5.5924, R:0.0099, T:0.5660(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5315 (C:5.6126, R:0.0100, T:0.5305(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5512

ğŸ“Š EPOCH 152 TRAINING SUMMARY:
  Total Loss: 0.5522
  Contrastive: 5.5949
  Reconstruction: 0.0100
  Topological: 0.5512 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8142
  Contrastive: 4.4492
  Reconstruction: 0.0099
  Topological: 4.8132 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 152/300 COMPLETE (46.2s)
Train Loss: 0.5522 (C:5.5949, R:0.0100, T:0.5512)
Val Loss:   4.8142 (C:4.4492, R:0.0099, T:4.8132)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 153 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5310 (C:5.5880, R:0.0100, T:0.5300(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5280 (C:5.5448, R:0.0100, T:0.5271(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5326 (C:5.6223, R:0.0100, T:0.5316(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5493 (C:5.5290, R:0.0099, T:0.5483(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5352 (C:5.6488, R:0.0099, T:0.5342(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5562 (C:5.5558, R:0.0099, T:0.5552(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5372 (C:5.6395, R:0.0099, T:0.5362(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5583 (C:5.5713, R:0.0100, T:0.5574(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5640 (C:5.5860, R:0.0100, T:0.5630(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5702 (C:5.5706, R:0.0100, T:0.5692(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5418 (C:5.5848, R:0.0100, T:0.5408(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5679 (C:5.5743, R:0.0100, T:0.5669(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5523 (C:5.5580, R:0.0099, T:0.5513(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5427 (C:5.6220, R:0.0100, T:0.5417(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5466 (C:5.5957, R:0.0100, T:0.5456(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5442 (C:5.5671, R:0.0100, T:0.5432(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5503 (C:5.6475, R:0.0100, T:0.5493(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5203 (C:5.5892, R:0.0100, T:0.5193(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5554 (C:5.5864, R:0.0099, T:0.5544(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5615 (C:5.5757, R:0.0099, T:0.5605(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5511 (C:5.5902, R:0.0099, T:0.5502(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5484 (C:5.6138, R:0.0100, T:0.5474(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 153 TRAINING SUMMARY:
  Total Loss: 0.5535
  Contrastive: 5.5933
  Reconstruction: 0.0100
  Topological: 0.5525 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8853
  Contrastive: 4.4359
  Reconstruction: 0.0099
  Topological: 4.8843 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 153/300 COMPLETE (45.9s)
Train Loss: 0.5535 (C:5.5933, R:0.0100, T:0.5525)
Val Loss:   4.8853 (C:4.4359, R:0.0099, T:4.8843)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 154 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5458 (C:5.5490, R:0.0099, T:0.5449(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5750 (C:5.5579, R:0.0099, T:0.5740(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5349 (C:5.5946, R:0.0100, T:0.5339(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5671 (C:5.6028, R:0.0100, T:0.5661(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5413 (C:5.6035, R:0.0100, T:0.5403(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5632 (C:5.6076, R:0.0100, T:0.5622(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5527 (C:5.6237, R:0.0100, T:0.5517(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5550 (C:5.6003, R:0.0100, T:0.5540(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5422 (C:5.6501, R:0.0100, T:0.5412(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5506 (C:5.5750, R:0.0099, T:0.5496(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5288 (C:5.5825, R:0.0099, T:0.5278(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5569 (C:5.6389, R:0.0100, T:0.5559(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5366 (C:5.5537, R:0.0099, T:0.5356(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.6063 (C:5.6222, R:0.0100, T:0.6053(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5392 (C:5.5822, R:0.0100, T:0.5382(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5512 (C:5.6022, R:0.0099, T:0.5502(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5306 (C:5.6049, R:0.0100, T:0.5296(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5522 (C:5.5914, R:0.0099, T:0.5512(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5313 (C:5.6311, R:0.0100, T:0.5303(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5487 (C:5.5872, R:0.0100, T:0.5477(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5282 (C:5.5795, R:0.0100, T:0.5272(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5339 (C:5.6297, R:0.0099, T:0.5329(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 154 TRAINING SUMMARY:
  Total Loss: 0.5530
  Contrastive: 5.5938
  Reconstruction: 0.0100
  Topological: 0.5520 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8099
  Contrastive: 4.4540
  Reconstruction: 0.0099
  Topological: 4.8089 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 154/300 COMPLETE (45.9s)
Train Loss: 0.5530 (C:5.5938, R:0.0100, T:0.5520)
Val Loss:   4.8099 (C:4.4540, R:0.0099, T:4.8089)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 155 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5428 (C:5.6069, R:0.0100, T:0.5418(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5674 (C:5.5791, R:0.0100, T:0.5664(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5598 (C:5.5841, R:0.0099, T:0.5588(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5461 (C:5.5483, R:0.0099, T:0.5451(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5608 (C:5.6227, R:0.0100, T:0.5598(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5534 (C:5.5707, R:0.0099, T:0.5525(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5771 (C:5.6550, R:0.0100, T:0.5761(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5482 (C:5.5373, R:0.0099, T:0.5472(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5437 (C:5.6054, R:0.0099, T:0.5427(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5412 (C:5.5846, R:0.0099, T:0.5402(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5394 (C:5.5816, R:0.0099, T:0.5384(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5307 (C:5.6041, R:0.0100, T:0.5297(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5561 (C:5.5841, R:0.0099, T:0.5551(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5228 (C:5.5609, R:0.0099, T:0.5218(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5567 (C:5.6190, R:0.0100, T:0.5557(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5258 (C:5.5654, R:0.0099, T:0.5248(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5852 (C:5.6179, R:0.0100, T:0.5842(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5274 (C:5.5633, R:0.0100, T:0.5264(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5594 (C:5.5891, R:0.0100, T:0.5584(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5255 (C:5.5359, R:0.0099, T:0.5245(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5550 (C:5.6389, R:0.0100, T:0.5540(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5643 (C:5.5848, R:0.0100, T:0.5633(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 155 TRAINING SUMMARY:
  Total Loss: 0.5527
  Contrastive: 5.5933
  Reconstruction: 0.0100
  Topological: 0.5517 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.7586
  Contrastive: 4.4707
  Reconstruction: 0.0099
  Topological: 4.7576 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 155/300 COMPLETE (44.9s)
Train Loss: 0.5527 (C:5.5933, R:0.0100, T:0.5517)
Val Loss:   4.7586 (C:4.4707, R:0.0099, T:4.7576)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 156 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5460 (C:5.6223, R:0.0100, T:0.5450(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5270 (C:5.5914, R:0.0100, T:0.5260(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5961 (C:5.6081, R:0.0100, T:0.5951(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5597 (C:5.6128, R:0.0099, T:0.5587(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5858 (C:5.5873, R:0.0099, T:0.5848(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5569 (C:5.5701, R:0.0099, T:0.5559(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5597 (C:5.5914, R:0.0100, T:0.5587(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5441 (C:5.5512, R:0.0100, T:0.5431(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5496 (C:5.5936, R:0.0100, T:0.5486(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5709 (C:5.6177, R:0.0100, T:0.5699(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5681 (C:5.5721, R:0.0099, T:0.5671(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5762 (C:5.6328, R:0.0100, T:0.5752(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5410 (C:5.5879, R:0.0099, T:0.5400(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5614 (C:5.5982, R:0.0099, T:0.5604(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5579 (C:5.5878, R:0.0100, T:0.5569(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5273 (C:5.6424, R:0.0100, T:0.5263(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5631 (C:5.6531, R:0.0099, T:0.5621(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5549 (C:5.5655, R:0.0099, T:0.5539(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5674 (C:5.6023, R:0.0100, T:0.5664(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5724 (C:5.5853, R:0.0100, T:0.5714(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5439 (C:5.5793, R:0.0099, T:0.5429(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5527 (C:5.5558, R:0.0100, T:0.5517(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 156 TRAINING SUMMARY:
  Total Loss: 0.5541
  Contrastive: 5.5945
  Reconstruction: 0.0100
  Topological: 0.5531 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8416
  Contrastive: 4.4482
  Reconstruction: 0.0099
  Topological: 4.8406 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 156/300 COMPLETE (43.8s)
Train Loss: 0.5541 (C:5.5945, R:0.0100, T:0.5531)
Val Loss:   4.8416 (C:4.4482, R:0.0099, T:4.8406)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 157 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5423 (C:5.6058, R:0.0100, T:0.5413(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5470 (C:5.5695, R:0.0099, T:0.5460(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5390 (C:5.6019, R:0.0100, T:0.5380(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5875 (C:5.6188, R:0.0100, T:0.5865(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5663 (C:5.5836, R:0.0099, T:0.5653(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5418 (C:5.5796, R:0.0099, T:0.5408(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5552 (C:5.5821, R:0.0100, T:0.5542(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5585 (C:5.6168, R:0.0100, T:0.5575(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5297 (C:5.6097, R:0.0099, T:0.5287(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5448 (C:5.5834, R:0.0100, T:0.5438(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5281 (C:5.6056, R:0.0100, T:0.5271(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5431 (C:5.5973, R:0.0099, T:0.5421(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5636 (C:5.5924, R:0.0099, T:0.5626(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5306 (C:5.6261, R:0.0099, T:0.5296(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5451 (C:5.6035, R:0.0099, T:0.5441(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5507 (C:5.6060, R:0.0100, T:0.5497(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5866 (C:5.6210, R:0.0099, T:0.5857(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5500 (C:5.5879, R:0.0100, T:0.5490(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5375 (C:5.6076, R:0.0100, T:0.5365(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5467 (C:5.5630, R:0.0100, T:0.5457(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5337 (C:5.5691, R:0.0100, T:0.5327(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5620 (C:5.6241, R:0.0100, T:0.5610(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 157 TRAINING SUMMARY:
  Total Loss: 0.5535
  Contrastive: 5.5942
  Reconstruction: 0.0100
  Topological: 0.5525 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.7552
  Contrastive: 4.4519
  Reconstruction: 0.0099
  Topological: 4.7542 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 157/300 COMPLETE (45.3s)
Train Loss: 0.5535 (C:5.5942, R:0.0100, T:0.5525)
Val Loss:   4.7552 (C:4.4519, R:0.0099, T:4.7542)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 158 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5944 (C:5.5769, R:0.0099, T:0.5934(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5297 (C:5.6359, R:0.0100, T:0.5287(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5367 (C:5.5966, R:0.0099, T:0.5357(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5452 (C:5.5993, R:0.0100, T:0.5442(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5364 (C:5.5590, R:0.0100, T:0.5354(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5484 (C:5.5748, R:0.0099, T:0.5474(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5706 (C:5.6383, R:0.0100, T:0.5696(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5843 (C:5.6118, R:0.0099, T:0.5833(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5452 (C:5.5758, R:0.0099, T:0.5443(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5705 (C:5.6083, R:0.0100, T:0.5695(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5710 (C:5.5881, R:0.0100, T:0.5700(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5399 (C:5.6228, R:0.0099, T:0.5390(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5582 (C:5.5482, R:0.0100, T:0.5572(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5495 (C:5.6043, R:0.0100, T:0.5485(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5497 (C:5.6172, R:0.0100, T:0.5487(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5463 (C:5.5651, R:0.0099, T:0.5453(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5666 (C:5.5485, R:0.0099, T:0.5656(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5324 (C:5.6095, R:0.0100, T:0.5314(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5485 (C:5.6017, R:0.0099, T:0.5475(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5882 (C:5.5738, R:0.0100, T:0.5872(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5671 (C:5.5807, R:0.0099, T:0.5661(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5248 (C:5.5989, R:0.0100, T:0.5238(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 158 TRAINING SUMMARY:
  Total Loss: 0.5531
  Contrastive: 5.5950
  Reconstruction: 0.0100
  Topological: 0.5521 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.7764
  Contrastive: 4.4653
  Reconstruction: 0.0099
  Topological: 4.7754 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 158/300 COMPLETE (45.2s)
Train Loss: 0.5531 (C:5.5950, R:0.0100, T:0.5521)
Val Loss:   4.7764 (C:4.4653, R:0.0099, T:4.7754)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 159 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5608 (C:5.6212, R:0.0100, T:0.5598(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5453 (C:5.6058, R:0.0100, T:0.5443(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5305 (C:5.5567, R:0.0100, T:0.5295(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5692 (C:5.6107, R:0.0100, T:0.5682(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5373 (C:5.6126, R:0.0100, T:0.5363(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5713 (C:5.6449, R:0.0100, T:0.5703(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5492 (C:5.5903, R:0.0100, T:0.5482(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5308 (C:5.5739, R:0.0100, T:0.5298(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5394 (C:5.5636, R:0.0099, T:0.5384(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5711 (C:5.6153, R:0.0099, T:0.5701(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5758 (C:5.5732, R:0.0099, T:0.5748(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5597 (C:5.5658, R:0.0100, T:0.5587(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5454 (C:5.6189, R:0.0100, T:0.5444(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5353 (C:5.5665, R:0.0100, T:0.5343(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5264 (C:5.5923, R:0.0099, T:0.5254(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5578 (C:5.6462, R:0.0100, T:0.5568(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5878 (C:5.6114, R:0.0100, T:0.5868(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5716 (C:5.6043, R:0.0100, T:0.5706(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5413 (C:5.5813, R:0.0099, T:0.5404(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5686 (C:5.6052, R:0.0100, T:0.5676(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5370 (C:5.6426, R:0.0100, T:0.5360(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5742 (C:5.5663, R:0.0099, T:0.5732(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 159 TRAINING SUMMARY:
  Total Loss: 0.5528
  Contrastive: 5.5936
  Reconstruction: 0.0100
  Topological: 0.5519 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.7431
  Contrastive: 4.4600
  Reconstruction: 0.0099
  Topological: 4.7421 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 159/300 COMPLETE (44.4s)
Train Loss: 0.5528 (C:5.5936, R:0.0100, T:0.5519)
Val Loss:   4.7431 (C:4.4600, R:0.0099, T:4.7421)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 160 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5275 (C:5.6136, R:0.0099, T:0.5265(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5441 (C:5.5800, R:0.0099, T:0.5432(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5471 (C:5.6623, R:0.0099, T:0.5461(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5261 (C:5.5889, R:0.0099, T:0.5251(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5466 (C:5.5666, R:0.0099, T:0.5456(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5365 (C:5.5749, R:0.0100, T:0.5355(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5229 (C:5.5852, R:0.0100, T:0.5219(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5740 (C:5.5975, R:0.0099, T:0.5730(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5717 (C:5.6017, R:0.0099, T:0.5707(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5653 (C:5.5965, R:0.0099, T:0.5643(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5519 (C:5.6125, R:0.0099, T:0.5509(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5661 (C:5.6313, R:0.0100, T:0.5651(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5520 (C:5.6237, R:0.0099, T:0.5510(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5532 (C:5.5793, R:0.0099, T:0.5522(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5461 (C:5.5893, R:0.0099, T:0.5451(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5440 (C:5.5765, R:0.0100, T:0.5430(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5378 (C:5.6188, R:0.0099, T:0.5368(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5581 (C:5.6068, R:0.0099, T:0.5571(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5639 (C:5.6146, R:0.0099, T:0.5629(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5583 (C:5.5788, R:0.0099, T:0.5573(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5367 (C:5.6111, R:0.0099, T:0.5357(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5640 (C:5.5645, R:0.0099, T:0.5630(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 160 TRAINING SUMMARY:
  Total Loss: 0.5527
  Contrastive: 5.5962
  Reconstruction: 0.0100
  Topological: 0.5517 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8379
  Contrastive: 4.4413
  Reconstruction: 0.0099
  Topological: 4.8370 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 160/300 COMPLETE (45.9s)
Train Loss: 0.5527 (C:5.5962, R:0.0100, T:0.5517)
Val Loss:   4.8379 (C:4.4413, R:0.0099, T:4.8370)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 161 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5423 (C:5.5693, R:0.0099, T:0.5413(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5588 (C:5.6335, R:0.0100, T:0.5578(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5487 (C:5.5800, R:0.0099, T:0.5477(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5491 (C:5.5732, R:0.0099, T:0.5481(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5741 (C:5.5341, R:0.0099, T:0.5732(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5620 (C:5.5352, R:0.0100, T:0.5610(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5704 (C:5.6046, R:0.0099, T:0.5694(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5286 (C:5.5951, R:0.0100, T:0.5276(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5770 (C:5.5967, R:0.0100, T:0.5760(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5379 (C:5.5670, R:0.0099, T:0.5369(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5452 (C:5.5946, R:0.0100, T:0.5442(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5410 (C:5.6012, R:0.0100, T:0.5400(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5440 (C:5.6129, R:0.0100, T:0.5430(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5467 (C:5.5321, R:0.0100, T:0.5457(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5658 (C:5.5757, R:0.0099, T:0.5649(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5694 (C:5.5639, R:0.0100, T:0.5684(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5229 (C:5.6111, R:0.0099, T:0.5219(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5315 (C:5.5923, R:0.0100, T:0.5305(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5310 (C:5.6028, R:0.0100, T:0.5300(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5674 (C:5.5886, R:0.0099, T:0.5664(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5263 (C:5.5574, R:0.0099, T:0.5253(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5546 (C:5.5971, R:0.0100, T:0.5536(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 161 TRAINING SUMMARY:
  Total Loss: 0.5531
  Contrastive: 5.5944
  Reconstruction: 0.0100
  Topological: 0.5521 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8232
  Contrastive: 4.4296
  Reconstruction: 0.0099
  Topological: 4.8222 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 161/300 COMPLETE (45.1s)
Train Loss: 0.5531 (C:5.5944, R:0.0100, T:0.5521)
Val Loss:   4.8232 (C:4.4296, R:0.0099, T:4.8222)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 162 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5441 (C:5.5720, R:0.0099, T:0.5431(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5312 (C:5.5865, R:0.0100, T:0.5302(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5602 (C:5.5873, R:0.0099, T:0.5592(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5429 (C:5.5647, R:0.0100, T:0.5419(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5679 (C:5.5682, R:0.0099, T:0.5669(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5229 (C:5.6096, R:0.0099, T:0.5219(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5492 (C:5.5741, R:0.0100, T:0.5482(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5481 (C:5.6795, R:0.0100, T:0.5471(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5285 (C:5.5592, R:0.0099, T:0.5275(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5310 (C:5.5893, R:0.0099, T:0.5300(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5336 (C:5.6210, R:0.0100, T:0.5326(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5958 (C:5.5843, R:0.0100, T:0.5948(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5614 (C:5.5559, R:0.0099, T:0.5604(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5522 (C:5.6034, R:0.0100, T:0.5512(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5699 (C:5.5706, R:0.0100, T:0.5689(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5466 (C:5.5880, R:0.0100, T:0.5456(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5859 (C:5.6352, R:0.0100, T:0.5849(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5481 (C:5.5727, R:0.0100, T:0.5471(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5573 (C:5.5943, R:0.0100, T:0.5563(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5265 (C:5.5980, R:0.0100, T:0.5255(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5382 (C:5.5399, R:0.0100, T:0.5372(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5537 (C:5.5978, R:0.0100, T:0.5527(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 162 TRAINING SUMMARY:
  Total Loss: 0.5535
  Contrastive: 5.5950
  Reconstruction: 0.0100
  Topological: 0.5525 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8940
  Contrastive: 4.4340
  Reconstruction: 0.0099
  Topological: 4.8930 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 162/300 COMPLETE (44.4s)
Train Loss: 0.5535 (C:5.5950, R:0.0100, T:0.5525)
Val Loss:   4.8940 (C:4.4340, R:0.0099, T:4.8930)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 163 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5676 (C:5.5665, R:0.0100, T:0.5666(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5662 (C:5.5972, R:0.0100, T:0.5652(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5442 (C:5.6017, R:0.0099, T:0.5432(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5990 (C:5.5406, R:0.0100, T:0.5980(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5664 (C:5.6261, R:0.0100, T:0.5654(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5656 (C:5.5897, R:0.0100, T:0.5646(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5480 (C:5.5913, R:0.0100, T:0.5470(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5370 (C:5.5795, R:0.0100, T:0.5360(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5571 (C:5.5503, R:0.0099, T:0.5561(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5439 (C:5.6140, R:0.0099, T:0.5429(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5251 (C:5.6278, R:0.0099, T:0.5241(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5550 (C:5.5651, R:0.0100, T:0.5540(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5870 (C:5.6283, R:0.0100, T:0.5860(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5436 (C:5.5361, R:0.0100, T:0.5426(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5475 (C:5.5937, R:0.0099, T:0.5465(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5419 (C:5.5333, R:0.0100, T:0.5409(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5313 (C:5.5930, R:0.0099, T:0.5303(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5578 (C:5.5841, R:0.0099, T:0.5568(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5435 (C:5.5874, R:0.0099, T:0.5425(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5628 (C:5.5971, R:0.0099, T:0.5618(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5362 (C:5.6195, R:0.0099, T:0.5352(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5622 (C:5.6316, R:0.0100, T:0.5612(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 163 TRAINING SUMMARY:
  Total Loss: 0.5523
  Contrastive: 5.5942
  Reconstruction: 0.0100
  Topological: 0.5513 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8984
  Contrastive: 4.4154
  Reconstruction: 0.0099
  Topological: 4.8974 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 163/300 COMPLETE (45.6s)
Train Loss: 0.5523 (C:5.5942, R:0.0100, T:0.5513)
Val Loss:   4.8984 (C:4.4154, R:0.0099, T:4.8974)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 164 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5609 (C:5.5372, R:0.0099, T:0.5599(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5739 (C:5.5706, R:0.0100, T:0.5729(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5541 (C:5.6022, R:0.0100, T:0.5531(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5629 (C:5.6065, R:0.0100, T:0.5619(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5697 (C:5.5775, R:0.0099, T:0.5688(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5631 (C:5.6138, R:0.0100, T:0.5621(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5578 (C:5.5247, R:0.0099, T:0.5568(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5544 (C:5.6340, R:0.0100, T:0.5534(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5555 (C:5.5772, R:0.0100, T:0.5545(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5567 (C:5.6022, R:0.0100, T:0.5557(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5510 (C:5.6443, R:0.0100, T:0.5500(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5742 (C:5.6323, R:0.0099, T:0.5732(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5507 (C:5.5205, R:0.0100, T:0.5497(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5406 (C:5.6135, R:0.0099, T:0.5396(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5567 (C:5.5666, R:0.0099, T:0.5557(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5532 (C:5.5945, R:0.0100, T:0.5522(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5446 (C:5.5946, R:0.0100, T:0.5436(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5545 (C:5.6090, R:0.0100, T:0.5535(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5320 (C:5.5898, R:0.0100, T:0.5310(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5344 (C:5.5751, R:0.0099, T:0.5334(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5516 (C:5.5834, R:0.0100, T:0.5506(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5728 (C:5.5941, R:0.0100, T:0.5718(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 164 TRAINING SUMMARY:
  Total Loss: 0.5531
  Contrastive: 5.5955
  Reconstruction: 0.0100
  Topological: 0.5521 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8483
  Contrastive: 4.4314
  Reconstruction: 0.0099
  Topological: 4.8473 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 164/300 COMPLETE (45.7s)
Train Loss: 0.5531 (C:5.5955, R:0.0100, T:0.5521)
Val Loss:   4.8483 (C:4.4314, R:0.0099, T:4.8473)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 165 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5497 (C:5.5529, R:0.0100, T:0.5487(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5471 (C:5.6748, R:0.0100, T:0.5461(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5615 (C:5.5614, R:0.0099, T:0.5605(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5566 (C:5.5975, R:0.0100, T:0.5556(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5633 (C:5.5925, R:0.0100, T:0.5623(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5613 (C:5.6007, R:0.0099, T:0.5603(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5339 (C:5.5931, R:0.0100, T:0.5329(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5661 (C:5.6210, R:0.0100, T:0.5651(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5615 (C:5.6530, R:0.0100, T:0.5605(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5386 (C:5.5686, R:0.0099, T:0.5376(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5601 (C:5.6331, R:0.0100, T:0.5591(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5781 (C:5.5767, R:0.0100, T:0.5771(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5294 (C:5.5933, R:0.0099, T:0.5284(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5168 (C:5.5969, R:0.0099, T:0.5158(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5221 (C:5.6307, R:0.0099, T:0.5211(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5603 (C:5.5368, R:0.0100, T:0.5593(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5557 (C:5.6122, R:0.0099, T:0.5547(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5336 (C:5.5742, R:0.0099, T:0.5326(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5748 (C:5.5813, R:0.0099, T:0.5738(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5673 (C:5.6009, R:0.0100, T:0.5663(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5536 (C:5.6027, R:0.0100, T:0.5526(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5721 (C:5.6163, R:0.0099, T:0.5711(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 165 TRAINING SUMMARY:
  Total Loss: 0.5530
  Contrastive: 5.5956
  Reconstruction: 0.0100
  Topological: 0.5521 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.9500
  Contrastive: 4.4179
  Reconstruction: 0.0099
  Topological: 4.9490 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 165/300 COMPLETE (45.0s)
Train Loss: 0.5530 (C:5.5956, R:0.0100, T:0.5521)
Val Loss:   4.9500 (C:4.4179, R:0.0099, T:4.9490)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 166 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5591 (C:5.5443, R:0.0100, T:0.5581(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5520 (C:5.6516, R:0.0099, T:0.5510(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5750 (C:5.5946, R:0.0099, T:0.5740(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5367 (C:5.5897, R:0.0099, T:0.5357(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5448 (C:5.5839, R:0.0099, T:0.5438(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5570 (C:5.6001, R:0.0099, T:0.5560(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5688 (C:5.5491, R:0.0099, T:0.5678(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5600 (C:5.6141, R:0.0100, T:0.5590(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5458 (C:5.5896, R:0.0100, T:0.5448(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5472 (C:5.5874, R:0.0100, T:0.5462(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5479 (C:5.5949, R:0.0100, T:0.5469(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5694 (C:5.6471, R:0.0100, T:0.5684(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5676 (C:5.5978, R:0.0100, T:0.5666(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5520 (C:5.6030, R:0.0099, T:0.5510(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5135 (C:5.6184, R:0.0100, T:0.5125(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5488 (C:5.5739, R:0.0100, T:0.5478(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5434 (C:5.6297, R:0.0100, T:0.5424(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5557 (C:5.5764, R:0.0099, T:0.5547(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5560 (C:5.6132, R:0.0100, T:0.5550(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5438 (C:5.6133, R:0.0099, T:0.5428(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5401 (C:5.5680, R:0.0100, T:0.5391(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5872 (C:5.6510, R:0.0100, T:0.5862(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 166 TRAINING SUMMARY:
  Total Loss: 0.5531
  Contrastive: 5.5935
  Reconstruction: 0.0100
  Topological: 0.5521 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8000
  Contrastive: 4.4623
  Reconstruction: 0.0099
  Topological: 4.7990 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 166/300 COMPLETE (45.5s)
Train Loss: 0.5531 (C:5.5935, R:0.0100, T:0.5521)
Val Loss:   4.8000 (C:4.4623, R:0.0099, T:4.7990)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 167 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5598 (C:5.6203, R:0.0100, T:0.5588(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5458 (C:5.6176, R:0.0100, T:0.5448(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5653 (C:5.5684, R:0.0100, T:0.5643(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5634 (C:5.6113, R:0.0099, T:0.5624(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5845 (C:5.6057, R:0.0100, T:0.5835(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5738 (C:5.6182, R:0.0099, T:0.5728(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5356 (C:5.5900, R:0.0100, T:0.5346(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5515 (C:5.5778, R:0.0099, T:0.5505(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5546 (C:5.5987, R:0.0100, T:0.5536(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5325 (C:5.5852, R:0.0099, T:0.5315(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5349 (C:5.5950, R:0.0099, T:0.5339(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5420 (C:5.6546, R:0.0100, T:0.5410(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5191 (C:5.5735, R:0.0100, T:0.5181(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5607 (C:5.5667, R:0.0100, T:0.5597(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5823 (C:5.6228, R:0.0100, T:0.5813(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5467 (C:5.6292, R:0.0100, T:0.5457(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5337 (C:5.6135, R:0.0100, T:0.5327(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5419 (C:5.5747, R:0.0099, T:0.5409(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5473 (C:5.6912, R:0.0100, T:0.5463(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5431 (C:5.5775, R:0.0100, T:0.5421(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5278 (C:5.5799, R:0.0100, T:0.5268(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5659 (C:5.5999, R:0.0099, T:0.5649(w:1.000)ğŸ‰)
ğŸ“ˆ New best topological loss: 0.5495

ğŸ“Š EPOCH 167 TRAINING SUMMARY:
  Total Loss: 0.5505
  Contrastive: 5.5959
  Reconstruction: 0.0100
  Topological: 0.5495 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.7312
  Contrastive: 4.4565
  Reconstruction: 0.0099
  Topological: 4.7302 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 167/300 COMPLETE (46.3s)
Train Loss: 0.5505 (C:5.5959, R:0.0100, T:0.5495)
Val Loss:   4.7312 (C:4.4565, R:0.0099, T:4.7302)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

============================================================
EPOCH 168 | Batches: 537 | Topological Weight: 1.0000
ğŸ§  Full topological learning active
============================================================
Batch   0/537: Loss=0.5653 (C:5.5827, R:0.0099, T:0.5643(w:1.000)ğŸ‰)
Batch  25/537: Loss=0.5620 (C:5.6137, R:0.0099, T:0.5610(w:1.000)ğŸ‰)
Batch  50/537: Loss=0.5529 (C:5.6140, R:0.0100, T:0.5519(w:1.000)ğŸ‰)
Batch  75/537: Loss=0.5942 (C:5.5980, R:0.0099, T:0.5932(w:1.000)ğŸ‰)
Batch 100/537: Loss=0.5382 (C:5.6266, R:0.0100, T:0.5372(w:1.000)ğŸ‰)
Batch 125/537: Loss=0.5710 (C:5.6101, R:0.0100, T:0.5700(w:1.000)ğŸ‰)
Batch 150/537: Loss=0.5414 (C:5.5780, R:0.0100, T:0.5404(w:1.000)ğŸ‰)
Batch 175/537: Loss=0.5147 (C:5.6466, R:0.0100, T:0.5137(w:1.000)ğŸ‰)
Batch 200/537: Loss=0.5329 (C:5.5911, R:0.0100, T:0.5319(w:1.000)ğŸ‰)
Batch 225/537: Loss=0.5522 (C:5.6253, R:0.0100, T:0.5512(w:1.000)ğŸ‰)
Batch 250/537: Loss=0.5701 (C:5.5601, R:0.0099, T:0.5691(w:1.000)ğŸ‰)
Batch 275/537: Loss=0.5417 (C:5.5931, R:0.0100, T:0.5407(w:1.000)ğŸ‰)
Batch 300/537: Loss=0.5258 (C:5.5894, R:0.0099, T:0.5248(w:1.000)ğŸ‰)
Batch 325/537: Loss=0.5096 (C:5.6256, R:0.0099, T:0.5086(w:1.000)ğŸ‰)
Batch 350/537: Loss=0.5598 (C:5.6053, R:0.0099, T:0.5588(w:1.000)ğŸ‰)
Batch 375/537: Loss=0.5446 (C:5.5446, R:0.0100, T:0.5436(w:1.000)ğŸ‰)
Batch 400/537: Loss=0.5595 (C:5.6023, R:0.0099, T:0.5585(w:1.000)ğŸ‰)
Batch 425/537: Loss=0.5587 (C:5.6365, R:0.0100, T:0.5577(w:1.000)ğŸ‰)
Batch 450/537: Loss=0.5744 (C:5.5615, R:0.0100, T:0.5734(w:1.000)ğŸ‰)
Batch 475/537: Loss=0.5460 (C:5.6129, R:0.0100, T:0.5450(w:1.000)ğŸ‰)
Batch 500/537: Loss=0.5567 (C:5.5849, R:0.0099, T:0.5557(w:1.000)ğŸ‰)
Batch 525/537: Loss=0.5775 (C:5.6246, R:0.0100, T:0.5766(w:1.000)ğŸ‰)

ğŸ“Š EPOCH 168 TRAINING SUMMARY:
  Total Loss: 0.5511
  Contrastive: 5.5950
  Reconstruction: 0.0100
  Topological: 0.5501 (weight: 1.000)
  Batches with topology: 537/537 (100.0%)

ğŸ“Š VALIDATION SUMMARY:
  Total Loss: 4.8008
  Contrastive: 4.4575
  Reconstruction: 0.0099
  Topological: 4.7998 (weight: 1.000)
  Batches with topology: 9/9 (100.0%)

ğŸ¯ EPOCH 168/300 COMPLETE (44.8s)
Train Loss: 0.5511 (C:5.5950, R:0.0100, T:0.5501)
Val Loss:   4.8008 (C:4.4575, R:0.0099, T:4.7998)
ğŸ‰ Topological complexity detected!
------------------------------------------------------------

ğŸ›‘ Early stopping triggered after 168 epochs
Best model was at epoch 148 with Val Loss: 4.7021

======================================================================
ğŸ“ˆ FINAL TOPOLOGICAL LEARNING ANALYSIS
======================================================================
First topological learning: Epoch 1
Epochs with topology: 168/168
Max consecutive topology epochs: 168
Best topological loss: 0.5495
Final topological loss: 0.5501
âœ… SUCCESS: Topological learning achieved!
ğŸš€ EXCELLENT: Very consistent topological learning (>80%)
ğŸ“ˆ Topological learning appears stable

======================================================================
ğŸ¯ TOPOLOGICAL AUTOENCODER TRAINING COMPLETED
======================================================================
âœ… Topological training completed successfully!
Saving results...
Loading best model from entailment_surfaces/supervised_contrastive_autoencoder/experiments/topological_autoencoder_torchph_phase1_20250722_115437/checkpoints/best_model.pt
Starting model evaluation...
========================================
GlobalContrastiveEvaluator initialized on cuda
Starting comprehensive evaluation...
============================================================
Extracting latent representations...
  Processed 1/10 batches
Extracted representations: torch.Size([9824, 100])
Evaluating clustering performance...
Clustering Results:
  Silhouette Score: 0.0007
  Adjusted Rand Score: 0.0004
  Clustering Accuracy: 0.3473
Evaluating classification performance...
  Extracting training representations...
Extracting latent representations...
  Processed 1/537 batches
  Processed 51/537 batches
  Processed 101/537 batches
  Processed 151/537 batches
  Processed 201/537 batches
  Processed 251/537 batches
  Processed 301/537 batches
  Processed 351/537 batches
  Processed 401/537 batches
  Processed 451/537 batches
  Processed 501/537 batches
Extracted representations: torch.Size([547740, 100])
  Extracting validation representations...
Extracting latent representations...
  Processed 1/9 batches
Extracted representations: torch.Size([9180, 100])
Subsampled training to 50000 samples
  Training on 50000 samples, evaluating on 9180 samples
Classification Results:
  Accuracy: 0.5233
  Per-class F1: [0.5637319316688568, 0.44200788076066466, 0.5572969672297986]
Evaluating reconstruction quality...
Reconstruction Results:
  Average MSE: 0.009862
Evaluating separation quality...
Separation Results:
  Positive distances: 4.455 Â± 0.425
  Negative distances: 4.474 Â± 0.415
  Separation ratio: 1.00x
  Gap: -5.906
  Perfect separation: No

Comprehensive evaluation completed!

============================================================
EVALUATION SUMMARY
============================================================
Clustering Performance:
  Silhouette Score: 0.0007
  Clustering Accuracy: 0.3473
  Adjusted Rand Score: 0.0004

Classification Performance:
  Accuracy: 0.5233

Separation Quality:
  Separation Ratio: 1.00x
  Gap: -5.906
  Perfect Separation: False

Reconstruction Quality:
  Average MSE: 0.009862
============================================================
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/topological_autoencoder_torchph_phase1_20250722_115437/results/evaluation_results_20250722_140142.json
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/topological_autoencoder_torchph_phase1_20250722_115437/results/evaluation_results_20250722_140142.json

Key Results:
  Separation ratio: 1.00x
  Perfect separation: False
  Classification accuracy: 0.5233

============================================================
TOPOLOGICAL TRAINING ANALYSIS
============================================================

ğŸ“ˆ TOPOLOGICAL LEARNING DIAGNOSIS:
  Total epochs: 168
  Epochs with topological learning: 168
  Current topological loss: 0.5501
  Current topological weight: 1.0000
  âœ… Topological loss is decreasing (good progress)
ğŸš€ EXCELLENT: Consistent topological learning achieved!
Final topological loss: 0.5501
Epochs with topology: 168/168
âš ï¸  Poor clustering accuracy: 0.347

Final analysis saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/topological_autoencoder_torchph_phase1_20250722_115437/results/final_analysis.json
Experiment saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/topological_autoencoder_torchph_phase1_20250722_115437

Analysis completed with exit code: 0
Time: Tue 22 Jul 14:01:44 BST 2025

=== ANALYSIS SUCCESSFUL ===
Regularization successful!


Job finished.
