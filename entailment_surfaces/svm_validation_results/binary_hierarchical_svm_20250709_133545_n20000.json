{
  "timestamp": "20250709_133545",
  "experiment_config": {
    "approach": "hierarchical_classification",
    "sample_size": 20000,
    "embedding_space": "lattice_containment",
    "method": "binary_svm_with_thresholds",
    "test_size": 0.2,
    "random_state": 42
  },
  "thresholds": {
    "entailment_threshold": -0.8468014897537195,
    "contradiction_threshold": 0.8665345338837573
  },
  "performance_metrics": {
    "test_accuracy": 0.6225,
    "confusion_matrix": [
      [
        817,
        503,
        17
      ],
      [
        320,
        826,
        176
      ],
      [
        56,
        438,
        847
      ]
    ],
    "classification_report": {
      "Entailment": {
        "precision": 0.6848281642917016,
        "recall": 0.6110695587135377,
        "f1-score": 0.6458498023715415,
        "support": 1337.0
      },
      "Neutral": {
        "precision": 0.46745897000565934,
        "recall": 0.6248108925869894,
        "f1-score": 0.5348009064422143,
        "support": 1322.0
      },
      "Contradiction": {
        "precision": 0.8144230769230769,
        "recall": 0.6316181953765846,
        "f1-score": 0.7114657706845863,
        "support": 1341.0
      },
      "accuracy": 0.6225,
      "macro avg": {
        "precision": 0.6555700704068126,
        "recall": 0.6224995488923706,
        "f1-score": 0.630705493166114,
        "support": 4000.0
      },
      "weighted avg": {
        "precision": 0.6564343400398331,
        "recall": 0.6225,
        "f1-score": 0.631145895643847,
        "support": 4000.0
      }
    }
  },
  "entailment_scores_stats": {
    "mean": 0.034187090458766466,
    "std": 1.2762777481952645,
    "min": -2.6408353246060967,
    "max": 3.6977062204524485,
    "range": 6.338541545058545
  }
}