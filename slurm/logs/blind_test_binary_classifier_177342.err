INFO:__main__:Initializing blind test evaluator on cuda
INFO:__main__:Loading models from results/overnight_binary_hyperparam_search_normalizer/final_binary_model
INFO:__main__:Loading binary_model_fold_1...
/homes/ahb24/MSc_Topology_Codebase/classifiers/evaluate_blind_test.py:96: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(model_file, map_location=self.device)
INFO:__main__:binary_model_fold_1 loaded (input_dim=14, val_acc=79.23%)
INFO:__main__:Loading binary_model_fold_2...
INFO:__main__:binary_model_fold_2 loaded (input_dim=14, val_acc=79.33%)
INFO:__main__:Loading binary_model_fold_3...
INFO:__main__:binary_model_fold_3 loaded (input_dim=14, val_acc=78.98%)
INFO:__main__:Loading binary_model_fold_4...
INFO:__main__:binary_model_fold_4 loaded (input_dim=14, val_acc=79.48%)
INFO:__main__:Loading binary_model_fold_5...
INFO:__main__:binary_model_fold_5 loaded (input_dim=14, val_acc=79.33%)
INFO:__main__:Loaded 5 models successfully
INFO:__main__:================================================================================
INFO:__main__:STARTING BLIND TEST EVALUATION
INFO:__main__:================================================================================
INFO:__main__:Loading blind test data from blind_tests/snli_10k_test_asymmetry_input.pt
/homes/ahb24/MSc_Topology_Codebase/classifiers/evaluate_blind_test.py:141: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  blind_data = torch.load(blind_data_path, map_location='cpu')
INFO:__main__:Loaded blind test data:
INFO:__main__:  - Samples: 9786
INFO:__main__:  - Features: 14D
INFO:__main__:  - Feature type: geometric+tda
INFO:__main__:  - Entailment: 3330 (34.0%)
INFO:__main__:  - Non-entailment: 6456 (66.0%)
WARNING:__main__:No saved normalizer found - using approximation
INFO:__main__:
Evaluating binary_model_fold_1...
INFO:__main__:  Accuracy: 0.7204 (72.04%)
INFO:__main__:  F1-Macro: 0.7061
INFO:__main__:  ROC-AUC:  0.7932
INFO:__main__:
Evaluating binary_model_fold_2...
INFO:__main__:  Accuracy: 0.7320 (73.20%)
INFO:__main__:  F1-Macro: 0.7126
INFO:__main__:  ROC-AUC:  0.7930
INFO:__main__:
Evaluating binary_model_fold_3...
INFO:__main__:  Accuracy: 0.7329 (73.29%)
INFO:__main__:  F1-Macro: 0.7130
INFO:__main__:  ROC-AUC:  0.7929
INFO:__main__:
Evaluating binary_model_fold_4...
INFO:__main__:  Accuracy: 0.7172 (71.72%)
INFO:__main__:  F1-Macro: 0.7043
INFO:__main__:  ROC-AUC:  0.7930
INFO:__main__:
Evaluating binary_model_fold_5...
INFO:__main__:  Accuracy: 0.7253 (72.53%)
INFO:__main__:  F1-Macro: 0.7094
INFO:__main__:  ROC-AUC:  0.7932
INFO:__main__:
Evaluating ensemble...
INFO:__main__:Evaluating ensemble of all models...
INFO:__main__:  Accuracy: 0.7251 (72.51%)
INFO:__main__:  F1-Macro: 0.7091
INFO:__main__:  ROC-AUC:  0.7934
INFO:__main__:
================================================================================
INFO:__main__:BLIND TEST EVALUATION SUMMARY
INFO:__main__:================================================================================
INFO:__main__:
Individual Fold Results:
INFO:__main__:  Mean Accuracy: 0.7256 ± 0.0062
INFO:__main__:  Range: 0.7172 - 0.7329
INFO:__main__:  Mean F1-Macro: 0.7091 ± 0.0035
INFO:__main__:
Per-Fold Details:
INFO:__main__:  Fold 1: Acc=0.7204, F1=0.7061, AUC=0.7932
INFO:__main__:  Fold 2: Acc=0.7320, F1=0.7126, AUC=0.7930
INFO:__main__:  Fold 3: Acc=0.7329, F1=0.7130, AUC=0.7929
INFO:__main__:  Fold 4: Acc=0.7172, F1=0.7043, AUC=0.7930
INFO:__main__:  Fold 5: Acc=0.7253, F1=0.7094, AUC=0.7932
INFO:__main__:
Ensemble Results:
INFO:__main__:  Accuracy: 0.7251 (72.51%)
INFO:__main__:  F1-Macro: 0.7091
INFO:__main__:  F1-Weighted: 0.7309
INFO:__main__:  Precision: 0.7058
INFO:__main__:  Recall: 0.7240
INFO:__main__:  ROC-AUC: 0.7934
INFO:__main__:
==================================================
INFO:__main__:PERFORMANCE COMPARISON
INFO:__main__:==================================================
INFO:__main__:Training Accuracy (CV): 79.27%
INFO:__main__:Blind Test Accuracy:    72.56%
INFO:__main__:Generalization Gap:     +6.71%
WARNING:__main__:⚠ ATTENTION: Large generalization gap - investigate!
INFO:__main__:Ensemble Improvement:   -0.04%
INFO:__main__:Results saved to results/overnight_binary_hyperparm_search_normalizer/blind_evaluation
INFO:__main__:
Blind test evaluation completed successfully!
