INFO:__main__:Using default configuration
INFO:__main__:Saved config to results/overnight_normal_hyperparam_search/training_config.json
INFO:__main__:
Loading data from results/tda_integration/landmark_tda_features/neural_network_features_snli_10k.pt
INFO:neural_classifier_landmark:Loading classifier data from results/tda_integration/landmark_tda_features/neural_network_features_snli_10k.pt...
/homes/ahb24/MSc_Topology_Codebase/classifiers/neural_classifier_landmark.py:163: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(data_path, map_location='cpu')
INFO:neural_classifier_landmark:Successfully loaded 9990 samples.
INFO:__main__:Loaded 9990 samples with 7 features each.
INFO:__main__:Running hyperparameter search with up to 50 combinations
INFO:__main__:
======================================================================
INFO:__main__:STARTING HYPERPARAMETER SEARCH
INFO:__main__:======================================================================
INFO:__main__:Random search: 50 combinations (max: 50)
INFO:__main__:Total hyperparameter combinations to test: 50
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 1/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 1e-05, 'batch_size': 256, 'dropout_rate': 0.5, 'weight_decay': 0.0001}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.5248 | Val Loss: 1.1099 | Train Acc: 33.51% | Val Acc: 25.03% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.5017 | Val Loss: 1.1097 | Train Acc: 32.39% | Val Acc: 31.18% | LR: 0.000005
INFO:__main__:Epoch  20/100 | Train Loss: 1.4551 | Val Loss: 1.0995 | Train Acc: 32.82% | Val Acc: 33.08% | LR: 0.000005
INFO:__main__:Epoch  30/100 | Train Loss: 1.4614 | Val Loss: 1.0942 | Train Acc: 33.16% | Val Acc: 37.09% | LR: 0.000005
INFO:__main__:Epoch  40/100 | Train Loss: 1.4282 | Val Loss: 1.0890 | Train Acc: 33.52% | Val Acc: 39.69% | LR: 0.000005
INFO:__main__:Epoch  50/100 | Train Loss: 1.3604 | Val Loss: 1.0836 | Train Acc: 33.78% | Val Acc: 41.24% | LR: 0.000005
INFO:__main__:Epoch  60/100 | Train Loss: 1.3676 | Val Loss: 1.0788 | Train Acc: 34.30% | Val Acc: 41.74% | LR: 0.000005
INFO:__main__:Epoch  70/100 | Train Loss: 1.3261 | Val Loss: 1.0754 | Train Acc: 34.23% | Val Acc: 44.49% | LR: 0.000005
INFO:__main__:Epoch  80/100 | Train Loss: 1.3092 | Val Loss: 1.0719 | Train Acc: 35.52% | Val Acc: 46.20% | LR: 0.000005
INFO:__main__:Epoch  90/100 | Train Loss: 1.3112 | Val Loss: 1.0689 | Train Acc: 35.24% | Val Acc: 47.55% | LR: 0.000005
INFO:__main__:Epoch 100/100 | Train Loss: 1.2708 | Val Loss: 1.0665 | Train Acc: 36.26% | Val Acc: 47.35% | LR: 0.000005
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 47.93 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 47.81%
INFO:__main__:Final Val Accuracy: 47.35%
INFO:__main__:Validation F1-Macro: 0.4398
INFO:__main__:Best Val Accuracy: 47.85%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.49      0.85      0.62       666
      neutral       0.48      0.29      0.36       666
contradiction       0.42      0.28      0.34       666

     accuracy                           0.47      1998
    macro avg       0.46      0.47      0.44      1998
 weighted avg       0.46      0.47      0.44      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3942 | Val Loss: 1.0983 | Train Acc: 33.63% | Val Acc: 43.64% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.3738 | Val Loss: 1.0863 | Train Acc: 33.55% | Val Acc: 43.74% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.3209 | Val Loss: 1.0718 | Train Acc: 35.36% | Val Acc: 47.50% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.3161 | Val Loss: 1.0572 | Train Acc: 35.11% | Val Acc: 50.15% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.2820 | Val Loss: 1.0493 | Train Acc: 36.59% | Val Acc: 51.05% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.2841 | Val Loss: 1.0408 | Train Acc: 36.85% | Val Acc: 51.35% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.2509 | Val Loss: 1.0329 | Train Acc: 37.26% | Val Acc: 51.00% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 1.2336 | Val Loss: 1.0281 | Train Acc: 37.22% | Val Acc: 51.35% | LR: 0.000010
INFO:__main__:Epoch  80/100 | Train Loss: 1.2203 | Val Loss: 1.0196 | Train Acc: 38.13% | Val Acc: 51.00% | LR: 0.000010
INFO:__main__:Epoch  90/100 | Train Loss: 1.2126 | Val Loss: 1.0176 | Train Acc: 37.73% | Val Acc: 51.45% | LR: 0.000010
INFO:__main__:Epoch 100/100 | Train Loss: 1.2038 | Val Loss: 1.0125 | Train Acc: 38.35% | Val Acc: 51.00% | LR: 0.000005
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 15.72 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 51.40%
INFO:__main__:Final Val Accuracy: 51.00%
INFO:__main__:Validation F1-Macro: 0.4468
INFO:__main__:Best Val Accuracy: 51.75%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.56      0.87      0.68       666
      neutral       0.46      0.57      0.51       666
contradiction       0.43      0.09      0.15       666

     accuracy                           0.51      1998
    macro avg       0.49      0.51      0.45      1998
 weighted avg       0.49      0.51      0.45      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.4055 | Val Loss: 1.1095 | Train Acc: 33.48% | Val Acc: 34.48% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.3849 | Val Loss: 1.0989 | Train Acc: 32.96% | Val Acc: 37.54% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.3974 | Val Loss: 1.0888 | Train Acc: 33.67% | Val Acc: 39.84% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.3592 | Val Loss: 1.0763 | Train Acc: 34.03% | Val Acc: 42.89% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.3268 | Val Loss: 1.0669 | Train Acc: 35.77% | Val Acc: 44.44% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.3165 | Val Loss: 1.0588 | Train Acc: 34.65% | Val Acc: 45.90% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.2857 | Val Loss: 1.0501 | Train Acc: 35.92% | Val Acc: 46.80% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 1.2656 | Val Loss: 1.0458 | Train Acc: 36.39% | Val Acc: 47.85% | LR: 0.000010
INFO:__main__:Epoch  80/100 | Train Loss: 1.2627 | Val Loss: 1.0359 | Train Acc: 36.91% | Val Acc: 50.05% | LR: 0.000010
INFO:__main__:Epoch  90/100 | Train Loss: 1.2297 | Val Loss: 1.0306 | Train Acc: 37.29% | Val Acc: 50.75% | LR: 0.000010
INFO:__main__:Epoch 100/100 | Train Loss: 1.2276 | Val Loss: 1.0243 | Train Acc: 37.66% | Val Acc: 51.50% | LR: 0.000010
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 15.77 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 49.52%
INFO:__main__:Final Val Accuracy: 51.50%
INFO:__main__:Validation F1-Macro: 0.4784
INFO:__main__:Best Val Accuracy: 51.50%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.56      0.87      0.68       666
      neutral       0.48      0.47      0.48       666
contradiction       0.44      0.20      0.28       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.48      1998
 weighted avg       0.49      0.52      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.4139 | Val Loss: 1.1068 | Train Acc: 33.57% | Val Acc: 36.04% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.3674 | Val Loss: 1.1043 | Train Acc: 34.72% | Val Acc: 37.54% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.3701 | Val Loss: 1.0910 | Train Acc: 33.55% | Val Acc: 39.54% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.3509 | Val Loss: 1.0845 | Train Acc: 34.92% | Val Acc: 41.99% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.3281 | Val Loss: 1.0728 | Train Acc: 34.87% | Val Acc: 44.94% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.2978 | Val Loss: 1.0633 | Train Acc: 35.80% | Val Acc: 46.20% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.2966 | Val Loss: 1.0580 | Train Acc: 36.92% | Val Acc: 46.80% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 1.2908 | Val Loss: 1.0501 | Train Acc: 36.34% | Val Acc: 48.10% | LR: 0.000010
INFO:__main__:Epoch  80/100 | Train Loss: 1.2701 | Val Loss: 1.0462 | Train Acc: 37.05% | Val Acc: 48.15% | LR: 0.000010
INFO:__main__:Epoch  90/100 | Train Loss: 1.2432 | Val Loss: 1.0352 | Train Acc: 37.85% | Val Acc: 49.95% | LR: 0.000010
INFO:__main__:Epoch 100/100 | Train Loss: 1.2443 | Val Loss: 1.0315 | Train Acc: 37.46% | Val Acc: 49.35% | LR: 0.000010
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 15.71 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 49.77%
INFO:__main__:Final Val Accuracy: 49.35%
INFO:__main__:Validation F1-Macro: 0.4513
INFO:__main__:Best Val Accuracy: 49.95%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.50      0.92      0.64       666
      neutral       0.49      0.33      0.39       666
contradiction       0.49      0.23      0.32       666

     accuracy                           0.49      1998
    macro avg       0.49      0.49      0.45      1998
 weighted avg       0.49      0.49      0.45      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.4066 | Val Loss: 1.0921 | Train Acc: 33.77% | Val Acc: 37.24% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.3649 | Val Loss: 1.0811 | Train Acc: 34.83% | Val Acc: 42.29% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.3627 | Val Loss: 1.0694 | Train Acc: 35.41% | Val Acc: 42.84% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.3216 | Val Loss: 1.0585 | Train Acc: 36.04% | Val Acc: 45.75% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.3057 | Val Loss: 1.0500 | Train Acc: 37.07% | Val Acc: 47.55% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.2852 | Val Loss: 1.0422 | Train Acc: 37.00% | Val Acc: 47.70% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.2521 | Val Loss: 1.0364 | Train Acc: 38.04% | Val Acc: 49.35% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 1.2314 | Val Loss: 1.0297 | Train Acc: 38.54% | Val Acc: 49.75% | LR: 0.000010
INFO:__main__:Epoch  80/100 | Train Loss: 1.2273 | Val Loss: 1.0218 | Train Acc: 39.09% | Val Acc: 52.15% | LR: 0.000010
INFO:__main__:Epoch  90/100 | Train Loss: 1.2053 | Val Loss: 1.0201 | Train Acc: 40.04% | Val Acc: 51.60% | LR: 0.000010
INFO:__main__:Epoch 100/100 | Train Loss: 1.1995 | Val Loss: 1.0130 | Train Acc: 40.39% | Val Acc: 50.60% | LR: 0.000010
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 15.90 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 50.98%
INFO:__main__:Final Val Accuracy: 50.60%
INFO:__main__:Validation F1-Macro: 0.4819
INFO:__main__:Best Val Accuracy: 52.15%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.56      0.84      0.67       666
      neutral       0.47      0.35      0.40       666
contradiction       0.44      0.33      0.37       666

     accuracy                           0.51      1998
    macro avg       0.49      0.51      0.48      1998
 weighted avg       0.49      0.51      0.48      1998

INFO:__main__:NEW BEST RESULT!
INFO:__main__:Results: Accuracy = 49.96% ± 1.49%
INFO:__main__:         F1-Macro = 0.4596 ± 0.0172
INFO:__main__:         Score = 48.47
INFO:__main__:         Time = 112.4s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 2/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.001, 'batch_size': 256, 'dropout_rate': 0.3, 'weight_decay': 1e-05}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2122 | Val Loss: 1.0007 | Train Acc: 38.81% | Val Acc: 50.65% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9487 | Val Loss: 0.9245 | Train Acc: 51.35% | Val Acc: 52.30% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9315 | Val Loss: 0.9221 | Train Acc: 51.29% | Val Acc: 51.65% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9270 | Val Loss: 0.9209 | Train Acc: 51.39% | Val Acc: 50.95% | LR: 0.000500
INFO:__main__:Early stopping triggered at epoch 38
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 6.10 seconds
INFO:__main__:Epochs Trained: 38
INFO:__main__:Final Train Accuracy: 52.31%
INFO:__main__:Final Val Accuracy: 51.25%
INFO:__main__:Validation F1-Macro: 0.4837
INFO:__main__:Best Val Accuracy: 52.95%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.82      0.69       666
      neutral       0.47      0.51      0.49       666
contradiction       0.40      0.21      0.28       666

     accuracy                           0.51      1998
    macro avg       0.49      0.51      0.48      1998
 weighted avg       0.49      0.51      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1246 | Val Loss: 0.9694 | Train Acc: 43.62% | Val Acc: 51.50% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9493 | Val Loss: 0.9214 | Train Acc: 50.69% | Val Acc: 51.90% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9289 | Val Loss: 0.9197 | Train Acc: 52.10% | Val Acc: 52.25% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9267 | Val Loss: 0.9196 | Train Acc: 51.29% | Val Acc: 52.95% | LR: 0.001000
INFO:__main__:Epoch  40/100 | Train Loss: 0.9246 | Val Loss: 0.9189 | Train Acc: 51.66% | Val Acc: 52.60% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 42
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 6.72 seconds
INFO:__main__:Epochs Trained: 42
INFO:__main__:Final Train Accuracy: 52.59%
INFO:__main__:Final Val Accuracy: 52.85%
INFO:__main__:Validation F1-Macro: 0.4814
INFO:__main__:Best Val Accuracy: 53.10%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.81      0.69       666
      neutral       0.48      0.64      0.55       666
contradiction       0.42      0.14      0.20       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.48      1998
 weighted avg       0.50      0.53      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2151 | Val Loss: 0.9540 | Train Acc: 39.50% | Val Acc: 52.15% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9532 | Val Loss: 0.9036 | Train Acc: 50.98% | Val Acc: 51.75% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9342 | Val Loss: 0.9007 | Train Acc: 51.33% | Val Acc: 52.50% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9339 | Val Loss: 0.9004 | Train Acc: 50.71% | Val Acc: 52.95% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 33
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 5.33 seconds
INFO:__main__:Epochs Trained: 33
INFO:__main__:Final Train Accuracy: 52.10%
INFO:__main__:Final Val Accuracy: 52.70%
INFO:__main__:Validation F1-Macro: 0.5025
INFO:__main__:Best Val Accuracy: 53.30%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.85      0.70       666
      neutral       0.48      0.44      0.46       666
contradiction       0.46      0.28      0.35       666

     accuracy                           0.53      1998
    macro avg       0.51      0.53      0.50      1998
 weighted avg       0.51      0.53      0.50      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1078 | Val Loss: 0.9853 | Train Acc: 44.38% | Val Acc: 50.15% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9484 | Val Loss: 0.9369 | Train Acc: 50.71% | Val Acc: 51.10% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9343 | Val Loss: 0.9334 | Train Acc: 51.69% | Val Acc: 50.50% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9222 | Val Loss: 0.9318 | Train Acc: 52.19% | Val Acc: 49.90% | LR: 0.001000
INFO:__main__:Epoch  40/100 | Train Loss: 0.9239 | Val Loss: 0.9314 | Train Acc: 51.81% | Val Acc: 50.15% | LR: 0.000250
INFO:__main__:Epoch  50/100 | Train Loss: 0.9295 | Val Loss: 0.9316 | Train Acc: 52.10% | Val Acc: 50.25% | LR: 0.000250
INFO:__main__:Epoch  60/100 | Train Loss: 0.9266 | Val Loss: 0.9313 | Train Acc: 52.88% | Val Acc: 50.10% | LR: 0.000063
INFO:__main__:Early stopping triggered at epoch 60
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 9.61 seconds
INFO:__main__:Epochs Trained: 60
INFO:__main__:Final Train Accuracy: 53.09%
INFO:__main__:Final Val Accuracy: 50.10%
INFO:__main__:Validation F1-Macro: 0.4460
INFO:__main__:Best Val Accuracy: 51.15%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.57      0.83      0.68       666
      neutral       0.45      0.57      0.51       666
contradiction       0.35      0.10      0.15       666

     accuracy                           0.50      1998
    macro avg       0.46      0.50      0.45      1998
 weighted avg       0.46      0.50      0.45      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1359 | Val Loss: 0.9700 | Train Acc: 40.63% | Val Acc: 50.05% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9413 | Val Loss: 0.9182 | Train Acc: 51.41% | Val Acc: 51.95% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9310 | Val Loss: 0.9178 | Train Acc: 51.80% | Val Acc: 52.35% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9266 | Val Loss: 0.9177 | Train Acc: 51.76% | Val Acc: 52.50% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 30
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 4.87 seconds
INFO:__main__:Epochs Trained: 30
INFO:__main__:Final Train Accuracy: 52.24%
INFO:__main__:Final Val Accuracy: 52.50%
INFO:__main__:Validation F1-Macro: 0.4995
INFO:__main__:Best Val Accuracy: 52.95%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.82      0.69       666
      neutral       0.49      0.52      0.50       666
contradiction       0.41      0.24      0.30       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.50      1998
 weighted avg       0.50      0.53      0.50      1998

INFO:__main__:NEW BEST RESULT!
INFO:__main__:Results: Accuracy = 51.88% ± 1.06%
INFO:__main__:         F1-Macro = 0.4826 ± 0.0201
INFO:__main__:         Score = 50.83
INFO:__main__:         Time = 32.7s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 3/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.0005, 'batch_size': 128, 'dropout_rate': 0.3, 'weight_decay': 1e-05}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2465 | Val Loss: 1.0059 | Train Acc: 37.63% | Val Acc: 49.55% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9440 | Val Loss: 0.9230 | Train Acc: 50.54% | Val Acc: 51.75% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9377 | Val Loss: 0.9225 | Train Acc: 52.44% | Val Acc: 51.55% | LR: 0.000250
INFO:__main__:Epoch  30/100 | Train Loss: 0.9315 | Val Loss: 0.9212 | Train Acc: 52.08% | Val Acc: 51.90% | LR: 0.000063
INFO:__main__:Early stopping triggered at epoch 38
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 9.72 seconds
INFO:__main__:Epochs Trained: 38
INFO:__main__:Final Train Accuracy: 52.29%
INFO:__main__:Final Val Accuracy: 51.80%
INFO:__main__:Validation F1-Macro: 0.4955
INFO:__main__:Best Val Accuracy: 52.40%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.82      0.69       666
      neutral       0.48      0.48      0.48       666
contradiction       0.41      0.26      0.32       666

     accuracy                           0.52      1998
    macro avg       0.50      0.52      0.50      1998
 weighted avg       0.50      0.52      0.50      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1475 | Val Loss: 0.9683 | Train Acc: 42.52% | Val Acc: 51.65% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9519 | Val Loss: 0.9248 | Train Acc: 50.68% | Val Acc: 52.15% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9350 | Val Loss: 0.9225 | Train Acc: 51.73% | Val Acc: 51.55% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9287 | Val Loss: 0.9220 | Train Acc: 51.69% | Val Acc: 52.80% | LR: 0.000500
INFO:__main__:Epoch  40/100 | Train Loss: 0.9283 | Val Loss: 0.9210 | Train Acc: 51.30% | Val Acc: 52.00% | LR: 0.000250
INFO:__main__:Epoch  50/100 | Train Loss: 0.9279 | Val Loss: 0.9216 | Train Acc: 52.00% | Val Acc: 52.70% | LR: 0.000063
INFO:__main__:Early stopping triggered at epoch 53
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 13.42 seconds
INFO:__main__:Epochs Trained: 53
INFO:__main__:Final Train Accuracy: 52.54%
INFO:__main__:Final Val Accuracy: 52.55%
INFO:__main__:Validation F1-Macro: 0.4870
INFO:__main__:Best Val Accuracy: 52.90%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.81      0.69       666
      neutral       0.49      0.60      0.54       666
contradiction       0.41      0.17      0.24       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.49      1998
 weighted avg       0.50      0.53      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2013 | Val Loss: 0.9560 | Train Acc: 40.49% | Val Acc: 52.70% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9629 | Val Loss: 0.9021 | Train Acc: 50.45% | Val Acc: 52.55% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9420 | Val Loss: 0.9000 | Train Acc: 51.38% | Val Acc: 51.95% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9331 | Val Loss: 0.9009 | Train Acc: 51.61% | Val Acc: 53.60% | LR: 0.000500
INFO:__main__:Epoch  40/100 | Train Loss: 0.9336 | Val Loss: 0.8994 | Train Acc: 51.78% | Val Acc: 52.55% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 40
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 10.24 seconds
INFO:__main__:Epochs Trained: 40
INFO:__main__:Final Train Accuracy: 52.53%
INFO:__main__:Final Val Accuracy: 52.55%
INFO:__main__:Validation F1-Macro: 0.5017
INFO:__main__:Best Val Accuracy: 53.65%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.84      0.70       666
      neutral       0.48      0.47      0.47       666
contradiction       0.43      0.27      0.33       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.50      1998
 weighted avg       0.50      0.53      0.50      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2475 | Val Loss: 0.9837 | Train Acc: 40.53% | Val Acc: 50.35% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9609 | Val Loss: 0.9341 | Train Acc: 51.14% | Val Acc: 49.90% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9387 | Val Loss: 0.9312 | Train Acc: 51.43% | Val Acc: 50.15% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9298 | Val Loss: 0.9303 | Train Acc: 52.01% | Val Acc: 50.15% | LR: 0.000250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9267 | Val Loss: 0.9300 | Train Acc: 51.63% | Val Acc: 50.45% | LR: 0.000250
INFO:__main__:Epoch  50/100 | Train Loss: 0.9269 | Val Loss: 0.9298 | Train Acc: 52.09% | Val Acc: 50.20% | LR: 0.000063
INFO:__main__:Early stopping triggered at epoch 50
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 12.70 seconds
INFO:__main__:Epochs Trained: 50
INFO:__main__:Final Train Accuracy: 52.90%
INFO:__main__:Final Val Accuracy: 50.20%
INFO:__main__:Validation F1-Macro: 0.4612
INFO:__main__:Best Val Accuracy: 51.25%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.57      0.83      0.68       666
      neutral       0.46      0.52      0.48       666
contradiction       0.38      0.16      0.22       666

     accuracy                           0.50      1998
    macro avg       0.47      0.50      0.46      1998
 weighted avg       0.47      0.50      0.46      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2535 | Val Loss: 0.9942 | Train Acc: 40.78% | Val Acc: 51.45% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9615 | Val Loss: 0.9229 | Train Acc: 50.59% | Val Acc: 52.45% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9404 | Val Loss: 0.9178 | Train Acc: 50.95% | Val Acc: 52.60% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9337 | Val Loss: 0.9182 | Train Acc: 52.05% | Val Acc: 52.60% | LR: 0.000250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9279 | Val Loss: 0.9170 | Train Acc: 51.66% | Val Acc: 52.50% | LR: 0.000250
INFO:__main__:Epoch  50/100 | Train Loss: 0.9316 | Val Loss: 0.9158 | Train Acc: 51.76% | Val Acc: 52.25% | LR: 0.000125
INFO:__main__:Epoch  60/100 | Train Loss: 0.9298 | Val Loss: 0.9163 | Train Acc: 51.53% | Val Acc: 52.80% | LR: 0.000063
INFO:__main__:Early stopping triggered at epoch 65
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 16.41 seconds
INFO:__main__:Epochs Trained: 65
INFO:__main__:Final Train Accuracy: 52.18%
INFO:__main__:Final Val Accuracy: 52.75%
INFO:__main__:Validation F1-Macro: 0.4897
INFO:__main__:Best Val Accuracy: 53.10%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.84      0.69       666
      neutral       0.50      0.57      0.53       666
contradiction       0.41      0.18      0.25       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.49      1998
 weighted avg       0.50      0.53      0.49      1998

INFO:__main__:NEW BEST RESULT!
INFO:__main__:Results: Accuracy = 51.97% ± 0.94%
INFO:__main__:         F1-Macro = 0.4870 ± 0.0139
INFO:__main__:         Score = 51.03
INFO:__main__:         Time = 62.5s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 4/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.001, 'batch_size': 256, 'dropout_rate': 0.5, 'weight_decay': 0.005}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3074 | Val Loss: 1.0466 | Train Acc: 35.59% | Val Acc: 43.64% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9736 | Val Loss: 0.9355 | Train Acc: 50.85% | Val Acc: 52.55% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9448 | Val Loss: 0.9309 | Train Acc: 50.74% | Val Acc: 52.25% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9421 | Val Loss: 0.9247 | Train Acc: 51.63% | Val Acc: 52.00% | LR: 0.001000
INFO:__main__:Epoch  40/100 | Train Loss: 0.9349 | Val Loss: 0.9242 | Train Acc: 51.59% | Val Acc: 52.05% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 43
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 6.86 seconds
INFO:__main__:Epochs Trained: 43
INFO:__main__:Final Train Accuracy: 52.33%
INFO:__main__:Final Val Accuracy: 52.60%
INFO:__main__:Validation F1-Macro: 0.4672
INFO:__main__:Best Val Accuracy: 52.75%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.84      0.69       666
      neutral       0.49      0.64      0.55       666
contradiction       0.40      0.10      0.16       666

     accuracy                           0.53      1998
    macro avg       0.49      0.53      0.47      1998
 weighted avg       0.49      0.53      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3204 | Val Loss: 1.0184 | Train Acc: 35.72% | Val Acc: 46.00% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9737 | Val Loss: 0.9335 | Train Acc: 49.77% | Val Acc: 50.10% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9495 | Val Loss: 0.9246 | Train Acc: 51.88% | Val Acc: 51.95% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9375 | Val Loss: 0.9217 | Train Acc: 51.80% | Val Acc: 52.25% | LR: 0.001000
INFO:__main__:Epoch  40/100 | Train Loss: 0.9379 | Val Loss: 0.9228 | Train Acc: 52.24% | Val Acc: 51.80% | LR: 0.000500
INFO:__main__:Epoch  50/100 | Train Loss: 0.9365 | Val Loss: 0.9216 | Train Acc: 51.76% | Val Acc: 51.55% | LR: 0.000250
INFO:__main__:Epoch  60/100 | Train Loss: 0.9353 | Val Loss: 0.9212 | Train Acc: 51.86% | Val Acc: 51.90% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 64
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 10.28 seconds
INFO:__main__:Epochs Trained: 64
INFO:__main__:Final Train Accuracy: 52.26%
INFO:__main__:Final Val Accuracy: 51.90%
INFO:__main__:Validation F1-Macro: 0.4820
INFO:__main__:Best Val Accuracy: 52.90%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.82      0.69       666
      neutral       0.49      0.57      0.53       666
contradiction       0.38      0.17      0.23       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.48      1998
 weighted avg       0.49      0.52      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2664 | Val Loss: 1.0099 | Train Acc: 36.47% | Val Acc: 52.70% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9748 | Val Loss: 0.9182 | Train Acc: 49.59% | Val Acc: 51.65% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9518 | Val Loss: 0.9081 | Train Acc: 50.69% | Val Acc: 53.30% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9470 | Val Loss: 0.9081 | Train Acc: 51.03% | Val Acc: 53.25% | LR: 0.000500
INFO:__main__:Epoch  40/100 | Train Loss: 0.9437 | Val Loss: 0.9043 | Train Acc: 51.55% | Val Acc: 52.80% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 48
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 7.63 seconds
INFO:__main__:Epochs Trained: 48
INFO:__main__:Final Train Accuracy: 52.29%
INFO:__main__:Final Val Accuracy: 52.55%
INFO:__main__:Validation F1-Macro: 0.4865
INFO:__main__:Best Val Accuracy: 53.35%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.84      0.70       666
      neutral       0.48      0.56      0.52       666
contradiction       0.41      0.17      0.24       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.49      1998
 weighted avg       0.50      0.53      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2630 | Val Loss: 1.0177 | Train Acc: 35.72% | Val Acc: 50.30% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9664 | Val Loss: 0.9390 | Train Acc: 50.85% | Val Acc: 50.70% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9406 | Val Loss: 0.9333 | Train Acc: 50.99% | Val Acc: 51.15% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9388 | Val Loss: 0.9326 | Train Acc: 51.88% | Val Acc: 50.55% | LR: 0.001000
INFO:__main__:Epoch  40/100 | Train Loss: 0.9352 | Val Loss: 0.9328 | Train Acc: 52.16% | Val Acc: 50.40% | LR: 0.000500
INFO:__main__:Epoch  50/100 | Train Loss: 0.9313 | Val Loss: 0.9310 | Train Acc: 51.94% | Val Acc: 50.30% | LR: 0.000250
INFO:__main__:Epoch  60/100 | Train Loss: 0.9307 | Val Loss: 0.9305 | Train Acc: 51.93% | Val Acc: 50.15% | LR: 0.000125
INFO:__main__:Epoch  70/100 | Train Loss: 0.9274 | Val Loss: 0.9308 | Train Acc: 52.41% | Val Acc: 50.50% | LR: 0.000063
INFO:__main__:Early stopping triggered at epoch 75
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 11.90 seconds
INFO:__main__:Epochs Trained: 75
INFO:__main__:Final Train Accuracy: 52.49%
INFO:__main__:Final Val Accuracy: 50.80%
INFO:__main__:Validation F1-Macro: 0.4719
INFO:__main__:Best Val Accuracy: 51.40%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.83      0.68       666
      neutral       0.47      0.52      0.49       666
contradiction       0.38      0.18      0.24       666

     accuracy                           0.51      1998
    macro avg       0.48      0.51      0.47      1998
 weighted avg       0.48      0.51      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3867 | Val Loss: 1.0168 | Train Acc: 35.44% | Val Acc: 46.70% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9719 | Val Loss: 0.9321 | Train Acc: 50.13% | Val Acc: 52.35% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9483 | Val Loss: 0.9236 | Train Acc: 51.21% | Val Acc: 51.85% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9434 | Val Loss: 0.9233 | Train Acc: 51.34% | Val Acc: 52.05% | LR: 0.001000
INFO:__main__:Epoch  40/100 | Train Loss: 0.9391 | Val Loss: 0.9223 | Train Acc: 51.10% | Val Acc: 52.20% | LR: 0.000500
INFO:__main__:Epoch  50/100 | Train Loss: 0.9359 | Val Loss: 0.9210 | Train Acc: 51.30% | Val Acc: 52.70% | LR: 0.000250
INFO:__main__:Epoch  60/100 | Train Loss: 0.9309 | Val Loss: 0.9196 | Train Acc: 51.75% | Val Acc: 52.95% | LR: 0.000125
INFO:__main__:Epoch  70/100 | Train Loss: 0.9324 | Val Loss: 0.9199 | Train Acc: 51.43% | Val Acc: 53.00% | LR: 0.000063
INFO:__main__:Epoch  80/100 | Train Loss: 0.9315 | Val Loss: 0.9193 | Train Acc: 51.64% | Val Acc: 52.85% | LR: 0.000016
INFO:__main__:Epoch  90/100 | Train Loss: 0.9319 | Val Loss: 0.9198 | Train Acc: 51.63% | Val Acc: 52.70% | LR: 0.000008
INFO:__main__:Early stopping triggered at epoch 94
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 14.84 seconds
INFO:__main__:Epochs Trained: 94
INFO:__main__:Final Train Accuracy: 51.90%
INFO:__main__:Final Val Accuracy: 52.75%
INFO:__main__:Validation F1-Macro: 0.4944
INFO:__main__:Best Val Accuracy: 53.25%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.83      0.69       666
      neutral       0.50      0.55      0.52       666
contradiction       0.40      0.20      0.27       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.49      1998
 weighted avg       0.50      0.53      0.49      1998

INFO:__main__:NEW BEST RESULT!
INFO:__main__:Results: Accuracy = 52.12% ± 0.72%
INFO:__main__:         F1-Macro = 0.4804 ± 0.0098
INFO:__main__:         Score = 51.40
INFO:__main__:         Time = 51.5s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 5/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.001, 'batch_size': 64, 'dropout_rate': 0.3, 'weight_decay': 0.0001}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1071 | Val Loss: 0.9436 | Train Acc: 44.12% | Val Acc: 51.65% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9338 | Val Loss: 0.9235 | Train Acc: 51.70% | Val Acc: 50.90% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9270 | Val Loss: 0.9202 | Train Acc: 51.89% | Val Acc: 52.25% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9273 | Val Loss: 0.9210 | Train Acc: 52.46% | Val Acc: 51.25% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 37
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 17.04 seconds
INFO:__main__:Epochs Trained: 37
INFO:__main__:Final Train Accuracy: 52.57%
INFO:__main__:Final Val Accuracy: 52.55%
INFO:__main__:Validation F1-Macro: 0.4801
INFO:__main__:Best Val Accuracy: 52.65%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.82      0.69       666
      neutral       0.48      0.61      0.54       666
contradiction       0.43      0.14      0.22       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.48      1998
 weighted avg       0.50      0.53      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0700 | Val Loss: 0.9471 | Train Acc: 45.41% | Val Acc: 50.40% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9340 | Val Loss: 0.9211 | Train Acc: 51.93% | Val Acc: 52.45% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9258 | Val Loss: 0.9187 | Train Acc: 51.99% | Val Acc: 51.90% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9282 | Val Loss: 0.9190 | Train Acc: 51.95% | Val Acc: 51.70% | LR: 0.001000
INFO:__main__:Epoch  40/100 | Train Loss: 0.9269 | Val Loss: 0.9184 | Train Acc: 51.85% | Val Acc: 51.85% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 41
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 18.71 seconds
INFO:__main__:Epochs Trained: 41
INFO:__main__:Final Train Accuracy: 52.26%
INFO:__main__:Final Val Accuracy: 51.55%
INFO:__main__:Validation F1-Macro: 0.4815
INFO:__main__:Best Val Accuracy: 52.80%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.83      0.68       666
      neutral       0.49      0.53      0.51       666
contradiction       0.37      0.19      0.25       666

     accuracy                           0.52      1998
    macro avg       0.48      0.52      0.48      1998
 weighted avg       0.48      0.52      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0824 | Val Loss: 0.9072 | Train Acc: 45.36% | Val Acc: 53.60% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9394 | Val Loss: 0.8993 | Train Acc: 51.33% | Val Acc: 52.25% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9279 | Val Loss: 0.8970 | Train Acc: 52.00% | Val Acc: 53.25% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9311 | Val Loss: 0.8981 | Train Acc: 52.08% | Val Acc: 52.35% | LR: 0.000500
INFO:__main__:Early stopping triggered at epoch 35
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 16.20 seconds
INFO:__main__:Epochs Trained: 35
INFO:__main__:Final Train Accuracy: 51.96%
INFO:__main__:Final Val Accuracy: 52.35%
INFO:__main__:Validation F1-Macro: 0.4888
INFO:__main__:Best Val Accuracy: 53.75%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.85      0.69       666
      neutral       0.48      0.53      0.50       666
contradiction       0.42      0.20      0.27       666

     accuracy                           0.52      1998
    macro avg       0.50      0.52      0.49      1998
 weighted avg       0.50      0.52      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0859 | Val Loss: 0.9530 | Train Acc: 46.23% | Val Acc: 50.35% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9394 | Val Loss: 0.9305 | Train Acc: 51.60% | Val Acc: 50.95% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9231 | Val Loss: 0.9286 | Train Acc: 52.60% | Val Acc: 50.90% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9241 | Val Loss: 0.9283 | Train Acc: 51.81% | Val Acc: 50.60% | LR: 0.000500
INFO:__main__:Epoch  40/100 | Train Loss: 0.9286 | Val Loss: 0.9280 | Train Acc: 51.86% | Val Acc: 50.45% | LR: 0.000250
INFO:__main__:Epoch  50/100 | Train Loss: 0.9241 | Val Loss: 0.9286 | Train Acc: 52.14% | Val Acc: 50.70% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 56
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 25.21 seconds
INFO:__main__:Epochs Trained: 56
INFO:__main__:Final Train Accuracy: 52.79%
INFO:__main__:Final Val Accuracy: 50.45%
INFO:__main__:Validation F1-Macro: 0.4589
INFO:__main__:Best Val Accuracy: 51.85%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.57      0.83      0.68       666
      neutral       0.46      0.55      0.50       666
contradiction       0.36      0.13      0.20       666

     accuracy                           0.50      1998
    macro avg       0.47      0.50      0.46      1998
 weighted avg       0.47      0.50      0.46      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0844 | Val Loss: 0.9303 | Train Acc: 44.98% | Val Acc: 52.45% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9342 | Val Loss: 0.9216 | Train Acc: 51.38% | Val Acc: 52.95% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9315 | Val Loss: 0.9213 | Train Acc: 51.61% | Val Acc: 52.15% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9313 | Val Loss: 0.9209 | Train Acc: 52.06% | Val Acc: 52.75% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 38
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 17.42 seconds
INFO:__main__:Epochs Trained: 38
INFO:__main__:Final Train Accuracy: 52.23%
INFO:__main__:Final Val Accuracy: 52.55%
INFO:__main__:Validation F1-Macro: 0.4849
INFO:__main__:Best Val Accuracy: 52.95%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.81      0.68       666
      neutral       0.50      0.61      0.55       666
contradiction       0.39      0.16      0.22       666

     accuracy                           0.53      1998
    macro avg       0.49      0.53      0.48      1998
 weighted avg       0.49      0.53      0.48      1998

INFO:__main__:Results: Accuracy = 51.89% ± 0.81%
INFO:__main__:         F1-Macro = 0.4788 ± 0.0104
INFO:__main__:         Score = 51.08
INFO:__main__:         Time = 94.6s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 6/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.005, 'batch_size': 128, 'dropout_rate': 0.5, 'weight_decay': 0.0001}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0831 | Val Loss: 0.9309 | Train Acc: 44.99% | Val Acc: 51.50% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9437 | Val Loss: 0.9214 | Train Acc: 50.85% | Val Acc: 51.60% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9385 | Val Loss: 0.9206 | Train Acc: 51.26% | Val Acc: 52.10% | LR: 0.002500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9355 | Val Loss: 0.9213 | Train Acc: 51.10% | Val Acc: 52.55% | LR: 0.001250
INFO:__main__:Early stopping triggered at epoch 37
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 9.35 seconds
INFO:__main__:Epochs Trained: 37
INFO:__main__:Final Train Accuracy: 52.03%
INFO:__main__:Final Val Accuracy: 52.50%
INFO:__main__:Validation F1-Macro: 0.4746
INFO:__main__:Best Val Accuracy: 52.70%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.82      0.69       666
      neutral       0.49      0.63      0.55       666
contradiction       0.39      0.12      0.19       666

     accuracy                           0.53      1998
    macro avg       0.49      0.53      0.47      1998
 weighted avg       0.49      0.53      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0650 | Val Loss: 0.9467 | Train Acc: 43.41% | Val Acc: 51.40% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9415 | Val Loss: 0.9254 | Train Acc: 51.69% | Val Acc: 52.20% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9380 | Val Loss: 0.9220 | Train Acc: 51.70% | Val Acc: 52.25% | LR: 0.002500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9378 | Val Loss: 0.9218 | Train Acc: 52.29% | Val Acc: 51.40% | LR: 0.000625
INFO:__main__:Epoch  40/100 | Train Loss: 0.9366 | Val Loss: 0.9216 | Train Acc: 51.96% | Val Acc: 51.85% | LR: 0.000313
INFO:__main__:Early stopping triggered at epoch 49
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 12.45 seconds
INFO:__main__:Epochs Trained: 49
INFO:__main__:Final Train Accuracy: 52.35%
INFO:__main__:Final Val Accuracy: 51.75%
INFO:__main__:Validation F1-Macro: 0.4646
INFO:__main__:Best Val Accuracy: 52.70%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.83      0.69       666
      neutral       0.48      0.62      0.54       666
contradiction       0.36      0.11      0.17       666

     accuracy                           0.52      1998
    macro avg       0.47      0.52      0.46      1998
 weighted avg       0.47      0.52      0.46      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0935 | Val Loss: 0.9171 | Train Acc: 44.39% | Val Acc: 53.05% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9466 | Val Loss: 0.9073 | Train Acc: 51.26% | Val Acc: 50.70% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9447 | Val Loss: 0.9039 | Train Acc: 51.15% | Val Acc: 51.20% | LR: 0.002500
INFO:__main__:Early stopping triggered at epoch 29
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 7.49 seconds
INFO:__main__:Epochs Trained: 29
INFO:__main__:Final Train Accuracy: 52.00%
INFO:__main__:Final Val Accuracy: 52.90%
INFO:__main__:Validation F1-Macro: 0.4733
INFO:__main__:Best Val Accuracy: 53.70%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.86      0.69       666
      neutral       0.49      0.61      0.55       666
contradiction       0.42      0.12      0.18       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.47      1998
 weighted avg       0.50      0.53      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1108 | Val Loss: 0.9466 | Train Acc: 44.74% | Val Acc: 50.85% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9390 | Val Loss: 0.9303 | Train Acc: 51.66% | Val Acc: 51.15% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9345 | Val Loss: 0.9298 | Train Acc: 52.05% | Val Acc: 50.30% | LR: 0.002500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9267 | Val Loss: 0.9299 | Train Acc: 52.44% | Val Acc: 50.50% | LR: 0.000625
INFO:__main__:Early stopping triggered at epoch 32
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 8.25 seconds
INFO:__main__:Epochs Trained: 32
INFO:__main__:Final Train Accuracy: 52.83%
INFO:__main__:Final Val Accuracy: 50.30%
INFO:__main__:Validation F1-Macro: 0.4564
INFO:__main__:Best Val Accuracy: 51.85%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.57      0.84      0.68       666
      neutral       0.46      0.54      0.50       666
contradiction       0.36      0.13      0.19       666

     accuracy                           0.50      1998
    macro avg       0.46      0.50      0.46      1998
 weighted avg       0.46      0.50      0.46      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0548 | Val Loss: 0.9309 | Train Acc: 44.66% | Val Acc: 52.00% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9394 | Val Loss: 0.9195 | Train Acc: 51.63% | Val Acc: 52.45% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9373 | Val Loss: 0.9186 | Train Acc: 51.48% | Val Acc: 52.00% | LR: 0.002500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9319 | Val Loss: 0.9169 | Train Acc: 51.85% | Val Acc: 53.15% | LR: 0.000625
INFO:__main__:Early stopping triggered at epoch 37
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 9.14 seconds
INFO:__main__:Epochs Trained: 37
INFO:__main__:Final Train Accuracy: 52.14%
INFO:__main__:Final Val Accuracy: 52.75%
INFO:__main__:Validation F1-Macro: 0.4831
INFO:__main__:Best Val Accuracy: 53.15%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.83      0.69       666
      neutral       0.50      0.61      0.55       666
contradiction       0.39      0.15      0.21       666

     accuracy                           0.53      1998
    macro avg       0.49      0.53      0.48      1998
 weighted avg       0.49      0.53      0.48      1998

INFO:__main__:Results: Accuracy = 52.04% ± 0.96%
INFO:__main__:         F1-Macro = 0.4704 ± 0.0091
INFO:__main__:         Score = 51.09
INFO:__main__:         Time = 46.7s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 7/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 1e-05, 'batch_size': 64, 'dropout_rate': 0.1, 'weight_decay': 0.005}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.5633 | Val Loss: 1.3292 | Train Acc: 32.36% | Val Acc: 32.98% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.1485 | Val Loss: 1.0517 | Train Acc: 41.03% | Val Acc: 48.65% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.0440 | Val Loss: 0.9976 | Train Acc: 47.80% | Val Acc: 50.75% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.0015 | Val Loss: 0.9696 | Train Acc: 50.33% | Val Acc: 50.45% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 0.9866 | Val Loss: 0.9533 | Train Acc: 50.65% | Val Acc: 51.35% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 0.9732 | Val Loss: 0.9424 | Train Acc: 50.58% | Val Acc: 51.85% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 0.9649 | Val Loss: 0.9385 | Train Acc: 50.71% | Val Acc: 51.75% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 0.9611 | Val Loss: 0.9329 | Train Acc: 50.49% | Val Acc: 52.35% | LR: 0.000010
INFO:__main__:Epoch  80/100 | Train Loss: 0.9488 | Val Loss: 0.9304 | Train Acc: 51.41% | Val Acc: 51.60% | LR: 0.000010
INFO:__main__:Epoch  90/100 | Train Loss: 0.9446 | Val Loss: 0.9285 | Train Acc: 52.13% | Val Acc: 51.90% | LR: 0.000005
INFO:__main__:Epoch 100/100 | Train Loss: 0.9474 | Val Loss: 0.9298 | Train Acc: 50.90% | Val Acc: 51.15% | LR: 0.000003
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 44.73 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 52.43%
INFO:__main__:Final Val Accuracy: 51.15%
INFO:__main__:Validation F1-Macro: 0.4843
INFO:__main__:Best Val Accuracy: 52.70%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.84      0.69       666
      neutral       0.46      0.45      0.46       666
contradiction       0.42      0.24      0.31       666

     accuracy                           0.51      1998
    macro avg       0.49      0.51      0.48      1998
 weighted avg       0.49      0.51      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2591 | Val Loss: 1.1495 | Train Acc: 35.92% | Val Acc: 37.74% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.0678 | Val Loss: 0.9933 | Train Acc: 45.11% | Val Acc: 51.35% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.0098 | Val Loss: 0.9587 | Train Acc: 49.41% | Val Acc: 50.05% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 0.9805 | Val Loss: 0.9406 | Train Acc: 50.53% | Val Acc: 50.20% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 0.9761 | Val Loss: 0.9329 | Train Acc: 50.34% | Val Acc: 51.05% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 0.9719 | Val Loss: 0.9299 | Train Acc: 49.91% | Val Acc: 51.20% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 0.9613 | Val Loss: 0.9260 | Train Acc: 51.24% | Val Acc: 51.10% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 0.9583 | Val Loss: 0.9255 | Train Acc: 50.59% | Val Acc: 51.35% | LR: 0.000003
INFO:__main__:Epoch  80/100 | Train Loss: 0.9574 | Val Loss: 0.9248 | Train Acc: 50.80% | Val Acc: 51.00% | LR: 0.000001
INFO:__main__:Early stopping triggered at epoch 89
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 40.97 seconds
INFO:__main__:Epochs Trained: 89
INFO:__main__:Final Train Accuracy: 52.33%
INFO:__main__:Final Val Accuracy: 51.55%
INFO:__main__:Validation F1-Macro: 0.4805
INFO:__main__:Best Val Accuracy: 51.90%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.84      0.69       666
      neutral       0.46      0.51      0.48       666
contradiction       0.43      0.20      0.27       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.48      1998
 weighted avg       0.49      0.52      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2648 | Val Loss: 1.1279 | Train Acc: 35.26% | Val Acc: 42.79% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.0570 | Val Loss: 0.9672 | Train Acc: 45.72% | Val Acc: 52.55% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.0118 | Val Loss: 0.9361 | Train Acc: 49.19% | Val Acc: 53.80% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 0.9861 | Val Loss: 0.9240 | Train Acc: 49.99% | Val Acc: 53.75% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 0.9820 | Val Loss: 0.9191 | Train Acc: 50.15% | Val Acc: 53.40% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 0.9711 | Val Loss: 0.9144 | Train Acc: 50.54% | Val Acc: 53.60% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 0.9642 | Val Loss: 0.9146 | Train Acc: 51.89% | Val Acc: 53.60% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 0.9556 | Val Loss: 0.9095 | Train Acc: 51.09% | Val Acc: 53.60% | LR: 0.000005
INFO:__main__:Epoch  80/100 | Train Loss: 0.9620 | Val Loss: 0.9102 | Train Acc: 49.97% | Val Acc: 53.25% | LR: 0.000003
INFO:__main__:Early stopping triggered at epoch 86
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 39.90 seconds
INFO:__main__:Epochs Trained: 86
INFO:__main__:Final Train Accuracy: 52.39%
INFO:__main__:Final Val Accuracy: 53.80%
INFO:__main__:Validation F1-Macro: 0.5203
INFO:__main__:Best Val Accuracy: 54.35%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.83      0.70       666
      neutral       0.54      0.34      0.42       666
contradiction       0.45      0.44      0.45       666

     accuracy                           0.54      1998
    macro avg       0.53      0.54      0.52      1998
 weighted avg       0.53      0.54      0.52      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1408 | Val Loss: 1.0571 | Train Acc: 36.92% | Val Acc: 40.14% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.0214 | Val Loss: 0.9781 | Train Acc: 48.41% | Val Acc: 50.05% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 0.9913 | Val Loss: 0.9615 | Train Acc: 50.09% | Val Acc: 50.00% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 0.9743 | Val Loss: 0.9539 | Train Acc: 50.99% | Val Acc: 49.85% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 0.9637 | Val Loss: 0.9469 | Train Acc: 51.73% | Val Acc: 50.40% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 0.9658 | Val Loss: 0.9431 | Train Acc: 51.54% | Val Acc: 50.80% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 0.9575 | Val Loss: 0.9431 | Train Acc: 51.29% | Val Acc: 50.50% | LR: 0.000005
INFO:__main__:Epoch  70/100 | Train Loss: 0.9559 | Val Loss: 0.9414 | Train Acc: 51.36% | Val Acc: 50.75% | LR: 0.000005
INFO:__main__:Epoch  80/100 | Train Loss: 0.9527 | Val Loss: 0.9392 | Train Acc: 51.30% | Val Acc: 50.35% | LR: 0.000001
INFO:__main__:Epoch  90/100 | Train Loss: 0.9476 | Val Loss: 0.9401 | Train Acc: 51.66% | Val Acc: 50.70% | LR: 0.000001
INFO:__main__:Epoch 100/100 | Train Loss: 0.9494 | Val Loss: 0.9405 | Train Acc: 51.89% | Val Acc: 50.25% | LR: 0.000001
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 46.06 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 52.94%
INFO:__main__:Final Val Accuracy: 50.25%
INFO:__main__:Validation F1-Macro: 0.4691
INFO:__main__:Best Val Accuracy: 51.25%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.82      0.68       666
      neutral       0.45      0.50      0.48       666
contradiction       0.39      0.18      0.25       666

     accuracy                           0.50      1998
    macro avg       0.47      0.50      0.47      1998
 weighted avg       0.47      0.50      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3617 | Val Loss: 1.2330 | Train Acc: 29.67% | Val Acc: 28.78% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.0861 | Val Loss: 1.0191 | Train Acc: 44.96% | Val Acc: 49.30% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.0165 | Val Loss: 0.9586 | Train Acc: 49.71% | Val Acc: 50.85% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 0.9916 | Val Loss: 0.9437 | Train Acc: 50.46% | Val Acc: 50.05% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 0.9771 | Val Loss: 0.9393 | Train Acc: 51.05% | Val Acc: 49.35% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 0.9714 | Val Loss: 0.9356 | Train Acc: 50.36% | Val Acc: 49.40% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 0.9642 | Val Loss: 0.9327 | Train Acc: 51.00% | Val Acc: 50.40% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 0.9642 | Val Loss: 0.9308 | Train Acc: 50.46% | Val Acc: 50.40% | LR: 0.000010
INFO:__main__:Epoch  80/100 | Train Loss: 0.9599 | Val Loss: 0.9298 | Train Acc: 51.49% | Val Acc: 50.40% | LR: 0.000005
INFO:__main__:Epoch  90/100 | Train Loss: 0.9539 | Val Loss: 0.9280 | Train Acc: 51.54% | Val Acc: 50.55% | LR: 0.000005
INFO:__main__:Epoch 100/100 | Train Loss: 0.9562 | Val Loss: 0.9295 | Train Acc: 51.41% | Val Acc: 50.45% | LR: 0.000003
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 45.83 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 53.02%
INFO:__main__:Final Val Accuracy: 50.45%
INFO:__main__:Validation F1-Macro: 0.4874
INFO:__main__:Best Val Accuracy: 50.85%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.80      0.68       666
      neutral       0.46      0.38      0.41       666
contradiction       0.41      0.33      0.37       666

     accuracy                           0.50      1998
    macro avg       0.49      0.50      0.49      1998
 weighted avg       0.49      0.50      0.49      1998

INFO:__main__:Results: Accuracy = 51.44% ± 1.27%
INFO:__main__:         F1-Macro = 0.4883 ± 0.0172
INFO:__main__:         Score = 50.17
INFO:__main__:         Time = 217.5s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 8/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 1e-05, 'batch_size': 64, 'dropout_rate': 0.3, 'weight_decay': 0.001}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.5622 | Val Loss: 1.1819 | Train Acc: 31.76% | Val Acc: 31.33% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.3038 | Val Loss: 1.0819 | Train Acc: 34.93% | Val Acc: 42.69% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.1725 | Val Loss: 1.0369 | Train Acc: 39.81% | Val Acc: 49.25% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.1236 | Val Loss: 1.0104 | Train Acc: 41.95% | Val Acc: 49.90% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.0826 | Val Loss: 0.9988 | Train Acc: 44.88% | Val Acc: 50.00% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.0625 | Val Loss: 0.9823 | Train Acc: 45.93% | Val Acc: 50.10% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.0486 | Val Loss: 0.9759 | Train Acc: 47.23% | Val Acc: 50.35% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 1.0322 | Val Loss: 0.9636 | Train Acc: 48.05% | Val Acc: 50.30% | LR: 0.000010
INFO:__main__:Epoch  80/100 | Train Loss: 1.0090 | Val Loss: 0.9566 | Train Acc: 49.14% | Val Acc: 50.25% | LR: 0.000010
INFO:__main__:Epoch  90/100 | Train Loss: 1.0092 | Val Loss: 0.9515 | Train Acc: 48.57% | Val Acc: 51.25% | LR: 0.000003
INFO:__main__:Epoch 100/100 | Train Loss: 1.0012 | Val Loss: 0.9549 | Train Acc: 49.01% | Val Acc: 51.00% | LR: 0.000003
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 45.29 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 51.69%
INFO:__main__:Final Val Accuracy: 51.00%
INFO:__main__:Validation F1-Macro: 0.4790
INFO:__main__:Best Val Accuracy: 51.40%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.56      0.87      0.68       666
      neutral       0.49      0.40      0.44       666
contradiction       0.42      0.25      0.32       666

     accuracy                           0.51      1998
    macro avg       0.49      0.51      0.48      1998
 weighted avg       0.49      0.51      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3391 | Val Loss: 1.1193 | Train Acc: 33.96% | Val Acc: 39.39% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.2238 | Val Loss: 1.0346 | Train Acc: 37.31% | Val Acc: 50.45% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.1380 | Val Loss: 0.9939 | Train Acc: 41.68% | Val Acc: 51.00% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.1043 | Val Loss: 0.9739 | Train Acc: 43.57% | Val Acc: 51.15% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.0891 | Val Loss: 0.9602 | Train Acc: 44.67% | Val Acc: 50.75% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.0601 | Val Loss: 0.9530 | Train Acc: 46.30% | Val Acc: 51.20% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.0430 | Val Loss: 0.9429 | Train Acc: 47.22% | Val Acc: 51.55% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 1.0303 | Val Loss: 0.9398 | Train Acc: 47.79% | Val Acc: 51.25% | LR: 0.000005
INFO:__main__:Epoch  80/100 | Train Loss: 1.0286 | Val Loss: 0.9392 | Train Acc: 48.15% | Val Acc: 51.50% | LR: 0.000005
INFO:__main__:Epoch  90/100 | Train Loss: 1.0261 | Val Loss: 0.9374 | Train Acc: 48.02% | Val Acc: 52.15% | LR: 0.000003
INFO:__main__:Epoch 100/100 | Train Loss: 1.0176 | Val Loss: 0.9343 | Train Acc: 48.10% | Val Acc: 51.85% | LR: 0.000001
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 46.97 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 52.34%
INFO:__main__:Final Val Accuracy: 51.85%
INFO:__main__:Validation F1-Macro: 0.4763
INFO:__main__:Best Val Accuracy: 52.15%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.84      0.69       666
      neutral       0.46      0.55      0.50       666
contradiction       0.44      0.16      0.24       666

     accuracy                           0.52      1998
    macro avg       0.50      0.52      0.48      1998
 weighted avg       0.50      0.52      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3642 | Val Loss: 1.1359 | Train Acc: 32.13% | Val Acc: 33.53% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.2678 | Val Loss: 1.0615 | Train Acc: 36.12% | Val Acc: 44.04% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.1847 | Val Loss: 1.0089 | Train Acc: 39.93% | Val Acc: 50.95% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.1364 | Val Loss: 0.9842 | Train Acc: 43.36% | Val Acc: 52.75% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.0948 | Val Loss: 0.9579 | Train Acc: 45.96% | Val Acc: 53.45% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.0725 | Val Loss: 0.9458 | Train Acc: 46.05% | Val Acc: 53.05% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.0514 | Val Loss: 0.9379 | Train Acc: 46.17% | Val Acc: 53.10% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 1.0420 | Val Loss: 0.9313 | Train Acc: 47.18% | Val Acc: 53.05% | LR: 0.000010
INFO:__main__:Epoch  80/100 | Train Loss: 1.0372 | Val Loss: 0.9249 | Train Acc: 47.84% | Val Acc: 52.45% | LR: 0.000005
INFO:__main__:Epoch  90/100 | Train Loss: 1.0113 | Val Loss: 0.9288 | Train Acc: 48.79% | Val Acc: 53.50% | LR: 0.000003
INFO:__main__:Early stopping triggered at epoch 95
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 45.21 seconds
INFO:__main__:Epochs Trained: 95
INFO:__main__:Final Train Accuracy: 51.66%
INFO:__main__:Final Val Accuracy: 53.25%
INFO:__main__:Validation F1-Macro: 0.5169
INFO:__main__:Best Val Accuracy: 53.75%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.63      0.80      0.71       666
      neutral       0.47      0.48      0.48       666
contradiction       0.45      0.32      0.37       666

     accuracy                           0.53      1998
    macro avg       0.52      0.53      0.52      1998
 weighted avg       0.52      0.53      0.52      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2766 | Val Loss: 1.1088 | Train Acc: 33.68% | Val Acc: 33.48% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.1815 | Val Loss: 1.0507 | Train Acc: 36.35% | Val Acc: 36.29% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.1330 | Val Loss: 1.0165 | Train Acc: 39.48% | Val Acc: 43.89% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.0885 | Val Loss: 0.9883 | Train Acc: 43.81% | Val Acc: 50.65% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.0514 | Val Loss: 0.9797 | Train Acc: 45.85% | Val Acc: 51.15% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.0351 | Val Loss: 0.9661 | Train Acc: 46.91% | Val Acc: 51.15% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.0232 | Val Loss: 0.9595 | Train Acc: 48.40% | Val Acc: 50.35% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 1.0123 | Val Loss: 0.9549 | Train Acc: 49.16% | Val Acc: 50.10% | LR: 0.000010
INFO:__main__:Epoch  80/100 | Train Loss: 1.0060 | Val Loss: 0.9510 | Train Acc: 49.25% | Val Acc: 50.25% | LR: 0.000010
INFO:__main__:Epoch  90/100 | Train Loss: 0.9908 | Val Loss: 0.9489 | Train Acc: 50.74% | Val Acc: 50.80% | LR: 0.000005
INFO:__main__:Epoch 100/100 | Train Loss: 0.9982 | Val Loss: 0.9476 | Train Acc: 50.25% | Val Acc: 50.50% | LR: 0.000005
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 48.35 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 52.60%
INFO:__main__:Final Val Accuracy: 50.50%
INFO:__main__:Validation F1-Macro: 0.4682
INFO:__main__:Best Val Accuracy: 51.40%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.82      0.68       666
      neutral       0.46      0.52      0.49       666
contradiction       0.38      0.17      0.24       666

     accuracy                           0.51      1998
    macro avg       0.47      0.51      0.47      1998
 weighted avg       0.47      0.51      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3723 | Val Loss: 1.0953 | Train Acc: 34.06% | Val Acc: 41.79% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.2580 | Val Loss: 1.0291 | Train Acc: 38.83% | Val Acc: 46.75% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.1797 | Val Loss: 0.9996 | Train Acc: 42.38% | Val Acc: 49.90% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.1281 | Val Loss: 0.9794 | Train Acc: 44.62% | Val Acc: 50.70% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.1007 | Val Loss: 0.9697 | Train Acc: 46.17% | Val Acc: 50.40% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.0966 | Val Loss: 0.9592 | Train Acc: 46.08% | Val Acc: 50.40% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.0671 | Val Loss: 0.9493 | Train Acc: 47.10% | Val Acc: 50.70% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 1.0486 | Val Loss: 0.9480 | Train Acc: 47.89% | Val Acc: 50.70% | LR: 0.000010
INFO:__main__:Epoch  80/100 | Train Loss: 1.0408 | Val Loss: 0.9434 | Train Acc: 48.44% | Val Acc: 50.05% | LR: 0.000010
INFO:__main__:Epoch  90/100 | Train Loss: 1.0263 | Val Loss: 0.9410 | Train Acc: 49.10% | Val Acc: 50.20% | LR: 0.000005
INFO:__main__:Epoch 100/100 | Train Loss: 1.0285 | Val Loss: 0.9381 | Train Acc: 48.57% | Val Acc: 50.00% | LR: 0.000003
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 48.77 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 51.84%
INFO:__main__:Final Val Accuracy: 50.00%
INFO:__main__:Validation F1-Macro: 0.4701
INFO:__main__:Best Val Accuracy: 51.15%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.79      0.68       666
      neutral       0.44      0.53      0.48       666
contradiction       0.38      0.19      0.25       666

     accuracy                           0.50      1998
    macro avg       0.47      0.50      0.47      1998
 weighted avg       0.47      0.50      0.47      1998

INFO:__main__:Results: Accuracy = 51.32% ± 1.14%
INFO:__main__:         F1-Macro = 0.4821 ± 0.0178
INFO:__main__:         Score = 50.18
INFO:__main__:         Time = 234.6s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 9/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 1e-05, 'batch_size': 64, 'dropout_rate': 0.3, 'weight_decay': 1e-05}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.5622 | Val Loss: 1.1819 | Train Acc: 31.76% | Val Acc: 31.33% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.3039 | Val Loss: 1.0819 | Train Acc: 34.91% | Val Acc: 42.69% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.1729 | Val Loss: 1.0368 | Train Acc: 39.74% | Val Acc: 49.25% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.1240 | Val Loss: 1.0101 | Train Acc: 41.93% | Val Acc: 50.00% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.0831 | Val Loss: 0.9984 | Train Acc: 44.87% | Val Acc: 50.00% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.0630 | Val Loss: 0.9818 | Train Acc: 45.91% | Val Acc: 49.90% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.0491 | Val Loss: 0.9754 | Train Acc: 47.16% | Val Acc: 50.40% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 1.0327 | Val Loss: 0.9630 | Train Acc: 48.12% | Val Acc: 50.50% | LR: 0.000010
INFO:__main__:Epoch  80/100 | Train Loss: 1.0096 | Val Loss: 0.9560 | Train Acc: 49.07% | Val Acc: 50.20% | LR: 0.000010
INFO:__main__:Epoch  90/100 | Train Loss: 1.0100 | Val Loss: 0.9510 | Train Acc: 48.69% | Val Acc: 51.30% | LR: 0.000003
INFO:__main__:Epoch 100/100 | Train Loss: 1.0018 | Val Loss: 0.9544 | Train Acc: 49.02% | Val Acc: 50.85% | LR: 0.000003
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 48.07 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 51.66%
INFO:__main__:Final Val Accuracy: 50.85%
INFO:__main__:Validation F1-Macro: 0.4772
INFO:__main__:Best Val Accuracy: 51.45%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.56      0.87      0.68       666
      neutral       0.49      0.40      0.44       666
contradiction       0.42      0.25      0.31       666

     accuracy                           0.51      1998
    macro avg       0.49      0.51      0.48      1998
 weighted avg       0.49      0.51      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3391 | Val Loss: 1.1193 | Train Acc: 33.96% | Val Acc: 39.39% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.2240 | Val Loss: 1.0345 | Train Acc: 37.34% | Val Acc: 50.40% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.1383 | Val Loss: 0.9936 | Train Acc: 41.65% | Val Acc: 51.00% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.1047 | Val Loss: 0.9734 | Train Acc: 43.54% | Val Acc: 51.10% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.0898 | Val Loss: 0.9597 | Train Acc: 44.67% | Val Acc: 50.80% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.0608 | Val Loss: 0.9525 | Train Acc: 46.26% | Val Acc: 51.20% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.0436 | Val Loss: 0.9423 | Train Acc: 47.20% | Val Acc: 51.55% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 1.0311 | Val Loss: 0.9392 | Train Acc: 47.77% | Val Acc: 51.25% | LR: 0.000005
INFO:__main__:Epoch  80/100 | Train Loss: 1.0295 | Val Loss: 0.9386 | Train Acc: 48.22% | Val Acc: 51.50% | LR: 0.000005
INFO:__main__:Epoch  90/100 | Train Loss: 1.0268 | Val Loss: 0.9368 | Train Acc: 48.07% | Val Acc: 51.90% | LR: 0.000003
INFO:__main__:Epoch 100/100 | Train Loss: 1.0183 | Val Loss: 0.9338 | Train Acc: 48.14% | Val Acc: 51.60% | LR: 0.000001
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 46.84 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 52.29%
INFO:__main__:Final Val Accuracy: 51.60%
INFO:__main__:Validation F1-Macro: 0.4723
INFO:__main__:Best Val Accuracy: 52.05%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.84      0.69       666
      neutral       0.46      0.55      0.50       666
contradiction       0.43      0.15      0.23       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.47      1998
 weighted avg       0.49      0.52      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3643 | Val Loss: 1.1359 | Train Acc: 32.14% | Val Acc: 33.58% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.2680 | Val Loss: 1.0613 | Train Acc: 36.12% | Val Acc: 44.14% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.1849 | Val Loss: 1.0086 | Train Acc: 39.96% | Val Acc: 51.05% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.1368 | Val Loss: 0.9838 | Train Acc: 43.33% | Val Acc: 52.75% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.0951 | Val Loss: 0.9573 | Train Acc: 45.93% | Val Acc: 53.45% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.0729 | Val Loss: 0.9451 | Train Acc: 46.06% | Val Acc: 53.10% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.0518 | Val Loss: 0.9371 | Train Acc: 46.20% | Val Acc: 53.20% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 1.0427 | Val Loss: 0.9305 | Train Acc: 47.02% | Val Acc: 52.80% | LR: 0.000010
INFO:__main__:Epoch  80/100 | Train Loss: 1.0377 | Val Loss: 0.9242 | Train Acc: 47.84% | Val Acc: 52.50% | LR: 0.000005
INFO:__main__:Epoch  90/100 | Train Loss: 1.0117 | Val Loss: 0.9279 | Train Acc: 48.82% | Val Acc: 53.50% | LR: 0.000003
INFO:__main__:Early stopping triggered at epoch 95
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 45.09 seconds
INFO:__main__:Epochs Trained: 95
INFO:__main__:Final Train Accuracy: 51.64%
INFO:__main__:Final Val Accuracy: 53.25%
INFO:__main__:Validation F1-Macro: 0.5168
INFO:__main__:Best Val Accuracy: 53.70%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.63      0.80      0.71       666
      neutral       0.47      0.48      0.48       666
contradiction       0.45      0.31      0.37       666

     accuracy                           0.53      1998
    macro avg       0.52      0.53      0.52      1998
 weighted avg       0.52      0.53      0.52      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2766 | Val Loss: 1.1088 | Train Acc: 33.68% | Val Acc: 33.48% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.1816 | Val Loss: 1.0506 | Train Acc: 36.32% | Val Acc: 36.29% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.1332 | Val Loss: 1.0163 | Train Acc: 39.48% | Val Acc: 43.84% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.0887 | Val Loss: 0.9880 | Train Acc: 43.77% | Val Acc: 50.60% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.0517 | Val Loss: 0.9793 | Train Acc: 45.78% | Val Acc: 51.05% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.0353 | Val Loss: 0.9657 | Train Acc: 46.88% | Val Acc: 51.15% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.0235 | Val Loss: 0.9591 | Train Acc: 48.46% | Val Acc: 50.30% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 1.0127 | Val Loss: 0.9545 | Train Acc: 49.09% | Val Acc: 50.00% | LR: 0.000010
INFO:__main__:Epoch  80/100 | Train Loss: 1.0063 | Val Loss: 0.9506 | Train Acc: 49.27% | Val Acc: 50.10% | LR: 0.000010
INFO:__main__:Epoch  90/100 | Train Loss: 0.9911 | Val Loss: 0.9485 | Train Acc: 50.73% | Val Acc: 50.80% | LR: 0.000005
INFO:__main__:Epoch 100/100 | Train Loss: 0.9986 | Val Loss: 0.9472 | Train Acc: 50.21% | Val Acc: 50.50% | LR: 0.000005
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 46.84 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 52.49%
INFO:__main__:Final Val Accuracy: 50.50%
INFO:__main__:Validation F1-Macro: 0.4683
INFO:__main__:Best Val Accuracy: 51.35%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.82      0.68       666
      neutral       0.46      0.52      0.49       666
contradiction       0.38      0.17      0.24       666

     accuracy                           0.51      1998
    macro avg       0.47      0.51      0.47      1998
 weighted avg       0.47      0.51      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3723 | Val Loss: 1.0953 | Train Acc: 34.07% | Val Acc: 41.79% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.2583 | Val Loss: 1.0290 | Train Acc: 38.83% | Val Acc: 46.75% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.1802 | Val Loss: 0.9993 | Train Acc: 42.34% | Val Acc: 49.85% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.1288 | Val Loss: 0.9790 | Train Acc: 44.67% | Val Acc: 50.65% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.1015 | Val Loss: 0.9694 | Train Acc: 46.23% | Val Acc: 50.55% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.0977 | Val Loss: 0.9588 | Train Acc: 46.07% | Val Acc: 50.25% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.0681 | Val Loss: 0.9490 | Train Acc: 47.18% | Val Acc: 50.80% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 1.0497 | Val Loss: 0.9477 | Train Acc: 47.85% | Val Acc: 50.95% | LR: 0.000010
INFO:__main__:Epoch  80/100 | Train Loss: 1.0418 | Val Loss: 0.9432 | Train Acc: 48.37% | Val Acc: 50.00% | LR: 0.000010
INFO:__main__:Epoch  90/100 | Train Loss: 1.0273 | Val Loss: 0.9407 | Train Acc: 49.05% | Val Acc: 50.15% | LR: 0.000005
INFO:__main__:Epoch 100/100 | Train Loss: 1.0297 | Val Loss: 0.9379 | Train Acc: 48.44% | Val Acc: 50.05% | LR: 0.000003
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 45.54 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 51.93%
INFO:__main__:Final Val Accuracy: 50.05%
INFO:__main__:Validation F1-Macro: 0.4711
INFO:__main__:Best Val Accuracy: 51.10%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.79      0.68       666
      neutral       0.44      0.53      0.48       666
contradiction       0.39      0.19      0.26       666

     accuracy                           0.50      1998
    macro avg       0.47      0.50      0.47      1998
 weighted avg       0.47      0.50      0.47      1998

INFO:__main__:Results: Accuracy = 51.25% ± 1.12%
INFO:__main__:         F1-Macro = 0.4811 ± 0.0180
INFO:__main__:         Score = 50.13
INFO:__main__:         Time = 232.4s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 10/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 1e-05, 'batch_size': 32, 'dropout_rate': 0.5, 'weight_decay': 0.0001}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.6040 | Val Loss: 1.1245 | Train Acc: 32.24% | Val Acc: 30.78% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.4135 | Val Loss: 1.0791 | Train Acc: 34.01% | Val Acc: 41.44% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.2962 | Val Loss: 1.0637 | Train Acc: 35.86% | Val Acc: 41.84% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.2341 | Val Loss: 1.0411 | Train Acc: 36.97% | Val Acc: 43.29% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.1896 | Val Loss: 1.0341 | Train Acc: 38.60% | Val Acc: 43.09% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.1321 | Val Loss: 1.0209 | Train Acc: 41.03% | Val Acc: 44.14% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.1202 | Val Loss: 1.0251 | Train Acc: 41.75% | Val Acc: 43.34% | LR: 0.000005
INFO:__main__:Epoch  70/100 | Train Loss: 1.1184 | Val Loss: 1.0149 | Train Acc: 41.78% | Val Acc: 44.74% | LR: 0.000003
INFO:__main__:Epoch  80/100 | Train Loss: 1.1064 | Val Loss: 1.0172 | Train Acc: 41.59% | Val Acc: 44.79% | LR: 0.000003
INFO:__main__:Epoch  90/100 | Train Loss: 1.1008 | Val Loss: 1.0065 | Train Acc: 42.20% | Val Acc: 46.35% | LR: 0.000001
INFO:__main__:Early stopping triggered at epoch 91
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 77.08 seconds
INFO:__main__:Epochs Trained: 91
INFO:__main__:Final Train Accuracy: 46.35%
INFO:__main__:Final Val Accuracy: 45.10%
INFO:__main__:Validation F1-Macro: 0.3554
INFO:__main__:Best Val Accuracy: 47.35%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.44      0.95      0.60       666
      neutral       0.49      0.39      0.43       666
contradiction       0.39      0.02      0.03       666

     accuracy                           0.45      1998
    macro avg       0.44      0.45      0.36      1998
 weighted avg       0.44      0.45      0.36      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.4903 | Val Loss: 1.1070 | Train Acc: 34.33% | Val Acc: 36.69% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.3908 | Val Loss: 1.0729 | Train Acc: 34.75% | Val Acc: 40.74% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.3011 | Val Loss: 1.0398 | Train Acc: 36.27% | Val Acc: 45.75% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.2412 | Val Loss: 1.0208 | Train Acc: 38.21% | Val Acc: 48.05% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.1766 | Val Loss: 1.0083 | Train Acc: 39.38% | Val Acc: 49.20% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.1499 | Val Loss: 0.9921 | Train Acc: 39.99% | Val Acc: 50.85% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.1121 | Val Loss: 0.9939 | Train Acc: 41.89% | Val Acc: 50.30% | LR: 0.000005
INFO:__main__:Epoch  70/100 | Train Loss: 1.1092 | Val Loss: 0.9854 | Train Acc: 42.93% | Val Acc: 51.30% | LR: 0.000005
INFO:__main__:Epoch  80/100 | Train Loss: 1.0967 | Val Loss: 0.9811 | Train Acc: 42.15% | Val Acc: 51.00% | LR: 0.000001
INFO:__main__:Early stopping triggered at epoch 88
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 74.90 seconds
INFO:__main__:Epochs Trained: 88
INFO:__main__:Final Train Accuracy: 50.65%
INFO:__main__:Final Val Accuracy: 50.50%
INFO:__main__:Validation F1-Macro: 0.4107
INFO:__main__:Best Val Accuracy: 51.85%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.62      0.73      0.67       666
      neutral       0.43      0.79      0.56       666
contradiction       0.50      0.00      0.01       666

     accuracy                           0.51      1998
    macro avg       0.52      0.51      0.41      1998
 weighted avg       0.52      0.51      0.41      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3232 | Val Loss: 1.1167 | Train Acc: 32.88% | Val Acc: 33.88% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.2439 | Val Loss: 1.0555 | Train Acc: 35.39% | Val Acc: 48.05% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.1858 | Val Loss: 1.0223 | Train Acc: 36.45% | Val Acc: 48.55% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.1630 | Val Loss: 0.9932 | Train Acc: 39.20% | Val Acc: 52.70% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.1225 | Val Loss: 0.9846 | Train Acc: 39.84% | Val Acc: 52.10% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.1067 | Val Loss: 0.9713 | Train Acc: 40.88% | Val Acc: 53.10% | LR: 0.000005
INFO:__main__:Epoch  60/100 | Train Loss: 1.0857 | Val Loss: 0.9700 | Train Acc: 42.25% | Val Acc: 52.90% | LR: 0.000005
INFO:__main__:Epoch  70/100 | Train Loss: 1.0813 | Val Loss: 0.9720 | Train Acc: 42.74% | Val Acc: 52.85% | LR: 0.000005
INFO:__main__:Epoch  80/100 | Train Loss: 1.0787 | Val Loss: 0.9587 | Train Acc: 42.27% | Val Acc: 53.20% | LR: 0.000003
INFO:__main__:Early stopping triggered at epoch 82
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 70.26 seconds
INFO:__main__:Epochs Trained: 82
INFO:__main__:Final Train Accuracy: 51.40%
INFO:__main__:Final Val Accuracy: 52.80%
INFO:__main__:Validation F1-Macro: 0.4648
INFO:__main__:Best Val Accuracy: 53.65%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.57      0.89      0.69       666
      neutral       0.49      0.60      0.54       666
contradiction       0.45      0.10      0.16       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.46      1998
 weighted avg       0.50      0.53      0.46      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3729 | Val Loss: 1.1248 | Train Acc: 33.80% | Val Acc: 31.28% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.2853 | Val Loss: 1.0820 | Train Acc: 35.82% | Val Acc: 36.24% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.2049 | Val Loss: 1.0502 | Train Acc: 38.34% | Val Acc: 44.74% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.1717 | Val Loss: 1.0343 | Train Acc: 39.53% | Val Acc: 45.50% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.1402 | Val Loss: 1.0296 | Train Acc: 40.90% | Val Acc: 46.85% | LR: 0.000005
INFO:__main__:Epoch  50/100 | Train Loss: 1.1285 | Val Loss: 1.0223 | Train Acc: 41.97% | Val Acc: 46.95% | LR: 0.000005
INFO:__main__:Epoch  60/100 | Train Loss: 1.1229 | Val Loss: 1.0159 | Train Acc: 41.58% | Val Acc: 47.05% | LR: 0.000003
INFO:__main__:Epoch  70/100 | Train Loss: 1.1161 | Val Loss: 1.0161 | Train Acc: 42.67% | Val Acc: 47.45% | LR: 0.000003
INFO:__main__:Epoch  80/100 | Train Loss: 1.1111 | Val Loss: 1.0186 | Train Acc: 42.23% | Val Acc: 46.80% | LR: 0.000001
INFO:__main__:Early stopping triggered at epoch 84
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 72.06 seconds
INFO:__main__:Epochs Trained: 84
INFO:__main__:Final Train Accuracy: 48.77%
INFO:__main__:Final Val Accuracy: 47.80%
INFO:__main__:Validation F1-Macro: 0.4706
INFO:__main__:Best Val Accuracy: 48.85%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.66      0.59      0.62       666
      neutral       0.49      0.25      0.33       666
contradiction       0.37      0.60      0.46       666

     accuracy                           0.48      1998
    macro avg       0.51      0.48      0.47      1998
 weighted avg       0.51      0.48      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.4921 | Val Loss: 1.1116 | Train Acc: 32.58% | Val Acc: 33.03% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.3960 | Val Loss: 1.0564 | Train Acc: 35.75% | Val Acc: 44.34% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.3150 | Val Loss: 1.0261 | Train Acc: 37.20% | Val Acc: 47.65% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.2601 | Val Loss: 1.0105 | Train Acc: 38.55% | Val Acc: 48.25% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.2308 | Val Loss: 0.9897 | Train Acc: 39.10% | Val Acc: 51.20% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.1703 | Val Loss: 0.9860 | Train Acc: 40.79% | Val Acc: 50.90% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.1457 | Val Loss: 0.9740 | Train Acc: 41.93% | Val Acc: 51.45% | LR: 0.000005
INFO:__main__:Epoch  70/100 | Train Loss: 1.1472 | Val Loss: 0.9723 | Train Acc: 42.30% | Val Acc: 50.60% | LR: 0.000003
INFO:__main__:Epoch  80/100 | Train Loss: 1.1365 | Val Loss: 0.9629 | Train Acc: 42.17% | Val Acc: 51.90% | LR: 0.000003
INFO:__main__:Epoch  90/100 | Train Loss: 1.1256 | Val Loss: 0.9721 | Train Acc: 42.63% | Val Acc: 50.65% | LR: 0.000001
INFO:__main__:Early stopping triggered at epoch 95
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 81.87 seconds
INFO:__main__:Epochs Trained: 95
INFO:__main__:Final Train Accuracy: 51.56%
INFO:__main__:Final Val Accuracy: 51.75%
INFO:__main__:Validation F1-Macro: 0.4321
INFO:__main__:Best Val Accuracy: 52.65%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.57      0.84      0.68       666
      neutral       0.47      0.67      0.55       666
contradiction       0.45      0.03      0.06       666

     accuracy                           0.52      1998
    macro avg       0.50      0.52      0.43      1998
 weighted avg       0.50      0.52      0.43      1998

INFO:__main__:Results: Accuracy = 49.59% ± 2.80%
INFO:__main__:         F1-Macro = 0.4267 ± 0.0418
INFO:__main__:         Score = 46.79
INFO:__main__:         Time = 376.2s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 11/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.0005, 'batch_size': 128, 'dropout_rate': 0.3, 'weight_decay': 0.001}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2462 | Val Loss: 1.0061 | Train Acc: 37.63% | Val Acc: 49.60% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9434 | Val Loss: 0.9236 | Train Acc: 50.51% | Val Acc: 51.75% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9361 | Val Loss: 0.9227 | Train Acc: 52.53% | Val Acc: 51.50% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9276 | Val Loss: 0.9210 | Train Acc: 52.16% | Val Acc: 51.75% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 38
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 9.94 seconds
INFO:__main__:Epochs Trained: 38
INFO:__main__:Final Train Accuracy: 52.68%
INFO:__main__:Final Val Accuracy: 51.85%
INFO:__main__:Validation F1-Macro: 0.4907
INFO:__main__:Best Val Accuracy: 52.55%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.81      0.68       666
      neutral       0.48      0.53      0.50       666
contradiction       0.41      0.22      0.28       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.49      1998
 weighted avg       0.49      0.52      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1473 | Val Loss: 0.9685 | Train Acc: 42.52% | Val Acc: 51.50% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9514 | Val Loss: 0.9252 | Train Acc: 50.59% | Val Acc: 52.10% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9342 | Val Loss: 0.9226 | Train Acc: 51.70% | Val Acc: 51.60% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9282 | Val Loss: 0.9223 | Train Acc: 51.59% | Val Acc: 52.25% | LR: 0.000500
INFO:__main__:Epoch  40/100 | Train Loss: 0.9273 | Val Loss: 0.9212 | Train Acc: 51.44% | Val Acc: 52.40% | LR: 0.000250
INFO:__main__:Epoch  50/100 | Train Loss: 0.9274 | Val Loss: 0.9213 | Train Acc: 51.89% | Val Acc: 52.70% | LR: 0.000063
INFO:__main__:Early stopping triggered at epoch 53
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 13.74 seconds
INFO:__main__:Epochs Trained: 53
INFO:__main__:Final Train Accuracy: 52.54%
INFO:__main__:Final Val Accuracy: 52.50%
INFO:__main__:Validation F1-Macro: 0.4868
INFO:__main__:Best Val Accuracy: 52.85%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.81      0.69       666
      neutral       0.49      0.60      0.54       666
contradiction       0.41      0.17      0.24       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.49      1998
 weighted avg       0.50      0.53      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2011 | Val Loss: 0.9566 | Train Acc: 40.50% | Val Acc: 52.70% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9619 | Val Loss: 0.9024 | Train Acc: 50.54% | Val Acc: 52.60% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9411 | Val Loss: 0.9002 | Train Acc: 51.06% | Val Acc: 52.10% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9326 | Val Loss: 0.9012 | Train Acc: 51.81% | Val Acc: 53.50% | LR: 0.000500
INFO:__main__:Epoch  40/100 | Train Loss: 0.9329 | Val Loss: 0.8993 | Train Acc: 52.28% | Val Acc: 52.70% | LR: 0.000125
INFO:__main__:Epoch  50/100 | Train Loss: 0.9337 | Val Loss: 0.8998 | Train Acc: 51.34% | Val Acc: 52.95% | LR: 0.000063
INFO:__main__:Early stopping triggered at epoch 55
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 14.00 seconds
INFO:__main__:Epochs Trained: 55
INFO:__main__:Final Train Accuracy: 52.46%
INFO:__main__:Final Val Accuracy: 52.85%
INFO:__main__:Validation F1-Macro: 0.5027
INFO:__main__:Best Val Accuracy: 53.50%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.84      0.70       666
      neutral       0.48      0.49      0.49       666
contradiction       0.44      0.26      0.32       666

     accuracy                           0.53      1998
    macro avg       0.51      0.53      0.50      1998
 weighted avg       0.51      0.53      0.50      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2057 | Val Loss: 1.0273 | Train Acc: 37.93% | Val Acc: 46.05% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9537 | Val Loss: 0.9344 | Train Acc: 51.40% | Val Acc: 51.65% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9334 | Val Loss: 0.9307 | Train Acc: 52.08% | Val Acc: 50.30% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9286 | Val Loss: 0.9304 | Train Acc: 52.33% | Val Acc: 50.40% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 38
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 9.51 seconds
INFO:__main__:Epochs Trained: 38
INFO:__main__:Final Train Accuracy: 53.04%
INFO:__main__:Final Val Accuracy: 50.40%
INFO:__main__:Validation F1-Macro: 0.4527
INFO:__main__:Best Val Accuracy: 51.65%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.83      0.68       666
      neutral       0.45      0.57      0.51       666
contradiction       0.37      0.11      0.17       666

     accuracy                           0.50      1998
    macro avg       0.47      0.50      0.45      1998
 weighted avg       0.47      0.50      0.45      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2200 | Val Loss: 0.9687 | Train Acc: 39.41% | Val Acc: 51.60% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9474 | Val Loss: 0.9175 | Train Acc: 50.61% | Val Acc: 51.70% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9375 | Val Loss: 0.9162 | Train Acc: 51.61% | Val Acc: 52.20% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9293 | Val Loss: 0.9170 | Train Acc: 51.10% | Val Acc: 52.60% | LR: 0.000125
INFO:__main__:Epoch  40/100 | Train Loss: 0.9299 | Val Loss: 0.9169 | Train Acc: 51.28% | Val Acc: 52.75% | LR: 0.000063
INFO:__main__:Early stopping triggered at epoch 47
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 11.99 seconds
INFO:__main__:Epochs Trained: 47
INFO:__main__:Final Train Accuracy: 52.62%
INFO:__main__:Final Val Accuracy: 52.80%
INFO:__main__:Validation F1-Macro: 0.4861
INFO:__main__:Best Val Accuracy: 53.15%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.82      0.69       666
      neutral       0.49      0.60      0.54       666
contradiction       0.43      0.16      0.23       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.49      1998
 weighted avg       0.50      0.53      0.49      1998

INFO:__main__:Results: Accuracy = 52.08% ± 0.91%
INFO:__main__:         F1-Macro = 0.4838 ± 0.0166
INFO:__main__:         Score = 51.17
INFO:__main__:         Time = 59.2s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 12/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.001, 'batch_size': 64, 'dropout_rate': 0.3, 'weight_decay': 1e-05}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1071 | Val Loss: 0.9435 | Train Acc: 44.14% | Val Acc: 51.70% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9339 | Val Loss: 0.9234 | Train Acc: 51.70% | Val Acc: 51.10% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9274 | Val Loss: 0.9207 | Train Acc: 51.65% | Val Acc: 52.05% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9267 | Val Loss: 0.9206 | Train Acc: 52.58% | Val Acc: 52.15% | LR: 0.000500
INFO:__main__:Early stopping triggered at epoch 37
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 16.56 seconds
INFO:__main__:Epochs Trained: 37
INFO:__main__:Final Train Accuracy: 52.45%
INFO:__main__:Final Val Accuracy: 52.45%
INFO:__main__:Validation F1-Macro: 0.4762
INFO:__main__:Best Val Accuracy: 52.45%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.82      0.69       666
      neutral       0.48      0.62      0.54       666
contradiction       0.41      0.13      0.20       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.48      1998
 weighted avg       0.49      0.52      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0701 | Val Loss: 0.9470 | Train Acc: 45.41% | Val Acc: 50.50% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9341 | Val Loss: 0.9210 | Train Acc: 51.89% | Val Acc: 52.45% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9259 | Val Loss: 0.9189 | Train Acc: 51.98% | Val Acc: 51.95% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9279 | Val Loss: 0.9190 | Train Acc: 51.90% | Val Acc: 51.70% | LR: 0.001000
INFO:__main__:Epoch  40/100 | Train Loss: 0.9271 | Val Loss: 0.9185 | Train Acc: 51.96% | Val Acc: 51.80% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 41
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 18.45 seconds
INFO:__main__:Epochs Trained: 41
INFO:__main__:Final Train Accuracy: 52.23%
INFO:__main__:Final Val Accuracy: 51.50%
INFO:__main__:Validation F1-Macro: 0.4812
INFO:__main__:Best Val Accuracy: 52.90%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.83      0.68       666
      neutral       0.49      0.53      0.51       666
contradiction       0.38      0.19      0.25       666

     accuracy                           0.52      1998
    macro avg       0.48      0.52      0.48      1998
 weighted avg       0.48      0.52      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0825 | Val Loss: 0.9071 | Train Acc: 45.35% | Val Acc: 53.60% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9395 | Val Loss: 0.8993 | Train Acc: 51.33% | Val Acc: 52.60% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9280 | Val Loss: 0.8970 | Train Acc: 51.96% | Val Acc: 52.80% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9313 | Val Loss: 0.8981 | Train Acc: 52.08% | Val Acc: 52.20% | LR: 0.000500
INFO:__main__:Early stopping triggered at epoch 35
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 15.94 seconds
INFO:__main__:Epochs Trained: 35
INFO:__main__:Final Train Accuracy: 52.03%
INFO:__main__:Final Val Accuracy: 52.40%
INFO:__main__:Validation F1-Macro: 0.4887
INFO:__main__:Best Val Accuracy: 53.70%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.85      0.69       666
      neutral       0.48      0.53      0.51       666
contradiction       0.42      0.19      0.27       666

     accuracy                           0.52      1998
    macro avg       0.50      0.52      0.49      1998
 weighted avg       0.50      0.52      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0859 | Val Loss: 0.9531 | Train Acc: 46.25% | Val Acc: 50.35% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9395 | Val Loss: 0.9305 | Train Acc: 51.51% | Val Acc: 51.15% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9234 | Val Loss: 0.9279 | Train Acc: 52.44% | Val Acc: 51.20% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9239 | Val Loss: 0.9285 | Train Acc: 51.89% | Val Acc: 50.65% | LR: 0.001000
INFO:__main__:Epoch  40/100 | Train Loss: 0.9272 | Val Loss: 0.9278 | Train Acc: 52.35% | Val Acc: 50.40% | LR: 0.000500
INFO:__main__:Epoch  50/100 | Train Loss: 0.9236 | Val Loss: 0.9287 | Train Acc: 51.89% | Val Acc: 50.75% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 58
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 26.48 seconds
INFO:__main__:Epochs Trained: 58
INFO:__main__:Final Train Accuracy: 52.73%
INFO:__main__:Final Val Accuracy: 50.45%
INFO:__main__:Validation F1-Macro: 0.4610
INFO:__main__:Best Val Accuracy: 51.85%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.57      0.85      0.68       666
      neutral       0.46      0.52      0.49       666
contradiction       0.38      0.15      0.21       666

     accuracy                           0.50      1998
    macro avg       0.47      0.50      0.46      1998
 weighted avg       0.47      0.50      0.46      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0745 | Val Loss: 0.9301 | Train Acc: 45.06% | Val Acc: 51.75% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9340 | Val Loss: 0.9200 | Train Acc: 51.48% | Val Acc: 52.60% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9272 | Val Loss: 0.9202 | Train Acc: 51.88% | Val Acc: 53.00% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 22
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 10.26 seconds
INFO:__main__:Epochs Trained: 22
INFO:__main__:Final Train Accuracy: 52.41%
INFO:__main__:Final Val Accuracy: 53.10%
INFO:__main__:Validation F1-Macro: 0.4892
INFO:__main__:Best Val Accuracy: 53.10%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.82      0.69       666
      neutral       0.49      0.62      0.55       666
contradiction       0.41      0.16      0.23       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.49      1998
 weighted avg       0.50      0.53      0.49      1998

INFO:__main__:Results: Accuracy = 51.98% ± 0.92%
INFO:__main__:         F1-Macro = 0.4793 ± 0.0103
INFO:__main__:         Score = 51.06
INFO:__main__:         Time = 87.7s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 13/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.0005, 'batch_size': 64, 'dropout_rate': 0.3, 'weight_decay': 0.001}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1966 | Val Loss: 0.9792 | Train Acc: 39.95% | Val Acc: 49.45% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9402 | Val Loss: 0.9249 | Train Acc: 52.31% | Val Acc: 51.40% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9311 | Val Loss: 0.9223 | Train Acc: 51.63% | Val Acc: 51.75% | LR: 0.000250
INFO:__main__:Epoch  30/100 | Train Loss: 0.9314 | Val Loss: 0.9213 | Train Acc: 52.41% | Val Acc: 51.20% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 38
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 17.37 seconds
INFO:__main__:Epochs Trained: 38
INFO:__main__:Final Train Accuracy: 52.75%
INFO:__main__:Final Val Accuracy: 51.50%
INFO:__main__:Validation F1-Macro: 0.4722
INFO:__main__:Best Val Accuracy: 52.30%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.80      0.68       666
      neutral       0.46      0.60      0.52       666
contradiction       0.41      0.14      0.21       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.47      1998
 weighted avg       0.49      0.52      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1152 | Val Loss: 0.9620 | Train Acc: 43.51% | Val Acc: 51.50% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9442 | Val Loss: 0.9229 | Train Acc: 50.90% | Val Acc: 51.20% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9324 | Val Loss: 0.9211 | Train Acc: 51.13% | Val Acc: 51.50% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9306 | Val Loss: 0.9211 | Train Acc: 51.84% | Val Acc: 52.75% | LR: 0.000250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9303 | Val Loss: 0.9198 | Train Acc: 51.64% | Val Acc: 52.15% | LR: 0.000125
INFO:__main__:Epoch  50/100 | Train Loss: 0.9259 | Val Loss: 0.9186 | Train Acc: 51.79% | Val Acc: 52.50% | LR: 0.000125
INFO:__main__:Epoch  60/100 | Train Loss: 0.9260 | Val Loss: 0.9184 | Train Acc: 51.88% | Val Acc: 52.95% | LR: 0.000063
INFO:__main__:Epoch  70/100 | Train Loss: 0.9237 | Val Loss: 0.9184 | Train Acc: 51.84% | Val Acc: 52.85% | LR: 0.000031
INFO:__main__:Early stopping triggered at epoch 76
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 34.76 seconds
INFO:__main__:Epochs Trained: 76
INFO:__main__:Final Train Accuracy: 52.64%
INFO:__main__:Final Val Accuracy: 53.05%
INFO:__main__:Validation F1-Macro: 0.4839
INFO:__main__:Best Val Accuracy: 53.10%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.81      0.69       666
      neutral       0.49      0.64      0.55       666
contradiction       0.42      0.14      0.21       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.48      1998
 weighted avg       0.50      0.53      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0802 | Val Loss: 0.9289 | Train Acc: 44.76% | Val Acc: 50.95% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9432 | Val Loss: 0.8995 | Train Acc: 50.63% | Val Acc: 52.55% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9343 | Val Loss: 0.9003 | Train Acc: 51.45% | Val Acc: 53.00% | LR: 0.000250
INFO:__main__:Epoch  30/100 | Train Loss: 0.9334 | Val Loss: 0.8993 | Train Acc: 51.64% | Val Acc: 53.10% | LR: 0.000250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9332 | Val Loss: 0.8990 | Train Acc: 51.18% | Val Acc: 53.50% | LR: 0.000063
INFO:__main__:Early stopping triggered at epoch 41
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 18.66 seconds
INFO:__main__:Epochs Trained: 41
INFO:__main__:Final Train Accuracy: 52.26%
INFO:__main__:Final Val Accuracy: 53.55%
INFO:__main__:Validation F1-Macro: 0.4840
INFO:__main__:Best Val Accuracy: 53.95%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.84      0.70       666
      neutral       0.49      0.64      0.56       666
contradiction       0.42      0.13      0.20       666

     accuracy                           0.54      1998
    macro avg       0.51      0.54      0.48      1998
 weighted avg       0.51      0.54      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1184 | Val Loss: 0.9686 | Train Acc: 41.84% | Val Acc: 50.70% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9375 | Val Loss: 0.9306 | Train Acc: 50.98% | Val Acc: 50.65% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9300 | Val Loss: 0.9302 | Train Acc: 51.56% | Val Acc: 50.35% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9274 | Val Loss: 0.9302 | Train Acc: 51.76% | Val Acc: 50.30% | LR: 0.000500
INFO:__main__:Epoch  40/100 | Train Loss: 0.9241 | Val Loss: 0.9281 | Train Acc: 51.38% | Val Acc: 50.25% | LR: 0.000125
INFO:__main__:Epoch  50/100 | Train Loss: 0.9230 | Val Loss: 0.9285 | Train Acc: 51.95% | Val Acc: 50.15% | LR: 0.000063
INFO:__main__:Epoch  60/100 | Train Loss: 0.9258 | Val Loss: 0.9278 | Train Acc: 51.95% | Val Acc: 50.55% | LR: 0.000016
INFO:__main__:Epoch  70/100 | Train Loss: 0.9269 | Val Loss: 0.9281 | Train Acc: 52.05% | Val Acc: 50.35% | LR: 0.000008
INFO:__main__:Epoch  80/100 | Train Loss: 0.9247 | Val Loss: 0.9291 | Train Acc: 52.55% | Val Acc: 50.45% | LR: 0.000002
INFO:__main__:Early stopping triggered at epoch 81
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 37.00 seconds
INFO:__main__:Epochs Trained: 81
INFO:__main__:Final Train Accuracy: 52.92%
INFO:__main__:Final Val Accuracy: 50.40%
INFO:__main__:Validation F1-Macro: 0.4627
INFO:__main__:Best Val Accuracy: 51.60%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.83      0.68       666
      neutral       0.46      0.53      0.49       666
contradiction       0.36      0.15      0.21       666

     accuracy                           0.50      1998
    macro avg       0.47      0.50      0.46      1998
 weighted avg       0.47      0.50      0.46      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1130 | Val Loss: 0.9592 | Train Acc: 44.37% | Val Acc: 49.75% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9397 | Val Loss: 0.9215 | Train Acc: 50.75% | Val Acc: 52.70% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9324 | Val Loss: 0.9219 | Train Acc: 52.59% | Val Acc: 52.70% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 26
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 12.16 seconds
INFO:__main__:Epochs Trained: 26
INFO:__main__:Final Train Accuracy: 52.26%
INFO:__main__:Final Val Accuracy: 53.25%
INFO:__main__:Validation F1-Macro: 0.4880
INFO:__main__:Best Val Accuracy: 53.75%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.82      0.69       666
      neutral       0.49      0.63      0.55       666
contradiction       0.45      0.15      0.23       666

     accuracy                           0.53      1998
    macro avg       0.51      0.53      0.49      1998
 weighted avg       0.51      0.53      0.49      1998

INFO:__main__:Results: Accuracy = 52.35% ± 1.21%
INFO:__main__:         F1-Macro = 0.4782 ± 0.0093
INFO:__main__:         Score = 51.15
INFO:__main__:         Time = 120.0s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 14/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.0005, 'batch_size': 64, 'dropout_rate': 0.3, 'weight_decay': 0.0001}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1969 | Val Loss: 0.9786 | Train Acc: 40.03% | Val Acc: 49.55% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9408 | Val Loss: 0.9245 | Train Acc: 52.41% | Val Acc: 51.50% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9310 | Val Loss: 0.9216 | Train Acc: 51.51% | Val Acc: 51.90% | LR: 0.000250
INFO:__main__:Epoch  30/100 | Train Loss: 0.9324 | Val Loss: 0.9210 | Train Acc: 52.30% | Val Acc: 51.05% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 38
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 17.55 seconds
INFO:__main__:Epochs Trained: 38
INFO:__main__:Final Train Accuracy: 52.52%
INFO:__main__:Final Val Accuracy: 51.80%
INFO:__main__:Validation F1-Macro: 0.4785
INFO:__main__:Best Val Accuracy: 52.40%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.81      0.68       666
      neutral       0.47      0.59      0.52       666
contradiction       0.42      0.16      0.23       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.48      1998
 weighted avg       0.49      0.52      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1155 | Val Loss: 0.9617 | Train Acc: 43.54% | Val Acc: 51.50% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9451 | Val Loss: 0.9225 | Train Acc: 51.08% | Val Acc: 51.30% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9329 | Val Loss: 0.9206 | Train Acc: 51.10% | Val Acc: 52.20% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9311 | Val Loss: 0.9207 | Train Acc: 51.76% | Val Acc: 52.45% | LR: 0.000250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9311 | Val Loss: 0.9193 | Train Acc: 51.89% | Val Acc: 52.30% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 48
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 21.93 seconds
INFO:__main__:Epochs Trained: 48
INFO:__main__:Final Train Accuracy: 52.38%
INFO:__main__:Final Val Accuracy: 52.80%
INFO:__main__:Validation F1-Macro: 0.4792
INFO:__main__:Best Val Accuracy: 53.00%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.81      0.69       666
      neutral       0.48      0.64      0.55       666
contradiction       0.42      0.13      0.20       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.48      1998
 weighted avg       0.50      0.53      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1705 | Val Loss: 0.9313 | Train Acc: 40.53% | Val Acc: 51.75% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9423 | Val Loss: 0.9016 | Train Acc: 51.60% | Val Acc: 53.05% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9425 | Val Loss: 0.9029 | Train Acc: 51.05% | Val Acc: 53.20% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9364 | Val Loss: 0.8998 | Train Acc: 51.15% | Val Acc: 53.55% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 34
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 15.60 seconds
INFO:__main__:Epochs Trained: 34
INFO:__main__:Final Train Accuracy: 52.35%
INFO:__main__:Final Val Accuracy: 52.70%
INFO:__main__:Validation F1-Macro: 0.4583
INFO:__main__:Best Val Accuracy: 53.60%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.85      0.69       666
      neutral       0.48      0.65      0.56       666
contradiction       0.40      0.08      0.13       666

     accuracy                           0.53      1998
    macro avg       0.49      0.53      0.46      1998
 weighted avg       0.49      0.53      0.46      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1629 | Val Loss: 0.9864 | Train Acc: 43.99% | Val Acc: 49.20% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9435 | Val Loss: 0.9324 | Train Acc: 51.91% | Val Acc: 50.80% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9334 | Val Loss: 0.9300 | Train Acc: 51.41% | Val Acc: 50.45% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9286 | Val Loss: 0.9295 | Train Acc: 52.74% | Val Acc: 50.30% | LR: 0.000250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9279 | Val Loss: 0.9288 | Train Acc: 51.66% | Val Acc: 50.25% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 49
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 22.57 seconds
INFO:__main__:Epochs Trained: 49
INFO:__main__:Final Train Accuracy: 52.79%
INFO:__main__:Final Val Accuracy: 50.35%
INFO:__main__:Validation F1-Macro: 0.4575
INFO:__main__:Best Val Accuracy: 50.95%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.57      0.83      0.68       666
      neutral       0.46      0.55      0.50       666
contradiction       0.36      0.13      0.19       666

     accuracy                           0.50      1998
    macro avg       0.47      0.50      0.46      1998
 weighted avg       0.47      0.50      0.46      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1574 | Val Loss: 0.9408 | Train Acc: 41.80% | Val Acc: 50.50% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9424 | Val Loss: 0.9228 | Train Acc: 50.78% | Val Acc: 52.95% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9366 | Val Loss: 0.9225 | Train Acc: 51.38% | Val Acc: 52.75% | LR: 0.000250
INFO:__main__:Epoch  30/100 | Train Loss: 0.9345 | Val Loss: 0.9212 | Train Acc: 52.15% | Val Acc: 53.10% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 39
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 17.87 seconds
INFO:__main__:Epochs Trained: 39
INFO:__main__:Final Train Accuracy: 52.28%
INFO:__main__:Final Val Accuracy: 52.90%
INFO:__main__:Validation F1-Macro: 0.4749
INFO:__main__:Best Val Accuracy: 53.20%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.83      0.69       666
      neutral       0.49      0.64      0.56       666
contradiction       0.41      0.12      0.18       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.47      1998
 weighted avg       0.50      0.53      0.47      1998

INFO:__main__:Results: Accuracy = 52.11% ± 0.96%
INFO:__main__:         F1-Macro = 0.4697 ± 0.0097
INFO:__main__:         Score = 51.15
INFO:__main__:         Time = 95.6s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 15/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.005, 'batch_size': 32, 'dropout_rate': 0.5, 'weight_decay': 0.0001}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0253 | Val Loss: 0.9368 | Train Acc: 48.45% | Val Acc: 52.05% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9444 | Val Loss: 0.9262 | Train Acc: 50.18% | Val Acc: 50.30% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9405 | Val Loss: 0.9225 | Train Acc: 50.75% | Val Acc: 52.20% | LR: 0.001250
INFO:__main__:Early stopping triggered at epoch 22
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 19.04 seconds
INFO:__main__:Epochs Trained: 22
INFO:__main__:Final Train Accuracy: 51.88%
INFO:__main__:Final Val Accuracy: 51.25%
INFO:__main__:Validation F1-Macro: 0.4900
INFO:__main__:Best Val Accuracy: 52.85%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.80      0.69       666
      neutral       0.50      0.25      0.34       666
contradiction       0.42      0.48      0.45       666

     accuracy                           0.51      1998
    macro avg       0.51      0.51      0.49      1998
 weighted avg       0.51      0.51      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0315 | Val Loss: 0.9360 | Train Acc: 47.20% | Val Acc: 51.90% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9459 | Val Loss: 0.9205 | Train Acc: 50.35% | Val Acc: 52.15% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9394 | Val Loss: 0.9273 | Train Acc: 51.76% | Val Acc: 52.00% | LR: 0.002500
INFO:__main__:Early stopping triggered at epoch 25
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 21.85 seconds
INFO:__main__:Epochs Trained: 25
INFO:__main__:Final Train Accuracy: 52.50%
INFO:__main__:Final Val Accuracy: 51.95%
INFO:__main__:Validation F1-Macro: 0.4756
INFO:__main__:Best Val Accuracy: 52.30%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.82      0.68       666
      neutral       0.49      0.60      0.54       666
contradiction       0.38      0.14      0.21       666

     accuracy                           0.52      1998
    macro avg       0.48      0.52      0.48      1998
 weighted avg       0.48      0.52      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0241 | Val Loss: 0.9220 | Train Acc: 47.28% | Val Acc: 51.30% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9449 | Val Loss: 0.9038 | Train Acc: 50.94% | Val Acc: 52.75% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9457 | Val Loss: 0.9060 | Train Acc: 50.99% | Val Acc: 53.00% | LR: 0.001250
INFO:__main__:Early stopping triggered at epoch 22
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 19.30 seconds
INFO:__main__:Epochs Trained: 22
INFO:__main__:Final Train Accuracy: 51.90%
INFO:__main__:Final Val Accuracy: 53.10%
INFO:__main__:Validation F1-Macro: 0.4806
INFO:__main__:Best Val Accuracy: 53.50%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.84      0.70       666
      neutral       0.49      0.62      0.55       666
contradiction       0.40      0.13      0.19       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.48      1998
 weighted avg       0.50      0.53      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0349 | Val Loss: 0.9457 | Train Acc: 46.51% | Val Acc: 50.70% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9418 | Val Loss: 0.9318 | Train Acc: 51.26% | Val Acc: 50.20% | LR: 0.002500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9437 | Val Loss: 0.9331 | Train Acc: 50.81% | Val Acc: 50.55% | LR: 0.002500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9362 | Val Loss: 0.9322 | Train Acc: 51.30% | Val Acc: 50.80% | LR: 0.000625
INFO:__main__:Early stopping triggered at epoch 38
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 32.75 seconds
INFO:__main__:Epochs Trained: 38
INFO:__main__:Final Train Accuracy: 52.52%
INFO:__main__:Final Val Accuracy: 50.65%
INFO:__main__:Validation F1-Macro: 0.4709
INFO:__main__:Best Val Accuracy: 51.45%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.57      0.84      0.68       666
      neutral       0.47      0.50      0.48       666
contradiction       0.39      0.18      0.25       666

     accuracy                           0.51      1998
    macro avg       0.48      0.51      0.47      1998
 weighted avg       0.48      0.51      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0066 | Val Loss: 0.9485 | Train Acc: 47.47% | Val Acc: 50.40% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9479 | Val Loss: 0.9256 | Train Acc: 50.70% | Val Acc: 52.00% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9411 | Val Loss: 0.9212 | Train Acc: 51.39% | Val Acc: 52.60% | LR: 0.001250
INFO:__main__:Early stopping triggered at epoch 21
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 18.32 seconds
INFO:__main__:Epochs Trained: 21
INFO:__main__:Final Train Accuracy: 52.15%
INFO:__main__:Final Val Accuracy: 52.90%
INFO:__main__:Validation F1-Macro: 0.4622
INFO:__main__:Best Val Accuracy: 53.00%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.83      0.69       666
      neutral       0.48      0.68      0.56       666
contradiction       0.43      0.08      0.13       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.46      1998
 weighted avg       0.50      0.53      0.46      1998

INFO:__main__:Results: Accuracy = 51.97% ± 0.94%
INFO:__main__:         F1-Macro = 0.4759 ± 0.0093
INFO:__main__:         Score = 51.03
INFO:__main__:         Time = 111.3s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 16/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 1e-05, 'batch_size': 128, 'dropout_rate': 0.3, 'weight_decay': 0.001}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.5473 | Val Loss: 1.1925 | Train Acc: 31.31% | Val Acc: 30.03% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.3767 | Val Loss: 1.1083 | Train Acc: 33.88% | Val Acc: 39.19% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.2307 | Val Loss: 1.0644 | Train Acc: 36.41% | Val Acc: 47.00% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.1675 | Val Loss: 1.0366 | Train Acc: 39.25% | Val Acc: 49.30% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.1408 | Val Loss: 1.0159 | Train Acc: 41.00% | Val Acc: 49.95% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.1035 | Val Loss: 1.0047 | Train Acc: 42.97% | Val Acc: 50.15% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.0872 | Val Loss: 0.9983 | Train Acc: 45.33% | Val Acc: 49.90% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 1.0764 | Val Loss: 0.9885 | Train Acc: 45.10% | Val Acc: 50.80% | LR: 0.000010
INFO:__main__:Epoch  80/100 | Train Loss: 1.0507 | Val Loss: 0.9811 | Train Acc: 47.30% | Val Acc: 50.60% | LR: 0.000010
INFO:__main__:Epoch  90/100 | Train Loss: 1.0427 | Val Loss: 0.9747 | Train Acc: 47.80% | Val Acc: 50.55% | LR: 0.000010
INFO:__main__:Epoch 100/100 | Train Loss: 1.0191 | Val Loss: 0.9685 | Train Acc: 48.16% | Val Acc: 50.25% | LR: 0.000005
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 25.41 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 51.75%
INFO:__main__:Final Val Accuracy: 50.25%
INFO:__main__:Validation F1-Macro: 0.4744
INFO:__main__:Best Val Accuracy: 51.25%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.55      0.86      0.68       666
      neutral       0.48      0.34      0.40       666
contradiction       0.41      0.30      0.35       666

     accuracy                           0.50      1998
    macro avg       0.48      0.50      0.47      1998
 weighted avg       0.48      0.50      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3138 | Val Loss: 1.1224 | Train Acc: 35.21% | Val Acc: 39.64% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.2277 | Val Loss: 1.0575 | Train Acc: 38.26% | Val Acc: 46.20% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.1695 | Val Loss: 1.0199 | Train Acc: 40.14% | Val Acc: 51.15% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.1411 | Val Loss: 0.9964 | Train Acc: 40.68% | Val Acc: 50.30% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.1298 | Val Loss: 0.9828 | Train Acc: 42.45% | Val Acc: 51.35% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.0846 | Val Loss: 0.9734 | Train Acc: 44.73% | Val Acc: 50.30% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.0657 | Val Loss: 0.9603 | Train Acc: 45.47% | Val Acc: 50.35% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 1.0560 | Val Loss: 0.9563 | Train Acc: 45.86% | Val Acc: 51.15% | LR: 0.000010
INFO:__main__:Epoch  80/100 | Train Loss: 1.0550 | Val Loss: 0.9487 | Train Acc: 46.26% | Val Acc: 51.35% | LR: 0.000010
INFO:__main__:Epoch  90/100 | Train Loss: 1.0385 | Val Loss: 0.9475 | Train Acc: 47.51% | Val Acc: 50.95% | LR: 0.000010
INFO:__main__:Epoch 100/100 | Train Loss: 1.0173 | Val Loss: 0.9416 | Train Acc: 48.65% | Val Acc: 51.65% | LR: 0.000010
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 25.34 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 52.19%
INFO:__main__:Final Val Accuracy: 51.65%
INFO:__main__:Validation F1-Macro: 0.4620
INFO:__main__:Best Val Accuracy: 51.80%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.85      0.69       666
      neutral       0.46      0.59      0.52       666
contradiction       0.44      0.11      0.18       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.46      1998
 weighted avg       0.49      0.52      0.46      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3633 | Val Loss: 1.1499 | Train Acc: 32.39% | Val Acc: 32.23% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.2976 | Val Loss: 1.0895 | Train Acc: 35.17% | Val Acc: 41.14% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.2280 | Val Loss: 1.0441 | Train Acc: 38.55% | Val Acc: 46.15% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.1748 | Val Loss: 1.0123 | Train Acc: 39.94% | Val Acc: 51.50% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.1464 | Val Loss: 0.9863 | Train Acc: 42.08% | Val Acc: 53.20% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.1096 | Val Loss: 0.9721 | Train Acc: 44.43% | Val Acc: 52.60% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.1032 | Val Loss: 0.9563 | Train Acc: 45.07% | Val Acc: 53.10% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 1.0878 | Val Loss: 0.9506 | Train Acc: 46.28% | Val Acc: 53.30% | LR: 0.000010
INFO:__main__:Epoch  80/100 | Train Loss: 1.0598 | Val Loss: 0.9426 | Train Acc: 46.38% | Val Acc: 53.50% | LR: 0.000010
INFO:__main__:Epoch  90/100 | Train Loss: 1.0392 | Val Loss: 0.9405 | Train Acc: 47.15% | Val Acc: 53.20% | LR: 0.000010
INFO:__main__:Epoch 100/100 | Train Loss: 1.0427 | Val Loss: 0.9357 | Train Acc: 47.31% | Val Acc: 53.00% | LR: 0.000010
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 25.42 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 51.31%
INFO:__main__:Final Val Accuracy: 53.00%
INFO:__main__:Validation F1-Macro: 0.5083
INFO:__main__:Best Val Accuracy: 53.80%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.62      0.82      0.70       666
      neutral       0.47      0.51      0.49       666
contradiction       0.44      0.27      0.33       666

     accuracy                           0.53      1998
    macro avg       0.51      0.53      0.51      1998
 weighted avg       0.51      0.53      0.51      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3268 | Val Loss: 1.1336 | Train Acc: 33.72% | Val Acc: 38.14% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.2729 | Val Loss: 1.0839 | Train Acc: 36.62% | Val Acc: 44.14% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.2132 | Val Loss: 1.0394 | Train Acc: 38.96% | Val Acc: 47.70% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.1686 | Val Loss: 1.0175 | Train Acc: 41.43% | Val Acc: 48.60% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.1381 | Val Loss: 1.0021 | Train Acc: 43.24% | Val Acc: 51.00% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.1199 | Val Loss: 0.9871 | Train Acc: 44.26% | Val Acc: 51.45% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.0983 | Val Loss: 0.9760 | Train Acc: 45.13% | Val Acc: 51.50% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 1.0822 | Val Loss: 0.9678 | Train Acc: 46.68% | Val Acc: 51.60% | LR: 0.000010
INFO:__main__:Epoch  80/100 | Train Loss: 1.0573 | Val Loss: 0.9627 | Train Acc: 48.07% | Val Acc: 51.85% | LR: 0.000010
INFO:__main__:Epoch  90/100 | Train Loss: 1.0544 | Val Loss: 0.9576 | Train Acc: 46.81% | Val Acc: 51.40% | LR: 0.000010
INFO:__main__:Epoch 100/100 | Train Loss: 1.0416 | Val Loss: 0.9557 | Train Acc: 48.72% | Val Acc: 52.15% | LR: 0.000010
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 25.44 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 52.04%
INFO:__main__:Final Val Accuracy: 52.15%
INFO:__main__:Validation F1-Macro: 0.4980
INFO:__main__:Best Val Accuracy: 52.15%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.57      0.85      0.68       666
      neutral       0.48      0.40      0.44       666
contradiction       0.47      0.31      0.38       666

     accuracy                           0.52      1998
    macro avg       0.51      0.52      0.50      1998
 weighted avg       0.51      0.52      0.50      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3538 | Val Loss: 1.0993 | Train Acc: 34.10% | Val Acc: 38.39% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.2508 | Val Loss: 1.0417 | Train Acc: 38.46% | Val Acc: 45.60% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.1991 | Val Loss: 1.0105 | Train Acc: 40.85% | Val Acc: 48.75% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.1543 | Val Loss: 0.9951 | Train Acc: 43.73% | Val Acc: 49.70% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.1247 | Val Loss: 0.9813 | Train Acc: 44.93% | Val Acc: 51.05% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.0995 | Val Loss: 0.9690 | Train Acc: 46.96% | Val Acc: 51.00% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.0699 | Val Loss: 0.9643 | Train Acc: 47.13% | Val Acc: 51.50% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 1.0587 | Val Loss: 0.9587 | Train Acc: 47.20% | Val Acc: 51.55% | LR: 0.000010
INFO:__main__:Epoch  80/100 | Train Loss: 1.0433 | Val Loss: 0.9515 | Train Acc: 47.70% | Val Acc: 51.70% | LR: 0.000010
INFO:__main__:Epoch  90/100 | Train Loss: 1.0425 | Val Loss: 0.9517 | Train Acc: 49.26% | Val Acc: 51.50% | LR: 0.000005
INFO:__main__:Epoch 100/100 | Train Loss: 1.0319 | Val Loss: 0.9488 | Train Acc: 48.32% | Val Acc: 51.70% | LR: 0.000005
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 25.39 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 52.13%
INFO:__main__:Final Val Accuracy: 51.70%
INFO:__main__:Validation F1-Macro: 0.4912
INFO:__main__:Best Val Accuracy: 52.15%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.80      0.69       666
      neutral       0.47      0.52      0.49       666
contradiction       0.41      0.23      0.29       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.49      1998
 weighted avg       0.49      0.52      0.49      1998

INFO:__main__:Results: Accuracy = 51.75% ± 0.89%
INFO:__main__:         F1-Macro = 0.4868 ± 0.0166
INFO:__main__:         Score = 50.86
INFO:__main__:         Time = 127.0s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 17/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.005, 'batch_size': 32, 'dropout_rate': 0.1, 'weight_decay': 0.0001}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9641 | Val Loss: 0.9231 | Train Acc: 50.36% | Val Acc: 51.95% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9227 | Val Loss: 0.9235 | Train Acc: 52.08% | Val Acc: 51.85% | LR: 0.002500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9258 | Val Loss: 0.9271 | Train Acc: 51.68% | Val Acc: 51.70% | LR: 0.002500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9209 | Val Loss: 0.9220 | Train Acc: 52.59% | Val Acc: 51.55% | LR: 0.000625
INFO:__main__:Early stopping triggered at epoch 33
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 28.22 seconds
INFO:__main__:Epochs Trained: 33
INFO:__main__:Final Train Accuracy: 52.98%
INFO:__main__:Final Val Accuracy: 51.90%
INFO:__main__:Validation F1-Macro: 0.4853
INFO:__main__:Best Val Accuracy: 52.55%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.81      0.69       666
      neutral       0.46      0.56      0.51       666
contradiction       0.42      0.19      0.26       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.49      1998
 weighted avg       0.49      0.52      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9606 | Val Loss: 0.9248 | Train Acc: 50.30% | Val Acc: 49.85% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9305 | Val Loss: 0.9208 | Train Acc: 50.86% | Val Acc: 51.75% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9276 | Val Loss: 0.9199 | Train Acc: 51.28% | Val Acc: 52.05% | LR: 0.001250
INFO:__main__:Epoch  30/100 | Train Loss: 0.9256 | Val Loss: 0.9180 | Train Acc: 51.70% | Val Acc: 51.65% | LR: 0.000625
INFO:__main__:Early stopping triggered at epoch 39
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 33.44 seconds
INFO:__main__:Epochs Trained: 39
INFO:__main__:Final Train Accuracy: 52.46%
INFO:__main__:Final Val Accuracy: 52.15%
INFO:__main__:Validation F1-Macro: 0.4791
INFO:__main__:Best Val Accuracy: 52.45%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.80      0.69       666
      neutral       0.48      0.62      0.54       666
contradiction       0.38      0.14      0.21       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.48      1998
 weighted avg       0.49      0.52      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9732 | Val Loss: 0.9026 | Train Acc: 50.14% | Val Acc: 52.55% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9327 | Val Loss: 0.9054 | Train Acc: 51.25% | Val Acc: 52.45% | LR: 0.002500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9270 | Val Loss: 0.9008 | Train Acc: 51.59% | Val Acc: 52.50% | LR: 0.001250
INFO:__main__:Epoch  30/100 | Train Loss: 0.9276 | Val Loss: 0.9004 | Train Acc: 52.00% | Val Acc: 53.05% | LR: 0.000313
INFO:__main__:Early stopping triggered at epoch 33
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 28.53 seconds
INFO:__main__:Epochs Trained: 33
INFO:__main__:Final Train Accuracy: 52.87%
INFO:__main__:Final Val Accuracy: 53.00%
INFO:__main__:Validation F1-Macro: 0.4902
INFO:__main__:Best Val Accuracy: 53.85%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.61      0.83      0.71       666
      neutral       0.48      0.59      0.53       666
contradiction       0.40      0.16      0.23       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.49      1998
 weighted avg       0.50      0.53      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9588 | Val Loss: 0.9377 | Train Acc: 50.41% | Val Acc: 50.75% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9275 | Val Loss: 0.9306 | Train Acc: 51.35% | Val Acc: 50.00% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9222 | Val Loss: 0.9288 | Train Acc: 51.89% | Val Acc: 51.20% | LR: 0.002500
INFO:__main__:Early stopping triggered at epoch 28
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 24.34 seconds
INFO:__main__:Epochs Trained: 28
INFO:__main__:Final Train Accuracy: 52.25%
INFO:__main__:Final Val Accuracy: 51.20%
INFO:__main__:Validation F1-Macro: 0.4934
INFO:__main__:Best Val Accuracy: 51.50%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.82      0.68       666
      neutral       0.49      0.35      0.40       666
contradiction       0.42      0.37      0.39       666

     accuracy                           0.51      1998
    macro avg       0.50      0.51      0.49      1998
 weighted avg       0.50      0.51      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9602 | Val Loss: 0.9293 | Train Acc: 50.10% | Val Acc: 52.25% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9301 | Val Loss: 0.9194 | Train Acc: 50.63% | Val Acc: 52.40% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9283 | Val Loss: 0.9316 | Train Acc: 51.71% | Val Acc: 49.70% | LR: 0.002500
INFO:__main__:Early stopping triggered at epoch 29
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 25.06 seconds
INFO:__main__:Epochs Trained: 29
INFO:__main__:Final Train Accuracy: 52.46%
INFO:__main__:Final Val Accuracy: 52.35%
INFO:__main__:Validation F1-Macro: 0.5079
INFO:__main__:Best Val Accuracy: 52.90%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.80      0.69       666
      neutral       0.51      0.44      0.47       666
contradiction       0.40      0.33      0.36       666

     accuracy                           0.52      1998
    macro avg       0.51      0.52      0.51      1998
 weighted avg       0.51      0.52      0.51      1998

INFO:__main__:NEW BEST RESULT!
INFO:__main__:Results: Accuracy = 52.12% ± 0.59%
INFO:__main__:         F1-Macro = 0.4912 ± 0.0097
INFO:__main__:         Score = 51.53
INFO:__main__:         Time = 139.6s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 18/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.0005, 'batch_size': 64, 'dropout_rate': 0.5, 'weight_decay': 0.0001}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3193 | Val Loss: 1.0430 | Train Acc: 36.09% | Val Acc: 42.74% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9615 | Val Loss: 0.9289 | Train Acc: 50.71% | Val Acc: 52.65% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9473 | Val Loss: 0.9228 | Train Acc: 50.96% | Val Acc: 52.00% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9449 | Val Loss: 0.9226 | Train Acc: 51.65% | Val Acc: 52.10% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 37
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 16.98 seconds
INFO:__main__:Epochs Trained: 37
INFO:__main__:Final Train Accuracy: 52.21%
INFO:__main__:Final Val Accuracy: 52.55%
INFO:__main__:Validation F1-Macro: 0.4663
INFO:__main__:Best Val Accuracy: 53.20%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.83      0.69       666
      neutral       0.49      0.65      0.56       666
contradiction       0.40      0.10      0.16       666

     accuracy                           0.53      1998
    macro avg       0.49      0.53      0.47      1998
 weighted avg       0.49      0.53      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2276 | Val Loss: 1.0008 | Train Acc: 38.96% | Val Acc: 47.50% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9672 | Val Loss: 0.9298 | Train Acc: 50.01% | Val Acc: 52.20% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9474 | Val Loss: 0.9237 | Train Acc: 50.69% | Val Acc: 51.80% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9423 | Val Loss: 0.9236 | Train Acc: 51.35% | Val Acc: 51.45% | LR: 0.000500
INFO:__main__:Epoch  40/100 | Train Loss: 0.9387 | Val Loss: 0.9212 | Train Acc: 51.38% | Val Acc: 51.60% | LR: 0.000250
INFO:__main__:Epoch  50/100 | Train Loss: 0.9398 | Val Loss: 0.9211 | Train Acc: 51.36% | Val Acc: 51.75% | LR: 0.000125
INFO:__main__:Epoch  60/100 | Train Loss: 0.9405 | Val Loss: 0.9218 | Train Acc: 51.75% | Val Acc: 51.65% | LR: 0.000063
INFO:__main__:Early stopping triggered at epoch 66
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 30.33 seconds
INFO:__main__:Epochs Trained: 66
INFO:__main__:Final Train Accuracy: 52.36%
INFO:__main__:Final Val Accuracy: 52.00%
INFO:__main__:Validation F1-Macro: 0.4662
INFO:__main__:Best Val Accuracy: 52.45%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.80      0.68       666
      neutral       0.47      0.66      0.55       666
contradiction       0.38      0.11      0.16       666

     accuracy                           0.52      1998
    macro avg       0.48      0.52      0.47      1998
 weighted avg       0.48      0.52      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2679 | Val Loss: 0.9703 | Train Acc: 38.48% | Val Acc: 52.30% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9741 | Val Loss: 0.9094 | Train Acc: 50.18% | Val Acc: 54.00% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9579 | Val Loss: 0.9074 | Train Acc: 50.83% | Val Acc: 52.90% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9482 | Val Loss: 0.9019 | Train Acc: 50.65% | Val Acc: 52.80% | LR: 0.000500
INFO:__main__:Epoch  40/100 | Train Loss: 0.9452 | Val Loss: 0.9013 | Train Acc: 50.74% | Val Acc: 52.80% | LR: 0.000250
INFO:__main__:Epoch  50/100 | Train Loss: 0.9447 | Val Loss: 0.9041 | Train Acc: 51.10% | Val Acc: 52.85% | LR: 0.000125
INFO:__main__:Epoch  60/100 | Train Loss: 0.9429 | Val Loss: 0.9022 | Train Acc: 51.50% | Val Acc: 52.70% | LR: 0.000063
INFO:__main__:Early stopping triggered at epoch 67
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 30.91 seconds
INFO:__main__:Epochs Trained: 67
INFO:__main__:Final Train Accuracy: 51.89%
INFO:__main__:Final Val Accuracy: 52.70%
INFO:__main__:Validation F1-Macro: 0.4577
INFO:__main__:Best Val Accuracy: 54.00%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.85      0.69       666
      neutral       0.48      0.66      0.56       666
contradiction       0.38      0.07      0.12       666

     accuracy                           0.53      1998
    macro avg       0.48      0.53      0.46      1998
 weighted avg       0.48      0.53      0.46      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3294 | Val Loss: 1.0016 | Train Acc: 37.54% | Val Acc: 49.00% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9684 | Val Loss: 0.9395 | Train Acc: 50.43% | Val Acc: 51.40% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9442 | Val Loss: 0.9340 | Train Acc: 51.31% | Val Acc: 51.05% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9361 | Val Loss: 0.9314 | Train Acc: 51.36% | Val Acc: 50.25% | LR: 0.000500
INFO:__main__:Epoch  40/100 | Train Loss: 0.9377 | Val Loss: 0.9303 | Train Acc: 51.90% | Val Acc: 50.20% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 49
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 22.62 seconds
INFO:__main__:Epochs Trained: 49
INFO:__main__:Final Train Accuracy: 52.53%
INFO:__main__:Final Val Accuracy: 50.15%
INFO:__main__:Validation F1-Macro: 0.4666
INFO:__main__:Best Val Accuracy: 51.55%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.57      0.83      0.68       666
      neutral       0.47      0.49      0.48       666
contradiction       0.37      0.18      0.25       666

     accuracy                           0.50      1998
    macro avg       0.47      0.50      0.47      1998
 weighted avg       0.47      0.50      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2797 | Val Loss: 1.0122 | Train Acc: 37.61% | Val Acc: 48.85% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9676 | Val Loss: 0.9304 | Train Acc: 50.36% | Val Acc: 51.25% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9474 | Val Loss: 0.9250 | Train Acc: 51.01% | Val Acc: 52.20% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9469 | Val Loss: 0.9247 | Train Acc: 50.86% | Val Acc: 52.50% | LR: 0.000250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9390 | Val Loss: 0.9234 | Train Acc: 51.98% | Val Acc: 52.45% | LR: 0.000125
INFO:__main__:Epoch  50/100 | Train Loss: 0.9383 | Val Loss: 0.9239 | Train Acc: 51.10% | Val Acc: 52.60% | LR: 0.000031
INFO:__main__:Early stopping triggered at epoch 51
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 23.41 seconds
INFO:__main__:Epochs Trained: 51
INFO:__main__:Final Train Accuracy: 52.20%
INFO:__main__:Final Val Accuracy: 52.60%
INFO:__main__:Validation F1-Macro: 0.4767
INFO:__main__:Best Val Accuracy: 52.90%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.82      0.69       666
      neutral       0.49      0.63      0.55       666
contradiction       0.40      0.13      0.19       666

     accuracy                           0.53      1998
    macro avg       0.49      0.53      0.48      1998
 weighted avg       0.49      0.53      0.48      1998

INFO:__main__:Results: Accuracy = 52.00% ± 0.96%
INFO:__main__:         F1-Macro = 0.4667 ± 0.0060
INFO:__main__:         Score = 51.04
INFO:__main__:         Time = 124.3s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 19/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.001, 'batch_size': 64, 'dropout_rate': 0.1, 'weight_decay': 0.005}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0295 | Val Loss: 0.9348 | Train Acc: 47.50% | Val Acc: 51.10% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9275 | Val Loss: 0.9262 | Train Acc: 52.01% | Val Acc: 51.00% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9245 | Val Loss: 0.9264 | Train Acc: 52.52% | Val Acc: 50.20% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9211 | Val Loss: 0.9231 | Train Acc: 52.52% | Val Acc: 51.15% | LR: 0.000500
INFO:__main__:Epoch  40/100 | Train Loss: 0.9205 | Val Loss: 0.9224 | Train Acc: 52.13% | Val Acc: 51.20% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 43
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 19.71 seconds
INFO:__main__:Epochs Trained: 43
INFO:__main__:Final Train Accuracy: 52.84%
INFO:__main__:Final Val Accuracy: 51.05%
INFO:__main__:Validation F1-Macro: 0.4829
INFO:__main__:Best Val Accuracy: 52.05%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.82      0.68       666
      neutral       0.46      0.48      0.47       666
contradiction       0.42      0.23      0.29       666

     accuracy                           0.51      1998
    macro avg       0.49      0.51      0.48      1998
 weighted avg       0.49      0.51      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0016 | Val Loss: 0.9324 | Train Acc: 48.52% | Val Acc: 50.60% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9304 | Val Loss: 0.9213 | Train Acc: 51.06% | Val Acc: 51.90% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9228 | Val Loss: 0.9207 | Train Acc: 52.11% | Val Acc: 52.60% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9247 | Val Loss: 0.9210 | Train Acc: 51.74% | Val Acc: 52.65% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 36
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 16.75 seconds
INFO:__main__:Epochs Trained: 36
INFO:__main__:Final Train Accuracy: 52.23%
INFO:__main__:Final Val Accuracy: 52.35%
INFO:__main__:Validation F1-Macro: 0.4899
INFO:__main__:Best Val Accuracy: 53.20%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.84      0.68       666
      neutral       0.49      0.52      0.51       666
contradiction       0.43      0.21      0.28       666

     accuracy                           0.52      1998
    macro avg       0.50      0.52      0.49      1998
 weighted avg       0.50      0.52      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9910 | Val Loss: 0.9034 | Train Acc: 49.30% | Val Acc: 52.05% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9293 | Val Loss: 0.9014 | Train Acc: 51.65% | Val Acc: 53.30% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9271 | Val Loss: 0.8998 | Train Acc: 51.91% | Val Acc: 52.70% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9272 | Val Loss: 0.9013 | Train Acc: 51.54% | Val Acc: 52.70% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 30
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 13.79 seconds
INFO:__main__:Epochs Trained: 30
INFO:__main__:Final Train Accuracy: 52.30%
INFO:__main__:Final Val Accuracy: 52.70%
INFO:__main__:Validation F1-Macro: 0.5007
INFO:__main__:Best Val Accuracy: 54.10%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.85      0.70       666
      neutral       0.49      0.48      0.48       666
contradiction       0.43      0.26      0.32       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.50      1998
 weighted avg       0.50      0.53      0.50      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0472 | Val Loss: 0.9457 | Train Acc: 48.22% | Val Acc: 52.50% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9238 | Val Loss: 0.9347 | Train Acc: 52.62% | Val Acc: 51.10% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9226 | Val Loss: 0.9294 | Train Acc: 51.99% | Val Acc: 51.20% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9193 | Val Loss: 0.9285 | Train Acc: 52.00% | Val Acc: 50.40% | LR: 0.000250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9182 | Val Loss: 0.9278 | Train Acc: 52.39% | Val Acc: 50.65% | LR: 0.000125
INFO:__main__:Epoch  50/100 | Train Loss: 0.9176 | Val Loss: 0.9280 | Train Acc: 52.39% | Val Acc: 50.80% | LR: 0.000063
INFO:__main__:Epoch  60/100 | Train Loss: 0.9179 | Val Loss: 0.9272 | Train Acc: 52.85% | Val Acc: 50.90% | LR: 0.000016
INFO:__main__:Early stopping triggered at epoch 62
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 28.04 seconds
INFO:__main__:Epochs Trained: 62
INFO:__main__:Final Train Accuracy: 52.84%
INFO:__main__:Final Val Accuracy: 51.05%
INFO:__main__:Validation F1-Macro: 0.4823
INFO:__main__:Best Val Accuracy: 52.50%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.57      0.84      0.68       666
      neutral       0.47      0.46      0.46       666
contradiction       0.42      0.24      0.30       666

     accuracy                           0.51      1998
    macro avg       0.49      0.51      0.48      1998
 weighted avg       0.49      0.51      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0039 | Val Loss: 0.9247 | Train Acc: 48.54% | Val Acc: 53.50% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9262 | Val Loss: 0.9217 | Train Acc: 51.88% | Val Acc: 52.00% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9228 | Val Loss: 0.9198 | Train Acc: 51.70% | Val Acc: 54.30% | LR: 0.000250
INFO:__main__:Epoch  30/100 | Train Loss: 0.9246 | Val Loss: 0.9180 | Train Acc: 52.06% | Val Acc: 53.65% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 38
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 17.51 seconds
INFO:__main__:Epochs Trained: 38
INFO:__main__:Final Train Accuracy: 52.28%
INFO:__main__:Final Val Accuracy: 53.60%
INFO:__main__:Validation F1-Macro: 0.5053
INFO:__main__:Best Val Accuracy: 54.30%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.82      0.69       666
      neutral       0.49      0.57      0.53       666
contradiction       0.46      0.22      0.30       666

     accuracy                           0.54      1998
    macro avg       0.52      0.54      0.51      1998
 weighted avg       0.52      0.54      0.51      1998

INFO:__main__:Results: Accuracy = 52.15% ± 0.99%
INFO:__main__:         F1-Macro = 0.4922 ± 0.0093
INFO:__main__:         Score = 51.16
INFO:__main__:         Time = 95.8s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 20/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.0005, 'batch_size': 64, 'dropout_rate': 0.5, 'weight_decay': 1e-05}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3193 | Val Loss: 1.0429 | Train Acc: 36.11% | Val Acc: 42.74% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9616 | Val Loss: 0.9288 | Train Acc: 50.78% | Val Acc: 52.80% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9475 | Val Loss: 0.9227 | Train Acc: 51.00% | Val Acc: 52.00% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9452 | Val Loss: 0.9225 | Train Acc: 51.78% | Val Acc: 52.10% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 37
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 16.88 seconds
INFO:__main__:Epochs Trained: 37
INFO:__main__:Final Train Accuracy: 52.28%
INFO:__main__:Final Val Accuracy: 52.55%
INFO:__main__:Validation F1-Macro: 0.4678
INFO:__main__:Best Val Accuracy: 53.20%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.83      0.68       666
      neutral       0.49      0.65      0.56       666
contradiction       0.40      0.10      0.16       666

     accuracy                           0.53      1998
    macro avg       0.49      0.53      0.47      1998
 weighted avg       0.49      0.53      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2277 | Val Loss: 1.0007 | Train Acc: 38.96% | Val Acc: 47.50% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9673 | Val Loss: 0.9297 | Train Acc: 50.00% | Val Acc: 52.20% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9476 | Val Loss: 0.9238 | Train Acc: 50.75% | Val Acc: 51.90% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9424 | Val Loss: 0.9236 | Train Acc: 51.46% | Val Acc: 51.45% | LR: 0.000500
INFO:__main__:Epoch  40/100 | Train Loss: 0.9389 | Val Loss: 0.9213 | Train Acc: 51.29% | Val Acc: 51.65% | LR: 0.000250
INFO:__main__:Epoch  50/100 | Train Loss: 0.9399 | Val Loss: 0.9212 | Train Acc: 51.34% | Val Acc: 51.70% | LR: 0.000125
INFO:__main__:Epoch  60/100 | Train Loss: 0.9408 | Val Loss: 0.9217 | Train Acc: 51.71% | Val Acc: 51.70% | LR: 0.000063
INFO:__main__:Epoch  70/100 | Train Loss: 0.9400 | Val Loss: 0.9215 | Train Acc: 51.80% | Val Acc: 51.80% | LR: 0.000063
INFO:__main__:Epoch  80/100 | Train Loss: 0.9427 | Val Loss: 0.9223 | Train Acc: 51.69% | Val Acc: 51.95% | LR: 0.000016
INFO:__main__:Early stopping triggered at epoch 82
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 37.43 seconds
INFO:__main__:Epochs Trained: 82
INFO:__main__:Final Train Accuracy: 52.29%
INFO:__main__:Final Val Accuracy: 51.65%
INFO:__main__:Validation F1-Macro: 0.4606
INFO:__main__:Best Val Accuracy: 52.40%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.83      0.69       666
      neutral       0.48      0.62      0.54       666
contradiction       0.35      0.10      0.15       666

     accuracy                           0.52      1998
    macro avg       0.47      0.52      0.46      1998
 weighted avg       0.47      0.52      0.46      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2311 | Val Loss: 0.9979 | Train Acc: 36.54% | Val Acc: 50.55% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9780 | Val Loss: 0.9099 | Train Acc: 49.69% | Val Acc: 51.65% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9529 | Val Loss: 0.9036 | Train Acc: 50.85% | Val Acc: 52.95% | LR: 0.000250
INFO:__main__:Epoch  30/100 | Train Loss: 0.9518 | Val Loss: 0.9026 | Train Acc: 50.95% | Val Acc: 52.70% | LR: 0.000125
INFO:__main__:Epoch  40/100 | Train Loss: 0.9538 | Val Loss: 0.9043 | Train Acc: 51.31% | Val Acc: 52.90% | LR: 0.000063
INFO:__main__:Epoch  50/100 | Train Loss: 0.9471 | Val Loss: 0.9025 | Train Acc: 50.66% | Val Acc: 52.75% | LR: 0.000016
INFO:__main__:Early stopping triggered at epoch 51
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 23.55 seconds
INFO:__main__:Epochs Trained: 51
INFO:__main__:Final Train Accuracy: 51.90%
INFO:__main__:Final Val Accuracy: 52.85%
INFO:__main__:Validation F1-Macro: 0.4674
INFO:__main__:Best Val Accuracy: 53.35%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.86      0.70       666
      neutral       0.49      0.63      0.55       666
contradiction       0.40      0.10      0.15       666

     accuracy                           0.53      1998
    macro avg       0.49      0.53      0.47      1998
 weighted avg       0.49      0.53      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3295 | Val Loss: 1.0016 | Train Acc: 37.51% | Val Acc: 49.00% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9686 | Val Loss: 0.9394 | Train Acc: 50.38% | Val Acc: 51.35% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9443 | Val Loss: 0.9341 | Train Acc: 51.35% | Val Acc: 51.05% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9363 | Val Loss: 0.9314 | Train Acc: 51.26% | Val Acc: 50.30% | LR: 0.000500
INFO:__main__:Epoch  40/100 | Train Loss: 0.9379 | Val Loss: 0.9303 | Train Acc: 51.81% | Val Acc: 50.30% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 49
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 22.44 seconds
INFO:__main__:Epochs Trained: 49
INFO:__main__:Final Train Accuracy: 52.44%
INFO:__main__:Final Val Accuracy: 50.15%
INFO:__main__:Validation F1-Macro: 0.4662
INFO:__main__:Best Val Accuracy: 51.60%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.57      0.83      0.68       666
      neutral       0.47      0.49      0.48       666
contradiction       0.37      0.18      0.24       666

     accuracy                           0.50      1998
    macro avg       0.47      0.50      0.47      1998
 weighted avg       0.47      0.50      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2798 | Val Loss: 1.0122 | Train Acc: 37.60% | Val Acc: 48.85% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9677 | Val Loss: 0.9304 | Train Acc: 50.26% | Val Acc: 51.20% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9476 | Val Loss: 0.9250 | Train Acc: 51.01% | Val Acc: 52.25% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9471 | Val Loss: 0.9247 | Train Acc: 50.85% | Val Acc: 52.45% | LR: 0.000250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9392 | Val Loss: 0.9235 | Train Acc: 51.81% | Val Acc: 52.40% | LR: 0.000125
INFO:__main__:Epoch  50/100 | Train Loss: 0.9385 | Val Loss: 0.9240 | Train Acc: 51.09% | Val Acc: 52.70% | LR: 0.000031
INFO:__main__:Early stopping triggered at epoch 51
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 23.30 seconds
INFO:__main__:Epochs Trained: 51
INFO:__main__:Final Train Accuracy: 52.29%
INFO:__main__:Final Val Accuracy: 52.75%
INFO:__main__:Validation F1-Macro: 0.4765
INFO:__main__:Best Val Accuracy: 52.95%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.82      0.69       666
      neutral       0.49      0.64      0.55       666
contradiction       0.40      0.12      0.19       666

     accuracy                           0.53      1998
    macro avg       0.49      0.53      0.48      1998
 weighted avg       0.49      0.53      0.48      1998

INFO:__main__:Results: Accuracy = 51.99% ± 1.01%
INFO:__main__:         F1-Macro = 0.4677 ± 0.0051
INFO:__main__:         Score = 50.98
INFO:__main__:         Time = 123.6s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 21/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.005, 'batch_size': 128, 'dropout_rate': 0.1, 'weight_decay': 0.005}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9738 | Val Loss: 0.9334 | Train Acc: 50.25% | Val Acc: 52.35% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9277 | Val Loss: 0.9405 | Train Acc: 51.53% | Val Acc: 49.80% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9286 | Val Loss: 0.9260 | Train Acc: 51.29% | Val Acc: 52.20% | LR: 0.005000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9269 | Val Loss: 0.9285 | Train Acc: 51.24% | Val Acc: 52.10% | LR: 0.005000
INFO:__main__:Epoch  40/100 | Train Loss: 0.9251 | Val Loss: 0.9260 | Train Acc: 50.98% | Val Acc: 52.35% | LR: 0.002500
INFO:__main__:Epoch  50/100 | Train Loss: 0.9259 | Val Loss: 0.9255 | Train Acc: 51.78% | Val Acc: 52.25% | LR: 0.000625
INFO:__main__:Early stopping triggered at epoch 59
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 15.06 seconds
INFO:__main__:Epochs Trained: 59
INFO:__main__:Final Train Accuracy: 52.10%
INFO:__main__:Final Val Accuracy: 52.30%
INFO:__main__:Validation F1-Macro: 0.4922
INFO:__main__:Best Val Accuracy: 52.85%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.80      0.68       666
      neutral       0.49      0.58      0.53       666
contradiction       0.39      0.20      0.26       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.49      1998
 weighted avg       0.49      0.52      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9679 | Val Loss: 0.9442 | Train Acc: 50.26% | Val Acc: 50.40% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9274 | Val Loss: 0.9455 | Train Acc: 52.11% | Val Acc: 51.75% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9232 | Val Loss: 0.9275 | Train Acc: 52.31% | Val Acc: 51.65% | LR: 0.002500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9259 | Val Loss: 0.9257 | Train Acc: 52.14% | Val Acc: 52.25% | LR: 0.001250
INFO:__main__:Early stopping triggered at epoch 36
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 9.23 seconds
INFO:__main__:Epochs Trained: 36
INFO:__main__:Final Train Accuracy: 52.36%
INFO:__main__:Final Val Accuracy: 52.00%
INFO:__main__:Validation F1-Macro: 0.4966
INFO:__main__:Best Val Accuracy: 52.35%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.80      0.68       666
      neutral       0.50      0.53      0.51       666
contradiction       0.39      0.24      0.29       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.50      1998
 weighted avg       0.49      0.52      0.50      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9693 | Val Loss: 0.9204 | Train Acc: 49.67% | Val Acc: 53.80% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9308 | Val Loss: 0.9228 | Train Acc: 51.14% | Val Acc: 51.85% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9284 | Val Loss: 0.9090 | Train Acc: 51.85% | Val Acc: 53.00% | LR: 0.001250
INFO:__main__:Early stopping triggered at epoch 20
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 5.20 seconds
INFO:__main__:Epochs Trained: 20
INFO:__main__:Final Train Accuracy: 51.89%
INFO:__main__:Final Val Accuracy: 53.00%
INFO:__main__:Validation F1-Macro: 0.4876
INFO:__main__:Best Val Accuracy: 53.80%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.84      0.70       666
      neutral       0.50      0.59      0.54       666
contradiction       0.40      0.16      0.23       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.49      1998
 weighted avg       0.50      0.53      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9737 | Val Loss: 0.9406 | Train Acc: 50.60% | Val Acc: 51.30% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9218 | Val Loss: 0.9313 | Train Acc: 51.60% | Val Acc: 50.40% | LR: 0.002500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9216 | Val Loss: 0.9292 | Train Acc: 52.08% | Val Acc: 50.35% | LR: 0.001250
INFO:__main__:Epoch  30/100 | Train Loss: 0.9199 | Val Loss: 0.9286 | Train Acc: 52.06% | Val Acc: 51.10% | LR: 0.000625
INFO:__main__:Early stopping triggered at epoch 38
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 9.70 seconds
INFO:__main__:Epochs Trained: 38
INFO:__main__:Final Train Accuracy: 52.68%
INFO:__main__:Final Val Accuracy: 51.00%
INFO:__main__:Validation F1-Macro: 0.4745
INFO:__main__:Best Val Accuracy: 51.85%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.84      0.68       666
      neutral       0.47      0.51      0.49       666
contradiction       0.39      0.18      0.25       666

     accuracy                           0.51      1998
    macro avg       0.48      0.51      0.47      1998
 weighted avg       0.48      0.51      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9861 | Val Loss: 0.9258 | Train Acc: 49.87% | Val Acc: 51.50% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9298 | Val Loss: 0.9183 | Train Acc: 51.13% | Val Acc: 52.55% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9274 | Val Loss: 0.9202 | Train Acc: 51.29% | Val Acc: 51.75% | LR: 0.002500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9266 | Val Loss: 0.9183 | Train Acc: 51.44% | Val Acc: 52.60% | LR: 0.001250
INFO:__main__:Early stopping triggered at epoch 39
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 9.98 seconds
INFO:__main__:Epochs Trained: 39
INFO:__main__:Final Train Accuracy: 52.25%
INFO:__main__:Final Val Accuracy: 52.55%
INFO:__main__:Validation F1-Macro: 0.4988
INFO:__main__:Best Val Accuracy: 53.00%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.81      0.69       666
      neutral       0.50      0.54      0.52       666
contradiction       0.39      0.22      0.29       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.50      1998
 weighted avg       0.50      0.53      0.50      1998

INFO:__main__:Results: Accuracy = 52.17% ± 0.67%
INFO:__main__:         F1-Macro = 0.4899 ± 0.0086
INFO:__main__:         Score = 51.50
INFO:__main__:         Time = 49.2s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 22/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.005, 'batch_size': 32, 'dropout_rate': 0.5, 'weight_decay': 0.001}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0235 | Val Loss: 0.9412 | Train Acc: 48.10% | Val Acc: 52.15% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9504 | Val Loss: 0.9292 | Train Acc: 50.43% | Val Acc: 50.75% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9482 | Val Loss: 0.9302 | Train Acc: 50.68% | Val Acc: 52.20% | LR: 0.002500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9437 | Val Loss: 0.9271 | Train Acc: 50.44% | Val Acc: 51.90% | LR: 0.002500
INFO:__main__:Epoch  40/100 | Train Loss: 0.9395 | Val Loss: 0.9248 | Train Acc: 51.34% | Val Acc: 52.45% | LR: 0.000625
INFO:__main__:Early stopping triggered at epoch 48
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 41.43 seconds
INFO:__main__:Epochs Trained: 48
INFO:__main__:Final Train Accuracy: 52.19%
INFO:__main__:Final Val Accuracy: 52.45%
INFO:__main__:Validation F1-Macro: 0.4931
INFO:__main__:Best Val Accuracy: 53.25%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.84      0.69       666
      neutral       0.50      0.52      0.51       666
contradiction       0.40      0.21      0.28       666

     accuracy                           0.52      1998
    macro avg       0.50      0.52      0.49      1998
 weighted avg       0.50      0.52      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0308 | Val Loss: 0.9404 | Train Acc: 47.12% | Val Acc: 50.10% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9522 | Val Loss: 0.9282 | Train Acc: 50.24% | Val Acc: 50.95% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9433 | Val Loss: 0.9263 | Train Acc: 50.76% | Val Acc: 52.05% | LR: 0.002500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9425 | Val Loss: 0.9244 | Train Acc: 50.98% | Val Acc: 52.15% | LR: 0.001250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9414 | Val Loss: 0.9214 | Train Acc: 51.40% | Val Acc: 51.75% | LR: 0.000313
INFO:__main__:Epoch  50/100 | Train Loss: 0.9390 | Val Loss: 0.9217 | Train Acc: 51.99% | Val Acc: 52.05% | LR: 0.000156
INFO:__main__:Early stopping triggered at epoch 55
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 46.93 seconds
INFO:__main__:Epochs Trained: 55
INFO:__main__:Final Train Accuracy: 52.19%
INFO:__main__:Final Val Accuracy: 51.80%
INFO:__main__:Validation F1-Macro: 0.4869
INFO:__main__:Best Val Accuracy: 52.60%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.61      0.78      0.68       666
      neutral       0.49      0.59      0.54       666
contradiction       0.36      0.18      0.24       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.49      1998
 weighted avg       0.49      0.52      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0256 | Val Loss: 0.9142 | Train Acc: 46.60% | Val Acc: 50.90% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9570 | Val Loss: 0.9027 | Train Acc: 50.21% | Val Acc: 52.80% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9518 | Val Loss: 0.9113 | Train Acc: 51.03% | Val Acc: 52.55% | LR: 0.002500
INFO:__main__:Early stopping triggered at epoch 25
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 21.78 seconds
INFO:__main__:Epochs Trained: 25
INFO:__main__:Final Train Accuracy: 51.69%
INFO:__main__:Final Val Accuracy: 52.90%
INFO:__main__:Validation F1-Macro: 0.4619
INFO:__main__:Best Val Accuracy: 53.70%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.62      0.81      0.70       666
      neutral       0.48      0.70      0.57       666
contradiction       0.36      0.07      0.12       666

     accuracy                           0.53      1998
    macro avg       0.48      0.53      0.46      1998
 weighted avg       0.48      0.53      0.46      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0295 | Val Loss: 0.9422 | Train Acc: 47.95% | Val Acc: 50.35% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9428 | Val Loss: 0.9404 | Train Acc: 50.49% | Val Acc: 51.60% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9409 | Val Loss: 0.9307 | Train Acc: 51.75% | Val Acc: 50.65% | LR: 0.002500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9417 | Val Loss: 0.9389 | Train Acc: 51.21% | Val Acc: 50.95% | LR: 0.001250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9418 | Val Loss: 0.9324 | Train Acc: 52.25% | Val Acc: 50.90% | LR: 0.000625
INFO:__main__:Epoch  50/100 | Train Loss: 0.9345 | Val Loss: 0.9290 | Train Acc: 51.99% | Val Acc: 51.65% | LR: 0.000313
INFO:__main__:Epoch  60/100 | Train Loss: 0.9366 | Val Loss: 0.9303 | Train Acc: 51.84% | Val Acc: 50.80% | LR: 0.000156
INFO:__main__:Early stopping triggered at epoch 65
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 56.00 seconds
INFO:__main__:Epochs Trained: 65
INFO:__main__:Final Train Accuracy: 52.30%
INFO:__main__:Final Val Accuracy: 51.00%
INFO:__main__:Validation F1-Macro: 0.4757
INFO:__main__:Best Val Accuracy: 51.90%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.56      0.86      0.68       666
      neutral       0.48      0.45      0.46       666
contradiction       0.42      0.21      0.28       666

     accuracy                           0.51      1998
    macro avg       0.49      0.51      0.48      1998
 weighted avg       0.49      0.51      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0413 | Val Loss: 0.9339 | Train Acc: 46.35% | Val Acc: 50.35% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9535 | Val Loss: 0.9291 | Train Acc: 49.99% | Val Acc: 51.50% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9471 | Val Loss: 0.9273 | Train Acc: 50.30% | Val Acc: 50.90% | LR: 0.002500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9456 | Val Loss: 0.9251 | Train Acc: 50.06% | Val Acc: 52.05% | LR: 0.001250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9429 | Val Loss: 0.9209 | Train Acc: 51.54% | Val Acc: 52.90% | LR: 0.000313
INFO:__main__:Epoch  50/100 | Train Loss: 0.9400 | Val Loss: 0.9230 | Train Acc: 51.49% | Val Acc: 52.10% | LR: 0.000156
INFO:__main__:Epoch  60/100 | Train Loss: 0.9360 | Val Loss: 0.9228 | Train Acc: 51.61% | Val Acc: 52.95% | LR: 0.000078
INFO:__main__:Epoch  70/100 | Train Loss: 0.9326 | Val Loss: 0.9206 | Train Acc: 52.13% | Val Acc: 52.50% | LR: 0.000020
INFO:__main__:Early stopping triggered at epoch 79
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 67.36 seconds
INFO:__main__:Epochs Trained: 79
INFO:__main__:Final Train Accuracy: 52.25%
INFO:__main__:Final Val Accuracy: 52.75%
INFO:__main__:Validation F1-Macro: 0.5026
INFO:__main__:Best Val Accuracy: 53.00%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.83      0.69       666
      neutral       0.51      0.49      0.50       666
contradiction       0.41      0.26      0.32       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.50      1998
 weighted avg       0.50      0.53      0.50      1998

INFO:__main__:Results: Accuracy = 52.18% ± 0.70%
INFO:__main__:         F1-Macro = 0.4840 ± 0.0141
INFO:__main__:         Score = 51.48
INFO:__main__:         Time = 233.5s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 23/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.001, 'batch_size': 64, 'dropout_rate': 0.5, 'weight_decay': 0.001}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2277 | Val Loss: 1.0221 | Train Acc: 38.94% | Val Acc: 43.99% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9478 | Val Loss: 0.9267 | Train Acc: 51.18% | Val Acc: 51.60% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9417 | Val Loss: 0.9223 | Train Acc: 50.94% | Val Acc: 52.30% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9386 | Val Loss: 0.9224 | Train Acc: 52.04% | Val Acc: 52.40% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 38
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 17.64 seconds
INFO:__main__:Epochs Trained: 38
INFO:__main__:Final Train Accuracy: 52.36%
INFO:__main__:Final Val Accuracy: 52.10%
INFO:__main__:Validation F1-Macro: 0.4570
INFO:__main__:Best Val Accuracy: 53.05%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.81      0.68       666
      neutral       0.48      0.67      0.56       666
contradiction       0.36      0.08      0.13       666

     accuracy                           0.52      1998
    macro avg       0.48      0.52      0.46      1998
 weighted avg       0.48      0.52      0.46      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1739 | Val Loss: 0.9829 | Train Acc: 40.63% | Val Acc: 51.70% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9486 | Val Loss: 0.9248 | Train Acc: 50.53% | Val Acc: 52.20% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9399 | Val Loss: 0.9236 | Train Acc: 51.81% | Val Acc: 51.90% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9369 | Val Loss: 0.9232 | Train Acc: 51.58% | Val Acc: 51.60% | LR: 0.001000
INFO:__main__:Epoch  40/100 | Train Loss: 0.9361 | Val Loss: 0.9231 | Train Acc: 51.81% | Val Acc: 51.55% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 40
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 18.45 seconds
INFO:__main__:Epochs Trained: 40
INFO:__main__:Final Train Accuracy: 52.18%
INFO:__main__:Final Val Accuracy: 51.55%
INFO:__main__:Validation F1-Macro: 0.4693
INFO:__main__:Best Val Accuracy: 52.95%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.82      0.68       666
      neutral       0.49      0.60      0.54       666
contradiction       0.35      0.13      0.19       666

     accuracy                           0.52      1998
    macro avg       0.47      0.52      0.47      1998
 weighted avg       0.47      0.52      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2329 | Val Loss: 0.9416 | Train Acc: 38.78% | Val Acc: 52.70% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9512 | Val Loss: 0.9019 | Train Acc: 51.09% | Val Acc: 52.60% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9393 | Val Loss: 0.9020 | Train Acc: 51.31% | Val Acc: 52.50% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9415 | Val Loss: 0.9013 | Train Acc: 51.31% | Val Acc: 52.75% | LR: 0.000500
INFO:__main__:Early stopping triggered at epoch 37
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 16.91 seconds
INFO:__main__:Epochs Trained: 37
INFO:__main__:Final Train Accuracy: 51.88%
INFO:__main__:Final Val Accuracy: 52.70%
INFO:__main__:Validation F1-Macro: 0.4684
INFO:__main__:Best Val Accuracy: 53.55%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.86      0.69       666
      neutral       0.49      0.62      0.55       666
contradiction       0.40      0.10      0.16       666

     accuracy                           0.53      1998
    macro avg       0.49      0.53      0.47      1998
 weighted avg       0.49      0.53      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2314 | Val Loss: 0.9814 | Train Acc: 40.04% | Val Acc: 50.20% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9476 | Val Loss: 0.9315 | Train Acc: 50.98% | Val Acc: 50.10% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9366 | Val Loss: 0.9298 | Train Acc: 51.19% | Val Acc: 50.30% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9352 | Val Loss: 0.9341 | Train Acc: 51.70% | Val Acc: 50.15% | LR: 0.000500
INFO:__main__:Epoch  40/100 | Train Loss: 0.9308 | Val Loss: 0.9286 | Train Acc: 52.28% | Val Acc: 50.75% | LR: 0.000250
INFO:__main__:Epoch  50/100 | Train Loss: 0.9315 | Val Loss: 0.9287 | Train Acc: 52.00% | Val Acc: 50.85% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 54
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 24.55 seconds
INFO:__main__:Epochs Trained: 54
INFO:__main__:Final Train Accuracy: 52.50%
INFO:__main__:Final Val Accuracy: 50.70%
INFO:__main__:Validation F1-Macro: 0.4630
INFO:__main__:Best Val Accuracy: 51.80%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.83      0.68       666
      neutral       0.46      0.54      0.50       666
contradiction       0.38      0.14      0.21       666

     accuracy                           0.51      1998
    macro avg       0.47      0.51      0.46      1998
 weighted avg       0.47      0.51      0.46      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2305 | Val Loss: 0.9608 | Train Acc: 39.34% | Val Acc: 51.40% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9478 | Val Loss: 0.9246 | Train Acc: 50.85% | Val Acc: 52.05% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9385 | Val Loss: 0.9243 | Train Acc: 51.48% | Val Acc: 52.85% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9441 | Val Loss: 0.9242 | Train Acc: 51.58% | Val Acc: 52.95% | LR: 0.000500
INFO:__main__:Epoch  40/100 | Train Loss: 0.9372 | Val Loss: 0.9228 | Train Acc: 51.63% | Val Acc: 52.95% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 49
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 22.48 seconds
INFO:__main__:Epochs Trained: 49
INFO:__main__:Final Train Accuracy: 52.11%
INFO:__main__:Final Val Accuracy: 52.70%
INFO:__main__:Validation F1-Macro: 0.4842
INFO:__main__:Best Val Accuracy: 53.30%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.80      0.69       666
      neutral       0.49      0.63      0.55       666
contradiction       0.40      0.15      0.21       666

     accuracy                           0.53      1998
    macro avg       0.49      0.53      0.48      1998
 weighted avg       0.49      0.53      0.48      1998

INFO:__main__:Results: Accuracy = 51.95% ± 0.76%
INFO:__main__:         F1-Macro = 0.4684 ± 0.0090
INFO:__main__:         Score = 51.19
INFO:__main__:         Time = 100.1s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 24/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.001, 'batch_size': 32, 'dropout_rate': 0.1, 'weight_decay': 0.001}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0125 | Val Loss: 0.9308 | Train Acc: 48.19% | Val Acc: 51.00% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9248 | Val Loss: 0.9258 | Train Acc: 51.71% | Val Acc: 50.60% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9244 | Val Loss: 0.9253 | Train Acc: 51.69% | Val Acc: 50.50% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9193 | Val Loss: 0.9207 | Train Acc: 52.33% | Val Acc: 51.30% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 30
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 25.93 seconds
INFO:__main__:Epochs Trained: 30
INFO:__main__:Final Train Accuracy: 52.99%
INFO:__main__:Final Val Accuracy: 51.30%
INFO:__main__:Validation F1-Macro: 0.4758
INFO:__main__:Best Val Accuracy: 52.30%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.80      0.68       666
      neutral       0.46      0.58      0.51       666
contradiction       0.41      0.16      0.23       666

     accuracy                           0.51      1998
    macro avg       0.49      0.51      0.48      1998
 weighted avg       0.49      0.51      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9853 | Val Loss: 0.9227 | Train Acc: 48.36% | Val Acc: 52.45% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9283 | Val Loss: 0.9185 | Train Acc: 51.90% | Val Acc: 52.25% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9256 | Val Loss: 0.9186 | Train Acc: 52.88% | Val Acc: 52.65% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 23
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 19.99 seconds
INFO:__main__:Epochs Trained: 23
INFO:__main__:Final Train Accuracy: 52.53%
INFO:__main__:Final Val Accuracy: 53.00%
INFO:__main__:Validation F1-Macro: 0.4994
INFO:__main__:Best Val Accuracy: 53.45%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.81      0.69       666
      neutral       0.49      0.57      0.53       666
contradiction       0.45      0.21      0.29       666

     accuracy                           0.53      1998
    macro avg       0.51      0.53      0.50      1998
 weighted avg       0.51      0.53      0.50      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9873 | Val Loss: 0.9027 | Train Acc: 48.16% | Val Acc: 52.55% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9328 | Val Loss: 0.9039 | Train Acc: 51.35% | Val Acc: 51.70% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9300 | Val Loss: 0.9010 | Train Acc: 51.74% | Val Acc: 52.90% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 28
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 24.21 seconds
INFO:__main__:Epochs Trained: 28
INFO:__main__:Final Train Accuracy: 52.89%
INFO:__main__:Final Val Accuracy: 53.65%
INFO:__main__:Validation F1-Macro: 0.5081
INFO:__main__:Best Val Accuracy: 54.00%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.61      0.83      0.70       666
      neutral       0.49      0.55      0.52       666
contradiction       0.44      0.23      0.30       666

     accuracy                           0.54      1998
    macro avg       0.51      0.54      0.51      1998
 weighted avg       0.51      0.54      0.51      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9851 | Val Loss: 0.9364 | Train Acc: 49.19% | Val Acc: 51.85% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9242 | Val Loss: 0.9305 | Train Acc: 51.69% | Val Acc: 50.65% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9242 | Val Loss: 0.9296 | Train Acc: 51.23% | Val Acc: 51.05% | LR: 0.000500
INFO:__main__:Early stopping triggered at epoch 26
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 22.53 seconds
INFO:__main__:Epochs Trained: 26
INFO:__main__:Final Train Accuracy: 52.46%
INFO:__main__:Final Val Accuracy: 50.85%
INFO:__main__:Validation F1-Macro: 0.4761
INFO:__main__:Best Val Accuracy: 51.85%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.83      0.68       666
      neutral       0.46      0.50      0.48       666
contradiction       0.41      0.20      0.27       666

     accuracy                           0.51      1998
    macro avg       0.48      0.51      0.48      1998
 weighted avg       0.48      0.51      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9842 | Val Loss: 0.9337 | Train Acc: 49.77% | Val Acc: 50.30% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9281 | Val Loss: 0.9202 | Train Acc: 51.21% | Val Acc: 52.35% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9248 | Val Loss: 0.9192 | Train Acc: 52.11% | Val Acc: 52.75% | LR: 0.000250
INFO:__main__:Epoch  30/100 | Train Loss: 0.9209 | Val Loss: 0.9166 | Train Acc: 51.95% | Val Acc: 53.10% | LR: 0.000125
INFO:__main__:Epoch  40/100 | Train Loss: 0.9237 | Val Loss: 0.9164 | Train Acc: 52.48% | Val Acc: 53.40% | LR: 0.000031
INFO:__main__:Early stopping triggered at epoch 42
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 36.22 seconds
INFO:__main__:Epochs Trained: 42
INFO:__main__:Final Train Accuracy: 52.36%
INFO:__main__:Final Val Accuracy: 53.25%
INFO:__main__:Validation F1-Macro: 0.4957
INFO:__main__:Best Val Accuracy: 53.40%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.83      0.69       666
      neutral       0.49      0.58      0.53       666
contradiction       0.45      0.19      0.26       666

     accuracy                           0.53      1998
    macro avg       0.51      0.53      0.50      1998
 weighted avg       0.51      0.53      0.50      1998

INFO:__main__:Results: Accuracy = 52.41% ± 1.12%
INFO:__main__:         F1-Macro = 0.4910 ± 0.0130
INFO:__main__:         Score = 51.29
INFO:__main__:         Time = 128.9s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 25/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.0005, 'batch_size': 64, 'dropout_rate': 0.3, 'weight_decay': 0.005}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1972 | Val Loss: 0.9820 | Train Acc: 39.95% | Val Acc: 49.60% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9386 | Val Loss: 0.9255 | Train Acc: 51.83% | Val Acc: 52.10% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9306 | Val Loss: 0.9253 | Train Acc: 51.71% | Val Acc: 51.35% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9293 | Val Loss: 0.9267 | Train Acc: 51.98% | Val Acc: 51.10% | LR: 0.000500
INFO:__main__:Epoch  40/100 | Train Loss: 0.9273 | Val Loss: 0.9230 | Train Acc: 52.38% | Val Acc: 51.90% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 40
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 18.48 seconds
INFO:__main__:Epochs Trained: 40
INFO:__main__:Final Train Accuracy: 52.65%
INFO:__main__:Final Val Accuracy: 51.90%
INFO:__main__:Validation F1-Macro: 0.4668
INFO:__main__:Best Val Accuracy: 52.10%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.81      0.68       666
      neutral       0.47      0.63      0.54       666
contradiction       0.40      0.11      0.18       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.47      1998
 weighted avg       0.49      0.52      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1592 | Val Loss: 0.9992 | Train Acc: 39.84% | Val Acc: 50.45% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9455 | Val Loss: 0.9264 | Train Acc: 52.28% | Val Acc: 52.15% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9340 | Val Loss: 0.9231 | Train Acc: 51.23% | Val Acc: 52.20% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 29
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 13.42 seconds
INFO:__main__:Epochs Trained: 29
INFO:__main__:Final Train Accuracy: 52.55%
INFO:__main__:Final Val Accuracy: 52.45%
INFO:__main__:Validation F1-Macro: 0.4796
INFO:__main__:Best Val Accuracy: 53.25%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.81      0.68       666
      neutral       0.49      0.62      0.54       666
contradiction       0.41      0.14      0.21       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.48      1998
 weighted avg       0.49      0.52      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1268 | Val Loss: 0.9356 | Train Acc: 44.73% | Val Acc: 52.90% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9464 | Val Loss: 0.9031 | Train Acc: 50.24% | Val Acc: 54.10% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9375 | Val Loss: 0.9033 | Train Acc: 51.14% | Val Acc: 53.10% | LR: 0.000250
INFO:__main__:Epoch  30/100 | Train Loss: 0.9352 | Val Loss: 0.9027 | Train Acc: 51.10% | Val Acc: 53.05% | LR: 0.000250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9341 | Val Loss: 0.9025 | Train Acc: 51.66% | Val Acc: 53.50% | LR: 0.000063
INFO:__main__:Early stopping triggered at epoch 47
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 21.25 seconds
INFO:__main__:Epochs Trained: 47
INFO:__main__:Final Train Accuracy: 52.08%
INFO:__main__:Final Val Accuracy: 53.40%
INFO:__main__:Validation F1-Macro: 0.5015
INFO:__main__:Best Val Accuracy: 54.10%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.84      0.70       666
      neutral       0.50      0.56      0.53       666
contradiction       0.43      0.21      0.28       666

     accuracy                           0.53      1998
    macro avg       0.51      0.53      0.50      1998
 weighted avg       0.51      0.53      0.50      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1150 | Val Loss: 0.9684 | Train Acc: 43.34% | Val Acc: 50.20% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9414 | Val Loss: 0.9336 | Train Acc: 51.51% | Val Acc: 50.15% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9288 | Val Loss: 0.9296 | Train Acc: 51.50% | Val Acc: 50.95% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9226 | Val Loss: 0.9302 | Train Acc: 52.59% | Val Acc: 50.50% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 37
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 16.40 seconds
INFO:__main__:Epochs Trained: 37
INFO:__main__:Final Train Accuracy: 52.65%
INFO:__main__:Final Val Accuracy: 50.95%
INFO:__main__:Validation F1-Macro: 0.4755
INFO:__main__:Best Val Accuracy: 51.20%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.83      0.68       666
      neutral       0.47      0.51      0.49       666
contradiction       0.39      0.19      0.25       666

     accuracy                           0.51      1998
    macro avg       0.48      0.51      0.48      1998
 weighted avg       0.48      0.51      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2041 | Val Loss: 0.9559 | Train Acc: 42.73% | Val Acc: 50.00% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9458 | Val Loss: 0.9252 | Train Acc: 50.91% | Val Acc: 52.40% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9373 | Val Loss: 0.9228 | Train Acc: 51.44% | Val Acc: 51.55% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9336 | Val Loss: 0.9243 | Train Acc: 51.46% | Val Acc: 52.15% | LR: 0.000250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9285 | Val Loss: 0.9206 | Train Acc: 52.25% | Val Acc: 52.55% | LR: 0.000250
INFO:__main__:Epoch  50/100 | Train Loss: 0.9318 | Val Loss: 0.9205 | Train Acc: 51.51% | Val Acc: 52.85% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 54
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 24.29 seconds
INFO:__main__:Epochs Trained: 54
INFO:__main__:Final Train Accuracy: 52.28%
INFO:__main__:Final Val Accuracy: 52.55%
INFO:__main__:Validation F1-Macro: 0.5019
INFO:__main__:Best Val Accuracy: 52.95%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.81      0.69       666
      neutral       0.51      0.52      0.51       666
contradiction       0.40      0.25      0.31       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.50      1998
 weighted avg       0.50      0.53      0.50      1998

INFO:__main__:Results: Accuracy = 52.25% ± 0.81%
INFO:__main__:         F1-Macro = 0.4851 ± 0.0142
INFO:__main__:         Score = 51.44
INFO:__main__:         Time = 93.9s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 26/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.001, 'batch_size': 64, 'dropout_rate': 0.3, 'weight_decay': 0.005}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1064 | Val Loss: 0.9477 | Train Acc: 44.07% | Val Acc: 51.30% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9334 | Val Loss: 0.9261 | Train Acc: 51.59% | Val Acc: 51.00% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9303 | Val Loss: 0.9259 | Train Acc: 51.76% | Val Acc: 51.60% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9277 | Val Loss: 0.9236 | Train Acc: 51.70% | Val Acc: 51.70% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 37
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 17.18 seconds
INFO:__main__:Epochs Trained: 37
INFO:__main__:Final Train Accuracy: 52.24%
INFO:__main__:Final Val Accuracy: 51.70%
INFO:__main__:Validation F1-Macro: 0.4789
INFO:__main__:Best Val Accuracy: 52.45%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.82      0.68       666
      neutral       0.49      0.56      0.52       666
contradiction       0.38      0.17      0.23       666

     accuracy                           0.52      1998
    macro avg       0.48      0.52      0.48      1998
 weighted avg       0.48      0.52      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0685 | Val Loss: 0.9506 | Train Acc: 45.53% | Val Acc: 50.15% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9337 | Val Loss: 0.9247 | Train Acc: 52.11% | Val Acc: 52.30% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9276 | Val Loss: 0.9239 | Train Acc: 52.13% | Val Acc: 51.90% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9301 | Val Loss: 0.9233 | Train Acc: 52.24% | Val Acc: 52.05% | LR: 0.000250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9282 | Val Loss: 0.9226 | Train Acc: 52.05% | Val Acc: 51.95% | LR: 0.000125
INFO:__main__:Epoch  50/100 | Train Loss: 0.9279 | Val Loss: 0.9218 | Train Acc: 51.89% | Val Acc: 52.00% | LR: 0.000031
INFO:__main__:Epoch  60/100 | Train Loss: 0.9309 | Val Loss: 0.9226 | Train Acc: 52.40% | Val Acc: 52.10% | LR: 0.000016
INFO:__main__:Early stopping triggered at epoch 66
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 30.61 seconds
INFO:__main__:Epochs Trained: 66
INFO:__main__:Final Train Accuracy: 51.99%
INFO:__main__:Final Val Accuracy: 52.35%
INFO:__main__:Validation F1-Macro: 0.4895
INFO:__main__:Best Val Accuracy: 53.05%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.80      0.69       666
      neutral       0.49      0.59      0.54       666
contradiction       0.38      0.18      0.25       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.49      1998
 weighted avg       0.49      0.52      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0795 | Val Loss: 0.9296 | Train Acc: 45.38% | Val Acc: 53.75% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9388 | Val Loss: 0.9054 | Train Acc: 51.08% | Val Acc: 52.50% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9368 | Val Loss: 0.9075 | Train Acc: 51.66% | Val Acc: 52.00% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9333 | Val Loss: 0.9024 | Train Acc: 51.61% | Val Acc: 52.95% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 32
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 14.91 seconds
INFO:__main__:Epochs Trained: 32
INFO:__main__:Final Train Accuracy: 52.10%
INFO:__main__:Final Val Accuracy: 52.75%
INFO:__main__:Validation F1-Macro: 0.4699
INFO:__main__:Best Val Accuracy: 53.85%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.61      0.82      0.70       666
      neutral       0.48      0.67      0.56       666
contradiction       0.36      0.10      0.15       666

     accuracy                           0.53      1998
    macro avg       0.48      0.53      0.47      1998
 weighted avg       0.48      0.53      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0842 | Val Loss: 0.9646 | Train Acc: 44.17% | Val Acc: 50.75% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9307 | Val Loss: 0.9346 | Train Acc: 51.69% | Val Acc: 50.80% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9304 | Val Loss: 0.9285 | Train Acc: 51.83% | Val Acc: 51.40% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9275 | Val Loss: 0.9292 | Train Acc: 51.69% | Val Acc: 50.65% | LR: 0.000500
INFO:__main__:Early stopping triggered at epoch 35
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 16.49 seconds
INFO:__main__:Epochs Trained: 35
INFO:__main__:Final Train Accuracy: 52.30%
INFO:__main__:Final Val Accuracy: 50.90%
INFO:__main__:Validation F1-Macro: 0.4715
INFO:__main__:Best Val Accuracy: 51.40%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.84      0.69       666
      neutral       0.46      0.52      0.49       666
contradiction       0.39      0.17      0.24       666

     accuracy                           0.51      1998
    macro avg       0.48      0.51      0.47      1998
 weighted avg       0.48      0.51      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0734 | Val Loss: 0.9287 | Train Acc: 44.51% | Val Acc: 52.05% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9364 | Val Loss: 0.9223 | Train Acc: 51.50% | Val Acc: 52.50% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9322 | Val Loss: 0.9240 | Train Acc: 51.33% | Val Acc: 52.55% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9273 | Val Loss: 0.9227 | Train Acc: 52.45% | Val Acc: 53.00% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 37
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 17.26 seconds
INFO:__main__:Epochs Trained: 37
INFO:__main__:Final Train Accuracy: 51.96%
INFO:__main__:Final Val Accuracy: 52.75%
INFO:__main__:Validation F1-Macro: 0.4929
INFO:__main__:Best Val Accuracy: 53.00%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.83      0.69       666
      neutral       0.50      0.57      0.53       666
contradiction       0.40      0.19      0.25       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.49      1998
 weighted avg       0.50      0.53      0.49      1998

INFO:__main__:Results: Accuracy = 52.09% ± 0.71%
INFO:__main__:         F1-Macro = 0.4805 ± 0.0093
INFO:__main__:         Score = 51.38
INFO:__main__:         Time = 96.5s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 27/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 1e-05, 'batch_size': 128, 'dropout_rate': 0.1, 'weight_decay': 1e-05}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.5670 | Val Loss: 1.3456 | Train Acc: 31.62% | Val Acc: 32.53% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.2347 | Val Loss: 1.1080 | Train Acc: 36.19% | Val Acc: 41.99% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.0878 | Val Loss: 1.0252 | Train Acc: 44.92% | Val Acc: 50.05% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.0327 | Val Loss: 0.9922 | Train Acc: 48.15% | Val Acc: 51.05% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.0209 | Val Loss: 0.9744 | Train Acc: 48.76% | Val Acc: 51.30% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 0.9930 | Val Loss: 0.9614 | Train Acc: 49.95% | Val Acc: 50.75% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 0.9804 | Val Loss: 0.9538 | Train Acc: 51.05% | Val Acc: 50.75% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 0.9778 | Val Loss: 0.9473 | Train Acc: 50.03% | Val Acc: 52.00% | LR: 0.000010
INFO:__main__:Epoch  80/100 | Train Loss: 0.9702 | Val Loss: 0.9419 | Train Acc: 50.43% | Val Acc: 51.95% | LR: 0.000010
INFO:__main__:Epoch  90/100 | Train Loss: 0.9666 | Val Loss: 0.9384 | Train Acc: 50.71% | Val Acc: 51.80% | LR: 0.000010
INFO:__main__:Epoch 100/100 | Train Loss: 0.9597 | Val Loss: 0.9361 | Train Acc: 50.65% | Val Acc: 52.20% | LR: 0.000010
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 25.72 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 52.08%
INFO:__main__:Final Val Accuracy: 52.20%
INFO:__main__:Validation F1-Macro: 0.5019
INFO:__main__:Best Val Accuracy: 52.55%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.83      0.69       666
      neutral       0.48      0.40      0.43       666
contradiction       0.45      0.33      0.38       666

     accuracy                           0.52      1998
    macro avg       0.50      0.52      0.50      1998
 weighted avg       0.50      0.52      0.50      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2532 | Val Loss: 1.1615 | Train Acc: 36.30% | Val Acc: 38.24% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.0991 | Val Loss: 1.0277 | Train Acc: 43.96% | Val Acc: 50.15% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.0431 | Val Loss: 0.9779 | Train Acc: 47.38% | Val Acc: 50.75% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.0080 | Val Loss: 0.9584 | Train Acc: 48.85% | Val Acc: 50.55% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 0.9970 | Val Loss: 0.9456 | Train Acc: 49.40% | Val Acc: 50.90% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 0.9839 | Val Loss: 0.9392 | Train Acc: 50.19% | Val Acc: 50.35% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 0.9717 | Val Loss: 0.9333 | Train Acc: 49.92% | Val Acc: 50.65% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 0.9648 | Val Loss: 0.9314 | Train Acc: 50.43% | Val Acc: 50.55% | LR: 0.000010
INFO:__main__:Epoch  80/100 | Train Loss: 0.9617 | Val Loss: 0.9283 | Train Acc: 51.09% | Val Acc: 51.00% | LR: 0.000010
INFO:__main__:Epoch  90/100 | Train Loss: 0.9548 | Val Loss: 0.9268 | Train Acc: 51.41% | Val Acc: 51.70% | LR: 0.000010
INFO:__main__:Epoch 100/100 | Train Loss: 0.9514 | Val Loss: 0.9258 | Train Acc: 51.14% | Val Acc: 51.70% | LR: 0.000010
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 25.70 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 52.20%
INFO:__main__:Final Val Accuracy: 51.70%
INFO:__main__:Validation F1-Macro: 0.4876
INFO:__main__:Best Val Accuracy: 51.75%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.84      0.69       666
      neutral       0.46      0.49      0.47       666
contradiction       0.43      0.23      0.30       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.49      1998
 weighted avg       0.49      0.52      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3405 | Val Loss: 1.2131 | Train Acc: 30.08% | Val Acc: 30.28% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.1710 | Val Loss: 1.0545 | Train Acc: 39.11% | Val Acc: 46.80% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.0801 | Val Loss: 0.9917 | Train Acc: 45.90% | Val Acc: 51.55% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.0456 | Val Loss: 0.9614 | Train Acc: 48.49% | Val Acc: 52.85% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.0215 | Val Loss: 0.9441 | Train Acc: 49.00% | Val Acc: 53.30% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.0125 | Val Loss: 0.9343 | Train Acc: 49.36% | Val Acc: 52.85% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 0.9999 | Val Loss: 0.9282 | Train Acc: 50.28% | Val Acc: 52.60% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 0.9860 | Val Loss: 0.9264 | Train Acc: 49.91% | Val Acc: 53.05% | LR: 0.000010
INFO:__main__:Epoch  80/100 | Train Loss: 0.9758 | Val Loss: 0.9194 | Train Acc: 50.79% | Val Acc: 53.65% | LR: 0.000010
INFO:__main__:Epoch  90/100 | Train Loss: 0.9743 | Val Loss: 0.9185 | Train Acc: 50.16% | Val Acc: 53.30% | LR: 0.000005
INFO:__main__:Epoch 100/100 | Train Loss: 0.9690 | Val Loss: 0.9166 | Train Acc: 50.99% | Val Acc: 53.60% | LR: 0.000005
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 25.39 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 52.16%
INFO:__main__:Final Val Accuracy: 53.60%
INFO:__main__:Validation F1-Macro: 0.5178
INFO:__main__:Best Val Accuracy: 53.90%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.61      0.83      0.70       666
      neutral       0.49      0.45      0.47       666
contradiction       0.46      0.33      0.38       666

     accuracy                           0.54      1998
    macro avg       0.52      0.54      0.52      1998
 weighted avg       0.52      0.54      0.52      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2522 | Val Loss: 1.1800 | Train Acc: 35.79% | Val Acc: 38.39% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.1321 | Val Loss: 1.0567 | Train Acc: 42.68% | Val Acc: 46.45% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.0720 | Val Loss: 1.0064 | Train Acc: 47.23% | Val Acc: 50.60% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.0400 | Val Loss: 0.9844 | Train Acc: 48.67% | Val Acc: 50.55% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.0122 | Val Loss: 0.9693 | Train Acc: 49.71% | Val Acc: 50.70% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 0.9961 | Val Loss: 0.9615 | Train Acc: 50.34% | Val Acc: 51.50% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 0.9899 | Val Loss: 0.9569 | Train Acc: 50.33% | Val Acc: 51.55% | LR: 0.000005
INFO:__main__:Epoch  70/100 | Train Loss: 0.9798 | Val Loss: 0.9558 | Train Acc: 50.94% | Val Acc: 51.65% | LR: 0.000001
INFO:__main__:Epoch  80/100 | Train Loss: 0.9829 | Val Loss: 0.9559 | Train Acc: 50.79% | Val Acc: 51.60% | LR: 0.000001
INFO:__main__:Epoch  90/100 | Train Loss: 0.9855 | Val Loss: 0.9532 | Train Acc: 51.63% | Val Acc: 51.65% | LR: 0.000001
INFO:__main__:Epoch 100/100 | Train Loss: 0.9801 | Val Loss: 0.9551 | Train Acc: 51.03% | Val Acc: 51.45% | LR: 0.000001
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 25.75 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 52.95%
INFO:__main__:Final Val Accuracy: 51.45%
INFO:__main__:Validation F1-Macro: 0.4678
INFO:__main__:Best Val Accuracy: 52.05%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.57      0.85      0.68       666
      neutral       0.45      0.55      0.50       666
contradiction       0.49      0.15      0.22       666

     accuracy                           0.51      1998
    macro avg       0.50      0.51      0.47      1998
 weighted avg       0.50      0.51      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2833 | Val Loss: 1.1449 | Train Acc: 36.22% | Val Acc: 39.74% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.1315 | Val Loss: 1.0246 | Train Acc: 44.77% | Val Acc: 46.60% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.0720 | Val Loss: 0.9866 | Train Acc: 47.57% | Val Acc: 49.40% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.0389 | Val Loss: 0.9788 | Train Acc: 49.27% | Val Acc: 50.35% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.0221 | Val Loss: 0.9637 | Train Acc: 50.46% | Val Acc: 51.25% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.0100 | Val Loss: 0.9602 | Train Acc: 50.28% | Val Acc: 50.55% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 0.9971 | Val Loss: 0.9543 | Train Acc: 50.04% | Val Acc: 51.10% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 0.9847 | Val Loss: 0.9474 | Train Acc: 50.98% | Val Acc: 51.35% | LR: 0.000010
INFO:__main__:Epoch  80/100 | Train Loss: 0.9732 | Val Loss: 0.9411 | Train Acc: 51.66% | Val Acc: 51.55% | LR: 0.000010
INFO:__main__:Epoch  90/100 | Train Loss: 0.9721 | Val Loss: 0.9398 | Train Acc: 51.39% | Val Acc: 51.40% | LR: 0.000010
INFO:__main__:Epoch 100/100 | Train Loss: 0.9723 | Val Loss: 0.9374 | Train Acc: 51.10% | Val Acc: 51.40% | LR: 0.000005
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 25.53 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 52.44%
INFO:__main__:Final Val Accuracy: 51.40%
INFO:__main__:Validation F1-Macro: 0.4877
INFO:__main__:Best Val Accuracy: 52.15%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.83      0.69       666
      neutral       0.48      0.47      0.47       666
contradiction       0.40      0.24      0.30       666

     accuracy                           0.51      1998
    macro avg       0.49      0.51      0.49      1998
 weighted avg       0.49      0.51      0.49      1998

INFO:__main__:Results: Accuracy = 52.07% ± 0.82%
INFO:__main__:         F1-Macro = 0.4926 ± 0.0166
INFO:__main__:         Score = 51.26
INFO:__main__:         Time = 128.1s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 28/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.005, 'batch_size': 64, 'dropout_rate': 0.1, 'weight_decay': 0.001}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9617 | Val Loss: 0.9266 | Train Acc: 50.53% | Val Acc: 50.60% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9296 | Val Loss: 0.9245 | Train Acc: 50.91% | Val Acc: 50.70% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9259 | Val Loss: 0.9240 | Train Acc: 51.55% | Val Acc: 52.00% | LR: 0.002500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9217 | Val Loss: 0.9203 | Train Acc: 51.93% | Val Acc: 52.30% | LR: 0.001250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9209 | Val Loss: 0.9222 | Train Acc: 52.05% | Val Acc: 52.40% | LR: 0.000625
INFO:__main__:Early stopping triggered at epoch 48
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 22.20 seconds
INFO:__main__:Epochs Trained: 48
INFO:__main__:Final Train Accuracy: 52.36%
INFO:__main__:Final Val Accuracy: 52.35%
INFO:__main__:Validation F1-Macro: 0.4873
INFO:__main__:Best Val Accuracy: 53.00%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.84      0.69       666
      neutral       0.49      0.54      0.52       666
contradiction       0.41      0.19      0.26       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.49      1998
 weighted avg       0.49      0.52      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9712 | Val Loss: 0.9273 | Train Acc: 49.67% | Val Acc: 52.50% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9287 | Val Loss: 0.9235 | Train Acc: 50.75% | Val Acc: 50.65% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9218 | Val Loss: 0.9241 | Train Acc: 51.79% | Val Acc: 51.45% | LR: 0.002500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9243 | Val Loss: 0.9211 | Train Acc: 51.51% | Val Acc: 51.75% | LR: 0.001250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9246 | Val Loss: 0.9235 | Train Acc: 52.03% | Val Acc: 51.80% | LR: 0.001250
INFO:__main__:Epoch  50/100 | Train Loss: 0.9207 | Val Loss: 0.9195 | Train Acc: 51.96% | Val Acc: 51.90% | LR: 0.000625
INFO:__main__:Epoch  60/100 | Train Loss: 0.9189 | Val Loss: 0.9202 | Train Acc: 52.31% | Val Acc: 52.00% | LR: 0.000313
INFO:__main__:Early stopping triggered at epoch 66
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 30.14 seconds
INFO:__main__:Epochs Trained: 66
INFO:__main__:Final Train Accuracy: 52.68%
INFO:__main__:Final Val Accuracy: 51.65%
INFO:__main__:Validation F1-Macro: 0.4731
INFO:__main__:Best Val Accuracy: 52.50%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.81      0.68       666
      neutral       0.48      0.59      0.53       666
contradiction       0.37      0.14      0.20       666

     accuracy                           0.52      1998
    macro avg       0.48      0.52      0.47      1998
 weighted avg       0.48      0.52      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9546 | Val Loss: 0.9065 | Train Acc: 50.63% | Val Acc: 51.85% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9328 | Val Loss: 0.9031 | Train Acc: 51.29% | Val Acc: 52.60% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9357 | Val Loss: 0.9006 | Train Acc: 51.23% | Val Acc: 53.50% | LR: 0.005000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9278 | Val Loss: 0.8997 | Train Acc: 51.01% | Val Acc: 53.15% | LR: 0.001250
INFO:__main__:Early stopping triggered at epoch 31
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 14.31 seconds
INFO:__main__:Epochs Trained: 31
INFO:__main__:Final Train Accuracy: 51.89%
INFO:__main__:Final Val Accuracy: 53.55%
INFO:__main__:Validation F1-Macro: 0.5021
INFO:__main__:Best Val Accuracy: 53.55%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.62      0.82      0.70       666
      neutral       0.50      0.59      0.54       666
contradiction       0.39      0.19      0.26       666

     accuracy                           0.54      1998
    macro avg       0.50      0.54      0.50      1998
 weighted avg       0.50      0.54      0.50      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9547 | Val Loss: 0.9335 | Train Acc: 50.96% | Val Acc: 50.20% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9235 | Val Loss: 0.9281 | Train Acc: 51.19% | Val Acc: 51.05% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9231 | Val Loss: 0.9312 | Train Acc: 51.64% | Val Acc: 50.30% | LR: 0.001250
INFO:__main__:Early stopping triggered at epoch 23
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 10.72 seconds
INFO:__main__:Epochs Trained: 23
INFO:__main__:Final Train Accuracy: 52.63%
INFO:__main__:Final Val Accuracy: 50.60%
INFO:__main__:Validation F1-Macro: 0.4564
INFO:__main__:Best Val Accuracy: 51.75%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.83      0.68       666
      neutral       0.46      0.57      0.51       666
contradiction       0.36      0.12      0.18       666

     accuracy                           0.51      1998
    macro avg       0.47      0.51      0.46      1998
 weighted avg       0.47      0.51      0.46      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9686 | Val Loss: 0.9211 | Train Acc: 50.29% | Val Acc: 52.05% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9276 | Val Loss: 0.9280 | Train Acc: 51.28% | Val Acc: 51.15% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9271 | Val Loss: 0.9214 | Train Acc: 51.80% | Val Acc: 51.15% | LR: 0.002500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9273 | Val Loss: 0.9200 | Train Acc: 51.66% | Val Acc: 52.70% | LR: 0.001250
INFO:__main__:Early stopping triggered at epoch 39
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 17.92 seconds
INFO:__main__:Epochs Trained: 39
INFO:__main__:Final Train Accuracy: 51.95%
INFO:__main__:Final Val Accuracy: 52.80%
INFO:__main__:Validation F1-Macro: 0.5038
INFO:__main__:Best Val Accuracy: 53.15%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.83      0.69       666
      neutral       0.51      0.50      0.50       666
contradiction       0.41      0.26      0.31       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.50      1998
 weighted avg       0.50      0.53      0.50      1998

INFO:__main__:Results: Accuracy = 52.19% ± 1.01%
INFO:__main__:         F1-Macro = 0.4845 ± 0.0179
INFO:__main__:         Score = 51.18
INFO:__main__:         Time = 95.3s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 29/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.0005, 'batch_size': 64, 'dropout_rate': 0.1, 'weight_decay': 1e-05}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0860 | Val Loss: 0.9476 | Train Acc: 45.71% | Val Acc: 51.25% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9289 | Val Loss: 0.9226 | Train Acc: 51.94% | Val Acc: 51.85% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9220 | Val Loss: 0.9218 | Train Acc: 51.88% | Val Acc: 52.20% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 24
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 11.24 seconds
INFO:__main__:Epochs Trained: 24
INFO:__main__:Final Train Accuracy: 53.37%
INFO:__main__:Final Val Accuracy: 51.85%
INFO:__main__:Validation F1-Macro: 0.4960
INFO:__main__:Best Val Accuracy: 52.70%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.79      0.68       666
      neutral       0.47      0.51      0.49       666
contradiction       0.43      0.25      0.32       666

     accuracy                           0.52      1998
    macro avg       0.50      0.52      0.50      1998
 weighted avg       0.50      0.52      0.50      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0336 | Val Loss: 0.9390 | Train Acc: 47.30% | Val Acc: 49.50% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9250 | Val Loss: 0.9192 | Train Acc: 52.54% | Val Acc: 51.60% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9239 | Val Loss: 0.9214 | Train Acc: 52.31% | Val Acc: 51.05% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 29
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 13.26 seconds
INFO:__main__:Epochs Trained: 29
INFO:__main__:Final Train Accuracy: 52.95%
INFO:__main__:Final Val Accuracy: 51.65%
INFO:__main__:Validation F1-Macro: 0.4936
INFO:__main__:Best Val Accuracy: 52.35%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.81      0.68       666
      neutral       0.47      0.48      0.48       666
contradiction       0.42      0.26      0.32       666

     accuracy                           0.52      1998
    macro avg       0.50      0.52      0.49      1998
 weighted avg       0.50      0.52      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0164 | Val Loss: 0.9120 | Train Acc: 47.21% | Val Acc: 51.65% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9341 | Val Loss: 0.8990 | Train Acc: 51.76% | Val Acc: 52.05% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9293 | Val Loss: 0.8992 | Train Acc: 51.45% | Val Acc: 51.70% | LR: 0.000250
INFO:__main__:Epoch  30/100 | Train Loss: 0.9241 | Val Loss: 0.8990 | Train Acc: 52.15% | Val Acc: 52.90% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 33
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 15.06 seconds
INFO:__main__:Epochs Trained: 33
INFO:__main__:Final Train Accuracy: 53.17%
INFO:__main__:Final Val Accuracy: 52.55%
INFO:__main__:Validation F1-Macro: 0.5043
INFO:__main__:Best Val Accuracy: 53.40%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.84      0.70       666
      neutral       0.48      0.43      0.46       666
contradiction       0.43      0.30      0.35       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.50      1998
 weighted avg       0.50      0.53      0.50      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0548 | Val Loss: 0.9444 | Train Acc: 46.37% | Val Acc: 50.60% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9247 | Val Loss: 0.9304 | Train Acc: 52.26% | Val Acc: 50.75% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9206 | Val Loss: 0.9288 | Train Acc: 52.46% | Val Acc: 51.15% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9182 | Val Loss: 0.9293 | Train Acc: 52.77% | Val Acc: 50.65% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 32
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 14.92 seconds
INFO:__main__:Epochs Trained: 32
INFO:__main__:Final Train Accuracy: 53.28%
INFO:__main__:Final Val Accuracy: 51.30%
INFO:__main__:Validation F1-Macro: 0.4802
INFO:__main__:Best Val Accuracy: 52.05%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.82      0.68       666
      neutral       0.47      0.52      0.49       666
contradiction       0.42      0.20      0.27       666

     accuracy                           0.51      1998
    macro avg       0.49      0.51      0.48      1998
 weighted avg       0.49      0.51      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0214 | Val Loss: 0.9443 | Train Acc: 49.22% | Val Acc: 51.15% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9280 | Val Loss: 0.9177 | Train Acc: 52.04% | Val Acc: 52.65% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9243 | Val Loss: 0.9173 | Train Acc: 52.19% | Val Acc: 51.95% | LR: 0.000250
INFO:__main__:Epoch  30/100 | Train Loss: 0.9215 | Val Loss: 0.9180 | Train Acc: 51.91% | Val Acc: 51.45% | LR: 0.000063
INFO:__main__:Early stopping triggered at epoch 31
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 14.31 seconds
INFO:__main__:Epochs Trained: 31
INFO:__main__:Final Train Accuracy: 52.98%
INFO:__main__:Final Val Accuracy: 51.60%
INFO:__main__:Validation F1-Macro: 0.4831
INFO:__main__:Best Val Accuracy: 52.85%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.82      0.68       666
      neutral       0.48      0.53      0.50       666
contradiction       0.40      0.19      0.26       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.48      1998
 weighted avg       0.49      0.52      0.48      1998

INFO:__main__:Results: Accuracy = 51.79% ± 0.42%
INFO:__main__:         F1-Macro = 0.4914 ± 0.0088
INFO:__main__:         Score = 51.37
INFO:__main__:         Time = 68.8s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 30/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.001, 'batch_size': 256, 'dropout_rate': 0.5, 'weight_decay': 0.0001}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3068 | Val Loss: 1.0450 | Train Acc: 35.56% | Val Acc: 44.64% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9778 | Val Loss: 0.9312 | Train Acc: 50.28% | Val Acc: 53.05% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9493 | Val Loss: 0.9267 | Train Acc: 50.50% | Val Acc: 52.40% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9467 | Val Loss: 0.9223 | Train Acc: 51.21% | Val Acc: 51.95% | LR: 0.001000
INFO:__main__:Epoch  40/100 | Train Loss: 0.9382 | Val Loss: 0.9238 | Train Acc: 51.19% | Val Acc: 52.05% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 43
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 7.08 seconds
INFO:__main__:Epochs Trained: 43
INFO:__main__:Final Train Accuracy: 51.93%
INFO:__main__:Final Val Accuracy: 52.30%
INFO:__main__:Validation F1-Macro: 0.4896
INFO:__main__:Best Val Accuracy: 53.05%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.83      0.69       666
      neutral       0.50      0.54      0.52       666
contradiction       0.40      0.20      0.26       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.49      1998
 weighted avg       0.49      0.52      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3205 | Val Loss: 1.0141 | Train Acc: 35.75% | Val Acc: 45.90% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9784 | Val Loss: 0.9301 | Train Acc: 49.32% | Val Acc: 50.50% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9526 | Val Loss: 0.9220 | Train Acc: 51.40% | Val Acc: 52.75% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9421 | Val Loss: 0.9207 | Train Acc: 51.76% | Val Acc: 52.20% | LR: 0.001000
INFO:__main__:Epoch  40/100 | Train Loss: 0.9425 | Val Loss: 0.9214 | Train Acc: 52.59% | Val Acc: 51.85% | LR: 0.001000
INFO:__main__:Epoch  50/100 | Train Loss: 0.9402 | Val Loss: 0.9203 | Train Acc: 51.60% | Val Acc: 51.95% | LR: 0.000250
INFO:__main__:Epoch  60/100 | Train Loss: 0.9392 | Val Loss: 0.9203 | Train Acc: 51.95% | Val Acc: 52.10% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 64
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 10.13 seconds
INFO:__main__:Epochs Trained: 64
INFO:__main__:Final Train Accuracy: 52.25%
INFO:__main__:Final Val Accuracy: 52.10%
INFO:__main__:Validation F1-Macro: 0.4841
INFO:__main__:Best Val Accuracy: 53.20%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.82      0.69       666
      neutral       0.49      0.57      0.53       666
contradiction       0.38      0.17      0.24       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.48      1998
 weighted avg       0.49      0.52      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2666 | Val Loss: 1.0060 | Train Acc: 36.46% | Val Acc: 52.70% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9782 | Val Loss: 0.9139 | Train Acc: 49.51% | Val Acc: 52.05% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9538 | Val Loss: 0.9061 | Train Acc: 50.28% | Val Acc: 52.75% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9498 | Val Loss: 0.9031 | Train Acc: 50.88% | Val Acc: 52.85% | LR: 0.001000
INFO:__main__:Epoch  40/100 | Train Loss: 0.9461 | Val Loss: 0.9032 | Train Acc: 51.18% | Val Acc: 52.30% | LR: 0.000500
INFO:__main__:Early stopping triggered at epoch 48
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 7.93 seconds
INFO:__main__:Epochs Trained: 48
INFO:__main__:Final Train Accuracy: 52.09%
INFO:__main__:Final Val Accuracy: 52.80%
INFO:__main__:Validation F1-Macro: 0.4745
INFO:__main__:Best Val Accuracy: 53.25%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.85      0.70       666
      neutral       0.48      0.61      0.54       666
contradiction       0.45      0.12      0.19       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.47      1998
 weighted avg       0.50      0.53      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2631 | Val Loss: 1.0148 | Train Acc: 35.61% | Val Acc: 50.65% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9699 | Val Loss: 0.9373 | Train Acc: 50.26% | Val Acc: 51.15% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9441 | Val Loss: 0.9333 | Train Acc: 51.11% | Val Acc: 50.90% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9426 | Val Loss: 0.9326 | Train Acc: 51.65% | Val Acc: 50.30% | LR: 0.000500
INFO:__main__:Early stopping triggered at epoch 36
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 5.87 seconds
INFO:__main__:Epochs Trained: 36
INFO:__main__:Final Train Accuracy: 52.43%
INFO:__main__:Final Val Accuracy: 50.25%
INFO:__main__:Validation F1-Macro: 0.4632
INFO:__main__:Best Val Accuracy: 51.30%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.57      0.84      0.68       666
      neutral       0.46      0.50      0.48       666
contradiction       0.37      0.16      0.23       666

     accuracy                           0.50      1998
    macro avg       0.47      0.50      0.46      1998
 weighted avg       0.47      0.50      0.46      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3716 | Val Loss: 1.0613 | Train Acc: 34.07% | Val Acc: 46.20% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9954 | Val Loss: 0.9324 | Train Acc: 48.87% | Val Acc: 51.55% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9521 | Val Loss: 0.9221 | Train Acc: 51.25% | Val Acc: 52.15% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9422 | Val Loss: 0.9203 | Train Acc: 50.50% | Val Acc: 52.10% | LR: 0.001000
INFO:__main__:Epoch  40/100 | Train Loss: 0.9404 | Val Loss: 0.9203 | Train Acc: 52.14% | Val Acc: 52.15% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 42
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 7.32 seconds
INFO:__main__:Epochs Trained: 42
INFO:__main__:Final Train Accuracy: 52.15%
INFO:__main__:Final Val Accuracy: 51.95%
INFO:__main__:Validation F1-Macro: 0.4706
INFO:__main__:Best Val Accuracy: 52.65%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.82      0.68       666
      neutral       0.48      0.61      0.54       666
contradiction       0.40      0.13      0.19       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.47      1998
 weighted avg       0.49      0.52      0.47      1998

INFO:__main__:Results: Accuracy = 51.88% ± 0.86%
INFO:__main__:         F1-Macro = 0.4764 ± 0.0094
INFO:__main__:         Score = 51.02
INFO:__main__:         Time = 38.4s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 31/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.001, 'batch_size': 64, 'dropout_rate': 0.3, 'weight_decay': 0.001}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1067 | Val Loss: 0.9444 | Train Acc: 43.98% | Val Acc: 51.40% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9338 | Val Loss: 0.9237 | Train Acc: 51.63% | Val Acc: 51.80% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9275 | Val Loss: 0.9217 | Train Acc: 51.71% | Val Acc: 51.70% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9264 | Val Loss: 0.9212 | Train Acc: 52.31% | Val Acc: 50.95% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 37
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 17.66 seconds
INFO:__main__:Epochs Trained: 37
INFO:__main__:Final Train Accuracy: 52.33%
INFO:__main__:Final Val Accuracy: 51.40%
INFO:__main__:Validation F1-Macro: 0.4712
INFO:__main__:Best Val Accuracy: 52.65%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.83      0.69       666
      neutral       0.47      0.57      0.51       666
contradiction       0.39      0.15      0.21       666

     accuracy                           0.51      1998
    macro avg       0.48      0.51      0.47      1998
 weighted avg       0.48      0.51      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0696 | Val Loss: 0.9477 | Train Acc: 45.37% | Val Acc: 50.45% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9333 | Val Loss: 0.9213 | Train Acc: 51.98% | Val Acc: 52.50% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9257 | Val Loss: 0.9187 | Train Acc: 51.60% | Val Acc: 51.80% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9288 | Val Loss: 0.9200 | Train Acc: 52.14% | Val Acc: 51.70% | LR: 0.000500
INFO:__main__:Epoch  40/100 | Train Loss: 0.9271 | Val Loss: 0.9188 | Train Acc: 51.44% | Val Acc: 52.20% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 41
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 19.36 seconds
INFO:__main__:Epochs Trained: 41
INFO:__main__:Final Train Accuracy: 52.36%
INFO:__main__:Final Val Accuracy: 51.65%
INFO:__main__:Validation F1-Macro: 0.4760
INFO:__main__:Best Val Accuracy: 52.95%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.82      0.68       666
      neutral       0.49      0.57      0.52       666
contradiction       0.38      0.16      0.22       666

     accuracy                           0.52      1998
    macro avg       0.48      0.52      0.48      1998
 weighted avg       0.48      0.52      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0819 | Val Loss: 0.9072 | Train Acc: 45.41% | Val Acc: 53.50% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9388 | Val Loss: 0.8996 | Train Acc: 51.54% | Val Acc: 52.75% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9286 | Val Loss: 0.8995 | Train Acc: 51.55% | Val Acc: 52.70% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9306 | Val Loss: 0.8991 | Train Acc: 51.88% | Val Acc: 53.00% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 31
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 15.15 seconds
INFO:__main__:Epochs Trained: 31
INFO:__main__:Final Train Accuracy: 51.73%
INFO:__main__:Final Val Accuracy: 52.90%
INFO:__main__:Validation F1-Macro: 0.4943
INFO:__main__:Best Val Accuracy: 53.75%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.86      0.69       666
      neutral       0.50      0.52      0.51       666
contradiction       0.42      0.21      0.28       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.49      1998
 weighted avg       0.50      0.53      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1760 | Val Loss: 0.9717 | Train Acc: 44.16% | Val Acc: 50.65% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9322 | Val Loss: 0.9315 | Train Acc: 52.01% | Val Acc: 50.35% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9250 | Val Loss: 0.9293 | Train Acc: 51.85% | Val Acc: 50.75% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9224 | Val Loss: 0.9284 | Train Acc: 52.36% | Val Acc: 50.90% | LR: 0.000125
INFO:__main__:Epoch  40/100 | Train Loss: 0.9230 | Val Loss: 0.9286 | Train Acc: 52.41% | Val Acc: 50.75% | LR: 0.000063
INFO:__main__:Epoch  50/100 | Train Loss: 0.9198 | Val Loss: 0.9284 | Train Acc: 52.39% | Val Acc: 50.75% | LR: 0.000016
INFO:__main__:Early stopping triggered at epoch 58
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 28.35 seconds
INFO:__main__:Epochs Trained: 58
INFO:__main__:Final Train Accuracy: 52.83%
INFO:__main__:Final Val Accuracy: 50.80%
INFO:__main__:Validation F1-Macro: 0.4688
INFO:__main__:Best Val Accuracy: 51.55%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.83      0.68       666
      neutral       0.47      0.53      0.50       666
contradiction       0.38      0.16      0.23       666

     accuracy                           0.51      1998
    macro avg       0.48      0.51      0.47      1998
 weighted avg       0.48      0.51      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0853 | Val Loss: 0.9273 | Train Acc: 46.77% | Val Acc: 50.20% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9360 | Val Loss: 0.9210 | Train Acc: 52.15% | Val Acc: 52.05% | LR: 0.000500
INFO:__main__:Early stopping triggered at epoch 19
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 9.59 seconds
INFO:__main__:Epochs Trained: 19
INFO:__main__:Final Train Accuracy: 52.28%
INFO:__main__:Final Val Accuracy: 53.25%
INFO:__main__:Validation F1-Macro: 0.4973
INFO:__main__:Best Val Accuracy: 53.25%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.82      0.69       666
      neutral       0.50      0.60      0.55       666
contradiction       0.41      0.19      0.26       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.50      1998
 weighted avg       0.50      0.53      0.50      1998

INFO:__main__:Results: Accuracy = 52.00% ± 0.93%
INFO:__main__:         F1-Macro = 0.4815 ± 0.0119
INFO:__main__:         Score = 51.07
INFO:__main__:         Time = 90.1s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 32/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.005, 'batch_size': 64, 'dropout_rate': 0.5, 'weight_decay': 0.001}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0499 | Val Loss: 0.9359 | Train Acc: 46.78% | Val Acc: 51.00% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9433 | Val Loss: 0.9300 | Train Acc: 50.50% | Val Acc: 50.85% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9387 | Val Loss: 0.9241 | Train Acc: 51.08% | Val Acc: 52.25% | LR: 0.002500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9352 | Val Loss: 0.9219 | Train Acc: 52.00% | Val Acc: 52.40% | LR: 0.001250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9347 | Val Loss: 0.9225 | Train Acc: 51.79% | Val Acc: 51.95% | LR: 0.000625
INFO:__main__:Epoch  50/100 | Train Loss: 0.9359 | Val Loss: 0.9222 | Train Acc: 51.35% | Val Acc: 51.95% | LR: 0.000156
INFO:__main__:Epoch  60/100 | Train Loss: 0.9300 | Val Loss: 0.9221 | Train Acc: 51.99% | Val Acc: 52.65% | LR: 0.000156
INFO:__main__:Epoch  70/100 | Train Loss: 0.9326 | Val Loss: 0.9209 | Train Acc: 51.68% | Val Acc: 52.40% | LR: 0.000078
INFO:__main__:Epoch  80/100 | Train Loss: 0.9319 | Val Loss: 0.9211 | Train Acc: 51.83% | Val Acc: 52.15% | LR: 0.000078
INFO:__main__:Epoch  90/100 | Train Loss: 0.9322 | Val Loss: 0.9211 | Train Acc: 52.23% | Val Acc: 51.80% | LR: 0.000020
INFO:__main__:Early stopping triggered at epoch 90
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 44.22 seconds
INFO:__main__:Epochs Trained: 90
INFO:__main__:Final Train Accuracy: 52.18%
INFO:__main__:Final Val Accuracy: 51.80%
INFO:__main__:Validation F1-Macro: 0.4825
INFO:__main__:Best Val Accuracy: 52.90%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.81      0.68       666
      neutral       0.49      0.57      0.53       666
contradiction       0.37      0.17      0.24       666

     accuracy                           0.52      1998
    macro avg       0.48      0.52      0.48      1998
 weighted avg       0.48      0.52      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0424 | Val Loss: 0.9294 | Train Acc: 46.66% | Val Acc: 51.80% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9425 | Val Loss: 0.9249 | Train Acc: 51.40% | Val Acc: 52.15% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9379 | Val Loss: 0.9224 | Train Acc: 50.81% | Val Acc: 52.30% | LR: 0.002500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9364 | Val Loss: 0.9219 | Train Acc: 51.76% | Val Acc: 52.15% | LR: 0.001250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9305 | Val Loss: 0.9230 | Train Acc: 51.79% | Val Acc: 52.05% | LR: 0.000625
INFO:__main__:Epoch  50/100 | Train Loss: 0.9369 | Val Loss: 0.9222 | Train Acc: 51.64% | Val Acc: 52.25% | LR: 0.000156
INFO:__main__:Early stopping triggered at epoch 52
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 26.49 seconds
INFO:__main__:Epochs Trained: 52
INFO:__main__:Final Train Accuracy: 52.16%
INFO:__main__:Final Val Accuracy: 51.95%
INFO:__main__:Validation F1-Macro: 0.4826
INFO:__main__:Best Val Accuracy: 52.30%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.81      0.69       666
      neutral       0.49      0.58      0.53       666
contradiction       0.37      0.17      0.23       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.48      1998
 weighted avg       0.49      0.52      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0460 | Val Loss: 0.9118 | Train Acc: 45.66% | Val Acc: 51.50% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9494 | Val Loss: 0.9072 | Train Acc: 50.00% | Val Acc: 53.15% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9467 | Val Loss: 0.9066 | Train Acc: 51.60% | Val Acc: 53.55% | LR: 0.001250
INFO:__main__:Early stopping triggered at epoch 23
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 11.68 seconds
INFO:__main__:Epochs Trained: 23
INFO:__main__:Final Train Accuracy: 51.99%
INFO:__main__:Final Val Accuracy: 53.20%
INFO:__main__:Validation F1-Macro: 0.4845
INFO:__main__:Best Val Accuracy: 53.75%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.85      0.70       666
      neutral       0.50      0.61      0.55       666
contradiction       0.40      0.14      0.21       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.48      1998
 weighted avg       0.50      0.53      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0775 | Val Loss: 0.9439 | Train Acc: 46.30% | Val Acc: 51.10% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9433 | Val Loss: 0.9326 | Train Acc: 51.05% | Val Acc: 50.35% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9386 | Val Loss: 0.9307 | Train Acc: 50.88% | Val Acc: 50.55% | LR: 0.002500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9369 | Val Loss: 0.9296 | Train Acc: 52.46% | Val Acc: 50.85% | LR: 0.001250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9323 | Val Loss: 0.9283 | Train Acc: 52.39% | Val Acc: 50.70% | LR: 0.000625
INFO:__main__:Epoch  50/100 | Train Loss: 0.9317 | Val Loss: 0.9284 | Train Acc: 51.94% | Val Acc: 50.55% | LR: 0.000625
INFO:__main__:Epoch  60/100 | Train Loss: 0.9353 | Val Loss: 0.9276 | Train Acc: 51.45% | Val Acc: 51.00% | LR: 0.000156
INFO:__main__:Early stopping triggered at epoch 61
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 29.10 seconds
INFO:__main__:Epochs Trained: 61
INFO:__main__:Final Train Accuracy: 52.49%
INFO:__main__:Final Val Accuracy: 50.95%
INFO:__main__:Validation F1-Macro: 0.4719
INFO:__main__:Best Val Accuracy: 51.70%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.83      0.69       666
      neutral       0.46      0.53      0.49       666
contradiction       0.38      0.17      0.24       666

     accuracy                           0.51      1998
    macro avg       0.48      0.51      0.47      1998
 weighted avg       0.48      0.51      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0378 | Val Loss: 0.9279 | Train Acc: 46.65% | Val Acc: 51.90% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9438 | Val Loss: 0.9296 | Train Acc: 50.70% | Val Acc: 50.25% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9440 | Val Loss: 0.9244 | Train Acc: 51.10% | Val Acc: 52.45% | LR: 0.002500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9415 | Val Loss: 0.9243 | Train Acc: 50.65% | Val Acc: 52.55% | LR: 0.002500
INFO:__main__:Epoch  40/100 | Train Loss: 0.9375 | Val Loss: 0.9214 | Train Acc: 51.58% | Val Acc: 52.70% | LR: 0.000625
INFO:__main__:Early stopping triggered at epoch 42
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 20.09 seconds
INFO:__main__:Epochs Trained: 42
INFO:__main__:Final Train Accuracy: 51.94%
INFO:__main__:Final Val Accuracy: 52.70%
INFO:__main__:Validation F1-Macro: 0.4798
INFO:__main__:Best Val Accuracy: 53.00%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.81      0.69       666
      neutral       0.49      0.64      0.55       666
contradiction       0.39      0.13      0.20       666

     accuracy                           0.53      1998
    macro avg       0.49      0.53      0.48      1998
 weighted avg       0.49      0.53      0.48      1998

INFO:__main__:Results: Accuracy = 52.12% ± 0.78%
INFO:__main__:         F1-Macro = 0.4803 ± 0.0044
INFO:__main__:         Score = 51.35
INFO:__main__:         Time = 131.6s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 33/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 1e-05, 'batch_size': 64, 'dropout_rate': 0.3, 'weight_decay': 0.005}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.5624 | Val Loss: 1.1822 | Train Acc: 31.74% | Val Acc: 31.33% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.3055 | Val Loss: 1.0826 | Train Acc: 34.91% | Val Acc: 42.69% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.1727 | Val Loss: 1.0380 | Train Acc: 39.68% | Val Acc: 49.20% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.1237 | Val Loss: 1.0121 | Train Acc: 42.04% | Val Acc: 50.10% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.0825 | Val Loss: 1.0009 | Train Acc: 44.92% | Val Acc: 49.90% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.0624 | Val Loss: 0.9847 | Train Acc: 45.83% | Val Acc: 50.10% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.0484 | Val Loss: 0.9786 | Train Acc: 47.16% | Val Acc: 50.75% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 1.0318 | Val Loss: 0.9665 | Train Acc: 48.10% | Val Acc: 50.30% | LR: 0.000010
INFO:__main__:Epoch  80/100 | Train Loss: 1.0081 | Val Loss: 0.9593 | Train Acc: 49.22% | Val Acc: 50.55% | LR: 0.000010
INFO:__main__:Epoch  90/100 | Train Loss: 1.0077 | Val Loss: 0.9540 | Train Acc: 48.55% | Val Acc: 51.50% | LR: 0.000003
INFO:__main__:Epoch 100/100 | Train Loss: 0.9999 | Val Loss: 0.9572 | Train Acc: 48.95% | Val Acc: 50.90% | LR: 0.000003
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 47.43 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 51.63%
INFO:__main__:Final Val Accuracy: 50.90%
INFO:__main__:Validation F1-Macro: 0.4775
INFO:__main__:Best Val Accuracy: 51.50%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.55      0.88      0.68       666
      neutral       0.49      0.40      0.44       666
contradiction       0.42      0.25      0.31       666

     accuracy                           0.51      1998
    macro avg       0.49      0.51      0.48      1998
 weighted avg       0.49      0.51      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3392 | Val Loss: 1.1196 | Train Acc: 33.97% | Val Acc: 39.34% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.2244 | Val Loss: 1.0359 | Train Acc: 37.35% | Val Acc: 50.25% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.1383 | Val Loss: 0.9955 | Train Acc: 41.63% | Val Acc: 51.05% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.1044 | Val Loss: 0.9759 | Train Acc: 43.44% | Val Acc: 51.30% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.0883 | Val Loss: 0.9625 | Train Acc: 44.72% | Val Acc: 50.70% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.0594 | Val Loss: 0.9554 | Train Acc: 46.35% | Val Acc: 51.50% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.0420 | Val Loss: 0.9454 | Train Acc: 47.26% | Val Acc: 51.90% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 1.0290 | Val Loss: 0.9421 | Train Acc: 47.77% | Val Acc: 51.15% | LR: 0.000005
INFO:__main__:Epoch  80/100 | Train Loss: 1.0269 | Val Loss: 0.9417 | Train Acc: 48.24% | Val Acc: 51.25% | LR: 0.000005
INFO:__main__:Epoch  90/100 | Train Loss: 1.0247 | Val Loss: 0.9398 | Train Acc: 48.07% | Val Acc: 51.85% | LR: 0.000003
INFO:__main__:Epoch 100/100 | Train Loss: 1.0162 | Val Loss: 0.9365 | Train Acc: 48.10% | Val Acc: 51.80% | LR: 0.000001
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 47.41 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 52.41%
INFO:__main__:Final Val Accuracy: 51.80%
INFO:__main__:Validation F1-Macro: 0.4772
INFO:__main__:Best Val Accuracy: 52.10%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.84      0.69       666
      neutral       0.46      0.55      0.50       666
contradiction       0.44      0.17      0.24       666

     accuracy                           0.52      1998
    macro avg       0.50      0.52      0.48      1998
 weighted avg       0.50      0.52      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3643 | Val Loss: 1.1360 | Train Acc: 32.13% | Val Acc: 33.58% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.2684 | Val Loss: 1.0628 | Train Acc: 36.11% | Val Acc: 43.89% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.1853 | Val Loss: 1.0109 | Train Acc: 39.95% | Val Acc: 50.65% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.1362 | Val Loss: 0.9869 | Train Acc: 43.23% | Val Acc: 52.80% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.0950 | Val Loss: 0.9610 | Train Acc: 45.80% | Val Acc: 53.45% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.0723 | Val Loss: 0.9491 | Train Acc: 45.98% | Val Acc: 52.85% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.0508 | Val Loss: 0.9413 | Train Acc: 46.16% | Val Acc: 53.35% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 1.0406 | Val Loss: 0.9347 | Train Acc: 47.26% | Val Acc: 52.70% | LR: 0.000010
INFO:__main__:Epoch  80/100 | Train Loss: 1.0361 | Val Loss: 0.9280 | Train Acc: 47.69% | Val Acc: 52.35% | LR: 0.000005
INFO:__main__:Epoch  90/100 | Train Loss: 1.0105 | Val Loss: 0.9323 | Train Acc: 48.77% | Val Acc: 53.55% | LR: 0.000003
INFO:__main__:Early stopping triggered at epoch 95
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 43.67 seconds
INFO:__main__:Epochs Trained: 95
INFO:__main__:Final Train Accuracy: 51.69%
INFO:__main__:Final Val Accuracy: 53.15%
INFO:__main__:Validation F1-Macro: 0.5160
INFO:__main__:Best Val Accuracy: 53.60%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.63      0.80      0.71       666
      neutral       0.47      0.47      0.47       666
contradiction       0.44      0.32      0.37       666

     accuracy                           0.53      1998
    macro avg       0.51      0.53      0.52      1998
 weighted avg       0.51      0.53      0.52      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2767 | Val Loss: 1.1089 | Train Acc: 33.71% | Val Acc: 33.48% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.1823 | Val Loss: 1.0513 | Train Acc: 36.24% | Val Acc: 36.24% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.1335 | Val Loss: 1.0176 | Train Acc: 39.50% | Val Acc: 43.69% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.0891 | Val Loss: 0.9898 | Train Acc: 43.56% | Val Acc: 50.55% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.0518 | Val Loss: 0.9816 | Train Acc: 45.70% | Val Acc: 51.05% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.0356 | Val Loss: 0.9682 | Train Acc: 46.93% | Val Acc: 51.30% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.0231 | Val Loss: 0.9613 | Train Acc: 48.40% | Val Acc: 50.45% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 1.0119 | Val Loss: 0.9569 | Train Acc: 49.19% | Val Acc: 50.65% | LR: 0.000010
INFO:__main__:Epoch  80/100 | Train Loss: 1.0055 | Val Loss: 0.9526 | Train Acc: 49.34% | Val Acc: 49.85% | LR: 0.000010
INFO:__main__:Epoch  90/100 | Train Loss: 0.9902 | Val Loss: 0.9505 | Train Acc: 50.69% | Val Acc: 50.90% | LR: 0.000005
INFO:__main__:Epoch 100/100 | Train Loss: 0.9976 | Val Loss: 0.9495 | Train Acc: 50.06% | Val Acc: 50.40% | LR: 0.000005
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 45.60 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 52.77%
INFO:__main__:Final Val Accuracy: 50.40%
INFO:__main__:Validation F1-Macro: 0.4649
INFO:__main__:Best Val Accuracy: 51.35%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.57      0.83      0.68       666
      neutral       0.46      0.53      0.49       666
contradiction       0.38      0.16      0.23       666

     accuracy                           0.50      1998
    macro avg       0.47      0.50      0.46      1998
 weighted avg       0.47      0.50      0.46      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3724 | Val Loss: 1.0954 | Train Acc: 34.03% | Val Acc: 41.74% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.2579 | Val Loss: 1.0301 | Train Acc: 38.80% | Val Acc: 46.70% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.1792 | Val Loss: 1.0011 | Train Acc: 42.29% | Val Acc: 49.90% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.1270 | Val Loss: 0.9811 | Train Acc: 44.56% | Val Acc: 50.45% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.0991 | Val Loss: 0.9715 | Train Acc: 46.17% | Val Acc: 50.50% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.0939 | Val Loss: 0.9609 | Train Acc: 46.27% | Val Acc: 50.60% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.0649 | Val Loss: 0.9509 | Train Acc: 47.16% | Val Acc: 50.90% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 1.0484 | Val Loss: 0.9509 | Train Acc: 47.65% | Val Acc: 50.75% | LR: 0.000005
INFO:__main__:Epoch  80/100 | Train Loss: 1.0474 | Val Loss: 0.9488 | Train Acc: 48.25% | Val Acc: 50.35% | LR: 0.000001
INFO:__main__:Epoch  90/100 | Train Loss: 1.0408 | Val Loss: 0.9496 | Train Acc: 48.42% | Val Acc: 50.50% | LR: 0.000001
INFO:__main__:Epoch 100/100 | Train Loss: 1.0473 | Val Loss: 0.9480 | Train Acc: 47.64% | Val Acc: 50.45% | LR: 0.000001
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 45.03 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 51.64%
INFO:__main__:Final Val Accuracy: 50.45%
INFO:__main__:Validation F1-Macro: 0.4801
INFO:__main__:Best Val Accuracy: 51.40%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.79      0.68       666
      neutral       0.45      0.50      0.47       666
contradiction       0.40      0.23      0.29       666

     accuracy                           0.50      1998
    macro avg       0.48      0.50      0.48      1998
 weighted avg       0.48      0.50      0.48      1998

INFO:__main__:Results: Accuracy = 51.34% ± 1.04%
INFO:__main__:         F1-Macro = 0.4831 ± 0.0172
INFO:__main__:         Score = 50.31
INFO:__main__:         Time = 229.2s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 34/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.0005, 'batch_size': 256, 'dropout_rate': 0.3, 'weight_decay': 0.001}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2984 | Val Loss: 1.0385 | Train Acc: 35.40% | Val Acc: 50.95% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9658 | Val Loss: 0.9296 | Train Acc: 50.48% | Val Acc: 52.05% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9389 | Val Loss: 0.9242 | Train Acc: 50.69% | Val Acc: 51.25% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9333 | Val Loss: 0.9217 | Train Acc: 51.60% | Val Acc: 51.70% | LR: 0.000500
INFO:__main__:Epoch  40/100 | Train Loss: 0.9300 | Val Loss: 0.9228 | Train Acc: 52.03% | Val Acc: 51.10% | LR: 0.000250
INFO:__main__:Epoch  50/100 | Train Loss: 0.9305 | Val Loss: 0.9211 | Train Acc: 51.50% | Val Acc: 51.35% | LR: 0.000063
INFO:__main__:Early stopping triggered at epoch 53
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 8.50 seconds
INFO:__main__:Epochs Trained: 53
INFO:__main__:Final Train Accuracy: 52.24%
INFO:__main__:Final Val Accuracy: 50.60%
INFO:__main__:Validation F1-Macro: 0.4827
INFO:__main__:Best Val Accuracy: 52.45%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.82      0.68       666
      neutral       0.46      0.44      0.45       666
contradiction       0.40      0.26      0.32       666

     accuracy                           0.51      1998
    macro avg       0.48      0.51      0.48      1998
 weighted avg       0.48      0.51      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1377 | Val Loss: 0.9619 | Train Acc: 41.58% | Val Acc: 50.50% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9539 | Val Loss: 0.9210 | Train Acc: 51.08% | Val Acc: 52.15% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9364 | Val Loss: 0.9192 | Train Acc: 51.51% | Val Acc: 51.70% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9342 | Val Loss: 0.9194 | Train Acc: 51.93% | Val Acc: 51.60% | LR: 0.000500
INFO:__main__:Epoch  40/100 | Train Loss: 0.9274 | Val Loss: 0.9191 | Train Acc: 52.63% | Val Acc: 51.85% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 40
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 6.50 seconds
INFO:__main__:Epochs Trained: 40
INFO:__main__:Final Train Accuracy: 52.36%
INFO:__main__:Final Val Accuracy: 51.85%
INFO:__main__:Validation F1-Macro: 0.4948
INFO:__main__:Best Val Accuracy: 52.80%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.83      0.68       666
      neutral       0.50      0.45      0.48       666
contradiction       0.41      0.27      0.32       666

     accuracy                           0.52      1998
    macro avg       0.50      0.52      0.49      1998
 weighted avg       0.50      0.52      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2820 | Val Loss: 0.9863 | Train Acc: 37.30% | Val Acc: 50.90% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9846 | Val Loss: 0.9122 | Train Acc: 50.08% | Val Acc: 53.50% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9506 | Val Loss: 0.9045 | Train Acc: 51.44% | Val Acc: 53.50% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9478 | Val Loss: 0.9023 | Train Acc: 51.04% | Val Acc: 52.70% | LR: 0.000500
INFO:__main__:Epoch  40/100 | Train Loss: 0.9333 | Val Loss: 0.9015 | Train Acc: 52.19% | Val Acc: 53.05% | LR: 0.000500
INFO:__main__:Epoch  50/100 | Train Loss: 0.9367 | Val Loss: 0.9013 | Train Acc: 51.29% | Val Acc: 53.15% | LR: 0.000500
INFO:__main__:Epoch  60/100 | Train Loss: 0.9340 | Val Loss: 0.9013 | Train Acc: 51.90% | Val Acc: 53.10% | LR: 0.000250
INFO:__main__:Epoch  70/100 | Train Loss: 0.9294 | Val Loss: 0.9002 | Train Acc: 51.80% | Val Acc: 53.30% | LR: 0.000250
INFO:__main__:Epoch  80/100 | Train Loss: 0.9336 | Val Loss: 0.9008 | Train Acc: 51.38% | Val Acc: 53.10% | LR: 0.000063
INFO:__main__:Early stopping triggered at epoch 89
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 14.24 seconds
INFO:__main__:Epochs Trained: 89
INFO:__main__:Final Train Accuracy: 52.30%
INFO:__main__:Final Val Accuracy: 52.80%
INFO:__main__:Validation F1-Macro: 0.4849
INFO:__main__:Best Val Accuracy: 54.20%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.84      0.70       666
      neutral       0.49      0.59      0.53       666
contradiction       0.41      0.16      0.23       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.48      1998
 weighted avg       0.50      0.53      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2326 | Val Loss: 0.9896 | Train Acc: 37.05% | Val Acc: 50.65% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9627 | Val Loss: 0.9349 | Train Acc: 51.35% | Val Acc: 50.95% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9389 | Val Loss: 0.9331 | Train Acc: 51.96% | Val Acc: 50.05% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9328 | Val Loss: 0.9323 | Train Acc: 52.09% | Val Acc: 50.75% | LR: 0.000250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9338 | Val Loss: 0.9324 | Train Acc: 51.84% | Val Acc: 50.25% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 46
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 7.31 seconds
INFO:__main__:Epochs Trained: 46
INFO:__main__:Final Train Accuracy: 52.84%
INFO:__main__:Final Val Accuracy: 50.25%
INFO:__main__:Validation F1-Macro: 0.4511
INFO:__main__:Best Val Accuracy: 51.60%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.57      0.83      0.68       666
      neutral       0.46      0.57      0.51       666
contradiction       0.36      0.11      0.17       666

     accuracy                           0.50      1998
    macro avg       0.46      0.50      0.45      1998
 weighted avg       0.46      0.50      0.45      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2572 | Val Loss: 0.9723 | Train Acc: 40.18% | Val Acc: 51.10% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9847 | Val Loss: 0.9235 | Train Acc: 49.09% | Val Acc: 51.95% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9547 | Val Loss: 0.9180 | Train Acc: 50.49% | Val Acc: 53.15% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9348 | Val Loss: 0.9171 | Train Acc: 51.20% | Val Acc: 52.30% | LR: 0.000250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9379 | Val Loss: 0.9168 | Train Acc: 51.41% | Val Acc: 52.75% | LR: 0.000250
INFO:__main__:Epoch  50/100 | Train Loss: 0.9348 | Val Loss: 0.9171 | Train Acc: 51.51% | Val Acc: 52.75% | LR: 0.000063
INFO:__main__:Early stopping triggered at epoch 50
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 8.06 seconds
INFO:__main__:Epochs Trained: 50
INFO:__main__:Final Train Accuracy: 52.33%
INFO:__main__:Final Val Accuracy: 52.75%
INFO:__main__:Validation F1-Macro: 0.5041
INFO:__main__:Best Val Accuracy: 53.20%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.83      0.69       666
      neutral       0.50      0.48      0.49       666
contradiction       0.43      0.27      0.33       666

     accuracy                           0.53      1998
    macro avg       0.51      0.53      0.50      1998
 weighted avg       0.51      0.53      0.50      1998

INFO:__main__:Results: Accuracy = 51.65% ± 1.06%
INFO:__main__:         F1-Macro = 0.4835 ± 0.0179
INFO:__main__:         Score = 50.59
INFO:__main__:         Time = 44.6s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 35/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.005, 'batch_size': 128, 'dropout_rate': 0.1, 'weight_decay': 0.001}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9731 | Val Loss: 0.9236 | Train Acc: 50.40% | Val Acc: 50.95% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9214 | Val Loss: 0.9228 | Train Acc: 51.85% | Val Acc: 51.40% | LR: 0.002500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9203 | Val Loss: 0.9220 | Train Acc: 52.58% | Val Acc: 51.30% | LR: 0.000625
INFO:__main__:Early stopping triggered at epoch 23
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 6.04 seconds
INFO:__main__:Epochs Trained: 23
INFO:__main__:Final Train Accuracy: 52.53%
INFO:__main__:Final Val Accuracy: 51.35%
INFO:__main__:Validation F1-Macro: 0.4868
INFO:__main__:Best Val Accuracy: 52.25%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.84      0.69       666
      neutral       0.46      0.45      0.45       666
contradiction       0.43      0.25      0.32       666

     accuracy                           0.51      1998
    macro avg       0.49      0.51      0.49      1998
 weighted avg       0.49      0.51      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9566 | Val Loss: 0.9291 | Train Acc: 50.28% | Val Acc: 51.90% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9222 | Val Loss: 0.9259 | Train Acc: 52.39% | Val Acc: 50.90% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9222 | Val Loss: 0.9236 | Train Acc: 51.84% | Val Acc: 51.85% | LR: 0.002500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9210 | Val Loss: 0.9211 | Train Acc: 52.68% | Val Acc: 52.20% | LR: 0.001250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9187 | Val Loss: 0.9210 | Train Acc: 52.39% | Val Acc: 52.35% | LR: 0.000313
INFO:__main__:Epoch  50/100 | Train Loss: 0.9208 | Val Loss: 0.9200 | Train Acc: 52.26% | Val Acc: 52.30% | LR: 0.000156
INFO:__main__:Early stopping triggered at epoch 57
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 14.82 seconds
INFO:__main__:Epochs Trained: 57
INFO:__main__:Final Train Accuracy: 52.83%
INFO:__main__:Final Val Accuracy: 52.30%
INFO:__main__:Validation F1-Macro: 0.4819
INFO:__main__:Best Val Accuracy: 53.05%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.81      0.68       666
      neutral       0.48      0.60      0.54       666
contradiction       0.41      0.16      0.23       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.48      1998
 weighted avg       0.49      0.52      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9847 | Val Loss: 0.9091 | Train Acc: 49.06% | Val Acc: 52.15% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9294 | Val Loss: 0.9011 | Train Acc: 51.80% | Val Acc: 53.85% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9256 | Val Loss: 0.9003 | Train Acc: 51.19% | Val Acc: 53.65% | LR: 0.001250
INFO:__main__:Early stopping triggered at epoch 21
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 5.69 seconds
INFO:__main__:Epochs Trained: 21
INFO:__main__:Final Train Accuracy: 52.25%
INFO:__main__:Final Val Accuracy: 53.50%
INFO:__main__:Validation F1-Macro: 0.4752
INFO:__main__:Best Val Accuracy: 53.85%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.84      0.70       666
      neutral       0.49      0.66      0.56       666
contradiction       0.42      0.10      0.16       666

     accuracy                           0.54      1998
    macro avg       0.50      0.54      0.48      1998
 weighted avg       0.50      0.54      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9640 | Val Loss: 0.9378 | Train Acc: 50.06% | Val Acc: 50.35% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9203 | Val Loss: 0.9337 | Train Acc: 51.71% | Val Acc: 50.45% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9208 | Val Loss: 0.9316 | Train Acc: 51.63% | Val Acc: 51.25% | LR: 0.002500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9170 | Val Loss: 0.9296 | Train Acc: 52.50% | Val Acc: 51.10% | LR: 0.001250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9178 | Val Loss: 0.9290 | Train Acc: 52.77% | Val Acc: 51.25% | LR: 0.001250
INFO:__main__:Epoch  50/100 | Train Loss: 0.9167 | Val Loss: 0.9282 | Train Acc: 52.16% | Val Acc: 51.25% | LR: 0.000313
INFO:__main__:Early stopping triggered at epoch 53
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 14.04 seconds
INFO:__main__:Epochs Trained: 53
INFO:__main__:Final Train Accuracy: 53.08%
INFO:__main__:Final Val Accuracy: 51.10%
INFO:__main__:Validation F1-Macro: 0.4712
INFO:__main__:Best Val Accuracy: 51.45%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.83      0.68       666
      neutral       0.47      0.54      0.50       666
contradiction       0.40      0.16      0.23       666

     accuracy                           0.51      1998
    macro avg       0.48      0.51      0.47      1998
 weighted avg       0.48      0.51      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9704 | Val Loss: 0.9185 | Train Acc: 50.06% | Val Acc: 51.90% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9244 | Val Loss: 0.9299 | Train Acc: 51.16% | Val Acc: 48.85% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9214 | Val Loss: 0.9151 | Train Acc: 51.58% | Val Acc: 52.75% | LR: 0.001250
INFO:__main__:Epoch  30/100 | Train Loss: 0.9188 | Val Loss: 0.9155 | Train Acc: 52.10% | Val Acc: 53.20% | LR: 0.000625
INFO:__main__:Epoch  40/100 | Train Loss: 0.9209 | Val Loss: 0.9137 | Train Acc: 52.04% | Val Acc: 52.95% | LR: 0.000625
INFO:__main__:Epoch  50/100 | Train Loss: 0.9204 | Val Loss: 0.9136 | Train Acc: 52.26% | Val Acc: 53.35% | LR: 0.000313
INFO:__main__:Epoch  60/100 | Train Loss: 0.9176 | Val Loss: 0.9140 | Train Acc: 53.03% | Val Acc: 52.85% | LR: 0.000156
INFO:__main__:Epoch  70/100 | Train Loss: 0.9211 | Val Loss: 0.9133 | Train Acc: 52.15% | Val Acc: 52.85% | LR: 0.000039
INFO:__main__:Early stopping triggered at epoch 70
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 17.88 seconds
INFO:__main__:Epochs Trained: 70
INFO:__main__:Final Train Accuracy: 52.54%
INFO:__main__:Final Val Accuracy: 52.85%
INFO:__main__:Validation F1-Macro: 0.4916
INFO:__main__:Best Val Accuracy: 53.45%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.83      0.69       666
      neutral       0.49      0.57      0.53       666
contradiction       0.42      0.18      0.26       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.49      1998
 weighted avg       0.50      0.53      0.49      1998

INFO:__main__:Results: Accuracy = 52.22% ± 0.90%
INFO:__main__:         F1-Macro = 0.4813 ± 0.0074
INFO:__main__:         Score = 51.32
INFO:__main__:         Time = 58.5s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 36/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 1e-05, 'batch_size': 32, 'dropout_rate': 0.3, 'weight_decay': 0.0001}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.5408 | Val Loss: 1.1861 | Train Acc: 32.49% | Val Acc: 33.38% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.2494 | Val Loss: 1.0577 | Train Acc: 37.53% | Val Acc: 46.80% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.1278 | Val Loss: 1.0177 | Train Acc: 41.72% | Val Acc: 47.85% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.0942 | Val Loss: 0.9894 | Train Acc: 44.61% | Val Acc: 50.15% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.0611 | Val Loss: 0.9737 | Train Acc: 46.81% | Val Acc: 50.50% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.0333 | Val Loss: 0.9575 | Train Acc: 47.76% | Val Acc: 50.65% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.0110 | Val Loss: 0.9558 | Train Acc: 48.61% | Val Acc: 50.60% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 1.0069 | Val Loss: 0.9456 | Train Acc: 49.44% | Val Acc: 51.30% | LR: 0.000005
INFO:__main__:Epoch  80/100 | Train Loss: 1.0000 | Val Loss: 0.9474 | Train Acc: 48.86% | Val Acc: 50.90% | LR: 0.000003
INFO:__main__:Epoch  90/100 | Train Loss: 1.0031 | Val Loss: 0.9419 | Train Acc: 49.21% | Val Acc: 51.25% | LR: 0.000001
INFO:__main__:Early stopping triggered at epoch 91
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 79.15 seconds
INFO:__main__:Epochs Trained: 91
INFO:__main__:Final Train Accuracy: 51.96%
INFO:__main__:Final Val Accuracy: 51.05%
INFO:__main__:Validation F1-Macro: 0.4689
INFO:__main__:Best Val Accuracy: 51.50%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.56      0.86      0.68       666
      neutral       0.48      0.50      0.49       666
contradiction       0.41      0.17      0.24       666

     accuracy                           0.51      1998
    macro avg       0.48      0.51      0.47      1998
 weighted avg       0.48      0.51      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.4090 | Val Loss: 1.1236 | Train Acc: 34.43% | Val Acc: 38.89% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.2295 | Val Loss: 1.0250 | Train Acc: 38.18% | Val Acc: 45.10% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.1185 | Val Loss: 0.9778 | Train Acc: 43.36% | Val Acc: 49.10% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.0687 | Val Loss: 0.9610 | Train Acc: 45.20% | Val Acc: 50.70% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.0295 | Val Loss: 0.9509 | Train Acc: 46.68% | Val Acc: 50.40% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.0177 | Val Loss: 0.9466 | Train Acc: 47.90% | Val Acc: 51.00% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.0109 | Val Loss: 0.9474 | Train Acc: 47.72% | Val Acc: 52.30% | LR: 0.000005
INFO:__main__:Epoch  70/100 | Train Loss: 1.0003 | Val Loss: 0.9443 | Train Acc: 48.37% | Val Acc: 51.90% | LR: 0.000005
INFO:__main__:Epoch  80/100 | Train Loss: 1.0055 | Val Loss: 0.9400 | Train Acc: 47.94% | Val Acc: 52.45% | LR: 0.000001
INFO:__main__:Epoch  90/100 | Train Loss: 1.0007 | Val Loss: 0.9393 | Train Acc: 48.47% | Val Acc: 51.90% | LR: 0.000001
INFO:__main__:Epoch 100/100 | Train Loss: 1.0009 | Val Loss: 0.9416 | Train Acc: 48.99% | Val Acc: 51.55% | LR: 0.000001
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 86.53 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 51.26%
INFO:__main__:Final Val Accuracy: 51.55%
INFO:__main__:Validation F1-Macro: 0.4509
INFO:__main__:Best Val Accuracy: 52.55%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.61      0.77      0.68       666
      neutral       0.45      0.70      0.55       666
contradiction       0.42      0.07      0.12       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.45      1998
 weighted avg       0.49      0.52      0.45      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.4350 | Val Loss: 1.2209 | Train Acc: 29.52% | Val Acc: 24.32% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.1850 | Val Loss: 1.0194 | Train Acc: 39.15% | Val Acc: 49.85% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.1022 | Val Loss: 0.9678 | Train Acc: 44.01% | Val Acc: 51.60% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.0577 | Val Loss: 0.9492 | Train Acc: 46.26% | Val Acc: 51.55% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.0438 | Val Loss: 0.9297 | Train Acc: 46.91% | Val Acc: 51.45% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.0238 | Val Loss: 0.9274 | Train Acc: 47.75% | Val Acc: 53.10% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.0032 | Val Loss: 0.9266 | Train Acc: 48.86% | Val Acc: 52.85% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 1.0073 | Val Loss: 0.9242 | Train Acc: 48.64% | Val Acc: 53.10% | LR: 0.000005
INFO:__main__:Epoch  80/100 | Train Loss: 1.0031 | Val Loss: 0.9205 | Train Acc: 48.55% | Val Acc: 53.20% | LR: 0.000001
INFO:__main__:Early stopping triggered at epoch 80
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 69.10 seconds
INFO:__main__:Epochs Trained: 80
INFO:__main__:Final Train Accuracy: 51.70%
INFO:__main__:Final Val Accuracy: 53.20%
INFO:__main__:Validation F1-Macro: 0.5063
INFO:__main__:Best Val Accuracy: 53.70%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.85      0.70       666
      neutral       0.50      0.48      0.49       666
contradiction       0.43      0.26      0.33       666

     accuracy                           0.53      1998
    macro avg       0.51      0.53      0.51      1998
 weighted avg       0.51      0.53      0.51      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2751 | Val Loss: 1.0988 | Train Acc: 33.83% | Val Acc: 36.29% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.1224 | Val Loss: 1.0090 | Train Acc: 41.13% | Val Acc: 48.60% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.0636 | Val Loss: 0.9673 | Train Acc: 44.96% | Val Acc: 51.05% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.0226 | Val Loss: 0.9563 | Train Acc: 46.80% | Val Acc: 49.95% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.0020 | Val Loss: 0.9507 | Train Acc: 48.24% | Val Acc: 50.60% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 0.9928 | Val Loss: 0.9447 | Train Acc: 49.36% | Val Acc: 50.30% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 0.9908 | Val Loss: 0.9453 | Train Acc: 49.12% | Val Acc: 50.45% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 0.9828 | Val Loss: 0.9415 | Train Acc: 49.74% | Val Acc: 50.00% | LR: 0.000005
INFO:__main__:Epoch  80/100 | Train Loss: 0.9852 | Val Loss: 0.9412 | Train Acc: 49.64% | Val Acc: 50.50% | LR: 0.000005
INFO:__main__:Epoch  90/100 | Train Loss: 0.9744 | Val Loss: 0.9407 | Train Acc: 50.00% | Val Acc: 50.65% | LR: 0.000003
INFO:__main__:Epoch 100/100 | Train Loss: 0.9735 | Val Loss: 0.9410 | Train Acc: 49.99% | Val Acc: 50.90% | LR: 0.000003
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 85.88 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 52.30%
INFO:__main__:Final Val Accuracy: 50.90%
INFO:__main__:Validation F1-Macro: 0.4942
INFO:__main__:Best Val Accuracy: 51.70%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.79      0.68       666
      neutral       0.46      0.37      0.41       666
contradiction       0.42      0.37      0.39       666

     accuracy                           0.51      1998
    macro avg       0.49      0.51      0.49      1998
 weighted avg       0.49      0.51      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.5302 | Val Loss: 1.1805 | Train Acc: 35.11% | Val Acc: 32.98% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.2434 | Val Loss: 0.9889 | Train Acc: 41.97% | Val Acc: 47.70% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.1599 | Val Loss: 0.9725 | Train Acc: 45.06% | Val Acc: 48.65% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.1180 | Val Loss: 0.9688 | Train Acc: 46.52% | Val Acc: 49.70% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.1052 | Val Loss: 0.9613 | Train Acc: 45.83% | Val Acc: 50.25% | LR: 0.000003
INFO:__main__:Epoch  50/100 | Train Loss: 1.0955 | Val Loss: 0.9605 | Train Acc: 46.43% | Val Acc: 49.15% | LR: 0.000001
INFO:__main__:Epoch  60/100 | Train Loss: 1.0924 | Val Loss: 0.9624 | Train Acc: 46.71% | Val Acc: 51.00% | LR: 0.000001
INFO:__main__:Epoch  70/100 | Train Loss: 1.0808 | Val Loss: 0.9592 | Train Acc: 47.15% | Val Acc: 51.25% | LR: 0.000001
INFO:__main__:Epoch  80/100 | Train Loss: 1.0806 | Val Loss: 0.9533 | Train Acc: 47.32% | Val Acc: 50.60% | LR: 0.000001
INFO:__main__:Epoch  90/100 | Train Loss: 1.0852 | Val Loss: 0.9568 | Train Acc: 47.37% | Val Acc: 50.45% | LR: 0.000001
INFO:__main__:Early stopping triggered at epoch 96
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 83.59 seconds
INFO:__main__:Epochs Trained: 96
INFO:__main__:Final Train Accuracy: 50.49%
INFO:__main__:Final Val Accuracy: 50.35%
INFO:__main__:Validation F1-Macro: 0.4912
INFO:__main__:Best Val Accuracy: 51.60%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.65      0.65      0.65       666
      neutral       0.46      0.61      0.52       666
contradiction       0.37      0.25      0.30       666

     accuracy                           0.50      1998
    macro avg       0.49      0.50      0.49      1998
 weighted avg       0.49      0.50      0.49      1998

INFO:__main__:Results: Accuracy = 51.41% ± 0.97%
INFO:__main__:         F1-Macro = 0.4823 ± 0.0198
INFO:__main__:         Score = 50.44
INFO:__main__:         Time = 404.3s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 37/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.001, 'batch_size': 256, 'dropout_rate': 0.1, 'weight_decay': 0.0001}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1139 | Val Loss: 0.9646 | Train Acc: 44.38% | Val Acc: 51.75% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9255 | Val Loss: 0.9236 | Train Acc: 52.18% | Val Acc: 51.80% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9169 | Val Loss: 0.9242 | Train Acc: 52.18% | Val Acc: 50.50% | LR: 0.000500
INFO:__main__:Early stopping triggered at epoch 28
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 4.71 seconds
INFO:__main__:Epochs Trained: 28
INFO:__main__:Final Train Accuracy: 53.89%
INFO:__main__:Final Val Accuracy: 51.65%
INFO:__main__:Validation F1-Macro: 0.4886
INFO:__main__:Best Val Accuracy: 51.85%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.81      0.69       666
      neutral       0.46      0.52      0.49       666
contradiction       0.43      0.22      0.29       666

     accuracy                           0.52      1998
    macro avg       0.50      0.52      0.49      1998
 weighted avg       0.50      0.52      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0686 | Val Loss: 0.9436 | Train Acc: 47.31% | Val Acc: 51.40% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9265 | Val Loss: 0.9177 | Train Acc: 51.95% | Val Acc: 52.55% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9254 | Val Loss: 0.9190 | Train Acc: 51.93% | Val Acc: 52.05% | LR: 0.000500
INFO:__main__:Early stopping triggered at epoch 25
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 4.16 seconds
INFO:__main__:Epochs Trained: 25
INFO:__main__:Final Train Accuracy: 53.34%
INFO:__main__:Final Val Accuracy: 52.00%
INFO:__main__:Validation F1-Macro: 0.5025
INFO:__main__:Best Val Accuracy: 53.20%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.81      0.68       666
      neutral       0.48      0.43      0.45       666
contradiction       0.44      0.33      0.38       666

     accuracy                           0.52      1998
    macro avg       0.50      0.52      0.50      1998
 weighted avg       0.50      0.52      0.50      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0397 | Val Loss: 0.9246 | Train Acc: 46.42% | Val Acc: 51.10% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9314 | Val Loss: 0.9008 | Train Acc: 51.58% | Val Acc: 51.95% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9233 | Val Loss: 0.9007 | Train Acc: 52.54% | Val Acc: 52.95% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9206 | Val Loss: 0.9003 | Train Acc: 51.99% | Val Acc: 53.00% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 33
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 5.40 seconds
INFO:__main__:Epochs Trained: 33
INFO:__main__:Final Train Accuracy: 53.14%
INFO:__main__:Final Val Accuracy: 52.85%
INFO:__main__:Validation F1-Macro: 0.5052
INFO:__main__:Best Val Accuracy: 53.40%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.84      0.70       666
      neutral       0.49      0.46      0.47       666
contradiction       0.43      0.28      0.34       666

     accuracy                           0.53      1998
    macro avg       0.51      0.53      0.51      1998
 weighted avg       0.51      0.53      0.51      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0721 | Val Loss: 0.9538 | Train Acc: 46.26% | Val Acc: 50.85% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9204 | Val Loss: 0.9349 | Train Acc: 52.23% | Val Acc: 51.45% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9197 | Val Loss: 0.9319 | Train Acc: 52.50% | Val Acc: 50.95% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9188 | Val Loss: 0.9314 | Train Acc: 52.84% | Val Acc: 51.60% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 38
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 6.26 seconds
INFO:__main__:Epochs Trained: 38
INFO:__main__:Final Train Accuracy: 53.78%
INFO:__main__:Final Val Accuracy: 51.15%
INFO:__main__:Validation F1-Macro: 0.4832
INFO:__main__:Best Val Accuracy: 51.60%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.83      0.69       666
      neutral       0.46      0.48      0.47       666
contradiction       0.42      0.23      0.29       666

     accuracy                           0.51      1998
    macro avg       0.49      0.51      0.48      1998
 weighted avg       0.49      0.51      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0120 | Val Loss: 0.9348 | Train Acc: 48.64% | Val Acc: 50.25% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9222 | Val Loss: 0.9151 | Train Acc: 51.95% | Val Acc: 52.60% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9197 | Val Loss: 0.9158 | Train Acc: 52.36% | Val Acc: 52.15% | LR: 0.000500
INFO:__main__:Early stopping triggered at epoch 24
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 3.94 seconds
INFO:__main__:Epochs Trained: 24
INFO:__main__:Final Train Accuracy: 53.20%
INFO:__main__:Final Val Accuracy: 52.20%
INFO:__main__:Validation F1-Macro: 0.4967
INFO:__main__:Best Val Accuracy: 52.85%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.81      0.69       666
      neutral       0.48      0.52      0.49       666
contradiction       0.43      0.24      0.31       666

     accuracy                           0.52      1998
    macro avg       0.50      0.52      0.50      1998
 weighted avg       0.50      0.52      0.50      1998

INFO:__main__:Results: Accuracy = 51.97% ± 0.57%
INFO:__main__:         F1-Macro = 0.4953 ± 0.0083
INFO:__main__:         Score = 51.41
INFO:__main__:         Time = 24.5s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 38/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.001, 'batch_size': 256, 'dropout_rate': 0.5, 'weight_decay': 0.001}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3066 | Val Loss: 1.0453 | Train Acc: 35.59% | Val Acc: 44.29% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9770 | Val Loss: 0.9323 | Train Acc: 50.26% | Val Acc: 52.95% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9482 | Val Loss: 0.9280 | Train Acc: 50.49% | Val Acc: 52.55% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9455 | Val Loss: 0.9233 | Train Acc: 51.28% | Val Acc: 51.95% | LR: 0.001000
INFO:__main__:Epoch  40/100 | Train Loss: 0.9375 | Val Loss: 0.9241 | Train Acc: 51.23% | Val Acc: 52.15% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 43
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 7.04 seconds
INFO:__main__:Epochs Trained: 43
INFO:__main__:Final Train Accuracy: 52.18%
INFO:__main__:Final Val Accuracy: 52.00%
INFO:__main__:Validation F1-Macro: 0.4796
INFO:__main__:Best Val Accuracy: 52.95%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.83      0.68       666
      neutral       0.49      0.57      0.53       666
contradiction       0.38      0.16      0.23       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.48      1998
 weighted avg       0.49      0.52      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3203 | Val Loss: 1.0149 | Train Acc: 35.70% | Val Acc: 45.95% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9771 | Val Loss: 0.9307 | Train Acc: 49.42% | Val Acc: 50.25% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9514 | Val Loss: 0.9226 | Train Acc: 51.56% | Val Acc: 52.45% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9407 | Val Loss: 0.9206 | Train Acc: 51.34% | Val Acc: 52.15% | LR: 0.001000
INFO:__main__:Epoch  40/100 | Train Loss: 0.9420 | Val Loss: 0.9216 | Train Acc: 52.53% | Val Acc: 51.75% | LR: 0.001000
INFO:__main__:Epoch  50/100 | Train Loss: 0.9392 | Val Loss: 0.9202 | Train Acc: 51.76% | Val Acc: 51.95% | LR: 0.000250
INFO:__main__:Epoch  60/100 | Train Loss: 0.9378 | Val Loss: 0.9201 | Train Acc: 51.90% | Val Acc: 52.05% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 64
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 10.10 seconds
INFO:__main__:Epochs Trained: 64
INFO:__main__:Final Train Accuracy: 52.28%
INFO:__main__:Final Val Accuracy: 52.20%
INFO:__main__:Validation F1-Macro: 0.4815
INFO:__main__:Best Val Accuracy: 52.95%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.82      0.69       666
      neutral       0.49      0.59      0.53       666
contradiction       0.38      0.16      0.22       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.48      1998
 weighted avg       0.49      0.52      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2664 | Val Loss: 1.0067 | Train Acc: 36.45% | Val Acc: 52.80% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9773 | Val Loss: 0.9146 | Train Acc: 49.52% | Val Acc: 51.80% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9532 | Val Loss: 0.9063 | Train Acc: 50.35% | Val Acc: 52.90% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9485 | Val Loss: 0.9030 | Train Acc: 51.20% | Val Acc: 53.25% | LR: 0.001000
INFO:__main__:Epoch  40/100 | Train Loss: 0.9450 | Val Loss: 0.9032 | Train Acc: 51.48% | Val Acc: 52.60% | LR: 0.000500
INFO:__main__:Early stopping triggered at epoch 48
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 7.78 seconds
INFO:__main__:Epochs Trained: 48
INFO:__main__:Final Train Accuracy: 52.24%
INFO:__main__:Final Val Accuracy: 53.15%
INFO:__main__:Validation F1-Macro: 0.4791
INFO:__main__:Best Val Accuracy: 53.45%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.84      0.70       666
      neutral       0.48      0.63      0.55       666
contradiction       0.45      0.13      0.20       666

     accuracy                           0.53      1998
    macro avg       0.51      0.53      0.48      1998
 weighted avg       0.51      0.53      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2628 | Val Loss: 1.0153 | Train Acc: 35.72% | Val Acc: 50.55% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9689 | Val Loss: 0.9375 | Train Acc: 50.50% | Val Acc: 51.20% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9430 | Val Loss: 0.9330 | Train Acc: 51.05% | Val Acc: 50.85% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9415 | Val Loss: 0.9325 | Train Acc: 52.00% | Val Acc: 50.30% | LR: 0.000500
INFO:__main__:Early stopping triggered at epoch 36
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 5.86 seconds
INFO:__main__:Epochs Trained: 36
INFO:__main__:Final Train Accuracy: 52.54%
INFO:__main__:Final Val Accuracy: 50.25%
INFO:__main__:Validation F1-Macro: 0.4651
INFO:__main__:Best Val Accuracy: 51.40%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.57      0.84      0.68       666
      neutral       0.46      0.50      0.48       666
contradiction       0.37      0.17      0.23       666

     accuracy                           0.50      1998
    macro avg       0.47      0.50      0.47      1998
 weighted avg       0.47      0.50      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3715 | Val Loss: 1.0619 | Train Acc: 34.12% | Val Acc: 45.85% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9942 | Val Loss: 0.9331 | Train Acc: 49.07% | Val Acc: 51.55% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9507 | Val Loss: 0.9223 | Train Acc: 51.20% | Val Acc: 52.50% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9413 | Val Loss: 0.9205 | Train Acc: 50.53% | Val Acc: 51.95% | LR: 0.001000
INFO:__main__:Epoch  40/100 | Train Loss: 0.9394 | Val Loss: 0.9201 | Train Acc: 51.83% | Val Acc: 52.50% | LR: 0.000500
INFO:__main__:Epoch  50/100 | Train Loss: 0.9375 | Val Loss: 0.9204 | Train Acc: 52.60% | Val Acc: 52.20% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 53
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 8.66 seconds
INFO:__main__:Epochs Trained: 53
INFO:__main__:Final Train Accuracy: 51.89%
INFO:__main__:Final Val Accuracy: 52.35%
INFO:__main__:Validation F1-Macro: 0.4970
INFO:__main__:Best Val Accuracy: 52.70%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.83      0.69       666
      neutral       0.50      0.50      0.50       666
contradiction       0.41      0.24      0.30       666

     accuracy                           0.52      1998
    macro avg       0.50      0.52      0.50      1998
 weighted avg       0.50      0.52      0.50      1998

INFO:__main__:Results: Accuracy = 51.99% ± 0.95%
INFO:__main__:         F1-Macro = 0.4805 ± 0.0101
INFO:__main__:         Score = 51.04
INFO:__main__:         Time = 39.5s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 39/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.005, 'batch_size': 64, 'dropout_rate': 0.5, 'weight_decay': 0.0001}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0512 | Val Loss: 0.9343 | Train Acc: 46.87% | Val Acc: 50.55% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9416 | Val Loss: 0.9263 | Train Acc: 50.84% | Val Acc: 50.55% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9345 | Val Loss: 0.9197 | Train Acc: 50.94% | Val Acc: 52.85% | LR: 0.002500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9344 | Val Loss: 0.9204 | Train Acc: 52.34% | Val Acc: 52.60% | LR: 0.001250
INFO:__main__:Early stopping triggered at epoch 38
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 17.64 seconds
INFO:__main__:Epochs Trained: 38
INFO:__main__:Final Train Accuracy: 52.19%
INFO:__main__:Final Val Accuracy: 52.35%
INFO:__main__:Validation F1-Macro: 0.4804
INFO:__main__:Best Val Accuracy: 52.90%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.81      0.68       666
      neutral       0.49      0.61      0.54       666
contradiction       0.39      0.15      0.21       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.48      1998
 weighted avg       0.49      0.52      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0435 | Val Loss: 0.9327 | Train Acc: 47.10% | Val Acc: 51.45% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9424 | Val Loss: 0.9246 | Train Acc: 50.84% | Val Acc: 50.85% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9383 | Val Loss: 0.9227 | Train Acc: 51.30% | Val Acc: 52.10% | LR: 0.005000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9366 | Val Loss: 0.9205 | Train Acc: 51.61% | Val Acc: 51.60% | LR: 0.005000
INFO:__main__:Epoch  40/100 | Train Loss: 0.9342 | Val Loss: 0.9227 | Train Acc: 51.08% | Val Acc: 51.85% | LR: 0.002500
INFO:__main__:Epoch  50/100 | Train Loss: 0.9352 | Val Loss: 0.9201 | Train Acc: 52.11% | Val Acc: 51.70% | LR: 0.000625
INFO:__main__:Early stopping triggered at epoch 50
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 22.98 seconds
INFO:__main__:Epochs Trained: 50
INFO:__main__:Final Train Accuracy: 52.24%
INFO:__main__:Final Val Accuracy: 51.70%
INFO:__main__:Validation F1-Macro: 0.4665
INFO:__main__:Best Val Accuracy: 52.45%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.57      0.84      0.68       666
      neutral       0.49      0.58      0.53       666
contradiction       0.37      0.12      0.18       666

     accuracy                           0.52      1998
    macro avg       0.48      0.52      0.47      1998
 weighted avg       0.48      0.52      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0676 | Val Loss: 0.9107 | Train Acc: 45.45% | Val Acc: 53.00% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9403 | Val Loss: 0.9024 | Train Acc: 51.13% | Val Acc: 51.25% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9413 | Val Loss: 0.8997 | Train Acc: 50.59% | Val Acc: 52.75% | LR: 0.002500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9390 | Val Loss: 0.9001 | Train Acc: 51.61% | Val Acc: 53.25% | LR: 0.001250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9360 | Val Loss: 0.8986 | Train Acc: 51.11% | Val Acc: 53.65% | LR: 0.000625
INFO:__main__:Epoch  50/100 | Train Loss: 0.9347 | Val Loss: 0.9008 | Train Acc: 51.49% | Val Acc: 53.25% | LR: 0.000313
INFO:__main__:Early stopping triggered at epoch 55
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 25.26 seconds
INFO:__main__:Epochs Trained: 55
INFO:__main__:Final Train Accuracy: 51.84%
INFO:__main__:Final Val Accuracy: 53.10%
INFO:__main__:Validation F1-Macro: 0.4771
INFO:__main__:Best Val Accuracy: 54.00%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.84      0.70       666
      neutral       0.49      0.63      0.55       666
contradiction       0.42      0.12      0.18       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.48      1998
 weighted avg       0.50      0.53      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0410 | Val Loss: 0.9343 | Train Acc: 46.87% | Val Acc: 50.65% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9404 | Val Loss: 0.9293 | Train Acc: 51.34% | Val Acc: 51.45% | LR: 0.002500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9374 | Val Loss: 0.9296 | Train Acc: 51.64% | Val Acc: 50.20% | LR: 0.001250
INFO:__main__:Early stopping triggered at epoch 27
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 12.56 seconds
INFO:__main__:Epochs Trained: 27
INFO:__main__:Final Train Accuracy: 52.79%
INFO:__main__:Final Val Accuracy: 50.45%
INFO:__main__:Validation F1-Macro: 0.4648
INFO:__main__:Best Val Accuracy: 51.60%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.57      0.84      0.68       666
      neutral       0.46      0.51      0.49       666
contradiction       0.38      0.16      0.23       666

     accuracy                           0.50      1998
    macro avg       0.47      0.50      0.46      1998
 weighted avg       0.47      0.50      0.46      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0367 | Val Loss: 0.9299 | Train Acc: 47.03% | Val Acc: 52.10% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9414 | Val Loss: 0.9233 | Train Acc: 50.61% | Val Acc: 52.45% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9409 | Val Loss: 0.9221 | Train Acc: 51.23% | Val Acc: 51.65% | LR: 0.005000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9352 | Val Loss: 0.9216 | Train Acc: 51.38% | Val Acc: 52.75% | LR: 0.002500
INFO:__main__:Epoch  40/100 | Train Loss: 0.9348 | Val Loss: 0.9226 | Train Acc: 51.13% | Val Acc: 53.15% | LR: 0.001250
INFO:__main__:Epoch  50/100 | Train Loss: 0.9312 | Val Loss: 0.9203 | Train Acc: 52.33% | Val Acc: 53.15% | LR: 0.000625
INFO:__main__:Epoch  60/100 | Train Loss: 0.9362 | Val Loss: 0.9211 | Train Acc: 51.36% | Val Acc: 52.85% | LR: 0.000625
INFO:__main__:Epoch  70/100 | Train Loss: 0.9344 | Val Loss: 0.9209 | Train Acc: 51.49% | Val Acc: 53.05% | LR: 0.000313
INFO:__main__:Epoch  80/100 | Train Loss: 0.9275 | Val Loss: 0.9201 | Train Acc: 51.73% | Val Acc: 53.00% | LR: 0.000078
INFO:__main__:Early stopping triggered at epoch 80
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 36.74 seconds
INFO:__main__:Epochs Trained: 80
INFO:__main__:Final Train Accuracy: 52.18%
INFO:__main__:Final Val Accuracy: 53.00%
INFO:__main__:Validation F1-Macro: 0.4993
INFO:__main__:Best Val Accuracy: 53.20%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.82      0.69       666
      neutral       0.51      0.56      0.53       666
contradiction       0.40      0.21      0.27       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.50      1998
 weighted avg       0.50      0.53      0.50      1998

INFO:__main__:Results: Accuracy = 52.12% ± 0.98%
INFO:__main__:         F1-Macro = 0.4776 ± 0.0124
INFO:__main__:         Score = 51.15
INFO:__main__:         Time = 115.2s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 40/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.0005, 'batch_size': 128, 'dropout_rate': 0.5, 'weight_decay': 0.001}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3608 | Val Loss: 1.0498 | Train Acc: 35.37% | Val Acc: 44.54% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9785 | Val Loss: 0.9365 | Train Acc: 49.76% | Val Acc: 52.40% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9584 | Val Loss: 0.9270 | Train Acc: 51.39% | Val Acc: 52.15% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9490 | Val Loss: 0.9235 | Train Acc: 51.31% | Val Acc: 51.45% | LR: 0.000250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9492 | Val Loss: 0.9238 | Train Acc: 51.49% | Val Acc: 52.05% | LR: 0.000125
INFO:__main__:Epoch  50/100 | Train Loss: 0.9459 | Val Loss: 0.9228 | Train Acc: 51.36% | Val Acc: 52.05% | LR: 0.000031
INFO:__main__:Epoch  60/100 | Train Loss: 0.9432 | Val Loss: 0.9243 | Train Acc: 50.76% | Val Acc: 52.00% | LR: 0.000016
INFO:__main__:Early stopping triggered at epoch 66
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 17.14 seconds
INFO:__main__:Epochs Trained: 66
INFO:__main__:Final Train Accuracy: 52.57%
INFO:__main__:Final Val Accuracy: 52.20%
INFO:__main__:Validation F1-Macro: 0.4737
INFO:__main__:Best Val Accuracy: 52.80%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.82      0.68       666
      neutral       0.49      0.62      0.55       666
contradiction       0.39      0.13      0.19       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.47      1998
 weighted avg       0.49      0.52      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2040 | Val Loss: 1.0562 | Train Acc: 34.96% | Val Acc: 47.95% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9861 | Val Loss: 0.9383 | Train Acc: 49.47% | Val Acc: 52.65% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9486 | Val Loss: 0.9263 | Train Acc: 50.50% | Val Acc: 51.90% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9400 | Val Loss: 0.9254 | Train Acc: 51.65% | Val Acc: 51.90% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 37
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 9.67 seconds
INFO:__main__:Epochs Trained: 37
INFO:__main__:Final Train Accuracy: 52.05%
INFO:__main__:Final Val Accuracy: 52.00%
INFO:__main__:Validation F1-Macro: 0.4437
INFO:__main__:Best Val Accuracy: 53.20%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.82      0.68       666
      neutral       0.46      0.69      0.56       666
contradiction       0.41      0.05      0.09       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.44      1998
 weighted avg       0.49      0.52      0.44      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2942 | Val Loss: 0.9884 | Train Acc: 37.42% | Val Acc: 51.05% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9873 | Val Loss: 0.9203 | Train Acc: 48.31% | Val Acc: 53.65% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9605 | Val Loss: 0.9069 | Train Acc: 49.86% | Val Acc: 53.05% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9511 | Val Loss: 0.9044 | Train Acc: 50.85% | Val Acc: 52.80% | LR: 0.000500
INFO:__main__:Epoch  40/100 | Train Loss: 0.9450 | Val Loss: 0.9042 | Train Acc: 51.13% | Val Acc: 52.85% | LR: 0.000500
INFO:__main__:Epoch  50/100 | Train Loss: 0.9420 | Val Loss: 0.9027 | Train Acc: 50.95% | Val Acc: 53.20% | LR: 0.000125
INFO:__main__:Epoch  60/100 | Train Loss: 0.9417 | Val Loss: 0.9027 | Train Acc: 50.84% | Val Acc: 53.40% | LR: 0.000063
INFO:__main__:Epoch  70/100 | Train Loss: 0.9455 | Val Loss: 0.9046 | Train Acc: 51.36% | Val Acc: 53.15% | LR: 0.000016
INFO:__main__:Early stopping triggered at epoch 73
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 18.92 seconds
INFO:__main__:Epochs Trained: 73
INFO:__main__:Final Train Accuracy: 51.93%
INFO:__main__:Final Val Accuracy: 53.40%
INFO:__main__:Validation F1-Macro: 0.4574
INFO:__main__:Best Val Accuracy: 54.10%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.84      0.70       666
      neutral       0.48      0.70      0.57       666
contradiction       0.43      0.06      0.10       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.46      1998
 weighted avg       0.50      0.53      0.46      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2440 | Val Loss: 0.9940 | Train Acc: 36.70% | Val Acc: 49.15% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9663 | Val Loss: 0.9353 | Train Acc: 50.50% | Val Acc: 50.35% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9456 | Val Loss: 0.9325 | Train Acc: 51.35% | Val Acc: 50.35% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9430 | Val Loss: 0.9315 | Train Acc: 51.08% | Val Acc: 50.65% | LR: 0.000250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9422 | Val Loss: 0.9318 | Train Acc: 52.64% | Val Acc: 50.55% | LR: 0.000125
INFO:__main__:Epoch  50/100 | Train Loss: 0.9369 | Val Loss: 0.9316 | Train Acc: 51.79% | Val Acc: 50.55% | LR: 0.000063
INFO:__main__:Epoch  60/100 | Train Loss: 0.9381 | Val Loss: 0.9311 | Train Acc: 51.65% | Val Acc: 50.65% | LR: 0.000016
INFO:__main__:Early stopping triggered at epoch 62
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 15.93 seconds
INFO:__main__:Epochs Trained: 62
INFO:__main__:Final Train Accuracy: 52.38%
INFO:__main__:Final Val Accuracy: 50.70%
INFO:__main__:Validation F1-Macro: 0.4455
INFO:__main__:Best Val Accuracy: 51.65%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.57      0.84      0.68       666
      neutral       0.46      0.60      0.52       666
contradiction       0.37      0.08      0.14       666

     accuracy                           0.51      1998
    macro avg       0.47      0.51      0.45      1998
 weighted avg       0.47      0.51      0.45      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.2546 | Val Loss: 1.0506 | Train Acc: 34.77% | Val Acc: 43.94% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9756 | Val Loss: 0.9273 | Train Acc: 49.40% | Val Acc: 52.20% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9463 | Val Loss: 0.9209 | Train Acc: 51.49% | Val Acc: 50.80% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9422 | Val Loss: 0.9199 | Train Acc: 51.08% | Val Acc: 52.40% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 39
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 10.08 seconds
INFO:__main__:Epochs Trained: 39
INFO:__main__:Final Train Accuracy: 52.18%
INFO:__main__:Final Val Accuracy: 53.05%
INFO:__main__:Validation F1-Macro: 0.4979
INFO:__main__:Best Val Accuracy: 53.10%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.83      0.69       666
      neutral       0.50      0.55      0.52       666
contradiction       0.43      0.21      0.28       666

     accuracy                           0.53      1998
    macro avg       0.51      0.53      0.50      1998
 weighted avg       0.51      0.53      0.50      1998

INFO:__main__:Results: Accuracy = 52.27% ± 0.94%
INFO:__main__:         F1-Macro = 0.4636 ± 0.0202
INFO:__main__:         Score = 51.33
INFO:__main__:         Time = 71.8s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 41/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.001, 'batch_size': 64, 'dropout_rate': 0.1, 'weight_decay': 0.0001}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0292 | Val Loss: 0.9343 | Train Acc: 47.67% | Val Acc: 50.95% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9249 | Val Loss: 0.9221 | Train Acc: 52.13% | Val Acc: 50.95% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9192 | Val Loss: 0.9227 | Train Acc: 52.77% | Val Acc: 51.25% | LR: 0.000500
INFO:__main__:Early stopping triggered at epoch 24
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 11.23 seconds
INFO:__main__:Epochs Trained: 24
INFO:__main__:Final Train Accuracy: 53.42%
INFO:__main__:Final Val Accuracy: 50.95%
INFO:__main__:Validation F1-Macro: 0.4909
INFO:__main__:Best Val Accuracy: 52.45%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.79      0.68       666
      neutral       0.45      0.47      0.46       666
contradiction       0.42      0.28      0.33       666

     accuracy                           0.51      1998
    macro avg       0.49      0.51      0.49      1998
 weighted avg       0.49      0.51      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0011 | Val Loss: 0.9277 | Train Acc: 48.66% | Val Acc: 51.40% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9228 | Val Loss: 0.9198 | Train Acc: 52.24% | Val Acc: 52.65% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9223 | Val Loss: 0.9209 | Train Acc: 52.18% | Val Acc: 51.35% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 29
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 13.53 seconds
INFO:__main__:Epochs Trained: 29
INFO:__main__:Final Train Accuracy: 52.79%
INFO:__main__:Final Val Accuracy: 51.55%
INFO:__main__:Validation F1-Macro: 0.4942
INFO:__main__:Best Val Accuracy: 52.70%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.81      0.68       666
      neutral       0.47      0.47      0.47       666
contradiction       0.42      0.27      0.33       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.49      1998
 weighted avg       0.49      0.52      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9905 | Val Loss: 0.9077 | Train Acc: 48.80% | Val Acc: 51.65% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9292 | Val Loss: 0.8976 | Train Acc: 51.80% | Val Acc: 52.65% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9276 | Val Loss: 0.8988 | Train Acc: 51.45% | Val Acc: 52.55% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9217 | Val Loss: 0.8982 | Train Acc: 52.73% | Val Acc: 52.75% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 33
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 15.12 seconds
INFO:__main__:Epochs Trained: 33
INFO:__main__:Final Train Accuracy: 53.27%
INFO:__main__:Final Val Accuracy: 53.05%
INFO:__main__:Validation F1-Macro: 0.5099
INFO:__main__:Best Val Accuracy: 53.45%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.84      0.70       666
      neutral       0.49      0.45      0.47       666
contradiction       0.43      0.30      0.35       666

     accuracy                           0.53      1998
    macro avg       0.51      0.53      0.51      1998
 weighted avg       0.51      0.53      0.51      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0091 | Val Loss: 0.9359 | Train Acc: 48.70% | Val Acc: 50.50% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9208 | Val Loss: 0.9290 | Train Acc: 52.50% | Val Acc: 51.00% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9187 | Val Loss: 0.9280 | Train Acc: 51.90% | Val Acc: 50.50% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9169 | Val Loss: 0.9288 | Train Acc: 52.59% | Val Acc: 51.30% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 33
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 15.37 seconds
INFO:__main__:Epochs Trained: 33
INFO:__main__:Final Train Accuracy: 53.19%
INFO:__main__:Final Val Accuracy: 51.20%
INFO:__main__:Validation F1-Macro: 0.4785
INFO:__main__:Best Val Accuracy: 51.75%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.82      0.69       666
      neutral       0.46      0.52      0.49       666
contradiction       0.41      0.19      0.26       666

     accuracy                           0.51      1998
    macro avg       0.49      0.51      0.48      1998
 weighted avg       0.49      0.51      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0123 | Val Loss: 0.9302 | Train Acc: 48.94% | Val Acc: 51.45% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9279 | Val Loss: 0.9185 | Train Acc: 52.25% | Val Acc: 51.75% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9188 | Val Loss: 0.9183 | Train Acc: 52.39% | Val Acc: 51.55% | LR: 0.000250
INFO:__main__:Epoch  30/100 | Train Loss: 0.9170 | Val Loss: 0.9187 | Train Acc: 53.09% | Val Acc: 51.25% | LR: 0.000063
INFO:__main__:Early stopping triggered at epoch 33
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 15.55 seconds
INFO:__main__:Epochs Trained: 33
INFO:__main__:Final Train Accuracy: 53.53%
INFO:__main__:Final Val Accuracy: 50.95%
INFO:__main__:Validation F1-Macro: 0.4900
INFO:__main__:Best Val Accuracy: 52.75%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.81      0.68       666
      neutral       0.47      0.43      0.45       666
contradiction       0.40      0.29      0.34       666

     accuracy                           0.51      1998
    macro avg       0.49      0.51      0.49      1998
 weighted avg       0.49      0.51      0.49      1998

INFO:__main__:Results: Accuracy = 51.54% ± 0.79%
INFO:__main__:         F1-Macro = 0.4927 ± 0.0101
INFO:__main__:         Score = 50.75
INFO:__main__:         Time = 70.8s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 42/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.005, 'batch_size': 64, 'dropout_rate': 0.3, 'weight_decay': 0.001}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9967 | Val Loss: 0.9311 | Train Acc: 49.37% | Val Acc: 52.15% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9348 | Val Loss: 0.9287 | Train Acc: 51.56% | Val Acc: 50.85% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9306 | Val Loss: 0.9254 | Train Acc: 51.54% | Val Acc: 52.15% | LR: 0.001250
INFO:__main__:Early stopping triggered at epoch 23
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 10.86 seconds
INFO:__main__:Epochs Trained: 23
INFO:__main__:Final Train Accuracy: 52.10%
INFO:__main__:Final Val Accuracy: 52.30%
INFO:__main__:Validation F1-Macro: 0.4913
INFO:__main__:Best Val Accuracy: 52.55%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.83      0.69       666
      neutral       0.50      0.53      0.51       666
contradiction       0.39      0.21      0.27       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.49      1998
 weighted avg       0.49      0.52      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9757 | Val Loss: 0.9289 | Train Acc: 49.70% | Val Acc: 52.05% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9283 | Val Loss: 0.9269 | Train Acc: 51.88% | Val Acc: 50.60% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9296 | Val Loss: 0.9252 | Train Acc: 51.09% | Val Acc: 52.05% | LR: 0.002500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9314 | Val Loss: 0.9224 | Train Acc: 50.94% | Val Acc: 52.10% | LR: 0.001250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9274 | Val Loss: 0.9214 | Train Acc: 52.41% | Val Acc: 51.85% | LR: 0.000625
INFO:__main__:Epoch  50/100 | Train Loss: 0.9299 | Val Loss: 0.9211 | Train Acc: 51.96% | Val Acc: 51.95% | LR: 0.000313
INFO:__main__:Epoch  60/100 | Train Loss: 0.9246 | Val Loss: 0.9212 | Train Acc: 51.29% | Val Acc: 52.10% | LR: 0.000156
INFO:__main__:Epoch  70/100 | Train Loss: 0.9292 | Val Loss: 0.9209 | Train Acc: 52.08% | Val Acc: 51.90% | LR: 0.000078
INFO:__main__:Epoch  80/100 | Train Loss: 0.9285 | Val Loss: 0.9219 | Train Acc: 52.15% | Val Acc: 52.05% | LR: 0.000020
INFO:__main__:Early stopping triggered at epoch 80
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 36.75 seconds
INFO:__main__:Epochs Trained: 80
INFO:__main__:Final Train Accuracy: 52.20%
INFO:__main__:Final Val Accuracy: 52.05%
INFO:__main__:Validation F1-Macro: 0.4860
INFO:__main__:Best Val Accuracy: 52.60%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.80      0.69       666
      neutral       0.49      0.59      0.53       666
contradiction       0.37      0.17      0.24       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.49      1998
 weighted avg       0.49      0.52      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9943 | Val Loss: 0.9098 | Train Acc: 49.37% | Val Acc: 53.30% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9383 | Val Loss: 0.8994 | Train Acc: 50.59% | Val Acc: 53.00% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9361 | Val Loss: 0.9042 | Train Acc: 51.71% | Val Acc: 52.60% | LR: 0.002500
INFO:__main__:Early stopping triggered at epoch 25
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 11.72 seconds
INFO:__main__:Epochs Trained: 25
INFO:__main__:Final Train Accuracy: 51.84%
INFO:__main__:Final Val Accuracy: 52.90%
INFO:__main__:Validation F1-Macro: 0.4443
INFO:__main__:Best Val Accuracy: 53.60%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.85      0.70       666
      neutral       0.48      0.70      0.57       666
contradiction       0.40      0.04      0.07       666

     accuracy                           0.53      1998
    macro avg       0.49      0.53      0.44      1998
 weighted avg       0.49      0.53      0.44      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9903 | Val Loss: 0.9380 | Train Acc: 49.61% | Val Acc: 51.15% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9279 | Val Loss: 0.9309 | Train Acc: 51.90% | Val Acc: 51.55% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9285 | Val Loss: 0.9294 | Train Acc: 51.30% | Val Acc: 50.50% | LR: 0.002500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9313 | Val Loss: 0.9380 | Train Acc: 52.13% | Val Acc: 50.25% | LR: 0.002500
INFO:__main__:Epoch  40/100 | Train Loss: 0.9257 | Val Loss: 0.9285 | Train Acc: 51.94% | Val Acc: 50.80% | LR: 0.000625
INFO:__main__:Early stopping triggered at epoch 42
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 19.57 seconds
INFO:__main__:Epochs Trained: 42
INFO:__main__:Final Train Accuracy: 52.60%
INFO:__main__:Final Val Accuracy: 51.10%
INFO:__main__:Validation F1-Macro: 0.4807
INFO:__main__:Best Val Accuracy: 51.80%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.83      0.68       666
      neutral       0.47      0.48      0.48       666
contradiction       0.40      0.21      0.28       666

     accuracy                           0.51      1998
    macro avg       0.48      0.51      0.48      1998
 weighted avg       0.48      0.51      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9865 | Val Loss: 0.9244 | Train Acc: 49.27% | Val Acc: 51.95% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9346 | Val Loss: 0.9219 | Train Acc: 51.03% | Val Acc: 52.90% | LR: 0.002500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9309 | Val Loss: 0.9220 | Train Acc: 51.53% | Val Acc: 52.35% | LR: 0.001250
INFO:__main__:Epoch  30/100 | Train Loss: 0.9259 | Val Loss: 0.9213 | Train Acc: 52.25% | Val Acc: 52.70% | LR: 0.000625
INFO:__main__:Early stopping triggered at epoch 39
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 18.19 seconds
INFO:__main__:Epochs Trained: 39
INFO:__main__:Final Train Accuracy: 52.16%
INFO:__main__:Final Val Accuracy: 52.60%
INFO:__main__:Validation F1-Macro: 0.4930
INFO:__main__:Best Val Accuracy: 53.25%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.83      0.69       666
      neutral       0.50      0.55      0.52       666
contradiction       0.39      0.20      0.26       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.49      1998
 weighted avg       0.50      0.53      0.49      1998

INFO:__main__:NEW BEST RESULT!
INFO:__main__:Results: Accuracy = 52.19% ± 0.62%
INFO:__main__:         F1-Macro = 0.4790 ± 0.0179
INFO:__main__:         Score = 51.58
INFO:__main__:         Time = 97.1s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 43/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 1e-05, 'batch_size': 128, 'dropout_rate': 0.5, 'weight_decay': 0.005}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.5566 | Val Loss: 1.1225 | Train Acc: 32.76% | Val Acc: 27.58% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.4742 | Val Loss: 1.0990 | Train Acc: 32.80% | Val Acc: 33.43% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.4083 | Val Loss: 1.0839 | Train Acc: 33.55% | Val Acc: 39.09% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.3184 | Val Loss: 1.0694 | Train Acc: 35.00% | Val Acc: 43.44% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.2735 | Val Loss: 1.0591 | Train Acc: 36.44% | Val Acc: 44.14% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.2159 | Val Loss: 1.0536 | Train Acc: 37.15% | Val Acc: 42.79% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.2175 | Val Loss: 1.0483 | Train Acc: 38.43% | Val Acc: 42.64% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 1.1817 | Val Loss: 1.0425 | Train Acc: 38.41% | Val Acc: 43.59% | LR: 0.000010
INFO:__main__:Epoch  80/100 | Train Loss: 1.1518 | Val Loss: 1.0372 | Train Acc: 39.56% | Val Acc: 43.29% | LR: 0.000010
INFO:__main__:Epoch  90/100 | Train Loss: 1.1488 | Val Loss: 1.0313 | Train Acc: 39.69% | Val Acc: 44.74% | LR: 0.000010
INFO:__main__:Epoch 100/100 | Train Loss: 1.1320 | Val Loss: 1.0312 | Train Acc: 39.90% | Val Acc: 43.54% | LR: 0.000003
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 25.98 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 44.72%
INFO:__main__:Final Val Accuracy: 43.54%
INFO:__main__:Validation F1-Macro: 0.3363
INFO:__main__:Best Val Accuracy: 46.70%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.42      0.96      0.58       666
      neutral       0.49      0.34      0.40       666
contradiction       0.38      0.01      0.03       666

     accuracy                           0.44      1998
    macro avg       0.43      0.44      0.34      1998
 weighted avg       0.43      0.44      0.34      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3914 | Val Loss: 1.1022 | Train Acc: 34.12% | Val Acc: 39.49% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.3694 | Val Loss: 1.0785 | Train Acc: 34.88% | Val Acc: 45.15% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.3182 | Val Loss: 1.0612 | Train Acc: 35.84% | Val Acc: 49.95% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.2738 | Val Loss: 1.0459 | Train Acc: 36.24% | Val Acc: 51.20% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.2659 | Val Loss: 1.0353 | Train Acc: 36.55% | Val Acc: 51.70% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.2358 | Val Loss: 1.0319 | Train Acc: 37.20% | Val Acc: 51.55% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.1998 | Val Loss: 1.0166 | Train Acc: 38.73% | Val Acc: 50.50% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 1.2036 | Val Loss: 1.0179 | Train Acc: 37.71% | Val Acc: 51.30% | LR: 0.000005
INFO:__main__:Epoch  80/100 | Train Loss: 1.1927 | Val Loss: 1.0135 | Train Acc: 37.95% | Val Acc: 51.00% | LR: 0.000003
INFO:__main__:Early stopping triggered at epoch 87
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 22.80 seconds
INFO:__main__:Epochs Trained: 87
INFO:__main__:Final Train Accuracy: 51.34%
INFO:__main__:Final Val Accuracy: 51.40%
INFO:__main__:Validation F1-Macro: 0.4485
INFO:__main__:Best Val Accuracy: 51.75%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.56      0.88      0.68       666
      neutral       0.47      0.58      0.52       666
contradiction       0.48      0.09      0.15       666

     accuracy                           0.51      1998
    macro avg       0.50      0.51      0.45      1998
 weighted avg       0.50      0.51      0.45      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3710 | Val Loss: 1.1081 | Train Acc: 33.31% | Val Acc: 35.84% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.3330 | Val Loss: 1.0912 | Train Acc: 33.32% | Val Acc: 41.09% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.2804 | Val Loss: 1.0742 | Train Acc: 35.27% | Val Acc: 48.00% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.2659 | Val Loss: 1.0614 | Train Acc: 36.44% | Val Acc: 50.10% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.2528 | Val Loss: 1.0500 | Train Acc: 36.80% | Val Acc: 52.20% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.2247 | Val Loss: 1.0416 | Train Acc: 36.40% | Val Acc: 52.50% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.1971 | Val Loss: 1.0331 | Train Acc: 38.16% | Val Acc: 52.40% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 1.1759 | Val Loss: 1.0324 | Train Acc: 39.34% | Val Acc: 52.35% | LR: 0.000005
INFO:__main__:Epoch  80/100 | Train Loss: 1.1739 | Val Loss: 1.0289 | Train Acc: 38.64% | Val Acc: 52.40% | LR: 0.000003
INFO:__main__:Epoch  90/100 | Train Loss: 1.1732 | Val Loss: 1.0285 | Train Acc: 39.10% | Val Acc: 52.25% | LR: 0.000001
INFO:__main__:Epoch 100/100 | Train Loss: 1.1783 | Val Loss: 1.0242 | Train Acc: 38.99% | Val Acc: 52.45% | LR: 0.000001
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 26.35 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 50.89%
INFO:__main__:Final Val Accuracy: 52.45%
INFO:__main__:Validation F1-Macro: 0.5008
INFO:__main__:Best Val Accuracy: 53.45%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.82      0.70       666
      neutral       0.48      0.26      0.34       666
contradiction       0.45      0.49      0.47       666

     accuracy                           0.52      1998
    macro avg       0.51      0.52      0.50      1998
 weighted avg       0.51      0.52      0.50      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.4951 | Val Loss: 1.1243 | Train Acc: 36.72% | Val Acc: 32.78% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.4310 | Val Loss: 1.1050 | Train Acc: 37.55% | Val Acc: 34.33% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.3765 | Val Loss: 1.0737 | Train Acc: 39.43% | Val Acc: 37.89% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.3068 | Val Loss: 1.0551 | Train Acc: 39.91% | Val Acc: 41.19% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.2499 | Val Loss: 1.0442 | Train Acc: 40.90% | Val Acc: 42.94% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.2372 | Val Loss: 1.0326 | Train Acc: 42.04% | Val Acc: 43.69% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.2129 | Val Loss: 1.0257 | Train Acc: 41.15% | Val Acc: 43.69% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 1.1785 | Val Loss: 1.0234 | Train Acc: 41.98% | Val Acc: 43.99% | LR: 0.000010
INFO:__main__:Epoch  80/100 | Train Loss: 1.1583 | Val Loss: 1.0192 | Train Acc: 42.89% | Val Acc: 44.99% | LR: 0.000010
INFO:__main__:Epoch  90/100 | Train Loss: 1.1570 | Val Loss: 1.0182 | Train Acc: 42.07% | Val Acc: 43.84% | LR: 0.000005
INFO:__main__:Epoch 100/100 | Train Loss: 1.1512 | Val Loss: 1.0224 | Train Acc: 42.78% | Val Acc: 44.04% | LR: 0.000003
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 25.84 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 45.26%
INFO:__main__:Final Val Accuracy: 44.04%
INFO:__main__:Validation F1-Macro: 0.4483
INFO:__main__:Best Val Accuracy: 45.55%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.72      0.38      0.49       666
      neutral       0.45      0.48      0.47       666
contradiction       0.33      0.46      0.38       666

     accuracy                           0.44      1998
    macro avg       0.50      0.44      0.45      1998
 weighted avg       0.50      0.44      0.45      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.5320 | Val Loss: 1.1339 | Train Acc: 32.56% | Val Acc: 33.08% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.4978 | Val Loss: 1.1111 | Train Acc: 33.62% | Val Acc: 36.69% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.4477 | Val Loss: 1.0898 | Train Acc: 34.47% | Val Acc: 43.74% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.4137 | Val Loss: 1.0761 | Train Acc: 34.52% | Val Acc: 49.30% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.3704 | Val Loss: 1.0614 | Train Acc: 35.99% | Val Acc: 50.60% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.3273 | Val Loss: 1.0503 | Train Acc: 35.71% | Val Acc: 50.90% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.3097 | Val Loss: 1.0450 | Train Acc: 36.26% | Val Acc: 51.80% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 1.2629 | Val Loss: 1.0328 | Train Acc: 38.01% | Val Acc: 51.40% | LR: 0.000010
INFO:__main__:Epoch  80/100 | Train Loss: 1.2478 | Val Loss: 1.0339 | Train Acc: 39.06% | Val Acc: 51.55% | LR: 0.000005
INFO:__main__:Epoch  90/100 | Train Loss: 1.2516 | Val Loss: 1.0289 | Train Acc: 38.69% | Val Acc: 51.70% | LR: 0.000005
INFO:__main__:Epoch 100/100 | Train Loss: 1.2539 | Val Loss: 1.0257 | Train Acc: 38.34% | Val Acc: 51.40% | LR: 0.000003
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 25.48 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 52.26%
INFO:__main__:Final Val Accuracy: 51.40%
INFO:__main__:Validation F1-Macro: 0.4789
INFO:__main__:Best Val Accuracy: 52.55%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.78      0.68       666
      neutral       0.47      0.60      0.52       666
contradiction       0.39      0.17      0.23       666

     accuracy                           0.51      1998
    macro avg       0.49      0.51      0.48      1998
 weighted avg       0.49      0.51      0.48      1998

INFO:__main__:Results: Accuracy = 48.57% ± 3.92%
INFO:__main__:         F1-Macro = 0.4426 ± 0.0567
INFO:__main__:         Score = 44.65
INFO:__main__:         Time = 126.5s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 44/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.001, 'batch_size': 256, 'dropout_rate': 0.1, 'weight_decay': 0.005}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1145 | Val Loss: 0.9675 | Train Acc: 44.46% | Val Acc: 51.60% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9255 | Val Loss: 0.9248 | Train Acc: 51.85% | Val Acc: 51.40% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9202 | Val Loss: 0.9239 | Train Acc: 52.31% | Val Acc: 51.15% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9160 | Val Loss: 0.9257 | Train Acc: 52.28% | Val Acc: 51.80% | LR: 0.001000
INFO:__main__:Epoch  40/100 | Train Loss: 0.9147 | Val Loss: 0.9230 | Train Acc: 53.05% | Val Acc: 52.00% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 40
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 6.59 seconds
INFO:__main__:Epochs Trained: 40
INFO:__main__:Final Train Accuracy: 53.13%
INFO:__main__:Final Val Accuracy: 52.00%
INFO:__main__:Validation F1-Macro: 0.4956
INFO:__main__:Best Val Accuracy: 52.60%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.81      0.68       666
      neutral       0.46      0.50      0.48       666
contradiction       0.45      0.25      0.32       666

     accuracy                           0.52      1998
    macro avg       0.50      0.52      0.50      1998
 weighted avg       0.50      0.52      0.50      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0765 | Val Loss: 0.9682 | Train Acc: 43.76% | Val Acc: 52.45% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9286 | Val Loss: 0.9218 | Train Acc: 51.94% | Val Acc: 52.30% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9215 | Val Loss: 0.9181 | Train Acc: 51.73% | Val Acc: 53.10% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9179 | Val Loss: 0.9195 | Train Acc: 52.63% | Val Acc: 52.45% | LR: 0.000125
INFO:__main__:Epoch  40/100 | Train Loss: 0.9160 | Val Loss: 0.9181 | Train Acc: 51.83% | Val Acc: 52.35% | LR: 0.000125
INFO:__main__:Epoch  50/100 | Train Loss: 0.9180 | Val Loss: 0.9185 | Train Acc: 52.34% | Val Acc: 52.70% | LR: 0.000031
INFO:__main__:Early stopping triggered at epoch 51
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 8.33 seconds
INFO:__main__:Epochs Trained: 51
INFO:__main__:Final Train Accuracy: 52.73%
INFO:__main__:Final Val Accuracy: 52.10%
INFO:__main__:Validation F1-Macro: 0.5011
INFO:__main__:Best Val Accuracy: 53.35%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.80      0.69       666
      neutral       0.47      0.48      0.48       666
contradiction       0.43      0.28      0.34       666

     accuracy                           0.52      1998
    macro avg       0.50      0.52      0.50      1998
 weighted avg       0.50      0.52      0.50      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0596 | Val Loss: 0.9301 | Train Acc: 46.92% | Val Acc: 51.90% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9364 | Val Loss: 0.9011 | Train Acc: 51.50% | Val Acc: 53.10% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9259 | Val Loss: 0.9008 | Train Acc: 52.79% | Val Acc: 53.05% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9216 | Val Loss: 0.9015 | Train Acc: 51.95% | Val Acc: 53.40% | LR: 0.000250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9207 | Val Loss: 0.9003 | Train Acc: 52.46% | Val Acc: 53.40% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 46
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 7.68 seconds
INFO:__main__:Epochs Trained: 46
INFO:__main__:Final Train Accuracy: 52.83%
INFO:__main__:Final Val Accuracy: 53.90%
INFO:__main__:Validation F1-Macro: 0.5169
INFO:__main__:Best Val Accuracy: 54.10%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.83      0.70       666
      neutral       0.50      0.50      0.50       666
contradiction       0.46      0.29      0.35       666

     accuracy                           0.54      1998
    macro avg       0.52      0.54      0.52      1998
 weighted avg       0.52      0.54      0.52      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0938 | Val Loss: 0.9957 | Train Acc: 41.28% | Val Acc: 51.45% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9222 | Val Loss: 0.9354 | Train Acc: 51.60% | Val Acc: 50.90% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9190 | Val Loss: 0.9329 | Train Acc: 52.44% | Val Acc: 50.80% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9138 | Val Loss: 0.9310 | Train Acc: 52.36% | Val Acc: 50.80% | LR: 0.000500
INFO:__main__:Epoch  40/100 | Train Loss: 0.9165 | Val Loss: 0.9315 | Train Acc: 52.55% | Val Acc: 51.55% | LR: 0.000500
INFO:__main__:Epoch  50/100 | Train Loss: 0.9155 | Val Loss: 0.9305 | Train Acc: 52.85% | Val Acc: 51.25% | LR: 0.000250
INFO:__main__:Epoch  60/100 | Train Loss: 0.9136 | Val Loss: 0.9302 | Train Acc: 52.80% | Val Acc: 51.70% | LR: 0.000063
INFO:__main__:Early stopping triggered at epoch 60
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 9.50 seconds
INFO:__main__:Epochs Trained: 60
INFO:__main__:Final Train Accuracy: 53.22%
INFO:__main__:Final Val Accuracy: 51.70%
INFO:__main__:Validation F1-Macro: 0.4881
INFO:__main__:Best Val Accuracy: 52.00%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.84      0.68       666
      neutral       0.47      0.48      0.48       666
contradiction       0.44      0.23      0.31       666

     accuracy                           0.52      1998
    macro avg       0.50      0.52      0.49      1998
 weighted avg       0.50      0.52      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9990 | Val Loss: 0.9350 | Train Acc: 49.44% | Val Acc: 52.20% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9284 | Val Loss: 0.9193 | Train Acc: 52.20% | Val Acc: 52.95% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9231 | Val Loss: 0.9175 | Train Acc: 52.49% | Val Acc: 52.65% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9204 | Val Loss: 0.9157 | Train Acc: 51.11% | Val Acc: 52.50% | LR: 0.000500
INFO:__main__:Epoch  40/100 | Train Loss: 0.9191 | Val Loss: 0.9162 | Train Acc: 51.91% | Val Acc: 53.10% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 47
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 7.68 seconds
INFO:__main__:Epochs Trained: 47
INFO:__main__:Final Train Accuracy: 52.83%
INFO:__main__:Final Val Accuracy: 52.70%
INFO:__main__:Validation F1-Macro: 0.5047
INFO:__main__:Best Val Accuracy: 53.45%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.82      0.69       666
      neutral       0.49      0.49      0.49       666
contradiction       0.44      0.27      0.33       666

     accuracy                           0.53      1998
    macro avg       0.51      0.53      0.50      1998
 weighted avg       0.51      0.53      0.50      1998

INFO:__main__:NEW BEST RESULT!
INFO:__main__:Results: Accuracy = 52.48% ± 0.78%
INFO:__main__:         F1-Macro = 0.5013 ± 0.0096
INFO:__main__:         Score = 51.70
INFO:__main__:         Time = 39.8s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 45/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 1e-05, 'batch_size': 256, 'dropout_rate': 0.3, 'weight_decay': 0.001}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.5169 | Val Loss: 1.1377 | Train Acc: 32.34% | Val Acc: 29.18% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.4522 | Val Loss: 1.1364 | Train Acc: 32.13% | Val Acc: 33.28% | LR: 0.000005
INFO:__main__:Epoch  20/100 | Train Loss: 1.3726 | Val Loss: 1.1146 | Train Acc: 33.75% | Val Acc: 37.39% | LR: 0.000005
INFO:__main__:Epoch  30/100 | Train Loss: 1.3322 | Val Loss: 1.1009 | Train Acc: 34.21% | Val Acc: 40.89% | LR: 0.000005
INFO:__main__:Epoch  40/100 | Train Loss: 1.3023 | Val Loss: 1.0832 | Train Acc: 35.15% | Val Acc: 44.04% | LR: 0.000005
INFO:__main__:Epoch  50/100 | Train Loss: 1.2352 | Val Loss: 1.0715 | Train Acc: 36.25% | Val Acc: 46.30% | LR: 0.000005
INFO:__main__:Epoch  60/100 | Train Loss: 1.2299 | Val Loss: 1.0603 | Train Acc: 37.46% | Val Acc: 46.95% | LR: 0.000005
INFO:__main__:Epoch  70/100 | Train Loss: 1.2031 | Val Loss: 1.0517 | Train Acc: 38.36% | Val Acc: 48.95% | LR: 0.000005
INFO:__main__:Epoch  80/100 | Train Loss: 1.1868 | Val Loss: 1.0420 | Train Acc: 38.64% | Val Acc: 49.60% | LR: 0.000005
INFO:__main__:Epoch  90/100 | Train Loss: 1.1574 | Val Loss: 1.0371 | Train Acc: 39.73% | Val Acc: 49.95% | LR: 0.000005
INFO:__main__:Epoch 100/100 | Train Loss: 1.1414 | Val Loss: 1.0302 | Train Acc: 40.67% | Val Acc: 50.00% | LR: 0.000005
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 15.90 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 50.84%
INFO:__main__:Final Val Accuracy: 50.00%
INFO:__main__:Validation F1-Macro: 0.4757
INFO:__main__:Best Val Accuracy: 50.00%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.57      0.81      0.67       666
      neutral       0.48      0.26      0.34       666
contradiction       0.42      0.43      0.42       666

     accuracy                           0.50      1998
    macro avg       0.49      0.50      0.48      1998
 weighted avg       0.49      0.50      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3196 | Val Loss: 1.1111 | Train Acc: 34.63% | Val Acc: 41.29% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.2644 | Val Loss: 1.0813 | Train Acc: 36.86% | Val Acc: 44.89% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.2209 | Val Loss: 1.0442 | Train Acc: 38.54% | Val Acc: 49.45% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.1571 | Val Loss: 1.0196 | Train Acc: 40.90% | Val Acc: 50.85% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.1382 | Val Loss: 1.0070 | Train Acc: 41.35% | Val Acc: 50.90% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.1303 | Val Loss: 0.9936 | Train Acc: 42.92% | Val Acc: 50.90% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.1104 | Val Loss: 0.9822 | Train Acc: 43.88% | Val Acc: 50.60% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 1.0985 | Val Loss: 0.9748 | Train Acc: 43.57% | Val Acc: 50.25% | LR: 0.000010
INFO:__main__:Epoch  80/100 | Train Loss: 1.0672 | Val Loss: 0.9673 | Train Acc: 45.21% | Val Acc: 50.45% | LR: 0.000010
INFO:__main__:Epoch  90/100 | Train Loss: 1.0798 | Val Loss: 0.9615 | Train Acc: 44.87% | Val Acc: 50.10% | LR: 0.000010
INFO:__main__:Epoch 100/100 | Train Loss: 1.0633 | Val Loss: 0.9569 | Train Acc: 46.66% | Val Acc: 50.80% | LR: 0.000010
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 16.08 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 51.81%
INFO:__main__:Final Val Accuracy: 50.80%
INFO:__main__:Validation F1-Macro: 0.4637
INFO:__main__:Best Val Accuracy: 51.35%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.57      0.86      0.69       666
      neutral       0.46      0.52      0.48       666
contradiction       0.41      0.15      0.22       666

     accuracy                           0.51      1998
    macro avg       0.48      0.51      0.46      1998
 weighted avg       0.48      0.51      0.46      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3623 | Val Loss: 1.1304 | Train Acc: 32.16% | Val Acc: 33.23% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.3091 | Val Loss: 1.1014 | Train Acc: 33.58% | Val Acc: 38.99% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.2592 | Val Loss: 1.0749 | Train Acc: 35.04% | Val Acc: 43.19% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.2337 | Val Loss: 1.0433 | Train Acc: 36.97% | Val Acc: 46.95% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.1960 | Val Loss: 1.0229 | Train Acc: 39.13% | Val Acc: 51.80% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.1708 | Val Loss: 1.0072 | Train Acc: 40.10% | Val Acc: 52.95% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.1421 | Val Loss: 0.9885 | Train Acc: 42.07% | Val Acc: 53.15% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 1.1295 | Val Loss: 0.9818 | Train Acc: 43.89% | Val Acc: 52.95% | LR: 0.000010
INFO:__main__:Epoch  80/100 | Train Loss: 1.1068 | Val Loss: 0.9643 | Train Acc: 44.37% | Val Acc: 53.20% | LR: 0.000010
INFO:__main__:Epoch  90/100 | Train Loss: 1.0996 | Val Loss: 0.9628 | Train Acc: 45.18% | Val Acc: 53.30% | LR: 0.000010
INFO:__main__:Epoch 100/100 | Train Loss: 1.0796 | Val Loss: 0.9533 | Train Acc: 46.22% | Val Acc: 53.30% | LR: 0.000010
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 16.37 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 51.34%
INFO:__main__:Final Val Accuracy: 53.30%
INFO:__main__:Validation F1-Macro: 0.5176
INFO:__main__:Best Val Accuracy: 53.65%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.62      0.82      0.70       666
      neutral       0.48      0.41      0.44       666
contradiction       0.45      0.37      0.40       666

     accuracy                           0.53      1998
    macro avg       0.52      0.53      0.52      1998
 weighted avg       0.52      0.53      0.52      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3316 | Val Loss: 1.1146 | Train Acc: 34.05% | Val Acc: 37.79% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.2698 | Val Loss: 1.1072 | Train Acc: 35.89% | Val Acc: 40.89% | LR: 0.000005
INFO:__main__:Epoch  20/100 | Train Loss: 1.2749 | Val Loss: 1.0866 | Train Acc: 35.72% | Val Acc: 44.04% | LR: 0.000005
INFO:__main__:Epoch  30/100 | Train Loss: 1.2495 | Val Loss: 1.0742 | Train Acc: 36.80% | Val Acc: 44.59% | LR: 0.000005
INFO:__main__:Epoch  40/100 | Train Loss: 1.2300 | Val Loss: 1.0602 | Train Acc: 37.29% | Val Acc: 46.25% | LR: 0.000005
INFO:__main__:Epoch  50/100 | Train Loss: 1.2066 | Val Loss: 1.0448 | Train Acc: 39.18% | Val Acc: 47.25% | LR: 0.000005
INFO:__main__:Epoch  60/100 | Train Loss: 1.2052 | Val Loss: 1.0379 | Train Acc: 39.24% | Val Acc: 48.45% | LR: 0.000005
INFO:__main__:Epoch  70/100 | Train Loss: 1.1955 | Val Loss: 1.0281 | Train Acc: 39.48% | Val Acc: 48.55% | LR: 0.000005
INFO:__main__:Epoch  80/100 | Train Loss: 1.1631 | Val Loss: 1.0229 | Train Acc: 40.90% | Val Acc: 48.80% | LR: 0.000003
INFO:__main__:Epoch  90/100 | Train Loss: 1.1664 | Val Loss: 1.0170 | Train Acc: 41.25% | Val Acc: 49.55% | LR: 0.000003
INFO:__main__:Epoch 100/100 | Train Loss: 1.1558 | Val Loss: 1.0147 | Train Acc: 41.88% | Val Acc: 49.60% | LR: 0.000001
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 16.01 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 50.70%
INFO:__main__:Final Val Accuracy: 49.60%
INFO:__main__:Validation F1-Macro: 0.4616
INFO:__main__:Best Val Accuracy: 49.95%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.54      0.81      0.65       666
      neutral       0.44      0.48      0.46       666
contradiction       0.47      0.19      0.27       666

     accuracy                           0.50      1998
    macro avg       0.49      0.50      0.46      1998
 weighted avg       0.49      0.50      0.46      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.3484 | Val Loss: 1.0965 | Train Acc: 34.83% | Val Acc: 37.04% | LR: 0.000010
INFO:__main__:Epoch  10/100 | Train Loss: 1.2886 | Val Loss: 1.0624 | Train Acc: 36.72% | Val Acc: 43.59% | LR: 0.000010
INFO:__main__:Epoch  20/100 | Train Loss: 1.2372 | Val Loss: 1.0325 | Train Acc: 38.66% | Val Acc: 46.60% | LR: 0.000010
INFO:__main__:Epoch  30/100 | Train Loss: 1.1829 | Val Loss: 1.0161 | Train Acc: 41.90% | Val Acc: 47.15% | LR: 0.000010
INFO:__main__:Epoch  40/100 | Train Loss: 1.1653 | Val Loss: 1.0004 | Train Acc: 42.54% | Val Acc: 49.55% | LR: 0.000010
INFO:__main__:Epoch  50/100 | Train Loss: 1.1445 | Val Loss: 0.9908 | Train Acc: 43.73% | Val Acc: 49.50% | LR: 0.000010
INFO:__main__:Epoch  60/100 | Train Loss: 1.1138 | Val Loss: 0.9829 | Train Acc: 45.45% | Val Acc: 50.10% | LR: 0.000010
INFO:__main__:Epoch  70/100 | Train Loss: 1.1057 | Val Loss: 0.9757 | Train Acc: 45.51% | Val Acc: 50.55% | LR: 0.000010
INFO:__main__:Epoch  80/100 | Train Loss: 1.0867 | Val Loss: 0.9692 | Train Acc: 46.42% | Val Acc: 51.05% | LR: 0.000010
INFO:__main__:Epoch  90/100 | Train Loss: 1.0750 | Val Loss: 0.9693 | Train Acc: 47.65% | Val Acc: 50.95% | LR: 0.000010
INFO:__main__:Epoch 100/100 | Train Loss: 1.0712 | Val Loss: 0.9658 | Train Acc: 46.81% | Val Acc: 51.00% | LR: 0.000003
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 16.01 seconds
INFO:__main__:Epochs Trained: 100
INFO:__main__:Final Train Accuracy: 52.06%
INFO:__main__:Final Val Accuracy: 51.00%
INFO:__main__:Validation F1-Macro: 0.4854
INFO:__main__:Best Val Accuracy: 51.35%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.82      0.68       666
      neutral       0.48      0.46      0.47       666
contradiction       0.40      0.25      0.31       666

     accuracy                           0.51      1998
    macro avg       0.49      0.51      0.49      1998
 weighted avg       0.49      0.51      0.49      1998

INFO:__main__:Results: Accuracy = 50.94% ± 1.29%
INFO:__main__:         F1-Macro = 0.4808 ± 0.0203
INFO:__main__:         Score = 49.65
INFO:__main__:         Time = 80.4s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 46/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.005, 'batch_size': 256, 'dropout_rate': 0.1, 'weight_decay': 0.001}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0058 | Val Loss: 0.9261 | Train Acc: 49.06% | Val Acc: 51.20% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9220 | Val Loss: 0.9235 | Train Acc: 51.40% | Val Acc: 51.35% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9180 | Val Loss: 0.9222 | Train Acc: 53.04% | Val Acc: 50.85% | LR: 0.002500
INFO:__main__:Early stopping triggered at epoch 27
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 4.46 seconds
INFO:__main__:Epochs Trained: 27
INFO:__main__:Final Train Accuracy: 52.33%
INFO:__main__:Final Val Accuracy: 51.70%
INFO:__main__:Validation F1-Macro: 0.4848
INFO:__main__:Best Val Accuracy: 52.35%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.83      0.69       666
      neutral       0.48      0.52      0.50       666
contradiction       0.41      0.20      0.27       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.48      1998
 weighted avg       0.49      0.52      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9907 | Val Loss: 0.9238 | Train Acc: 49.31% | Val Acc: 52.75% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9244 | Val Loss: 0.9200 | Train Acc: 51.91% | Val Acc: 52.50% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9207 | Val Loss: 0.9262 | Train Acc: 51.88% | Val Acc: 53.10% | LR: 0.005000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9172 | Val Loss: 0.9190 | Train Acc: 52.48% | Val Acc: 52.40% | LR: 0.002500
INFO:__main__:Epoch  40/100 | Train Loss: 0.9181 | Val Loss: 0.9183 | Train Acc: 52.44% | Val Acc: 52.60% | LR: 0.001250
INFO:__main__:Epoch  50/100 | Train Loss: 0.9224 | Val Loss: 0.9170 | Train Acc: 52.41% | Val Acc: 52.50% | LR: 0.000625
INFO:__main__:Epoch  60/100 | Train Loss: 0.9153 | Val Loss: 0.9164 | Train Acc: 52.26% | Val Acc: 52.15% | LR: 0.000156
INFO:__main__:Epoch  70/100 | Train Loss: 0.9197 | Val Loss: 0.9164 | Train Acc: 52.20% | Val Acc: 52.55% | LR: 0.000156
INFO:__main__:Epoch  80/100 | Train Loss: 0.9180 | Val Loss: 0.9163 | Train Acc: 52.33% | Val Acc: 52.85% | LR: 0.000039
INFO:__main__:Early stopping triggered at epoch 80
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 12.87 seconds
INFO:__main__:Epochs Trained: 80
INFO:__main__:Final Train Accuracy: 52.43%
INFO:__main__:Final Val Accuracy: 52.85%
INFO:__main__:Validation F1-Macro: 0.4945
INFO:__main__:Best Val Accuracy: 53.25%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.81      0.68       666
      neutral       0.49      0.58      0.53       666
contradiction       0.45      0.20      0.27       666

     accuracy                           0.53      1998
    macro avg       0.51      0.53      0.49      1998
 weighted avg       0.51      0.53      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9812 | Val Loss: 0.9041 | Train Acc: 49.46% | Val Acc: 53.45% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9267 | Val Loss: 0.9075 | Train Acc: 51.39% | Val Acc: 50.95% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9254 | Val Loss: 0.8997 | Train Acc: 52.08% | Val Acc: 53.20% | LR: 0.001250
INFO:__main__:Early stopping triggered at epoch 20
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 3.37 seconds
INFO:__main__:Epochs Trained: 20
INFO:__main__:Final Train Accuracy: 52.49%
INFO:__main__:Final Val Accuracy: 53.20%
INFO:__main__:Validation F1-Macro: 0.4956
INFO:__main__:Best Val Accuracy: 53.90%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.61      0.83      0.70       666
      neutral       0.49      0.59      0.53       666
contradiction       0.41      0.18      0.25       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.50      1998
 weighted avg       0.50      0.53      0.50      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9753 | Val Loss: 0.9363 | Train Acc: 49.49% | Val Acc: 52.50% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9207 | Val Loss: 0.9338 | Train Acc: 52.25% | Val Acc: 50.65% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9148 | Val Loss: 0.9311 | Train Acc: 52.48% | Val Acc: 51.15% | LR: 0.002500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9150 | Val Loss: 0.9304 | Train Acc: 52.29% | Val Acc: 50.45% | LR: 0.001250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9130 | Val Loss: 0.9303 | Train Acc: 52.45% | Val Acc: 50.95% | LR: 0.000625
INFO:__main__:Epoch  50/100 | Train Loss: 0.9148 | Val Loss: 0.9289 | Train Acc: 52.24% | Val Acc: 51.15% | LR: 0.000313
INFO:__main__:Early stopping triggered at epoch 58
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 9.46 seconds
INFO:__main__:Epochs Trained: 58
INFO:__main__:Final Train Accuracy: 52.99%
INFO:__main__:Final Val Accuracy: 51.45%
INFO:__main__:Validation F1-Macro: 0.4706
INFO:__main__:Best Val Accuracy: 52.50%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.83      0.69       666
      neutral       0.46      0.56      0.51       666
contradiction       0.41      0.15      0.22       666

     accuracy                           0.51      1998
    macro avg       0.49      0.51      0.47      1998
 weighted avg       0.49      0.51      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9884 | Val Loss: 0.9221 | Train Acc: 49.79% | Val Acc: 50.75% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9242 | Val Loss: 0.9213 | Train Acc: 51.53% | Val Acc: 52.45% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9218 | Val Loss: 0.9176 | Train Acc: 52.08% | Val Acc: 52.05% | LR: 0.002500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9185 | Val Loss: 0.9175 | Train Acc: 52.60% | Val Acc: 52.15% | LR: 0.001250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9171 | Val Loss: 0.9157 | Train Acc: 52.25% | Val Acc: 53.00% | LR: 0.000625
INFO:__main__:Epoch  50/100 | Train Loss: 0.9164 | Val Loss: 0.9144 | Train Acc: 52.34% | Val Acc: 52.85% | LR: 0.000313
INFO:__main__:Epoch  60/100 | Train Loss: 0.9168 | Val Loss: 0.9148 | Train Acc: 51.99% | Val Acc: 53.35% | LR: 0.000156
INFO:__main__:Early stopping triggered at epoch 65
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 10.54 seconds
INFO:__main__:Epochs Trained: 65
INFO:__main__:Final Train Accuracy: 52.41%
INFO:__main__:Final Val Accuracy: 53.60%
INFO:__main__:Validation F1-Macro: 0.5124
INFO:__main__:Best Val Accuracy: 53.65%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.82      0.69       666
      neutral       0.49      0.53      0.51       666
contradiction       0.46      0.26      0.33       666

     accuracy                           0.54      1998
    macro avg       0.52      0.54      0.51      1998
 weighted avg       0.52      0.54      0.51      1998

INFO:__main__:NEW BEST RESULT!
INFO:__main__:Results: Accuracy = 52.56% ± 0.84%
INFO:__main__:         F1-Macro = 0.4916 ± 0.0137
INFO:__main__:         Score = 51.72
INFO:__main__:         Time = 40.7s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 47/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.001, 'batch_size': 32, 'dropout_rate': 0.3, 'weight_decay': 0.0001}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0856 | Val Loss: 0.9351 | Train Acc: 45.13% | Val Acc: 52.40% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9327 | Val Loss: 0.9238 | Train Acc: 51.53% | Val Acc: 51.30% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9316 | Val Loss: 0.9228 | Train Acc: 51.69% | Val Acc: 52.20% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9287 | Val Loss: 0.9203 | Train Acc: 51.70% | Val Acc: 51.95% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 33
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 28.75 seconds
INFO:__main__:Epochs Trained: 33
INFO:__main__:Final Train Accuracy: 52.60%
INFO:__main__:Final Val Accuracy: 52.00%
INFO:__main__:Validation F1-Macro: 0.4930
INFO:__main__:Best Val Accuracy: 53.05%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.79      0.69       666
      neutral       0.47      0.55      0.51       666
contradiction       0.42      0.22      0.28       666

     accuracy                           0.52      1998
    macro avg       0.50      0.52      0.49      1998
 weighted avg       0.50      0.52      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0766 | Val Loss: 0.9422 | Train Acc: 45.53% | Val Acc: 49.30% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9369 | Val Loss: 0.9201 | Train Acc: 50.79% | Val Acc: 52.20% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9355 | Val Loss: 0.9203 | Train Acc: 51.61% | Val Acc: 51.90% | LR: 0.000250
INFO:__main__:Epoch  30/100 | Train Loss: 0.9349 | Val Loss: 0.9199 | Train Acc: 51.44% | Val Acc: 52.35% | LR: 0.000250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9316 | Val Loss: 0.9185 | Train Acc: 52.14% | Val Acc: 52.05% | LR: 0.000063
INFO:__main__:Early stopping triggered at epoch 42
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 36.46 seconds
INFO:__main__:Epochs Trained: 42
INFO:__main__:Final Train Accuracy: 52.40%
INFO:__main__:Final Val Accuracy: 52.35%
INFO:__main__:Validation F1-Macro: 0.4911
INFO:__main__:Best Val Accuracy: 53.00%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.81      0.69       666
      neutral       0.49      0.57      0.53       666
contradiction       0.39      0.19      0.26       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.49      1998
 weighted avg       0.49      0.52      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0827 | Val Loss: 0.9137 | Train Acc: 46.26% | Val Acc: 53.20% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9363 | Val Loss: 0.9027 | Train Acc: 50.88% | Val Acc: 53.30% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9379 | Val Loss: 0.9037 | Train Acc: 50.56% | Val Acc: 52.65% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9355 | Val Loss: 0.9002 | Train Acc: 51.78% | Val Acc: 53.80% | LR: 0.000250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9362 | Val Loss: 0.9012 | Train Acc: 51.63% | Val Acc: 53.20% | LR: 0.000125
INFO:__main__:Epoch  50/100 | Train Loss: 0.9337 | Val Loss: 0.9009 | Train Acc: 50.88% | Val Acc: 53.70% | LR: 0.000063
INFO:__main__:Early stopping triggered at epoch 50
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 44.13 seconds
INFO:__main__:Epochs Trained: 50
INFO:__main__:Final Train Accuracy: 52.01%
INFO:__main__:Final Val Accuracy: 53.70%
INFO:__main__:Validation F1-Macro: 0.4826
INFO:__main__:Best Val Accuracy: 53.90%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.61      0.83      0.70       666
      neutral       0.49      0.67      0.56       666
contradiction       0.43      0.12      0.18       666

     accuracy                           0.54      1998
    macro avg       0.51      0.54      0.48      1998
 weighted avg       0.51      0.54      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0601 | Val Loss: 0.9461 | Train Acc: 46.35% | Val Acc: 50.50% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9344 | Val Loss: 0.9294 | Train Acc: 51.20% | Val Acc: 51.30% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9305 | Val Loss: 0.9306 | Train Acc: 51.59% | Val Acc: 49.95% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9262 | Val Loss: 0.9290 | Train Acc: 51.95% | Val Acc: 50.45% | LR: 0.000250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9247 | Val Loss: 0.9291 | Train Acc: 52.21% | Val Acc: 50.05% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 46
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 39.83 seconds
INFO:__main__:Epochs Trained: 46
INFO:__main__:Final Train Accuracy: 52.74%
INFO:__main__:Final Val Accuracy: 50.50%
INFO:__main__:Validation F1-Macro: 0.4663
INFO:__main__:Best Val Accuracy: 51.90%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.57      0.84      0.68       666
      neutral       0.47      0.51      0.49       666
contradiction       0.38      0.17      0.23       666

     accuracy                           0.51      1998
    macro avg       0.47      0.51      0.47      1998
 weighted avg       0.47      0.51      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0533 | Val Loss: 0.9281 | Train Acc: 45.77% | Val Acc: 52.25% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9386 | Val Loss: 0.9226 | Train Acc: 51.05% | Val Acc: 50.40% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9317 | Val Loss: 0.9208 | Train Acc: 51.43% | Val Acc: 53.10% | LR: 0.000500
INFO:__main__:Early stopping triggered at epoch 29
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 25.35 seconds
INFO:__main__:Epochs Trained: 29
INFO:__main__:Final Train Accuracy: 52.05%
INFO:__main__:Final Val Accuracy: 52.65%
INFO:__main__:Validation F1-Macro: 0.4921
INFO:__main__:Best Val Accuracy: 53.10%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.81      0.69       666
      neutral       0.50      0.59      0.54       666
contradiction       0.38      0.18      0.24       666

     accuracy                           0.53      1998
    macro avg       0.49      0.53      0.49      1998
 weighted avg       0.49      0.53      0.49      1998

INFO:__main__:Results: Accuracy = 52.24% ± 1.04%
INFO:__main__:         F1-Macro = 0.4850 ± 0.0100
INFO:__main__:         Score = 51.20
INFO:__main__:         Time = 174.5s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 48/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.0005, 'batch_size': 32, 'dropout_rate': 0.3, 'weight_decay': 0.005}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1565 | Val Loss: 0.9699 | Train Acc: 41.95% | Val Acc: 51.20% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9375 | Val Loss: 0.9300 | Train Acc: 51.26% | Val Acc: 52.10% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9350 | Val Loss: 0.9299 | Train Acc: 51.25% | Val Acc: 52.15% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9317 | Val Loss: 0.9267 | Train Acc: 51.61% | Val Acc: 52.10% | LR: 0.000250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9316 | Val Loss: 0.9245 | Train Acc: 52.11% | Val Acc: 52.30% | LR: 0.000063
INFO:__main__:Early stopping triggered at epoch 41
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 35.47 seconds
INFO:__main__:Epochs Trained: 41
INFO:__main__:Final Train Accuracy: 52.18%
INFO:__main__:Final Val Accuracy: 51.80%
INFO:__main__:Validation F1-Macro: 0.4798
INFO:__main__:Best Val Accuracy: 52.85%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.81      0.68       666
      neutral       0.49      0.58      0.53       666
contradiction       0.38      0.16      0.23       666

     accuracy                           0.52      1998
    macro avg       0.48      0.52      0.48      1998
 weighted avg       0.48      0.52      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1138 | Val Loss: 0.9609 | Train Acc: 42.92% | Val Acc: 51.15% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9383 | Val Loss: 0.9227 | Train Acc: 51.39% | Val Acc: 52.75% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9338 | Val Loss: 0.9239 | Train Acc: 51.44% | Val Acc: 52.30% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 29
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 25.55 seconds
INFO:__main__:Epochs Trained: 29
INFO:__main__:Final Train Accuracy: 52.35%
INFO:__main__:Final Val Accuracy: 52.00%
INFO:__main__:Validation F1-Macro: 0.4857
INFO:__main__:Best Val Accuracy: 52.75%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.82      0.68       666
      neutral       0.50      0.56      0.53       666
contradiction       0.39      0.18      0.25       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.49      1998
 weighted avg       0.49      0.52      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0935 | Val Loss: 0.9373 | Train Acc: 44.06% | Val Acc: 52.20% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9437 | Val Loss: 0.9068 | Train Acc: 50.88% | Val Acc: 53.00% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9368 | Val Loss: 0.9028 | Train Acc: 50.76% | Val Acc: 53.50% | LR: 0.000250
INFO:__main__:Epoch  30/100 | Train Loss: 0.9377 | Val Loss: 0.9069 | Train Acc: 50.84% | Val Acc: 53.75% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 35
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 30.79 seconds
INFO:__main__:Epochs Trained: 35
INFO:__main__:Final Train Accuracy: 51.93%
INFO:__main__:Final Val Accuracy: 53.50%
INFO:__main__:Validation F1-Macro: 0.5013
INFO:__main__:Best Val Accuracy: 53.75%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.61      0.82      0.70       666
      neutral       0.50      0.59      0.54       666
contradiction       0.40      0.19      0.26       666

     accuracy                           0.54      1998
    macro avg       0.50      0.54      0.50      1998
 weighted avg       0.50      0.54      0.50      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1052 | Val Loss: 0.9581 | Train Acc: 44.12% | Val Acc: 50.35% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9365 | Val Loss: 0.9332 | Train Acc: 51.53% | Val Acc: 50.80% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9308 | Val Loss: 0.9307 | Train Acc: 52.04% | Val Acc: 50.75% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 28
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 24.69 seconds
INFO:__main__:Epochs Trained: 28
INFO:__main__:Final Train Accuracy: 52.39%
INFO:__main__:Final Val Accuracy: 50.40%
INFO:__main__:Validation F1-Macro: 0.4689
INFO:__main__:Best Val Accuracy: 51.80%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.82      0.68       666
      neutral       0.46      0.52      0.49       666
contradiction       0.38      0.18      0.24       666

     accuracy                           0.50      1998
    macro avg       0.47      0.50      0.47      1998
 weighted avg       0.47      0.50      0.47      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1193 | Val Loss: 0.9403 | Train Acc: 43.61% | Val Acc: 51.65% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9396 | Val Loss: 0.9241 | Train Acc: 51.15% | Val Acc: 52.25% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9326 | Val Loss: 0.9261 | Train Acc: 51.96% | Val Acc: 52.10% | LR: 0.000250
INFO:__main__:Epoch  30/100 | Train Loss: 0.9350 | Val Loss: 0.9219 | Train Acc: 51.39% | Val Acc: 53.00% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 34
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 29.93 seconds
INFO:__main__:Epochs Trained: 34
INFO:__main__:Final Train Accuracy: 52.14%
INFO:__main__:Final Val Accuracy: 52.90%
INFO:__main__:Validation F1-Macro: 0.5072
INFO:__main__:Best Val Accuracy: 53.05%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.80      0.69       666
      neutral       0.51      0.53      0.52       666
contradiction       0.40      0.26      0.31       666

     accuracy                           0.53      1998
    macro avg       0.51      0.53      0.51      1998
 weighted avg       0.51      0.53      0.51      1998

INFO:__main__:Results: Accuracy = 52.12% ± 1.06%
INFO:__main__:         F1-Macro = 0.4886 ± 0.0140
INFO:__main__:         Score = 51.06
INFO:__main__:         Time = 146.5s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 49/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.0005, 'batch_size': 128, 'dropout_rate': 0.1, 'weight_decay': 0.005}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1378 | Val Loss: 0.9667 | Train Acc: 43.27% | Val Acc: 50.85% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9233 | Val Loss: 0.9240 | Train Acc: 52.15% | Val Acc: 52.45% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9195 | Val Loss: 0.9223 | Train Acc: 52.40% | Val Acc: 52.20% | LR: 0.000125
INFO:__main__:Epoch  30/100 | Train Loss: 0.9173 | Val Loss: 0.9221 | Train Acc: 52.79% | Val Acc: 51.65% | LR: 0.000063
INFO:__main__:Early stopping triggered at epoch 38
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 9.94 seconds
INFO:__main__:Epochs Trained: 38
INFO:__main__:Final Train Accuracy: 53.48%
INFO:__main__:Final Val Accuracy: 51.65%
INFO:__main__:Validation F1-Macro: 0.4929
INFO:__main__:Best Val Accuracy: 52.45%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.80      0.69       666
      neutral       0.46      0.50      0.48       666
contradiction       0.43      0.25      0.31       666

     accuracy                           0.52      1998
    macro avg       0.50      0.52      0.49      1998
 weighted avg       0.50      0.52      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0439 | Val Loss: 0.9469 | Train Acc: 47.32% | Val Acc: 52.20% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9299 | Val Loss: 0.9223 | Train Acc: 52.13% | Val Acc: 52.55% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9234 | Val Loss: 0.9218 | Train Acc: 52.06% | Val Acc: 51.85% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9183 | Val Loss: 0.9224 | Train Acc: 51.71% | Val Acc: 52.35% | LR: 0.000500
INFO:__main__:Epoch  40/100 | Train Loss: 0.9194 | Val Loss: 0.9229 | Train Acc: 52.34% | Val Acc: 51.55% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 40
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 10.43 seconds
INFO:__main__:Epochs Trained: 40
INFO:__main__:Final Train Accuracy: 52.87%
INFO:__main__:Final Val Accuracy: 51.55%
INFO:__main__:Validation F1-Macro: 0.4972
INFO:__main__:Best Val Accuracy: 52.75%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.80      0.68       666
      neutral       0.48      0.44      0.46       666
contradiction       0.43      0.30      0.35       666

     accuracy                           0.52      1998
    macro avg       0.50      0.52      0.50      1998
 weighted avg       0.50      0.52      0.50      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0678 | Val Loss: 0.9169 | Train Acc: 44.36% | Val Acc: 52.40% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9341 | Val Loss: 0.8998 | Train Acc: 51.44% | Val Acc: 52.70% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9249 | Val Loss: 0.9005 | Train Acc: 52.15% | Val Acc: 52.90% | LR: 0.000500
INFO:__main__:Early stopping triggered at epoch 29
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 7.61 seconds
INFO:__main__:Epochs Trained: 29
INFO:__main__:Final Train Accuracy: 52.92%
INFO:__main__:Final Val Accuracy: 53.25%
INFO:__main__:Validation F1-Macro: 0.5035
INFO:__main__:Best Val Accuracy: 53.90%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.84      0.70       666
      neutral       0.49      0.52      0.51       666
contradiction       0.45      0.24      0.31       666

     accuracy                           0.53      1998
    macro avg       0.51      0.53      0.50      1998
 weighted avg       0.51      0.53      0.50      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0941 | Val Loss: 0.9702 | Train Acc: 45.30% | Val Acc: 51.50% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9334 | Val Loss: 0.9318 | Train Acc: 52.31% | Val Acc: 51.00% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9237 | Val Loss: 0.9327 | Train Acc: 51.95% | Val Acc: 50.85% | LR: 0.000250
INFO:__main__:Epoch  30/100 | Train Loss: 0.9181 | Val Loss: 0.9296 | Train Acc: 53.08% | Val Acc: 51.20% | LR: 0.000250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9179 | Val Loss: 0.9288 | Train Acc: 52.58% | Val Acc: 51.05% | LR: 0.000250
INFO:__main__:Epoch  50/100 | Train Loss: 0.9150 | Val Loss: 0.9283 | Train Acc: 52.87% | Val Acc: 51.00% | LR: 0.000125
INFO:__main__:Epoch  60/100 | Train Loss: 0.9164 | Val Loss: 0.9280 | Train Acc: 53.05% | Val Acc: 51.70% | LR: 0.000031
INFO:__main__:Early stopping triggered at epoch 62
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 16.08 seconds
INFO:__main__:Epochs Trained: 62
INFO:__main__:Final Train Accuracy: 53.29%
INFO:__main__:Final Val Accuracy: 51.70%
INFO:__main__:Validation F1-Macro: 0.4787
INFO:__main__:Best Val Accuracy: 51.85%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.83      0.68       666
      neutral       0.47      0.55      0.50       666
contradiction       0.43      0.17      0.25       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.48      1998
 weighted avg       0.49      0.52      0.48      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0592 | Val Loss: 0.9355 | Train Acc: 45.37% | Val Acc: 51.75% | LR: 0.000500
INFO:__main__:Epoch  10/100 | Train Loss: 0.9294 | Val Loss: 0.9170 | Train Acc: 51.99% | Val Acc: 52.45% | LR: 0.000500
INFO:__main__:Epoch  20/100 | Train Loss: 0.9220 | Val Loss: 0.9164 | Train Acc: 52.24% | Val Acc: 52.75% | LR: 0.000250
INFO:__main__:Epoch  30/100 | Train Loss: 0.9207 | Val Loss: 0.9160 | Train Acc: 52.19% | Val Acc: 52.60% | LR: 0.000063
INFO:__main__:Early stopping triggered at epoch 31
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 8.09 seconds
INFO:__main__:Epochs Trained: 31
INFO:__main__:Final Train Accuracy: 53.50%
INFO:__main__:Final Val Accuracy: 52.85%
INFO:__main__:Validation F1-Macro: 0.5070
INFO:__main__:Best Val Accuracy: 53.15%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.81      0.69       666
      neutral       0.49      0.50      0.49       666
contradiction       0.44      0.27      0.34       666

     accuracy                           0.53      1998
    macro avg       0.51      0.53      0.51      1998
 weighted avg       0.51      0.53      0.51      1998

INFO:__main__:Results: Accuracy = 52.20% ± 0.71%
INFO:__main__:         F1-Macro = 0.4958 ± 0.0099
INFO:__main__:         Score = 51.49
INFO:__main__:         Time = 52.2s
INFO:__main__:
--------------------------------------------------
INFO:__main__:COMBINATION 50/50
INFO:__main__:--------------------------------------------------
INFO:__main__:Hyperparameters: {'learning_rate': 0.001, 'batch_size': 128, 'dropout_rate': 0.3, 'weight_decay': 0.001}
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1638 | Val Loss: 0.9659 | Train Acc: 42.14% | Val Acc: 50.15% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9340 | Val Loss: 0.9221 | Train Acc: 51.63% | Val Acc: 52.00% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9308 | Val Loss: 0.9223 | Train Acc: 52.55% | Val Acc: 51.50% | LR: 0.000500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9261 | Val Loss: 0.9207 | Train Acc: 51.75% | Val Acc: 52.65% | LR: 0.000500
INFO:__main__:Epoch  40/100 | Train Loss: 0.9291 | Val Loss: 0.9220 | Train Acc: 52.33% | Val Acc: 51.40% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 43
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 11.20 seconds
INFO:__main__:Epochs Trained: 43
INFO:__main__:Final Train Accuracy: 52.39%
INFO:__main__:Final Val Accuracy: 51.55%
INFO:__main__:Validation F1-Macro: 0.4861
INFO:__main__:Best Val Accuracy: 52.65%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.82      0.69       666
      neutral       0.47      0.51      0.49       666
contradiction       0.42      0.22      0.28       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.49      1998
 weighted avg       0.49      0.52      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1334 | Val Loss: 0.9519 | Train Acc: 42.87% | Val Acc: 49.70% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9348 | Val Loss: 0.9223 | Train Acc: 50.69% | Val Acc: 52.60% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9275 | Val Loss: 0.9208 | Train Acc: 52.44% | Val Acc: 52.65% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9269 | Val Loss: 0.9205 | Train Acc: 51.58% | Val Acc: 52.50% | LR: 0.000500
INFO:__main__:Epoch  40/100 | Train Loss: 0.9238 | Val Loss: 0.9203 | Train Acc: 52.14% | Val Acc: 52.45% | LR: 0.000250
INFO:__main__:Epoch  50/100 | Train Loss: 0.9268 | Val Loss: 0.9205 | Train Acc: 52.16% | Val Acc: 51.85% | LR: 0.000063
INFO:__main__:Early stopping triggered at epoch 52
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 13.84 seconds
INFO:__main__:Epochs Trained: 52
INFO:__main__:Final Train Accuracy: 52.54%
INFO:__main__:Final Val Accuracy: 52.50%
INFO:__main__:Validation F1-Macro: 0.4911
INFO:__main__:Best Val Accuracy: 53.00%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.81      0.69       666
      neutral       0.49      0.57      0.53       666
contradiction       0.41      0.19      0.26       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.49      1998
 weighted avg       0.50      0.53      0.49      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1209 | Val Loss: 0.9251 | Train Acc: 43.72% | Val Acc: 52.95% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9413 | Val Loss: 0.9017 | Train Acc: 51.13% | Val Acc: 53.85% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9379 | Val Loss: 0.9022 | Train Acc: 51.50% | Val Acc: 53.60% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9321 | Val Loss: 0.9011 | Train Acc: 51.98% | Val Acc: 53.20% | LR: 0.000500
INFO:__main__:Epoch  40/100 | Train Loss: 0.9323 | Val Loss: 0.9005 | Train Acc: 51.95% | Val Acc: 53.50% | LR: 0.000250
INFO:__main__:Early stopping triggered at epoch 44
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 12.00 seconds
INFO:__main__:Epochs Trained: 44
INFO:__main__:Final Train Accuracy: 52.16%
INFO:__main__:Final Val Accuracy: 53.25%
INFO:__main__:Validation F1-Macro: 0.5047
INFO:__main__:Best Val Accuracy: 54.35%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.85      0.69       666
      neutral       0.51      0.51      0.51       666
contradiction       0.43      0.24      0.31       666

     accuracy                           0.53      1998
    macro avg       0.51      0.53      0.50      1998
 weighted avg       0.51      0.53      0.50      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1082 | Val Loss: 0.9509 | Train Acc: 44.21% | Val Acc: 50.95% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9317 | Val Loss: 0.9321 | Train Acc: 51.90% | Val Acc: 50.40% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9263 | Val Loss: 0.9299 | Train Acc: 51.91% | Val Acc: 50.50% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9236 | Val Loss: 0.9301 | Train Acc: 52.26% | Val Acc: 50.20% | LR: 0.000500
INFO:__main__:Epoch  40/100 | Train Loss: 0.9218 | Val Loss: 0.9295 | Train Acc: 52.58% | Val Acc: 50.50% | LR: 0.000250
INFO:__main__:Epoch  50/100 | Train Loss: 0.9220 | Val Loss: 0.9295 | Train Acc: 52.26% | Val Acc: 50.65% | LR: 0.000250
INFO:__main__:Epoch  60/100 | Train Loss: 0.9217 | Val Loss: 0.9288 | Train Acc: 52.89% | Val Acc: 50.70% | LR: 0.000125
INFO:__main__:Early stopping triggered at epoch 68
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 17.73 seconds
INFO:__main__:Epochs Trained: 68
INFO:__main__:Final Train Accuracy: 53.17%
INFO:__main__:Final Val Accuracy: 50.80%
INFO:__main__:Validation F1-Macro: 0.4568
INFO:__main__:Best Val Accuracy: 51.25%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.57      0.84      0.68       666
      neutral       0.46      0.56      0.51       666
contradiction       0.38      0.12      0.18       666

     accuracy                           0.51      1998
    macro avg       0.47      0.51      0.46      1998
 weighted avg       0.47      0.51      0.46      1998

INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.1499 | Val Loss: 0.9587 | Train Acc: 44.47% | Val Acc: 51.40% | LR: 0.001000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9421 | Val Loss: 0.9166 | Train Acc: 51.59% | Val Acc: 52.15% | LR: 0.001000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9308 | Val Loss: 0.9158 | Train Acc: 51.53% | Val Acc: 51.55% | LR: 0.001000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9307 | Val Loss: 0.9157 | Train Acc: 51.51% | Val Acc: 51.65% | LR: 0.000500
INFO:__main__:Early stopping triggered at epoch 34
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 9.06 seconds
INFO:__main__:Epochs Trained: 34
INFO:__main__:Final Train Accuracy: 52.50%
INFO:__main__:Final Val Accuracy: 51.70%
INFO:__main__:Validation F1-Macro: 0.4889
INFO:__main__:Best Val Accuracy: 52.25%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.83      0.69       666
      neutral       0.49      0.50      0.49       666
contradiction       0.39      0.22      0.28       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.49      1998
 weighted avg       0.49      0.52      0.49      1998

INFO:__main__:Results: Accuracy = 51.96% ± 0.84%
INFO:__main__:         F1-Macro = 0.4855 ± 0.0157
INFO:__main__:         Score = 51.12
INFO:__main__:         Time = 63.9s
INFO:__main__:
======================================================================
INFO:__main__:HYPERPARAMETER SEARCH COMPLETED
INFO:__main__:======================================================================
INFO:__main__:
Top 5 Hyperparameter Combinations:
INFO:__main__:1. Score: 51.72 | Accuracy: 52.56% ± 0.84% | Params: {'learning_rate': 0.005, 'batch_size': 256, 'dropout_rate': 0.1, 'weight_decay': 0.001}
INFO:__main__:2. Score: 51.70 | Accuracy: 52.48% ± 0.78% | Params: {'learning_rate': 0.001, 'batch_size': 256, 'dropout_rate': 0.1, 'weight_decay': 0.005}
INFO:__main__:3. Score: 51.58 | Accuracy: 52.19% ± 0.62% | Params: {'learning_rate': 0.005, 'batch_size': 64, 'dropout_rate': 0.3, 'weight_decay': 0.001}
INFO:__main__:4. Score: 51.53 | Accuracy: 52.12% ± 0.59% | Params: {'learning_rate': 0.005, 'batch_size': 32, 'dropout_rate': 0.1, 'weight_decay': 0.0001}
INFO:__main__:5. Score: 51.50 | Accuracy: 52.17% ± 0.67% | Params: {'learning_rate': 0.005, 'batch_size': 128, 'dropout_rate': 0.1, 'weight_decay': 0.005}
INFO:__main__:
BEST HYPERPARAMETERS:
INFO:__main__:Parameters: {'learning_rate': 0.005, 'batch_size': 256, 'dropout_rate': 0.1, 'weight_decay': 0.001}
INFO:__main__:Validation Accuracy: 52.56% ± 0.84%
INFO:__main__:Validation F1-Macro: 0.4916 ± 0.0137
INFO:__main__:Optimization Score: 51.72
INFO:__main__:
Hyperparameter search results saved to results/overnight_normal_hyperparam_search/hyperparameter_search_results.json
INFO:__main__:
Training final model with best hyperparameters...
INFO:__main__:Best hyperparameters: {'learning_rate': 0.005, 'batch_size': 256, 'dropout_rate': 0.1, 'weight_decay': 0.001}
INFO:__main__:Using device: cuda
INFO:__main__:
Preparing fold 1/5
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 1
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 1.0058 | Val Loss: 0.9261 | Train Acc: 49.06% | Val Acc: 51.20% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9220 | Val Loss: 0.9235 | Train Acc: 51.40% | Val Acc: 51.35% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9180 | Val Loss: 0.9222 | Train Acc: 53.04% | Val Acc: 50.85% | LR: 0.002500
INFO:__main__:Early stopping triggered at epoch 27
INFO:__main__:
Fold 1 Results:
INFO:__main__:Training Time: 4.86 seconds
INFO:__main__:Epochs Trained: 27
INFO:__main__:Final Train Accuracy: 52.33%
INFO:__main__:Final Val Accuracy: 51.70%
INFO:__main__:Validation F1-Macro: 0.4848
INFO:__main__:Best Val Accuracy: 52.35%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.83      0.69       666
      neutral       0.48      0.52      0.50       666
contradiction       0.41      0.20      0.27       666

     accuracy                           0.52      1998
    macro avg       0.49      0.52      0.48      1998
 weighted avg       0.49      0.52      0.48      1998

INFO:__main__:Saved model checkpoint: results/overnight_normal_hyperparam_search/final_model/model_fold_1.pt
INFO:__main__:
Preparing fold 2/5
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 2
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9907 | Val Loss: 0.9238 | Train Acc: 49.31% | Val Acc: 52.75% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9244 | Val Loss: 0.9200 | Train Acc: 51.91% | Val Acc: 52.50% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9207 | Val Loss: 0.9262 | Train Acc: 51.88% | Val Acc: 53.10% | LR: 0.005000
INFO:__main__:Epoch  30/100 | Train Loss: 0.9172 | Val Loss: 0.9190 | Train Acc: 52.48% | Val Acc: 52.40% | LR: 0.002500
INFO:__main__:Epoch  40/100 | Train Loss: 0.9181 | Val Loss: 0.9183 | Train Acc: 52.44% | Val Acc: 52.60% | LR: 0.001250
INFO:__main__:Epoch  50/100 | Train Loss: 0.9224 | Val Loss: 0.9170 | Train Acc: 52.41% | Val Acc: 52.50% | LR: 0.000625
INFO:__main__:Epoch  60/100 | Train Loss: 0.9153 | Val Loss: 0.9164 | Train Acc: 52.26% | Val Acc: 52.15% | LR: 0.000156
INFO:__main__:Epoch  70/100 | Train Loss: 0.9197 | Val Loss: 0.9164 | Train Acc: 52.20% | Val Acc: 52.55% | LR: 0.000156
INFO:__main__:Epoch  80/100 | Train Loss: 0.9180 | Val Loss: 0.9163 | Train Acc: 52.33% | Val Acc: 52.85% | LR: 0.000039
INFO:__main__:Early stopping triggered at epoch 80
INFO:__main__:
Fold 2 Results:
INFO:__main__:Training Time: 14.13 seconds
INFO:__main__:Epochs Trained: 80
INFO:__main__:Final Train Accuracy: 52.43%
INFO:__main__:Final Val Accuracy: 52.85%
INFO:__main__:Validation F1-Macro: 0.4945
INFO:__main__:Best Val Accuracy: 53.25%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.59      0.81      0.68       666
      neutral       0.49      0.58      0.53       666
contradiction       0.45      0.20      0.27       666

     accuracy                           0.53      1998
    macro avg       0.51      0.53      0.49      1998
 weighted avg       0.51      0.53      0.49      1998

INFO:__main__:Saved model checkpoint: results/overnight_normal_hyperparam_search/final_model/model_fold_2.pt
INFO:__main__:
Preparing fold 3/5
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 3
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9812 | Val Loss: 0.9041 | Train Acc: 49.46% | Val Acc: 53.45% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9267 | Val Loss: 0.9075 | Train Acc: 51.39% | Val Acc: 50.95% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9254 | Val Loss: 0.8997 | Train Acc: 52.08% | Val Acc: 53.20% | LR: 0.001250
INFO:__main__:Early stopping triggered at epoch 20
INFO:__main__:
Fold 3 Results:
INFO:__main__:Training Time: 3.45 seconds
INFO:__main__:Epochs Trained: 20
INFO:__main__:Final Train Accuracy: 52.49%
INFO:__main__:Final Val Accuracy: 53.20%
INFO:__main__:Validation F1-Macro: 0.4956
INFO:__main__:Best Val Accuracy: 53.90%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.61      0.83      0.70       666
      neutral       0.49      0.59      0.53       666
contradiction       0.41      0.18      0.25       666

     accuracy                           0.53      1998
    macro avg       0.50      0.53      0.50      1998
 weighted avg       0.50      0.53      0.50      1998

INFO:__main__:Saved model checkpoint: results/overnight_normal_hyperparam_search/final_model/model_fold_3.pt
INFO:__main__:
Preparing fold 4/5
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 4
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9753 | Val Loss: 0.9363 | Train Acc: 49.49% | Val Acc: 52.50% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9207 | Val Loss: 0.9338 | Train Acc: 52.25% | Val Acc: 50.65% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9148 | Val Loss: 0.9311 | Train Acc: 52.48% | Val Acc: 51.15% | LR: 0.002500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9150 | Val Loss: 0.9304 | Train Acc: 52.29% | Val Acc: 50.45% | LR: 0.001250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9130 | Val Loss: 0.9303 | Train Acc: 52.45% | Val Acc: 50.95% | LR: 0.000625
INFO:__main__:Epoch  50/100 | Train Loss: 0.9148 | Val Loss: 0.9289 | Train Acc: 52.24% | Val Acc: 51.15% | LR: 0.000313
INFO:__main__:Early stopping triggered at epoch 58
INFO:__main__:
Fold 4 Results:
INFO:__main__:Training Time: 10.07 seconds
INFO:__main__:Epochs Trained: 58
INFO:__main__:Final Train Accuracy: 52.99%
INFO:__main__:Final Val Accuracy: 51.45%
INFO:__main__:Validation F1-Macro: 0.4706
INFO:__main__:Best Val Accuracy: 52.50%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.58      0.83      0.69       666
      neutral       0.46      0.56      0.51       666
contradiction       0.41      0.15      0.22       666

     accuracy                           0.51      1998
    macro avg       0.49      0.51      0.47      1998
 weighted avg       0.49      0.51      0.47      1998

INFO:__main__:Saved model checkpoint: results/overnight_normal_hyperparam_search/final_model/model_fold_4.pt
INFO:__main__:
Preparing fold 5/5
INFO:neural_classifier_landmark:Fitting feature normalizer (StandardScaler)...
INFO:neural_classifier_landmark:Normalizer fitted for 7 features.
INFO:neural_classifier_landmark:Feature names: []
INFO:__main__:
==================================================
INFO:__main__:TRAINING FOLD 5
INFO:__main__:==================================================
INFO:__main__:Class counts: [2664, 2664, 2664]
INFO:__main__:Class weights: [1.0, 1.0, 1.0]
/vol/bitbucket/ahb24/tda_entailment_new/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
INFO:__main__:Epoch   1/100 | Train Loss: 0.9884 | Val Loss: 0.9221 | Train Acc: 49.79% | Val Acc: 50.75% | LR: 0.005000
INFO:__main__:Epoch  10/100 | Train Loss: 0.9242 | Val Loss: 0.9213 | Train Acc: 51.53% | Val Acc: 52.45% | LR: 0.005000
INFO:__main__:Epoch  20/100 | Train Loss: 0.9218 | Val Loss: 0.9176 | Train Acc: 52.08% | Val Acc: 52.05% | LR: 0.002500
INFO:__main__:Epoch  30/100 | Train Loss: 0.9185 | Val Loss: 0.9175 | Train Acc: 52.60% | Val Acc: 52.15% | LR: 0.001250
INFO:__main__:Epoch  40/100 | Train Loss: 0.9171 | Val Loss: 0.9157 | Train Acc: 52.25% | Val Acc: 53.00% | LR: 0.000625
INFO:__main__:Epoch  50/100 | Train Loss: 0.9164 | Val Loss: 0.9144 | Train Acc: 52.34% | Val Acc: 52.85% | LR: 0.000313
INFO:__main__:Epoch  60/100 | Train Loss: 0.9168 | Val Loss: 0.9148 | Train Acc: 51.99% | Val Acc: 53.35% | LR: 0.000156
INFO:__main__:Early stopping triggered at epoch 65
INFO:__main__:
Fold 5 Results:
INFO:__main__:Training Time: 11.24 seconds
INFO:__main__:Epochs Trained: 65
INFO:__main__:Final Train Accuracy: 52.41%
INFO:__main__:Final Val Accuracy: 53.60%
INFO:__main__:Validation F1-Macro: 0.5124
INFO:__main__:Best Val Accuracy: 53.65%
INFO:__main__:
Detailed Classification Report:
INFO:__main__:
               precision    recall  f1-score   support

   entailment       0.60      0.82      0.69       666
      neutral       0.49      0.53      0.51       666
contradiction       0.46      0.26      0.33       666

     accuracy                           0.54      1998
    macro avg       0.52      0.54      0.51      1998
 weighted avg       0.52      0.54      0.51      1998

INFO:__main__:Saved model checkpoint: results/overnight_normal_hyperparam_search/final_model/model_fold_5.pt
INFO:__main__:
============================================================
INFO:__main__:CROSS-VALIDATION SUMMARY
INFO:__main__:============================================================
INFO:__main__:Validation Accuracy: 52.56% ± 0.84%
INFO:__main__:Range: 51.45% - 53.60%
INFO:__main__:Validation F1-Macro: 0.4916 ± 0.0137
INFO:__main__:Total Training Time: 43.75 seconds
INFO:__main__:Average Epochs: 50.0
INFO:__main__:
Per-Fold Results:
INFO:__main__:Fold 1: Val Acc = 51.70%, F1 = 0.4848, Epochs = 27
INFO:__main__:Fold 2: Val Acc = 52.85%, F1 = 0.4945, Epochs = 80
INFO:__main__:Fold 3: Val Acc = 53.20%, F1 = 0.4956, Epochs = 20
INFO:__main__:Fold 4: Val Acc = 51.45%, F1 = 0.4706, Epochs = 58
INFO:__main__:Fold 5: Val Acc = 53.60%, F1 = 0.5124, Epochs = 65
INFO:__main__:
Diagnostic Analysis:
INFO:__main__:Train-Val gap is reasonable: -0.03%
INFO:__main__:Low variance across folds: 0.84%
WARNING:__main__:MODERATE: Validation accuracy 45-60% - consider TDA pipeline improvements
INFO:__main__:Final model results saved to results/overnight_normal_hyperparam_search/final_model/final_cv_results.json
INFO:__main__:
Training completed successfully!
